file_diff,commit_time,file_diff_id
"@@ -144,6 +144,7 @@ protected void destroy() {
       super.destroy();
    }
 
+   @Test (enabled = false, description = ""Temporary disabled : https://issues.jboss.org/browse/ISPN-2249"")
    public void testHashInfoRetrieved() throws InterruptedException {
       assertEquals(3, tcpConnectionFactory.getServers().size());
       for (int i = 0; i < 10; i++) {",2012-08-31T21:22:26Z,1
"@@ -37,7 +37,7 @@
 import javax.transaction.RollbackException;
 import javax.transaction.Transaction;
 
-@Test(testName = ""container.versioning.VersionedDistStateTransferTest"", groups = ""functional"")
+@Test(testName = ""container.versioning.VersionedDistStateTransferTest"", groups = ""functional"", enabled = false, description = ""Temporary disabled : https://issues.jboss.org/browse/ISPN-2249"")
 @CleanupAfterMethod
 public class VersionedDistStateTransferTest extends MultipleCacheManagersTest {
    ConfigurationBuilder builder;",2012-08-31T21:22:26Z,2
"@@ -285,7 +285,8 @@ public void testAtomicReplaceFromNonOwnerWithFlag() throws Exception {
          }
       }
    }
-   
+
+   @Test (enabled = false, description = ""Temporary disabled : https://issues.jboss.org/browse/ISPN-2249"")
    public void testAtomicPutIfAbsentFromNonOwner() throws Exception {
       String key = ""k1"", value = ""value"", value2 = ""v2"";
       for (Cache<Object, String> c : caches) assert c.isEmpty();",2012-08-31T21:22:26Z,3
"@@ -43,7 +43,7 @@
  *
  * @author Carsten Lohmann
  */
-@Test(testName = ""distribution.rehash.RehashAfterJoinWithPreloadTest"", groups = ""functional"")
+@Test(testName = ""distribution.rehash.RehashAfterJoinWithPreloadTest"", groups = ""functional"", enabled = false, description = ""Temporary disabled : https://issues.jboss.org/browse/ISPN-2249"")
 public class RehashAfterJoinWithPreloadTest extends MultipleCacheManagersTest {
 
    private static final Log log = LogFactory.getLog(RehashAfterJoinWithPreloadTest.class);",2012-08-31T21:22:26Z,4
"@@ -44,7 +44,7 @@
  * @author Mircea.Markus@jboss.com
  * @since 4.2
  */
-@Test(groups = ""functional"" , testName=""statetransfer.StateTransferLargeObjectTest"")
+@Test(groups = ""functional"" , testName=""statetransfer.StateTransferLargeObjectTest"", enabled = false, description = ""Temporary disabled : https://issues.jboss.org/browse/ISPN-2249"")
 public class StateTransferLargeObjectTest extends MultipleCacheManagersTest {
 
    private static final Log log = LogFactory.getLog(StateTransferLargeObjectTest.class);",2012-08-31T21:22:26Z,5
"@@ -43,7 +43,7 @@
 /**
  * @author Mircea Markus
  */
-@Test(groups = ""functional"", testName = ""tx.ParticipantFailsAfterPrepareTest"")
+@Test(groups = ""functional"", testName = ""tx.ParticipantFailsAfterPrepareTest"", enabled = false, description = ""Temporary disabled : https://issues.jboss.org/browse/ISPN-2249"")
 public class ParticipantFailsAfterPrepareTest extends MultipleCacheManagersTest {
 
    @Override",2012-08-31T21:22:26Z,6
"@@ -35,7 +35,8 @@
  * @author Galder Zamarreño
  * @since 5.2
  */
-@Test(groups = ""functional"", testName = ""query.cacheloaders.SharedCacheLoaderQueryIndexTest"")
+@Test(groups = ""functional"", testName = ""query.cacheloaders.SharedCacheLoaderQueryIndexTest"", enabled = false,
+      description = ""Temporary disabled: https://issues.jboss.org/browse/ISPN-2249"")
 public class SharedCacheLoaderQueryIndexTest extends BaseReIndexingTest {
 
    protected void configureCache(ConfigurationBuilder builder) {",2012-08-31T21:22:26Z,7
"@@ -48,7 +48,7 @@
  * 
  * @author Sanne Grinovero
  */
-@Test(groups = ""functional"", testName = ""query.distributed.MultiNodeDistributedTest"")
+@Test(groups = ""functional"", testName = ""query.distributed.MultiNodeDistributedTest"", enabled = false, description = ""Temporary disabled : https://issues.jboss.org/browse/ISPN-2249"")
 public class MultiNodeDistributedTest extends AbstractInfinispanTest {
 
    private List<EmbeddedCacheManager> cacheManagers = new ArrayList<EmbeddedCacheManager>(4);",2012-08-31T21:22:26Z,8
"@@ -35,7 +35,8 @@ import org.testng.annotations.Test
  * @author Galder Zamarreño
  * @since 5.1
  */
-@Test(groups = Array(""functional""), testName = ""server.hotrod.HotRod11DistributionTest"")
+@Test(groups = Array(""functional""), testName = ""server.hotrod.HotRod11DistributionTest"" enabled = false,
+      description = ""Temporary disabled : https://issues.jboss.org/browse/ISPN-2249"")
 class HotRod11DistributionTest extends HotRodMultiNodeTest {
 
    override protected def cacheName = ""distributedVersion11""",2012-08-31T21:22:26Z,9
"@@ -42,7 +42,8 @@ import scala.collection.JavaConversions._
  * @author Galder Zamarreño
  * @since 4.1
  */
-@Test(groups = Array(""functional""), testName = ""server.hotrod.HotRodDistributionTest"")
+@Test(groups = Array(""functional""), testName = ""server.hotrod.HotRodDistributionTest"", enabled = false,
+      description = ""Temporary disabled : https://issues.jboss.org/browse/ISPN-2249"")
 class HotRodDistributionTest extends HotRodMultiNodeTest {
 
    override protected def cacheName: String = ""hotRodDistSync""",2012-08-31T21:22:26Z,10
"@@ -32,6 +32,7 @@
 import org.infinispan.marshall.AdvancedExternalizer;
 import org.infinispan.marshall.Marshaller;
 import org.infinispan.remoting.transport.Transport;
+import org.jboss.marshalling.ClassResolver;
 
 import java.util.Properties;
 
@@ -108,6 +109,13 @@ public FluentGlobalConfiguration(GlobalConfiguration globalConfig) {
        * @param advancedExternalizers
        */
       <T> SerializationConfig addAdvancedExternalizer(AdvancedExternalizer<T>... advancedExternalizers);
+
+      /**
+       * Class resolver to use when unmarshallig objects.
+       *
+       * @param classResolver
+       */
+      SerializationConfig classResolver(ClassResolver classResolver);
    }
 
    /**",2012-03-19T13:24:00Z,11
"@@ -50,6 +50,7 @@
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
+import org.jboss.marshalling.ClassResolver;
 
 import javax.xml.bind.annotation.XmlAccessType;
 import javax.xml.bind.annotation.XmlAccessorType;
@@ -695,6 +696,10 @@ public List<AdvancedExternalizerConfig> getExternalizers() {
       return serialization.externalizerTypes.advancedExternalizers;
    }
 
+   public ClassResolver getClassResolver() {
+      return serialization.classResolver;
+   }
+
    public long getDistributedSyncTimeout() {
       return transport.distributedSyncTimeout;
    }
@@ -1361,6 +1366,9 @@ TransportType setGlobalConfiguration(GlobalConfiguration globalConfig) {
       @XmlElement(name = ""advancedExternalizers"")
       protected AdvancedExternalizersType externalizerTypes = new AdvancedExternalizersType();
 
+      @XmlTransient
+      private ClassResolver classResolver;
+
       public SerializationType() {
          super();
       }
@@ -1453,6 +1461,12 @@ public <T> SerializationConfig addAdvancedExternalizer(int id, AdvancedExternali
                new AdvancedExternalizerConfig().setId(id).setAdvancedExternalizer(advancedExternalizer));
          return this;
       }
+
+      @Override
+      public SerializationConfig classResolver(ClassResolver classResolver) {
+         this.classResolver = classResolver;
+         return this;
+      }
    }
 
    /**",2012-03-19T13:24:00Z,12
"@@ -73,6 +73,8 @@ public static org.infinispan.config.GlobalConfiguration adapt(GlobalConfiguratio
       for (Entry<Integer, AdvancedExternalizer<?>> entry : config.serialization().advancedExternalizers().entrySet()) {
          legacy.serialization().addAdvancedExternalizer(entry.getKey(), entry.getValue());
       }
+
+      legacy.serialization().classResolver(config.serialization().classResolver());
       
       legacy.asyncTransportExecutor()
          .factory(config.asyncTransportExecutor().factory().getClass())
@@ -134,6 +136,8 @@ public static org.infinispan.configuration.global.GlobalConfiguration adapt(org.
       for (AdvancedExternalizerConfig externalizerConfig : legacy.getExternalizers()) {
          builder.serialization().addAdvancedExternalizer(externalizerConfig.getId(), externalizerConfig.getAdvancedExternalizer());
       }
+
+      builder.serialization().classResolver(legacy.getClassResolver());
       
       builder.asyncTransportExecutor()
          .factory(Util.<ExecutorFactory>getInstance(legacy.getAsyncTransportExecutorFactoryClass(), legacy.getClassLoader()))",2012-03-19T13:24:00Z,13
"@@ -24,18 +24,22 @@
 
 import org.infinispan.marshall.AdvancedExternalizer;
 import org.infinispan.marshall.Marshaller;
+import org.jboss.marshalling.ClassResolver;
 
 public class SerializationConfiguration {
 
    private final Marshaller marshaller;
    private final short version;
    private final Map<Integer, AdvancedExternalizer<?>> advancedExternalizers;
+   private final ClassResolver classResolver;
    
    SerializationConfiguration(Marshaller marshaller, short version,
-         Map<Integer, AdvancedExternalizer<?>> advancedExternalizers) {
+         Map<Integer, AdvancedExternalizer<?>> advancedExternalizers,
+         ClassResolver classResolver) {
       this.marshaller = marshaller;
       this.version = version;
       this.advancedExternalizers = Collections.unmodifiableMap(new HashMap<Integer, AdvancedExternalizer<?>>(advancedExternalizers));
+      this.classResolver = classResolver;
    }
 
    public Marshaller marshaller() {
@@ -50,12 +54,17 @@ public Map<Integer, AdvancedExternalizer<?>> advancedExternalizers() {
       return advancedExternalizers;
    }
 
+   public ClassResolver classResolver() {
+      return classResolver;
+   }
+
    @Override
    public String toString() {
       return ""SerializationConfiguration{"" +
             ""advancedExternalizers="" + advancedExternalizers +
             "", marshaller="" + marshaller +
             "", version="" + version +
+            "", classResolver="" + classResolver +
             '}';
    }
 ",2012-03-19T13:24:00Z,14
"@@ -22,6 +22,8 @@
 import org.infinispan.marshall.AdvancedExternalizer;
 import org.infinispan.marshall.Marshaller;
 import org.infinispan.marshall.VersionAwareMarshaller;
+import org.jboss.marshalling.ClassResolver;
+
 import java.util.HashMap;
 import java.util.Map;
 
@@ -33,6 +35,7 @@ public class SerializationConfigurationBuilder extends AbstractGlobalConfigurati
    private Marshaller marshaller = new VersionAwareMarshaller();
    private short marshallVersion = Short.valueOf(Version.MAJOR_MINOR.replace(""."", """"));
    private Map<Integer, AdvancedExternalizer<?>> advancedExternalizers = new HashMap<Integer, AdvancedExternalizer<?>>();
+   private ClassResolver classResolver;
 
    SerializationConfigurationBuilder(GlobalConfigurationBuilder globalConfig) {
       super(globalConfig);
@@ -111,14 +114,25 @@ public <T> SerializationConfigurationBuilder addAdvancedExternalizer(AdvancedExt
       return this;
    }
 
+   /**
+    * Class resolver to use when unmarshallig objects.
+    *
+    * @param classResolver
+    */
+   public SerializationConfigurationBuilder classResolver(ClassResolver classResolver) {
+      this.classResolver = classResolver;
+      return this;
+   }
+
    @Override
    protected void validate() {
       // No-op, no validation required
    }
 
    @Override
    SerializationConfiguration create() {
-      return new SerializationConfiguration(marshaller, marshallVersion, advancedExternalizers);
+      return new SerializationConfiguration(
+            marshaller, marshallVersion, advancedExternalizers, classResolver);
    }
 
    @Override
@@ -136,6 +150,7 @@ public String toString() {
             ""advancedExternalizers="" + advancedExternalizers +
             "", marshaller="" + marshaller +
             "", marshallVersion="" + marshallVersion +
+            "", classResolver="" + classResolver +
             '}';
    }
 
@@ -151,6 +166,8 @@ public boolean equals(Object o) {
          return false;
       if (marshaller != null ? !marshaller.equals(that.marshaller) : that.marshaller != null)
          return false;
+      if (classResolver != null ? !classResolver.equals(that.classResolver) : that.classResolver != null)
+         return false;
 
       return true;
    }
@@ -160,6 +177,7 @@ public int hashCode() {
       int result = marshaller != null ? marshaller.hashCode() : 0;
       result = 31 * result + (int) marshallVersion;
       result = 31 * result + (advancedExternalizers != null ? advancedExternalizers.hashCode() : 0);
+      result = 31 * result + (classResolver != null ? classResolver.hashCode() : 0);
       return result;
    }
 ",2012-03-19T13:24:00Z,15
"@@ -1,6 +1,7 @@
 package org.infinispan.marshall;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Stop;
@@ -22,8 +23,10 @@ public CacheMarshaller(VersionAwareMarshaller marshaller) {
    }
 
    @Inject
-   public void inject(Configuration cfg, InvocationContextContainer icc, ExternalizerTable extTable) {
-      ((VersionAwareMarshaller) this.marshaller).inject(cfg, null, icc, extTable);
+   public void inject(Configuration cfg, InvocationContextContainer icc,
+            ExternalizerTable extTable, GlobalConfiguration globalCfg) {
+      ((VersionAwareMarshaller) this.marshaller).inject(
+            cfg, null, icc, extTable, globalCfg);
    }
 
    @Stop(priority = 11) // Stop after RPCManager to avoid send/receive and marshaller not being ready",2012-03-19T13:24:00Z,16
"@@ -1,5 +1,6 @@
 package org.infinispan.marshall;
 
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.factories.scopes.Scope;
@@ -22,8 +23,10 @@ public GlobalMarshaller(VersionAwareMarshaller marshaller) {
    }
 
    @Inject
-   public void inject(ClassLoader loader, ExternalizerTable extTable) {
-      ((VersionAwareMarshaller) this.marshaller).inject(null, loader, null, extTable);
+   public void inject(ClassLoader loader, ExternalizerTable extTable,
+            GlobalConfiguration globalCfg) {
+      ((VersionAwareMarshaller) this.marshaller).inject(
+            null, loader, null, extTable, globalCfg);
    }
 
    @Stop(priority = 11) // Stop after transport to avoid send/receive and marshaller not being ready",2012-03-19T13:24:00Z,17
"@@ -23,6 +23,7 @@
 package org.infinispan.marshall;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.io.ByteBuffer;
 import org.infinispan.io.ExposedByteArrayOutputStream;
@@ -61,7 +62,9 @@ public VersionAwareMarshaller() {
       defaultMarshaller = new JBossMarshaller();
    }
 
-   public void inject(Configuration cfg, ClassLoader loader, InvocationContextContainer icc, ExternalizerTable extTable) {
+   public void inject(Configuration cfg, ClassLoader loader,
+         InvocationContextContainer icc, ExternalizerTable extTable,
+         GlobalConfiguration globalCfg) {
       ClassLoader myClassLoader;
       if (cfg == null) {
          myClassLoader = loader;
@@ -71,7 +74,7 @@ public void inject(Configuration cfg, ClassLoader loader, InvocationContextConta
          this.cacheName = cfg.getName();
       }
 
-      this.defaultMarshaller.inject(extTable, myClassLoader, icc);
+      this.defaultMarshaller.inject(extTable, myClassLoader, icc, globalCfg);
    }
 
    public void stop() {",2012-03-19T13:24:00Z,18
"@@ -22,14 +22,11 @@
  */
 package org.infinispan.marshall.jboss;
 
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.marshall.StreamingMarshaller;
-import org.jboss.marshalling.Marshaller;
-import org.jboss.marshalling.MarshallingConfiguration;
-import org.jboss.marshalling.Unmarshaller;
-
-import java.io.IOException;
+import org.jboss.marshalling.ClassResolver;
 
 /**
  * A JBoss Marshalling based marshaller that is oriented at internal, embedded,
@@ -52,13 +49,20 @@ public final class JBossMarshaller extends AbstractJBossMarshaller implements St
 
    ExternalizerTable externalizerTable;
 
-   public void inject(ExternalizerTable externalizerTable, ClassLoader cl, InvocationContextContainer icc) {
+   public void inject(ExternalizerTable externalizerTable, ClassLoader cl,
+         InvocationContextContainer icc, GlobalConfiguration globalCfg) {
       log.debug(""Using JBoss Marshalling"");
       this.externalizerTable = externalizerTable;
       baseCfg.setObjectTable(externalizerTable);
-      // Override the class resolver with one that can detect injected
-      // classloaders via AdvancedCache.with(ClassLoader) calls.
-      baseCfg.setClassResolver(new EmbeddedContextClassResolver(cl, icc));
+
+      ClassResolver classResolver = globalCfg.getClassResolver();
+      if (classResolver == null) {
+         // Override the class resolver with one that can detect injected
+         // classloaders via AdvancedCache.with(ClassLoader) calls.
+         classResolver = new EmbeddedContextClassResolver(cl, icc);
+      }
+
+      baseCfg.setClassResolver(classResolver);
    }
 
    @Override",2012-03-19T13:24:00Z,19
"@@ -2,16 +2,16 @@
 
 import org.infinispan.Cache;
 import org.infinispan.CacheException;
-import org.infinispan.config.Configuration.CacheMode;
-import org.infinispan.config.GlobalConfiguration;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.test.CherryPickClassLoader;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
 import java.io.Serializable;
 
-import static org.infinispan.test.fwk.TestCacheManagerFactory.createCacheManager;
+import static org.infinispan.test.fwk.TestCacheManagerFactory.createClusteredCacheManager;
 import static org.testng.AssertJUnit.assertEquals;
 import static org.testng.AssertJUnit.fail;
 
@@ -30,22 +30,29 @@ public class WithClassLoaderTest extends MultipleCacheManagersTest {
 
    @Override
    protected void createCacheManagers() throws Throwable {
-      EmbeddedCacheManager cm0 = createCacheManager(GlobalConfiguration.getClusteredDefault());
-      cm0.getDefaultConfiguration().fluent()
-         .clustering().mode(CacheMode.REPL_SYNC)
-         .storeAsBinary().build();
+      ConfigurationBuilder builder = new ConfigurationBuilder();
+      builder.storeAsBinary().enable()
+            .clustering()
+            .cacheMode(org.infinispan.configuration.cache.CacheMode.REPL_SYNC);
+      EmbeddedCacheManager cm0 = createClusteredCacheManager(builder);
       cacheManagers.add(cm0);
 
       String[] notFound = new String[]{CAR};
       systemCl = Thread.currentThread().getContextClassLoader();
       CherryPickClassLoader cl = new CherryPickClassLoader(null, null, notFound, systemCl);
-      EmbeddedCacheManager cm1 = createCacheManager(GlobalConfiguration.getClusteredDefault(cl));
-      cm1.getDefaultConfiguration().fluent()
-         .clustering().mode(CacheMode.REPL_SYNC)
-         .storeAsBinary().build();
+
+      GlobalConfigurationBuilder gcBuilder = createSecondGlobalCfgBuilder(cl);
+      EmbeddedCacheManager cm1 = createClusteredCacheManager(gcBuilder, builder);
       cacheManagers.add(cm1);
    }
 
+   protected GlobalConfigurationBuilder createSecondGlobalCfgBuilder(ClassLoader cl) {
+      GlobalConfigurationBuilder gcBuilder =
+            GlobalConfigurationBuilder.defaultClusteredBuilder();
+      gcBuilder.classLoader(cl);
+      return gcBuilder;
+   }
+
    public void testReadingWithCorrectClassLoaderAfterReplication() {
       Cache<Integer, Car> cache0 = cache(0);
       Cache<Integer, Car> cache1 = cache(1);",2012-03-19T13:24:00Z,20
"@@ -0,0 +1,55 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.configuration;
+
+import org.infinispan.api.WithClassLoaderTest;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
+import org.infinispan.marshall.jboss.DefaultContextClassResolver;
+import org.testng.annotations.Test;
+
+/**
+ * A test that verifies that a class resolver can be configured successfully.
+ *
+ * @author Galder Zamarreño
+ * @since 5.1
+ */
+@Test(groups = ""functional"", testName = ""configuration.ClassResolverConfigTest"")
+public class ClassResolverConfigTest extends WithClassLoaderTest {
+
+   @Override
+   protected GlobalConfigurationBuilder createSecondGlobalCfgBuilder(ClassLoader cl) {
+      GlobalConfigurationBuilder gcBuilder = super.createSecondGlobalCfgBuilder(cl);
+      gcBuilder.serialization().classResolver(new DefaultContextClassResolver(cl));
+      return gcBuilder;
+   }
+
+   @Override
+   @Test(expectedExceptions = AssertionError.class,
+         expectedExceptionsMessageRegExp = ""Expected a ClassNotFoundException"")
+   public void testReadingWithCorrectClassLoaderAfterReplication() {
+      // With the default context class resolver, if configured correctly,
+      // the classloader that we set with the invocation context (i.e.
+      // coming from global configuration) is ignored (the super class test
+      // has one specific classloader that forces not finding a class), and
+      // so the class is found.
+      super.testReadingWithCorrectClassLoaderAfterReplication();
+   }
+
+}
\ No newline at end of file",2012-03-19T13:24:00Z,21
"@@ -29,6 +29,7 @@
 
 import org.infinispan.Version;
 
+import org.infinispan.factories.annotations.SurvivesRestarts;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
 
@@ -48,6 +49,7 @@
  *
  */
 @Scope(Scopes.GLOBAL)
+@SurvivesRestarts
 public class GlobalConfiguration {
 
    /**",2012-08-31T21:04:11Z,22
"@@ -495,9 +495,11 @@ private void populateLifeCycleMethods(Component c) {
     */
    public void resetVolatileComponents() {
       // destroy all components to clean up resources
+      getLog().tracef(""Resetting volatile components"");
       for (Component c : new HashSet<Component>(componentLookup.values())) {
          // the component is volatile!!
          if (!c.metadata.isSurvivesRestarts()) {
+            getLog().tracef(""Removing volatile component %s"", c.metadata.getName());
             componentLookup.remove(c.name);
          }
       }",2012-08-31T21:04:11Z,23
"@@ -106,8 +106,8 @@ public GlobalComponentRegistry(GlobalConfiguration configuration,
          globalConfiguration = configuration;
 
          registerComponent(this, GlobalComponentRegistry.class);
-         registerComponent(cacheManager, EmbeddedCacheManager.class);
          registerComponent(configuration, GlobalConfiguration.class);
+         registerComponent(cacheManager, EmbeddedCacheManager.class);
          registerComponent(new CacheManagerJmxRegistration(), CacheManagerJmxRegistration.class);
          registerComponent(new CacheManagerNotifierImpl(), CacheManagerNotifier.class);
 ",2012-08-31T21:04:11Z,24
"@@ -23,18 +23,13 @@
 package org.infinispan.container;
 
 import net.jcip.annotations.ThreadSafe;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalNullEntry;
 import org.infinispan.container.versioning.EntryVersion;
 import org.infinispan.eviction.EvictionManager;
 import org.infinispan.eviction.EvictionStrategy;
 import org.infinispan.eviction.EvictionThreadPolicy;
 import org.infinispan.eviction.PassivationManager;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
-import org.infinispan.loaders.CacheLoaderManager;
-import org.infinispan.loaders.decorators.AsyncStore;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.concurrent.BoundedConcurrentHashMap;
 import org.infinispan.util.concurrent.BoundedConcurrentHashMap.Eviction;
@@ -69,10 +64,6 @@ public class DefaultDataContainer implements DataContainer {
    final protected DefaultEvictionListener evictionListener;
    private EvictionManager evictionManager;
    private PassivationManager passivator;
-   private boolean isAsyncStore;
-   private CacheLoaderManager cacheLoaderManager;
-   private Configuration config;
-   private AsyncStore asyncStore;
 
    public DefaultDataContainer(int concurrencyLevel) {
       entries = ConcurrentMapFactory.makeConcurrentMap(128, concurrencyLevel);
@@ -108,19 +99,10 @@ protected DefaultDataContainer(int concurrencyLevel, int maxEntries, EvictionStr
 
    @Inject
    public void initialize(EvictionManager evictionManager, PassivationManager passivator,
-         InternalEntryFactory entryFactory, Configuration config, CacheLoaderManager cacheLoaderManager) {
+         InternalEntryFactory entryFactory) {
       this.evictionManager = evictionManager;
       this.passivator = passivator;
       this.entryFactory = entryFactory;
-      this.config = config;
-      this.cacheLoaderManager = cacheLoaderManager;
-   }
-
-   @Start(priority = 11) // Start after cache loader manager
-   public void start() {
-      this.isAsyncStore = config.loaders().usingAsyncStore();
-      if (isAsyncStore)
-         this.asyncStore = (AsyncStore) cacheLoaderManager.getCacheStore();
    }
 
    public static DataContainer boundedDataContainer(int concurrencyLevel, int maxEntries,
@@ -134,15 +116,7 @@ public static DataContainer unBoundedDataContainer(int concurrencyLevel) {
 
    @Override
    public InternalCacheEntry peek(Object key) {
-      InternalCacheEntry entry = entries.get(key);
-      // If the entry was passivated to an async store, it would have been
-      // marked as 'evicted', so check whether the key has been flushed to
-      // the cache store, and if it has, return null so that it can go through
-      // the activation process.
-      if (entry != null && entry.isEvicted() && isKeyFlushedToStore(key))
-         return null;
-
-      return entry;
+      return entries.get(key);
    }
 
    @Override
@@ -162,7 +136,7 @@ public InternalCacheEntry get(Object k) {
 
    @Override
    public void put(Object k, Object v, EntryVersion version, long lifespan, long maxIdle) {
-      InternalCacheEntry e = peek(k);
+      InternalCacheEntry e = entries.get(k);
       if (e != null) {
          e.setValue(v);
          InternalCacheEntry original = e;
@@ -191,12 +165,7 @@ public boolean containsKey(Object k) {
 
    @Override
    public InternalCacheEntry remove(Object k) {
-      InternalCacheEntry e;
-      if (isAsyncStore) {
-         e = entries.replace(k, new InternalNullEntry(asyncStore));
-      } else {
-         e = entries.remove(k);
-      }
+      InternalCacheEntry e = entries.remove(k);
       return e == null || (e.canExpire() && e.isExpired(System.currentTimeMillis())) ? null : e;
    }
 
@@ -230,24 +199,12 @@ public void purgeExpired() {
       long currentTimeMillis = System.currentTimeMillis();
       for (Iterator<InternalCacheEntry> purgeCandidates = entries.values().iterator(); purgeCandidates.hasNext();) {
          InternalCacheEntry e = purgeCandidates.next();
-         if (isAsyncStore && e instanceof InternalNullEntry) {
-            InternalNullEntry nullEntry = (InternalNullEntry) e;
-            if (nullEntry.isExpired(asyncStore.getAsyncProcessorId())) {
-               purgeCandidates.remove();
-               continue;
-            }
-         }
-
          if (e.isExpired(currentTimeMillis)) {
             purgeCandidates.remove();
          }
       }
    }
 
-   private boolean isKeyFlushedToStore(Object key) {
-      return !isAsyncStore || (isAsyncStore && !asyncStore.isLocked(key));
-   }
-
    @Override
    public Iterator<InternalCacheEntry> iterator() {
       return new EntryIterator(entries.values().iterator());
@@ -261,24 +218,10 @@ public void onEntryEviction(Map<Object, InternalCacheEntry> evicted) {
       }
 
       @Override
-      public boolean onEntryChosenForEviction(InternalCacheEntry entry) {
-         boolean allowEviction = isKeyFlushedToStore(entry.getKey());
-
-         if (allowEviction) {
-            passivator.passivate(entry);
-            if (isAsyncStore) {
-               // Storing in cache store is still in flight, so don't remove
-               // the entry from memory yet. Instead, mark the entry as 'evicted'
-               // and if someone requests it, check whether it's locked on the
-               // cache store. If it's not, assume that the entry was stored
-               // in the async store and the container can return null.
-               entry.setEvicted(true);
-               return false;
-            }
-         }
-
-         return allowEviction;
+      public void onEntryChosenForEviction(InternalCacheEntry entry) {
+         passivator.passivate(entry);
       }
+
    }
 
    private static class ImmutableEntryIterator extends EntryIterator {",2012-10-03T12:24:38Z,25
"@@ -34,7 +34,6 @@
 public abstract class AbstractInternalCacheEntry implements InternalCacheEntry {
 
    protected Object key;
-   private boolean evicted;
 
    protected AbstractInternalCacheEntry() {
    }
@@ -65,7 +64,7 @@ public final void setRemoved(boolean removed) {
 
    @Override
    public final void setEvicted(boolean evicted) {
-      this.evicted = evicted;
+      // no-op
    }
 
    @Override
@@ -95,7 +94,7 @@ public final boolean isRemoved() {
 
    @Override
    public final boolean isEvicted() {
-      return evicted;
+      return true;
    }
 
    @Override",2012-10-03T12:24:38Z,26
"@@ -1,229 +0,0 @@
-/*
- * Copyright 2012 Red Hat, Inc. and/or its affiliates.
- *
- * This is free software; you can redistribute it and/or modify it
- * under the terms of the GNU Lesser General Public License as
- * published by the Free Software Foundation; either version 2.1 of
- * the License, or (at your option) any later version.
- *
- * This software is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this library; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
- * 02110-1301 USA
- */
-
-package org.infinispan.container.entries;
-
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.versioning.EntryVersion;
-import org.infinispan.loaders.decorators.AsyncStore;
-
-/**
- * Internal null cache entry used to signal that an entry has been removed
- * but it's in the process of being removed from another component,
- * i.e. an async cache store.
- *
- * This entry helps deal with situations where an eventual removal
- * is under way.
- *
- * @author Galder Zamarreño
- * @since 5.2
- */
-public class InternalNullEntry implements InternalCacheEntry {
-
-   private final long asyncProcessorId;
-   private final AsyncStore asyncStore;
-
-   public InternalNullEntry(AsyncStore asyncStore) {
-      this.asyncStore = asyncStore;
-      this.asyncProcessorId = this.asyncStore.getAsyncProcessorId();
-   }
-
-   @Override
-   public boolean isNull() {
-      return false; // not null to avoid cache loader interceptor loading from store
-   }
-
-   @Override
-   public Object getValue() {
-      return this; // set this value to avoid cache loader interceptor
-   }
-
-   @Override
-   public boolean canExpire() {
-      return true;
-   }
-
-   @Override
-   public boolean isExpired(long now) {
-      return asyncStore.getAsyncProcessorId() > asyncProcessorId;
-   }
-
-   @Override
-   public boolean isExpired() {
-      return asyncStore.getAsyncProcessorId() > asyncProcessorId;
-   }
-
-   // Below are non-relevant method implementations
-
-   @Override
-   public boolean isChanged() {
-      return false;
-   }
-
-   @Override
-   public boolean isCreated() {
-      return false;
-   }
-
-   @Override
-   public boolean isRemoved() {
-      return false;
-   }
-
-   @Override
-   public boolean isEvicted() {
-      return false;
-   }
-
-   @Override
-   public boolean isValid() {
-      return false;
-   }
-
-   @Override
-   public Object getKey() {
-      return null;
-   }
-
-   @Override
-   public long getLifespan() {
-      return 0;
-   }
-
-   @Override
-   public long getMaxIdle() {
-      return 0;
-   }
-
-   @Override
-   public void setMaxIdle(long maxIdle) {
-      // Empty
-   }
-
-   @Override
-   public void setLifespan(long lifespan) {
-      // Empty
-   }
-
-   @Override
-   public Object setValue(Object value) {
-      return null;
-   }
-
-   @Override
-   public boolean equals(Object o) {
-      return false;
-   }
-
-   @Override
-   public int hashCode() {
-      return 0;
-   }
-
-   @Override
-   public void commit(DataContainer container, EntryVersion newVersion) {
-      // Empty
-   }
-
-   @Override
-   public void rollback() {
-      // Empty
-   }
-
-   @Override
-   public void setCreated(boolean created) {
-      // Empty
-   }
-
-   @Override
-   public void setRemoved(boolean removed) {
-      // Empty
-   }
-
-   @Override
-   public void setEvicted(boolean evicted) {
-      // Empty
-   }
-
-   @Override
-   public void setValid(boolean valid) {
-      // Empty
-   }
-
-   @Override
-   public boolean isLockPlaceholder() {
-      return false;
-   }
-
-   @Override
-   public boolean undelete(boolean doUndelete) {
-      return false;
-   }
-
-   @Override
-   public long getCreated() {
-      return 0;
-   }
-
-   @Override
-   public long getLastUsed() {
-      return 0;
-   }
-
-   @Override
-   public long getExpiryTime() {
-      return 0;
-   }
-
-   @Override
-   public void touch() {
-      // Empty
-   }
-
-   @Override
-   public void touch(long currentTimeMillis) {
-      // Empty
-   }
-
-   @Override
-   public void reincarnate() {
-      // Empty
-   }
-
-   @Override
-   public InternalCacheValue toInternalCacheValue() {
-      return null;
-   }
-
-   @Override
-   public InternalCacheEntry clone() {
-      return null;
-   }
-
-   @Override
-   public EntryVersion getVersion() {
-      return null;
-   }
-
-   @Override
-   public void setVersion(EntryVersion version) {
-      // Empty
-   }
-
-}",2012-10-03T12:24:38Z,27
"@@ -32,7 +32,6 @@
 import org.infinispan.container.EntryFactory;
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalNullEntry;
 import org.infinispan.container.entries.MVCCEntry;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
@@ -174,9 +173,6 @@ private boolean loadIfNeeded(InvocationContext ctx, Object key, boolean isRetrie
          } else {
             return false;
          }
-      } else if (e instanceof InternalNullEntry) {
-         ctx.putLookedUpEntry(key, null);
-         return false;
       } else {
          return true;
       }",2012-10-03T12:24:38Z,28
"@@ -50,7 +50,6 @@
 import org.infinispan.configuration.cache.StoreConfiguration;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.context.Flag;
-import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.ComponentRegistry;
 import org.infinispan.factories.annotations.ComponentName;
@@ -66,7 +65,6 @@
 import org.infinispan.loaders.decorators.SingletonStoreConfig;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.statetransfer.StateTransferManager;
-import org.infinispan.topology.CacheTopology;
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;",2012-10-03T12:24:38Z,29
"@@ -25,7 +25,7 @@
 import net.jcip.annotations.GuardedBy;
 import org.infinispan.Cache;
 import org.infinispan.CacheException;
-import org.infinispan.config.Configuration;
+import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.loaders.CacheLoaderConfig;
 import org.infinispan.loaders.CacheLoaderException;
@@ -37,43 +37,40 @@
 import org.infinispan.loaders.modifications.Store;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.transaction.xa.TransactionFactory;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.locks.containers.ReentrantPerEntryLockContainer;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
 import java.util.concurrent.LinkedBlockingQueue;
 import java.util.concurrent.ThreadFactory;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.atomic.AtomicLong;
-import java.util.concurrent.locks.Lock;
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
+import java.util.concurrent.locks.AbstractQueuedSynchronizer;
 
 /**
- * The AsyncStore is a delegating CacheStore that extends AbstractDelegatingStore, overriding methods to that should not
- * just delegate the operation to the underlying store.
+ * The AsyncStore is a delegating CacheStore that buffers changes and writes them asynchronously to
+ * the underlying CacheStore.
  * <p/>
- * Read operations are done synchronously, while write operations are done asynchronously.  There is no provision for
- * exception handling for problems encountered with the underlying store during a write operation, and the exception is
- * just logged.
+ * Read operations are done synchronously, taking into account the current state of buffered changes.
+ * <p/>
+ * There is no provision for exception handling for problems encountered with the underlying store
+ * during a write operation, and the exception is just logged.
  * <p/>
  * When configuring the loader, use the following element:
  * <p/>
  * <code> &lt;async enabled=""true"" /&gt; </code>
  * <p/>
- * to define whether cache loader operations are to be asynchronous.  If not specified, a cache loader operation is
+ * to define whether cache loader operations are to be asynchronous. If not specified, a cache loader operation is
  * assumed synchronous and this decorator is not applied.
  * <p/>
  * Write operations affecting same key are now coalesced so that only the final state is actually stored.
@@ -82,62 +79,43 @@
  * @author Manik Surtani
  * @author Galder Zamarreño
  * @author Sanne Grinovero
+ * @author Karsten Blees
  * @since 4.0
  */
 public class AsyncStore extends AbstractDelegatingStore {
    private static final Log log = LogFactory.getLog(AsyncStore.class);
    private static final boolean trace = log.isTraceEnabled();
    private static final AtomicInteger threadId = new AtomicInteger(0);
-   private final AtomicBoolean stopped = new AtomicBoolean(true);
-   
+
    private final AsyncStoreConfig asyncStoreConfig;
+   private final TransactionFactory txFactory;
    private Map<GlobalTransaction, List<? extends Modification>> transactions;
-   
-   /**
-    * This is used as marker to shutdown the AsyncStoreCoordinator
-    */
-   private static final Modification QUIT_SIGNAL = new Clear();
-   
-   /**
-    * clear() is performed in sync by the one thread of storeCoordinator, while blocking all
-    * other threads interacting with the decorated store.
-    */
-   private final ReadWriteLock clearAllLock = new ReentrantReadWriteLock();
-   private final Lock clearAllReadLock = clearAllLock.readLock();
-   private final Lock clearAllWriteLock = clearAllLock.writeLock();
-   private final Lock stateMapLock = new ReentrantLock();
-   
-   ExecutorService executor;
+
+   private ExecutorService executor;
+   private Thread coordinator;
    private int concurrencyLevel;
-   @GuardedBy(""stateMapLock"")
-   protected ConcurrentMap<Object, Modification> state;
-   private ReleaseAllLockContainer lockContainer;
-   private LinkedBlockingQueue<Modification> changesDeque;
-   public volatile boolean lastAsyncProcessorShutsDownExecutor = false;
    private long shutdownTimeout;
    private String cacheName;
 
-   /**
-    * Identifies each of the asynchronous processor runs. This incrementing
-    * counter can be used to decide whether a phantom null entry in the cache
-    * can be expired or not.
-    */
-   private final AtomicLong asyncProcessorId = new AtomicLong();
+   private BufferLock stateLock;
+   @GuardedBy(""stateLock"")
+   private volatile State state;
 
    public AsyncStore(CacheStore delegate, AsyncStoreConfig asyncStoreConfig) {
       super(delegate);
       this.asyncStoreConfig = asyncStoreConfig;
+      txFactory = new TransactionFactory();
+      txFactory.init(false, false, false, false);
    }
 
    @Override
    public void init(CacheLoaderConfig config, Cache<?, ?> cache, StreamingMarshaller m) throws CacheLoaderException {
       super.init(config, cache, m);
-      changesDeque = new LinkedBlockingQueue<Modification>(asyncStoreConfig.getModificationQueueSize());
-      Configuration cacheCfg = cache != null ? cache.getConfiguration() : null;
-      concurrencyLevel = cacheCfg != null ? cacheCfg.getConcurrencyLevel() : 16;
-      int cacheStopTimeout = cacheCfg != null ? cacheCfg.getCacheStopTimeout() : 30000;
+      Configuration cacheCfg = cache != null ? cache.getCacheConfiguration() : null;
+      concurrencyLevel = cacheCfg != null ? cacheCfg.locking().concurrencyLevel() : 16;
+      long cacheStopTimeout = cacheCfg != null ? cacheCfg.transaction().cacheStopTimeout() : 30000;
       Long configuredAsyncStopTimeout = asyncStoreConfig.getShutdownTimeout();
-      cacheName = cacheCfg != null ? cacheCfg.getName() : null;
+      cacheName = cache != null ? cache.getName() : null;
 
       // Async store shutdown timeout cannot be bigger than
       // the overall cache stop timeout, so limit it accordingly.
@@ -148,308 +126,476 @@ public void init(CacheLoaderConfig config, Cache<?, ?> cache, StreamingMarshalle
          shutdownTimeout = configuredAsyncStopTimeout;
       }
 
-      lockContainer = new ReleaseAllLockContainer(concurrencyLevel);
       transactions = ConcurrentMapFactory.makeConcurrentMap(64, concurrencyLevel);
    }
 
+   private State newState(boolean clear, State next) {
+      ConcurrentMap<Object, Modification> map = ConcurrentMapFactory.makeConcurrentMap(64, concurrencyLevel);
+      return new State(clear, map, next);
+   }
+
+   private void put(Modification mod, int count) {
+      stateLock.writeLock(count);
+      try {
+         state.put(mod);
+      } finally {
+         stateLock.writeUnlock();
+      }
+   }
+
+   @Override
+   public InternalCacheEntry load(Object key) throws CacheLoaderException {
+      Modification mod = state.get(key);
+      if (mod != null) {
+         switch (mod.getType()) {
+            case REMOVE:
+            case CLEAR:
+               return null;
+            case STORE:
+               InternalCacheEntry ice = ((Store) mod).getStoredEntry();
+               if (ice.isExpired())
+                  return null;
+               return ice;
+         }
+      }
+
+      return super.load(key);
+   }
+
+   @Override
+   public boolean containsKey(Object key) throws CacheLoaderException {
+      Modification mod = state.get(key);
+      if (mod != null)
+         return mod.getType() == Modification.Type.STORE;
+
+      return super.containsKey(key);
+   }
+
+   private void loadKeys(State s, Set<Object> exclude, Set<Object> result) throws CacheLoaderException {
+      // if not cleared, get keys from next State or the back-end store
+      if (!s.clear) {
+         State next = s.next;
+         if (next != null)
+            loadKeys(next, exclude, result);
+         else
+            result.addAll(super.loadAllKeys(exclude));
+      }
+
+      // merge keys of the current State
+      for (Modification mod : s.modifications.values()) {
+         switch (mod.getType()) {
+            case STORE:
+               Object key = ((Store) mod).getStoredEntry().getKey();
+               if (exclude == null || !exclude.contains(key))
+                  result.add(key);
+               break;
+            case REMOVE:
+               result.remove(((Remove) mod).getKey());
+               break;
+         }
+      }
+   }
+
+   @Override
+   public Set<Object> loadAllKeys(Set<Object> keysToExclude) throws CacheLoaderException {
+      Set<Object> result = new HashSet<Object>();
+      loadKeys(state, keysToExclude, result);
+      return result;
+   }
+
+   @Override
+   public Set<InternalCacheEntry> loadAll() throws CacheLoaderException {
+      return load(Integer.MAX_VALUE);
+   }
+
    @Override
-   public void store(InternalCacheEntry ed) {
-      enqueue(new Store(ed));
+   public Set<InternalCacheEntry> load(int numEntries) throws CacheLoaderException {
+      Set<InternalCacheEntry> result = new HashSet<InternalCacheEntry>();
+      for (Object key : loadAllKeys(null)) {
+         InternalCacheEntry entry = load(key);
+         if (entry != null) {
+            result.add(entry);
+            if (result.size() == numEntries)
+               return result;
+         }
+      }
+      return result;
+   }
+
+   @Override
+   public void store(InternalCacheEntry entry) {
+      put(new Store(entry), 1);
+   }
+
+   @Override
+   public void clear() {
+      stateLock.writeLock(1);
+      try {
+         state = newState(true, state.next);
+      } finally {
+         stateLock.reset(1);
+         stateLock.writeUnlock();
+      }
    }
 
    @Override
    public boolean remove(Object key) {
-      enqueue(new Remove(key));
+      put(new Remove(key), 1);
       return true;
    }
 
    @Override
-   public void clear() {
-      Clear clear = new Clear();
-      checkNotStopped(); //check we can change the changesDeque
-      changesDeque.clear();
-      enqueue(clear);
+   public void removeAll(Set<Object> keys) throws CacheLoaderException {
+      if (keys != null && !keys.isEmpty()) {
+         List<Modification> mods = new ArrayList<Modification>(keys.size());
+         for (Object key : keys)
+            mods.add(new Remove(key));
+         put(new ModificationsList(mods), mods.size());
+      }
    }
 
    @Override
-   public void prepare(List<? extends Modification> mods, GlobalTransaction tx, boolean isOnePhase) throws CacheLoaderException {
+   public void prepare(List<? extends Modification> mods, GlobalTransaction tx, boolean isOnePhase)
+         throws CacheLoaderException {
       if (isOnePhase) {
          enqueueModificationsList(mods);
       } else {
          transactions.put(tx, mods);
       }
    }
-   
+
    @Override
    public void rollback(GlobalTransaction tx) {
       transactions.remove(tx);
    }
 
    @Override
    public void commit(GlobalTransaction tx) throws CacheLoaderException {
-      List<? extends Modification> list = transactions.remove(tx);
-      enqueueModificationsList(list);
+      enqueueModificationsList(transactions.remove(tx));
    }
-   
-   protected void enqueueModificationsList(List<? extends Modification> mods) {
-      if (mods != null && !mods.isEmpty()) {
-         enqueue(new ModificationsList(mods));
+
+   private void enqueueModificationsList(List<? extends Modification> mods) {
+      // scan backwards to find the last CLEAR (anything before that can be discarded)
+      int i = mods.size() - 1;
+      for (; i >= 0; i--)
+         if (mods.get(i).getType() == Modification.Type.CLEAR)
+            break;
+      // treat CLEAR specially
+      if (i >= 0) {
+         clear();
+         mods = mods.subList(i + 1, mods.size());
       }
+      // put the rest
+      if (!mods.isEmpty())
+         put(new ModificationsList(mods), mods.size());
    }
 
    @Override
    public void start() throws CacheLoaderException {
-      state = newStateMap();
       log.debugf(""Async cache loader starting %s"", this);
-      stopped.set(false);
-      lastAsyncProcessorShutsDownExecutor = false;
+      state = newState(false, null);
+      stateLock = new BufferLock(asyncStoreConfig.getModificationQueueSize());
+
       super.start();
-      int poolSize = asyncStoreConfig.getThreadPoolSize();
-      executor = new ThreadPoolExecutor(poolSize, poolSize, 0L, TimeUnit.MILLISECONDS,
-               // note the use of poolSize+1 as maximum workingQueue together with DiscardPolicy:
-               // this way when a new AsyncProcessor is started unnecessarily we discard it
-               // before it takes locks to perform no work
-               // this way we save memory from the executor queue, CPU, and also avoid
-               // any possible RejectedExecutionException.
-               new LinkedBlockingQueue<Runnable>(poolSize + 1),
-               new ThreadFactory() {
-                  @Override
-                  public Thread newThread(Runnable r) {
-                     Thread t = new Thread(r, ""CoalescedAsyncStore-"" + threadId.getAndIncrement());
-                     t.setDaemon(true);
-                     return t;
-                  }
-               },
-               new ThreadPoolExecutor.DiscardPolicy()
-         );
-      startStoreCoordinator();
-   }
 
-   private void startStoreCoordinator() {
-      ExecutorService storeCoordinator = Executors.newFixedThreadPool(1);
-      storeCoordinator.execute( new AsyncStoreCoordinator() );
-      storeCoordinator.shutdown();
+      int poolSize = asyncStoreConfig.getThreadPoolSize();
+      executor = new ThreadPoolExecutor(0, poolSize, 120L, TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),
+            new ThreadFactory() {
+               @Override
+               public Thread newThread(Runnable r) {
+                  Thread t = new Thread(r, ""AsyncStoreProcessor-"" + cacheName + ""-"" + threadId.getAndIncrement());
+                  t.setDaemon(true);
+                  return t;
+               }
+            });
+      coordinator = new Thread(new AsyncStoreCoordinator(), ""AsyncStoreCoordinator-"" + cacheName);
+      coordinator.setDaemon(true);
+      coordinator.start();
    }
 
    @Override
    public void stop() throws CacheLoaderException {
-      stopped.set(true);
+      stateLock.writeLock(1);
+      state.stopped = true;
+      stateLock.writeUnlock();
       try {
-         changesDeque.put(QUIT_SIGNAL);
-         boolean finished = executor.awaitTermination(shutdownTimeout, TimeUnit.MILLISECONDS);
-         if (!finished) log.error(""Async store executor did not stop properly"");
+         coordinator.join(shutdownTimeout);
+         if (coordinator.isAlive())
+            log.error(""Async store executor did not stop properly"");
       } catch (InterruptedException e) {
          log.interruptedWaitingAsyncStorePush(e);
          Thread.currentThread().interrupt();
       }
       super.stop();
    }
 
-   public boolean isLocked(Object key) {
-      boolean locked = lockContainer.isLocked(key);
-      if (log.isTraceEnabled()) log.tracef(""Key %s is locked? %b"", key, locked);
-      return locked;
+   protected void applyModificationsSync(List<Modification> mods) throws CacheLoaderException {
+      getDelegate().prepare(mods, txFactory.newGlobalTransaction(null, false), true);
    }
 
-   public long getAsyncProcessorId() {
-      return asyncProcessorId.get();
-   }
+   private static class State {
+      private static final Clear CLEAR = new Clear();
+
+      /**
+       * True if the state has been cleared before making modifications.
+       */
+      private final boolean clear;
+
+      /**
+       * Modifications to apply to the back-end CacheStore.
+       */
+      private final ConcurrentMap<Object, Modification> modifications;
+
+      /**
+       * Next state in the chain, initialized in constructor, may be set to <code>null</code>
+       * asynchronously at any time.
+       */
+      private volatile State next;
+
+      /**
+       * True if the CacheStore has been stopped (i.e. this is the last state to process).
+       */
+      private volatile boolean stopped = false;
+
+      /**
+       * Number of worker threads that currently work with this instance.
+       */
+      private CountDownLatch workerThreads;
+
+      private State(boolean clear, ConcurrentMap<Object, Modification> modMap, State next) {
+         this.clear = clear;
+         this.modifications = modMap;
+         this.next = next;
+         if (next != null)
+            stopped = next.stopped;
+      }
 
-   protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
-      Set<Map.Entry<Object, Modification>> entries = mods.entrySet();
-      for (Map.Entry<Object, Modification> entry : entries) {
-         Modification mod = entry.getValue();
+      /**
+       * Gets the Modification for the specified key from this State object or chained (
+       * <code>next</code>) State objects.
+       *
+       * @param key
+       *           the key to look up
+       * @return the Modification for the specified key, or <code>CLEAR</code> if the state was
+       *         cleared, or <code>null</code> if the key is not in the state map
+       */
+      Modification get(Object key) {
+         for (State state = this; state != null; state = state.next) {
+            Modification mod = state.modifications.get(key);
+            if (mod != null)
+               return mod;
+            else if (state.clear)
+               return CLEAR;
+         }
+         return null;
+      }
+
+      /**
+       * Adds the Modification(s) to the state map.
+       *
+       * @param mod
+       *           the Modification to add, supports modification types STORE, REMOVE and LIST
+       */
+      void put(Modification mod) {
+         if (stopped)
+            throw new CacheException(""AsyncStore stopped; no longer accepting more entries."");
          switch (mod.getType()) {
             case STORE:
-               super.store(((Store) mod).getStoredEntry());
+               modifications.put(((Store) mod).getStoredEntry().getKey(), mod);
                break;
             case REMOVE:
-               super.remove(entry.getKey());
+               modifications.put(((Remove) mod).getKey(), mod);
+               break;
+            case LIST:
+               for (Modification m : ((ModificationsList) mod).getList())
+                  put(m);
                break;
             default:
-               throw new IllegalArgumentException(""Unexpected modification type "" + mod.getType());
+               throw new IllegalArgumentException(""Unknown modification type "" + mod.getType());
          }
       }
    }
-   
-   protected boolean applyClear() {
-      try {
-         super.clear();
-         return true;
-      } catch (CacheLoaderException e) {
-         log.errorClearinAsyncStore(e);
-         return false;
-      }
-   }
-   
-   protected void delegatePurgeExpired() {
-      try {
-         super.purgeExpired();
-      } catch (CacheLoaderException e) {
-         log.errorPurgingAsyncStore(e);
-      }
-   }
 
-   private void enqueue(Modification mod) {
-      try {
-         checkNotStopped();
-         if (trace) log.tracef(""Enqueuing modification %s"", mod);
-         changesDeque.put(mod);
-      } catch (Exception e) {
-         throw new CacheException(""Unable to enqueue asynchronous task"", e);
-      }
-   }
+   /**
+    * A custom reader-writer-lock combined with a bounded buffer size counter.
+    * <p/>
+    * Supports multiple concurrent writers and a single exclusive reader. This ensures that no more
+    * data is being written to the current state when the AsyncStoreCoordinator thread hands the
+    * data off to the back-end store.
+    * <p/>
+    * Additionally, {@link #writeLock(int)} blocks if the buffer is full, and {@link #readLock()}
+    * blocks if no data is available.
+    * <p/>
+    * This lock implementation is <em>not</em> reentrant!
+    */
+   private static class BufferLock {
+      /**
+       * AQS state is the number of 'items' in the buffer. AcquireShared blocks if the buffer is
+       * full (>= size).
+       */
+      private static class Counter extends AbstractQueuedSynchronizer {
+         private static final long serialVersionUID = 1688655561670368887L;
+         private final int size;
+
+         Counter(int size) {
+            this.size = size;
+         }
 
-   private void checkNotStopped() {
-      if (stopped.get()) {
-         throw new CacheException(""AsyncStore stopped; no longer accepting more entries."");
-      }
-   }
+         int add(int count) {
+            for (;;) {
+               int state = getState();
+               if (compareAndSetState(state, state + count))
+                  return state + count;
+            }
+         }
 
-   private void acquireLock(Lock lock) {
-      try {
-         if (!lock.tryLock(asyncStoreConfig.getFlushLockTimeout(), TimeUnit.MILLISECONDS))
-            throw new CacheException(""Unable to acquire lock on update map"");
-      } catch (InterruptedException ie) {
-         // restore interrupted status
-         Thread.currentThread().interrupt();
+         protected int tryAcquireShared(int count) {
+            for (;;) {
+               int state = getState();
+               if (state >= size)
+                  return -1;
+               if (compareAndSetState(state, state + count))
+                  return state + count >= size ? 0 : 1;
+            }
+         }
+
+         protected boolean tryReleaseShared(int state) {
+            setState(state);
+            return state < size;
+         }
       }
-   }
 
-   private ConcurrentMap<Object, Modification> newStateMap() {
-      return ConcurrentMapFactory.makeConcurrentMap(64, concurrencyLevel);
-   }
+      /**
+       * AQS state is 0 if no data is available, 1 otherwise. AcquireShared blocks if no data is
+       * available.
+       */
+      private static class Available extends AbstractQueuedSynchronizer {
+         private static final long serialVersionUID = 6464514100313353749L;
 
-   private void ensureMoreWorkIsHandled() {
-      executor.execute(new AsyncProcessor());
-   }
+         protected int tryAcquireShared(int unused) {
+            return getState() > 0 ? 1 : -1;
+         }
 
-   /**
-    * Processes modifications taking the latest updates from a state map.
-    */
-   class AsyncProcessor implements Runnable {
-      private final Set<Object> lockedKeys = new HashSet<Object>();
-      boolean runAgainAfterWaiting = false;
+         protected boolean tryReleaseShared(int state) {
+            setState(state > 0 ? 1 : 0);
+            return state > 0;
+         }
+      }
 
-      @Override
-      public void run() {
-         LogFactory.pushNDC(cacheName, trace);
-         try {
-            clearAllReadLock.lock();
-            try {
-               innerRun();
-            } catch (Throwable t) {
-               runAgainAfterWaiting = false;
-               log.unexpectedErrorInAsyncProcessor(t);
-            } finally {
-               clearAllReadLock.unlock();
+      /**
+       * Minimal non-reentrant read-write-lock. AQS state is number of concurrent shared locks, or 0
+       * if unlocked, or -1 if locked exclusively.
+       */
+      private static class Sync extends AbstractQueuedSynchronizer {
+         private static final long serialVersionUID = 2983687000985096017L;
+
+         protected boolean tryAcquire(int unused) {
+            if (!compareAndSetState(0, -1))
+               return false;
+            setExclusiveOwnerThread(Thread.currentThread());
+            return true;
+         }
+
+         protected boolean tryRelease(int unused) {
+            setExclusiveOwnerThread(null);
+            setState(0);
+            return true;
+         }
+
+         protected int tryAcquireShared(int unused) {
+            for (;;) {
+               int state = getState();
+               if (state < 0)
+                  return -1;
+               if (compareAndSetState(state, state + 1))
+                  return 1;
             }
-            if (runAgainAfterWaiting) {
-               try {
-                  Thread.sleep(10);
-               } catch (InterruptedException e) {
-                  // just speedup ignoring more sleep but still make sure to store all data
-               }
-               ensureMoreWorkIsHandled();
+         }
+
+         protected boolean tryReleaseShared(int unused) {
+            for (;;) {
+               int state = getState();
+               if (compareAndSetState(state, state - 1))
+                  return true;
             }
-         } finally {
-            LogFactory.popNDC(trace);
          }
       }
-      
-      private void innerRun() {
-         final ConcurrentMap<Object, Modification> swap;
-         if (trace) log.trace(""Checking for modifications"");
-         try {
-            acquireLock(stateMapLock);
-            try {
-               swap = state;
-               state = newStateMap();
-
-               // This needs to be done within the stateMapLock section, because if a key is in use,
-               // we need to put it back in the state
-               // map for later processing and we don't wanna do it in such way that we override a
-               // newer value that might
-               // have been taken already for processing by another instance of this same code.
-               // AsyncStoreCoordinator doesn't need to acquired the same lock as values put by it
-               // will never be overwritten (putIfAbsent below)
-               for (Object key : swap.keySet()) {
-                  if (trace) log.tracef(""Going to process mod key: %s"", key);
-                  boolean acquired;
-                  try {
-                     acquired = lockContainer.acquireLock(null, key, 0, TimeUnit.NANOSECONDS) != null;
-                  } catch (InterruptedException e) {
-                     log.interruptedAcquiringLock(0, e);
-                     Thread.currentThread().interrupt();
-                     return;
-                  }
-                  if (trace)
-                     log.tracef(""Lock for key %s was acquired=%s"", key, acquired);
-                  if (!acquired) {
-                     Modification prev = swap.remove(key);
-                     Modification didPut = state.putIfAbsent(key, prev); // don't overwrite more recently put work
-                     if (didPut == null) {
-                        // otherwise a new job is being spawned by the arbiter, so no need to create
-                        // a new worker
-                        runAgainAfterWaiting = true;
-                     }
-                  } else {
-                     lockedKeys.add(key);
-                  }
-               }
-            } finally {
-               stateMapLock.unlock();
-            }
 
-            if (swap.isEmpty()) {
-               if (lastAsyncProcessorShutsDownExecutor && !runAgainAfterWaiting) {
-                  executor.shutdown();
-               }
-            } else {
-               if (trace)
-                  log.tracef(""Apply %s modifications"", swap.size());
-               int maxRetries = 3;
-               int attemptNumber = 0;
-               boolean successful;
-               do {
-                  if (attemptNumber > 0 && log.isDebugEnabled())
-                     log.debugf(""Retrying due to previous failure. %s attempts left."", maxRetries - attemptNumber);
-                  successful = put(swap);
-                  attemptNumber++;
-               } while (!successful && attemptNumber <= maxRetries);
-
-               if (!successful)
-                  log.unableToProcessAsyncModifications(maxRetries);
+      private final Sync sync;
+      private final Counter counter;
+      private final Available available;
+
+      /**
+       * Create a new BufferLock with the specified buffer size.
+       *
+       * @param size
+       *           the buffer size
+       */
+      BufferLock(int size) {
+         sync = new Sync();
+         counter = size > 0 ? new Counter(size) : null;
+         available = new Available();
+      }
 
-            }
-         } finally {
-            lockContainer.releaseLocks(lockedKeys);
-            lockedKeys.clear();
-            asyncProcessorId.incrementAndGet();
-         }
+      /**
+       * Acquires the write lock and consumes the specified amount of buffer space. Blocks if the
+       * buffer is full or if the object is currently locked for reading.
+       *
+       * @param count
+       *           number of items the caller intends to write
+       */
+      void writeLock(int count) {
+         if (counter != null)
+            counter.acquireShared(count);
+         sync.acquireShared(1);
       }
 
-      boolean put(ConcurrentMap<Object, Modification> mods) {
-         try {
-            AsyncStore.this.applyModificationsSync(mods);
-            return true;
-         } catch (Exception e) {
-            if (log.isDebugEnabled()) log.debug(""Failed to process async modifications"", e);
-            return false;
-         }
+      /**
+       * Releases the write lock.
+       */
+      void writeUnlock() {
+         sync.releaseShared(1);
+         available.releaseShared(1);
       }
-   }
 
-   private static class ReleaseAllLockContainer extends ReentrantPerEntryLockContainer {
-      private ReleaseAllLockContainer(int concurrencyLevel) {
-         super(concurrencyLevel);
+      /**
+       * Acquires the read lock. Blocks if the buffer is empty or if the object is currently locked
+       * for writing.
+       */
+      void readLock() {
+         available.acquireShared(1);
+         sync.acquire(1);
       }
 
-      void releaseLocks(Set<Object> keys) {
-         for (Object key : keys) {
-            if (trace) log.tracef(""Release lock for key %s"", key);
-            releaseLock(null, key);
-         }
+      /**
+       * Releases the read lock.
+       */
+      void readUnlock() {
+         sync.release(1);
+      }
+
+      /**
+       * Resets the buffer counter to the specified number.
+       *
+       * @param count
+       *           number of available items in the buffer
+       */
+      void reset(int count) {
+         if (counter != null)
+            counter.releaseShared(count);
+         available.releaseShared(count);
+      }
+
+      /**
+       * Modifies the buffer counter by the specified value.
+       *
+       * @param count
+       *           number of items to add to the buffer counter
+       */
+      void add(int count) {
+         if (counter != null)
+            count = counter.add(count);
+         available.releaseShared(count);
       }
    }
 
@@ -459,106 +605,118 @@ private class AsyncStoreCoordinator implements Runnable {
       public void run() {
          LogFactory.pushNDC(cacheName, trace);
          try {
-            while (true) {
+            for (;;) {
+               State s, head, tail;
+               stateLock.readLock();
                try {
-                  Modification take = changesDeque.take();
-                  if (take == QUIT_SIGNAL) {
-                     lastAsyncProcessorShutsDownExecutor = true;
-                     ensureMoreWorkIsHandled();
-                     return;
+                  s = state;
+                  tail = s.next;
+                  assert tail == null || tail.next == null : ""State chain longer than 3 entries!"";
+                  state = head = newState(false, s);
+               } finally {
+                  stateLock.reset(0);
+                  stateLock.readUnlock();
+               }
+
+               try {
+                  if (s.clear) {
+                     // clear() must be called synchronously, wait until background threads are done
+                     if (tail != null)
+                        tail.workerThreads.await();
+                     getDelegate().clear();
                   }
-                  else {
-                     handleSafely(take);
+
+                  List<Modification> mods;
+                  if (tail != null) {
+                     // if there's work in progress, push-back keys that are still in use to the head state
+                     mods = new ArrayList<Modification>();
+                     for (Map.Entry<Object, Modification> e : s.modifications.entrySet()) {
+                        if (!tail.modifications.containsKey(e.getKey()))
+                           mods.add(e.getValue());
+                        else {
+                           if (!head.clear && head.modifications.putIfAbsent(e.getKey(), e.getValue()) == null)
+                              stateLock.add(1);
+                           s.modifications.remove(e.getKey());
+                        }
+                     }
+                  } else {
+                     mods = new ArrayList<Modification>(s.modifications.values());
+                  }
+
+                  // distribute modifications evenly across worker threads
+                  int threads = Math.min(mods.size(), asyncStoreConfig.getThreadPoolSize());
+                  s.workerThreads = new CountDownLatch(threads);
+                  if (threads > 0) {
+                     // schedule background threads
+                     int start = 0;
+                     int quotient = mods.size() / threads;
+                     int remainder = mods.size() % threads;
+                     for (int i = 0; i < threads; i++) {
+                        int end = start + quotient + (i < remainder ? 1 : 0);
+                        executor.execute(new AsyncStoreProcessor(mods.subList(start, end), s));
+                        start = end;
+                     }
+                     assert start == mods.size() : ""Thread distribution is broken!"";
+                  }
+
+                  // wait until background threads of previous round are done
+                  if (tail != null) {
+                     tail.workerThreads.await();
+                     s.next = null;
                   }
-               } catch (InterruptedException e) {
-                  log.asyncStoreCoordinatorInterrupted(e);
-                  return;
-               } catch (Throwable t) {
-                  log.unexpectedErrorInAsyncStoreCoordinator(t);
+
+                  // if this is the last state to process, wait for background threads, then quit
+                  if (s.stopped) {
+                     s.workerThreads.await();
+                     return;
+                  }
+               } catch (Exception e) {
+                  if (log.isDebugEnabled())
+                     log.debug(""Failed to process async modifications"", e);
                }
             }
          } finally {
             LogFactory.popNDC(trace);
          }
       }
+   }
 
-      private void handleSafely(Modification mod) {
-         try {
-            if (trace) log.tracef(""taking from modification queue: %s"", mod);
-            handle(mod, false);
-         } catch (Exception e) {
-            log.errorModifyingAsyncStore(e);
-         }
-      }
+   private class AsyncStoreProcessor implements Runnable {
+      private final List<Modification> modifications;
+      private final State myState;
 
-      private void handle(Modification mod, boolean nested) {
-         boolean asyncProcessorNeeded = false;
-         switch (mod.getType()) {
-            case STORE:
-               Store store = (Store) mod;
-               stateMapLock.lock();
-               state.put(store.getStoredEntry().getKey(), store);
-               stateMapLock.unlock();
-               asyncProcessorNeeded = true;
-               break;
-            case REMOVE:
-               Remove remove = (Remove) mod;
-               stateMapLock.lock();
-               state.put(remove.getKey(), remove);
-               stateMapLock.unlock();
-               asyncProcessorNeeded = true;
-               break;
-            case CLEAR:
-               performClear();
-               break;
-            case PURGE_EXPIRED:
-               delegatePurgeExpired();
-               break;
-            case LIST:
-               applyModificationsList((ModificationsList) mod);
-               asyncProcessorNeeded = true;
-               break;
-            default:
-               throw new IllegalArgumentException(""Unexpected modification type "" + mod.getType());
-         }
-         if (asyncProcessorNeeded && !nested) {
-            // we know when it's possible for some work to be done, starting short-lived
-            // AsyncProcessor(s) simplifies shutdown process.
-             ensureMoreWorkIsHandled();
-         }
+      AsyncStoreProcessor(List<Modification> modifications, State myState) {
+         this.modifications = modifications;
+         this.myState = myState;
       }
 
-      private void applyModificationsList(ModificationsList mod) {
-         for (Modification m : mod.getList()) {
-            handle(m, true);
-         }
+      @Override
+      public void run() {
+         // try 3 times to store the modifications
+         retryWork(3);
+
+         // decrement active worker threads and disconnect myState if this was the last one
+         myState.workerThreads.countDown();
+         if (myState.workerThreads.getCount() == 0)
+            for (State s = state; s != null; s = s.next)
+               if (s.next == myState)
+                  s.next = null;
       }
 
-      private void performClear() {
-         state.clear(); // cancel any other scheduled changes
-         clearAllWriteLock.lock(); // ensure no other tasks concurrently working
-         try {
-            // to acquire clearAllWriteLock we might have had to wait for N AsyncProcessor to have finished
-            // (as they have to release all clearAllReadLock),
-            // so as they might have put back some work to the state map, clear the state map again inside the writeLock:
-            state.clear();
-            if (trace) log.trace(""Performed clear operation"");
-            int maxRetries = 3;
-            int attemptNumber = 0;
-            boolean successful = false;
-            do {
-               if (attemptNumber > 0 && log.isDebugEnabled())
-                  log.debugf(""Retrying clear() due to previous failure. %s attempts left."", maxRetries - attemptNumber);
-               successful = applyClear();
-               attemptNumber++;
-            } while (!successful && attemptNumber <= maxRetries);
-            if (!successful) {
-               log.unableToClearAsyncStore();
+      private void retryWork(int maxRetries) {
+         for (int attempt = 0; attempt < maxRetries; attempt++) {
+            if (attempt > 0 && log.isDebugEnabled())
+               log.debugf(""Retrying due to previous failure. %s attempts left."", maxRetries - attempt);
+
+            try {
+               AsyncStore.this.applyModificationsSync(modifications);
+               return;
+            } catch (Exception e) {
+               if (log.isDebugEnabled())
+                  log.debug(""Failed to process async modifications"", e);
             }
-         } finally {
-            clearAllWriteLock.unlock();
          }
+         log.unableToProcessAsyncModifications(maxRetries);
       }
-
    }
-}
+}
\ No newline at end of file",2012-10-03T12:24:38Z,30
"@@ -26,9 +26,11 @@
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.NoSuchElementException;
+import java.util.Set;
 
 import static java.util.Collections.singletonMap;
 import static java.util.Collections.unmodifiableMap;
@@ -165,4 +167,20 @@ public static <K, V, E> Map<K, V> transformCollectionToMap(Collection<E> input,
          return unmodifiableMap(map);
       }
    }
+
+   /**
+    * Returns the elements that are present in s1 but which are not present
+    * in s2, without changing the contents of neither s1, nor s2.
+    *
+    * @param s1 first set
+    * @param s2 second set
+    * @param <E> type of objects in Set
+    * @return the elements in s1 that are not in s2
+    */
+   public static <E> Set<E> difference(Set<E> s1, Set<E> s2) {
+      Set<E> copy1 = new HashSet<E>(s1);
+      copy1.removeAll(new HashSet<E>(s2));
+      return copy1;
+   }
+
 }",2012-10-03T12:24:38Z,31
"@@ -295,18 +295,7 @@ public interface EvictionListener<K, V> {
 
       void onEntryEviction(Map<K, V> evicted);
 
-      /**
-       * Callback when an entry has been selected for eviction.
-       * Implementations can use this method to make a decision on whether the
-       * evicted entry should really be evicted, and they can use the return
-       * of this method to signal that.
-       *
-       * @param internalCacheEntry
-       * @return true if the eviction should go through, false if the
-       * eviction process should halt.
-       */
-      boolean onEntryChosenForEviction(V internalCacheEntry);
-
+      void onEntryChosenForEviction(V internalCacheEntry);
    }
 
    static final class NullEvictionListener<K, V> implements EvictionListener<K, V> {
@@ -315,9 +304,8 @@ public void onEntryEviction(Map<K, V> evicted) {
          // Do nothing.
       }
       @Override
-      public boolean onEntryChosenForEviction(V internalCacheEntry) {
+      public void onEntryChosenForEviction(V internalCacheEntry) {
          // Do nothing.
-         return false;
       }
    }
 
@@ -530,11 +518,9 @@ protected boolean removeEldestEntry(Map.Entry<HashEntry<K,V>,V> eldest){
          boolean aboveThreshold = isAboveThreshold();
          if(aboveThreshold){
             HashEntry<K, V> evictedEntry = eldest.getKey();
-            boolean evict = segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
-            if (evict) {
-               segment.remove(evictedEntry.key, evictedEntry.hash, null);
-               evicted.add(evictedEntry);
-            }
+            segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
+            segment.remove(evictedEntry.key, evictedEntry.hash, null);
+            evicted.add(evictedEntry);
          }
          return aboveThreshold;
       }
@@ -608,11 +594,9 @@ public void addAndRemoveEldest(HashEntry<K, V> entry) {
             LRUHashEntry<K, V> evictedEntry = head.nextEntry;
             //remove eldest entry from doubly-linked list
             head.nextEntry.remove();
-            boolean evict = segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
-            if (evict) {
-               segment.remove(evictedEntry.key, evictedEntry.hash, null);
-               evicted.add(evictedEntry);
-            }
+            segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
+            segment.remove(evictedEntry.key, evictedEntry.hash, null);
+            evicted.add(evictedEntry);
          }
       }
 
@@ -1231,9 +1215,10 @@ public Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> en) {
       private void removeFromSegment(Set<HashEntry<K, V>> evicted) {
          for (HashEntry<K, V> e : evicted) {
             ((LIRSHashEntry<K, V>)e).evict();
-            boolean evict = segment.evictionListener.onEntryChosenForEviction(e.value);
-            if (evict)
-               segment.remove(e.key, e.hash, null);
+//            boolean evict =
+            segment.evictionListener.onEntryChosenForEviction(e.value);
+//            if (evict)
+            segment.remove(e.key, e.hash, null);
          }
       }
 ",2012-10-03T12:24:38Z,32
"@@ -23,7 +23,6 @@
 package org.infinispan.config;
 
 import org.infinispan.AdvancedCache;
-import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.DefaultDataContainer;
 import org.infinispan.container.InternalEntryFactoryImpl;
@@ -79,8 +78,7 @@ public void testCustomDataContainerClass() throws IOException {
          AdvancedCache<Object, Object> cache = cm.getCache().getAdvancedCache();
 
          DataContainer ddc = DefaultDataContainer.unBoundedDataContainer(cache.getConfiguration().getConcurrencyLevel());
-         ((DefaultDataContainer) ddc).initialize(null, null,new InternalEntryFactoryImpl(),
-               new ConfigurationBuilder().build(), null);
+         ((DefaultDataContainer) ddc).initialize(null, null,new InternalEntryFactoryImpl());
          QueryableDataContainer.setDelegate(ddc);
 
          // Verify that the default is correctly established
@@ -113,8 +111,7 @@ public void testCustomDataContainer() {
          AdvancedCache<Object, Object> cache = cm.getCache().getAdvancedCache();
 
          DataContainer ddc = DefaultDataContainer.unBoundedDataContainer(cache.getConfiguration().getConcurrencyLevel());
-         ((DefaultDataContainer) ddc).initialize(
-               null, null,new InternalEntryFactoryImpl(), new ConfigurationBuilder().build(), null);
+         ((DefaultDataContainer) ddc).initialize(null, null,new InternalEntryFactoryImpl());
          QueryableDataContainer.setDelegate(ddc);
 
          // Verify that the config is correct",2012-10-03T12:24:38Z,33
"@@ -22,7 +22,6 @@
  */
 package org.infinispan.container;
 
-import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.container.entries.ImmortalCacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.MortalCacheEntry;
@@ -56,8 +55,7 @@ public void tearDown() {
 
    protected DataContainer createContainer() {
       DefaultDataContainer dc = new DefaultDataContainer(16);
-      dc.initialize(null, null, new InternalEntryFactoryImpl(),
-            new ConfigurationBuilder().build(), null);
+      dc.initialize(null, null, new InternalEntryFactoryImpl());
       return dc;
    }
 ",2012-10-03T12:24:38Z,34
"@@ -0,0 +1,297 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.loaders.decorators;
+
+import java.util.concurrent.locks.ReentrantLock;
+
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.cache.StoreConfigurationBuilder;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.eviction.EvictionStrategy;
+import org.infinispan.loaders.CacheLoaderConfig;
+import org.infinispan.loaders.CacheLoaderMetadata;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.test.CacheManagerCallable;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+
+import org.testng.annotations.Test;
+
+@Test(groups = ""unit"", testName = ""loaders.decorators.AsyncTest"")
+public class AsyncStoreEvictionTest {
+
+   // set to false to fix all the tests
+   private static final boolean USE_ASYNC_STORE = true;
+
+   private static ConfigurationBuilder config(boolean passivation, int threads) {
+      ConfigurationBuilder config = new ConfigurationBuilder();
+      config.expiration().wakeUpInterval(100);
+      config.eviction().maxEntries(1).strategy(EvictionStrategy.LRU);
+      StoreConfigurationBuilder store = config.loaders().passivation(passivation).addStore().cacheStore(new LockableCacheStore());
+      if (USE_ASYNC_STORE)
+         store.async().enable().threadPoolSize(threads);
+      return config;
+   }
+
+   private final static ThreadLocal<LockableCacheStore> STORE = new ThreadLocal<LockableCacheStore>();
+
+   public static class LockableCacheStoreConfig extends DummyInMemoryCacheStore.Cfg {
+      private static final long serialVersionUID = 1L;
+
+      public LockableCacheStoreConfig() {
+         setCacheLoaderClassName(LockableCacheStore.class.getName());
+      }
+   }
+
+   @CacheLoaderMetadata(configurationClass = LockableCacheStoreConfig.class)
+   public static class LockableCacheStore extends DummyInMemoryCacheStore {
+      private final ReentrantLock lock = new ReentrantLock();
+
+      public LockableCacheStore() {
+         super();
+         STORE.set(this);
+      }
+
+      @Override
+      public Class<? extends CacheLoaderConfig> getConfigurationClass() {
+         return LockableCacheStoreConfig.class;
+      }
+
+      @Override
+      public void store(InternalCacheEntry ed) {
+         lock.lock();
+         try {
+            super.store(ed);
+         } finally {
+            lock.unlock();
+         }
+      }
+
+      @Override
+      public boolean remove(Object key) {
+         lock.lock();
+         try {
+            return super.remove(key);
+         } finally {
+            lock.unlock();
+         }
+      }
+   }
+
+   private static abstract class CacheCallable extends CacheManagerCallable {
+      protected final Cache<String, String> cache;
+      protected final LockableCacheStore store;
+
+      CacheCallable(ConfigurationBuilder builder) {
+         super(TestCacheManagerFactory.createCacheManager(builder));
+         cache = cm.getCache();
+         store = STORE.get();
+      }
+   }
+
+   public void testEndToEndEvictionPassivation() throws Exception {
+      testEndToEndEviction(true);
+   }
+   public void testEndToEndEviction() throws Exception {
+      testEndToEndEviction(false);
+   }
+   private void testEndToEndEviction(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(passivation, 1)) {
+         @Override
+         public void call() {
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.put(""k1"", ""v1"");
+               cache.put(""k2"", ""v2""); // force eviction of ""k1""
+               TestingUtil.sleepThread(100); // wait until the only AsyncProcessor thread is blocked
+               cache.put(""k3"", ""v3"");
+               cache.put(""k4"", ""v4""); // force eviction of ""k3""
+
+               assert ""v3"".equals(cache.get(""k3"")) : ""cache must return k3 == v3 (was: "" + cache.get(""k3"") + "")"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testEndToEndUpdatePassivation() throws Exception {
+      testEndToEndUpdate(true);
+   }
+   public void testEndToEndUpdate() throws Exception {
+      testEndToEndUpdate(false);
+   }
+   private void testEndToEndUpdate(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(passivation, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v0"");
+            cache.put(""k2"", ""v2""); // force eviction of ""k1""
+
+            // wait for k1 == v1 to appear in store
+            while (store.load(""k1"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.put(""k3"", ""v3"");
+               cache.put(""k4"", ""v4""); // force eviction of ""k3""
+               TestingUtil.sleepThread(100); // wait until the only AsyncProcessor thread is blocked
+               cache.put(""k1"", ""v1"");
+               cache.put(""k5"", ""v5""); // force eviction of ""k1""
+
+               assert ""v1"".equals(cache.get(""k1"")) : ""cache must return k1 == v1 (was: "" + cache.get(""k1"") + "")"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testEndToEndRemovePassivation() throws Exception {
+      testEndToEndRemove(true);
+   }
+   public void testEndToEndRemove() throws Exception {
+      testEndToEndRemove(false);
+   }
+   private void testEndToEndRemove(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(passivation, 2)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2""); // force eviction of ""k1""
+
+            // wait for ""k1"" to appear in store
+            while (store.load(""k1"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.remove(""k1"");
+               TestingUtil.sleepThread(100); // wait until the first AsyncProcessor thread is blocked
+               cache.remove(""k1""); // make second AsyncProcessor thread burn asyncProcessorIds
+               TestingUtil.sleepThread(200); // wait for reaper to collect InternalNullEntry
+
+               assert null == cache.get(""k1"") : ""cache must return k1 == null (was: "" + cache.get(""k1"") + "")"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testNPE() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.remove(""k1"");
+            // this causes NPE in AsyncStore.isLocked(InternalNullEntry.getKey())
+            cache.put(""k2"", ""v2"");
+         }
+      });
+   }
+
+   public void testLIRS() throws Exception {
+      ConfigurationBuilder config = config(false, 1);
+      config.eviction().strategy(EvictionStrategy.LIRS).maxEntries(1);
+      TestingUtil.withCacheManager(new CacheCallable(config) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2"");
+            cache.put(""k1"", ""v3"");
+            cache.put(""k2"", ""v4"");
+            cache.put(""k3"", ""v3"");
+            cache.put(""k4"", ""v4"");
+         }
+      });
+   }
+
+   public void testSize() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2"");
+
+            assert cache.size() == 1 : ""cache size must be 1, was: "" + cache.size();
+         }
+      });
+   }
+
+   public void testSizeAfterExpiration() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2"");
+            TestingUtil.sleepThread(200);
+
+            assert !(cache.size() == 2) : ""expiry doesn't work even after expiration"";
+         }
+      });
+   }
+
+   public void testSizeAfterEvict() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.evict(""k1"");
+
+            assert cache.size() == 0 : ""cache size must be 0, was: "" + cache.size();
+         }
+      });
+   }
+
+   public void testSizeAfterRemove() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.remove(""k1"");
+
+            assert cache.size() == 0 : ""cache size must be 0, was: "" + cache.size();
+         }
+      });
+   }
+
+   public void testSizeAfterRemoveAndExpiration() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.remove(""k1"");
+            int size = cache.size();
+            TestingUtil.sleepThread(200);
+
+            assert !(size == 1 && cache.size() == 0) : ""remove only works after expiration"";
+         }
+      });
+   }
+}",2012-10-03T12:24:38Z,35
"@@ -35,6 +35,7 @@
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStoreConfigurationBuilder;
 import org.infinispan.loaders.modifications.Modification;
+import org.infinispan.loaders.modifications.Remove;
 import org.infinispan.loaders.modifications.Store;
 import org.infinispan.test.CacheManagerCallable;
 import org.infinispan.test.TestingUtil;
@@ -44,9 +45,9 @@
 import org.testng.annotations.Test;
 
 import java.util.Collection;
+import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
@@ -249,11 +250,11 @@ public MockAsyncStore(CountDownLatch modApplyLatch, CountDownLatch lockedWaitLat
       }
 
       @Override
-      protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
+      protected void applyModificationsSync(List<Modification> mods)
             throws CacheLoaderException {
          try {
             // Wait for signal to do the modification
-            if (mods.containsKey(1) && !isSkip(mods.get(1))) {
+            if (containsModificationForKey(1, mods) && !isSkip(findModificationForKey(1, mods))) {
                log.tracef(""Wait to apply modifications: %s"", mods);
                lockedWaitLatch.countDown();
                modApplyLatch.await(60, TimeUnit.SECONDS);
@@ -265,6 +266,30 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          }
       }
 
+      private boolean containsModificationForKey(Object key, List<Modification> mods) {
+         return findModificationForKey(key, mods) != null;
+      }
+
+      private Modification findModificationForKey(Object key, List<Modification> mods) {
+         for (Modification modification : mods) {
+            switch (modification.getType()) {
+               case STORE:
+                  Store store = (Store) modification;
+                  if (store.getStoredEntry().getKey().equals(key))
+                     return store;
+                  break;
+               case REMOVE:
+                  Remove remove = (Remove) modification;
+                  if (remove.getKey().equals(key))
+                     return remove;
+                  break;
+               default:
+                  return null;
+            }
+         }
+         return null;
+      }
+
       private boolean isSkip(Modification mod) {
          if (mod instanceof Store) {
             InternalCacheEntry storedEntry = ((Store) mod).getStoredEntry();",2012-10-03T12:24:38Z,36
"@@ -22,18 +22,23 @@
  */
 package org.infinispan.loaders.decorators;
 
+import org.infinispan.Cache;
 import org.infinispan.CacheException;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
 import org.infinispan.test.fwk.TestInternalCacheEntryFactory;
+import org.infinispan.loaders.CacheLoaderConfig;
 import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.CacheLoaderMetadata;
 import org.infinispan.loaders.CacheStore;
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
 import org.infinispan.loaders.modifications.Clear;
 import org.infinispan.loaders.modifications.Modification;
 import org.infinispan.loaders.modifications.Remove;
 import org.infinispan.loaders.modifications.Store;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.test.AbstractInfinispanTest;
+import org.infinispan.test.CacheManagerCallable;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.transaction.xa.TransactionFactory;
@@ -46,7 +51,6 @@
 import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;
@@ -55,6 +59,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.locks.ReentrantLock;
 
 import static org.infinispan.test.TestingUtil.k;
 import static org.infinispan.test.TestingUtil.v;
@@ -168,6 +173,8 @@ public void testThreadSafetyWritingDiffValuesForKey(Method m) throws Exception {
    }
 
    public void testTransactionalModificationsHappenInDiffThread(Method m) throws Exception {
+      final int waitTimeout = 10;
+      final TimeUnit waitUnit = TimeUnit.SECONDS;
       try {
          final TransactionFactory gtf = new TransactionFactory();
          gtf.init(false, false, true, false);
@@ -177,19 +184,30 @@ public void testTransactionalModificationsHappenInDiffThread(Method m) throws Ex
          DummyInMemoryCacheStore underlying = new DummyInMemoryCacheStore();
          store = new AsyncStore(underlying, asyncConfig) {
             @Override
-            protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
-               for (Map.Entry<Object, Modification> entry : mods.entrySet()) {
-                  localMods.put(entry.getKey(), entry.getValue());
-               }
+            protected void applyModificationsSync(List<Modification> mods) throws CacheLoaderException {
+               for (Modification mod : mods)
+                  localMods.put(getKey(mod), mod);
+
                super.applyModificationsSync(mods);
                try {
-                  barrier.await(5, TimeUnit.SECONDS);
+                  barrier.await(waitTimeout, waitUnit);
                } catch (TimeoutException e) {
                   assert false : ""Timed out applying for modifications"";
                } catch (Exception e) {
                   throw new CacheLoaderException(""Barrier failed"", e);
                }
             }
+
+            private Object getKey(Modification modification) {
+               switch (modification.getType()) {
+                  case STORE:
+                     return ((Store) modification).getStoredEntry().getKey();
+                  case REMOVE:
+                     return ((Remove) modification).getKey();
+                  default:
+                     return null;
+               }
+            }
          };
          dummyCfg = new DummyInMemoryCacheStore.Cfg();
          dummyCfg.setStoreName(m.getName());
@@ -208,7 +226,8 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert !store.containsKey(k2);
 
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit); // Wait for store
+         barrier.await(waitTimeout, waitUnit); // Wait for remove
          assert store.load(k2).getValue().equals(v2);
          assert !store.containsKey(k1);
          assert 2 == localMods.size();
@@ -221,6 +240,8 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
    }
 
    public void testTransactionalModificationsAreCoalesced(Method m) throws Exception {
+      final int waitTimeout = 10;
+      final TimeUnit waitUnit = TimeUnit.SECONDS;
       try {
          final TransactionFactory gtf = new TransactionFactory();
          gtf.init(false, false, true, false);
@@ -251,10 +272,12 @@ public void clear() {
          };
          store = new AsyncStore(underlying, asyncConfig) {
             @Override
-            protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
+            protected void applyModificationsSync(List<Modification> mods)
+                  throws CacheLoaderException {
                super.applyModificationsSync(mods);
                try {
-                  barrier.await(5, TimeUnit.SECONDS);
+                  log.tracef(""Wait to apply modifications: %s"", mods);
+                  barrier.await(waitTimeout, waitUnit);
                } catch (TimeoutException e) {
                   assert false : ""Timed out applying for modifications"";
                } catch (Exception e) {
@@ -280,7 +303,9 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS); //modifications applied all at once
+         log.tracef(""Wait for modifications to be queued: %s"", mods);
+         barrier.await(waitTimeout, waitUnit); // Wait for single store to be applied
+         barrier.await(waitTimeout, waitUnit); // Wait for single remove to be applied
          assert 1 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 1 == removeCount.get();
          assert 0 == clearCount.get();
@@ -301,7 +326,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit);
          assert 0 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 1 == removeCount.get();
          assert 1 == clearCount.get();
@@ -322,7 +347,9 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit); // Wait for store to be applied
+         barrier.await(waitTimeout, waitUnit); // Wait for first removal to be applied
+         barrier.await(waitTimeout, waitUnit); // Wait for second removal to be applied
          assert 1 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 2 == removeCount.get();
          assert 0 == clearCount.get();
@@ -340,7 +367,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit);
          assert 0 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 1 == removeCount.get();
          assert 1 == clearCount.get();
@@ -358,7 +385,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit);
          assert 1 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 0 == removeCount.get();
          assert 1 == clearCount.get();
@@ -375,94 +402,38 @@ private void doTestPut(int number, String key, String value) throws Exception {
          store.store(cacheEntry);
       }
 
-      store.stop();
-      store.start();
-
-      InternalCacheEntry[] entries = new InternalCacheEntry[number];
-      for (int i = 0; i < number; i++) {
-         entries[i] = store.load(key + i);
-      }
-
       for (int i = 0; i < number; i++) {
-         InternalCacheEntry entry = entries[i];
-         if (entry != null) {
-            assert entry.getValue().equals(value + i);
-         } else {
-            while (entry == null) {
-               entry = store.load(key + i);
-               if (entry != null) {
-                  assert entry.getValue().equals(value + i);
-               } else {
-                  TestingUtil.sleepThreadInt(20, ""still waiting for key to appear: "" + key + i);
-               }
-            }
-         }
+         InternalCacheEntry ice = store.load(key + i);
+         assert ice != null && (value + i).equals(ice.getValue());
       }
    }
 
    private void doTestSameKeyPut(int number, String key, String value) throws Exception {
       for (int i = 0; i < number; i++) {
          store.store(TestInternalCacheEntryFactory.create(key, value + i));
       }
-
-      store.stop();
-      store.start();
-      InternalCacheEntry entry;
-      boolean success = false;
-      for (int i = 0; i < 120; i++) {
-         TestingUtil.sleepThreadInt(20, null);
-         entry = store.load(key);
-         success = entry.getValue().equals(value + (number - 1));
-         if (success) break;
-      }
-      assert success;
+      InternalCacheEntry ice = store.load(key);
+      assert ice != null && (value + (number - 1)).equals(ice.getValue());
    }
 
    private void doTestRemove(int number, String key) throws Exception {
       for (int i = 0; i < number; i++) store.remove(key + i);
 
-      store.stop();//makes sure the store is flushed
-      store.start();
-
-      InternalCacheEntry[] entries = new InternalCacheEntry[number];
-      for (int i = 0; i < number; i++) {
-         entries[i] = store.load(key + i);
-      }
-
       for (int i = 0; i < number; i++) {
-         InternalCacheEntry entry = entries[i];
-         while (entry != null) {
-            TestingUtil.sleepThreadInt(20, ""still waiting for key to be removed: "" + key + i);
-            entry = store.load(key + i);
-         }
+         assert store.load(key + i) == null;
       }
    }
 
    private void doTestSameKeyRemove(String key) throws Exception {
       store.remove(key);
-      InternalCacheEntry entry;
-      do {
-         TestingUtil.sleepThreadInt(20, ""still waiting for key to be removed: "" + key);
-         entry = store.load(key);
-      } while (entry != null);
+      assert store.load(key) == null;
    }
 
    private void doTestClear(int number, String key) throws Exception {
       store.clear();
-      store.stop();
-      store.start();
-
-      InternalCacheEntry[] entries = new InternalCacheEntry[number];
-      for (int i = 0; i < number; i++) {
-         entries[i] = store.load(key + i);
-      }
 
       for (int i = 0; i < number; i++) {
-         InternalCacheEntry entry = entries[i];
-         while (entry != null) {
-            TestingUtil.sleepThreadInt(20, ""still waiting for key to be removed: "" + key + i);
-            entry = store.load(key + i);
-         }
+         assert store.load(key + i) == null;
       }
    }
 
@@ -483,23 +454,207 @@ static class MockAsyncStore extends AsyncStore {
       }
 
       @Override
-      protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
-         if (mods.get(key) != null && block) {
+      protected void applyModificationsSync(List<Modification> mods) throws CacheLoaderException {
+         boolean keyFound = findModificationForKey(key, mods) != null;
+         if (keyFound && block) {
             log.trace(""Wait for v1 latch"");
             try {
                v2Latch.countDown();
                block = false;
                v1Latch.await(2, TimeUnit.SECONDS);
             } catch (InterruptedException e) {
+               Thread.currentThread().interrupt();
             }
             super.applyModificationsSync(mods);
-         } else if (mods.get(key) != null && !block) {
+         } else if (keyFound && !block) {
             log.trace(""Do v2 modification and unleash v1 latch"");
             super.applyModificationsSync(mods);
             v1Latch.countDown();
             endLatch.countDown();
          }
       }
 
+      private Modification findModificationForKey(Object key, List<Modification> mods) {
+         for (Modification modification : mods) {
+            switch (modification.getType()) {
+               case STORE:
+                  Store store = (Store) modification;
+                  if (store.getStoredEntry().getKey().equals(key))
+                     return store;
+                  break;
+               case REMOVE:
+                  Remove remove = (Remove) modification;
+                  if (remove.getKey().equals(key))
+                     return remove;
+                  break;
+               default:
+                  return null;
+            }
+         }
+         return null;
+      }
+
+   }
+
+   private final static ThreadLocal<LockableCacheStore> STORE = new ThreadLocal<LockableCacheStore>();
+
+   public static class LockableCacheStoreConfig extends DummyInMemoryCacheStore.Cfg {
+      private static final long serialVersionUID = 1L;
+
+      public LockableCacheStoreConfig() {
+         setCacheLoaderClassName(LockableCacheStore.class.getName());
+      }
+   }
+
+   @CacheLoaderMetadata(configurationClass = LockableCacheStoreConfig.class)
+   public static class LockableCacheStore extends DummyInMemoryCacheStore {
+      private final ReentrantLock lock = new ReentrantLock();
+
+      public LockableCacheStore() {
+         super();
+         STORE.set(this);
+      }
+
+      @Override
+      public Class<? extends CacheLoaderConfig> getConfigurationClass() {
+         return LockableCacheStoreConfig.class;
+      }
+
+      @Override
+      public void store(InternalCacheEntry ed) {
+         lock.lock();
+         try {
+            super.store(ed);
+         } finally {
+            lock.unlock();
+         }
+      }
+
+      @Override
+      public boolean remove(Object key) {
+         lock.lock();
+         try {
+            return super.remove(key);
+         } finally {
+            lock.unlock();
+         }
+      }
+   }
+
+   public void testModificationQueueSize(final Method m) throws Exception {
+      LockableCacheStore underlying = new LockableCacheStore();
+      asyncConfig.modificationQueueSize(10);
+      store = new AsyncStore(underlying, asyncConfig);
+      store.init(new LockableCacheStoreConfig(), null, null);
+      store.start();
+      try {
+         final CountDownLatch done = new CountDownLatch(1);
+
+         underlying.lock.lock();
+         try {
+            Thread t = new Thread() {
+               @Override
+               public void run() {
+                  try {
+                     for (int i = 0; i < 100; i++)
+                        store.store(TestInternalCacheEntryFactory.create(k(m, i), v(m, i)));
+                  } catch (Exception e) {
+                     log.error(""Error storing entry"", e);
+                  }
+                  done.countDown();
+               }
+            };
+            t.start();
+
+            assert !done.await(1, TimeUnit.SECONDS) : ""Background thread should have blocked after adding 10 entries"";
+         } finally {
+            underlying.lock.unlock();
+         }
+      } finally {
+         store.stop();
+      }
+   }
+
+   private static abstract class OneEntryCacheManagerCallable extends CacheManagerCallable {
+      protected final Cache<String, String> cache;
+      protected final LockableCacheStore store;
+
+      private static ConfigurationBuilder config(boolean passivation) {
+         ConfigurationBuilder config = new ConfigurationBuilder();
+         config.eviction().maxEntries(1).loaders().passivation(passivation).addStore()
+               .cacheStore(new LockableCacheStore()).async().enable();
+         return config;
+      }
+
+      OneEntryCacheManagerCallable(boolean passivation) {
+         super(TestCacheManagerFactory.createCacheManager(config(passivation)));
+         cache = cm.getCache();
+         store = STORE.get();
+      }
+   }
+
+   public void testEndToEndPutPutPassivation() throws Exception {
+      doTestEndToEndPutPut(true);
+   }
+
+   public void testEndToEndPutPut() throws Exception {
+      doTestEndToEndPutPut(false);
+   }
+
+   private void doTestEndToEndPutPut(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new OneEntryCacheManagerCallable(passivation) {
+         @Override
+         public void call() {
+            cache.put(""X"", ""1"");
+            cache.put(""Y"", ""1""); // force eviction of ""X""
+
+            // wait for X == 1 to appear in store
+            while (store.load(""X"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.put(""X"", ""2"");
+               cache.put(""Y"", ""2""); // force eviction of ""X""
+
+               assert ""2"".equals(cache.get(""X"")) : ""cache must return X == 2"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testEndToEndPutRemovePassivation() throws Exception {
+      doTestEndToEndPutRemove(true);
+   }
+
+   public void testEndToEndPutRemove() throws Exception {
+      doTestEndToEndPutRemove(false);
+   }
+
+   private void doTestEndToEndPutRemove(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new OneEntryCacheManagerCallable(passivation) {
+         @Override
+         public void call() {
+            cache.put(""X"", ""1"");
+            cache.put(""Y"", ""1""); // force eviction of ""X""
+
+            // wait for ""X"" to appear in store
+            while (store.load(""X"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.remove(""X"");
+
+               assert null == cache.get(""X"") : ""cache must return X == null"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
    }
 }",2012-10-03T12:24:38Z,37
"@@ -28,6 +28,7 @@
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.marshall.TestObjectStreamMarshaller;
 import org.infinispan.test.TestingUtil;
+import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
@@ -38,18 +39,20 @@
 import java.util.*;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.atomic.AtomicInteger;
 
 @CacheLoaderMetadata(configurationClass = DummyInMemoryCacheStore.Cfg.class)
 public class DummyInMemoryCacheStore extends AbstractCacheStore {
    private static final Log log = LogFactory.getLog(DummyInMemoryCacheStore.class);
    private static final boolean trace = log.isTraceEnabled();
+   private static final boolean debug = log.isDebugEnabled();
    static final ConcurrentMap<String, Map<Object, InternalCacheEntry>> stores = new ConcurrentHashMap<String, Map<Object, InternalCacheEntry>>();
-   static final ConcurrentMap<String, ConcurrentMap<String, Integer>> storeStats =
-         new ConcurrentHashMap<String, ConcurrentMap<String, Integer>>();
+   static final ConcurrentMap<String, ConcurrentMap<String, AtomicInteger>> storeStats =
+         new ConcurrentHashMap<String, ConcurrentMap<String, AtomicInteger>>();
    String storeName;
    Map<Object, InternalCacheEntry> store;
    // When a store is 'shared', multiple nodes could be trying to update it concurrently.
-   ConcurrentMap<String, Integer> stats;
+   ConcurrentMap<String, AtomicInteger> stats;
    Cfg config;
 
    public DummyInMemoryCacheStore(String storeName) {
@@ -60,26 +63,14 @@ public DummyInMemoryCacheStore() {
    }
 
    private void record(String method) {
-      boolean replaced;
-      long end = System.currentTimeMillis() + 5000;
-      do {
-         int i = stats.get(method);
-         replaced = stats.replace(method, i, i + 1);
-         if (!replaced) {
-            try {
-               Thread.sleep(200);
-            } catch (InterruptedException e) {
-               Thread.currentThread().interrupt();
-            }
-         }
-      } while (!replaced && end < System.currentTimeMillis());
+      stats.get(method).incrementAndGet();
    }
 
    @Override
    public void store(InternalCacheEntry ed) {
       record(""store"");
       if (ed != null) {
-         if (trace) log.tracef(""Store %s in dummy map store@%s"", ed, Util.hexIdHashCode(store));
+         if (debug) log.debugf(""Store %s in dummy map store@%s"", ed, Util.hexIdHashCode(store));
          config.failIfNeeded(ed.getKey());
          store.put(ed.getKey(), ed);
       }
@@ -123,11 +114,11 @@ public void clear() {
    public boolean remove(Object key) {
       record(""remove"");
       if (store.remove(key) != null) {
-         if (trace) log.tracef(""Removed %s from dummy store"", key);
+         if (debug) log.debugf(""Removed %s from dummy store"", key);
          return true;
       }
 
-      if (trace) log.tracef(""Key %s not present in store, so don't remove"", key);
+      if (debug) log.debugf(""Key %s not present in store, so don't remove"", key);
       return false;
    }
 
@@ -238,7 +229,7 @@ public void start() throws CacheLoaderException {
             log.debugf(""Creating new in-memory cache store %s"", storeName);
          }
 
-         ConcurrentMap<String, Integer> existingStats = storeStats.putIfAbsent(storeName, stats);
+         ConcurrentMap<String, AtomicInteger> existingStats = storeStats.putIfAbsent(storeName, stats);
          if (existing != null) {
             stats = existingStats;
          }
@@ -248,10 +239,10 @@ public void start() throws CacheLoaderException {
       record(""start"");
    }
 
-   private ConcurrentMap<String, Integer> newStatsMap() {
-      ConcurrentMap<String, Integer> m = new ConcurrentHashMap<String, Integer>();
+   private ConcurrentMap<String, AtomicInteger> newStatsMap() {
+      ConcurrentMap<String, AtomicInteger> m = new ConcurrentHashMap<String, AtomicInteger>();
       for (Method method: CacheStore.class.getMethods()) {
-         m.put(method.getName(), 0);
+         m.put(method.getName(), new AtomicInteger(0));
       }
       return m;
    }
@@ -274,11 +265,13 @@ public boolean isEmpty() {
    }
 
    public Map<String, Integer> stats() {
-      return Collections.unmodifiableMap(stats);
+      Map<String, Integer> copy = new HashMap<String, Integer>(stats.size());
+      for (String k: stats.keySet()) copy.put(k, stats.get(k).get());
+      return copy;
    }
 
    public void clearStats() {
-      for (String k: stats.keySet()) stats.put(k, 0);
+      for (String k: stats.keySet()) stats.get(k).set(0);
    }
 
    public void blockUntilCacheStoreContains(Object key, Object expectedValue, long timeout) {
@@ -293,6 +286,57 @@ public void blockUntilCacheStoreContains(Object key, Object expectedValue, long
             timeout, key, expectedValue));
    }
 
+   public void blockUntilCacheStoreContains(Set<Map.Entry<Object, InternalCacheEntry>> expectedState, long timeout) {
+      long killTime = System.currentTimeMillis() + timeout;
+      // Set<? extends Map.Entry<?, InternalCacheEntry>> expectedEntries = expectedState.entrySet();
+      Set<Map.Entry<Object, InternalCacheEntry>> notStored = null;
+      Set<Map.Entry<Object, InternalCacheEntry>> notRemoved = null;
+      while (System.currentTimeMillis() < killTime) {
+         Set<Map.Entry<Object, InternalCacheEntry>> storeEntries = store.entrySet();
+         // Find out which entries might not have been removed from the store
+         notRemoved = InfinispanCollections.difference(storeEntries, expectedState);
+         // Find out which entries might not have been stored
+         notStored = InfinispanCollections.difference(expectedState, storeEntries);
+         if (!notStored.isEmpty() || !notRemoved.isEmpty()) {
+            TestingUtil.sleepThread(5000);
+         } else if (notStored.isEmpty() && notRemoved.isEmpty()) {
+            break;
+         }
+      }
+
+      if ((notStored != null && !notStored.isEmpty()) || (notRemoved != null && !notRemoved.isEmpty())) {
+         if (log.isTraceEnabled()) {
+            log.tracef(""Entries still not stored: %s"", notStored);
+            log.tracef(""Entries still not removed: %s"", notRemoved);
+         }
+         throw new RuntimeException(String.format(
+               ""Timed out waiting (%d ms) for cache store to be flushed. entries-not-stored=[%s], entries-not-removed=[%s]"",
+               timeout, notStored, notRemoved));
+      }
+
+
+//      if (missingEntries != null && !missingEntries.isEmpty())
+//         throw new RuntimeException(String.format(
+//            ""Timed out waiting (%d ms) for cache store to contain entry %s"",
+//            timeout, missingEntries));
+//
+//      long killTime = System.currentTimeMillis() + timeout;
+//      Map.Entry<?, ?> missingEntry = null;
+//      while (System.currentTimeMillis() < killTime) {
+//         for (Map.Entry<?, ?> stateEntry : expectedState.entrySet()) {
+//            InternalCacheEntry entry = store.get(stateEntry.getKey());
+//            if (entry == null || !entry.getValue().equals(stateEntry.getValue())) {
+//               missingEntry = entry;
+//               TestingUtil.sleepThread(50);
+//            }
+//         }
+//      }
+//      if (missingEntry != null)
+//         throw new RuntimeException(String.format(
+//            ""Timed out waiting (%d ms) for cache store to contain entry %s"",
+//            timeout, missingEntry));
+   }
+
    public static class Cfg extends AbstractCacheStoreConfig {
 
       private static final long serialVersionUID = 4258914047690999424L;",2012-10-03T12:24:38Z,38
"@@ -0,0 +1,466 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.stress;
+
+import org.infinispan.container.InternalEntryFactory;
+import org.infinispan.container.InternalEntryFactoryImpl;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.container.versioning.EntryVersion;
+import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.decorators.AbstractDelegatingStore;
+import org.infinispan.loaders.decorators.AsyncStore;
+import org.infinispan.loaders.decorators.AsyncStoreConfig;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.marshall.TestObjectStreamMarshaller;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.util.concurrent.locks.containers.LockContainer;
+import org.infinispan.util.concurrent.locks.containers.ReentrantPerEntryLockContainer;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.testng.annotations.DataProvider;
+import org.testng.annotations.Test;
+
+import java.util.ArrayList;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.TreeMap;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.locks.Lock;
+
+import static java.lang.Math.sqrt;
+
+/**
+ * Async store stress test.
+ *
+ * // TODO: Add a test to verify clear() too!
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(testName = ""stress.AsyncStoreStressTest"", groups = ""stress"",
+      enabled = true, description = ""Disabled by default, designed to be run manually."")
+public class AsyncStoreStressTest {
+
+   static final Log log = LogFactory.getLog(AsyncStoreStressTest.class);
+   static final boolean trace = log.isTraceEnabled();
+
+   static final int CAPACITY = Integer.getInteger(""size"", 100000);
+   static final int LOOP_FACTOR = 10;
+   static final long RUNNING_TIME = Integer.getInteger(""time"", 1) * 60 * 1000;
+   static final Random RANDOM = new Random(12345);
+
+   private volatile CountDownLatch latch;
+   private List<String> keys = new ArrayList<String>();
+   private InternalEntryFactory entryFactory = new InternalEntryFactoryImpl();
+   private Map<Object, InternalCacheEntry> expectedState = new ConcurrentHashMap<Object, InternalCacheEntry>();
+
+   // Lock container that mimics per-key locking produced by the cache.
+   // This per-key lock holder provides guarantees that the final expected
+   // state has not been affected by ordering issues such as this:
+   //
+   // (Thread-200:) Enqueuing modification Store{storedEntry=
+   // ImmortalCacheEntry{key=key165168, value=ImmortalCacheValue {value=60483}}}
+   // (Thread-194:) Enqueuing modification Store{storedEntry=
+   // ImmortalCacheEntry{key=key165168, value=ImmortalCacheValue {value=61456}}}
+   // (Thread-194:) Expected state updated with key=key165168, value=61456
+   // (Thread-200:) Expected state updated with key=key165168, value=60483
+   private LockContainer locks = new ReentrantPerEntryLockContainer(32);
+
+   private Map<String, AbstractDelegatingStore> createAsyncStores() throws CacheLoaderException {
+      Map<String, AbstractDelegatingStore> stores = new TreeMap<String, AbstractDelegatingStore>();
+      stores.put(""ASYNC"", createAsyncStore());
+      return stores;
+   }
+
+   private AsyncStore createAsyncStore() throws CacheLoaderException {
+      DummyInMemoryCacheStore backendStore = createBackendStore(""async2"");
+      AsyncStoreConfig asyncCfg = new AsyncStoreConfig();
+      asyncCfg.modificationQueueSize(0);
+      AsyncStore store = new AsyncStore(backendStore, asyncCfg);
+      store.init(backendStore.getCacheStoreConfig(), null, new TestObjectStreamMarshaller());
+      store.start();
+      return store;
+   }
+
+   private DummyInMemoryCacheStore createBackendStore(String storeName) throws CacheLoaderException {
+      DummyInMemoryCacheStore store = new DummyInMemoryCacheStore();
+      store.init(new DummyInMemoryCacheStore.Cfg(storeName), null, new TestObjectStreamMarshaller());
+      store.start();
+      return store;
+   }
+
+   @DataProvider(name = ""readWriteRemove"")
+   public Object[][] independentReadWriteRemoveParams() {
+      return new Object[][]{
+            new Object[]{CAPACITY, 3 * CAPACITY, 90, 9, 1},
+            new Object[]{CAPACITY, 3 * CAPACITY, 9, 1, 0},
+      };
+   }
+
+   @Test(dataProvider = ""readWriteRemove"", enabled = true)
+   public void testReadWriteRemove(int capacity, int numKeys,
+         int readerThreads, int writerThreads, int removerThreads) throws Exception {
+      System.out.printf(""Testing independent read/write/remove performance "" +
+            ""with capacity %d, keys %d, readers %d, writers %d, removers %d\n"",
+            capacity, numKeys, readerThreads, writerThreads, removerThreads);
+
+      generateKeyList(numKeys);
+
+      Map<String, AbstractDelegatingStore> stores = createAsyncStores();
+
+      for (Map.Entry<String, AbstractDelegatingStore> e : stores.entrySet()) {
+         mapTestReadWriteRemove(e.getKey(), e.getValue(), numKeys,
+               readerThreads, writerThreads, removerThreads);
+         e.setValue(null);
+      }
+   }
+
+   private void mapTestReadWriteRemove(String name, AbstractDelegatingStore store,
+         int numKeys, int readerThreads, int writerThreads, int removerThreads) throws Exception {
+      DummyInMemoryCacheStore delegate = (DummyInMemoryCacheStore) store.getDelegate();
+      try {
+         // warm up for 1 second
+         System.out.printf(""[store=%s] Warming up\n"", name);
+         runMapTestReadWriteRemove(name, store, readerThreads, writerThreads, removerThreads, 1000);
+
+         // real test
+         System.out.printf(""[store=%s] Testing...\n"", name);
+         TotalStats perf = runMapTestReadWriteRemove(name, store, readerThreads, writerThreads, removerThreads, RUNNING_TIME);
+
+         // Wait until the cache store contains the expected state
+         System.out.printf(""[store=%s] Verify contents\n"", name);
+         TestingUtil.sleepThread(10000); // Wait a bit before starting to verify contents
+         delegate.blockUntilCacheStoreContains(expectedState.entrySet(), 60000);
+
+         System.out.printf(""Container %-12s  "", name);
+         System.out.printf(""Ops/s %10.2f  "", perf.getTotalOpsPerSec());
+         System.out.printf(""Gets/s %10.2f  "", perf.getOpsPerSec(""GET""));
+         System.out.printf(""Puts/s %10.2f  "", perf.getOpsPerSec(""PUT""));
+         System.out.printf(""Removes/s %10.2f  "", perf.getOpsPerSec(""REMOVE""));
+         System.out.printf(""HitRatio %10.2f  "", perf.getTotalHitRatio() * 100);
+         System.out.printf(""Size %10d  "", store.loadAllKeys(null).size());
+         double stdDev = computeStdDev(store, numKeys);
+         System.out.printf(""StdDev %10.2f\n"", stdDev);
+      } finally {
+         // Clean up state, expected state and keys
+         expectedState.clear();
+         delegate.clear();
+      }
+   }
+
+   private TotalStats runMapTestReadWriteRemove(String name, final AbstractDelegatingStore store, int numReaders, int numWriters,
+         int numRemovers, final long runningTimeout) throws Exception {
+      latch = new CountDownLatch(1);
+      final TotalStats perf = new TotalStats();
+      List<Thread> threads = new LinkedList<Thread>();
+
+      for (int i = 0; i < numReaders; i++) {
+         Thread reader = new WorkerThread(""worker-"" + name + ""-get-"" + i, runningTimeout, perf, readOperation(store));
+         threads.add(reader);
+      }
+
+      for (int i = 0; i < numWriters; i++) {
+         Thread writer = new WorkerThread(""worker-"" + name + ""-put-"" + i, runningTimeout, perf, writeOperation(store));
+         threads.add(writer);
+      }
+
+      for (int i = 0; i < numRemovers; i++) {
+         Thread remover = new WorkerThread(""worker-"" + name + ""-remove-"" + i, runningTimeout, perf, removeOperation(store));
+         threads.add(remover);
+      }
+
+      for (Thread t : threads)
+         t.start();
+      latch.countDown();
+
+      for (Thread t : threads)
+         t.join();
+
+      return perf;
+   }
+
+   private void generateKeyList(int numKeys) {
+      // without this we keep getting OutOfMemoryErrors
+      keys = null;
+      keys = new ArrayList<String>(numKeys * LOOP_FACTOR);
+      for (int i = 0; i < numKeys * LOOP_FACTOR; i++) {
+         keys.add(""key"" + nextIntGaussian(numKeys));
+      }
+   }
+
+   private int nextIntGaussian(int numKeys) {
+      double gaussian = RANDOM.nextGaussian();
+      if (gaussian < -3 || gaussian > 3)
+         return nextIntGaussian(numKeys);
+
+      return (int) Math.abs((gaussian + 3) * numKeys / 6);
+   }
+
+   private void waitForStart() {
+      try {
+         latch.await();
+      } catch (InterruptedException e) {
+         throw new RuntimeException(e);
+      }
+   }
+
+   private Operation<String, Integer> readOperation(AbstractDelegatingStore store) {
+      return new Operation<String, Integer>(store, ""GET"") {
+         @Override
+         public boolean call(String key, long run) {
+            try {
+               InternalCacheEntry ice = store.load(key);
+               if (trace)
+                  log.tracef(""Loaded key=%s, value=%s"", key, ice != null ? ice.getValue() : ""null"");
+               return ice != null;
+            } catch (CacheLoaderException e) {
+               e.printStackTrace();
+               return false;
+            }
+         }
+      };
+   }
+
+   private Operation<String, Integer> writeOperation(AbstractDelegatingStore store) {
+      return new Operation<String, Integer>(store, ""PUT"") {
+         @Override
+         public boolean call(final String key, long run) {
+            final int value = (int) run;
+            final InternalCacheEntry entry =
+                  entryFactory.create(key, value, (EntryVersion) null);
+            // Store acquiring locks and catching exceptions
+            boolean result = withStore(key, new Callable<Boolean>() {
+               @Override
+               public Boolean call() throws Exception {
+                  store.store(entry);
+                  expectedState.put(key, entry);
+                  if (trace)
+                     log.tracef(""Expected state updated with key=%s, value=%s"", key, value);
+                  return true;
+               }
+            });
+            return result;
+         }
+      };
+   }
+
+   private Operation<String, Integer> removeOperation(AbstractDelegatingStore store) {
+      return new Operation<String, Integer>(store, ""REMOVE"") {
+         @Override
+         public boolean call(final String key, long run) {
+            // Remove acquiring locks and catching exceptions
+            boolean result = withStore(key, new Callable<Boolean>() {
+               @Override
+               public Boolean call() throws Exception {
+                  boolean removed = store.remove(key);
+                  if (removed) {
+                     expectedState.remove(key);
+                     if (trace)
+                        log.tracef(""Expected state removed key=%s"", key);
+                  }
+                  return true;
+               }
+            });
+            return result;
+         }
+      };
+   }
+   
+   private boolean withStore(String key, Callable<Boolean> call) {
+      Lock lock = null;
+      boolean result = false;
+      try {
+         lock = locks.acquireLock(Thread.currentThread(), key, 30, TimeUnit.SECONDS);
+         if (lock != null) {
+            result = call.call().booleanValue();
+         }
+      } catch (CacheLoaderException e) {
+         e.printStackTrace();
+         result = false;
+      } catch (InterruptedException e) {
+         e.printStackTrace();
+         result = false;
+      } finally {
+         if (lock == null) return false;
+         else {
+            lock.unlock();
+            return result;
+         }
+      }
+   }
+
+   private double computeStdDev(AbstractDelegatingStore store, int numKeys) throws CacheLoaderException {
+      // The keys closest to the mean are suposed to be accessed more often
+      // So we score each map by the standard deviation of the keys in the map
+      // at the end of the test
+      double variance = 0;
+      Set<Object> keys = store.loadAllKeys(null);
+      for (Object key : keys) {
+         double value = Integer.parseInt(((String )key).substring(3));
+         variance += (value - numKeys / 2) * (value - numKeys / 2);
+      }
+      return sqrt(variance / keys.size());
+   }
+
+   private class WorkerThread extends Thread {
+      private final long runningTimeout;
+      private final TotalStats perf;
+      private Operation<String, Integer> op;
+
+      public WorkerThread(String name, long runningTimeout, TotalStats perf, Operation<String, Integer> op) {
+         super(name);
+         this.runningTimeout = runningTimeout;
+         this.perf = perf;
+         this.op = op;
+      }
+
+      public void run() {
+         waitForStart();
+         long startMilis = System.currentTimeMillis();
+         long endMillis = startMilis + runningTimeout;
+         int keyIndex = RANDOM.nextInt(keys.size());
+         long runs = 0;
+         long missCount = 0;
+         while ((runs & 0x3FFF) != 0 || System.currentTimeMillis() < endMillis) {
+            boolean hit = op.call(keys.get(keyIndex), runs);
+            if (!hit) missCount++;
+            keyIndex++;
+            runs++;
+            if (keyIndex >= keys.size()) {
+               keyIndex = 0;
+            }
+         }
+         perf.addStats(op.getName(), runs, System.currentTimeMillis() - startMilis, missCount);
+      }
+   }
+
+   private static abstract class Operation<K, V> {
+      protected final AbstractDelegatingStore store;
+      protected final String name;
+
+      public Operation(AbstractDelegatingStore store, String name) {
+         this.store = store;
+         this.name = name;
+      }
+
+      /**
+       * @return Return true for a hit, false for a miss.
+       */
+      public abstract boolean call(K key, long run);
+
+      public String getName() {
+         return name;
+      }
+   }
+
+   private static class TotalStats {
+      private ConcurrentHashMap<String, OpStats> statsMap = new ConcurrentHashMap<String, OpStats>();
+
+      public void addStats(String opName, long opCount, long runningTime, long missCount) {
+         OpStats s = new OpStats(opName, opCount, runningTime, missCount);
+         OpStats old = statsMap.putIfAbsent(opName, s);
+         boolean replaced = old == null;
+         while (!replaced) {
+            old = statsMap.get(opName);
+            s = new OpStats(old, opCount, runningTime, missCount);
+            replaced = statsMap.replace(opName, old, s);
+         }
+      }
+
+      public double getOpsPerSec(String opName) {
+         OpStats s = statsMap.get(opName);
+         if (s == null) return 0;
+         return s.opCount * 1000. / s.runningTime * s.threadCount;
+      }
+
+      public double getTotalOpsPerSec() {
+         long totalOpCount = 0;
+         long totalRunningTime = 0;
+         long totalThreadCount = 0;
+         for (Map.Entry<String, OpStats> e : statsMap.entrySet()) {
+            OpStats s = e.getValue();
+            totalOpCount += s.opCount;
+            totalRunningTime += s.runningTime;
+            totalThreadCount += s.threadCount;
+         }
+         return totalOpCount * 1000. / totalRunningTime * totalThreadCount;
+      }
+
+      public double getHitRatio(String opName) {
+         OpStats s = statsMap.get(opName);
+         if (s == null) return 0;
+         return 1 - 1. * s.missCount / s.opCount;
+      }
+
+      public double getTotalHitRatio() {
+         long totalOpCount = 0;
+         long totalMissCount = 0;
+         for (Map.Entry<String, OpStats> e : statsMap.entrySet()) {
+            OpStats s = e.getValue();
+            totalOpCount += s.opCount;
+            totalMissCount += s.missCount;
+         }
+         return 1 - 1. * totalMissCount / totalOpCount;
+      }
+   }
+
+   private static class OpStats {
+      public final String opName;
+      public final int threadCount;
+      public final long opCount;
+      public final long runningTime;
+      public final long missCount;
+
+      private OpStats(String opName, long opCount, long runningTime, long missCount) {
+         this.opName = opName;
+         this.threadCount = 1;
+         this.opCount = opCount;
+         this.runningTime = runningTime;
+         this.missCount = missCount;
+      }
+
+      private OpStats(OpStats base, long opCount, long runningTime, long missCount) {
+         this.opName = base.opName;
+         this.threadCount = base.threadCount + 1;
+         this.opCount = base.opCount + opCount;
+         this.runningTime = base.runningTime + runningTime;
+         this.missCount = base.missCount + missCount;
+      }
+   }
+
+   @Test(enabled = false) // Disable explicitly to avoid TestNG thinking this is a test!!
+   public static void main(String[] args) throws Exception {
+      AsyncStoreStressTest test = new AsyncStoreStressTest();
+      test.testReadWriteRemove(100000, 300000, 90, 9, 1);
+      test.testReadWriteRemove(10000, 30000, 9, 1, 0);
+      System.exit(0);
+   }
+
+}",2012-10-03T12:24:38Z,39
"@@ -443,18 +443,20 @@ public void addStats(String opName, long opCount, long runningTime, long missCou
       public double getOpsPerSec(String opName) {
          OpStats s = statsMap.get(opName);
          if (s == null) return 0;
-         return s.opCount * 1000. / s.runningTime;
+         return s.opCount * 1000. / s.runningTime * s.threadCount;
       }
 
       public double getTotalOpsPerSec() {
          long totalOpCount = 0;
          long totalRunningTime = 0;
+         long totalThreadCount = 0;
          for (Map.Entry<String, OpStats> e : statsMap.entrySet()) {
             OpStats s = e.getValue();
             totalOpCount += s.opCount;
-            totalRunningTime = s.runningTime;
+            totalRunningTime += s.runningTime;
+            totalThreadCount += s.threadCount;
          }
-         return totalOpCount * 1000. / totalRunningTime;
+         return totalOpCount * 1000. / totalRunningTime * totalThreadCount;
       }
 
       public double getHitRatio(String opName) {",2012-10-03T12:24:38Z,40
"@@ -0,0 +1,123 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.util;
+
+import org.testng.annotations.Test;
+
+import java.util.HashSet;
+import java.util.Set;
+
+import static org.testng.AssertJUnit.assertEquals;
+import static org.testng.AssertJUnit.assertTrue;
+
+/**
+ * // TODO: Document this
+ *
+ * @author Galder Zamarreño
+ * @since // TODO
+ */
+@Test(testName = ""util.InfinispanCollectionsTest"")
+public class InfinispanCollectionsTest {
+
+   public void testDifferenceNotStored() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+      expected.add(""d"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(1, notStored.size());
+      assertTrue(notStored.contains(""d""));
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(0, notRemoved.size());
+   }
+
+   public void testDifferenceNotRemoved() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+      store.add(""d"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(0, notStored.size());
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(1, notRemoved.size());
+      assertTrue(notRemoved.contains(""d""));
+   }
+
+   public void testDifferenceNotStoreAndNotRemoved() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+      store.add(""d"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+      expected.add(""e"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(1, notStored.size());
+      assertTrue(notStored.contains(""e""));
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(1, notRemoved.size());
+      assertTrue(notRemoved.contains(""d""));
+   }
+
+   public void testNoDifference() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(0, notStored.size());
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(0, notRemoved.size());
+   }
+
+}",2012-10-03T12:24:38Z,31
"@@ -122,10 +122,15 @@ public S purgeSynchronously(boolean b) {
    public void validate() {
       async.validate();
       singletonStore.validate();
+      ConfigurationBuilder builder = getBuilder();
       if (!loaders().shared() && !fetchPersistentState && !purgeOnStartup
-            && getBuilder().clustering().cacheMode().isClustered())
+            && builder.clustering().cacheMode().isClustered())
          log.staleEntriesWithoutFetchPersistentStateOrPurgeOnStartup();
-   }
 
+      if (loaders().shared() && !loaders().preload()
+            && builder.indexing().enabled()
+            && builder.indexing().indexLocalOnly())
+         log.localIndexingWithSharedCacheLoaderRequiresPreload();
+   }
 
 }",2012-08-30T15:45:20Z,41
"@@ -62,6 +62,10 @@ public IndexingConfigurationBuilder enabled(boolean enabled) {
       return this;
    }
 
+   boolean enabled() {
+      return enabled;
+   }
+
    /**
     * If true, only index changes made locally, ignoring remote changes. This is useful if indexes
     * are shared across a cluster to prevent redundant indexing of updates.
@@ -71,6 +75,10 @@ public IndexingConfigurationBuilder indexLocalOnly(boolean b) {
       return this;
    }
 
+   boolean indexLocalOnly() {
+      return indexLocalOnly;
+   }
+
    /**
     * <p>
     * Defines a single property. Can be used multiple times to define all needed properties, but the",2012-08-30T15:45:20Z,42
"@@ -49,4 +49,4 @@ public interface LoaderConfigurationBuilder<T extends LoaderConfiguration, S ext
     */
    S withProperties(Properties p);
 
-}
\ No newline at end of file
+}",2012-08-30T15:45:20Z,43
"@@ -72,6 +72,10 @@ public LoadersConfigurationBuilder preload(boolean b) {
       return this;
    }
 
+   boolean preload() {
+      return preload;
+   }
+
    /**
     * This setting should be set to true when multiple cache instances share the same cache store
     * (e.g., multiple nodes in a cluster using a JDBC-based CacheStore pointing to the same, shared
@@ -173,7 +177,7 @@ public LegacyStoreConfigurationBuilder addStore() {
    /**
     * Adds a cache store which uses the specified builder instance to build its configuration
     *
-    * @param klass an instance of {@link StoreConfigurationBuilder}
+    * @param builder an instance of {@link StoreConfigurationBuilder}
     */
    public LoaderConfigurationBuilder<?, ?> addStore(StoreConfigurationBuilder<?, ?> builder) {
       this.cacheLoaders.add(builder);",2012-08-30T15:45:20Z,44
"@@ -31,7 +31,10 @@
 import static org.infinispan.context.Flag.IGNORE_RETURN_VALUES;
 import static org.infinispan.factories.KnownComponentNames.CACHE_MARSHALLER;
 
+import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collections;
+import java.util.List;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
@@ -47,6 +50,7 @@
 import org.infinispan.configuration.cache.LoadersConfiguration;
 import org.infinispan.configuration.cache.StoreConfiguration;
 import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.annotations.ComponentName;
@@ -189,18 +193,24 @@ public void preload() {
                throw new CacheException(""Unable to preload!"", e);
             }
 
-            for (InternalCacheEntry e : state) {
-               if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
-                  cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, SKIP_CACHE_STORE, IGNORE_RETURN_VALUES, SKIP_INDEXING)
-                       .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
-               } else {
-                  cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES, SKIP_INDEXING)
-                       .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
-               }
+            List<Flag> flags = new ArrayList(Arrays.asList(
+                  CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES));
+
+            if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
+               flags.add(SKIP_CACHE_STORE);
+               if (!localIndexingEnabled())
+                  flags.add(SKIP_INDEXING);
+            } else {
+               flags.add(SKIP_INDEXING);
             }
 
+            AdvancedCache<Object, Object> flaggedCache = cache.getAdvancedCache()
+                  .withFlags(flags.toArray(new Flag[]{}));
+
+            for (InternalCacheEntry e : state)
+               flaggedCache.put(e.getKey(), e.getValue(),
+                     e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
+
             if (debugTiming) {
                final long stop = System.nanoTime();
                log.debugf(""Preloaded %s keys in %s"", state.size(), Util.prettyPrintTime(stop - start, TimeUnit.NANOSECONDS));
@@ -209,6 +219,10 @@ public void preload() {
       }
    }
 
+   private boolean localIndexingEnabled() {
+      return configuration.indexing().enabled() && configuration.indexing().indexLocalOnly();
+   }
+
    private Set<InternalCacheEntry> loadState() throws CacheLoaderException {
       int ne = -1;
       if (configuration.eviction().strategy().isEnabled()) ne = configuration.eviction().maxEntries();",2012-08-30T15:45:20Z,29
"@@ -863,6 +863,11 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    void componentFailedToStop(@Cause Throwable e);
 
    @LogMessage(level = WARN)
-   @Message(value = ""Use of the 'loader' element to configure a store is deprecated, please use the 'store' element instead"")
+   @Message(value = ""Use of the 'loader' element to configure a store is deprecated, please use the 'store' element instead"", id = 190)
    void deprecatedLoaderAsStoreConfiguration();
+
+   @LogMessage(level = DEBUG)
+   @Message(value = ""When indexing locally a cache with shared cache loader, preload must be enabled"", id = 191)
+   void localIndexingWithSharedCacheLoaderRequiresPreload();
+
 }",2012-08-30T15:45:20Z,45
"@@ -29,7 +29,6 @@
 import org.infinispan.test.TestingUtil;
 import org.testng.annotations.Test;
 
-import java.util.LinkedList;
 import java.util.List;
 
 @Test (testName = ""loaders.SharedCacheStoreTest"", groups = ""functional"")
@@ -50,13 +49,6 @@ protected void createCacheManagers() throws Throwable {
       // don't create the caches here, we want them to join the cluster one by one
    }
 
-   private List<CacheStore> cachestores() {
-      List<CacheStore> l = new LinkedList<CacheStore>();
-      for (Cache<?, ?> c: caches())
-         l.add(TestingUtil.extractComponent(c, CacheLoaderManager.class).getCacheStore());
-      return l;
-   }
-
    public void testUnnecessaryWrites() throws CacheLoaderException {
       cache(0).put(""key"", ""value"");
 
@@ -66,7 +58,8 @@ public void testUnnecessaryWrites() throws CacheLoaderException {
       for (Cache<Object, Object> c: caches())
          assert ""value"".equals(c.get(""key""));
 
-      for (CacheStore cs: cachestores()) {
+      List<CacheStore> cachestores = TestingUtil.cachestores(caches());
+      for (CacheStore cs: cachestores) {
          assert cs.containsKey(""key"");
          DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
          assert dimcs.stats().get(""clear"") == 0: ""Cache store should not be cleared, purgeOnStartup is false"";
@@ -78,7 +71,7 @@ public void testUnnecessaryWrites() throws CacheLoaderException {
       for (Cache<Object, Object> c: caches())
          assert c.get(""key"") == null;
 
-      for (CacheStore cs: cachestores()) {
+      for (CacheStore cs: cachestores) {
          assert !cs.containsKey(""key"");
          DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
          assert dimcs.stats().get(""remove"") == 1: ""Entry should have been removed from the cache store just once, but was removed "" + dimcs.stats().get(""store"") + "" times"";",2012-08-30T15:45:20Z,46
"@@ -0,0 +1,73 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.TestingUtil;
+
+import java.util.concurrent.Callable;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+
+/**
+ * Represents a joining node, designed for state transfer related tests.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public class JoiningNode {
+
+   private final EmbeddedCacheManager cm;
+   private final CountDownLatch latch;
+   private final MergeOrViewChangeListener listener;
+
+   public JoiningNode(EmbeddedCacheManager cm) {
+      this.cm = cm;
+      latch = new CountDownLatch(1);
+      listener = new MergeOrViewChangeListener(latch);
+      cm.addListener(listener);
+   }
+
+   public Cache getCache() {
+      return cm.getCache();
+   }
+
+   public Cache getCache(String cacheName) {
+      return cm.getCache(cacheName);
+   }
+
+   public void waitForJoin(long timeout, Cache... caches) throws InterruptedException {
+      // Wait for either a merge or view change to happen
+      latch.await(timeout, TimeUnit.MILLISECONDS);
+      // Wait for the state transfer to end
+      TestingUtil.waitForRehashToComplete(caches);
+   }
+
+   private boolean isStateTransferred() {
+      return !listener.merged;
+   }
+
+   void verifyStateTransfer(Callable<Void> verify) throws Exception {
+      if (isStateTransferred())
+         verify.call();
+   }
+
+}",2012-08-30T15:45:20Z,47
"@@ -0,0 +1,72 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.statetransfer;
+
+import org.infinispan.notifications.Listener;
+import org.infinispan.notifications.cachemanagerlistener.annotation.Merged;
+import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
+import org.infinispan.notifications.cachemanagerlistener.event.MergeEvent;
+import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+import java.util.concurrent.CountDownLatch;
+
+/**
+ * Listener implementation that detects whether a merge or
+ * a view change occurred.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Listener
+public class MergeOrViewChangeListener {
+
+   private static final Log log = LogFactory.getLog(MergeOrViewChangeListener.class);
+
+   // The latch provides the visibility guarantees
+   public boolean merged;
+
+   // The latch provides the visibility guarantees
+   public boolean viewChanged;
+
+   private final CountDownLatch latch;
+
+   public MergeOrViewChangeListener(CountDownLatch latch) {
+      this.latch = latch;
+   }
+
+   @Merged
+   @SuppressWarnings(""unused"")
+   public void mergedView(MergeEvent me) {
+      log.infof(""View merged received %s"", me);
+      merged = true;
+      latch.countDown();
+   }
+
+   @ViewChanged
+   @SuppressWarnings(""unused"")
+   public void viewChanged(ViewChangedEvent e) {
+      log.infof(""View change received %s"", e);
+      viewChanged = true;
+      latch.countDown();
+   }
+
+}",2012-08-30T15:45:20Z,48
"@@ -25,11 +25,6 @@
 import org.infinispan.Cache;
 import org.infinispan.config.Configuration;
 import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.notifications.Listener;
-import org.infinispan.notifications.cachemanagerlistener.annotation.Merged;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.MergeEvent;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
@@ -46,8 +41,7 @@
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.lang.reflect.Method;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.TimeUnit;
+import java.util.concurrent.Callable;
 
 @Test(groups = ""functional"", testName = ""statetransfer.StateTransferFunctionalTest"", enabled = true)
 public class StateTransferFunctionalTest extends MultipleCacheManagersTest {
@@ -183,10 +177,10 @@ public void testInitialStateTransfer(Method m) throws Exception {
       cache1 = cm1.getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node = new JoiningNode();
+      JoiningNode node = new JoiningNode(createCacheManager());
       cache2 = node.getCache(cacheName);
       node.waitForJoin(60000, cache1, cache2);
-      node.verifyStateTransfer(cache2);
+      node.verifyStateTransfer(new CacheVerifier(cache2));
 
       logTestEnd(m);
    }
@@ -199,10 +193,10 @@ public void testInitialStateTransferCacheNotPresent(Method m) throws Exception {
       cache1 = cacheManager1.getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node = new JoiningNode();
+      JoiningNode node = new JoiningNode(createCacheManager());
       cache2 = node.getCache(cacheName);
       node.waitForJoin(60000, cache1, cache2);
-      node.verifyStateTransfer(cache2);
+      node.verifyStateTransfer(new CacheVerifier(cache2));
 
       cacheManager1.defineConfiguration(""otherCache"", config.clone());
       cacheManager1.getCache(""otherCache"");
@@ -216,16 +210,16 @@ public void testConcurrentStateTransfer(Method m) throws Exception {
       cache1 = createCacheManager().getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
 
       cache1.put(""delay"", new StateTransferFunctionalTest.DelayTransfer());
 
       node2.waitForJoin(60000, cache1, cache2);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
-      final JoiningNode node3 = new JoiningNode();
-      final JoiningNode node4 = new JoiningNode();
+      final JoiningNode node3 = new JoiningNode(createCacheManager());
+      final JoiningNode node4 = new JoiningNode(createCacheManager());
 
       Thread t1 = new Thread(new Runnable() {
          public void run() {
@@ -252,8 +246,8 @@ public void run() {
       node3.waitForJoin(120000, cache1, cache2, cache3, cache4);
       node4.waitForJoin(120000, cache1, cache2, cache3, cache4);
 
-      node3.verifyStateTransfer(cache3);
-      node4.verifyStateTransfer(cache4);
+      node3.verifyStateTransfer(new CacheVerifier(cache3));
+      node4.verifyStateTransfer(new CacheVerifier(cache4));
 
       logTestEnd(m);
    }
@@ -300,10 +294,10 @@ public void testInitialStateTransferAfterRestart(Method m) throws Exception {
       cache1 = createCacheManager().getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
       node2.waitForJoin(60000, cache1, cache2);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       cache2.stop();
       cache2.start();
@@ -324,7 +318,7 @@ private void logTestLifecycle(Method m, String lifecycle) {
       log.infof(""%s %s - %s"", m.getName(), lifecycle, testCount);
    }
 
-   private void thirdWritingCacheTest(boolean tx) throws InterruptedException {
+   private void thirdWritingCacheTest(boolean tx) throws Exception {
       Cache<Object, Object> cache1, cache2, cache3;
       cache1 = createCacheManager().getCache(cacheName);
       cache3 = createCacheManager().getCache(cacheName);
@@ -340,15 +334,15 @@ private void thirdWritingCacheTest(boolean tx) throws InterruptedException {
       WritingThread writerThread = new WritingThread(cache3, tx);
       writerThread.start();
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
 
       node2.waitForJoin(60000, cache1, cache2, cache3);
 
       writerThread.stopThread();
       writerThread.join();
 
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       int count = writerThread.result();
 
@@ -374,7 +368,7 @@ protected void writeInitialData(final Cache<Object, Object> c) {
       c.put(A_C_AGE, FORTY);
    }
 
-   private void writingThreadTest(boolean tx) throws InterruptedException {
+   private void writingThreadTest(boolean tx) throws Exception {
       Cache<Object, Object> cache1, cache2;
       cache1 = createCacheManager().getCache(cacheName);
 
@@ -388,81 +382,34 @@ private void writingThreadTest(boolean tx) throws InterruptedException {
       writerThread.start();
       verifyInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
       node2.waitForJoin(60000, cache1, cache2);
 
       writerThread.stopThread();
       writerThread.join();
 
       verifyInitialData(cache1);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       int count = writerThread.result();
 
       for (int c = 0; c < count; c++)
          assert new Integer(c).equals(cache2.get(""test"" + c)) : ""Entry under key [test"" + c + ""] was ["" + cache2.get(""test"" + c) + ""] but expected ["" + c + ""]"";
    }
 
-   @Listener
-   public static class MergeOrViewChangeListener {
-      // The latch provides the visibility guarantees
-      public boolean merged;
-      // The latch provides the visibility guarantees
-      public boolean viewChanged;
-      private final CountDownLatch latch;
+   public class CacheVerifier implements Callable<Void> {
 
-      public MergeOrViewChangeListener(CountDownLatch latch) {
-         this.latch = latch;
-      }
-
-      @Merged
-      public void mergedView(MergeEvent me) {
-         log.infof(""View merged received %s"", me);
-         merged = true;
-         latch.countDown();
-      }
-
-      @ViewChanged
-      public void viewChanged(ViewChangedEvent e) {
-         log.infof(""View change received %s"", e);
-         viewChanged = true;
-         latch.countDown();
-      }
-
-   }
-
-   private class JoiningNode {
-
-      private final EmbeddedCacheManager cm;
-      private final CountDownLatch latch;
-      private final MergeOrViewChangeListener listener;
-
-      private JoiningNode() {
-         cm = createCacheManager();
-         latch = new CountDownLatch(1);
-         listener = new MergeOrViewChangeListener(latch);
-         cm.addListener(listener);
-      }
-
-      Cache getCache(String cacheName) {
-         return cm.getCache(cacheName);
-      }
-
-      void waitForJoin(long timeout, Cache... caches) throws InterruptedException {
-         // Wait for either a merge or view change to happen
-         latch.await(timeout, TimeUnit.MILLISECONDS);
-         // Wait for the state transfer to end
-         TestingUtil.waitForRehashToComplete(caches);
-      }
+      private final Cache<Object, Object> cache;
 
-      private boolean isStateTransferred() {
-         return !listener.merged;
+      public CacheVerifier(Cache<Object, Object> cache) {
+         this.cache = cache;
       }
 
-      void verifyStateTransfer(Cache cache) {
-         if (isStateTransferred())
-            StateTransferFunctionalTest.this.verifyInitialData(cache);
+      @Override
+      public Void call() throws Exception {
+         verifyInitialData(cache);
+         return null;
       }
 
    }",2012-08-30T15:45:20Z,49
"@@ -33,6 +33,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.LinkedList;
 import java.util.List;
 import java.util.Random;
 import java.util.Set;
@@ -62,6 +63,7 @@
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.loaders.CacheLoader;
 import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.loaders.CacheStore;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.AbstractDelegatingMarshaller;
@@ -754,6 +756,13 @@ public static void clearCacheLoader(Cache cache) {
       }
    }
 
+   public static <K, V> List<CacheStore> cachestores(List<Cache<K, V>> caches) {
+      List<CacheStore> l = new LinkedList<CacheStore>();
+      for (Cache<?, ?> c: caches)
+         l.add(TestingUtil.extractComponent(c, CacheLoaderManager.class).getCacheStore());
+      return l;
+   }
+
    private static void removeInMemoryData(Cache cache) {
       EmbeddedCacheManager mgr = cache.getCacheManager();
       Address a = mgr.getAddress();",2012-08-30T15:45:20Z,50
"@@ -0,0 +1,69 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.cacheloaders;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.query.statetransfer.BaseReIndexingTest;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.Test;
+
+/**
+ * Tests behaviour of indexing and querying when a cache is clustered and
+ * and it's configured with a shared cache store. If preload is enabled,
+ * it should be possible to index the preloaded contents.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.cacheloaders.SharedCacheLoaderQueryIndexTest"")
+public class SharedCacheLoaderQueryIndexTest extends BaseReIndexingTest {
+
+   protected void configureCache(ConfigurationBuilder builder) {
+      // To force a shared cache store, make sure storeName property
+      // for dummy store is the same for all nodes
+      builder.clustering().stateTransfer().fetchInMemoryState(false)
+         .loaders().shared(true).preload(true).addStore()
+            .cacheStore(new DummyInMemoryCacheStore()).addProperty(""storeName"",
+            SharedCacheLoaderQueryIndexTest.class.getName());
+   }
+
+   public void testPreloadIndexingAfterAddingNewNode() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      for (CacheStore cs: TestingUtil.cachestores(this.<String, Person>caches())) {
+         assert cs.containsKey(persons[0].getName()) :
+               ""Cache misconfigured, maybe cache store not pointing to same place, maybe passivation on...etc"";
+         DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
+         assert dimcs.stats().get(""clear"") == 0:
+               ""Cache store should not be cleared, purgeOnStartup is false"";
+         assert dimcs.stats().get(""store"") == 4:
+               ""Cache store should have been written to just once, but was written to "" + dimcs.stats().get(""store"") + "" times"";
+      }
+
+      // Before adding a node, verify that the query resolves properly
+      executeSimpleQuery(this.<String, Person>caches().get(0));
+
+      addNodeCheckingContentsAndQuery();
+   }
+
+}",2012-08-30T15:45:20Z,7
"@@ -0,0 +1,138 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.apache.lucene.queryParser.ParseException;
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.query.CacheQuery;
+import org.infinispan.query.test.Person;
+import org.infinispan.statetransfer.JoiningNode;
+import org.infinispan.test.CacheManagerCallable;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.fwk.TransportFlags;
+
+import java.util.List;
+
+import static org.infinispan.query.helper.TestQueryHelperFactory.createCacheQuery;
+import static org.infinispan.test.TestingUtil.withCacheManager;
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Base class for state transfer and query related tests
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public abstract class BaseReIndexingTest extends MultipleCacheManagersTest {
+
+   protected Person[] persons;
+   protected ConfigurationBuilder builder;
+
+   abstract protected void configureCache(ConfigurationBuilder builder);
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      builder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, false);
+
+      // Explicitly disable fetching in-memory state in order
+      // to fetch it from the persistence layer
+      builder.indexing().enable().indexLocalOnly(true)
+            .addProperty(""hibernate.search.default.directory_provider"", ""ram"")
+            .addProperty(""hibernate.search.lucene_version"", ""LUCENE_CURRENT"");
+
+      configureCache(builder);
+
+      createClusteredCaches(2, builder);
+   }
+
+   private EmbeddedCacheManager createCacheManager() {
+      return addClusterEnabledCacheManager(
+            builder, new TransportFlags().withMerge(true));
+   }
+
+   protected void executeSimpleQuery(Cache<String, Person> cache) throws ParseException {
+      CacheQuery cacheQuery = createCacheQuery(cache, ""blurb"", ""playing"");
+      List<Object> found = cacheQuery.list();
+      int elems = found.size();
+      assertEquals(1, elems);
+      Object val = found.get(0);
+      Person expectedPerson = persons[0];
+      assertEquals(expectedPerson, val);
+   }
+
+   protected void loadCacheEntries(Cache<String, Person> cache) {
+      Person person1 = new Person();
+      person1.setName(""NavinSurtani"");
+      person1.setBlurb(""Likes playing WoW"");
+      person1.setAge(45);
+
+      Person person2 = new Person();
+      person2.setName(""BigGoat"");
+      person2.setBlurb(""Eats grass"");
+      person2.setAge(30);
+
+      Person person3 = new Person();
+      person3.setName(""MiniGoat"");
+      person3.setBlurb(""Eats cheese"");
+      person3.setAge(35);
+
+      Person person4 = new Person();
+      person4.setName(""MightyGoat"");
+      person4.setBlurb(""Also eats grass"");
+      person4.setAge(66);
+
+      persons = new Person[]{person1, person2, person3, person4};
+
+      // Put the 3 created objects in the cache
+      cache.put(person1.getName(), person1);
+      cache.put(person2.getName(), person2);
+      cache.put(person3.getName(), person3);
+      cache.put(person4.getName(), person4);
+   }
+
+   protected void addNodeCheckingContentsAndQuery() {
+      withCacheManager(new CacheManagerCallable(createCacheManager()) {
+         @Override
+         public void call() {
+            try {
+               // New node joining
+               JoiningNode newNode = new JoiningNode(cm);
+               Cache<String, Person> newCache = newNode.getCache();
+               newNode.waitForJoin(120000, caches().get(0), caches().get(1), newCache);
+
+               // Verify state transfer
+               int size = newCache.size();
+               assertEquals(4, size);
+               for (int i = 0; i < size; i++)
+                  assertEquals(persons[i], newCache.get(persons[i].getName()));
+
+               // Repeat query on new node
+               executeSimpleQuery(newCache);
+            } catch (Exception e) {
+               throw new RuntimeException(e);
+            }
+         }
+      });
+   }
+
+}",2012-08-30T15:45:20Z,51
"@@ -0,0 +1,94 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.Test;
+
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Test that verifies that querying works even after multiple nodes have
+ * started with unshared, passivated, cache stores, and a new node comes in
+ * to fetch the persistent state from the other nodes.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.PersistentStateTransferQueryIndexTest"")
+public class PersistentStateTransferQueryIndexTest extends BaseReIndexingTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      builder.clustering().stateTransfer().fetchInMemoryState(false)
+            .loaders().passivation(true).shared(false).addStore()
+            .cacheStore(new DummyInMemoryCacheStore())
+                  .fetchPersistentState(true);
+   }
+
+   public void testFetchingPersistentStateUpdatesIndex() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      // Before adding a node, verify that the query resolves properly
+      Cache<String, Person> cache1 = this.<String, Person>caches().get(0);
+      executeSimpleQuery(cache1);
+
+      // Since passivation is enabled, cache stores should still be empty
+      checkCacheStoresEmpty();
+
+      // Evict manually entries from both nodes
+      for (Cache<Object, Object> cache : caches()) {
+         for (Person p2 : persons) {
+            cache.evict(p2.getName());
+         }
+      }
+
+      // After eviction, cache stores should be loaded with instances
+      checkCacheStoresContainPersons();
+
+      // Finally add a node and verify that state transfer happens and query works
+      addNodeCheckingContentsAndQuery();
+   }
+
+   private void checkCacheStoresContainPersons() throws CacheLoaderException {
+      for (Cache<Object, Object> cache : caches()) {
+         CacheStore store = TestingUtil.extractComponent(cache, CacheLoaderManager.class).getCacheStore();
+         for (int i = 0; i < persons.length; i++)
+            assertEquals(persons[i], store.load(persons[i].getName()).getValue());
+      }
+   }
+
+   private void checkCacheStoresEmpty() throws CacheLoaderException {
+      for (Cache<Object, Object> cache : caches()) {
+         CacheStore store = TestingUtil.extractComponent(cache, CacheLoaderManager.class).getCacheStore();
+         for (Person person : persons) {
+            assert !store.containsKey(person.getName());
+         }
+      }
+   }
+
+}",2012-08-30T15:45:20Z,52
"@@ -0,0 +1,50 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.query.test.Person;
+import org.testng.annotations.Test;
+
+/**
+ * Test that verifies that querying works even after a new node is added and
+ * state transfer has provided it with the data belonging to that node.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.StateTransferQueryIndexTest"")
+public class StateTransferQueryIndexTest extends BaseReIndexingTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      builder.clustering().stateTransfer().fetchInMemoryState(true);
+   }
+
+   public void testQueryAfterAddingNewNode() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      // Before adding a node, verify that the query resolves properly
+      executeSimpleQuery(this.<String, Person>caches().get(0));
+
+      addNodeCheckingContentsAndQuery();
+   }
+
+}",2012-08-30T15:45:20Z,53
"@@ -341,13 +341,13 @@ private void addTransfers(Set<Integer> segments) {
       log.debugf(""Adding state transfer for segments: %s"", segments);
 
       Set<Integer> segmentsToProcess = new HashSet<Integer>(segments);
-      Set<Address> faultyMembers = new HashSet<Address>();
+      Set<Address> blacklistedSources = new HashSet<Address>();
 
       // ignore all segments for which there are no other owners to pull data from.
       // these segments are considered empty (or lost) and do not require a state transfer
       for (Iterator<Integer> it = segmentsToProcess.iterator(); it.hasNext(); ) {
          Integer segmentId = it.next();
-         Address source = pickSourceOwner(segmentId, faultyMembers);
+         Address source = pickSourceOwner(segmentId, blacklistedSources);
          if (source == null) {
             it.remove();
          }
@@ -364,24 +364,22 @@ private void addTransfers(Set<Integer> segments) {
                   throw new IllegalStateException(""Cannot have more than one transfer for segment "" + segmentId);
                }
 
-               Address source = pickSourceOwner(segmentId, faultyMembers);
-               if (source == null) {
-                  log.errorf(""No owners found for segment %d"", segmentId);
-               } else {
-                  Set<Integer> segs = segmentsBySource.get(source);
-                  if (segs == null) {
-                     segs = new HashSet<Integer>();
-                     segmentsBySource.put(source, segs);
+               Address source = pickSourceOwner(segmentId, blacklistedSources);
+               if (source != null) {
+                  Set<Integer> segmentsFromSource = segmentsBySource.get(source);
+                  if (segmentsFromSource == null) {
+                     segmentsFromSource = new HashSet<Integer>();
+                     segmentsBySource.put(source, segmentsFromSource);
                   }
-                  segs.add(segmentId);
+                  segmentsFromSource.add(segmentId);
                }
             }
 
             Set<Integer> failedSegments = new HashSet<Integer>();
             for (Address source : segmentsBySource.keySet()) {
-               Set<Integer> segs = segmentsBySource.get(source);
-               InboundTransferTask inboundTransfer = new InboundTransferTask(segs, source, topologyId, this, rpcManager, commandsFactory, timeout);
-               for (int segmentId : segs) {
+               Set<Integer> segmentsFromSource = segmentsBySource.get(source);
+               InboundTransferTask inboundTransfer = new InboundTransferTask(segmentsFromSource, source, topologyId, this, rpcManager, commandsFactory, timeout);
+               for (int segmentId : segmentsFromSource) {
                   transfersBySegment.put(segmentId, inboundTransfer);
                }
                List<InboundTransferTask> inboundTransfers = transfersBySource.get(inboundTransfer.getSource());
@@ -394,12 +392,14 @@ private void addTransfers(Set<Integer> segments) {
                // if requesting the transactions fails we need to retry from another source
                if (inboundTransfer.requestTransactions()) {
                   if (!inboundTransfer.requestSegments()) {
-                     log.errorf(""Failed to request segments %s from %s"", segs, source);
+                     log.errorf(""Failed to request segments %s from %s"", segmentsFromSource, source);
+                     //todo [anistor] maybe I need to remove this transfer to be retried from another source
                   }
                } else {
-                  log.errorf(""Failed to retrieve transactions for segments %s from %s"", segs, source);
-                  failedSegments.addAll(segs);
-                  faultyMembers.add(source);
+                  log.errorf(""Failed to retrieve transactions for segments %s from %s"", segmentsFromSource, source);
+                  log.tracef(""Adding members %s to black list"", source);
+                  failedSegments.addAll(segmentsFromSource);
+                  blacklistedSources.add(source);
                   removeTransfer(inboundTransfer);
                }
             }
@@ -409,14 +409,15 @@ private void addTransfers(Set<Integer> segments) {
       }
    }
 
-   private Address pickSourceOwner(int segmentId, Set<Address> faultyMembers) {
+   private Address pickSourceOwner(int segmentId, Set<Address> blacklistedSources) {
       List<Address> owners = readCh.locateOwnersForSegment(segmentId);
       for (int i = owners.size() - 1; i >= 0; i--) {
          Address o = owners.get(i);
-         if (!faultyMembers.contains(o) && !o.equals(rpcManager.getAddress())) {
+         if (!blacklistedSources.contains(o) && !o.equals(rpcManager.getAddress())) {
             return o;
          }
       }
+      log.errorf(""No live owners found for segment %d. Current owners are %s"", segmentId, owners);
       return null;
    }
 ",2012-08-31T21:05:27Z,54
"@@ -62,6 +62,7 @@ public class StateProviderImpl implements StateProvider {
    private final long timeout;
    private final int chunkSize;
 
+   private int topolopyId;
    private ConsistentHash readCh;
 
    /**
@@ -104,6 +105,7 @@ public boolean isStateTransferInProgress() {
 
    public void onTopologyUpdate(int topologyId, ConsistentHash readCh, ConsistentHash writeCh) {
       this.readCh = readCh;
+      this.topolopyId = topologyId;
 
       // cancel outbound state transfers for destinations that are no longer members in new topology
       Set<Address> members = new HashSet<Address>(writeCh.getMembers());
@@ -198,23 +200,26 @@ public void startOutboundTransfer(Address destination, int topologyId, Set<Integ
       if (trace) {
          log.tracef(""Starting outbound transfer of segments %s to %s"", segments, destination);
       }
+      if (topologyId != this.topolopyId) {
+         log.warnf(""Received topology id (%d) is different that expected (%d)"", topologyId, this.topolopyId);
+      }
       // the destination node must already have an InboundTransferTask waiting for these segments
       OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId, readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);
    }
 
-   private void addTransfer(OutboundTransferTask outboundTransfer) {
+   private void addTransfer(OutboundTransferTask transferTask) {
       if (trace) {
-         log.tracef(""Adding outbound transfer of segments %s to %s"", outboundTransfer.getSegments(), outboundTransfer.getDestination());
+         log.tracef(""Adding outbound transfer of segments %s to %s"", transferTask.getSegments(), transferTask.getDestination());
       }
       synchronized (transfersByDestination) {
-         List<OutboundTransferTask> transfers = transfersByDestination.get(outboundTransfer.getDestination());
+         List<OutboundTransferTask> transfers = transfersByDestination.get(transferTask.getDestination());
          if (transfers == null) {
             transfers = new ArrayList<OutboundTransferTask>();
-            transfersByDestination.put(outboundTransfer.getDestination(), transfers);
+            transfersByDestination.put(transferTask.getDestination(), transfers);
          }
-         transfers.add(outboundTransfer);
+         transfers.add(transferTask);
       }
    }
 
@@ -235,9 +240,6 @@ public void cancelOutboundTransfer(Address destination, int topologyId, Set<Inte
    }
 
    private void removeTransfer(OutboundTransferTask transferTask) {
-      if (trace) {
-         log.tracef(""Removing outbound transfer of segments %s to %s"", transferTask.getSegments(), transferTask.getDestination());
-      }
       synchronized (transfersByDestination) {
          List<OutboundTransferTask> transferTasks = transfersByDestination.get(transferTask.getDestination());
          if (transferTasks != null) {
@@ -249,10 +251,11 @@ private void removeTransfer(OutboundTransferTask transferTask) {
       }
    }
 
-   void onTaskCompletion(OutboundTransferTask outboundTransferTask) {
+   void onTaskCompletion(OutboundTransferTask transferTask) {
       if (trace) {
-         log.tracef(""Outbound transfer of segments %s to %s is complete"", outboundTransferTask.getSegments(), outboundTransferTask.getDestination());
+         log.tracef(""Removing %s outbound transfer of segments %s to %s"", transferTask.isCancelled() ? ""cancelled"" : ""completed"", transferTask.getSegments(), transferTask.getDestination());
       }
-      removeTransfer(outboundTransferTask);
+
+      removeTransfer(transferTask);
    }
 }",2012-08-31T21:05:27Z,55
"@@ -106,7 +106,7 @@ public void test1() {
       // create dependencies
       StateTransferManager stateTransferManager = mock(StateTransferManager.class);
       CacheNotifier cacheNotifier = mock(CacheNotifier.class);
-      ExecutorService executorService2 = mock(ExecutorService.class);
+      ExecutorService mockExecutorService = mock(ExecutorService.class);
       RpcManager rpcManager = mock(RpcManager.class);
       CommandsFactory commandsFactory = mock(CommandsFactory.class);
       CacheLoaderManager cacheLoaderManager = mock(CacheLoaderManager.class);
@@ -116,7 +116,7 @@ public void test1() {
       InterceptorChain interceptorChain = mock(InterceptorChain.class);
       InvocationContextContainer icc = mock(InvocationContextContainer.class);
 
-      when(executorService2.submit(any(Runnable.class))).thenAnswer(new Answer<Future<?>>() {
+      when(mockExecutorService.submit(any(Runnable.class))).thenAnswer(new Answer<Future<?>>() {
          @Override
          public Future<?> answer(InvocationOnMock invocation) {
             return null;",2012-08-31T21:05:27Z,56
"@@ -24,6 +24,7 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.ReplicableCommand;
 import org.infinispan.commons.hash.MurmurHash3;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configuration;
@@ -35,12 +36,15 @@
 import org.infinispan.distribution.ch.DefaultConsistentHash;
 import org.infinispan.distribution.ch.DefaultConsistentHashFactory;
 import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.remoting.responses.Response;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.test.TestingUtil;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.util.concurrent.IsolationLevel;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.mockito.InOrder;
@@ -189,4 +193,109 @@ public Iterator<InternalCacheEntry> answer(InvocationOnMock invocation) {
 
       assertFalse(stateProvider.isStateTransferInProgress());
    }
+
+   public void test2() {
+      // create list of 6 members
+      List<Address> members1 = new ArrayList<Address>();
+      for (int i = 0; i < 6; i++) {
+         members1.add(new TestAddress(i));
+      }
+      List<Address> members2 = new ArrayList<Address>(members1);
+      members2.remove(new TestAddress(0));
+      members2.remove(new TestAddress(5));
+      members2.add(new TestAddress(6));
+
+      // create CHes
+      DefaultConsistentHashFactory chf = new DefaultConsistentHashFactory();
+      DefaultConsistentHash ch1 = chf.create(new MurmurHash3(), 2, 4, members1);
+      DefaultConsistentHash ch2 = chf.updateMembers(ch1, members2);   //todo [anistor] it seems that address 6 is not used for un-owned segments
+
+      when(commandsFactory.buildStateResponseCommand(any(Address.class), anyInt(), anyInt(), any(Collection.class), anyBoolean())).thenAnswer(new Answer<StateResponseCommand>() {
+         @Override
+         public StateResponseCommand answer(InvocationOnMock invocation) {
+            return new StateResponseCommand(""cache1"", (Address) invocation.getArguments()[0],
+                  ((Integer) invocation.getArguments()[1]).intValue(),
+                  ((Integer) invocation.getArguments()[2]).intValue(),
+                  (Collection<InternalCacheEntry>) invocation.getArguments()[3],
+                  ((Boolean)invocation.getArguments()[4]).booleanValue());
+         }
+      });
+
+      // create dependencies
+      when(rpcManager.getAddress()).thenReturn(new TestAddress(0));
+
+      //rpcManager.invokeRemotelyInFuture(Collections.singleton(destination), cmd, false, sendFuture, timeout);
+      doAnswer(new Answer<Map<Address, Response>>() {
+         @Override
+         public Map<Address, Response> answer(InvocationOnMock invocation) {
+            Collection<Address> recipients = (Collection<Address>) invocation.getArguments()[0];
+            ReplicableCommand rpcCommand = (ReplicableCommand) invocation.getArguments()[1];
+            if (rpcCommand instanceof StateResponseCommand) {
+               Map<Address, Response> results = new HashMap<Address, Response>();
+               TestingUtil.sleepThread(10000, ""RpcManager mock interrupted during invokeRemotelyInFuture(..)"");
+               return results;
+            }
+            return Collections.emptyMap();
+         }
+      }).when(rpcManager).invokeRemotelyInFuture(any(Collection.class), any(ReplicableCommand.class), anyBoolean(), any(NotifyingNotifiableFuture.class), anyLong());
+
+
+      // create state provider
+      StateProviderImpl stateProvider = new StateProviderImpl(""testCache"", pooledExecutorService,
+            configuration, rpcManager, commandsFactory, cacheLoaderManager,
+            dataContainer, transactionTable, stateTransferLock);
+
+      final List<InternalCacheEntry> cacheEntries = new ArrayList<InternalCacheEntry>();
+      Object key1 = new TestKey(""key1"", 0, ch1);
+      Object key2 = new TestKey(""key2"", 0, ch1);
+      Object key3 = new TestKey(""key3"", 1, ch1);
+      Object key4 = new TestKey(""key4"", 1, ch1);
+      cacheEntries.add(new ImmortalCacheEntry(key1, ""value1""));
+      cacheEntries.add(new ImmortalCacheEntry(key2, ""value2""));
+      cacheEntries.add(new ImmortalCacheEntry(key3, ""value3""));
+      cacheEntries.add(new ImmortalCacheEntry(key4, ""value4""));
+      when(dataContainer.iterator()).thenAnswer(new Answer<Iterator<InternalCacheEntry>>() {
+         @Override
+         public Iterator<InternalCacheEntry> answer(InvocationOnMock invocation) {
+            return cacheEntries.iterator();
+         }
+      });
+      when(transactionTable.getLocalTransactions()).thenReturn(Collections.<LocalTransaction>emptyList());
+      when(transactionTable.getRemoteTransactions()).thenReturn(Collections.<RemoteTransaction>emptyList());
+
+      stateProvider.onTopologyUpdate(1, ch1, ch1);
+
+      log.debug(""ch1: "" + ch1);
+      List<TransactionInfo> transactions = stateProvider.getTransactionsForSegments(members1.get(0), 1, new HashSet<Integer>(Arrays.asList(0, 3)));
+      assertEquals(0, transactions.size());
+
+      try {
+         stateProvider.getTransactionsForSegments(members1.get(0), 1, new HashSet<Integer>(Arrays.asList(2, 4)));
+         fail(""IllegalArgumentException expected"");
+      } catch (IllegalArgumentException e) {
+         // expected
+      }
+
+      InOrder stateTransferLockVerifier = inOrder(stateTransferLock);
+      stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveLock();
+      stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveUnlock();
+
+      stateProvider.startOutboundTransfer(new TestAddress(5), 1, Collections.singleton(0));
+
+      assertTrue(stateProvider.isStateTransferInProgress());
+
+     // TestingUtil.sleepThread(15000);
+      log.debug(""ch2: "" + ch2);
+      stateProvider.onTopologyUpdate(2, ch1, ch2);
+
+      assertFalse(stateProvider.isStateTransferInProgress());
+
+      stateProvider.startOutboundTransfer(new TestAddress(4), 1, Collections.singleton(0));
+
+      assertTrue(stateProvider.isStateTransferInProgress());
+
+      stateProvider.shutdown();
+
+      assertFalse(stateProvider.isStateTransferInProgress());
+   }
 }",2012-08-31T21:05:27Z,57
"@@ -49,6 +49,9 @@ final class TestKey implements Serializable {
    private final int hashCode;
 
    public TestKey(String name, int segmentId, ConsistentHash ch) {
+      if (segmentId < 0 || segmentId >= ch.getNumSegments()) {
+         throw new IllegalArgumentException(""segmentId is out of range"");
+      }
       this.name = name;
 
       Random rnd = new Random();",2012-08-31T21:05:27Z,58
"@@ -48,7 +48,8 @@ public ApplyDeltaCommand() {
       super();
    }
    
-   public ApplyDeltaCommand(Object deltaAwareValueKey, Delta delta, Collection<Object> keys) {      
+   public ApplyDeltaCommand(Object deltaAwareValueKey, Delta delta, Collection<Object> keys) {
+      //todo [anistor] should invoke super(deltaAwareValueKey)
       if (keys == null || keys.isEmpty())
          throw new IllegalArgumentException(""At least one key to be locked needs to be specified"");
       else",2012-08-31T21:04:48Z,59
"@@ -120,6 +120,10 @@ public interface DistributionManager {
     */
    ConsistentHash getConsistentHash();
 
+   ConsistentHash getReadConsistentHash();
+
+   ConsistentHash getWriteConsistentHash();
+
    /**
     * Sets the consistent hash implementation in use.
     *",2012-08-31T21:04:48Z,60
"@@ -189,6 +189,14 @@ public InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext
 
    @Override
    public ConsistentHash getConsistentHash() {
+      return getWriteConsistentHash();
+   }
+
+   public ConsistentHash getReadConsistentHash() {
+      return cacheTopology.getReadConsistentHash();
+   }
+
+   public ConsistentHash getWriteConsistentHash() {
       return cacheTopology.getWriteConsistentHash();
    }
 ",2012-08-31T21:04:48Z,60
"@@ -0,0 +1,110 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.newstatetransfer;
+
+import org.infinispan.commands.AbstractVisitor;
+import org.infinispan.commands.control.LockControlCommand;
+import org.infinispan.commands.tx.CommitCommand;
+import org.infinispan.commands.tx.PrepareCommand;
+import org.infinispan.commands.tx.RollbackCommand;
+import org.infinispan.commands.write.*;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.context.impl.TxInvocationContext;
+
+import java.util.Collections;
+import java.util.HashSet;
+
+/**
+ * // TODO: Document this
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+public class AffectedKeysVisitor extends AbstractVisitor {
+
+   @Override
+   public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand command) {
+      return command.getAffectedKeys();
+   }
+
+   @Override
+   public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command) {
+      return ctx.getAffectedKeys();
+   }
+
+   @Override
+   public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand command) {
+      return ctx.getAffectedKeys();
+   }
+
+   @Override
+   public Object visitLockControlCommand(TxInvocationContext ctx, LockControlCommand command) {
+      return new HashSet<Object>(command.getKeys());
+   }
+
+   @Override
+   public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) {
+      return command.getAffectedKeys();
+   }
+
+   @Override
+   public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) {
+      return command.getAffectedKeys();
+   }
+
+   @Override
+   public Object visitApplyDeltaCommand(InvocationContext ctx, ApplyDeltaCommand command) {
+      return Collections.singleton(command.getDeltaAwareKey());
+   }
+
+   @Override
+   public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) {
+      return command.getAffectedKeys();
+   }
+
+   @Override
+   public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) {
+      return command.getAffectedKeys();
+   }
+
+   @Override
+   public Object visitClearCommand(InvocationContext ctx, ClearCommand command) {
+      return command.getAffectedKeys();
+   }
+
+   @Override
+   public Object visitInvalidateCommand(InvocationContext ctx, InvalidateCommand command) {
+      return null;
+   }
+
+   @Override
+   public Object visitInvalidateL1Command(InvocationContext ctx, InvalidateL1Command command) {
+      return null;
+   }
+
+   @Override
+   public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) {
+      return null;
+   }
+}",2012-08-31T21:04:48Z,61
"@@ -34,7 +34,9 @@
 import java.util.concurrent.CopyOnWriteArraySet;
 
 /**
- * // TODO [anistor] Document this
+ * Inbound state transfer task. Fetches transactions and data segments from a remote source and applies it to local
+ * cache. Instances of InboundTransferTask are created and managed by StateTransferManagerImpl. There should be at most
+ * one such task per source at any time.
  *
  * @author anistor@redhat.com
  * @since 5.2",2012-08-31T21:04:48Z,62
"@@ -43,7 +43,9 @@
 import java.util.concurrent.CopyOnWriteArraySet;
 
 /**
- * // TODO [anistor] Document this
+ * Outbound state transfer task. Pushes data segments to another cluster member on request. Instances of
+ * OutboundTransferTask are created and managed by StateTransferManagerImpl. There should be at most
+ * one such task per destination at any time.
  *
  * @author anistor@redhat.com
  * @since 5.2",2012-08-31T21:04:48Z,63
"@@ -63,6 +63,7 @@ public class StateConsumerImpl implements StateConsumer {
    private static final Log log = LogFactory.getLog(StateConsumerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
+   private StateTransferManager stateTransferManager;
    private CacheNotifier cacheNotifier;
    private Configuration configuration;
    private RpcManager rpcManager;
@@ -89,7 +90,8 @@ public class StateConsumerImpl implements StateConsumer {
    private Map<Address, List<InboundTransferTask>> transfersBySource = new HashMap<Address, List<InboundTransferTask>>();
    private Map<Integer, InboundTransferTask> transfersBySegment = new HashMap<Integer, InboundTransferTask>();
 
-   public StateConsumerImpl(CacheNotifier cacheNotifier,
+   public StateConsumerImpl(StateTransferManager stateTransferManager,
+                            CacheNotifier cacheNotifier,
                             InterceptorChain interceptorChain,
                             InvocationContextContainer icc,
                             Configuration configuration,
@@ -99,6 +101,7 @@ public StateConsumerImpl(CacheNotifier cacheNotifier,
                             DataContainer dataContainer,
                             TransactionTable transactionTable,
                             StateTransferLock stateTransferLock) {
+      this.stateTransferManager = stateTransferManager;
       this.cacheNotifier = cacheNotifier;
       this.interceptorChain = interceptorChain;
       this.icc = icc;
@@ -133,7 +136,6 @@ public boolean isStateTransferInProgressForKey(Object key) {
       }
       // todo [anistor] also return true for keys to be removed (now we report only keys to be added)
       synchronized (this) {
-         // todo [anistor] do not lookup segment in map if there is no transfer in progress
          return rCh != null && transfersBySegment.containsKey(rCh.getSegment(key));
       }
    }
@@ -148,7 +150,7 @@ public void onTopologyUpdate(int topologyId, ConsistentHash rCh, ConsistentHash
          this.topologyId = topologyId;
       }
 
-      ((StateTransferLockImpl) stateTransferLock).setTopologyId(topologyId);
+      stateTransferLock.setTopologyId(topologyId);
 
       try {
          Set<Integer> addedSegments = null;
@@ -158,10 +160,10 @@ public void onTopologyUpdate(int topologyId, ConsistentHash rCh, ConsistentHash
             this.wCh = wCh;
 
             if (configuration.clustering().stateTransfer().fetchInMemoryState()) {
-               addedSegments = this.rCh.getSegmentsForOwner(rpcManager.getAddress());
+               addedSegments = this.wCh.getSegmentsForOwner(rpcManager.getAddress());
             }
          } else {
-            Set<Integer> oldSegments = this.rCh.getSegmentsForOwner(rpcManager.getAddress());
+            Set<Integer> oldSegments = this.rCh.getMembers().contains(rpcManager.getAddress()) ? this.rCh.getSegmentsForOwner(rpcManager.getAddress()) : new HashSet<Integer>();
             this.rCh = rCh;
             this.wCh = wCh;
             Set<Integer> newSegments = this.wCh.getSegmentsForOwner(rpcManager.getAddress());
@@ -209,20 +211,18 @@ public void onTopologyUpdate(int topologyId, ConsistentHash rCh, ConsistentHash
          synchronized (this) {
             isTopologyUpdate--;
             if (isTopologyUpdate == 0 && !isStateTransferInProgress()) {
-               notifyEndOfStateTransfer();
+               stateTransferManager.notifyEndOfStateTransfer(topologyId);
             }
          }
       }
    }
 
-   private void notifyEndOfStateTransfer() {
-      // TODO [anistor] implement!
-   }
-
    public void applyState(Address sender, int topologyId, int segmentId, Collection<InternalCacheEntry> cacheEntries, boolean isLastChunk) {
       // it's possible to receive a late message so we must be prepared to ignore segments we no longer own
-      if (rCh == null || !rCh.locateOwnersForSegment(segmentId).contains(rpcManager.getAddress())) {  //todo [anistor] optimize
-         log.tracef(""Discarding the received cache entries because they do not belong to this node."");
+      if (wCh == null || !wCh.getSegmentsForOwner(rpcManager.getAddress()).contains(segmentId)) {
+         if (trace) {
+            log.tracef(""Discarding received cache entries for segment %d because they do not belong to this node."", segmentId);
+         }
          return;
       }
 
@@ -314,16 +314,19 @@ private void addTransfers(Set<Integer> segments) {
                }
 
                Address source = pickSourceOwner(segmentId, faultyMembers);
-
-               Set<Integer> segs = segmentsBySource.get(source);
-               if (segs == null) {
-                  segs = new HashSet<Integer>();
-                  segmentsBySource.put(source, segs);
+               if (source == null) {
+                  log.errorf(""No owners found for segment %d"", segmentId);
+               } else {
+                  Set<Integer> segs = segmentsBySource.get(source);
+                  if (segs == null) {
+                     segs = new HashSet<Integer>();
+                     segmentsBySource.put(source, segs);
+                  }
+                  segs.add(segmentId);
                }
-               segs.add(segmentId);
             }
 
-            Set<Integer> failedSegments = new HashSet<Integer>(segments);
+            Set<Integer> failedSegments = new HashSet<Integer>();
             for (Address source : segmentsBySource.keySet()) {
                Set<Integer> segs = segmentsBySource.get(source);
                InboundTransferTask inboundTransfer = new InboundTransferTask(segs, source, topologyId, this, rpcManager, commandsFactory, timeout);
@@ -375,7 +378,7 @@ private void discardSegments(Set<Integer> segments) {
       synchronized (this) {
          List<Integer> segmentsToCancel = new ArrayList<Integer>(segments);
          while (!segmentsToCancel.isEmpty()) {
-            int segmentId = segmentsToCancel.get(0);
+            int segmentId = segmentsToCancel.remove(0);
             log.debugf(""Removing state transfer for segment %d"", segmentId);
             InboundTransferTask inboundTransfer = transfersBySegment.remove(segmentId);
             if (inboundTransfer != null) { // we need to check the transfer was not already completed
@@ -408,7 +411,7 @@ private void discardSegments(Set<Integer> segments) {
             }
 
          } catch (CacheLoaderException e) {
-            e.printStackTrace();  // TODO [anistor] handle properly
+            log.failedLoadingKeysFromCacheStore(e);
          }
       }
 
@@ -420,7 +423,7 @@ private void discardSegments(Set<Integer> segments) {
             interceptorChain.invoke(ctx, invalidateCmd);
 
             log.debugf(""Invalidated %d keys, data container now has %d keys"", keysToRemove.size(), dataContainer.size());
-            log.tracef(""Invalidated keys: %s"", keysToRemove);
+            if (trace) log.tracef(""Invalidated keys: %s"", keysToRemove);
          } catch (CacheException e) {
             log.failedToInvalidateKeys(e);
          }
@@ -463,7 +466,7 @@ void onTaskCompletion(InboundTransferTask inboundTransfer) {
          allTasksCompleted = isTopologyUpdate == 0 && !isStateTransferInProgress();
       }
       if (allTasksCompleted) {
-         notifyEndOfStateTransfer();
+         stateTransferManager.notifyEndOfStateTransfer(topologyId);
       }
    }
 }",2012-08-31T21:04:48Z,64
"@@ -128,6 +128,10 @@ public void shutdown() {
    }
 
    public List<TransactionInfo> getTransactionsForSegments(Address destination, int topologyId, Set<Integer> segments) {
+      if (rCh == null) {
+         throw new IllegalStateException(""No cache topology received yet"");
+      }
+
       Set<Integer> ownedSegments = rCh.getSegmentsForOwner(rpcManager.getAddress());
       if (!ownedSegments.containsAll(segments)) {
          segments.removeAll(ownedSegments);",2012-08-31T21:04:48Z,65
"@@ -26,6 +26,8 @@
 import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
+import org.infinispan.commands.read.GetKeyValueCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.tx.RollbackCommand;
@@ -34,13 +36,17 @@
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
+import org.infinispan.distribution.DistributionManager;
+import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.Collections;
+import java.util.HashSet;
 import java.util.Set;
 
 /**
@@ -49,12 +55,16 @@
  * @author anistor@redhat.com
  * @since 5.2
  */
-public class StateTransferInterceptor extends CommandInterceptor {
+public class StateTransferInterceptor extends CommandInterceptor {   //todo [anistor] this interceptor should be added to stack only if we have state transfer
 
    private static final Log log = LogFactory.getLog(StateTransferInterceptor.class);
 
+   private final AffectedKeysVisitor affectedKeysVisitor = new AffectedKeysVisitor();
+
    private StateTransferLock stateTransferLock;
 
+   private DistributionManager distributionManager;
+
    private RpcManager rpcManager;
 
    private long rpcTimeout;
@@ -65,9 +75,10 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager) {
+   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager, DistributionManager distributionManager) {
       this.stateTransferLock = stateTransferLock;
       this.rpcManager = rpcManager;
+      this.distributionManager = distributionManager;
       // no need to retry for asynchronous caches
       this.rpcTimeout = configuration.clustering().cacheMode().isSynchronous()
             ? configuration.clustering().sync().replTimeout() : 0;
@@ -93,12 +104,6 @@ public Object visitLockControlCommand(TxInvocationContext ctx, LockControlComman
       return handleTxCommand(ctx, command);
    }
 
-   @Override
-   public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) throws Throwable {
-      // it's not necessary to propagate eviction to the new owners in case of state transfer
-      return invokeNextInterceptor(ctx, command);
-   }
-
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
       return handleWriteCommand(ctx, command);
@@ -141,6 +146,12 @@ public Object visitInvalidateL1Command(InvocationContext ctx, InvalidateL1Comman
       return invokeNextInterceptor(ctx, command);
    }
 
+   @Override
+   public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) throws Throwable {
+      // it's not necessary to propagate eviction to the new owners in case of state transfer
+      return invokeNextInterceptor(ctx, command);
+   }
+
    /**
     * Special processing required for transaction commands.
     *
@@ -150,57 +161,113 @@ public Object visitInvalidateL1Command(InvocationContext ctx, InvalidateL1Comman
     * @throws Throwable
     */
    private Object handleTxCommand(InvocationContext ctx, TransactionBoundaryCommand command) throws Throwable {
-      try {
-         stateTransferLock.commandsSharedLock();
-         try {
-            stateTransferLock.transactionsSharedLock();
-            try {
-               return invokeNextInterceptor(ctx, command);
-            } finally {
-               stateTransferLock.transactionsSharedUnlock();
-            }
-         } finally {
-            stateTransferLock.commandsSharedUnlock();
-         }
-      } finally {
-         forwardCommand(ctx, command);
-      }
+      return handleTopologyAffectedCommand(ctx, command);
    }
 
    private Object handleWriteCommand(InvocationContext ctx, WriteCommand command) throws Throwable {
-      try {
-         stateTransferLock.commandsSharedLock();
-         try {
-            return invokeNextInterceptor(ctx, command);
-         } finally {
-            stateTransferLock.commandsSharedUnlock();
-         }
-      } finally {
-         forwardCommand(ctx, command);
-      }
+      return handleTopologyAffectedCommand(ctx, command);
    }
 
    @Override
    protected Object handleDefault(InvocationContext ctx, VisitableCommand command) throws Throwable {
       if (command instanceof TopologyAffectedCommand) {
+         return handleTopologyAffectedCommand(ctx, (TopologyAffectedCommand) command);
+      } else {
+         return invokeNextInterceptor(ctx, command);
+      }
+   }
+
+   private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffectedCommand command) throws Throwable {
+      Set<Address> newTargets = null;
+      stateTransferLock.commandsSharedLock();
+      final int topologyId = stateTransferLock.getTopologyId();
+      final ConsistentHash rCh = distributionManager.getReadConsistentHash();
+      final ConsistentHash wCh = distributionManager.getWriteConsistentHash();
+      try {
+         final boolean isTxCommand = command instanceof TransactionBoundaryCommand;
+         if (isTxCommand) {
+            stateTransferLock.transactionsSharedLock();
+         }
          try {
-            stateTransferLock.commandsSharedLock();
-            try {
-               return invokeNextInterceptor(ctx, command);
-            } finally {
-               stateTransferLock.commandsSharedUnlock();
+            if (command.getTopologyId() < topologyId) {
+               // if it is a read request and comes from an older topology we need to check if we still hold the data
+               Object readKey = null;
+               if (command instanceof GetKeyValueCommand) {   //todo [anistor] would be nice to have a common ReadCommand interface for these
+                  readKey = ((GetKeyValueCommand) command).getKey();
+               } else if (command instanceof ClusteredGetCommand) {
+                  readKey = ((ClusteredGetCommand) command).getKey();
+               }
+               if (readKey != null) {
+                  // it's a read operation
+                  if (!rCh.isKeyLocalToNode(rpcManager.getAddress(), readKey)) {
+                     return null; //todo [anistor] throw an exception or return a special result that will cause the read command to be retried on the originator
+                  }
+               } else if (command instanceof PrepareCommand || command instanceof LockControlCommand || command instanceof WriteCommand) {  //todo a ClearCommand should be executed directly
+                  // a TX or a write command from an old topology
+                  Set<Object> affectedKeys = getAffectedKeys(ctx, command);
+                  newTargets = new HashSet<Address>();
+                  boolean localExecutionNeeded = false;
+                  for (Object key : affectedKeys) {
+                     if (wCh.isKeyLocalToNode(rpcManager.getAddress(), key)) {
+                        localExecutionNeeded = true;
+                     } else {
+                        newTargets.addAll(wCh.locateOwners(key));
+                     }
+                  }
+
+                  if (localExecutionNeeded) {
+                     return invokeNextInterceptor(ctx, command);
+                  }
+               } else if (command instanceof CommitCommand || command instanceof RollbackCommand) {
+                  // for these commands we can determine affected keys only after they are executed
+                  try {
+                     return invokeNextInterceptor(ctx, command);
+                  } finally {
+                     newTargets = new HashSet<Address>();
+                     Set<Object> affectedKeys = ((TxInvocationContext) ctx).getAffectedKeys();
+                     for (Object key : affectedKeys) {
+                        if (!wCh.isKeyLocalToNode(rpcManager.getAddress(), key)) {
+                           newTargets.addAll(wCh.locateOwners(key));
+                        }
+                     }
+                  }
+               }
+            } else if (command.getTopologyId() > topologyId) {
+               // this means there will be a new topology installed soon. no need to wait until then
+               //stateTransferLock.waitForTopology(command.getTopologyId());
+
+               // proceed normally
+            } else {
+               // proceed normally
             }
+
+            // no special handling was needed, invoke normally (and do not forward)
+            return invokeNextInterceptor(ctx, command);
          } finally {
-            forwardCommand(ctx, command);
+            if (isTxCommand) {
+               stateTransferLock.transactionsSharedUnlock();
+            }
+         }
+      } finally {
+         stateTransferLock.commandsSharedUnlock();
+
+         if (newTargets != null && !newTargets.isEmpty()) {
+            command.setTopologyId(topologyId);
+            rpcManager.invokeRemotely(newTargets, command, true);
          }
-      } else {
-         return invokeNextInterceptor(ctx, command);
       }
    }
 
-   private void forwardCommand(InvocationContext ctx, VisitableCommand command) {
-      // TODO: Customise this generated block
-      Set<Address> newTarget = null;
-      rpcManager.invokeRemotely(newTarget, command, true);
+   private Set<Object> getAffectedKeys(InvocationContext ctx, VisitableCommand command) {
+      Set<Object> affectedKeys = null;
+      try {
+         affectedKeys = (Set<Object>) command.acceptVisitor(ctx, affectedKeysVisitor);
+      } catch (Throwable throwable) {
+         // impossible to reach this
+      }
+      if (affectedKeys == null) {
+         affectedKeys = Collections.emptySet();
+      }
+      return affectedKeys;
    }
 }
\ No newline at end of file",2012-08-31T21:04:48Z,66
"@@ -52,4 +52,8 @@ public interface StateTransferLock {
    void commandsSharedUnlock();
 
    int getTopologyId();
+
+   void setTopologyId(int topologyId);
+
+   void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-08-31T21:04:48Z,67
"@@ -40,6 +40,8 @@ public class StateTransferLockImpl implements StateTransferLock {
 
    private volatile int topologyId;
 
+   private final Object topologyLock = new Object();
+
    @Override
    public void transactionsSharedLock() {
       transactionTableLock.readLock().lock();
@@ -85,7 +87,20 @@ public int getTopologyId() {
       return topologyId;
    }
 
+   @Override
    public void setTopologyId(int topologyId) {
       this.topologyId = topologyId;
+      synchronized (topologyLock) {
+         topologyLock.notifyAll();
+      }
+   }
+
+   @Override
+   public void waitForTopology(int expectedTopologyId) throws InterruptedException {
+      while (topologyId <= expectedTopologyId) {
+         synchronized (topologyLock) {
+            topologyLock.wait();
+         }
+      }
    }
 }",2012-08-31T21:04:48Z,68
"@@ -71,4 +71,6 @@ public interface StateTransferManager {
    boolean isStateTransferInProgressForKey(Object key);
 
    int getTopologyId();
+
+   void notifyEndOfStateTransfer(int topologyId);
 }",2012-08-31T21:04:48Z,69
"@@ -166,7 +166,9 @@ private void doTopologyUpdate(CacheTopology cacheTopology, boolean rebalance) {
 
             topologyId = cacheTopology.getTopologyId();
             rebalanceInProgress = rebalance;
-            distributionManager.setCacheTopology(cacheTopology);
+            if (distributionManager != null) { // need to check we are really in distributed mode
+               distributionManager.setCacheTopology(cacheTopology);
+            }
             onTopologyUpdate(topologyId, cacheTopology.getReadConsistentHash(), cacheTopology.getWriteConsistentHash());
          }
       };",2012-08-31T21:04:48Z,70
"@@ -24,6 +24,7 @@
 package org.infinispan.newstatetransfer;
 
 import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.ReplicableCommand;
 import org.infinispan.commons.hash.MurmurHash3;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configuration;
@@ -38,6 +39,9 @@
 import org.infinispan.interceptors.InterceptorChain;
 import org.infinispan.loaders.CacheLoaderManager;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.responses.SuccessfulResponse;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.LocalTransaction;
@@ -53,11 +57,10 @@
 import java.util.*;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Future;
-import java.util.concurrent.ThreadFactory;
 
 import static org.junit.Assert.assertFalse;
 import static org.junit.Assert.assertTrue;
-import static org.mockito.Matchers.any;
+import static org.mockito.Matchers.*;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.when;
 
@@ -81,12 +84,6 @@ public void test1() {
             .versioning().enable().scheme(VersioningScheme.SIMPLE)
             .locking().lockAcquisitionTimeout(200).writeSkewCheck(true).isolationLevel(IsolationLevel.REPEATABLE_READ);
 
-      ThreadFactory threadFactory = new ThreadFactory() {
-         @Override
-         public Thread newThread(Runnable r) {
-            return new Thread(r);
-         }
-      };
       Configuration configuration = cb.build();
 
       // create list of 6 members
@@ -101,12 +98,13 @@ public Thread newThread(Runnable r) {
       // create CHes
       DefaultConsistentHashFactory chf = new DefaultConsistentHashFactory();
       DefaultConsistentHash ch1 = chf.create(new MurmurHash3(), 2, 4, members1);
-      DefaultConsistentHash ch2 = chf.updateMembers(ch1, members2);   //todo [anistor] it seems that adress 6 is not used for un-owned segments
+      DefaultConsistentHash ch2 = chf.updateMembers(ch1, members2);   //todo [anistor] it seems that address 6 is not used for un-owned segments
 
-      System.out.println(ch1.dump());
-      System.out.println(ch2.dump());
+      log.debug(ch1.dump());
+      log.debug(ch2.dump());
 
       // create dependencies
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
       CacheNotifier cacheNotifier = mock(CacheNotifier.class);
       ExecutorService executorService2 = mock(ExecutorService.class);
       RpcManager rpcManager = mock(RpcManager.class);
@@ -120,46 +118,75 @@ public Thread newThread(Runnable r) {
 
       when(executorService2.submit(any(Runnable.class))).thenAnswer(new Answer<Future<?>>() {
          @Override
-         public Future<?> answer(InvocationOnMock invocation) throws Throwable {
+         public Future<?> answer(InvocationOnMock invocation) {
             return null;
          }
       });
 
+      when(commandsFactory.buildStateRequestCommand(any(StateRequestCommand.Type.class), any(Address.class), anyInt(), any(Set.class))).thenAnswer(new Answer<StateRequestCommand>() {
+         @Override
+         public StateRequestCommand answer(InvocationOnMock invocation) {
+            return new StateRequestCommand(""cache1"", (StateRequestCommand.Type) invocation.getArguments()[0], (Address) invocation.getArguments()[1], (Integer) invocation.getArguments()[2], (Set) invocation.getArguments()[3]);
+         }
+      });
+
       when(rpcManager.getAddress()).thenReturn(new TestAddress(0));
 
+      when(rpcManager.invokeRemotely(any(Collection.class), any(ReplicableCommand.class), any(ResponseMode.class), anyLong())).thenAnswer(new Answer<Map<Address, Response>>() {
+         @Override
+         public Map<Address, Response> answer(InvocationOnMock invocation) {
+            Collection<Address> recipients = (Collection<Address>) invocation.getArguments()[0];
+            ReplicableCommand rpcCommand = (ReplicableCommand) invocation.getArguments()[1];
+            if (rpcCommand instanceof StateRequestCommand) {
+               StateRequestCommand cmd = (StateRequestCommand) rpcCommand;
+               Map<Address, Response> results = new HashMap<Address, Response>();
+               if (cmd.getType().equals(StateRequestCommand.Type.GET_TRANSACTIONS)) {
+                  for (Address recipient : recipients) {
+                     results.put(recipient, SuccessfulResponse.create(new ArrayList<TransactionInfo>()));
+                  }
+               } else if (cmd.getType().equals(StateRequestCommand.Type.START_STATE_TRANSFER) || cmd.getType().equals(StateRequestCommand.Type.CANCEL_STATE_TRANSFER)) {
+                  for (Address recipient : recipients) {
+                     results.put(recipient, SuccessfulResponse.SUCCESSFUL_EMPTY_RESPONSE);
+                  }
+               }
+               return results;
+            }
+            return Collections.emptyMap();
+         }
+      });
+
+
       // create state provider
-      StateConsumerImpl stateConsumer = new StateConsumerImpl(cacheNotifier, interceptorChain, icc,
+      StateConsumerImpl stateConsumer = new StateConsumerImpl(stateTransferManager, cacheNotifier, interceptorChain, icc,
             configuration, rpcManager, commandsFactory, cacheLoaderManager,
             dataContainer, transactionTable, stateTransferLock);
 
       final List<InternalCacheEntry> cacheEntries = new ArrayList<InternalCacheEntry>();
-      cacheEntries.add(new ImmortalCacheEntry(""key1"", ""value1""));
-      cacheEntries.add(new ImmortalCacheEntry(""key2"", ""value2""));
+      Object key1 = new TestKey(""key1"", 0, ch1);
+      Object key2 = new TestKey(""key2"", 0, ch1);
+      cacheEntries.add(new ImmortalCacheEntry(key1, ""value1""));
+      cacheEntries.add(new ImmortalCacheEntry(key2, ""value2""));
       when(dataContainer.iterator()).thenAnswer(new Answer<Iterator<InternalCacheEntry>>() {
          @Override
-         public Iterator<InternalCacheEntry> answer(InvocationOnMock invocation) throws Throwable {
+         public Iterator<InternalCacheEntry> answer(InvocationOnMock invocation) {
             return cacheEntries.iterator();
          }
       });
       when(transactionTable.getLocalTransactions()).thenReturn(Collections.<LocalTransaction>emptyList());
       when(transactionTable.getRemoteTransactions()).thenReturn(Collections.<RemoteTransaction>emptyList());
 
       // create segments
-      Set<Integer> segments = new HashSet<Integer>();
-      for (int i = 0; i < 5; i++) {
-         segments.add(i);
-      }
+      Set<Integer> segments = new HashSet<Integer>(Arrays.asList(0, 1, 2, 3, 4));
 
-      Set<Integer> seg = new HashSet<Integer>();
-      seg.add(0);
+      Set<Integer> seg = new HashSet<Integer>(Arrays.asList(0));
 
       assertFalse(stateConsumer.isStateTransferInProgress());
 
       stateConsumer.onTopologyUpdate(1, ch1, ch1);
 
       assertTrue(stateConsumer.isStateTransferInProgress());
 
-      stateConsumer.onTopologyUpdate(3, ch1, ch2);
+      stateConsumer.onTopologyUpdate(2, ch1, ch2);
 
       stateConsumer.shutdown();
 ",2012-08-31T21:04:48Z,71
"@@ -126,63 +126,67 @@ public void test1() {
       DefaultConsistentHash ch1 = chf.create(new MurmurHash3(), 2, 4, members1);
       DefaultConsistentHash ch2 = chf.updateMembers(ch1, members2);   //todo [anistor] it seems that address 6 is not used for un-owned segments
 
-      System.out.println(""StateProviderTest.test1 "" + ch1.dump());
-      System.out.println(""StateProviderTest.test1 "" + ch2.dump());
-
       // create dependencies
       when(mockExecutorService.submit(any(Runnable.class))).thenAnswer(new Answer<Future<?>>() {
          @Override
-         public Future<?> answer(InvocationOnMock invocation) throws Throwable {
+         public Future<?> answer(InvocationOnMock invocation) {
             return null;
          }
       });
 
+      when(rpcManager.getAddress()).thenReturn(new TestAddress(0));
+
       // create state provider
       StateProviderImpl stateProvider = new StateProviderImpl(mockExecutorService,
             configuration, rpcManager, commandsFactory, cacheLoaderManager,
             dataContainer, transactionTable, stateTransferLock);
 
       final List<InternalCacheEntry> cacheEntries = new ArrayList<InternalCacheEntry>();
-      cacheEntries.add(new ImmortalCacheEntry(""key1"", ""value1""));
-      cacheEntries.add(new ImmortalCacheEntry(""key2"", ""value2""));
+      Object key1 = new TestKey(""key1"", 0, ch1);
+      Object key2 = new TestKey(""key2"", 0, ch1);
+      cacheEntries.add(new ImmortalCacheEntry(key1, ""value1""));
+      cacheEntries.add(new ImmortalCacheEntry(key2, ""value2""));
       when(dataContainer.iterator()).thenAnswer(new Answer<Iterator<InternalCacheEntry>>() {
          @Override
-         public Iterator<InternalCacheEntry> answer(InvocationOnMock invocation) throws Throwable {
+         public Iterator<InternalCacheEntry> answer(InvocationOnMock invocation) {
             return cacheEntries.iterator();
          }
       });
       when(transactionTable.getLocalTransactions()).thenReturn(Collections.<LocalTransaction>emptyList());
       when(transactionTable.getRemoteTransactions()).thenReturn(Collections.<RemoteTransaction>emptyList());
 
-      // create segments
-      Set<Integer> segments = new HashSet<Integer>();
-      for (int i = 0; i < 5; i++) {
-         segments.add(i);
-      }
+      stateProvider.onTopologyUpdate(1, ch1, ch1);
 
-      List<TransactionInfo> transactions = stateProvider.getTransactionsForSegments(members1.get(0), 1, segments);
+      log.debug(""ch1: "" + ch1.dump());
+      List<TransactionInfo> transactions = stateProvider.getTransactionsForSegments(members1.get(0), 1, new HashSet<Integer>(Arrays.asList(0, 3)));
       assertEquals(0, transactions.size());
 
+      try {
+         stateProvider.getTransactionsForSegments(members1.get(0), 1, new HashSet<Integer>(Arrays.asList(2, 4)));
+         fail(""IllegalArgumentException expected"");
+      } catch (IllegalArgumentException e) {
+         // expected
+      }
+
       InOrder stateTransferLockVerifier = inOrder(stateTransferLock);
       stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveLock();
       stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveUnlock();
 
-      Set<Integer> seg = new HashSet<Integer>();
-      seg.add(0);
-      stateProvider.startOutboundTransfer(new TestAddress(5), 1, seg);
+      stateProvider.startOutboundTransfer(new TestAddress(5), 1, Collections.singleton(0));
 
       assertTrue(stateProvider.isStateTransferInProgress());
 
-      stateProvider.onTopologyUpdate(2, ch1, ch1);
+      log.debug(""ch2: "" + ch2.dump());
+      stateProvider.onTopologyUpdate(2, ch1, ch2);
+
+      assertFalse(stateProvider.isStateTransferInProgress());
+
+      stateProvider.startOutboundTransfer(new TestAddress(4), 1, Collections.singleton(0));
 
       assertTrue(stateProvider.isStateTransferInProgress());
 
       stateProvider.shutdown();
 
-      stateProvider.onTopologyUpdate(3, ch1, ch2);
-
       assertFalse(stateProvider.isStateTransferInProgress());
-
-      stateProvider.shutdown();
    }
 }",2012-08-31T21:04:48Z,72
"@@ -0,0 +1,80 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.newstatetransfer;
+
+import org.infinispan.distribution.ch.ConsistentHash;
+
+import java.io.Serializable;
+import java.util.Random;
+
+/**
+ * A key that maps to a given data segment of the ConsistentHash.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+public final class TestKey implements Serializable {
+
+   private static final long serialVersionUID = -42;
+
+   /**
+    * A name used for easier debugging. This is not relevant for equals() and hashCode().
+    */
+   private final String name;
+
+   /**
+    * A carefully crafted hash code.
+    */
+   private final int hashCode;
+
+   public TestKey(String name, int segmentId, ConsistentHash ch) {
+      this.name = name;
+
+      Random rnd = new Random();
+      Integer r;
+      do {
+         r = rnd.nextInt();
+      } while (segmentId != ch.getSegment(r));
+
+      hashCode = r;
+   }
+
+   @Override
+   public int hashCode() {
+      return hashCode;
+   }
+
+   @Override
+   public boolean equals(Object o) {
+      if (this == o) return true;
+      if (o == null || o.getClass() != TestKey.class) return false;
+      TestKey other = (TestKey) o;
+      return hashCode == other.hashCode;
+   }
+
+   @Override
+   public String toString() {
+      return ""TestKey{name="" + name + "", hashCode="" + hashCode + '}';
+   }
+}
\ No newline at end of file",2012-08-31T21:04:48Z,73
"@@ -0,0 +1,165 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.io;
+
+/**
+ * A byte stream that can be written to and expanded on the fly, not dissimilar to {@link ExposedByteArrayOutputStream}
+ * but with the benefit of not having to allocate unnecessary byte arrays byt not extending {@link java.io.ByteArrayOutputStream}.
+ *
+ * @author Manik Surtani
+ * @since 5.1
+ */
+public class ExpandableMarshalledValueByteStream extends MarshalledValueByteStream {
+   /**
+    * The buffer where data is stored.
+    */
+   private byte buf[];
+
+   /**
+    * The number of valid bytes in the buffer.
+    */
+   private int count;
+
+   /**
+    * Default buffer size after which if more buffer capacity is needed the buffer will grow by 25% rather than 100%
+    */
+   public static final int DEFAULT_DOUBLING_SIZE = 4 * 1024 * 1024; // 4MB
+
+   private int maxDoublingSize = DEFAULT_DOUBLING_SIZE;
+
+   public ExpandableMarshalledValueByteStream() {
+      this(32);
+   }
+
+   public ExpandableMarshalledValueByteStream(int size) {
+      if (size < 0) {
+         throw new IllegalArgumentException(""Negative initial size: ""
+                                                  + size);
+      }
+      buf = new byte[size];
+
+   }
+
+   /**
+    * Creates a new byte array output stream, with a buffer capacity of the specified size, in bytes.
+    *
+    * @param size            the initial size.
+    * @param maxDoublingSize the buffer size, after which if more capacity is needed the buffer will grow by 25% rather
+    *                        than 100%
+    * @throws IllegalArgumentException if size is negative.
+    */
+   public ExpandableMarshalledValueByteStream(int size, int maxDoublingSize) {
+      this(size);
+      this.maxDoublingSize = maxDoublingSize;
+   }
+
+   /**
+    * Gets the internal buffer array. Note that the length of this array will almost certainly be longer than the data
+    * written to it; call <code>size()</code> to get the number of bytes of actual data.
+    */
+   @Override
+   public final byte[] getRaw() {
+      return buf;
+   }
+
+   public final void set(byte[] b) {
+      this.buf = b;
+      this.count = b.length;
+   }
+
+   @Override
+   public final void write(byte[] b, int off, int len) {
+      if ((off < 0) || (off > b.length) || (len < 0) ||
+            ((off + len) > b.length) || ((off + len) < 0)) {
+         throw new IndexOutOfBoundsException();
+      } else if (len == 0) {
+         return;
+      }
+
+      int newcount = count + len;
+      if (newcount > buf.length) {
+         byte newbuf[] = new byte[getNewBufferSize(buf.length, newcount)];
+         System.arraycopy(buf, 0, newbuf, 0, count);
+         buf = newbuf;
+      }
+
+      System.arraycopy(b, off, buf, count, len);
+      count = newcount;
+   }
+
+   @Override
+   public final void write(int b) {
+      int newcount = count + 1;
+      if (newcount > buf.length) {
+         byte newbuf[] = new byte[getNewBufferSize(buf.length, newcount)];
+         System.arraycopy(buf, 0, newbuf, 0, count);
+         buf = newbuf;
+      }
+      buf[count] = (byte) b;
+      count = newcount;
+   }
+
+   /**
+    * Gets the highest internal buffer size after which if more capacity is needed the buffer will grow in 25%
+    * increments rather than 100%.
+    */
+   public final int getMaxDoublingSize() {
+      return maxDoublingSize;
+   }
+
+   /**
+    * Gets the number of bytes to which the internal buffer should be resized.
+    *
+    * @param curSize    the current number of bytes
+    * @param minNewSize the minimum number of bytes required
+    * @return the size to which the internal buffer should be resized
+    */
+   public final int getNewBufferSize(int curSize, int minNewSize) {
+      if (curSize <= maxDoublingSize)
+         return Math.max(curSize << 1, minNewSize);
+      else
+         return Math.max(curSize + (curSize >> 2), minNewSize);
+   }
+
+   /**
+    * Overriden only to avoid unneeded synchronization
+    */
+   @Override
+   public final int size() {
+      return count;
+   }
+
+   @Override
+   public boolean equals(Object thatObject) {
+      if (thatObject instanceof MarshalledValueByteStream) {
+         MarshalledValueByteStream that = (MarshalledValueByteStream) thatObject;
+         if (this == that) return true;
+         byte[] thoseBytes = that.getRaw();
+         if (this.buf == thoseBytes) return true;
+         if (this.count != that.size()) return false;
+         for (int i = 0; i < count; i++) {
+            if (this.buf[i] != thoseBytes[i]) return false;
+         }
+         return true;
+      } else {
+         return false;
+      }
+   }
+}",2012-05-08T16:12:05Z,74
"@@ -25,6 +25,7 @@
 import net.jcip.annotations.NotThreadSafe;
 
 import java.io.ByteArrayOutputStream;
+import java.util.Arrays;
 
 /**
  * Extends ByteArrayOutputStream, but exposes the internal buffer. Using this, callers don't need to call toByteArray()
@@ -56,6 +57,12 @@ public ExposedByteArrayOutputStream(int size) {
       super(size);
    }
 
+   public ExposedByteArrayOutputStream(byte[] bytes) {
+      if (bytes == null || bytes.length == 0) throw new IllegalArgumentException(""Null or empty byte arrays not allowed"");
+      buf = bytes;
+      count = bytes.length;
+   }
+
    /**
     * Creates a new byte array output stream, with a buffer capacity of the specified size, in bytes.
     *
@@ -77,6 +84,11 @@ public final byte[] getRawBuffer() {
       return buf;
    }
 
+   public final void set(byte[] b) {
+      this.buf = b;
+      this.count = b.length;
+   }
+
    @Override
    public final void write(byte[] b, int off, int len) {
       if ((off < 0) || (off > b.length) || (len < 0) ||
@@ -138,4 +150,20 @@ public final int getNewBufferSize(int curSize, int minNewSize) {
    public final int size() {
       return count;
    }
+
+   @Override
+   public boolean equals(Object thatObject) {
+      if (thatObject instanceof ExposedByteArrayOutputStream) {
+         ExposedByteArrayOutputStream that = (ExposedByteArrayOutputStream) thatObject;
+         if (this == that) return true;
+         if (this.buf == that.buf) return true;
+         if (this.count != that.count) return false;
+         for (int i=0; i<count; i++) {
+            if (this.buf[i] != that.buf[i]) return false;
+         }
+         return true;
+      } else {
+         return false;
+      }
+   }
 }",2012-05-08T16:12:05Z,75
"@@ -0,0 +1,71 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.io;
+
+import net.jcip.annotations.ThreadSafe;
+
+import java.io.IOException;
+
+/**
+ * A byte stream that is immutable.  Bytes are captured during construction and cannot be written to thereafter.
+ *
+ * @author Manik Surtani
+ * @since 5.1
+ */
+@ThreadSafe
+public class ImmutableMarshalledValueByteStream extends MarshalledValueByteStream {
+   private final byte[] bytes;
+
+   public ImmutableMarshalledValueByteStream(byte[] bytes) {
+      this.bytes = bytes;
+   }
+
+   @Override
+   public int size() {
+      return bytes.length;
+   }
+
+   @Override
+   public byte[] getRaw() {
+      return bytes;
+   };
+
+   @Override
+   public void write(int b) throws IOException {
+      throw new UnsupportedOperationException(""Immutable"");
+   }
+
+   @Override
+   public boolean equals(Object thatObject) {
+      if (thatObject instanceof MarshalledValueByteStream) {
+         MarshalledValueByteStream that = (MarshalledValueByteStream) thatObject;
+         if (this == that) return true;
+         byte[] thoseBytes = that.getRaw();
+         if (this.bytes == thoseBytes) return true;
+         if (this.size() != that.size()) return false;
+         for (int i=0; i<bytes.length; i++) {
+            if (this.bytes[i] != thoseBytes[i]) return false;
+         }
+         return true;
+      } else {
+         return false;
+      }
+   }
+}",2012-05-08T16:12:05Z,76
"@@ -0,0 +1,37 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.io;
+
+
+import java.io.OutputStream;
+
+/**
+ * A stream of bytes which can be written to, and the underlying byte array can be directly accessed.
+ *
+ * @author Manik Surtani
+ * @since 5.1
+ */
+public abstract class MarshalledValueByteStream extends OutputStream {
+
+   public abstract int size();
+
+   public abstract byte[] getRaw();
+
+}",2012-05-08T16:12:05Z,77
"@@ -24,8 +24,9 @@
 
 import org.infinispan.CacheException;
 import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.factories.GlobalComponentRegistry;
-import org.infinispan.io.ExposedByteArrayOutputStream;
+import org.infinispan.io.ExpandableMarshalledValueByteStream;
+import org.infinispan.io.ImmutableMarshalledValueByteStream;
+import org.infinispan.io.MarshalledValueByteStream;
 import org.infinispan.io.UnsignedNumeric;
 import org.infinispan.marshall.jboss.ExtendedRiverUnmarshaller;
 import org.infinispan.remoting.transport.Address;
@@ -71,7 +72,7 @@
  */
 public class MarshalledValue implements Serializable {
    volatile protected Object instance;
-   volatile protected byte[] raw;
+   volatile protected MarshalledValueByteStream raw;
    volatile protected int serialisedSize = 128; //size of serialized representation: initial value is a guess
    volatile private int cachedHashCode = 0;
    // by default equals() will test on the instance rather than the byte array if conversion is required.
@@ -94,48 +95,39 @@ private MarshalledValue(byte[] raw, int cachedHashCode, StreamingMarshaller mars
 
    private void init(byte[] raw, int cachedHashCode) {
       // for unmarshalling
-      this.raw = raw;
+      this.raw = new ImmutableMarshalledValueByteStream(raw);
       this.serialisedSize = raw.length;
       this.cachedHashCode = cachedHashCode;
    }
 
-   public synchronized byte[] serialize() {
+   public synchronized MarshalledValueByteStream serialize() {
       return serialize0();
    }
 
    /**
     * Should only be called from a synchronized method
     */
-   private byte[] serialize0() {
-      byte[] rawValue = raw;
-      if (rawValue == null) {
+   private MarshalledValueByteStream serialize0() {
+      MarshalledValueByteStream localRaw = raw;
+      if (localRaw == null) {
          try {
             // Do NOT set instance to null over here, since it may be used elsewhere (e.g., in a cache listener).
             // this will be compacted by the MarshalledValueInterceptor when the call returns.
-            ExposedByteArrayOutputStream baos = new ExposedByteArrayOutputStream(this.serialisedSize);
+            MarshalledValueByteStream baos = new ExpandableMarshalledValueByteStream(this.serialisedSize);
             ObjectOutput out = marshaller.startObjectOutput(baos, true, this.serialisedSize);
             try {
                marshaller.objectToObjectStream(instance, out);
             } finally {
                marshaller.finishObjectOutput(out);
             }
-            final byte[] buf = baos.getRawBuffer();
-            final int length = baos.size();
-            if (buf.length == length) {
-               // in this case we can avoid duplicating the buffer
-               rawValue = buf;
-            }
-            else {
-               serialisedSize = length;
-               rawValue = new byte[length];
-               System.arraycopy(buf, 0, rawValue, 0, length);
-            }
-            raw = rawValue;
+            serialisedSize = baos.size();
+            localRaw = baos;
+            raw = baos;
          } catch (Exception e) {
             throw new CacheException(""Unable to marshall value "" + instance, e);
          }
       }
-      return rawValue;
+      return localRaw;
    }
 
    public synchronized Object deserialize() {
@@ -150,7 +142,7 @@ private Object deserialize0() {
       if (instanceValue == null) {
          try {
             // StreamingMarshaller underneath deals with making sure the right classloader is set.
-            instanceValue = marshaller.objectFromByteBuffer(raw);
+            instanceValue = marshaller.objectFromByteBuffer(raw.getRaw(), 0, raw.size());
             instance = instanceValue;
             return instanceValue;
          }
@@ -178,7 +170,7 @@ public synchronized void compact(boolean preferSerializedRepresentation, boolean
       // reset the equalityPreference
       equalityPreferenceForInstance = true;
       Object thisInstance = this.instance;
-      byte[] thisRaw = this.raw;
+      MarshalledValueByteStream thisRaw = this.raw;
       if (force) {
          if (preferSerializedRepresentation && thisRaw == null) {
             // Accessing a synchronized method from an already synchronized
@@ -206,8 +198,8 @@ else if (!preferSerializedRepresentation && thisInstance == null){
       }
    }
 
-   public byte[] getRaw() {
-      byte[] rawValue = raw;
+   public MarshalledValueByteStream getRaw() {
+      MarshalledValueByteStream rawValue = raw;
       if (rawValue == null){
          rawValue = serialize();
       }
@@ -239,10 +231,10 @@ public boolean equals(Object o) {
       Object thatInstance = that.instance;
       //test the default equality first so we might skip some work:
       if (preferInstanceEquality && thisInstance != null && thatInstance != null) return thisInstance.equals(thatInstance);
-      
-      byte[] thisRaw = this.raw;
-      byte[] thatRaw = that.raw;
-      if (thisRaw != null && thatRaw != null) return Arrays.equals(thisRaw, thatRaw);
+
+      MarshalledValueByteStream thisRaw = this.raw;
+      MarshalledValueByteStream thatRaw = that.raw;
+      if (thisRaw != null && thatRaw != null) return this.raw.equals(that.raw);
       if (thisInstance != null && thatInstance != null) return thisInstance.equals(thatInstance);
 
       // if conversion of one representation to the other is necessary, then see which we prefer converting.
@@ -261,7 +253,7 @@ public boolean equals(Object o) {
          if (thatRaw == null) {
             thatRaw = that.serialize();
          }
-         return Arrays.equals(thisRaw, thatRaw);
+         return Arrays.equals(thisRaw.getRaw(), thatRaw.getRaw());
       }
    }
 
@@ -286,7 +278,7 @@ public String toString() {
       StringBuilder sb = new StringBuilder()
          .append(""MarshalledValue{"")
          .append(""instance="").append(instance != null ? instance.toString() : ""<serialized>"")
-         .append("", serialized="").append(raw != null ?  Util.printArray(raw, false) : ""false"")
+         .append("", serialized="").append(raw != null ?  Util.printArray(raw == null ? Util.EMPTY_BYTE_ARRAY : raw.getRaw(), false) : ""false"")
          .append("", cachedHashCode="").append(cachedHashCode)
          .append(""}@"").append(Util.hexIdHashCode(this));
       return sb.toString();
@@ -321,9 +313,10 @@ public Externalizer(StreamingMarshaller globalMarshaller) {
 
       @Override
       public void writeObject(ObjectOutput output, MarshalledValue mv) throws IOException {
-         byte[] raw = mv.getRaw();
-         UnsignedNumeric.writeUnsignedInt(output, raw.length);
-         output.write(raw);
+         MarshalledValueByteStream raw = mv.getRaw();
+         int rawLength = raw.size();
+         UnsignedNumeric.writeUnsignedInt(output, rawLength);
+         output.write(raw.getRaw(), 0, rawLength);
          output.writeInt(mv.hashCode());
       }
 
@@ -359,6 +352,5 @@ public Integer getId() {
       public Set<Class<? extends MarshalledValue>> getTypeClasses() {
          return Util.<Class<? extends MarshalledValue>>asSet(MarshalledValue.class);
       }
-
    }
 }",2012-05-08T16:12:05Z,78
"@@ -60,6 +60,7 @@ public final class Util {
 
    private static final boolean isArraysDebug = Boolean.getBoolean(""infinispan.arrays.debug"");
    public static final Object[] EMPTY_OBJECT_ARRAY = new Object[0];
+   public static final byte[] EMPTY_BYTE_ARRAY = new byte[0];
 
    /**
     * <p>",2012-05-08T16:12:05Z,79
"@@ -40,7 +40,7 @@
  * @since 4.0
  */
 @NotThreadSafe
-public class ExposedByteArrayOutputStream extends ByteArrayOutputStream {
+public final class ExposedByteArrayOutputStream extends ByteArrayOutputStream {
    /**
     * Default buffer size after which if more buffer capacity is needed the buffer will grow by 25% rather than 100%
     */
@@ -78,7 +78,7 @@ public final byte[] getRawBuffer() {
    }
 
    @Override
-   public void write(byte[] b, int off, int len) {
+   public final void write(byte[] b, int off, int len) {
       if ((off < 0) || (off > b.length) || (len < 0) ||
             ((off + len) > b.length) || ((off + len) < 0)) {
          throw new IndexOutOfBoundsException();
@@ -98,7 +98,7 @@ public void write(byte[] b, int off, int len) {
    }
 
    @Override
-   public void write(int b) {
+   public final void write(int b) {
       int newcount = count + 1;
       if (newcount > buf.length) {
          byte newbuf[] = new byte[getNewBufferSize(buf.length, newcount)];
@@ -130,4 +130,12 @@ public final int getNewBufferSize(int curSize, int minNewSize) {
       else
          return Math.max(curSize + (curSize >> 2), minNewSize);
    }
+   
+   /**
+    * Overriden only to avoid unneeded synchronization
+    */
+   @Override
+   public final int size() {
+      return count;
+   }
 }",2011-05-12T23:30:12Z,75
"@@ -57,6 +57,7 @@
  * @author Manik Surtani (<a href=""mailto:manik@jboss.org"">manik@jboss.org</a>)
  * @author Mircea.Markus@jboss.com
  * @author Galder Zamarreño
+ * @author Sanne Grinovero
  * @see org.infinispan.interceptors.MarshalledValueInterceptor
  * @since 4.0
  */
@@ -87,8 +88,9 @@ public void init(byte[] raw, int cachedHashCode) {
       this.cachedHashCode = cachedHashCode;
    }
 
-   public synchronized void serialize() {
-      if (raw == null) {
+   public synchronized byte[] serialize() {
+      byte[] rawValue = raw;
+      if (rawValue == null) {
          try {
             // Do NOT set instance to null over here, since it may be used elsewhere (e.g., in a cache listener).
             // this will be compacted by the MarshalledValueInterceptor when the call returns.
@@ -99,28 +101,38 @@ public synchronized void serialize() {
             } finally {
                marshaller.finishObjectOutput(out);
             }
-            byte[] buf = baos.getRawBuffer();
-            int length = baos.size();
-            raw = new byte[length];
-            System.arraycopy(buf, 0, raw, 0, length);
+            final byte[] buf = baos.getRawBuffer();
+            final int length = baos.size();
+            if (buf.length == length) {
+               // in this unlikely case we can avoid duplicating the buffer
+               rawValue = buf;
+            }
+            else {
+               rawValue = new byte[length];
+               System.arraycopy(buf, 0, rawValue, 0, length);
+            }
+            raw = rawValue;
          } catch (Exception e) {
             throw new CacheException(""Unable to marshall value "" + instance, e);
-         } finally {
-            
          }
       }
+      return rawValue;
    }
 
-   public synchronized void deserialize() {
-      if (instance == null) {
+   public synchronized Object deserialize() {
+      Object instanceValue = instance;
+      if (instanceValue == null) {
          try {
             // StreamingMarshaller underneath deals with making sure the right classloader is set.
-            instance = marshaller.objectFromByteBuffer(raw);
+            instanceValue = marshaller.objectFromByteBuffer(raw);
+            instance = instanceValue;
+            return instanceValue;
          }
          catch (Exception e) {
             throw new CacheException(""Unable to unmarshall value"", e);
          }
       }
+      return instanceValue;
    }
 
    /**
@@ -136,43 +148,51 @@ public synchronized void deserialize() {
     * @param force                          ensures the preferred representation is maintained and the other released,
     *                                       even if this means serializing or deserializing.
     */
-   public void compact(boolean preferSerializedRepresentation, boolean force) {
+   public synchronized void compact(boolean preferSerializedRepresentation, boolean force) {
       // reset the equalityPreference
       equalityPreferenceForInstance = true;
+      Object thisInstance = this.instance;
+      byte[] thisRaw = this.raw;
       if (force) {
-         if (preferSerializedRepresentation && raw == null) serialize();
-         else if (!preferSerializedRepresentation && instance == null) deserialize();
+         if (preferSerializedRepresentation && thisRaw == null) {
+            thisRaw = serialize();
+         }
+         else if (!preferSerializedRepresentation && thisInstance == null){
+            thisInstance = deserialize();
+         }
       }
 
-      if (instance != null && raw != null) {
-         // need to lose one representation!
-
+      if (thisInstance != null && thisRaw != null) {
+         // need to loose one representation!
          if (preferSerializedRepresentation) {
-            nullifyInstance();
+            //in both branches we first set one then null the other, so that there's always one available
+            //to read from those methods not being synchronized
+            raw = thisRaw;
+            instance = null;
          } else {
+            instance = thisInstance;
             raw = null;
          }
       }
    }
 
-   private synchronized void nullifyInstance() {
-      instance = null;
-   }
-
    public byte[] getRaw() {
-      if (raw == null) serialize();
-      return raw;
+      byte[] rawValue = raw;
+      if (rawValue == null){
+         rawValue = serialize();
+      }
+      return rawValue;
    }
 
    /**
-    * Returns the 'cached' instance. Impl note: this method is synchronized so that it synchronizez with the code that
-    * nullifies the instance.
-    *
-    * @see #nullifyInstance()
+    * Returns the 'cached' instance
     */
-   public synchronized Object get() {
-      if (instance == null) deserialize();
-      return instance;
+   public Object get() {
+      Object value = instance;
+      if (value == null) {
+         value = deserialize();
+      }
+      return value;
    }
 
    @Override
@@ -181,35 +201,54 @@ public boolean equals(Object o) {
       if (o == null || getClass() != o.getClass()) return false;
 
       MarshalledValue that = (MarshalledValue) o;
+      final boolean preferInstanceEquality = equalityPreferenceForInstance && that.equalityPreferenceForInstance;
 
-      // if both versions are serialized or deserialized, just compare the relevant representations.
-      if (raw != null && that.raw != null) return Arrays.equals(raw, that.raw);
-      if (instance != null && that.instance != null) return instance.equals(that.instance);
+      // if both versions are serialized or deserialized, just compare the relevant representations,
+      // but attempt the operations in order to respect the value of equalityPreferenceForInstance
+      Object thisInstance = this.instance;
+      Object thatInstance = that.instance;
+      //test the default equality first so we might skip some work:
+      if (preferInstanceEquality && thisInstance != null && thatInstance != null) return thisInstance.equals(thatInstance);
+      
+      byte[] thisRaw = this.raw;
+      byte[] thatRaw = that.raw;
+      if (thisRaw != null && thatRaw != null) return Arrays.equals(thisRaw, thatRaw);
+      if (thisInstance != null && thatInstance != null) return thisInstance.equals(thatInstance);
 
       // if conversion of one representation to the other is necessary, then see which we prefer converting.
-      if (equalityPreferenceForInstance && that.equalityPreferenceForInstance) {
-         if (instance == null) deserialize();
-         if (that.instance == null) that.deserialize();
-         return instance.equals(that.instance);
+      if (preferInstanceEquality) {
+         if (thisInstance == null) {
+            thisInstance = this.deserialize();
+         }
+         if (thatInstance == null) {
+            thatInstance = that.deserialize();
+         }
+         return thisInstance.equals(thatInstance);
       } else {
-         if (raw == null) serialize();
-         if (that.raw == null) that.serialize();
-         return Arrays.equals(raw, that.raw);
+         if (thisRaw == null) {
+            thisRaw = this.serialize();
+         }
+         if (thatRaw == null) {
+            thatRaw = that.serialize();
+         }
+         return Arrays.equals(thisRaw, thatRaw);
       }
    }
 
    @Override
    public int hashCode() {
-      if (cachedHashCode == 0) {
-         // always calculate the hashcode based on the instance since this is where we're getting the equals()
-         if (instance == null) deserialize();
-         cachedHashCode = instance.hashCode();
-         if (cachedHashCode == 0) // degenerate case
+      //make a local copy to avoid multiple read/writes on the volatile field
+      int value = cachedHashCode;
+      if (value == 0) {
+         Object localInstance = deserialize();
+         value = localInstance.hashCode();
+         if (value == 0) // degenerate case
          {
-            cachedHashCode = 0xFEED;
+            value = 0xFEED;
          }
+         cachedHashCode = value;
       }
-      return cachedHashCode;
+      return value;
    }
 
    @Override
@@ -259,7 +298,7 @@ public void writeObject(ObjectOutput output, MarshalledValue mv) throws IOExcept
       }
 
       @Override
-      public MarshalledValue readObject(ObjectInput input) throws IOException, ClassNotFoundException {
+      public MarshalledValue readObject(ObjectInput input) throws IOException {
          int length = UnsignedNumeric.readUnsignedInt(input);
          byte[] raw = new byte[length];
          input.readFully(raw);",2011-05-12T23:30:12Z,78
"@@ -1,64 +0,0 @@
-/*
- * JBoss, Home of Professional Open Source
- * Copyright 2009 Red Hat Inc. and/or its affiliates and other
- * contributors as indicated by the @author tags. All rights reserved.
- * See the copyright.txt in the distribution for a full listing of
- * individual contributors.
- *
- * This is free software; you can redistribute it and/or modify it
- * under the terms of the GNU Lesser General Public License as
- * published by the Free Software Foundation; either version 2.1 of
- * the License, or (at your option) any later version.
- *
- * This software is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this software; if not, write to the Free
- * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
- * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
- */
-package org.infinispan.loaders.bdbje;
-
-import org.infinispan.loaders.CacheLoaderException;
-import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.marshall.StreamingMarshaller;
-import org.infinispan.test.fwk.TestCacheManagerFactory;
-import org.testng.annotations.AfterClass;
-import org.testng.annotations.AfterMethod;
-import org.testng.annotations.BeforeClass;
-import org.testng.annotations.Test;
-
-import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
-
-/**
- * BdjeCacheStoreIntegrationTest using production level marshaller.
- * 
- * @author Galder Zamarreño
- * @since 4.0
- */
-@Test(groups = ""unit"", enabled = true, testName = ""loaders.bdbje.BdbjeCacheStoreIntegrationVamTest"")
-public class BdbjeCacheStoreIntegrationVamTest extends BdbjeCacheStoreIntegrationTest {
-
-   EmbeddedCacheManager cm;
-   StreamingMarshaller marshaller;
-
-   @BeforeClass(alwaysRun = true)
-   public void setUpClass() {
-      cm = TestCacheManagerFactory.createLocalCacheManager(false);
-      marshaller = extractCacheMarshaller(cm.getCache());
-   }
-
-   @AfterClass(alwaysRun = true)
-   public void tearDownClass() throws CacheLoaderException {
-      cm.stop();
-   }
-
-   @Override
-   protected StreamingMarshaller getMarshaller() {
-      return marshaller;
-   }
-
-}",2012-01-05T15:13:23Z,80
"@@ -27,7 +27,9 @@
 import org.apache.cassandra.config.ConfigurationException;
 import org.apache.thrift.transport.TTransportException;
 import org.infinispan.loaders.BaseCacheStoreTest;
+import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.keymappers.UnsupportedKeyTypeException;
 import org.testng.annotations.AfterClass;
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
@@ -69,4 +71,10 @@ protected CacheStore createCacheStore() throws Exception {
       return cs;
    }
 
+   @Override
+   @Test(expectedExceptions = UnsupportedKeyTypeException.class)
+   public void testLoadAndStoreMarshalledValues() throws CacheLoaderException {
+      super.testLoadAndStoreMarshalledValues();
+   }
+
 }",2012-01-05T15:13:23Z,81
"@@ -24,10 +24,12 @@
 
 import static org.easymock.classextension.EasyMock.*;
 import org.infinispan.loaders.BaseCacheStoreTest;
+import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheStore;
 import org.infinispan.loaders.jdbc.TableManipulation;
 import org.infinispan.loaders.jdbc.connectionfactory.ConnectionFactory;
 import org.infinispan.loaders.jdbc.connectionfactory.ConnectionFactoryConfig;
+import org.infinispan.loaders.keymappers.UnsupportedKeyTypeException;
 import org.infinispan.test.fwk.UnitTestDatabaseManager;
 import org.infinispan.CacheImpl;
 import org.testng.annotations.Test;
@@ -77,4 +79,11 @@ public void testNotCreateConnectionFactory() throws Exception {
       stringBasedCacheStore.stop();
       verify(tableManipulation, connectionFactory);
    }
+
+   @Override
+   @Test(expectedExceptions = UnsupportedKeyTypeException.class)
+   public void testLoadAndStoreMarshalledValues() throws CacheLoaderException {
+      super.testLoadAndStoreMarshalledValues();
+   }
+
 }",2012-01-05T15:13:23Z,82
"@@ -25,12 +25,14 @@
 import org.infinispan.Cache;
 import org.infinispan.CacheImpl;
 import org.infinispan.loaders.CacheLoaderConfig;
+import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheLoaderManager;
 import org.infinispan.loaders.CacheStore;
 import org.infinispan.loaders.jdbc.ManagedConnectionFactoryTest;
 import org.infinispan.loaders.jdbc.TableManipulation;
 import org.infinispan.loaders.jdbc.connectionfactory.ConnectionFactoryConfig;
 import org.infinispan.loaders.jdbc.connectionfactory.ManagedConnectionFactory;
+import org.infinispan.loaders.keymappers.UnsupportedKeyTypeException;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
@@ -80,4 +82,11 @@ public void testLoadFromFile() throws Exception {
    public String getDatasourceLocation() {
       return ""java:/StringStoreWithManagedConnectionTest/DS"";
    }
+
+   @Override
+   @Test(expectedExceptions = UnsupportedKeyTypeException.class)
+   public void testLoadAndStoreMarshalledValues() throws CacheLoaderException {
+      super.testLoadAndStoreMarshalledValues();
+   }
+
 }",2012-01-05T15:13:23Z,83
"@@ -36,6 +36,7 @@
 import java.io.IOException;
 import java.io.ObjectInput;
 import java.io.ObjectOutput;
+import java.io.Serializable;
 import java.util.Arrays;
 import java.util.Set;
 
@@ -56,22 +57,28 @@
  * methods of their keys need to be aware of this.
  * <p />
  *
+ * This class can be marshalled either via its externalizer or via the JVM
+ * serialization.  The reason for supporting both methods is to enable
+ * third-party libraries to be able to marshall/unmarshall them using standard
+ * JVM serialization rules.  The Infinispan marshalling layer will always
+ * chose the most performant one, aka the externalizer method.
+ *
  * @author Manik Surtani (<a href=""mailto:manik@jboss.org"">manik@jboss.org</a>)
  * @author Mircea.Markus@jboss.com
  * @author Galder Zamarreño
  * @author Sanne Grinovero
  * @see org.infinispan.interceptors.MarshalledValueInterceptor
  * @since 4.0
  */
-public class MarshalledValue {
+public class MarshalledValue implements Serializable {
    volatile protected Object instance;
    volatile protected byte[] raw;
    volatile protected int serialisedSize = 128; //size of serialized representation: initial value is a guess
    volatile private int cachedHashCode = 0;
    // by default equals() will test on the instance rather than the byte array if conversion is required.
    private transient volatile boolean equalityPreferenceForInstance = true;
    // A marshaller is needed at construction time to handle equals/hashCode impls
-   private final StreamingMarshaller marshaller;
+   private transient final StreamingMarshaller marshaller;
 
    public MarshalledValue(Object instance, boolean equalityPreferenceForInstance, StreamingMarshaller marshaller) {
       if (instance == null) throw new NullPointerException(""Null values cannot be wrapped as MarshalledValues!"");",2012-01-05T15:13:23Z,78
"@@ -25,6 +25,10 @@
 import org.easymock.EasyMock;
 import org.infinispan.Cache;
 import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.marshall.AbstractDelegatingMarshaller;
+import org.infinispan.marshall.MarshalledValue;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
 import org.infinispan.test.fwk.TestInternalCacheEntryFactory;
 import org.infinispan.io.UnclosableObjectInputStream;
 import org.infinispan.io.UnclosableObjectOutputStream;
@@ -46,6 +50,7 @@
 import java.util.*;
 
 import static java.util.Collections.emptySet;
+import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
 import static org.testng.AssertJUnit.assertEquals;
 
 /**
@@ -718,4 +723,52 @@ public void testReplaceExpiredEntry() throws Exception {
 
       assert null == cs.load(""k1"");
    }
+
+   public void testLoadAndStoreMarshalledValues() throws CacheLoaderException {
+      MarshalledValue key = new MarshalledValue(new Pojo().role(""key""), true, getMarshaller());
+      MarshalledValue key2 = new MarshalledValue(new Pojo().role(""key2""), true, getMarshaller());
+      MarshalledValue value = new MarshalledValue(new Pojo().role(""value""), true, getMarshaller());
+
+      assert !cs.containsKey(key);
+      InternalCacheEntry se = TestInternalCacheEntryFactory.create(key, value);
+      cs.store(se);
+
+      assert cs.load(key).getValue().equals(value);
+      assert cs.load(key).getLifespan() == -1;
+      assert cs.load(key).getMaxIdle() == -1;
+      assert !cs.load(key).isExpired(System.currentTimeMillis());
+      assert cs.containsKey(key);
+
+      boolean removed = cs.remove(key2);
+      assert !removed;
+   }
+
+   public static class Pojo implements Serializable {
+
+      private String role;
+
+      public Pojo role(String role) {
+         this.role = role;
+         return this;
+      }
+
+      @Override
+      public boolean equals(Object o) {
+         if (this == o) return true;
+         if (o == null || getClass() != o.getClass()) return false;
+
+         Pojo pojo = (Pojo) o;
+
+         if (role != null ? !role.equals(pojo.role) : pojo.role != null)
+            return false;
+
+         return true;
+      }
+
+      @Override
+      public int hashCode() {
+         return role != null ? role.hashCode() : 0;
+      }
+   }
+
 }
\ No newline at end of file",2012-01-05T15:13:23Z,84
"@@ -26,8 +26,8 @@
 import org.infinispan.context.impl.NonTxInvocationContext;
 import org.infinispan.context.impl.RemoteTxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
+import org.infinispan.transaction.xa.LocalTransaction;
 import org.infinispan.transaction.xa.TransactionTable;
-import org.infinispan.transaction.xa.TransactionXaAdapter;
 
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
@@ -64,8 +64,8 @@ public InvocationContext createInvocationContext() {
          } else {
             localContext = (LocalTxInvocationContext) existing;
          }
-         TransactionXaAdapter xaAdapter = transactionTable.getXaCacheAdapter(tx);
-         localContext.setXaCache(xaAdapter);
+         LocalTransaction localTransaction = transactionTable.getLocalTransaction(tx);
+         localContext.setLocalTransaction(localTransaction);
          return localContext;
       } else {
          NonTxInvocationContext nonTxContext;",2010-12-09T08:05:14Z,85
"@@ -4,7 +4,7 @@
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.xa.GlobalTransaction;
-import org.infinispan.transaction.xa.TransactionXaAdapter;
+import org.infinispan.transaction.xa.LocalTransaction;
 import org.infinispan.util.BidirectionalMap;
 
 import javax.transaction.Transaction;
@@ -20,10 +20,10 @@
  */
 public class LocalTxInvocationContext extends AbstractTxInvocationContext {
 
-   private volatile TransactionXaAdapter xaAdapter;
+   private volatile LocalTransaction localTransaction;
 
    public Transaction getRunningTransaction() {
-      return xaAdapter.getTransaction();
+      return localTransaction.getTransaction();
    }
 
    public boolean isOriginLocal() {
@@ -35,53 +35,53 @@ public boolean isInTxScope() {
    }
 
    public Object getLockOwner() {
-      return xaAdapter.getGlobalTx();
+      return localTransaction.getGlobalTransaction();
    }
 
    public GlobalTransaction getGlobalTransaction() {
-      return xaAdapter.getGlobalTx();
+      return localTransaction.getGlobalTransaction();
    }
 
    public List<WriteCommand> getModifications() {
-      return xaAdapter == null ? null : xaAdapter.getModifications();
+      return localTransaction == null ? null : localTransaction.getModifications();
    }
 
-   public void setXaCache(TransactionXaAdapter xaAdapter) {
-      this.xaAdapter = xaAdapter;
+   public void setLocalTransaction(LocalTransaction localTransaction) {
+      this.localTransaction = localTransaction;
    }
 
    public CacheEntry lookupEntry(Object key) {
-      return xaAdapter != null ? xaAdapter.lookupEntry(key) : null;
+      return localTransaction != null ? localTransaction.lookupEntry(key) : null;
    }
 
    public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
-      return xaAdapter.getLookedUpEntries();
+      return localTransaction.getLookedUpEntries();
    }
 
    public void putLookedUpEntry(Object key, CacheEntry e) {
-      xaAdapter.putLookedUpEntry(key, e);
+      localTransaction.putLookedUpEntry(key, e);
    }
 
    public void putLookedUpEntries(Map<Object, CacheEntry> lookedUpEntries) {
       for (Map.Entry<Object, CacheEntry> ce: lookedUpEntries.entrySet()) {
-         xaAdapter.putLookedUpEntry(ce.getKey(), ce.getValue());
+         localTransaction.putLookedUpEntry(ce.getKey(), ce.getValue());
       }
    }
 
    public void removeLookedUpEntry(Object key) {
-      xaAdapter.removeLookedUpEntry(key);
+      localTransaction.removeLookedUpEntry(key);
    }
 
    public void clearLookedUpEntries() {
-      xaAdapter.clearLookedUpEntries();
+      localTransaction.clearLookedUpEntries();
    }
 
    @Override
    public boolean hasLockedKey(Object key) {
-      return xaAdapter != null && super.hasLockedKey(key);
+      return localTransaction != null && super.hasLockedKey(key);
    }
 
    public void remoteLocksAcquired(Collection<Address> nodes) {
-      xaAdapter.locksAcquired(nodes);
+      localTransaction.locksAcquired(nodes);
    }
 }",2010-12-09T08:05:14Z,86
"@@ -1,5 +1,7 @@
 package org.infinispan.interceptors;
 
+import org.infinispan.CacheException;
+import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.GetKeyValueCommand;
@@ -16,6 +18,7 @@
 import org.infinispan.config.Configuration;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
+import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
@@ -24,6 +27,7 @@
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.transaction.TransactionLog;
+import org.infinispan.transaction.xa.LocalTransaction;
 import org.infinispan.transaction.xa.TransactionTable;
 import org.infinispan.transaction.xa.TransactionXaAdapter;
 import org.rhq.helpers.pluginAnnotations.agent.DataType;
@@ -61,14 +65,20 @@ public class TxInterceptor extends CommandInterceptor {
    private final AtomicLong rollbacks = new AtomicLong(0);
    @ManagedAttribute(description = ""Enables or disables the gathering of statistics by this component"", writable = true)
    private boolean statisticsEnabled;
+   private CommandsFactory commandsFactory;
+   private InvocationContextContainer icc;
+   private InterceptorChain invoker;
 
 
    @Inject
-   public void init(TransactionManager tm, TransactionTable txTable, TransactionLog transactionLog, Configuration c) {
+   public void init(TransactionManager tm, TransactionTable txTable, TransactionLog transactionLog, Configuration c, CommandsFactory commandsFactory, InvocationContextContainer icc, InterceptorChain invoker) {
       this.configuration = c;
       this.tm = tm;
       this.transactionLog = transactionLog;
       this.txTable = txTable;
+      this.commandsFactory = commandsFactory;
+      this.icc = icc;
+      this.invoker = invoker;
       setStatisticsEnabled(configuration.isExposeJmxStatistics());
    }
 
@@ -152,37 +162,46 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
 
    private Object enlistReadAndInvokeNext(InvocationContext ctx, VisitableCommand command) throws Throwable {
       if (shouldEnlist(ctx)) {
-         TransactionXaAdapter xaAdapter = enlist(ctx);
+         LocalTransaction localTransaction = enlist(ctx);
          LocalTxInvocationContext localTxContext = (LocalTxInvocationContext) ctx;
-         localTxContext.setXaCache(xaAdapter);
+         localTxContext.setLocalTransaction(localTransaction);
       }
       return invokeNextInterceptor(ctx, command);
    }
 
    private Object enlistWriteAndInvokeNext(InvocationContext ctx, WriteCommand command) throws Throwable {
-      TransactionXaAdapter xaAdapter = null;
+      LocalTransaction localTransaction = null;
       boolean shouldAddMod = false;
       if (shouldEnlist(ctx)) {
-         xaAdapter = enlist(ctx);
+         localTransaction = enlist(ctx);
          LocalTxInvocationContext localTxContext = (LocalTxInvocationContext) ctx;
          if (localModeNotForced(ctx)) shouldAddMod = true;
-         localTxContext.setXaCache(xaAdapter);
+         localTxContext.setLocalTransaction(localTransaction);
       }
       Object rv;
       rv = invokeNextInterceptor(ctx, command);
       if (!ctx.isInTxScope())
          transactionLog.logNoTxWrite(command);
-      if (command.isSuccessful() && shouldAddMod) xaAdapter.addModification(command);
+      if (command.isSuccessful() && shouldAddMod) localTransaction.addModification(command);
       return rv;
    }
 
-   public TransactionXaAdapter enlist(InvocationContext ctx) throws SystemException, RollbackException {
+   public LocalTransaction enlist(InvocationContext ctx) throws SystemException, RollbackException {
       Transaction transaction = tm.getTransaction();
       if (transaction == null) throw new IllegalStateException(""This should only be called in an tx scope"");
       int status = transaction.getStatus();
       if (isNotValid(status)) throw new IllegalStateException(""Transaction "" + transaction +
             "" is not in a valid state to be invoking cache operations on."");
-      return txTable.getOrCreateXaAdapter(transaction, ctx);
+      LocalTransaction localTransaction = txTable.getOrCreateLocalTransaction(transaction, ctx);
+      if (!localTransaction.isEnlisted()) { //make sure that you only enlist it once
+         try {
+            transaction.enlistResource(new TransactionXaAdapter(localTransaction, txTable, commandsFactory, configuration, invoker, icc));
+         } catch (Exception e) {
+            log.error(""Failed to enlist TransactionXaAdapter to transaction"");
+            throw new CacheException(e);
+         }
+      }
+      return localTransaction;
    }
 
    private boolean isNotValid(int status) {",2010-12-09T08:05:14Z,87
"@@ -0,0 +1,46 @@
+package org.infinispan.transaction.xa;
+
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.util.BidirectionalLinkedHashMap;
+import org.infinispan.util.BidirectionalMap;
+
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * Base class for local and remote transaction.
+ * Impl note: The aggregated modification list and lookedUpEntries are not instantiated here but in subclasses.
+ * This is done in order to take advantage of the fact that, for remote transactions we already know the size of the
+ * modifications list at creation time.
+ *
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+public abstract class AbstractCacheTransaction implements CacheTransaction {
+
+   protected List<WriteCommand> modifications;
+   protected BidirectionalLinkedHashMap<Object, CacheEntry> lookedUpEntries;
+   protected GlobalTransaction tx;
+
+
+   public GlobalTransaction getGlobalTransaction() {
+      return tx;
+   }
+
+   public List<WriteCommand> getModifications() {
+      return modifications;
+   }
+
+   public void setModifications(WriteCommand[] modifications) {
+      this.modifications = Arrays.asList(modifications);
+   }
+
+   public CacheEntry lookupEntry(Object key) {
+      return lookedUpEntries.get(key);
+   }
+
+   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
+      return lookedUpEntries;
+   }
+}",2010-12-09T08:05:14Z,88
"@@ -0,0 +1,117 @@
+package org.infinispan.transaction.xa;
+
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.util.BidirectionalLinkedHashMap;
+import org.infinispan.util.BidirectionalMap;
+import org.infinispan.util.InfinispanCollections;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+import javax.transaction.Transaction;
+import javax.transaction.xa.Xid;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+/**
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+public class LocalTransaction extends AbstractCacheTransaction {
+
+   private static Log log = LogFactory.getLog(LocalTransaction.class);
+   private static final boolean trace = log.isTraceEnabled();
+
+   private Set<Address> remoteLockedNodes;
+
+   /** mark as volatile as this might be set from the tx thread code on view change*/
+   private volatile boolean isMarkedForRollback;
+
+   private final Transaction transaction;
+   private Xid xid;
+
+   public LocalTransaction(Transaction transaction, GlobalTransaction tx) {
+      super.tx = tx;
+      this.transaction = transaction;
+   }
+
+   public void addModification(WriteCommand mod) {
+      if (trace) log.trace(""Adding modification {0}. Mod list is {1}"", mod, modifications);
+      if (modifications == null) {
+         modifications = new ArrayList<WriteCommand>(8);
+      }
+      modifications.add(mod);
+   }
+
+   public boolean hasRemoteLocksAcquired(List<Address> leavers) {
+      if (log.isTraceEnabled()) {
+         log.trace(""My remote locks: "" + remoteLockedNodes + "", leavers are:"" + leavers);
+      }
+      return (remoteLockedNodes != null) && !Collections.disjoint(remoteLockedNodes, leavers);
+   }
+
+   public void locksAcquired(Collection<Address> nodes) {
+      if (remoteLockedNodes == null) remoteLockedNodes = new HashSet<Address>();
+      remoteLockedNodes.addAll(nodes);
+   }
+
+   public void markForRollback() {
+      isMarkedForRollback = true;
+   }
+
+   public boolean isMarkedForRollback() {
+      return isMarkedForRollback;
+   }
+
+   public Transaction getTransaction() {
+      return transaction;
+   }
+
+   public CacheEntry lookupEntry(Object key) {
+      if (lookedUpEntries == null) return null;
+      return lookedUpEntries.get(key);
+   }
+
+   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
+      return (BidirectionalMap<Object, CacheEntry>)
+            (lookedUpEntries == null ? InfinispanCollections.emptyBidirectionalMap() : lookedUpEntries);
+   }
+
+   public void putLookedUpEntry(Object key, CacheEntry e) {
+      if (lookedUpEntries == null) lookedUpEntries = new BidirectionalLinkedHashMap<Object, CacheEntry>(4);
+      lookedUpEntries.put(key, e);
+   }
+
+   public void removeLookedUpEntry(Object key) {
+      if (lookedUpEntries != null) lookedUpEntries.remove(key);
+   }
+
+   public void clearLookedUpEntries() {
+      if (lookedUpEntries != null) lookedUpEntries.clear();
+   }
+
+   public boolean isReadOnly() {
+      return (modifications == null || modifications.isEmpty()) && (lookedUpEntries == null || lookedUpEntries.isEmpty());
+   }
+
+   public void setXid(Xid xid) {
+      this.xid = xid;
+   }
+
+   public Xid getXid() {
+      return xid;
+   }
+
+   /**
+    * As per the JTA spec, XAResource.start is called on enlistment. That method also sets the xid for this local
+    * transaction.
+    */
+   public boolean isEnlisted() {
+      return xid != null;
+   }
+}",2010-12-09T08:05:14Z,89
"@@ -21,19 +21,12 @@
  * @author Mircea.Markus@jboss.com
  * @since 4.0
  */
-public class RemoteTransaction implements CacheTransaction, Cloneable {
+public class RemoteTransaction extends AbstractCacheTransaction implements Cloneable {
 
    private static Log log = LogFactory.getLog(RemoteTransaction.class);
 
-   private List<WriteCommand> modifications;
-
-   private BidirectionalLinkedHashMap<Object, CacheEntry> lookedUpEntries;
-
-   private GlobalTransaction tx;
-
    private volatile boolean valid = true;
 
-
    public RemoteTransaction(WriteCommand[] modifications, GlobalTransaction tx) {
       this.modifications = modifications == null || modifications.length == 0 ? Collections.<WriteCommand>emptyList() : Arrays.asList(modifications);
       lookedUpEntries = new BidirectionalLinkedHashMap<Object, CacheEntry>(this.modifications.size());
@@ -50,26 +43,6 @@ public void invalidate() {
       valid = false;
    }
 
-   public GlobalTransaction getGlobalTransaction() {
-      return tx;
-   }
-
-   public List<WriteCommand> getModifications() {
-      return modifications;
-   }
-
-   public void setModifications(WriteCommand[] modifications) {
-      this.modifications = Arrays.asList(modifications);
-   }
-
-   public CacheEntry lookupEntry(Object key) {
-      return lookedUpEntries.get(key);
-   }
-
-   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
-      return lookedUpEntries;
-   }
-
    public void putLookedUpEntry(Object key, CacheEntry e) {
       if (valid) {
          if (log.isTraceEnabled()) {",2010-12-09T08:05:14Z,90
"@@ -1,7 +1,5 @@
 package org.infinispan.transaction.xa;
 
-import org.infinispan.CacheException;
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.tx.RollbackCommand;
 import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.config.Configuration;
@@ -23,6 +21,7 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.Transaction;
+import javax.transaction.xa.Xid;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -46,13 +45,14 @@ public class TransactionTable {
    private static final Log log = LogFactory.getLog(TransactionTable.class);
    private static boolean trace = log.isTraceEnabled();
 
-   private final Map<Transaction, TransactionXaAdapter> localTransactions = new ConcurrentHashMap<Transaction, TransactionXaAdapter>();
+   private final Map<Transaction, LocalTransaction> localTransactions = new ConcurrentHashMap<Transaction, LocalTransaction>();
 
    private final Map<GlobalTransaction, RemoteTransaction> remoteTransactions = new ConcurrentHashMap<GlobalTransaction, RemoteTransaction>();
 
+   private final Map<Xid, LocalTransaction> xid2LocalTx = new ConcurrentHashMap<Xid, LocalTransaction>();
+
    private final Object listener = new StaleTransactionCleanup();
    
-   private CommandsFactory commandsFactory;
    private Configuration configuration;
    private InvocationContextContainer icc;
    private InterceptorChain invoker;
@@ -63,10 +63,9 @@ public class TransactionTable {
    private EmbeddedCacheManager cm;
 
    @Inject
-   public void initialize(CommandsFactory commandsFactory, RpcManager rpcManager, Configuration configuration,
+   public void initialize(RpcManager rpcManager, Configuration configuration,
                           InvocationContextContainer icc, InterceptorChain invoker, CacheNotifier notifier,
                           GlobalTransactionFactory gtf, EmbeddedCacheManager cm) {
-      this.commandsFactory = commandsFactory;
       this.rpcManager = rpcManager;
       this.configuration = configuration;
       this.icc = icc;
@@ -94,6 +93,15 @@ public Set<Object> getLockedKeysForRemoteTransaction(GlobalTransaction gtx) {
       return transaction.getLockedKeys();
    }
 
+   public LocalTransaction getLocalTransaction(Xid xid) {
+      return this.xid2LocalTx.get(xid);
+   }
+
+   public void addLocalTransactionMapping(LocalTransaction localTransaction) {
+      if (localTransaction.getXid() == null) throw new IllegalStateException(""Initialize xid first!"");
+      this.xid2LocalTx.put(localTransaction.getXid(), localTransaction);
+   }
+
    @Listener
    public class StaleTransactionCleanup {
       @ViewChanged
@@ -103,9 +111,9 @@ public void onViewChange(ViewChangedEvent vce) {
             if (trace) log.trace(""Saw {0} leavers - kicking off a lock breaking task"", leavers.size());
             cleanTxForWhichTheOwnerLeft(leavers);
             if (configuration.isUseEagerLocking() && configuration.isEagerLockSingleNode() && configuration.getCacheMode().isDistributed()) {
-               for (TransactionXaAdapter xaAdapter : localTransactions.values()) {
-                  if (xaAdapter.hasRemoteLocksAcquired(leavers)) {
-                     xaAdapter.markForRollback();
+               for (LocalTransaction localTx : localTransactions.values()) {
+                  if (localTx.hasRemoteLocksAcquired(leavers)) {
+                     localTx.markForRollback();
                   }
                }
             }
@@ -198,20 +206,14 @@ private void registerRemoteTransaction(GlobalTransaction gtx, RemoteTransaction
     * Returns the {@link org.infinispan.transaction.xa.TransactionXaAdapter} corresponding to the supplied transaction.
     * If none exists, will be created first.
     */
-   public TransactionXaAdapter getOrCreateXaAdapter(Transaction transaction, InvocationContext ctx) {
-      TransactionXaAdapter current = localTransactions.get(transaction);
+   public LocalTransaction getOrCreateLocalTransaction(Transaction transaction, InvocationContext ctx) {
+      LocalTransaction current = localTransactions.get(transaction);
       if (current == null) {
          Address localAddress = rpcManager != null ? rpcManager.getTransport().getAddress() : null;
          GlobalTransaction tx = gtf.newGlobalTransaction(localAddress, false);
          if (trace) log.trace(""Created a new GlobalTransaction {0}"", tx);
-         current = new TransactionXaAdapter(tx, icc, invoker, commandsFactory, configuration, this, transaction);
+         current = new LocalTransaction(transaction, tx);
          localTransactions.put(transaction, current);
-         try {
-            transaction.enlistResource(current);
-         } catch (Exception e) {
-            log.error(""Failed to enlist TransactionXaAdapter to transaction"");
-            throw new CacheException(e);
-         }
          notifier.notifyTransactionRegistered(tx, ctx);
       }
       return current;
@@ -221,8 +223,9 @@ public TransactionXaAdapter getOrCreateXaAdapter(Transaction transaction, Invoca
     * Removes the {@link org.infinispan.transaction.xa.TransactionXaAdapter} corresponding to the given tx. Returns true
     * if such an tx exists.
     */
-   public boolean removeLocalTransaction(Transaction tx) {
-      return localTransactions.remove(tx) != null;
+   public boolean removeLocalTransaction(LocalTransaction localTransaction) {
+      xid2LocalTx.remove(localTransaction.getXid());
+      return localTransactions.remove(localTransaction.getTransaction()) != null;
    }
 
    /**
@@ -245,13 +248,11 @@ public int getLocalTxCount() {
       return localTransactions.size();
    }
 
-   public TransactionXaAdapter getXaCacheAdapter(Transaction tx) {
+   public LocalTransaction getLocalTransaction(Transaction tx) {
       return localTransactions.get(tx);
    }
 
    public boolean containRemoteTx(GlobalTransaction globalTransaction) {
       return remoteTransactions.containsKey(globalTransaction);
    }
-
-
 }",2010-12-09T08:05:14Z,91
"@@ -4,29 +4,16 @@
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.tx.RollbackCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.config.Configuration;
-import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.interceptors.InterceptorChain;
-import org.infinispan.remoting.transport.Address;
-import org.infinispan.util.BidirectionalLinkedHashMap;
-import org.infinispan.util.BidirectionalMap;
-import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import javax.transaction.Transaction;
 import javax.transaction.xa.XAException;
 import javax.transaction.xa.XAResource;
 import javax.transaction.xa.Xid;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
 
 /**
  * This acts both as an local {@link org.infinispan.transaction.xa.CacheTransaction} and implementor of an {@link
@@ -35,91 +22,94 @@
  * @author Mircea.Markus@jboss.com
  * @since 4.0
  */
-public class TransactionXaAdapter implements CacheTransaction, XAResource {
+public class TransactionXaAdapter implements XAResource {
 
    private static final Log log = LogFactory.getLog(TransactionXaAdapter.class);
    private static boolean trace = log.isTraceEnabled();
 
    private int txTimeout;
 
-   private volatile List<WriteCommand> modifications;
-   private BidirectionalMap<Object, CacheEntry> lookedUpEntries;
+   private final InvocationContextContainer icc;
+   private final InterceptorChain invoker;
 
-   private GlobalTransaction globalTx;
-   private InvocationContextContainer icc;
-   private InterceptorChain invoker;
+   private final CommandsFactory commandsFactory;
+   private final Configuration configuration;
 
-   private CommandsFactory commandsFactory;
-   private Configuration configuration;
+   private final TransactionTable txTable;
 
-   private TransactionTable txTable;
-   private Transaction transaction;
+   /**
+    * XAResource is associated with a transaction between enlistment (XAResource.start()) XAResource.end(). It's only the
+    * boundary methods (prepare, commit, rollback) that need to be ""stateless"".
+    * Reefer to section 3.4.4 from JTA spec v.1.1
+    */
+   private final LocalTransaction localTransaction;
 
-   private Set<Address> remoteLockedNodes;
-   private boolean isMarkedForRollback;
 
-
-   public TransactionXaAdapter(GlobalTransaction globalTx, InvocationContextContainer icc, InterceptorChain invoker,
-                               CommandsFactory commandsFactory, Configuration configuration, TransactionTable txTable,
-                               Transaction transaction) {
-      this.globalTx = globalTx;
-      this.icc = icc;
-      this.invoker = invoker;
+   public TransactionXaAdapter(LocalTransaction localTransaction, TransactionTable txTable, CommandsFactory commandsFactory,
+                               Configuration configuration, InterceptorChain invoker, InvocationContextContainer icc) {
+      this.localTransaction = localTransaction;
+      this.txTable = txTable;
       this.commandsFactory = commandsFactory;
       this.configuration = configuration;
-      this.txTable = txTable;
-      this.transaction = transaction;
-   }
-
-   public void addModification(WriteCommand mod) {
-      if (trace) log.trace(""Adding modification {0}. Mod list is {1}"", mod, modifications);
-      if (modifications == null) {
-         modifications = new ArrayList<WriteCommand>(8);
-      }
-      modifications.add(mod);
+      this.invoker = invoker;
+      this.icc = icc;
    }
 
+   /**
+    * This can be call for any transaction object. See Section 3.4.6 (Resource Sharing) from JTA spec v1.1.
+    */
    public int prepare(Xid xid) throws XAException {
-      checkMarkedForRollback();
+      LocalTransaction localTransaction = getLocalTransactionAndValidate(xid);
+      
+      validateNotMarkedForRollback(localTransaction);
+
       if (configuration.isOnePhaseCommit()) {
-         if (trace)
-            log.trace(""Received prepare for tx: "" + xid + "" . Skipping call as 1PC will be used."");
+         if (trace) log.trace(""Received prepare for tx: {0}. Skipping call as 1PC will be used."", xid);
          return XA_OK;
       }
 
-      PrepareCommand prepareCommand = commandsFactory.buildPrepareCommand(globalTx, modifications, configuration.isOnePhaseCommit());
+      PrepareCommand prepareCommand = commandsFactory.buildPrepareCommand(localTransaction.getGlobalTransaction(), localTransaction.getModifications(), configuration.isOnePhaseCommit());
       if (trace) log.trace(""Sending prepare command through the chain: "" + prepareCommand);
 
       LocalTxInvocationContext ctx = icc.createTxInvocationContext();
-      ctx.setXaCache(this);
+      ctx.setLocalTransaction(localTransaction);
       try {
          invoker.invoke(ctx, prepareCommand);
-         return XA_OK;
+         if (localTransaction.isReadOnly()) {
+            if (trace) log.trace(""Readonly transaction: "" + localTransaction.getGlobalTransaction());
+            return XA_RDONLY;
+         } else {
+            return XA_OK;
+         }
       } catch (Throwable e) {
          log.error(""Error while processing PrepareCommand"", e);
          throw new XAException(XAException.XAER_RMERR);
       }
    }
 
+   /**
+    * Same comment as for {@link #prepare(javax.transaction.xa.Xid)} applies for commit.
+    */
    public void commit(Xid xid, boolean isOnePhase) throws XAException {
-      // always call prepare() - even if this is just a 1PC!
-      if (isOnePhase) prepare(xid);
-      if (trace) log.trace(""committing transaction: "" + globalTx);
+      LocalTransaction localTransaction = getLocalTransactionAndValidate(xid);
+
+      if (trace) log.trace(""committing transaction {0}"" + localTransaction.getGlobalTransaction());
       try {
          LocalTxInvocationContext ctx = icc.createTxInvocationContext();
-         ctx.setXaCache(this);
-         if (configuration.isOnePhaseCommit()) {
-            checkMarkedForRollback();
+         ctx.setLocalTransaction(localTransaction);
+         if (configuration.isOnePhaseCommit() || isOnePhase) {
+            validateNotMarkedForRollback(localTransaction);
+
             if (trace) log.trace(""Doing an 1PC prepare call on the interceptor chain"");
-            PrepareCommand command = commandsFactory.buildPrepareCommand(globalTx, modifications, true);
+            PrepareCommand command = commandsFactory.buildPrepareCommand(localTransaction.getGlobalTransaction(), localTransaction.getModifications(), true);
             try {
                invoker.invoke(ctx, command);
             } catch (Throwable e) {
                log.error(""Error while processing 1PC PrepareCommand"", e);
                throw new XAException(XAException.XAER_RMERR);
             }
          } else {
-            CommitCommand commitCommand = commandsFactory.buildCommitCommand(globalTx);
+            CommitCommand commitCommand = commandsFactory.buildCommitCommand(localTransaction.getGlobalTransaction());
             try {
                invoker.invoke(ctx, commitCommand);
             } catch (Throwable e) {
@@ -128,35 +118,46 @@ public void commit(Xid xid, boolean isOnePhase) throws XAException {
             }
          }
       } finally {
-         txTable.removeLocalTransaction(transaction);
-         icc.suspend();
-         this.modifications = null;
+         cleanup(localTransaction);
       }
    }
 
-   public void rollback(Xid xid) throws XAException {
-      if (trace) log.trace(""rollback transaction: "" + globalTx);
-      RollbackCommand rollbackCommand = commandsFactory.buildRollbackCommand(globalTx);
+   /**
+    * Same comment as for {@link #prepare(javax.transaction.xa.Xid)} applies for commit.
+    */   
+   public void rollback(Xid xid) throws XAException {      
+      LocalTransaction localTransaction = getLocalTransactionAndValidate(xid);
+      if (trace) log.trace(""rollback transaction {0} "", localTransaction.getGlobalTransaction());
+      RollbackCommand rollbackCommand = commandsFactory.buildRollbackCommand(localTransaction.getGlobalTransaction());
       LocalTxInvocationContext ctx = icc.createTxInvocationContext();
-      ctx.setXaCache(this);
+      ctx.setLocalTransaction(localTransaction);
       try {
          invoker.invoke(ctx, rollbackCommand);
       } catch (Throwable e) {
          log.error(""Exception while rollback"", e);
          throw new XAException(XAException.XA_HEURHAZ);
       } finally {
-         txTable.removeLocalTransaction(transaction);
-         icc.suspend();
-         this.modifications = null;
+         cleanup(localTransaction);
+      }
+   }
+
+   private LocalTransaction getLocalTransactionAndValidate(Xid xid) throws XAException {
+      LocalTransaction localTransaction = txTable.getLocalTransaction(xid);
+      if  (localTransaction == null) {
+         if (trace) log.trace(""no tx found for {0}"", xid);
+         throw new XAException(XAException.XAER_NOTA);
       }
+      return localTransaction;
    }
 
    public void start(Xid xid, int i) throws XAException {
-      if (trace) log.trace(""start called on tx "" + this.globalTx);
+      localTransaction.setXid(xid);
+      txTable.addLocalTransactionMapping(localTransaction);
+      if (trace) log.trace(""start called on tx "" + this.localTransaction.getGlobalTransaction());
    }
 
    public void end(Xid xid, int i) throws XAException {
-      if (trace) log.trace(""end called on tx "" + this.globalTx);
+      if (trace) log.trace(""end called on tx "" + this.localTransaction.getGlobalTransaction());
    }
 
    public void forget(Xid xid) throws XAException {
@@ -186,95 +187,35 @@ public boolean setTransactionTimeout(int i) throws XAException {
       return true;
    }
 
-   public CacheEntry lookupEntry(Object key) {
-      if (lookedUpEntries == null) return null;
-      return lookedUpEntries.get(key);
-   }
-
-   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
-      return (BidirectionalMap<Object, CacheEntry>)
-            (lookedUpEntries == null ? InfinispanCollections.emptyBidirectionalMap() : lookedUpEntries);
-   }
-
-   public void putLookedUpEntry(Object key, CacheEntry e) {
-      initLookedUpEntries();
-      lookedUpEntries.put(key, e);
-   }
-
-   private void initLookedUpEntries() {
-      if (lookedUpEntries == null) lookedUpEntries = new BidirectionalLinkedHashMap<Object, CacheEntry>(4);
-   }
-
-   public GlobalTransaction getGlobalTx() {
-      return globalTx;
-   }
-
-   public List<WriteCommand> getModifications() {
-      if (trace) log.trace(""Retrieving modification list {0}."", modifications);
-      return modifications;
-   }
-
-   public Transaction getTransaction() {
-      return transaction;
-   }
-
-   public GlobalTransaction getGlobalTransaction() {
-      return globalTx;
-   }
-
-   public void removeLookedUpEntry(Object key) {
-      if (lookedUpEntries != null) lookedUpEntries.remove(key);
-   }
-
-   public void clearLookedUpEntries() {
-      if (lookedUpEntries != null) lookedUpEntries.clear();
-   }
-
    @Override
    public boolean equals(Object o) {
       if (this == o) return true;
       if (!(o instanceof TransactionXaAdapter)) return false;
-
       TransactionXaAdapter that = (TransactionXaAdapter) o;
-
-      if (!globalTx.equals(that.globalTx)) return false;
-
-      return true;
+      return this.localTransaction.equals(that.localTransaction);
    }
 
    @Override
    public int hashCode() {
-      return globalTx.hashCode();
+      return localTransaction.getGlobalTransaction().hashCode();
    }
 
    @Override
    public String toString() {
       return ""TransactionXaAdapter{"" +
-            ""modifications="" + modifications +
-            "", lookedUpEntries="" + lookedUpEntries +
-            "", globalTx="" + globalTx +
-            "", transaction="" + transaction +
-            "", txTimeout="" + txTimeout +
+            ""localTransaction="" + localTransaction +
             '}';
    }
 
-   public boolean hasRemoteLocksAcquired(List<Address> leavers) {
-      if (log.isTraceEnabled()) {
-         log.trace(""My remote locks: "" + remoteLockedNodes + "", leavers are:"" + leavers);
+   private void validateNotMarkedForRollback(LocalTransaction localTransaction) throws XAException {
+      if (localTransaction.isMarkedForRollback()) {
+         if (trace) log.trace(""Transaction already marked for rollback: {0}"", localTransaction);
+         throw new XAException(XAException.XA_RBROLLBACK);
       }
-      return (remoteLockedNodes != null) && !Collections.disjoint(remoteLockedNodes, leavers);
-   }
-
-   public void locksAcquired(Collection<Address> nodes) {
-      if (remoteLockedNodes == null) remoteLockedNodes = new HashSet<Address>();
-      remoteLockedNodes.addAll(nodes);
-   }
-
-   public void markForRollback() {
-      isMarkedForRollback = true;
    }
 
-   private void checkMarkedForRollback() throws XAException {
-      if (isMarkedForRollback) throw new XAException(XAException.XA_RBOTHER);
+   private void cleanup(LocalTransaction localTransaction) {
+      txTable.removeLocalTransaction(localTransaction);
+      icc.suspend();
    }   
 }",2010-12-09T08:05:14Z,92
"@@ -0,0 +1,61 @@
+package org.infinispan.tx;
+
+import org.infinispan.config.Configuration;
+import org.infinispan.context.Flag;
+import org.infinispan.manager.DefaultCacheManager;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.SingleCacheManagerTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.transaction.xa.LocalTransaction;
+import org.infinispan.transaction.xa.TransactionTable;
+import org.testng.annotations.Test;
+
+import javax.transaction.Transaction;
+
+/**
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+@Test (groups = ""functional"", testName = ""tx.ReadOnlyTxTest"")
+@CleanupAfterMethod
+public class ReadOnlyTxTest extends SingleCacheManagerTest {
+
+   @Override
+   protected EmbeddedCacheManager createCacheManager() throws Exception {
+      Configuration configuration = getDefaultClusteredConfig(Configuration.CacheMode.LOCAL, true);
+      return new DefaultCacheManager(configuration);
+   }
+
+   public void testSimpleReadOnlTx() throws Exception {
+      tm().begin();
+      assert cache.get(""k"") == null;
+      Transaction transaction = tm().suspend();
+      LocalTransaction localTransaction = txTable().getLocalTransaction(transaction);
+      assert localTransaction != null && localTransaction.isReadOnly();
+   }
+
+   public void testNotROWhenHasWrites() throws Exception {
+      tm().begin();
+      cache.put(""k"", ""v"");
+      assert TestingUtil.extractLockManager(cache).isLocked(""k"");
+      Transaction transaction = tm().suspend();
+      LocalTransaction localTransaction = txTable().getLocalTransaction(transaction);
+      assert localTransaction != null && !localTransaction.isReadOnly();
+   }
+
+   public void testNotROWhenHasOnlyLocks() throws Exception {
+      cache.put(""k"", ""v"");
+      tm().begin();
+      cache.getAdvancedCache().withFlags(Flag.FORCE_WRITE_LOCK).get(""k"");
+      assert TestingUtil.extractLockManager(cache).isLocked(""k"");
+      Transaction transaction = tm().suspend();
+      LocalTransaction localTransaction = txTable().getLocalTransaction(transaction);
+      assert localTransaction != null && !localTransaction.isReadOnly();
+   }
+
+
+   private TransactionTable txTable() {
+      return TestingUtil.getTransactionTable(cache);
+   }
+}",2010-12-09T08:05:14Z,93
"@@ -0,0 +1,110 @@
+package org.infinispan.tx;
+
+import org.infinispan.config.Configuration;
+import org.infinispan.transaction.tm.DummyTransaction;
+import org.infinispan.transaction.tm.DummyXid;
+import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.transaction.xa.GlobalTransactionFactory;
+import org.infinispan.transaction.xa.LocalTransaction;
+import org.infinispan.transaction.xa.TransactionTable;
+import org.infinispan.transaction.xa.TransactionXaAdapter;
+import org.testng.annotations.BeforeMethod;
+import org.testng.annotations.Test;
+
+import javax.transaction.xa.XAException;
+import javax.transaction.xa.XAResource;
+
+/**
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+@Test(testName = ""tx.TransactionXaAdapterTest"", groups = ""unit"")
+public class TransactionXaAdapterTmIntegrationTest {
+   private Configuration configuration;
+   private TransactionTable txTable;
+   private GlobalTransaction globalTransaction;
+   private LocalTransaction localTx;
+   private TransactionXaAdapter xaAdapter;
+   private DummyXid xid;
+
+   @BeforeMethod
+   public void setUp() {
+      txTable = new TransactionTable();
+      GlobalTransactionFactory gtf = new GlobalTransactionFactory();
+      globalTransaction = gtf.newGlobalTransaction(null, false);
+      localTx = new LocalTransaction(new DummyTransaction(null), globalTransaction);
+      xid = new DummyXid();
+      localTx.setXid(xid);
+      txTable.addLocalTransactionMapping(localTx);      
+
+      configuration = new Configuration();
+      xaAdapter = new TransactionXaAdapter(localTx, txTable, null, configuration, null, null);
+   }
+
+   public void testPrepareOnNonexistentXid() {
+      DummyXid xid = new DummyXid();
+      try {
+         xaAdapter.prepare(xid);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void testCommitOnNonexistentXid() {
+      DummyXid xid = new DummyXid();
+      try {
+         xaAdapter.commit(xid, false);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void testRollabckOnNonexistentXid() {
+      DummyXid xid = new DummyXid();
+      try {
+         xaAdapter.rollback(xid);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void testPrepareTxMarkedForRollback() {
+      localTx.markForRollback();
+      try {
+         xaAdapter.prepare(xid);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XA_RBROLLBACK;
+      }
+   }
+
+   public void testOnePhaseCommitConfigured() throws XAException {
+      configuration.setCacheMode(Configuration.CacheMode.INVALIDATION_ASYNC);//this would force 1pc
+      assert XAResource.XA_OK == xaAdapter.prepare(xid);
+   }
+
+   public void test1PcAndNonExistentXid() {
+      configuration.setCacheMode(Configuration.CacheMode.INVALIDATION_ASYNC);
+      try {
+         DummyXid doesNotExists = new DummyXid();
+         xaAdapter.commit(doesNotExists, false);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void test1PcAndNonExistentXid2() {
+      configuration.setCacheMode(Configuration.CacheMode.DIST_SYNC);
+      try {
+         DummyXid doesNotExists = new DummyXid();
+         xaAdapter.commit(doesNotExists, true);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+}",2010-12-09T08:05:14Z,94
"@@ -8,11 +8,11 @@
 import org.infinispan.factories.ComponentRegistry;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.util.concurrent.NotifyingFuture;
 
 import java.util.Collection;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
 /**
@@ -130,51 +130,51 @@ public boolean replace(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, lo
       return cache.replace(k, oV, nV, lifespan, lifespanUnit, maxIdle, maxIdleUnit, flags);
    }
 
-   public Future<V> putAsync(K key, V value, Flag... flags) {
+   public NotifyingFuture<V> putAsync(K key, V value, Flag... flags) {
       return cache.putAsync(key, value, flags);
    }
 
-   public Future<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
+   public NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
       return cache.putAsync(key, value, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
    }
 
-   public Future<V> putIfAbsentAsync(K key, V value, Flag... flags) {
+   public NotifyingFuture<V> putIfAbsentAsync(K key, V value, Flag... flags) {
       return cache.putIfAbsentAsync(key, value, flags);
    }
 
-   public Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
+   public NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
       return cache.putIfAbsentAsync(key, value, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
    }
 
-   public Future<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags) {
+   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags) {
       return cache.putAllAsync(map, flags);
    }
 
-   public Future<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
+   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
       return cache.putAllAsync(map, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
    }
 
-   public Future<V> removeAsync(Object key, Flag... flags) {
+   public NotifyingFuture<V> removeAsync(Object key, Flag... flags) {
       return cache.removeAsync(key, flags);
    }
 
-   public Future<Void> clearAsync(Flag... flags) {
+   public NotifyingFuture<Void> clearAsync(Flag... flags) {
       return cache.clearAsync(flags);
    }
 
-   public Future<V> replaceAsync(K k, V v, Flag... flags) {
+   public NotifyingFuture<V> replaceAsync(K k, V v, Flag... flags) {
       return cache.replaceAsync(k, v, flags);
    }
 
-   public Future<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags) {
+   public NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags) {
       return cache.replaceAsync(k, oV, nV, flags);
    }
 
-   public Future<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
+   public NotifyingFuture<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
       return cache.replaceAsync(k, v, lifespan, lifespanUnit, maxIdle, maxIdleUnit, flags);
    }
 
-   public Future<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
+   public NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
       return cache.replaceAsync(k, oV, nV, lifespan, lifespanUnit, maxIdle, maxIdleUnit, flags);
    }
 
@@ -186,78 +186,6 @@ public V get(Object key, Flag... flags) {
       return cache.get(key, flags);
    }
 
-   public Future<V> putAsync(K key, V value) {
-      return cache.putAsync(key, value);
-   }
-
-   public Future<V> putAsync(K key, V value, long lifespan, TimeUnit unit) {
-      return cache.putAsync(key, value, lifespan, unit);
-   }
-
-   public Future<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return cache.putAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
-   }
-
-   public Future<Void> putAllAsync(Map<? extends K, ? extends V> data) {
-      return cache.putAllAsync(data);
-   }
-
-   public Future<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit unit) {
-      return cache.putAllAsync(data, lifespan, unit);
-   }
-
-   public Future<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return cache.putAllAsync(data, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
-   }
-
-   public Future<Void> clearAsync() {
-      return cache.clearAsync();
-   }
-
-   public Future<V> putIfAbsentAsync(K key, V value) {
-      return cache.putIfAbsentAsync(key, value);
-   }
-
-   public Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit unit) {
-      return cache.putIfAbsentAsync(key, value, lifespan, unit);
-   }
-
-   public Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return cache.putIfAbsentAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
-   }
-
-   public Future<V> removeAsync(Object key) {
-      return cache.removeAsync(key);
-   }
-
-   public Future<Boolean> removeAsync(Object key, Object value) {
-      return cache.removeAsync(key, value);
-   }
-
-   public Future<V> replaceAsync(K key, V value) {
-      return cache.replaceAsync(key, value);
-   }
-
-   public Future<V> replaceAsync(K key, V value, long lifespan, TimeUnit unit) {
-      return cache.replaceAsync(key, value, lifespan, unit);
-   }
-
-   public Future<V> replaceAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return cache.replaceAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
-   }
-
-   public Future<Boolean> replaceAsync(K key, V oldValue, V newValue) {
-      return cache.replaceAsync(key, oldValue, newValue);
-   }
-
-   public Future<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit unit) {
-      return cache.replaceAsync(key, oldValue, newValue, lifespan, unit);
-   }
-
-   public Future<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return cache.replaceAsync(key, oldValue, newValue, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
-   }
-
    public void lock(K key) {
       cache.lock(key);
    }",2009-05-20T15:18:23Z,95
"@@ -3,22 +3,23 @@
 import org.infinispan.config.Configuration;
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.manager.CacheManager;
+import org.infinispan.util.concurrent.NotifyingFuture;
 
 import java.util.Collection;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
-/**                                                                 
- * This is a convenient base class for implementing a cache delegate. The only constructor takes a {@link Cache} argument, to
- * which each method call is delegated. One can extend this class and override the method sub-set it is interested in.
- * There is also an similar implmentation for {@link org.infinispan.AdvancedCache}:
- * {@link org.infinispan.AbstractDelegatingAdvancedCache}.
+/**
+ * This is a convenient base class for implementing a cache delegate. The only constructor takes a {@link Cache}
+ * argument, to which each method call is delegated. One can extend this class and override the method sub-set it is
+ * interested in. There is also an similar implmentation for {@link org.infinispan.AdvancedCache}: {@link
+ * org.infinispan.AbstractDelegatingAdvancedCache}.
  *
- * @see org.infinispan.AbstractDelegatingAdvancedCache
  * @author Mircea.Markus@jboss.com
+ * @see org.infinispan.AbstractDelegatingAdvancedCache
  */
-public abstract class AbstractDelegatingCache<K, V> implements Cache<K, V> {
+public class AbstractDelegatingCache<K, V> implements Cache<K, V> {
 
    private Cache<K, V> cache;
 
@@ -98,6 +99,78 @@ public boolean replace(K key, V oldValue, V value, long lifespan, TimeUnit lifes
       return cache.replace(key, oldValue, value, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit);
    }
 
+   public NotifyingFuture<V> putAsync(K key, V value) {
+      return cache.putAsync(key, value);
+   }
+
+   public NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit unit) {
+      return cache.putAsync(key, value, lifespan, unit);
+   }
+
+   public NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
+      return cache.putAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
+   }
+
+   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data) {
+      return cache.putAllAsync(data);
+   }
+
+   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit unit) {
+      return cache.putAllAsync(data, lifespan, unit);
+   }
+
+   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
+      return cache.putAllAsync(data, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
+   }
+
+   public NotifyingFuture<Void> clearAsync() {
+      return cache.clearAsync();
+   }
+
+   public NotifyingFuture<V> putIfAbsentAsync(K key, V value) {
+      return cache.putIfAbsentAsync(key, value);
+   }
+
+   public NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit unit) {
+      return cache.putIfAbsentAsync(key, value, lifespan, unit);
+   }
+
+   public NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
+      return cache.putIfAbsentAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
+   }
+
+   public NotifyingFuture<V> removeAsync(Object key) {
+      return cache.removeAsync(key);
+   }
+
+   public NotifyingFuture<Boolean> removeAsync(Object key, Object value) {
+      return cache.removeAsync(key, value);
+   }
+
+   public NotifyingFuture<V> replaceAsync(K key, V value) {
+      return cache.replaceAsync(key, value);
+   }
+
+   public NotifyingFuture<V> replaceAsync(K key, V value, long lifespan, TimeUnit unit) {
+      return cache.replaceAsync(key, value, lifespan, unit);
+   }
+
+   public NotifyingFuture<V> replaceAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
+      return cache.replaceAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
+   }
+
+   public NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue) {
+      return cache.replaceAsync(key, oldValue, newValue);
+   }
+
+   public NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit unit) {
+      return cache.replaceAsync(key, oldValue, newValue, lifespan, unit);
+   }
+
+   public NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
+      return cache.replaceAsync(key, oldValue, newValue, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
+   }
+
    public AdvancedCache<K, V> getAdvancedCache() {
       return cache.getAdvancedCache();
    }",2009-05-20T15:18:23Z,96
"@@ -8,11 +8,11 @@
 import org.infinispan.factories.ComponentRegistry;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.util.concurrent.NotifyingFuture;
 
 import java.util.Collection;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
 /**
@@ -123,29 +123,29 @@ public interface AdvancedCache<K, V> extends Cache<K, V> {
 
 
    // -- async methods --
-   Future<V> putAsync(K key, V value, Flag... flags);
+   NotifyingFuture<V> putAsync(K key, V value, Flag... flags);
 
-   Future<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
+   NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
 
-   Future<V> putIfAbsentAsync(K key, V value, Flag... flags);
+   NotifyingFuture<V> putIfAbsentAsync(K key, V value, Flag... flags);
 
-   Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
+   NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
 
-   Future<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags);
+   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags);
 
-   Future<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
+   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
 
-   Future<V> removeAsync(Object key, Flag... flags);
+   NotifyingFuture<V> removeAsync(Object key, Flag... flags);
 
-   Future<Void> clearAsync(Flag... flags);
+   NotifyingFuture<Void> clearAsync(Flag... flags);
 
-   Future<V> replaceAsync(K k, V v, Flag... flags);
+   NotifyingFuture<V> replaceAsync(K k, V v, Flag... flags);
 
-   Future<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags);
+   NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags);
 
-   Future<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
+   NotifyingFuture<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
 
-   Future<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
+   NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
 
    boolean containsKey(Object key, Flag... flags);
 ",2009-05-20T15:18:23Z,97
"@@ -1,44 +0,0 @@
-package org.infinispan;
-
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.Future;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.TimeoutException;
-
-/**
- * Wraps up return values for the asunc API
- *
- * @author Manik Surtani
- * @since 4.0
- */
-public class AsyncReturnValue implements Future<Object> {
-   final Future<Object> networkCallFuture;
-   final Object actualReturnValue;
-
-   public AsyncReturnValue(Future<Object> networkCallFuture, Object actualReturnValue) {
-      this.networkCallFuture = networkCallFuture;
-      this.actualReturnValue = actualReturnValue;
-   }
-
-   public boolean cancel(boolean mayInterruptIfRunning) {
-      return networkCallFuture.cancel(mayInterruptIfRunning);
-   }
-
-   public boolean isCancelled() {
-      return networkCallFuture.isCancelled();
-   }
-
-   public boolean isDone() {
-      return networkCallFuture.isDone();
-   }
-
-   public Object get() throws InterruptedException, ExecutionException {
-      networkCallFuture.get();
-      return actualReturnValue;
-   }
-
-   public Object get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {
-      networkCallFuture.get(timeout, unit);
-      return actualReturnValue;
-   }
-}",2009-05-20T15:18:23Z,98
"@@ -28,10 +28,10 @@
 import org.infinispan.manager.CacheManager;
 import org.infinispan.manager.DefaultCacheManager;
 import org.infinispan.notifications.Listenable;
+import org.infinispan.util.concurrent.NotifyingFuture;
 
 import java.util.Map;
 import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
 /**
@@ -54,15 +54,16 @@
  * <h3>Asynchronous operations</h3> Cache also supports the use of ""async"" remote operations.  Note that these methods
  * only really make sense if you are using a clustered cache.  I.e., when used in LOCAL mode, these ""async"" operations
  * offer no benefit whatsoever.  These methods, such as {@link #putAsync(Object, Object)} offer the best of both worlds
- * between a fully synchronous and a fully asynchronous cache in that a {@link Future} is returned.  The <tt>Future</tt>
- * can then be ignored or thrown away for typical asynchronous behaviour, or queried for synchronous behaviour, which
- * would block until any remote calls complete.  Note that all remote calls are, as far as the transport is concerned,
- * synchronous.  This allows you the guarantees that remote calls succeed, while not blocking your application thread
- * unnecessarily.  For example, usage such as the following could benefit from the async operations:
+ * between a fully synchronous and a fully asynchronous cache in that a {@link NotifyingFuture} is returned.  The
+ * <tt>NotifyingFuture</tt> can then be ignored or thrown away for typical asynchronous behaviour, or queried for
+ * synchronous behaviour, which would block until any remote calls complete.  Note that all remote calls are, as far as
+ * the transport is concerned, synchronous.  This allows you the guarantees that remote calls succeed, while not
+ * blocking your application thread unnecessarily.  For example, usage such as the following could benefit from the
+ * async operations:
  * <pre>
- *   Future f1 = cache.putAsync(""key1"", ""value1"");
- *   Future f2 = cache.putAsync(""key2"", ""value2"");
- *   Future f3 = cache.putAsync(""key3"", ""value3"");
+ *   NotifyingFuture f1 = cache.putAsync(""key1"", ""value1"");
+ *   NotifyingFuture f2 = cache.putAsync(""key2"", ""value2"");
+ *   NotifyingFuture f3 = cache.putAsync(""key3"", ""value3"");
  *   f1.get();
  *   f2.get();
  *   f3.get();
@@ -72,8 +73,8 @@
  * especially advantageous if the cache uses distribution and the three keys map to different cache instances in the
  * cluster.
  * <p/>
- * Also, the use of async operations when within a transaction return your local value only, as expected.  A Future is
- * still returned though for API consistency.
+ * Also, the use of async operations when within a transaction return your local value only, as expected.  A
+ * NotifyingFuture is still returned though for API consistency.
  * <p/>
  * <h3>Constructing a Cache</h3> An instance of the Cache is usually obtained by using a {@link CacheManager}.
  * <pre>
@@ -310,7 +311,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param value value to store
     * @return a future containing the old value replaced.
     */
-   Future<V> putAsync(K key, V value);
+   NotifyingFuture<V> putAsync(K key, V value);
 
    /**
     * Asynchronous version of {@link #put(Object, Object, long, TimeUnit)} .  This method does not block on remote
@@ -323,7 +324,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param unit     time unit for lifespan
     * @return a future containing the old value replaced
     */
-   Future<V> putAsync(K key, V value, long lifespan, TimeUnit unit);
+   NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit unit);
 
    /**
     * Asynchronous version of {@link #put(Object, Object, long, TimeUnit, long, TimeUnit)}.  This method does not block
@@ -339,7 +340,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param maxIdleUnit  time unit for max idle time
     * @return a future containing the old value replaced
     */
-   Future<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
+   NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
    /**
     * Asynchronous version of {@link #putAll(Map)}.  This method does not block on remote calls, even if your cache mode
@@ -348,7 +349,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param data to store
     * @return a future containing a void return type
     */
-   Future<Void> putAllAsync(Map<? extends K, ? extends V> data);
+   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data);
 
    /**
     * Asynchronous version of {@link #putAll(Map, long, TimeUnit)}.  This method does not block on remote calls, even if
@@ -359,7 +360,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param unit     time unit for lifespan
     * @return a future containing a void return type
     */
-   Future<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit unit);
+   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit unit);
 
    /**
     * Asynchronous version of {@link #putAll(Map, long, TimeUnit, long, TimeUnit)}.  This method does not block on
@@ -374,15 +375,15 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param maxIdleUnit  time unit for max idle time
     * @return a future containing a void return type
     */
-   Future<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
+   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
    /**
     * Asynchronous version of {@link #clear()}.  This method does not block on remote calls, even if your cache mode is
     * synchronous.  Has no benefit over {@link #clear()} if used in LOCAL mode.
     *
     * @return a future containing a void return type
     */
-   Future<Void> clearAsync();
+   NotifyingFuture<Void> clearAsync();
 
    /**
     * Asynchronous version of {@link #putIfAbsent(Object, Object)}.  This method does not block on remote calls, even if
@@ -393,7 +394,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param value value to store
     * @return a future containing the old value replaced.
     */
-   Future<V> putIfAbsentAsync(K key, V value);
+   NotifyingFuture<V> putIfAbsentAsync(K key, V value);
 
    /**
     * Asynchronous version of {@link #putIfAbsent(Object, Object, long, TimeUnit)} .  This method does not block on
@@ -406,7 +407,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param unit     time unit for lifespan
     * @return a future containing the old value replaced
     */
-   Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit unit);
+   NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit unit);
 
    /**
     * Asynchronous version of {@link #putIfAbsent(Object, Object, long, TimeUnit, long, TimeUnit)}.  This method does
@@ -422,7 +423,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param maxIdleUnit  time unit for max idle time
     * @return a future containing the old value replaced
     */
-   Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
+   NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
    /**
     * Asynchronous version of {@link #remove(Object)}.  This method does not block on remote calls, even if your cache
@@ -431,7 +432,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param key key to remove
     * @return a future containing the value removed
     */
-   Future<V> removeAsync(Object key);
+   NotifyingFuture<V> removeAsync(Object key);
 
    /**
     * Asynchronous version of {@link #remove(Object, Object)}.  This method does not block on remote calls, even if your
@@ -441,7 +442,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param value value to match on
     * @return a future containing a boolean, indicating whether the entry was removed or not
     */
-   Future<Boolean> removeAsync(Object key, Object value);
+   NotifyingFuture<Boolean> removeAsync(Object key, Object value);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object)}.  This method does not block on remote calls, even if
@@ -451,7 +452,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param value value to store
     * @return a future containing the previous value overwritten
     */
-   Future<V> replaceAsync(K key, V value);
+   NotifyingFuture<V> replaceAsync(K key, V value);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object, long, TimeUnit)}.  This method does not block on remote
@@ -464,7 +465,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param unit     time unit for lifespan
     * @return a future containing the previous value overwritten
     */
-   Future<V> replaceAsync(K key, V value, long lifespan, TimeUnit unit);
+   NotifyingFuture<V> replaceAsync(K key, V value, long lifespan, TimeUnit unit);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object, long, TimeUnit, long, TimeUnit)}.  This method does not
@@ -480,7 +481,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param maxIdleUnit  time unit for max idle time
     * @return a future containing the previous value overwritten
     */
-   Future<V> replaceAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
+   NotifyingFuture<V> replaceAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object, Object)}.  This method does not block on remote calls,
@@ -492,7 +493,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param newValue value to store
     * @return a future containing a boolean, indicating whether the entry was replaced or not
     */
-   Future<Boolean> replaceAsync(K key, V oldValue, V newValue);
+   NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object, Object, long, TimeUnit)}.  This method does not block on
@@ -506,7 +507,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param unit     time unit for lifespan
     * @return a future containing a boolean, indicating whether the entry was replaced or not
     */
-   Future<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit unit);
+   NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit unit);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object, Object, long, TimeUnit, long, TimeUnit)}.  This method
@@ -523,7 +524,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param maxIdleUnit  time unit for max idle time
     * @return a future containing a boolean, indicating whether the entry was replaced or not
     */
-   Future<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
+   NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
 
    AdvancedCache<K, V> getAdvancedCache();",2009-05-20T15:18:23Z,99
"@@ -1,49 +0,0 @@
-package org.infinispan.distribution;
-
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.Future;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.TimeoutException;
-
-/**
- * A version of the async return values for dist
- *
- * @author Manik Surtani
- * @since 4.0
- */
-public class DistAsyncReturnValue implements Future<Object> {
-   final Future<Object> invalFuture, replFuture;
-   final Object returnValue;
-
-   public DistAsyncReturnValue(Future<Object> invalFuture, Future<Object> replFuture, Object returnValue) {
-      this.invalFuture = invalFuture;
-      this.replFuture = replFuture;
-      this.returnValue = returnValue;
-   }
-
-   public boolean cancel(boolean mayInterruptIfRunning) {
-      boolean invalCancelled = true;
-      if (invalFuture != null) invalCancelled = invalFuture.cancel(mayInterruptIfRunning);
-      return replFuture.cancel(mayInterruptIfRunning) && invalCancelled;
-   }
-
-   public boolean isCancelled() {
-      return replFuture.isCancelled() && (invalFuture == null || invalFuture.isCancelled());
-   }
-
-   public boolean isDone() {
-      return replFuture.isDone() && (invalFuture == null || invalFuture.isDone());
-   }
-
-   public Object get() throws InterruptedException, ExecutionException {
-      if (invalFuture != null) invalFuture.get();
-      replFuture.get();
-      return returnValue;
-   }
-
-   public Object get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {
-      if (invalFuture != null) invalFuture.get(timeout, unit);
-      replFuture.get(timeout, unit);
-      return returnValue;
-   }
-}",2009-05-20T15:18:23Z,100
"@@ -17,21 +17,22 @@
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.DistAsyncReturnValue;
 import org.infinispan.distribution.DistributionManager;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.interceptors.base.BaseRpcInterceptor;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.util.Immutables;
+import org.infinispan.util.concurrent.AggregatingNotifyingFutureImpl;
+import org.infinispan.util.concurrent.NotifyingFutureImpl;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.concurrent.Future;
 
 /**
  * The interceptor that handles distribution of entries across a cluster, as well as transparent lookup
@@ -233,39 +234,37 @@ private Object handleWriteCommand(InvocationContext ctx, WriteCommand command, R
             if (ctx.isOriginLocal()) {
                List<Address> rec = recipientGenerator.generateRecipients();
                if (trace) log.trace(""Invoking command {0} on hosts {1}"", command, rec);
-               Future<Object> f1 = null, f2;
                boolean useFuture = ctx.isUseFutureReturnType();
                boolean sync = isSynchronous(ctx);
-
+               NotifyingNotifiableFuture<Object> future = null;
                // if L1 caching is used make sure we broadcast an invalidate message
                if (isL1CacheEnabled && rec != null && rpcManager.getTransport().getMembers().size() > rec.size()) {
                   InvalidateCommand ic = cf.buildInvalidateFromL1Command(recipientGenerator.getKeys());
-                  f1 = submitRpc(null, ic, sync, useFuture);
+                  if (useFuture) {
+                     future = new AggregatingNotifyingFutureImpl(returnValue, 2);
+                     rpcManager.broadcastRpcCommandInFuture(ic, future);
+                  } else {
+                     rpcManager.broadcastRpcCommand(ic, sync);
+                  }
                }
-               f2 = submitRpc(rec, command, sync, useFuture);
 
-               if (f2 != null) return new DistAsyncReturnValue(f1, f2, returnValue);
+               if (useFuture) {
+                  if (future == null) future = new NotifyingFutureImpl(returnValue);
+                  rpcManager.anycastRpcCommandInFuture(rec, command, future);
+                  return future;
+               } else {
+                  rpcManager.anycastRpcCommand(rec, command, sync);
+               }
             }
          } else {
             if (!localModeForced) {
                ((TxInvocationContext) ctx).addTransactionParticipants(recipientGenerator.generateRecipients());
-            } else {
-               // add to list of participants
             }
          }
       }
       return returnValue;
    }
 
-   private Future<Object> submitRpc(final List<Address> recipients, final WriteCommand cmd, final boolean sync, boolean useFuture) {
-      if (useFuture) {
-         return rpcManager.anycastRpcCommandInFuture(recipients, cmd);
-      } else {
-         rpcManager.anycastRpcCommand(recipients, cmd, sync);
-         return null;
-      }
-   }
-
    interface RecipientGenerator {
       List<Address> generateRecipients();
 ",2009-05-20T15:18:23Z,101
"@@ -21,7 +21,6 @@
  */
 package org.infinispan.interceptors;
 
-import org.infinispan.AsyncReturnValue;
 import org.infinispan.commands.AbstractVisitor;
 import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.VisitableCommand;
@@ -41,6 +40,8 @@
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.util.concurrent.NotifyingFutureImpl;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
@@ -195,7 +196,9 @@ protected Object invalidateAcrossCluster(boolean synchronous, InvocationContext
             log.debug(""Cache ["" + rpcManager.getTransport().getAddress() + ""] replicating "" + command);
          // voila, invalidated!
          if (useFuture) {
-            return new AsyncReturnValue(rpcManager.broadcastRpcCommandInFuture(command), retvalForFuture);
+            NotifyingNotifiableFuture<Object> future = new NotifyingFutureImpl(retvalForFuture);
+            rpcManager.broadcastRpcCommandInFuture(command, future);
+            return future;
          } else {
             rpcManager.broadcastRpcCommand(command, synchronous);
          }",2009-05-20T15:18:23Z,102
"@@ -21,7 +21,6 @@
  */
 package org.infinispan.interceptors;
 
-import org.infinispan.AsyncReturnValue;
 import org.infinispan.commands.LockControlCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
@@ -36,6 +35,8 @@
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.util.concurrent.NotifyingFutureImpl;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 
 /**
  * Takes care of replicating modifications to other caches in a cluster. Also listens for prepare(), commit() and
@@ -116,7 +117,9 @@ private Object handleCrudMethod(final InvocationContext ctx, final WriteCommand
       final Object returnValue = invokeNextInterceptor(ctx, command);
       if (!isLocalModeForced(ctx) && command.isSuccessful() && ctx.isOriginLocal() && !ctx.isInTxScope()) {
          if (ctx.isUseFutureReturnType()) {
-            return new AsyncReturnValue(rpcManager.broadcastRpcCommandInFuture(command), returnValue);
+            NotifyingNotifiableFuture<Object> future = new NotifyingFutureImpl(returnValue);
+            rpcManager.broadcastRpcCommandInFuture(command, future);
+            return future;
          } else {
             rpcManager.broadcastRpcCommand(command, isSynchronous(ctx));
          }",2009-05-20T15:18:23Z,103
"@@ -27,9 +27,9 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.statetransfer.StateTransferException;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 
 import java.util.List;
-import java.util.concurrent.Future;
 
 /**
  * Provides a mechanism for communicating with other caches in the cluster, by formatting and passing requests down to
@@ -119,10 +119,10 @@ public interface RpcManager {
     * is passed to the transport executor and a Future is returned.  The transport always deals with this
     * synchronously.
     *
-    * @param rpc command to execute remotely
-    * @return a future
+    * @param rpc    command to execute remotely
+    * @param future the future which will be passed back to the user
     */
-   Future<Object> broadcastRpcCommandInFuture(ReplicableCommand rpc);
+   void broadcastRpcCommandInFuture(ReplicableCommand rpc, NotifyingNotifiableFuture<Object> future);
 
    /**
     * The same as {@link #broadcastRpcCommand(org.infinispan.commands.ReplicableCommand, boolean, boolean)} except that
@@ -131,9 +131,9 @@ public interface RpcManager {
     *
     * @param rpc              command to execute remotely
     * @param usePriorityQueue if true, a priority queue is used
-    * @return a future
+    * @param future           the future which will be passed back to the user
     */
-   Future<Object> broadcastRpcCommandInFuture(ReplicableCommand rpc, boolean usePriorityQueue);
+   void broadcastRpcCommandInFuture(ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future);
 
    /**
     * Broadcasts an RPC command to a specified set of recipients
@@ -164,9 +164,9 @@ public interface RpcManager {
     *
     * @param recipients recipients to invoke remote call on
     * @param rpc        command to execute remotely
-    * @return a future
+    * @param future     the future which will be passed back to the user
     */
-   Future<Object> anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc);
+   void anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc, NotifyingNotifiableFuture<Object> future);
 
    /**
     * The same as {@link #anycastRpcCommand(java.util.List, org.infinispan.commands.ReplicableCommand, boolean)} except
@@ -176,9 +176,9 @@ public interface RpcManager {
     * @param recipients       recipients to invoke remote call on
     * @param rpc              command to execute remotely
     * @param usePriorityQueue if true, a priority queue is used
-    * @return a future
+    * @param future           the future which will be passed back to the user
     */
-   Future<Object> anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc, boolean usePriorityQueue);
+   void anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future);
 
    /**
     * @return a reference to the underlying transport.",2009-05-20T15:18:23Z,104
"@@ -18,6 +18,7 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.statetransfer.StateTransferException;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -27,7 +28,6 @@
 import java.util.Random;
 import java.util.concurrent.Callable;
 import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Future;
 import java.util.concurrent.atomic.AtomicLong;
 
 /**
@@ -180,12 +180,12 @@ public final void broadcastRpcCommand(ReplicableCommand rpc, boolean sync, boole
       }
    }
 
-   public final Future<Object> broadcastRpcCommandInFuture(ReplicableCommand rpc) {
-      return broadcastRpcCommandInFuture(rpc, false);
+   public final void broadcastRpcCommandInFuture(ReplicableCommand rpc, NotifyingNotifiableFuture<Object> l) {
+      broadcastRpcCommandInFuture(rpc, false, l);
    }
 
-   public final Future<Object> broadcastRpcCommandInFuture(ReplicableCommand rpc, boolean usePriorityQueue) {
-      return anycastRpcCommandInFuture(null, rpc, usePriorityQueue);
+   public final void broadcastRpcCommandInFuture(ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> l) {
+      anycastRpcCommandInFuture(null, rpc, usePriorityQueue, l);
    }
 
    public final void anycastRpcCommand(List<Address> recipients, ReplicableCommand rpc, boolean sync) throws ReplicationException {
@@ -219,18 +219,19 @@ public final void anycastRpcCommand(List<Address> recipients, ReplicableCommand
       }
    }
 
-   public final Future<Object> anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc) {
-      return anycastRpcCommandInFuture(recipients, rpc, false);
+   public final void anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc, NotifyingNotifiableFuture<Object> l) {
+      anycastRpcCommandInFuture(recipients, rpc, false, l);
    }
 
-   public final Future<Object> anycastRpcCommandInFuture(final List<Address> recipients, final ReplicableCommand rpc, final boolean usePriorityQueue) {
+   public final void anycastRpcCommandInFuture(final List<Address> recipients, final ReplicableCommand rpc, final boolean usePriorityQueue, final NotifyingNotifiableFuture<Object> l) {
       Callable<Object> c = new Callable<Object>() {
          public Object call() {
             anycastRpcCommand(recipients, rpc, true, usePriorityQueue);
+            l.notifyDone();
             return null;
          }
       };
-      return asyncExecutor.submit(c);
+      l.setNetworkFuture(asyncExecutor.submit(c));
    }
 
    public Transport getTransport() {",2009-05-20T15:18:23Z,105
"@@ -0,0 +1,69 @@
+package org.infinispan.util.concurrent;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * For use with > 1 underlying network future
+ *
+ * @author Manik Surtani
+ * @since 4.0
+ */
+public class AggregatingNotifyingFutureImpl extends NotifyingFutureImpl {
+   final List<Future<Object>> futures;
+   final AtomicInteger awaitingCompletions = new AtomicInteger();
+
+   public AggregatingNotifyingFutureImpl(Object actualReturnValue, int maxFutures) {
+      super(actualReturnValue);
+      futures = new ArrayList<Future<Object>>(maxFutures);
+      awaitingCompletions.set(maxFutures);
+   }
+
+   @Override
+   public void setNetworkFuture(Future<Object> future) {
+      futures.add(future);
+   }
+
+   @Override
+   public boolean cancel(boolean mayInterruptIfRunning) {
+      boolean aggregateValue = false;
+      for (Future<Object> f : futures) aggregateValue = f.cancel(mayInterruptIfRunning) && aggregateValue;
+      return aggregateValue;
+   }
+
+   @Override
+   public boolean isCancelled() {
+      for (Future<Object> f : futures) if (f.isCancelled()) return true;
+      return false;
+   }
+
+   @Override
+   public boolean isDone() {
+      for (Future<Object> f : futures) if (!f.isDone()) return false;
+      return true;
+   }
+
+   @Override
+   public Object get() throws InterruptedException, ExecutionException {
+      for (Future<Object> f : futures) f.get();
+      return actualReturnValue;
+   }
+
+   @Override
+   public Object get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, java.util.concurrent.TimeoutException {
+      for (Future<Object> f : futures) f.get(timeout, unit);
+      return actualReturnValue;
+   }
+
+   @Override
+   public void notifyDone() {
+      if (awaitingCompletions.decrementAndGet() == 0) {
+         callCompleted = true;
+         for (FutureListener<Object> l : listeners) l.futureDone(this);
+      }
+   }
+}",2009-05-20T15:18:23Z,106
"@@ -0,0 +1,18 @@
+package org.infinispan.util.concurrent;
+
+import java.util.concurrent.Future;
+
+/**
+ * A listener that is called back when a future is done.  FutureListener instances are attached to {@link
+ * NotifyingFuture}s by passing them in to {@link NotifyingFuture#attachListener(FutureListener)}
+ * <p/>
+ * Note that the {@link #futureDone(Future)} callback is invoked when the future completes, regardless of how the future
+ * completes (i.e., normally, due to an exception, or cancelled}.  As such, implementations should check the future
+ * passed in by calling <tt>future.get()</tt>.
+ *
+ * @author Manik Surtani
+ * @since 4.0
+ */
+public interface FutureListener<T> {
+   void futureDone(Future<T> future);
+}",2009-05-20T15:18:23Z,107
"@@ -0,0 +1,29 @@
+package org.infinispan.util.concurrent;
+
+import java.util.concurrent.Future;
+
+/**
+ * A sub-interface of a Future, that allows for listeners to be attached so that observers can be notified of when the
+ * future completes.
+ * <p/>
+ * See {@link FutureListener} for more details.
+ * <p/>
+ * {@link #attachListener(FutureListener)} returns the same future instance, which is useful for 'building' a future.
+ * E.g.,
+ * <p/>
+ * <code> Future<Void> f = cache.clearAsync().attachListener(new MyCustomListener()); </code>
+ *
+ * @author Manik Surtani
+ * @since 4.0
+ */
+public interface NotifyingFuture<T> extends Future<T> {
+
+   /**
+    * Attaches a listener and returns the same future instance, to allow for 'building'.
+    *
+    * @param listener listener to attach
+    * @return the same future instance
+    */
+   NotifyingFuture<T> attachListener(FutureListener<T> listener);
+
+}",2009-05-20T15:18:23Z,108
"@@ -0,0 +1,67 @@
+package org.infinispan.util.concurrent;
+
+import java.util.Set;
+import java.util.concurrent.CopyOnWriteArraySet;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+
+/**
+ * Constructs an instance of a {@link org.infinispan.util.concurrent.NotifyingFuture}.
+ * <p/>
+ * Typical usage:
+ * <p/>
+ * <code> Object retval = .... // do some work here NotifyingFuture nf = new NotifyingFutureImpl(retval);
+ * rpcManager.broadcastRpcCommandInFuture(nf, command); return nf; </code>
+ *
+ * @author Manik Surtani
+ * @since 4.0
+ */
+public class NotifyingFutureImpl implements NotifyingNotifiableFuture<Object> {
+
+   final Object actualReturnValue;
+   volatile Future<Object> ioFuture;
+   volatile boolean callCompleted = false;
+   final Set<FutureListener<Object>> listeners = new CopyOnWriteArraySet<FutureListener<Object>>();
+
+   public NotifyingFutureImpl(Object actualReturnValue) {
+      this.actualReturnValue = actualReturnValue;
+   }
+
+   public void setNetworkFuture(Future<Object> future) {
+      this.ioFuture = future;
+   }
+
+   public boolean cancel(boolean mayInterruptIfRunning) {
+      return ioFuture.cancel(mayInterruptIfRunning);
+   }
+
+   public boolean isCancelled() {
+      return ioFuture.isCancelled();
+   }
+
+   public boolean isDone() {
+      return ioFuture.isDone();
+   }
+
+   public Object get() throws InterruptedException, ExecutionException {
+      ioFuture.get();
+      return actualReturnValue;
+   }
+
+   public Object get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, java.util.concurrent.TimeoutException {
+      ioFuture.get(timeout, unit);
+      return actualReturnValue;
+   }
+
+   public void notifyDone() {
+      callCompleted = true;
+      for (FutureListener<Object> l : listeners) l.futureDone(this);
+   }
+
+   public NotifyingFuture<Object> attachListener(FutureListener<Object> objectFutureListener) {
+      if (!callCompleted) listeners.add(objectFutureListener);
+      if (callCompleted) objectFutureListener.futureDone(this);
+      return this;
+   }
+}
\ No newline at end of file",2009-05-20T15:18:23Z,109
"@@ -0,0 +1,15 @@
+package org.infinispan.util.concurrent;
+
+import java.util.concurrent.Future;
+
+/**
+ * An internal interface which adds the ability to inform the future of completion.
+ *
+ * @author Manik Surtani
+ * @since 4.0
+ */
+public interface NotifyingNotifiableFuture<Object> extends NotifyingFuture<Object> {
+   void notifyDone();
+
+   void setNetworkFuture(Future<java.lang.Object> future);
+}",2009-05-20T15:18:23Z,110
"@@ -79,6 +79,7 @@
 import org.infinispan.statetransfer.StateChunk;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.xa.DldGlobalTransaction;
@@ -128,6 +129,7 @@ public class CommandsFactoryImpl implements CommandsFactory {
    private LockManager lockManager;
    private InternalEntryFactory entryFactory;
    private MapReduceManager mapReduceManager;
+   private StateTransferManager stateTransferManager;
 
    private Map<Byte, ModuleCommandInitializer> moduleCommandInitializers;
 
@@ -137,7 +139,7 @@ public void setupDependencies(DataContainer container, CacheNotifier notifier, C
                                  InvocationContextContainer icc, TransactionTable txTable, Configuration configuration,
                                  @ComponentName(KnownComponentNames.MODULE_COMMAND_INITIALIZERS) Map<Byte, ModuleCommandInitializer> moduleCommandInitializers,
                                  RecoveryManager recoveryManager, StateProvider stateProvider, StateConsumer stateConsumer,
-                                 LockManager lockManager, InternalEntryFactory entryFactory, MapReduceManager mapReduceManager) {
+                                 LockManager lockManager, InternalEntryFactory entryFactory, MapReduceManager mapReduceManager, StateTransferManager stm) {
       this.dataContainer = container;
       this.notifier = notifier;
       this.cache = cache;
@@ -153,6 +155,7 @@ public void setupDependencies(DataContainer container, CacheNotifier notifier, C
       this.lockManager = lockManager;
       this.entryFactory = entryFactory;
       this.mapReduceManager = mapReduceManager;
+      this.stateTransferManager = stm;
    }
 
    @Start(priority = 1)
@@ -402,7 +405,7 @@ public void initializeReplicableCommand(ReplicableCommand c, boolean isRemote) {
             break;
          case TxCompletionNotificationCommand.COMMAND_ID:
             TxCompletionNotificationCommand ftx = (TxCompletionNotificationCommand) c;
-            ftx.init(txTable, lockManager, recoveryManager);
+            ftx.init(txTable, lockManager, recoveryManager, stateTransferManager);
             break;
          case MapCombineCommand.COMMAND_ID:
             MapCombineCommand mrc = (MapCombineCommand)c;",2012-10-12T16:37:21Z,111
"@@ -36,7 +36,7 @@
  * @author Sanne Grinovero <sanne@hibernate.org> (C) 2011 Red Hat Inc.
  * @since 5.0
  */
-public interface FlagAffectedCommand extends TopologyAffectedCommand {
+public interface FlagAffectedCommand extends VisitableCommand, TopologyAffectedCommand {
    
    /**
     * @return the Flags which where set in the context - only valid to invoke after {@link #setFlags(Set)}",2012-10-12T16:37:21Z,112
"@@ -28,7 +28,7 @@
  * @author anistor@redhat.com
  * @since 5.2
  */
-public interface TopologyAffectedCommand extends VisitableCommand {
+public interface TopologyAffectedCommand extends ReplicableCommand {
 
    int getTopologyId();
 ",2012-10-12T16:37:21Z,113
"@@ -22,7 +22,9 @@
  */
 package org.infinispan.commands.remote.recovery;
 
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.context.InvocationContext;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.xa.GlobalTransaction;
@@ -32,14 +34,15 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.xa.Xid;
+import java.util.Set;
 
 /**
  * Command for removing recovery related information from the cluster.
  *
  * @author Mircea.Markus@jboss.com
  * @since 5.0
  */
-public class TxCompletionNotificationCommand extends RecoveryCommand {
+public class TxCompletionNotificationCommand  extends RecoveryCommand implements TopologyAffectedCommand {
 
    private static Log log = LogFactory.getLog(TxCompletionNotificationCommand.class);
 
@@ -50,6 +53,8 @@ public class TxCompletionNotificationCommand extends RecoveryCommand {
    private GlobalTransaction gtx;
    private TransactionTable txTable;
    private LockManager lockManager;
+   private StateTransferManager stateTransferManager;
+   private int topologyId;
 
    private TxCompletionNotificationCommand() {
       super(null); // For command id uniqueness test
@@ -61,10 +66,11 @@ public TxCompletionNotificationCommand(Xid xid, GlobalTransaction gtx, String ca
       this.gtx = gtx;
    }
 
-   public void init(TransactionTable tt, LockManager lockManager, RecoveryManager rm) {
+   public void init(TransactionTable tt, LockManager lockManager, RecoveryManager rm, StateTransferManager stm) {
       super.init(rm);
       this.txTable = tt;
       this.lockManager = lockManager;
+      this.stateTransferManager = stm;
    }
 
 
@@ -77,6 +83,21 @@ public TxCompletionNotificationCommand(String cacheName) {
       super(cacheName);
    }
 
+   @Override
+   public int getTopologyId() {
+      return topologyId;
+   }
+
+   @Override
+   public void setTopologyId(int topologyId) {
+      this.topologyId = topologyId;
+   }
+
+   @Override
+   public boolean isReturnValueExpected() {
+      return false;
+   }
+
    @Override
    public Object perform(InvocationContext ctx) throws Throwable {
       log.tracef(""Processing completed transaction %s"", gtx);
@@ -92,10 +113,21 @@ public Object perform(InvocationContext ctx) throws Throwable {
          remoteTx = txTable.removeRemoteTransaction(gtx);
       }
       if (remoteTx == null) return null;
+      forwardCommandRemotely(remoteTx);
+
       lockManager.unlock(remoteTx.getLockedKeys(), remoteTx.getGlobalTransaction());
       return null;
    }
 
+   /**
+    * This only happens during state transfer.
+    */
+   private void forwardCommandRemotely(RemoteTransaction remoteTx) {
+      Set<Object> affectedKeys = remoteTx.getAffectedKeys();
+      log.tracef(""Invoking forward of TxCompletionNotification for transaction %s. Affected keys: %w"", gtx, affectedKeys);
+      stateTransferManager.forwardCommandIfNeeded(this, affectedKeys, false);
+   }
+
    @Override
    public byte getCommandId() {
       return COMMAND_ID;
@@ -124,6 +156,7 @@ public String toString() {
       return getClass().getSimpleName() +
             ""{ xid="" + xid +
             "", internalId="" + internalId +
+            "", topologyId="" + topologyId +
             "", gtx="" + gtx +
             "", cacheName="" + cacheName + ""} "";
    }",2012-10-12T16:37:21Z,114
"@@ -34,20 +34,18 @@
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.remoting.transport.Address;
-import org.infinispan.topology.CacheTopology;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.*;
+import java.util.Collections;
+import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
 /**
@@ -60,20 +58,16 @@ public class StateTransferInterceptor extends CommandInterceptor {   //todo [ani
 
    private static final Log log = LogFactory.getLog(StateTransferInterceptor.class);
 
-   private final AffectedKeysVisitor affectedKeysVisitor = new AffectedKeysVisitor();
-
    private StateTransferLock stateTransferLock;
 
    private StateTransferManager stateTransferManager;
 
-   private RpcManager rpcManager;
-
    private CommandsFactory commandFactory;
 
-   private long rpcTimeout;
-
    private boolean useVersioning;
 
+   private final AffectedKeysVisitor affectedKeysVisitor = new AffectedKeysVisitor();
+
    @Override
    protected Log getLog() {
       return log;
@@ -83,14 +77,9 @@ protected Log getLog() {
    public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
-      this.rpcManager = rpcManager;
       this.commandFactory = commandFactory;
       this.stateTransferManager = stateTransferManager;
 
-      // no need to retry for asynchronous caches
-      rpcTimeout = configuration.clustering().cacheMode().isSynchronous()
-            ? configuration.clustering().sync().replTimeout() : 0;
-
       useVersioning = configuration.transaction().transactionMode().isTransactional() && configuration.locking().writeSkewCheck() &&
             configuration.transaction().lockingMode() == LockingMode.OPTIMISTIC && configuration.versioning().enabled();
    }
@@ -205,25 +194,32 @@ private Object handleWriteCommand(InvocationContext ctx, WriteCommand command) t
    @Override
    protected Object handleDefault(InvocationContext ctx, VisitableCommand command) throws Throwable {
       if (command instanceof TopologyAffectedCommand) {
-         return handleTopologyAffectedCommand(ctx, (TopologyAffectedCommand) command, ctx.isOriginLocal());
+         return handleTopologyAffectedCommand(ctx, command, ctx.isOriginLocal());
       } else {
          return invokeNextInterceptor(ctx, command);
       }
    }
 
-   private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffectedCommand command,
-                                                boolean originLocal) throws Throwable {
-      boolean cacheModeLocal = false;
-      if (command instanceof FlagAffectedCommand) {
-         cacheModeLocal = ((FlagAffectedCommand)command).hasFlag(Flag.CACHE_MODE_LOCAL);
-      }
-      log.tracef(""handleTopologyAffectedCommand for command %s, originLocal=%s, cacheModeLocal=%s"", command, originLocal
-            , cacheModeLocal);
-      if (originLocal || cacheModeLocal) {
+   private Object handleTopologyAffectedCommand(InvocationContext ctx, VisitableCommand command, boolean originLocal) throws Throwable {
+
+      log.tracef(""handleTopologyAffectedCommand for command %s, originLocal=%s, cacheModeLocal=%s"", command, originLocal);
+
+      if (isLocal(command, originLocal)) {
          return invokeNextInterceptor(ctx, command);
       }
+      updateTopologyIdAndWaitForTransactionData((TopologyAffectedCommand) command);
+
+      // TODO we may need to skip local invocation for read/write/tx commands if the command is too old and none of its keys are local
+      Object localResult = invokeNextInterceptor(ctx, command);
+
+      if (command instanceof TransactionBoundaryCommand || (command instanceof WriteCommand && !ctx.isInTxScope())) {
+         stateTransferManager.forwardCommandIfNeeded(((TopologyAffectedCommand)command), getAffectedKeys(ctx, command), true);
+      }
 
+      return localResult;
+   }
 
+   private void updateTopologyIdAndWaitForTransactionData(TopologyAffectedCommand command) throws InterruptedException {
       // set the topology id if it was not set before (ie. this is local command)
       // TODO Make tx commands extend FlagAffectedCommand so we can use CACHE_MODE_LOCAL in StaleTransactionCleanupService
       if (command.getTopologyId() == -1) {
@@ -233,34 +229,16 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       // remote/forwarded command
       int cmdTopologyId = command.getTopologyId();
       stateTransferLock.waitForTransactionData(cmdTopologyId);
+   }
 
-      // TODO we may need to skip local invocation for read/write/tx commands if the command is too old and none of its keys are local
-      Object localResult = invokeNextInterceptor(ctx, command);
+   private boolean isLocal(VisitableCommand command, boolean originLocal) {
+      if (originLocal) return true;
 
-      // forward commands with older topology ids to their new targets
-      // but we need to make sure we have the latest topology
-      CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
-      int localTopologyId = cacheTopology.getTopologyId();
-      // if it's a tx/lock/write command, forward it to the new owners
-      log.tracef(""CommandTopologyId=%s, localTopologyId=%s"", cmdTopologyId, localTopologyId);
-
-      if (cmdTopologyId < localTopologyId) {
-         if (command instanceof TransactionBoundaryCommand  || (command instanceof WriteCommand && !ctx.isInTxScope())) {
-            ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
-            Set<Object> affectedKeys = getAffectedKeys(ctx, command);
-            Set<Address> newTargets = writeCh.locateAllOwners(affectedKeys);
-            newTargets.remove(rpcManager.getAddress());
-            if (!newTargets.isEmpty()) {
-               // Update the topology id to prevent cycles
-               command.setTopologyId(localTopologyId);
-               log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
-               // TODO find a way to forward the command async if it was received async
-               rpcManager.invokeRemotely(newTargets, command, true, false);
-            }
-         }
+      boolean cacheModeLocal = false;
+      if (command instanceof FlagAffectedCommand) {
+         cacheModeLocal = ((FlagAffectedCommand)command).hasFlag(Flag.CACHE_MODE_LOCAL);
       }
-
-      return localResult;
+      return cacheModeLocal;
    }
 
    @SuppressWarnings(""unchecked"")",2012-10-12T16:37:21Z,115
"@@ -23,14 +23,16 @@
 
 package org.infinispan.statetransfer;
 
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.topology.CacheTopology;
 import org.rhq.helpers.pluginAnnotations.agent.DataType;
 import org.rhq.helpers.pluginAnnotations.agent.Metric;
 
-//todo [anistor] remove this class and move the remaining functionality to StateConsumer
+import java.util.Set;
+
 /**
  * A component that manages the state transfer when the topology of the cluster changes.
  *
@@ -72,4 +74,11 @@ public interface StateTransferManager {
     * @return {@code true} if the local node was the first to start this cache in the cluster.
     */
    boolean isLocalNodeFirst();
+
+   /**
+    * If there is an state transfer happening at the moment, this method forwards the supplied
+    * command to the nodes that are new owners of the data, in order to assure consistency.
+    */
+   void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
+
 }",2012-10-12T16:37:21Z,116
"@@ -23,11 +23,13 @@
 
 package org.infinispan.statetransfer;
 
+import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.Cache;
 import org.infinispan.CacheException;
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.configuration.global.GlobalConfiguration;
@@ -40,6 +42,7 @@
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
 import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheJoinInfo;
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.topology.CacheTopologyHandler;
@@ -242,4 +245,27 @@ public boolean isLocalNodeFirst() {
       return cacheTopology.getMembers().get(0).equals(rpcManager.getAddress());
    }
 
+   @Override
+   public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync) {
+      int cmdTopologyId = command.getTopologyId();
+      // forward commands with older topology ids to their new targets
+      // but we need to make sure we have the latest topology
+      CacheTopology cacheTopology = getCacheTopology();
+      int localTopologyId = cacheTopology.getTopologyId();
+      // if it's a tx/lock/write command, forward it to the new owners
+      log.tracef(""CommandTopologyId=%s, localTopologyId=%s"", cmdTopologyId, localTopologyId);
+
+      if (cmdTopologyId < localTopologyId) {
+         ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
+         Set<Address> newTargets = writeCh.locateAllOwners(affectedKeys);
+         newTargets.remove(rpcManager.getAddress());
+         if (!newTargets.isEmpty()) {
+            // Update the topology id to prevent cycles
+            command.setTopologyId(localTopologyId);
+            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
+            // TODO find a way to forward the command async if it was received async
+            rpcManager.invokeRemotely(newTargets, command, sync, false);
+         }
+      }
+   }
 }
\ No newline at end of file",2012-10-12T16:37:21Z,117
"@@ -52,7 +52,6 @@
 import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.ConfigurationBuilder;
-import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.versioning.EntryVersion;
 import org.infinispan.context.Flag;
 import org.infinispan.distexec.mapreduce.Mapper;
@@ -67,16 +66,12 @@
 import org.infinispan.test.TestingUtil;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
-import org.infinispan.transaction.tm.DummyTransaction;
-import org.infinispan.transaction.tm.DummyTransactionManager;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.concurrent.ReclosableLatch;
 import org.testng.annotations.Test;
 
-import javax.transaction.HeuristicMixedException;
 import javax.transaction.xa.Xid;
 import java.util.Collection;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -104,11 +99,18 @@ protected void createCacheManagers() throws Throwable {
       waitForClusterToForm();
    }
 
-   public void testLockReleasedCorrectly() throws Throwable {
+   public void testBelatedCommit() throws Throwable {
+      testLockReleasedCorrectly(CommitCommand.class);
+   }
+
+   public void testBelatedTxCompletionNotificationCommand() throws Throwable {
+      testLockReleasedCorrectly(TxCompletionNotificationCommand.class);
+   }
 
+   private void testLockReleasedCorrectly(Class<? extends  ReplicableCommand> toBlock ) throws Throwable {
 
       ComponentRegistry componentRegistry = advancedCache(1).getComponentRegistry();
-      final ControlledCommandFactory ccf = new ControlledCommandFactory(componentRegistry.getCommandsFactory());
+      final ControlledCommandFactory ccf = new ControlledCommandFactory(componentRegistry.getCommandsFactory(), toBlock);
       TestingUtil.replaceField(ccf, ""commandsFactory"", componentRegistry, ComponentRegistry.class);
 
       //hack: re-add the component registry to the GlobalComponentRegistry's ""namedComponents"" (CHM) in order to correctly publish it for
@@ -137,7 +139,7 @@ public Object call() throws Exception {
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            return ccf.receivedCommits.get() == 1;
+            return ccf.receivedCommands.get() == 1;
          }
       });
 
@@ -153,17 +155,12 @@ public boolean isSatisfied() throws Exception {
       }
 
       log.tracef(""Number of migrated keys is %s"", migratedKeys.size());
-      System.out.println(""Number of migrated tx is "" + migratedKeys.size());
       if (migratedKeys.size() == 0) return;
 
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            int remoteTxCount = TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount();
-            int localTxCount = TestingUtil.getTransactionTable(cache(2)).getLocalTxCount();
-            log.trace(""remoteTxCount = "" + remoteTxCount);
-            log.trace(""localTxCount = "" + localTxCount);
-            return remoteTxCount == 1;
+            return TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount() == 1;
          }
       });
 
@@ -173,7 +170,8 @@ public boolean isSatisfied() throws Exception {
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            return TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount() == 0;
+            int remoteTxCount = TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount();
+            return remoteTxCount == 0;
          }
       });
 
@@ -189,6 +187,12 @@ public boolean isSatisfied() throws Exception {
          assertNotLocked(key);
          assertEquals(key, cache(0).get(key));
       }
+
+      for (Object k : migratedKeys) {
+         assertFalse(advancedCache(0).getDataContainer().containsKey(k));
+         assertFalse(advancedCache(1).getDataContainer().containsKey(k));
+         assertTrue(advancedCache(2).getDataContainer().containsKey(k));
+      }
    }
 
    private boolean keyMapsToNode(Object key, int nodeIndex) {
@@ -203,10 +207,12 @@ private Address owner(Object key) {
    public class ControlledCommandFactory implements CommandsFactory {
       final CommandsFactory actual;
       final ReclosableLatch gate = new ReclosableLatch(true);
-      final AtomicInteger receivedCommits = new AtomicInteger(0);
+      final AtomicInteger receivedCommands = new AtomicInteger(0);
+      final Class<? extends  ReplicableCommand> toBlock;
 
-      public ControlledCommandFactory(CommandsFactory actual) {
+      public ControlledCommandFactory(CommandsFactory actual, Class<? extends  ReplicableCommand> toBlock) {
          this.actual = actual;
+         this.toBlock = toBlock;
       }
 
       @Override
@@ -316,11 +322,11 @@ public RollbackCommand buildRollbackCommand(GlobalTransaction gtx) {
 
       @Override
       public void initializeReplicableCommand(ReplicableCommand command, boolean isRemote) {
-         if (isRemote && command instanceof CommitCommand) {
-            receivedCommits.incrementAndGet();
+         if (isRemote && command.getClass().isAssignableFrom(toBlock)) {
+            receivedCommands.incrementAndGet();
             try {
                gate.await();
-               log.tracef(""gate is opened, processing the commit:  %s"", command);
+               log.tracef(""gate is opened, processing the lock cleanup:  %s"", command);
             } catch (InterruptedException e) {
                throw new RuntimeException(e);
             }",2012-10-12T16:37:21Z,118
"@@ -0,0 +1,188 @@
+/*
+ * JBoss, Home of Professional Open Source
+ *  Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ *  contributors as indicated by the @author tags. All rights reserved
+ *  See the copyright.txt in the distribution for a full listing of
+ *  individual contributors.
+ *
+ *  This is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU Lesser General Public License as
+ *  published by the Free Software Foundation; either version 2.1 of
+ *  the License, or (at your option) any later version.
+ *
+ *  This software is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ *  Lesser General Public License for more details.
+ *
+ *  You should have received a copy of the GNU Lesser General Public
+ *  License along with this software; if not, write to the Free
+ *  Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ *  02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.statetransfer;
+
+import java.util.Collection;
+import java.util.Map;
+import java.util.concurrent.Callable;
+
+import org.infinispan.Cache;
+import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.JGroupsTransport;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.test.fwk.TransportFlags;
+import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
+import org.infinispan.util.InfinispanCollections;
+import org.jgroups.protocols.DISCARD;
+import org.testng.annotations.Test;
+
+import static org.junit.Assert.assertEquals;
+
+/**
+ * tests scenario for ISPN-2574
+ *
+ * - create nodes A, B - start node C - starts state transfer from B to C
+ * - abruptly kill B before it is able to send StateResponse to C
+ * - C resends the request to A
+ * - finally cluster A, C is formed where all entries are properly backed up on both nodes
+ *
+ * @author Michal Linhard
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.StateTransferRestartTest"")
+@CleanupAfterMethod
+public class StateTransferRestartTest extends MultipleCacheManagersTest {
+
+   private ConfigurationBuilder cfgBuilder;
+   private GlobalConfigurationBuilder gcfgBuilder;
+
+   private class MockTransport extends JGroupsTransport {
+      volatile Callable<Void> callOnStateResponseCommand;
+
+      @Override
+      public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout,
+                                                   boolean usePriorityQueue, ResponseFilter responseFilter) throws Exception {
+         if (callOnStateResponseCommand != null && rpcCommand.getClass() == StateResponseCommand.class) {
+            log.trace(""Ignoring StateResponseCommand"");
+            try {
+               callOnStateResponseCommand.call();
+            } catch (Exception e) {
+               log.error(""Error in callOnStateResponseCommand"", e);
+            }
+            return InfinispanCollections.emptyMap();
+         }
+         return super.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue, responseFilter);
+      }
+   }
+
+   private MockTransport mockTransport = new MockTransport();
+
+   private void waitForStateTransfer(Cache... caches) throws InterruptedException {
+      StateTransferManager[] stm = new StateTransferManager[caches.length];
+      for (int i = 0; i < stm.length; i++) {
+         stm[i] = TestingUtil.extractComponent(caches[i], StateTransferManager.class);
+      }
+      while (true) {
+         boolean inProgress = false;
+         for (StateTransferManager aStm : stm) {
+            if (aStm.isStateTransferInProgress()) {
+               inProgress = true;
+               break;
+            }
+         }
+         if (!inProgress) {
+            break;
+         }
+         wait(100);
+      }
+   }
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      cfgBuilder = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+      cfgBuilder.transaction().transactionManagerLookup(new DummyTransactionManagerLookup());
+      cfgBuilder.clustering().hash().numOwners(2);
+      cfgBuilder.clustering().stateTransfer().fetchInMemoryState(true);
+      cfgBuilder.clustering().stateTransfer().timeout(10000);
+
+      gcfgBuilder = new GlobalConfigurationBuilder();
+      gcfgBuilder.transport().transport(mockTransport);
+   }
+
+   public void testStateTransferRestart() throws Throwable {
+      addClusterEnabledCacheManager(cfgBuilder, new TransportFlags().withFD(true));
+      addClusterEnabledCacheManager(gcfgBuilder, cfgBuilder, new TransportFlags().withFD(true));
+      log.info(""waiting for cluster { c0, c1 }"");
+      waitForClusterToForm();
+
+      log.info(""putting in data"");
+      final Cache<Object, Object> c0 = cache(0);
+      final Cache<Object, Object> c1 = cache(1);
+      for (int k = 0; k < 1000; k++) {
+         c0.put(k, k);
+      }
+      waitForStateTransfer(c0, c1);
+
+      assertEquals(1000, c0.entrySet().size());
+      assertEquals(1000, c1.entrySet().size());
+
+      mockTransport.callOnStateResponseCommand = new Callable<Void>() {
+         @Override
+         public Void call() throws Exception {
+            fork(new Callable<Void>() {
+               @Override
+               public Void call() throws Exception {
+                  log.info(""KILLING the c1 cache"");
+                  try {
+                     DISCARD d3 = TestingUtil.getDiscardForCache(c1);
+                     d3.setDiscardAll(true);
+                     d3.setExcludeItself(true);
+                     TestingUtil.killCacheManagers(manager(c1));
+                  } catch (Exception e) {
+                     log.info(""there was some exception while killing cache"");
+                  }
+                  return null;
+               }
+            });
+            try {
+               // sleep and wait to be killed
+               Thread.sleep(20000);
+            } catch (InterruptedException e) {
+               log.info(""Interrupted as expected."");
+               Thread.currentThread().interrupt();
+            }
+            return null;
+         }
+      };
+
+      log.info(""adding cache c2"");
+      addClusterEnabledCacheManager(cfgBuilder, new TransportFlags().withFD(true));
+      log.info(""get c2"");
+      final Cache<Object, Object> c2 = cache(2);
+
+      log.info(""waiting for cluster { c0, c2 }"");
+      TestingUtil.blockUntilViewsChanged(10000, 2, c0, c2);
+
+      log.infof(""c0 entrySet size before : %d"", c0.entrySet().size());
+      log.infof(""c2 entrySet size before : %d"", c2.entrySet().size());
+
+      eventually(new Condition() {
+         @Override
+         public boolean isSatisfied() throws Exception {
+            return c0.entrySet().size() == 1000 && c2.entrySet().size() == 1000;
+         }
+      });
+
+      log.info(""Ending the test"");
+   }
+}",2013-01-23T11:38:31Z,119
"@@ -66,7 +66,9 @@ public class InboundTransferTask {
 
    private final long timeout;
 
-   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout) {
+   private final String cacheName;
+
+   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""segments must not be null or empty"");
       }
@@ -81,6 +83,7 @@ public InboundTransferTask(Set<Integer> segments, Address source, int topologyId
       this.rpcManager = rpcManager;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public Set<Integer> getSegments() {
@@ -93,7 +96,7 @@ public Address getSource() {
 
    public boolean requestTransactions() {
       if (trace) {
-         log.tracef(""Requesting transactions for segments %s"", segments);
+         log.tracef(""Requesting transactions for segments %s of cache %s from node %s"", segments, cacheName, source);
       }
       // get transactions and locks
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.GET_TRANSACTIONS, rpcManager.getAddress(), topologyId, segments);
@@ -109,6 +112,10 @@ public boolean requestTransactions() {
    }
 
    public boolean requestSegments() {
+      if (trace) {
+         log.tracef(""Requesting segments %s of cache %s from node %s"", segments, cacheName, source);
+      }
+
       // start transfer of cache entries
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.START_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
       Map<Address, Response> responses = rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
@@ -139,24 +146,21 @@ public void cancel() {
       if (!isCancelled) {
          isCancelled = true;
 
-         Set<Integer> cancelledSegments = new HashSet<Integer>(segments);
-         segments.clear();
-         finishedSegments.clear();
-
-         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, cancelledSegments);
+         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
          rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
 
          stateConsumer.onTaskCompletion(this);
       }
    }
 
    public void onStateReceived(int segmentId, boolean isLastChunk) {
-      if (!isCancelled && segments.contains(segmentId)) {
-         if (isLastChunk) {
-            finishedSegments.add(segmentId);
-            if (finishedSegments.containsAll(segments)) {
-               stateConsumer.onTaskCompletion(this);
+      if (!isCancelled && isLastChunk && segments.contains(segmentId)) {
+         finishedSegments.add(segmentId);
+         if (finishedSegments.containsAll(segments)) {
+            if (trace) {
+               log.tracef(""Finished receiving state for segments %s of cache %s"", segments, cacheName);
             }
+            stateConsumer.onTaskCompletion(this);
          }
       }
    }
@@ -166,11 +170,14 @@ public String toString() {
       HashSet<Integer> unfinishedSegments = new HashSet<Integer>(segments);
       unfinishedSegments.removeAll(finishedSegments);
       return ""InboundTransferTask{"" +
-            ""unfinishedSegments="" + unfinishedSegments +
+            ""segments="" + segments +
+            "", finishedSegments="" + finishedSegments +
+            "", unfinishedSegments="" + unfinishedSegments +
             "", source="" + source +
             "", isCancelled="" + isCancelled +
             "", topologyId="" + topologyId +
             "", timeout="" + timeout +
+            "", cacheName="" + cacheName +
             '}';
    }
 }",2012-11-07T14:07:34Z,120
"@@ -24,20 +24,19 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.commands.CommandsFactory;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheLoaderManager;
 import org.infinispan.loaders.CacheStore;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.SuspectException;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
-import org.infinispan.util.concurrent.AggregatingNotifyingFutureBuilder;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -70,8 +69,6 @@ public class OutboundTransferTask implements Runnable {
 
    private final int stateTransferChunkSize;
 
-   private final Configuration configuration;
-
    private final ConsistentHash readCh;
 
    private final DataContainer dataContainer;
@@ -84,27 +81,24 @@ public class OutboundTransferTask implements Runnable {
 
    private final long timeout;
 
+   private final String cacheName;
+
    private final Map<Integer, List<InternalCacheEntry>> entriesBySegment = ConcurrentMapFactory.makeConcurrentMap();
 
    /**
     * The total number of entries from all segments accumulated in entriesBySegment.
     */
    private int accumulatedEntries;
 
-   /**
-    * This is used with RpcManager.invokeRemotelyInFuture() to be able to cancel message sending if the task needs to be canceled.
-    */
-   private final NotifyingNotifiableFuture<Object> sendFuture = new AggregatingNotifyingFutureBuilder(null);
-
    /**
     * The Future obtained from submitting this task to an executor service. This is used for cancellation.
     */
    private FutureTask runnableFuture;
 
    public OutboundTransferTask(Address destination, Set<Integer> segments, int stateTransferChunkSize,
                                int topologyId, ConsistentHash readCh, StateProviderImpl stateProvider, DataContainer dataContainer,
-                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager, Configuration configuration,
-                               CommandsFactory commandsFactory, long timeout) {
+                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager,
+                               CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""Segments must not be null or empty"");
       }
@@ -123,9 +117,9 @@ public OutboundTransferTask(Address destination, Set<Integer> segments, int stat
       this.dataContainer = dataContainer;
       this.cacheLoaderManager = cacheLoaderManager;
       this.rpcManager = rpcManager;
-      this.configuration = configuration;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public void execute(ExecutorService executorService) {
@@ -154,7 +148,7 @@ public void run() {
       try {
          // send data container entries
          for (InternalCacheEntry ice : dataContainer) {
-            Object key = ice.getKey();
+            Object key = ice.getKey();  //todo [anistor] should we check for expired entries?
             int segmentId = readCh.getSegment(key);
             if (segments.contains(segmentId)) {
                sendEntry(ice, segmentId);
@@ -198,7 +192,7 @@ public void run() {
          }
       }
       if (trace) {
-         log.tracef(""Outbound transfer of segments %s to %s is complete"", segments, destination);
+         log.tracef(""Outbound transfer of segments %s of cache %s to node %s is complete"", segments, cacheName, destination);
       }
    }
 
@@ -217,7 +211,6 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
       // send if we have a full chunk
       if (accumulatedEntries >= stateTransferChunkSize) {
          sendEntries(false);
-         entriesBySegment.clear();
          accumulatedEntries = 0;
       }
 
@@ -232,32 +225,42 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
 
    private void sendEntries(boolean isLast) {
       List<StateChunk> chunks = new ArrayList<StateChunk>();
+      for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
+         List<InternalCacheEntry> entries = e.getValue();
+         if (!entries.isEmpty()) {
+            chunks.add(new StateChunk(e.getKey(), new ArrayList<InternalCacheEntry>(entries), isLast));
+            entries.clear();
+         }
+      }
+
       if (isLast) {
          for (int segmentId : segments) {
             List<InternalCacheEntry> entries = entriesBySegment.get(segmentId);
             if (entries == null) {
-               entries = InfinispanCollections.emptyList();
-            }
-            chunks.add(new StateChunk(segmentId, entries, isLast));
-         }
-      } else {
-         for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
-            List<InternalCacheEntry> entries = e.getValue();
-            if (!entries.isEmpty()) {
-               chunks.add(new StateChunk(e.getKey(), entries, isLast));
+               chunks.add(new StateChunk(segmentId, InfinispanCollections.<InternalCacheEntry>emptyList(), true));
             }
          }
       }
 
-      if (!chunks.isEmpty() || isLast) {
+      if (!chunks.isEmpty()) {
          if (trace) {
-            log.tracef(""Sending %d cache entries from segments %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), destination);
+            if (isLast) {
+               log.tracef(""Sending last chunk containing %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, segments, cacheName, destination);
+            } else {
+               log.tracef(""Sending %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), cacheName, destination);
+            }
          }
 
-         //todo [anistor] send back the received topologyId or my local one?
          StateResponseCommand cmd = commandsFactory.buildStateResponseCommand(rpcManager.getAddress(), topologyId, chunks);
-         // send synchronously, in FIFO mode. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
-         rpcManager.invokeRemotelyInFuture(Collections.singleton(destination), cmd, false, sendFuture, timeout);
+         // send synchronously, in order. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
+         try {
+            rpcManager.invokeRemotely(Collections.singleton(destination), cmd, ResponseMode.SYNCHRONOUS, timeout, false, null);
+         } catch (SuspectException e) {
+            log.errorf(e, ""Node %s left cache %s: %s"", destination, cacheName, e.getMessage());
+            cancel();
+         } catch (Exception e) {
+            log.errorf(e, ""Failed to send entries to node %s : %s"", destination, e.getMessage());
+         }
       }
    }
 
@@ -268,7 +271,7 @@ private void sendEntries(boolean isLast) {
     */
    public void cancelSegments(Set<Integer> cancelledSegments) {
       if (trace) {
-         log.tracef(""Cancelling outbound transfer of segments %s to %s"", cancelledSegments, destination);
+         log.tracef(""Cancelling outbound transfer of segments %s of cache %s to node %s"", cancelledSegments, cacheName, destination);
       }
       if (segments.removeAll(cancelledSegments)) {
          entriesBySegment.keySet().removeAll(cancelledSegments);  // here we do not update accumulatedEntries but this inaccuracy does not cause any harm
@@ -284,11 +287,22 @@ public void cancelSegments(Set<Integer> cancelledSegments) {
    public void cancel() {
       if (runnableFuture != null && !runnableFuture.isCancelled()) {
          runnableFuture.cancel(true);
-         sendFuture.cancel(true);
       }
    }
 
    public boolean isCancelled() {
       return runnableFuture != null && runnableFuture.isCancelled();
    }
+
+   @Override
+   public String toString() {
+      return ""OutboundTransferTask{"" +
+            ""topologyId="" + topologyId +
+            "", destination="" + destination +
+            "", segments="" + segments +
+            "", stateTransferChunkSize="" + stateTransferChunkSize +
+            "", timeout="" + timeout +
+            "", cacheName='"" + cacheName + '\'' +
+            '}';
+   }
 }",2012-11-07T14:07:34Z,121
"@@ -45,7 +45,6 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -62,7 +61,7 @@
 import static org.infinispan.context.Flag.*;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateConsumer} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -72,7 +71,7 @@ public class StateConsumerImpl implements StateConsumer {
    private static final Log log = LogFactory.getLog(StateConsumerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
-   private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
    private Configuration configuration;
    private RpcManager rpcManager;
@@ -119,7 +118,7 @@ public StateConsumerImpl() {
 
    @Inject
    public void init(Cache cache,
-                    LocalTopologyManager localTopologyManager,
+                    StateTransferManager stateTransferManager,
                     InterceptorChain interceptorChain,
                     InvocationContextContainer icc,
                     Configuration configuration,
@@ -130,7 +129,7 @@ public void init(Cache cache,
                     TransactionTable transactionTable,
                     StateTransferLock stateTransferLock) {
       this.cacheName = cache.getName();
-      this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
       this.interceptorChain = interceptorChain;
       this.icc = icc;
       this.configuration = configuration;
@@ -171,26 +170,30 @@ public boolean isStateTransferInProgressForKey(Object key) {
 
    @Override
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
-      if (trace) log.tracef(""Received new CH: %s"", cacheTopology.getWriteConsistentHash());
+      if (trace) log.tracef(""Received new CH %s for cache %s"", cacheTopology.getWriteConsistentHash(), cacheName);
 
       activeTopologyUpdates.incrementAndGet();
       if (isRebalance) {
          rebalanceInProgress.set(true);
       }
-      ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
+      final ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
       // Ensures writes to the data container use the right consistent hash
       // No need for a try/finally block, since it's just an assignment
       stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
       stateTransferLock.releaseExclusiveTopologyLock();
-      stateTransferLock.topologyInstalled(cacheTopology.getTopologyId());
+      stateTransferLock.notifyTopologyInstalled(cacheTopology.getTopologyId());
 
       try {
          Set<Integer> addedSegments;
          if (previousCh == null) {
             // we start fresh, without any data, so we need to pull everything we own according to writeCh
 
             addedSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
+
+            if (trace) {
+               log.tracef(""On cache %s we have: added segments: %s"", cacheName, addedSegments);
+            }
          } else {
             Set<Integer> previousSegments = getOwnedSegments(previousCh);
             Set<Integer> newSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
@@ -199,16 +202,16 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             Set<Integer> removedSegments = new HashSet<Integer>(previousSegments);
             removedSegments.removeAll(newSegments);
 
-            // remove inbound transfers and any data for segments we no longer own
+            addedSegments = new HashSet<Integer>(newSegments);
+            addedSegments.removeAll(previousSegments);
+
             if (trace) {
-               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                     removedSegments, newSegments, previousSegments);
+               log.tracef(""On cache %s we have: removed segments: %s; new segments: %s; old segments: %s; added segments: %s"",
+                     cacheName, removedSegments, newSegments, previousSegments, addedSegments);
             }
-            discardSegments(removedSegments);
 
-            Set<Integer> currentSegments = getOwnedSegments(cacheTopology.getReadConsistentHash());
-            addedSegments = new HashSet<Integer>(newSegments);
-            addedSegments.removeAll(currentSegments);
+            // remove inbound transfers and any data for segments we no longer own
+            discardSegments(removedSegments);
 
             // check if any of the existing transfers should be restarted from a different source because the initial source is no longer a member
             Set<Address> members = new HashSet<Address>(cacheTopology.getReadConsistentHash().getMembers());
@@ -230,24 +233,30 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
                      }
                   }
                }
+
+               // exclude those that are already in progress from a valid source
+               addedSegments.removeAll(transfersBySegment.keySet());
             }
          }
 
-         if (addedSegments != null && !addedSegments.isEmpty()) {
+         if (!addedSegments.isEmpty()) {
             addTransfers(addedSegments);  // add transfers for new or restarted segments
          }
       } finally {
-         stateTransferLock.transactionDataReceived(cacheTopology.getTopologyId());
+         stateTransferLock.notifyTransactionDataReceived(cacheTopology.getTopologyId());
 
-         if (activeTopologyUpdates.decrementAndGet() == 0 && !isStateTransferInProgress()) {
+         if (activeTopologyUpdates.decrementAndGet() == 0) {
             notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
          }
       }
    }
 
    private void notifyEndOfTopologyUpdate(int topologyId) {
-      if (rebalanceInProgress.compareAndSet(true, false)) {
-         localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+      if (!isStateTransferInProgress()) {
+         if (rebalanceInProgress.compareAndSet(true, false)) {
+            log.debugf(""Finished receiving of segments for cache %s for topology %d."", cacheName, topologyId);
+            stateTransferManager.notifyEndOfTopologyUpdate(topologyId);
+         }
       }
    }
 
@@ -262,43 +271,42 @@ public void applyState(Address sender, int topologyId, int segmentId, Collection
       //todo [anistor] this check should be based on topologyId
       if (!cacheTopology.getWriteConsistentHash().getSegmentsForOwner(rpcManager.getAddress()).contains(segmentId)) {
          if (trace) {
-            log.warnf(""Discarding received cache entries for segment %d because they do not belong to this node."", segmentId);
+            log.warnf(""Discarding received cache entries for segment %d of cache %s because they do not belong to this node."", segmentId, cacheName);
          }
          return;
       }
 
-      if (cacheEntries != null) {
-         doApplyState(sender, segmentId, cacheEntries);
-      }
-
       // notify the inbound task that a chunk of cache entries was received
       InboundTransferTask inboundTransfer;
       synchronized (this) {
          inboundTransfer = transfersBySegment.get(segmentId);
       }
       if (inboundTransfer != null) {
+         if (cacheEntries != null) {
+            doApplyState(sender, segmentId, cacheEntries);
+         }
+
          inboundTransfer.onStateReceived(segmentId, isLastChunk);
-      } else {
-         log.debugf(""Received unsolicited state for segment %d from node %s"", segmentId, sender);
-         return;
-      }
 
-      if (trace) {
-         log.tracef(""After applying the received state the data container has %d keys"", dataContainer.size());
-         synchronized (this) {
-            log.tracef(""Segments not received yet: %s"", transfersBySource);
+         if (trace) {
+            log.tracef(""After applying the received state the data container of cache %s has %d keys"", cacheName, dataContainer.size());
+            synchronized (this) {
+               log.tracef(""Segments not received yet for cache %s: %s"", cacheName, transfersBySource);
+            }
          }
+      } else {
+         log.warnf(""Received unsolicited state from node %s for segment %d of cache %s"", sender, segmentId, cacheName);
       }
    }
 
    private void doApplyState(Address sender, int segmentId, Collection<InternalCacheEntry> cacheEntries) {
-      log.debugf(""Applying new state for segment %d from %s: received %d cache entries"", segmentId, sender, cacheEntries.size());
+      log.debugf(""Applying new state for segment %d of cache %s from node %s: received %d cache entries"", segmentId, cacheName, sender, cacheEntries.size());
       if (trace) {
          List<Object> keys = new ArrayList<Object>(cacheEntries.size());
          for (InternalCacheEntry e : cacheEntries) {
             keys.add(e.getKey());
          }
-         log.tracef(""Received keys: %s"", keys);
+         log.tracef(""Received keys %s for segment %d of cache %s from node %s"", keys, segmentId, cacheName, sender);
       }
 
       // CACHE_MODE_LOCAL avoids handling by StateTransferInterceptor and any potential locks in StateTransferLock
@@ -316,10 +324,11 @@ private void doApplyState(Address sender, int segmentId, Collection<InternalCach
             log.problemApplyingStateForKey(ex.getMessage(), e.getKey());
          }
       }
+      log.debugf(""Finished applying state for segment %d of cache %s"", segmentId, cacheName);
    }
 
    public void applyTransactions(Address sender, int topologyId, Collection<TransactionInfo> transactions) {
-      log.debugf(""Applying %d transactions transferred from %s"", transactions.size(), sender);
+      log.debugf(""Applying %d transactions for cache %s transferred from node %s"", transactions.size(), cacheName, sender);
       if (configuration.transaction().transactionMode().isTransactional()) {
          for (TransactionInfo transactionInfo : transactions) {
             CacheTransaction tx = transactionTable.getLocalTransaction(transactionInfo.getGlobalTransaction());
@@ -374,30 +383,31 @@ public CacheTopology getCacheTopology() {
    }
 
    private void addTransfers(Set<Integer> segments) {
-      log.debugf(""Adding state transfer for segments: %s"", segments);
+      log.debugf(""Adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
 
       Set<Integer> segmentsToProcess = new HashSet<Integer>(segments);
-      Set<Address> blacklistedSources = new HashSet<Address>();
+      Set<Address> faultysources = new HashSet<Address>();
 
       // ignore all segments for which there are no other owners to pull data from.
       // these segments are considered empty (or lost) and do not require a state transfer
       for (Iterator<Integer> it = segmentsToProcess.iterator(); it.hasNext(); ) {
          Integer segmentId = it.next();
-         Address source = pickSourceOwner(segmentId, blacklistedSources);
+         Address source = pickSourceOwner(segmentId, faultysources);
          if (source == null) {
             it.remove();
          }
       }
 
-      synchronized (this) {
-         // already active transfers do not need to be added again
-         segmentsToProcess.removeAll(transfersBySegment.keySet());
-      }
-
       while (!segmentsToProcess.isEmpty()) {
          Map<Address, Set<Integer>> segmentsBySource = new HashMap<Address, Set<Integer>>();
          for (int segmentId : segmentsToProcess) {
-            Address source = pickSourceOwner(segmentId, blacklistedSources);
+            synchronized (this) {
+               // already active transfers do not need to be added again
+               if (transfersBySegment.containsKey(segmentId)) {
+                  continue;
+               }
+            }
+            Address source = pickSourceOwner(segmentId, faultysources);
             if (source != null) {
                Set<Integer> segmentsFromSource = segmentsBySource.get(source);
                if (segmentsFromSource == null) {
@@ -411,8 +421,14 @@ private void addTransfers(Set<Integer> segments) {
          Set<Integer> failedSegments = new HashSet<Integer>();
          for (Address source : segmentsBySource.keySet()) {
             Set<Integer> segmentsFromSource = segmentsBySource.get(source);
-            InboundTransferTask inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout);
+            InboundTransferTask inboundTransfer;
             synchronized (this) {
+               segmentsFromSource.removeAll(transfersBySegment.keySet());  // already in progress segments are excluded
+               if (segmentsFromSource.isEmpty()) {
+                  continue;
+               }
+
+               inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout, cacheName);
                for (int segmentId : segmentsFromSource) {
                   transfersBySegment.put(segmentId, inboundTransfer);
                }
@@ -427,9 +443,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the transactions fails we need to retry from another source
             if (configuration.transaction().transactionMode().isTransactional()) {
                if (!inboundTransfer.requestTransactions()) {
-                  log.errorf(""Failed to retrieve transactions for segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRetrieveTransactionsForSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                   continue;
                }
@@ -438,9 +454,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the segments fails we need to retry from another source
             if (fetchEnabled) {
                if (!inboundTransfer.requestSegments()) {
-                  log.errorf(""Failed to request segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRequestSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                }
             } else {
@@ -450,21 +466,22 @@ private void addTransfers(Set<Integer> segments) {
 
          segmentsToProcess = failedSegments;
       }
+      log.debugf(""Finished adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
    }
 
-   private Address pickSourceOwner(int segmentId, Set<Address> blacklistedSources) {
+   private Address pickSourceOwner(int segmentId, Set<Address> faultySources) {
       List<Address> owners = cacheTopology.getReadConsistentHash().locateOwnersForSegment(segmentId);
       if (owners.size() == 1 && owners.get(0).equals(rpcManager.getAddress())) {
          return null;
       }
 
       for (int i = owners.size() - 1; i >= 0; i--) {   // iterate backwards because we prefer to fetch from newer nodes
          Address o = owners.get(i);
-         if (!o.equals(rpcManager.getAddress()) && !blacklistedSources.contains(o)) {
+         if (!o.equals(rpcManager.getAddress()) && !faultySources.contains(o)) {
             return o;
          }
       }
-      log.errorf(""No live owners found for segment %d. Current owners are:  %s. Blacklisted owners: %s"", segmentId, owners, blacklistedSources);
+      log.noLiveOwnersFoundForSegment(segmentId, cacheName, owners, faultySources);
       return null;
    }
 
@@ -478,9 +495,9 @@ private void discardSegments(Set<Integer> segments) {
          List<Integer> segmentsToCancel = new ArrayList<Integer>(segments);
          while (!segmentsToCancel.isEmpty()) {
             int segmentId = segmentsToCancel.remove(0);
-            log.debugf(""Removing state transfer for segment %d"", segmentId);
             InboundTransferTask inboundTransfer = transfersBySegment.remove(segmentId);
             if (inboundTransfer != null) { // we need to check the transfer was not already completed
+               log.debugf(""Cancelling inbound state transfer for segment %d of cache %s"", segmentId, cacheName);
                Set<Integer> cancelledSegments = new HashSet<Integer>(segmentsToCancel);
                cancelledSegments.retainAll(inboundTransfer.getSegments());
                segmentsToCancel.removeAll(cancelledSegments);
@@ -489,6 +506,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      // gather all keys from data container that belong to the segments that are being removed
       Set<Object> keysToRemove = new HashSet<Object>();
       for (InternalCacheEntry ice : dataContainer) {
          Object key = ice.getKey();
@@ -497,7 +515,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
-      // we also remove keys from the cache store
+      // gather all keys from cache store that belong to the segments that are being removed
       CacheStore cacheStore = getCacheStore();
       if (cacheStore != null) {
          //todo [anistor] extend CacheStore interface to be able to specify a filter when loading keys (ie. keys should belong to desired segments)
@@ -514,13 +532,14 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      log.debugf(""Removing state for segments %s of cache %s"", segments, cacheName);
       if (!keysToRemove.isEmpty()) {
          try {
             InvalidateCommand invalidateCmd = commandsFactory.buildInvalidateFromL1Command(true, EnumSet.of(CACHE_MODE_LOCAL, SKIP_LOCKING), keysToRemove);
             InvocationContext ctx = icc.createNonTxInvocationContext();
             interceptorChain.invoke(ctx, invalidateCmd);
 
-            log.debugf(""Invalidated %d keys, data container now has %d keys"", keysToRemove.size(), dataContainer.size());
+            log.debugf(""Invalidated %d keys, data container of cache %s now has %d keys"", keysToRemove.size(), cacheName, dataContainer.size());
             if (trace) log.tracef(""Invalidated keys: %s"", keysToRemove);
          } catch (CacheException e) {
             log.failedToInvalidateKeys(e);
@@ -553,18 +572,17 @@ private void removeTransfer(InboundTransferTask inboundTransfer) {
                if (transfers.isEmpty()) {
                   transfersBySource.remove(inboundTransfer.getSource());
                }
-               for (int segmentId : inboundTransfer.getSegments()) {
-                  transfersBySegment.remove(segmentId);
-               }
+               transfersBySegment.keySet().removeAll(inboundTransfer.getSegments());
             }
          }
       }
    }
 
    void onTaskCompletion(InboundTransferTask inboundTransfer) {
+      log.tracef(""Completion of inbound transfer task: %s "", inboundTransfer);
       removeTransfer(inboundTransfer);
 
-      if (activeTopologyUpdates.get() == 0 && !isStateTransferInProgress()) {
+      if (activeTopologyUpdates.get() == 0) {
          notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
       }
    }",2012-11-07T14:07:34Z,54
"@@ -52,7 +52,7 @@
 import static org.infinispan.factories.KnownComponentNames.ASYNC_TRANSPORT_EXECUTOR;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateProvider} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -90,7 +90,7 @@ public StateProviderImpl() {
 
    @Inject
    public void init(Cache cache,
-                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //todo [anistor] use a separate ExecutorService
+                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //TODO Use a dedicated ExecutorService
                     Configuration configuration,
                     RpcManager rpcManager,
                     CommandsFactory commandsFactory,
@@ -184,7 +184,7 @@ public void stop() {
 
    public List<TransactionInfo> getTransactionsForSegments(Address destination, int requestTopologyId, Set<Integer> segments) throws InterruptedException {
       if (trace) {
-         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, requestTopologyId);
+         log.tracef(""Received request for transactions from node %s for segments %s of cache %s with topology id %d"", destination, segments, cacheName, requestTopologyId);
       }
 
       if (readCh == null) {
@@ -262,8 +262,8 @@ public void startOutboundTransfer(Address destination, int requestTopologyId, Se
       }
 
       // the destination node must already have an InboundTransferTask waiting for these segments
-      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, requestTopologyId,
-            readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
+      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId,
+            readCh, this, dataContainer, cacheLoaderManager, rpcManager, commandsFactory, timeout, cacheName);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);
    }
@@ -294,7 +294,7 @@ public void cancelOutboundTransfer(Address destination, int topologyId, Set<Inte
             // get an array copy of the collection to avoid ConcurrentModificationException if the entire task gets cancelled and removeTransfer(transferTask) is called
             OutboundTransferTask[] tasks = transferTasks.toArray(new OutboundTransferTask[transferTasks.size()]);
             for (OutboundTransferTask transferTask : tasks) {
-               transferTask.cancelSegments(segments); //this can potentially result in a removeTransfer(transferTask)
+               transferTask.cancelSegments(segments); //this can potentially result in a call to removeTransfer(transferTask)
             }
          }
       }",2012-11-07T14:07:34Z,55
"@@ -36,16 +36,13 @@
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
-import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
 import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
@@ -75,7 +72,7 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
+   public void init(StateTransferLock stateTransferLock, Configuration configuration,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
       this.commandFactory = commandFactory;",2012-11-07T14:07:34Z,115
"@@ -58,13 +58,13 @@ public interface StateTransferLock {
    void releaseSharedTopologyLock();
 
    // transaction data latch
-   void transactionDataReceived(int topologyId);
+   void notifyTransactionDataReceived(int topologyId);
 
    void waitForTransactionData(int expectedTopologyId) throws InterruptedException;
 
    // topology installation latch
    // TODO move this to Cluster/LocalTopologyManagerImpl and don't start requesting state until every node has the jgroups view with the local node
-   void topologyInstalled(int topologyId);
+   void notifyTopologyInstalled(int topologyId);
 
    void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-11-07T14:07:34Z,122
"@@ -23,12 +23,12 @@
 
 package org.infinispan.statetransfer;
 
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+
 /**
  * {@code StateTransferLock} implementation.
  *
@@ -38,6 +38,7 @@
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
+   private static final boolean trace = log.isTraceEnabled();
 
    private final ReadWriteLock ownershipLock = new ReentrantReadWriteLock();
 
@@ -68,8 +69,15 @@ public void releaseSharedTopologyLock() {
    }
 
    @Override
-   public void transactionDataReceived(int topologyId) {
-      this.transactionDataTopologyId = topologyId;
+   public void notifyTransactionDataReceived(int topologyId) {
+      if (topologyId < transactionDataTopologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + transactionDataTopologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling transaction data received for topology %d"", topologyId);
+      }
+      transactionDataTopologyId = topologyId;
       synchronized (transactionDataLock) {
          transactionDataLock.notifyAll();
       }
@@ -80,19 +88,32 @@ public void waitForTransactionData(int expectedTopologyId) throws InterruptedExc
       if (transactionDataTopologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
-            transactionDataTopologyId);
+      if (trace) {
+         log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
+               transactionDataTopologyId);
+      }
       synchronized (transactionDataLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (transactionDataTopologyId < expectedTopologyId) {
             transactionDataLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Received transaction data for topology %d, expected topology was %d"", transactionDataTopologyId,
+               expectedTopologyId);
+      }
    }
 
    @Override
-   public void topologyInstalled(int topologyId) {
+   public void notifyTopologyInstalled(int topologyId) {
+      if (topologyId < this.topologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + this.topologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling topology %d is installed"", topologyId);
+      }
       this.topologyId = topologyId;
       synchronized (topologyLock) {
          topologyLock.notifyAll();
@@ -104,14 +125,18 @@ public void waitForTopology(int expectedTopologyId) throws InterruptedException
       if (topologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId,
-            topologyId);
+      if (trace) {
+         log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId, topologyId);
+      }
       synchronized (topologyLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (topologyId < expectedTopologyId) {
             topologyLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Topology %d is now installed, expected topology was %d"", topologyId, expectedTopologyId);
+      }
    }
 }",2012-11-07T14:07:34Z,123
"@@ -81,4 +81,5 @@ public interface StateTransferManager {
     */
    void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
 
+   void notifyEndOfTopologyUpdate(int topologyId);
 }",2012-11-07T14:07:34Z,116
"@@ -70,7 +70,7 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private GroupManager groupManager;   // optional
    private LocalTopologyManager localTopologyManager;
 
-   private CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
+   private final CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
 
    public StateTransferManagerImpl() {
    }
@@ -170,13 +170,18 @@ private CacheTopology addGrouping(CacheTopology cacheTopology) {
 
    private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalance) {
       if (trace) {
-         log.tracef(""Installing new cache topology %s"", newCacheTopology);
+         log.tracef(""Installing new cache topology %s on cache %s"", newCacheTopology, cacheName);
       }
 
       // handle grouping
       newCacheTopology = addGrouping(newCacheTopology);
 
       CacheTopology oldCacheTopology = stateConsumer.getCacheTopology();
+
+      if (oldCacheTopology != null && oldCacheTopology.getTopologyId() > newCacheTopology.getTopologyId()) {
+         throw new IllegalStateException(""Old topology is higher: old="" + oldCacheTopology + "", new="" + newCacheTopology);
+      }
+
       ConsistentHash oldCH = oldCacheTopology != null ? oldCacheTopology.getWriteConsistentHash() : null;
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
@@ -188,15 +193,17 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
 
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
-      if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
+      boolean isJoined = stateConsumer.getCacheTopology().getReadConsistentHash().getMembers().contains(rpcManager.getAddress());
+      if (initialStateTransferComplete.getCount() > 0 && isJoined) {
          initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
    }
 
    @Start(priority = 1000)
    @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
-      if (trace) log.tracef(""Waiting for initial state transfer to finish"");
+      if (trace) log.tracef(""Waiting for initial state transfer to finish for cache %s on %s"", cacheName, rpcManager.getAddress());
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);
       if (!success) {
          throw new CacheException(String.format(""Initial state transfer timed out for cache %s on %s"",
@@ -210,6 +217,7 @@ public void stop() {
       if (trace) {
          log.tracef(""Shutting down StateTransferManager of cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
+      initialStateTransferComplete.countDown();
       localTopologyManager.leave(cacheName);
    }
 
@@ -268,4 +276,14 @@ public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object>
          }
       }
    }
+
+   @Override
+   public void notifyEndOfTopologyUpdate(int topologyId) {
+      if (initialStateTransferComplete.getCount() > 0
+            && stateConsumer.getCacheTopology().getWriteConsistentHash().getMembers().contains(rpcManager.getAddress())) {
+         initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
+      }
+      localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+   }
 }
\ No newline at end of file",2012-11-07T14:07:34Z,117
"@@ -126,13 +126,17 @@ public void triggerRebalance(final String cacheName) throws Exception {
       asyncTransportExecutor.submit(new Callable<Object>() {
          @Override
          public Object call() throws Exception {
-            startRebalance(cacheName);
-            return null;
+            try {
+               startRebalance(cacheName);
+               return null;
+            } catch (Throwable t) {
+               log.errorf(t, ""Failed to start rebalance: %s"", t.getMessage());
+               throw new Exception(t);
+            }
          }
       });
    }
 
-
    @Override
    public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo joinInfo, int viewId) throws Exception {
       waitForView(viewId);
@@ -594,6 +598,7 @@ public Object call() throws Exception {
             try {
                return command.perform(null);
             } catch (Throwable t) {
+               log.errorf(t, ""Failed to execute ReplicableCommand %s on cluster async: %s"", command, t.getMessage());
                throw new Exception(t);
             }
          }",2012-11-07T14:07:34Z,124
"@@ -280,6 +280,7 @@ public Object call() throws Exception {
                try {
                   return command.perform(null);
                } catch (Throwable t) {
+                  log.errorf(t, ""Failed to execute ReplicableCommand %s on coordinator async: %s"", command, t.getMessage());
                   throw new Exception(t);
                }
             }
@@ -298,8 +299,6 @@ class LocalCacheStatus {
    private final CacheTopologyHandler handler;
    private volatile CacheTopology topology;
 
-   private boolean joined;
-
    public LocalCacheStatus(CacheJoinInfo joinInfo, CacheTopologyHandler handler) {
       this.joinInfo = joinInfo;
       this.handler = handler;
@@ -320,12 +319,4 @@ public CacheTopology getTopology() {
    public void setTopology(CacheTopology topology) {
       this.topology = topology;
    }
-
-   public boolean isJoined() {
-      return joined;
-   }
-
-   public void setJoined(boolean joined) {
-      this.joined = joined;
-   }
 }",2012-11-07T14:07:34Z,125
"@@ -53,15 +53,14 @@ public class StaleTransactionCleanupService {
 
    private static Log log = LogFactory.getLog(StaleTransactionCleanupService.class);
 
+   private ScheduledExecutorService executorService;
 
    private TransactionTable transactionTable;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
-   private ScheduledExecutorService executorService;
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * because the main data owner left. Also unlocks keys for which the lock owner has changed as a result of a topology change.
@@ -71,15 +70,19 @@ public StaleTransactionCleanupService(TransactionTable transactionTable) {
    @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // Roll back remote transactions originating on nodes that have left the cluster.
-      if (tce.isPre()) {
-         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
-         if (consistentHashAtStart != null) {
-            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
-            if (!leavers.isEmpty()) {
-               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-               cleanTxForWhichTheOwnerLeft(leavers);
+      try {
+         if (tce.isPre()) {
+            ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+            if (consistentHashAtStart != null) {
+               List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+               if (!leavers.isEmpty()) {
+                  log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+                  cleanTxForWhichTheOwnerLeft(leavers);
+               }
             }
          }
+      } catch (Exception e) {
+         log.error(""Failed to process topology update"", e);
       }
    }
 
@@ -120,7 +123,6 @@ public void run() {
             transactionTable.cleanupCompletedTransactions();
          }
       }, interval, interval, TimeUnit.MILLISECONDS);
-
    }
 
    public void stop() {",2012-11-07T14:07:34Z,126
"@@ -523,25 +523,29 @@ public boolean isTransactionCompleted(GlobalTransaction gtx) {
    }
 
    public void cleanupCompletedTransactions() {
-      log.debugf(""About to cleanup completed transaction. Initial size is %s"", completedTransactions.size());
-      //this iterator is weekly consistent and will never throw ConcurrentModificationException
-      Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
-      long timeout = configuration.transaction().completedTxTimeout();
-
-      int removedEntries = 0;
-      long beginning = System.nanoTime();
-      while (iterator.hasNext()) {
-         Map.Entry<GlobalTransaction, Long> e = iterator.next();
-         long ageNanos = System.nanoTime() - e.getValue();
-         if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
-            iterator.remove();
-            removedEntries++;
+      try {
+         log.debugf(""About to cleanup completed transaction. Initial size is %d"", completedTransactions.size());
+         //this iterator is weekly consistent and will never throw ConcurrentModificationException
+         Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
+         long timeout = configuration.transaction().completedTxTimeout();
+
+         int removedEntries = 0;
+         long beginning = System.nanoTime();
+         while (iterator.hasNext()) {
+            Map.Entry<GlobalTransaction, Long> e = iterator.next();
+            long ageNanos = System.nanoTime() - e.getValue();
+            if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
+               iterator.remove();
+               removedEntries++;
+            }
          }
-      }
-      long duration = System.nanoTime() - beginning;
+         long duration = System.nanoTime() - beginning;
 
-      log.debugf(""Finished cleaning up completed transactions. %s transactions were removed, total duration was %s millis, "" +
-                      ""current number of completed transactions is %"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
-                 completedTransactions.size());
+         log.debugf(""Finished cleaning up completed transactions. %d transactions were removed, total duration was %d millis, "" +
+                         ""current number of completed transactions is %d"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
+                    completedTransactions.size());
+      } catch (Exception e) {
+         log.errorf(e, ""Failed to cleanup completed transactions: %s"", e.getMessage());
+      }
    }
 }",2012-11-07T14:07:34Z,127
"@@ -24,9 +24,7 @@
 
 import org.infinispan.CacheException;
 import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.commands.tx.PrepareCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.bucket.Bucket;
 import org.infinispan.loaders.decorators.SingletonStore;
@@ -60,7 +58,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.UUID;
-import java.util.concurrent.ExecutionException;
 
 import static org.jboss.logging.Logger.Level.*;
 
@@ -131,26 +128,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Can not select %s random members for %s"", id = 8)
    void cannotSelectRandomMembers(int numNeeded, List<Address> members);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Detected a view change. Member list changed from %s to %s"", id = 9)
-   void viewChangeDetected(List<Address> oldMembers, List<Address> newMembers);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a JOIN event! Wait for notification from new joiner %s"", id = 10)
-   void joinEvent(Address joiner);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a LEAVE event! Node %s has just left"", id = 11)
-   void leaveEvent(Address leaver);
-
-   @LogMessage(level = FATAL)
-   @Message(value = ""Unable to process leaver!!"", id = 12)
-   void unableToProcessLeaver(@Cause Exception e);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""I %s am participating in rehash, state providers %s, state receivers %s"", id = 13)
-   void participatingInRehash(Address address, List<Address> stateProviders, List<Address> receiversOfLeaverState);
-
    @LogMessage(level = INFO)
    @Message(value = ""DistributionManager not yet joined the cluster. Cannot do anything about other concurrent joiners."", id = 14)
    void distributionManagerNotJoined();
@@ -163,10 +140,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Problem %s encountered when applying state for key %s!"", id = 16)
    void problemApplyingStateForKey(String msg, Object key);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""View change interrupted; not rehashing!"", id = 17)
-   void viewChangeInterrupted();
-
    @LogMessage(level = WARN)
    @Message(value = ""Unable to apply prepare %s"", id = 18)
    void unableToApplyPrepare(PrepareCommand pc, @Cause Throwable t);
@@ -175,26 +148,10 @@ public interface Log extends BasicLogger {
    @Message(value = ""Couldn't acquire shared lock"", id = 19)
    void couldNotAcquireSharedLock();
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Caught exception replaying %s"", id = 20)
-   void exceptionWhenReplaying(WriteCommand cmd, @Cause Exception e);
-
    @LogMessage(level = WARN)
    @Message(value = ""Expected just one response; got %s"", id = 21)
    void expectedJustOneResponse(Map<Address, Response> lr);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Completed leave rehash on node %s in %s - leavers now are %s"", id = 22)
-   void completedLeaveRehash(Address self, String duration, List<Address> leavers);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error pushing tx log"", id = 23)
-   void errorPushingTxLog(@Cause ExecutionException e);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Unable to stop transaction logging!"", id = 24)
-   void unableToStopTransactionLogging(@Cause IllegalMonitorStateException imse);
-
    @LogMessage(level = INFO)
    @Message(value = ""wakeUpInterval is <= 0, not starting expired purge thread"", id = 25)
    void notStartingEvictionThread();
@@ -211,7 +168,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unable to passivate entry under %s"", id = 28)
    void unableToPassivateEntry(Object key, @Cause Exception e);
 
-
    @LogMessage(level = INFO)
    @Message(value = ""Passivating all entries to disk"", id = 29)
    void passivatingAllEntries();
@@ -296,14 +252,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Interrupted or timeout while waiting for AsyncStore worker threads to push all state to the decorated store"", id = 48)
    void interruptedWaitingAsyncStorePush(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing clear in async store"", id = 49)
-   void errorClearinAsyncStore(@Cause CacheLoaderException e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing purging expired from async store"", id = 50)
-   void errorPurgingAsyncStore(@Cause CacheLoaderException e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Unexpected error"", id = 51)
    void unexpectedErrorInAsyncProcessor(@Cause Throwable t);
@@ -376,14 +324,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Cache named %s does not exist on this cache manager!"", id = 68)
    void namedCacheDoesNotExist(String cacheName);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Cache named [%s] exists but isn't in a state to handle remote invocations"", id = 69)
-   void cacheCanNotHandleInvocations(String cacheName);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Quietly ignoring clustered get call %s since unable to acquire processing lock, even after %s"", id = 70)
-   void ignoreClusterGetCall(CacheRpcCommand cmd, String time);
-
    @LogMessage(level = WARN)
    @Message(value = ""Caught exception when handling command %s"", id = 71)
    void exceptionHandlingCommand(ReplicableCommand cmd, @Cause Throwable t);
@@ -396,18 +336,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unexpected error while replicating"", id = 73)
    void unexpectedErrorReplicating(@Cause Throwable t);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Trying to fetch state from %s"", id = 74)
-   void tryingToFetchState(Address member);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Could not find available peer for state, backing off and retrying"", id = 75)
-   void couldNotFindPeerForState();
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Successfully retrieved and applied state from %s"", id = 76)
-   void successfullyAppliedState(Address member);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Message or message buffer is null or empty."", id = 77)
    void msgOrMsgBufferEmpty();
@@ -461,15 +389,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""getCoordinator(): Interrupted while waiting for members to be set"", id = 89)
    void interruptedWaitingForCoordinator(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Unable to retrieve state from member %s"", id = 90)
-   void unableToRetrieveState(Address member, @Cause Exception e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Channel does not contain STREAMING_STATE_TRANSFER. "" +
-         ""Cannot support state transfers!"", id = 91)
-   void streamingStateTransferNotPresent();
-
    @LogMessage(level = WARN)
    @Message(value = ""Channel not set up properly!"", id = 92)
    void channelNotSetUp();
@@ -482,10 +401,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Received new cluster view: %s"", id = 94)
    void receivedClusterView(View newView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Caught while requesting or applying state"", id = 96)
-   void errorRequestingOrApplyingState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error while processing a prepare in a single-phase transaction"", id = 97)
    void errorProcessing1pcPrepareCommand(@Cause Throwable e);
@@ -688,14 +603,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Failed loading value for key %s from cache store"", id = 144)
    void failedLoadingValueFromCacheStore(Object key, @Cause Exception e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error during rehash"", id = 145)
-   void errorDuringRehash(@Cause Throwable th);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error transferring state to node after rehash"", id = 146)
-   void errorTransferringState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error invalidating keys from L1 after rehash"", id = 147)
    void failedToInvalidateKeys(@Cause Exception e);
@@ -729,14 +636,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Unable to unlock keys %2$s for transaction %1$s after they were rebalanced off node %3$s"", id = 154)
    void unableToUnlockRebalancedKeys(GlobalTransaction gtx, List<Object> keys, Address self, @Cause Throwable t);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm pushing data for view %d, received confirmations %s. Cancelling state transfer"", id = 157)
-   void stateTransferTimeoutWaitingForPushConfirmations(int viewId, Map<Address, Integer> pushConfirmations);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm joining for view %d, joined %s. Cancelling state transfer"", id = 158)
-   void stateTransferTimeoutWaitingForJoinConfirmations(int viewId, Map<Address, Integer> joinConfirmations);
-
    @LogMessage(level = WARN)
    @Message(value = ""Unblocking transactions failed"", id = 159)
    void errorUnblockingTransactions(@Cause Exception e);
@@ -761,26 +660,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Rolling back to cache view %d, but last committed view is %d"", id = 164)
    void cacheViewRollbackIdMismatch(int committedViewId, int committedView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error triggering a view installation for cache %s"", id = 165)
-   void errorTriggeringViewInstallation(@Cause RuntimeException e, String cacheName);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""View installation failed for cache %s"", id = 166)
-   void viewInstallationFailure(@Cause Throwable e, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Rejecting state pushed by node %s for view %d, there is no state transfer in progress (we are at view %d)"", id = 167)
-   void remoteStateRejected(Address sender, int viewId, int installedViewId);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error rolling back to cache view %1$d for cache %2$s"", id = 168)
-   void cacheViewRollbackFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error committing cache view %1$d for cache %2$s"", id = 169)
-   void cacheViewCommitFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
    @LogMessage(level = INFO)
    @Message(value = ""Strict peer-to-peer is enabled but the JGroups channel was started externally - this is very likely to result in RPC timeout errors on startup"", id = 171)
    void warnStrictPeerToPeerWithInjectedChannel();
@@ -926,5 +805,16 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @LogMessage(level = WARN)
    @Message(value = ""Could not interrupt as no thread found for command uuid %s"", id=207)
    void couldNotInterruptThread(UUID id);
-   
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""No live owners found for segment %d of cache %s. Current owners are:  %s. Faulty owners: %s"", id=208)
+   void noLiveOwnersFoundForSegment(int segmentId, String cacheName, Collection<Address> owners, Collection<Address> faultySources);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to retrieve transactions for segments %s of cache %s from node %s (node will not be retried)"", id=209)
+   void failedToRetrieveTransactionsForSegments(Collection<Integer> segments, String cacheName, Address source);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to request segments %s of cache %s from node %s (node will not be retried)"", id=210)
+   void failedToRequestSegments(Collection<Integer> segments, String cacheName, Address source);
 }",2012-11-07T14:07:34Z,45
"@@ -263,7 +263,7 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm, boolean deprecated) {
 
       assert gc.asyncTransportExecutor().factory() instanceof DefaultExecutorFactory;
       // Should be 25, but it's overriden by the test cache manager factory
-      assertEquals(""4"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
+      assertEquals(""6"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
       assert gc.asyncTransportExecutor().properties().getProperty(""threadNamePrefix"").equals(""AsyncSerializationThread"");
 
       assert gc.evictionScheduledExecutor().factory() instanceof DefaultScheduledExecutorFactory;",2012-11-07T14:07:34Z,128
"@@ -50,7 +50,6 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -126,7 +125,7 @@ public void test1() throws Exception {
       when(cache.getName()).thenReturn(""testCache"");
 
       StateProvider stateProvider = mock(StateProvider.class);
-      LocalTopologyManager localTopologyManager = mock(LocalTopologyManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
       CacheNotifier cacheNotifier = mock(CacheNotifier.class);
       ExecutorService mockExecutorService = mock(ExecutorService.class);
       RpcManager rpcManager = mock(RpcManager.class);
@@ -183,7 +182,7 @@ public Map<Address, Response> answer(InvocationOnMock invocation) {
 
       // create state provider
       StateConsumerImpl stateConsumer = new StateConsumerImpl();
-      stateConsumer.init(cache, localTopologyManager, interceptorChain, icc, configuration, rpcManager,
+      stateConsumer.init(cache, stateTransferManager, interceptorChain, icc, configuration, rpcManager,
             commandsFactory, cacheLoaderManager, dataContainer, transactionTable, stateTransferLock);
       stateConsumer.start();
 ",2012-11-07T14:07:34Z,56
"@@ -40,6 +40,7 @@
 
 /**
  * Test if state transfer happens properly on a cache with pessimistic transactions.
+ * See https://issues.jboss.org/browse/ISPN-2408.
  *
  * @since 5.2
  */",2012-11-07T14:07:34Z,129
"@@ -75,6 +75,8 @@
  */
 public class TestCacheManagerFactory {
 
+   private static final int MAX_ASYNC_EXEC_THREADS = 6;
+
    public static final String MARSHALLER = LegacyKeySupportSystemProperties.getProperty(""infinispan.test.marshaller.class"", ""infinispan.marshaller.class"");
    private static final Log log = LogFactory.getLog(TestCacheManagerFactory.class);
 
@@ -523,12 +525,12 @@ private static void checkTestName(String fullTestName) {
 
    public static void minimizeThreads(GlobalConfiguration gc) {
       Properties p = new Properties();
-      p.setProperty(""maxThreads"", ""4"");
+      p.setProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
       gc.setAsyncTransportExecutorProperties(p);
    }
 
    public static void minimizeThreads(GlobalConfigurationBuilder builder) {
-      builder.asyncTransportExecutor().addProperty(""maxThreads"", ""4"");
+      builder.asyncTransportExecutor().addProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
    }
 
    public static void amendMarshaller(GlobalConfiguration configuration) {",2012-11-07T14:07:34Z,130
"@@ -35,7 +35,6 @@
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.TransactionTable;
@@ -58,14 +57,9 @@ public abstract class AbstractTxLockingInterceptor extends AbstractLockingInterc
    public void setDependencies(TransactionTable txTable, RpcManager rpcManager) {
       this.txTable = txTable;
       this.rpcManager = rpcManager;
-   }
-
-   @Start
-   private void setClustered() {
       clustered = rpcManager != null;
    }
 
-
    @Override
    public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand command) throws Throwable {
       try {
@@ -169,10 +163,12 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
       TxInvocationContext txContext = (TxInvocationContext) ctx;
       int transactionViewId = -1;
+      boolean useStrictComparison = true;
       if (clustered) {
          transactionViewId = txContext.getCacheTransaction().getViewId();
          if (transactionViewId != TransactionTable.CACHE_STOPPED_VIEW_ID) {
-            checkForPendingLocks = transactionViewId > txTable.getMinViewId();
+            useStrictComparison = txTable.useStrictTopologyIdComparison();
+            checkForPendingLocks = isFromOlderTopology(txTable.getMinViewId(), transactionViewId, useStrictComparison);
          }
       }
 
@@ -183,15 +179,15 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
 
          // Check local transactions first
          for (CacheTransaction ct: txTable.getLocalTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
          }
 
          // ... then remote ones
          for (CacheTransaction ct: txTable.getRemoteTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
@@ -211,6 +207,19 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
    }
 
+   /**
+    * Checks if first topology id is smaller than the second. The comparison can be strict or non-strict,
+    * depending on the isStrictComparison flag.
+    *
+    * @param tx1TopologyId topology id of first transaction
+    * @param tx2TopologyId topology id of second transaction
+    * @param useStrictComparison a flag indicating if comparison must be strict
+    * @return if the first transaction was started in an older topology than the second transaction
+    */
+   private boolean isFromOlderTopology(int tx1TopologyId, int tx2TopologyId, boolean useStrictComparison) {
+      return useStrictComparison ? tx1TopologyId < tx2TopologyId : tx1TopologyId <= tx2TopologyId;
+   }
+
    private TimeoutException newTimeoutException(Object key, TxInvocationContext txContext) {
       return new TimeoutException(""Could not acquire lock on "" + key + "" on behalf of transaction "" +
                                        txContext.getGlobalTransaction() + "". Lock is being held by "" + lockManager.getOwner(key));",2012-09-21T12:26:43Z,131
"@@ -109,9 +109,7 @@ public interface CacheNotifier extends Listenable {
     */
    void notifyTransactionRegistered(GlobalTransaction globalTransaction, InvocationContext ctx);
 
-   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre);
-
-   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre);
-
+   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre);
 
+   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre);
 }
\ No newline at end of file",2012-09-21T12:26:43Z,132
"@@ -334,24 +334,25 @@ public void notifyTransactionRegistered(GlobalTransaction globalTransaction, Inv
    }
 
    @Override
-   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre) {
+   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre) {
       if (!dataRehashedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, DATA_REHASHED);
          e.setPre(pre);
          e.setMembersAtStart(oldView);
          e.setMembersAtEnd(newView);
-         e.setNewViewId(newViewId);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : dataRehashedListeners) listener.invoke(e);
       }
    }
 
    @Override
-   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre) {
+   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre) {
       if (!topologyChangedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, TOPOLOGY_CHANGED);
          e.setPre(pre);
          e.setConsistentHashAtStart(oldConsistentHash);
          e.setConsistentHashAtEnd(newConsistentHash);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : topologyChangedListeners) listener.invoke(e);
       }
    }",2012-09-21T12:26:43Z,133
"@@ -43,7 +43,7 @@ public interface DataRehashedEvent<K, V> extends Event<K, V> {
    Collection<Address> getMembersAtEnd();
 
    /**
-    * @return Retrieves the new view id after rehashing was triggered.
+    * @return Retrieves the new topology id after rehashing was triggered.
     */
-   long getNewViewId();
+   int getNewTopologyId();
 }",2012-09-21T12:26:43Z,134
"@@ -53,7 +53,7 @@ public class EventImpl<K, V> implements CacheEntryActivatedEvent, CacheEntryCrea
    private V value;
    private Collection<Address> membersAtStart, membersAtEnd;
    private ConsistentHash consistentHashAtStart, consistentHashAtEnd;
-   private long newViewId;
+   private int newTopologyId;
    private Map<Object, Object> entries;
 
    public EventImpl() {
@@ -150,8 +150,8 @@ public void setConsistentHashAtEnd(ConsistentHash consistentHashAtEnd) {
       this.consistentHashAtEnd = consistentHashAtEnd;
    }
 
-   public void setNewViewId(long newViewId) {
-      this.newViewId = newViewId;
+   public void setNewTopologyId(int newTopologyId) {
+      this.newTopologyId = newTopologyId;
    }
 
    @Override
@@ -189,7 +189,7 @@ public boolean equals(Object o) {
       if (!Util.safeEquals(consistentHashAtEnd, event.consistentHashAtEnd)) return false;
       if (!Util.safeEquals(membersAtStart, event.membersAtStart)) return false;
       if (!Util.safeEquals(membersAtEnd, event.membersAtEnd)) return false;
-      if (newViewId != event.newViewId) return false;
+      if (newTopologyId != event.newTopologyId) return false;
 
       return true;
    }
@@ -208,7 +208,7 @@ public int hashCode() {
       result = 31 * result + (membersAtEnd != null ? membersAtEnd.hashCode() : 0);
       result = 31 * result + (consistentHashAtStart != null ? consistentHashAtStart.hashCode() : 0);
       result = 31 * result + (consistentHashAtEnd != null ? consistentHashAtEnd.hashCode() : 0);
-      result = 31 * result + ((int) newViewId);
+      result = 31 * result + ((int) newTopologyId);
       return result;
    }
 
@@ -236,8 +236,8 @@ public Collection<Address> getMembersAtEnd() {
    }
 
    @Override
-   public long getNewViewId() {
-      return newViewId;
+   public int getNewTopologyId() {
+      return newTopologyId;
    }
 
    @Override",2012-09-21T12:26:43Z,135
"@@ -40,5 +40,7 @@ public interface TopologyChangedEvent<K, V> extends Event<K, V> {
     */
    ConsistentHash getConsistentHashAtEnd();
 
+   int getNewTopologyId();
+
    //todo [anistor] add topologyId, prevReadCH, prevWriteCH, newReadCH2, newWriteCH
 }",2012-09-21T12:26:43Z,136
"@@ -95,7 +95,7 @@ public class StateConsumerImpl implements StateConsumer {
    private AtomicInteger activeTopologyUpdates = new AtomicInteger(0);
 
    /**
-    * Indicates if currently executing topology update is a rabalance.
+    * Indicates if the currently executing topology update is a rebalance.
     */
    private AtomicBoolean rebalanceInProgress = new AtomicBoolean(false);
 
@@ -197,8 +197,10 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             removedSegments.removeAll(newSegments);
 
             // remove inbound transfers and any data for segments we no longer own
-            log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                  removedSegments, newSegments, previousSegments);
+            if (trace) {
+               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
+                     removedSegments, newSegments, previousSegments);
+            }
             discardSegments(removedSegments);
 
             if (fetchEnabled) {",2012-09-21T12:26:43Z,54
"@@ -80,7 +80,7 @@ public class StateProviderImpl implements StateProvider {
    private volatile ConsistentHash readCh;
 
    /**
-    * A map that keeps track of current outbound state transfers by source address. There could be multiple transfers
+    * A map that keeps track of current outbound state transfers by destination address. There could be multiple transfers
     * flowing to the same destination (but for different segments) so the values are lists.
     */
    private final Map<Address, List<OutboundTransferTask>> transfersByDestination = new HashMap<Address, List<OutboundTransferTask>>();
@@ -124,6 +124,7 @@ public boolean isStateTransferInProgress() {
    }
 
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // do all the work AFTER the consistent hash has changed
       if (tce.isPre())
@@ -236,12 +237,14 @@ private void collectTransactionsToTransfer(List<TransactionInfo> transactionsToT
                lockedKeys.add(key);
             }
          }
-         List<WriteCommand> txModifications = tx.getModifications();
-         WriteCommand[] modifications = null;
-         if (txModifications != null) {
-            modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+         if (!lockedKeys.isEmpty()) {
+            List<WriteCommand> txModifications = tx.getModifications();
+            WriteCommand[] modifications = null;
+            if (txModifications != null) {
+               modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+            }
+            transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), tx.getViewId(), modifications, lockedKeys));
          }
-         transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), modifications, lockedKeys));
       }
    }
 ",2012-09-21T12:26:43Z,55
"@@ -48,10 +48,9 @@
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 
+//todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
 /**
  * // TODO: Document this
  *
@@ -317,8 +316,8 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       } finally {
          stateTransferLock.commandsSharedUnlock();
 
-         log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
          if (newTargets != null && !newTargets.isEmpty()) {
+            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
             rpcManager.invokeRemotely(newTargets, command, true);
          }
       }",2012-09-21T12:26:43Z,115
"@@ -178,19 +178,20 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
       // TODO Improve notification to contain both CHs
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, true);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), true);
 
       stateConsumer.onTopologyUpdate(newCacheTopology, isRebalance);
       stateProvider.onTopologyUpdate(newCacheTopology, isRebalance);
 
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, false);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
       if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
          initialStateTransferComplete.countDown();
       }
    }
 
    @Start(priority = 1000)
+   @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
       if (trace) log.tracef(""Waiting for initial state transfer to finish"");
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);",2012-09-21T12:26:43Z,117
"@@ -50,8 +50,11 @@ public class TransactionInfo {
 
    private final Set<Object> lockedKeys;
 
-   public TransactionInfo(GlobalTransaction globalTransaction, WriteCommand[] modifications, Set<Object> lockedKeys) {
+   private final int topologyId;
+
+   public TransactionInfo(GlobalTransaction globalTransaction, int topologyId, WriteCommand[] modifications, Set<Object> lockedKeys) {
       this.globalTransaction = globalTransaction;
+      this.topologyId = topologyId;
       this.modifications = modifications;
       this.lockedKeys = lockedKeys;
    }
@@ -68,10 +71,15 @@ public Set<Object> getLockedKeys() {
       return lockedKeys;
    }
 
+   public int getTopologyId() {
+      return topologyId;
+   }
+
    @Override
    public String toString() {
       return ""TransactionInfo{"" +
             ""globalTransaction="" + globalTransaction +
+            "", topologyId="" + topologyId +
             "", modifications="" + Arrays.asList(modifications) +
             "", lockedKeys="" + lockedKeys +
             '}';
@@ -92,6 +100,7 @@ public Set<Class<? extends TransactionInfo>> getTypeClasses() {
       @Override
       public void writeObject(ObjectOutput output, TransactionInfo object) throws IOException {
          output.writeObject(object.globalTransaction);
+         output.writeInt(object.topologyId);
          output.writeObject(object.modifications);
          output.writeObject(object.lockedKeys);
       }
@@ -100,9 +109,10 @@ public void writeObject(ObjectOutput output, TransactionInfo object) throws IOEx
       @SuppressWarnings(""unchecked"")
       public TransactionInfo readObject(ObjectInput input) throws IOException, ClassNotFoundException {
          GlobalTransaction globalTransaction = (GlobalTransaction) input.readObject();
+         int topologyId = input.readInt();
          WriteCommand[] modifications = (WriteCommand[]) input.readObject();
          Set<Object> lockedKeys = (Set<Object>) input.readObject();
-         return new TransactionInfo(globalTransaction, modifications, lockedKeys);
+         return new TransactionInfo(globalTransaction, topologyId, modifications, lockedKeys);
       }
    }
 }",2012-09-21T12:26:43Z,137
"@@ -31,8 +31,6 @@
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
 import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.MembershipArithmetic;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
@@ -67,37 +65,41 @@ public class StaleTransactionCleanupService {
    private TransactionTable transactionTable;
    private InterceptorChain invoker;
    private String cacheName;
+   private boolean isDistributed;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
    private ExecutorService lockBreakingService; // a thread pool with max. 1 thread
 
-   /**
-    * Roll back remote transactions originating on nodes that have left the cluster.
-    */
-   @ViewChanged
-   public void onViewChange(ViewChangedEvent vce) {
-      final List<Address> leavers = MembershipArithmetic.getMembersLeft(vce.getOldMembers(),
-                                                                        vce.getNewMembers());
-      if (!leavers.isEmpty()) {
-         log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-         cleanTxForWhichTheOwnerLeft(leavers);
-      }
-   }
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * either because the main data owner left the cluster or because a node joined
     * the cluster and is the new data owner.
     * This method will only ever be called in distributed mode.
     */
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
-      // do all the work AFTER the consistent hash has changed
-      if (tce.isPre())
+      // Roll back remote transactions originating on nodes that have left the cluster.
+      if (tce.isPre()) {
+         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+         if (consistentHashAtStart != null) {
+            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+            if (!leavers.isEmpty()) {
+               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+               cleanTxForWhichTheOwnerLeft(leavers);
+            }
+         }
+         return;
+      }
+
+      if (!isDistributed) {
          return;
+      }
+
+      // do all the work AFTER the consistent hash has changed
 
       Address self = transactionTable.rpcManager.getAddress();
       ConsistentHash chOld = tce.getConsistentHashAtStart();
@@ -173,7 +175,7 @@ public void run() {
       }
    }
 
-   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain) {
+   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain, boolean isDistributed) {
       this.invoker = interceptorChain;
       ThreadFactory tf = new ThreadFactory() {
          @Override
@@ -185,8 +187,9 @@ public Thread newThread(Runnable r) {
          }
       };
       this.cacheName = cacheName;
+      this.isDistributed = isDistributed;
       lockBreakingService = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingDeque<Runnable>(), tf,
-                                                   new ThreadPoolExecutor.CallerRunsPolicy());
+                                                   new ThreadPoolExecutor.DiscardOldestPolicy());
    }
 
    public void stop() {",2012-09-21T12:26:43Z,126
"@@ -38,11 +38,10 @@
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.interceptors.InterceptorChain;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
-import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
+import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.synchronization.SyncLocalTransaction;
@@ -57,9 +56,7 @@
 
 import javax.transaction.Transaction;
 import javax.transaction.TransactionSynchronizationRegistry;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.locks.Lock;
@@ -76,7 +73,7 @@
  * @author Galder Zamarreño
  * @since 4.0
  */
-@Listener(sync = false)
+@Listener
 public class TransactionTable {
 
    public static final int CACHE_STOPPED_VIEW_ID = -1;
@@ -95,25 +92,23 @@ public class TransactionTable {
    protected CommandsFactory commandsFactory;
    private InterceptorChain invoker;
    private CacheNotifier notifier;
-   private EmbeddedCacheManager cm;
    private TransactionSynchronizationRegistry transactionSynchronizationRegistry;
    protected ClusteringDependentLogic clusteringLogic;
    protected boolean clustered = false;
    private Lock minViewRecalculationLock;
 
    /**
-    * minTxViewId is the minimum view ID across all ongoing local and remote transactions. It doesn't update on
-    * transaction creation, but only on removal. That's because it is not possible for a newly created transaction to
-    * have an bigger view ID than the current one.
+    * minTxViewId is the minimum view ID across all ongoing local and remote transactions.
     */
    private volatile int minTxViewId = CACHE_STOPPED_VIEW_ID;
    private volatile int currentViewId = CACHE_STOPPED_VIEW_ID;
+   private volatile boolean useStrictTopologyIdComparison = true;
    private String cacheName;
 
    @Inject
    public void initialize(RpcManager rpcManager, Configuration configuration,
                           InvocationContextContainer icc, InterceptorChain invoker, CacheNotifier notifier,
-                          TransactionFactory gtf, EmbeddedCacheManager cm, TransactionCoordinator txCoordinator,
+                          TransactionFactory gtf, TransactionCoordinator txCoordinator,
                           TransactionSynchronizationRegistry transactionSynchronizationRegistry,
                           CommandsFactory commandsFactory, ClusteringDependentLogic clusteringDependentLogic, Cache cache) {
       this.rpcManager = rpcManager;
@@ -122,7 +117,6 @@ public void initialize(RpcManager rpcManager, Configuration configuration,
       this.invoker = invoker;
       this.notifier = notifier;
       this.txFactory = gtf;
-      this.cm = cm;
       this.txCoordinator = txCoordinator;
       this.transactionSynchronizationRegistry = transactionSynchronizationRegistry;
       this.commandsFactory = commandsFactory;
@@ -139,24 +133,20 @@ private void start() {
          minViewRecalculationLock = new ReentrantLock();
          // Only initialize this if we are clustered.
          remoteTransactions = ConcurrentMapFactory.makeConcurrentMap(concurrencyLevel, 0.75f, concurrencyLevel);
-         cleanupService.start(cacheName, rpcManager, invoker);
-         cm.addListener(cleanupService);
-         cm.addListener(this);
+         cleanupService.start(cacheName, rpcManager, invoker, configuration.clustering().cacheMode().isDistributed());
          notifier.addListener(cleanupService);
-         minTxViewId = rpcManager.getTransport().getViewId();
-         currentViewId = minTxViewId;
-         log.debugf(""Min view id set to %s"", minTxViewId);
+         notifier.addListener(this);
          clustered = true;
       }
    }
 
    @Stop
+   @SuppressWarnings(""unused"")
    private void stop() {
       if (clustered) {
          notifier.removeListener(cleanupService);
-         cm.removeListener(cleanupService);
          cleanupService.stop();
-         cm.removeListener(this);
+         notifier.removeListener(this);
          currentViewId = CACHE_STOPPED_VIEW_ID; // indicate that the cache has stopped
       }
       shutDownGracefully();
@@ -223,6 +213,17 @@ public int getMinViewId() {
       return minTxViewId;
    }
 
+   /**
+    * Indicates if topology id comparisons should be strict if one wants to compare topology ids in oder to tell
+    * if a transaction was started in an older topology than a second transaction. This flag is true most of the time
+    * except when the current topology did not increase its id (it's not caused by a rebalance).
+    *
+    * @return true if strict topology id comparisons should be used, false otherwise
+    */
+   public boolean useStrictTopologyIdComparison() {
+      return useStrictTopologyIdComparison;
+   }
+
    protected void updateStateOnNodesLeaving(Collection<Address> leavers) {
       Set<GlobalTransaction> toKill = new HashSet<GlobalTransaction>();
       for (GlobalTransaction gt : remoteTransactions.keySet()) {
@@ -263,14 +264,24 @@ public void remoteTransactionRollback(GlobalTransaction gtx) {
    }
 
    /**
-    * Creates and register a {@link RemoteTransaction} with no modifications. Returns the created transaction.
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
     *
     * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
     *                               made.
     */
    public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications) {
-      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, currentViewId)
-            : txFactory.newRemoteTransaction(modifications, globalTx, currentViewId);
+      return createRemoteTransaction(globalTx, modifications, currentViewId);
+   }
+
+   /**
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
+    *
+    * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
+    *                               made.
+    */
+   public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications, int topologyId) {
+      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, topologyId)
+            : txFactory.newRemoteTransaction(modifications, globalTx, topologyId);
       registerRemoteTransaction(globalTx, remoteTransaction);
       return remoteTransaction;
    }
@@ -283,6 +294,10 @@ private void registerRemoteTransaction(GlobalTransaction gtx, RemoteTransaction
       }
 
       log.tracef(""Created and registered remote transaction %s"", rtx);
+      if (rtx.getViewId() < minTxViewId) {
+         log.tracef(""Changing minimum view ID from %d to %d"", minTxViewId, rtx.getViewId());
+         minTxViewId = rtx.getViewId();
+      }
    }
 
    /**
@@ -293,6 +308,9 @@ public LocalTransaction getOrCreateLocalTransaction(Transaction transaction, TxI
       LocalTransaction current = localTransactions.get(transaction);
       if (current == null) {
          Address localAddress = rpcManager != null ? rpcManager.getTransport().getAddress() : null;
+         if (rpcManager != null && currentViewId < 0) {
+            throw new IllegalStateException(""Cannot create transactions if topology id is not known yet!"");
+         }
          GlobalTransaction tx = txFactory.newGlobalTransaction(localAddress, false);
          current = txFactory.newLocalTransaction(transaction, tx, ctx.isImplicitTransaction(), currentViewId);
          log.tracef(""Created a new local transaction: %s"", current);
@@ -310,10 +328,6 @@ public boolean removeLocalTransaction(LocalTransaction localTransaction) {
       return localTransaction != null && (removeLocalTransactionInternal(localTransaction.getTransaction()) != null);
    }
 
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      return removeLocalTransactionInternal(tx);
-   }
-
    protected final LocalTransaction removeLocalTransactionInternal(Transaction tx) {
       LocalTransaction removed;
       removed = localTransactions.remove(tx);
@@ -357,8 +371,8 @@ public int getLocalTxCount() {
 
    /**
     * Looks up a LocalTransaction given a GlobalTransaction.
-    * @param txId
-    * @return
+    * @param txId the global transaction identifier
+    * @return the LocalTransaction or null if not found
     */
    public LocalTransaction getLocalTransaction(GlobalTransaction txId) {
       for (LocalTransaction localTx : localTransactions.values()) { //todo [anistor] optimize lookup!
@@ -402,17 +416,21 @@ protected final void recalculateMinViewIdIfNeeded(CacheTransaction removedTransa
       }
    }
 
-   @ViewChanged
-   public void recalculateMinViewIdOnTopologyChange(ViewChangedEvent vce) {
-      // don't do anything if this cache is not clustered - view changes are global
+   @TopologyChanged
+   @SuppressWarnings(""unused"")
+   public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
+      // don't do anything if this cache is not clustered
       if (clustered) {
-         log.debugf(""View changed, recalculating minViewId"");
-         currentViewId = vce.getViewId();
-         calculateMinViewId(-1);
+         if (tce.isPre()) {
+            useStrictTopologyIdComparison = tce.getNewTopologyId() != currentViewId;
+            currentViewId = tce.getNewTopologyId();
+         } else {
+            log.debugf(""Topology changed, recalculating minViewId"");
+            calculateMinViewId(-1);
+         }
       }
    }
 
-
    /**
     * This method calculates the minimum view ID known by the current node.  This method is only used in a clustered
     * cache, and only invoked when either a view change is detected, or a transaction whose view ID is not the same as
@@ -442,7 +460,7 @@ private void calculateMinViewId(int idOfRemovedTransaction) {
                int viewId = ct.getViewId();
                if (viewId < minViewIdFound) minViewIdFound = viewId;
             }
-            if (minViewIdFound > minTxViewId) {
+            if (minViewIdFound != minTxViewId) {
                log.tracef(""Changing minimum view ID from %s to %s"", minTxViewId, minViewIdFound);
                minTxViewId = minViewIdFound;
             } else {",2012-09-21T12:26:43Z,127
"@@ -80,13 +80,6 @@ private void removeXidTxMapping(LocalXaTransaction localTx) {
       xid2LocalTx.remove(xid);
    }
 
-   @Override
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      final LocalTransaction remove = removeLocalTransactionInternal(tx);
-      if (remove != null) removeXidTxMapping((LocalXaTransaction) remove);
-      return remove;
-   }
-
    public LocalXaTransaction getLocalTransaction(Xid xid) {
       return this.xid2LocalTx.get(xid);
    }",2012-09-21T12:26:43Z,138
"@@ -22,10 +22,8 @@
  */
 package org.infinispan.util.concurrent.locks;
 
-import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.jmx.annotations.MBean;",2012-09-21T12:26:43Z,139
"@@ -93,15 +93,16 @@ public boolean isSatisfied() throws Exception {
          public void run() {
             try {
                log.trace(""This thread runs a different tx"");
-               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).resume(suspend);
+               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).commit();
             } catch (Exception e) {
                e.printStackTrace();
             }
          }
       }, false);
 
+      // this 'ensures' transaction called 'suspend' has the chance to start the prepare phase and is waiting to acquire the locks on k held by first transaction before it gets resumed
       Thread.sleep(1000);
 
       log.trace(""Before completing the transaction!"");",2012-09-21T12:26:43Z,140
"@@ -21,7 +21,7 @@
 /**
  * @since 5.1
  */
-@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"", enabled = false) //todo [anistor] temporarily disabled for NBST
+@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"")
 @CleanupAfterMethod
 public class MainOwnerChangesLockTest extends MultipleCacheManagersTest {
 ",2012-09-21T12:26:43Z,141
"@@ -24,6 +24,7 @@
 package org.infinispan.lock.singlelock;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.CleanupAfterMethod;
@@ -33,8 +34,7 @@
 import org.infinispan.transaction.tm.DummyTransaction;
 import org.testng.annotations.Test;
 
-import javax.transaction.Status;
-
+import static org.testng.Assert.assertTrue;
 import static org.testng.Assert.assertEquals;
 
 
@@ -60,21 +60,22 @@ protected void createCacheManagers() throws Throwable {
       waitForClusterToForm();
    }
 
-   @Test(enabled = false, description = ""See ISPN-2113"")
    public void testMinViewId1() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
+
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);
 
       //add a new cache and check that min view is updated
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId2);
       assertEquals(tt1.getMinViewId(), viewId2);
@@ -88,8 +89,8 @@ public void testMinViewId2() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
 
       tm(1).begin();
       cache(1).put(getKeyForCache(0),""v"");
@@ -109,8 +110,8 @@ public boolean isSatisfied() throws Exception {
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);",2012-09-21T12:26:43Z,142
"@@ -36,7 +36,6 @@
 import javax.transaction.InvalidTransactionException;
 import javax.transaction.NotSupportedException;
 import javax.transaction.RollbackException;
-import javax.transaction.Status;
 import javax.transaction.SystemException;
 
 import static org.testng.Assert.assertEquals;
@@ -45,7 +44,7 @@
  * @author Mircea Markus
  * @since 5.1
  */
-@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"", enabled = false, description = ""See ISPN-2113"")
+@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"")
 @CleanupAfterMethod
 public class LockOwnerCrashPessimisticTest extends AbstractLockOwnerCrashTest {
 ",2012-09-21T12:26:43Z,143
"@@ -107,4 +107,31 @@ public Xid getXid() {
    public boolean isEnlisted() {
       return xid != null;
    }
+
+   @Override
+   public boolean equals(Object o) {
+      if (this == o) return true;
+      if (o == null || getClass() != o.getClass()) return false;
+
+      LocalTransaction that = (LocalTransaction) o;
+
+      if (xid != null ? !xid.equals(that.xid) : that.xid != null) return false;
+
+      return true;
+   }
+
+   @Override
+   public int hashCode() {
+      return xid != null ? xid.hashCode() : 0;
+   }
+
+   @Override
+   public String toString() {
+      return ""LocalTransaction{"" +
+            ""remoteLockedNodes="" + remoteLockedNodes +
+            "", isMarkedForRollback="" + isMarkedForRollback +
+            "", transaction="" + transaction +
+            "", xid="" + xid +
+            ""} "" + super.toString();
+   }
 }",2011-02-11T11:59:08Z,89
"@@ -54,6 +54,7 @@
 import org.apache.cassandra.thrift.SlicePredicate;
 import org.apache.cassandra.thrift.SliceRange;
 import org.apache.cassandra.thrift.SuperColumn;
+import org.apache.cassandra.utils.ByteBufferUtil;
 import org.infinispan.Cache;
 import org.infinispan.config.ConfigurationException;
 import org.infinispan.container.entries.InternalCacheEntry;",2011-06-14T10:45:50Z,144
"@@ -59,6 +59,8 @@
 import org.rhq.helpers.pluginAnnotations.agent.Metric;
 import org.rhq.helpers.pluginAnnotations.agent.Operation;
 
+import javax.transaction.Transaction;
+import javax.transaction.TransactionManager;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
@@ -85,6 +87,7 @@ public class CacheStoreInterceptor extends JmxStatsCommandInterceptor {
    CacheStore store;
    private CacheLoaderManager loaderManager;
    private InternalEntryFactory entryFactory;
+   private TransactionManager transactionManager;
 
    private static final Log log = LogFactory.getLog(CacheStoreInterceptor.class);
 
@@ -94,9 +97,10 @@ protected Log getLog() {
    }
 
    @Inject
-   protected void init(CacheLoaderManager loaderManager, InternalEntryFactory entryFactory) {
+   protected void init(CacheLoaderManager loaderManager, InternalEntryFactory entryFactory, TransactionManager transactionManager) {
       this.loaderManager = loaderManager;
       this.entryFactory = entryFactory;
+      this.transactionManager = transactionManager;
    }
 
    @Start(priority = 15)
@@ -134,13 +138,25 @@ public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command)
             // this is a commit call.
             GlobalTransaction tx = ctx.getGlobalTransaction();
             if (getLog().isTraceEnabled()) getLog().tracef(""Calling loader.commit() for transaction %s"", tx);
+
+            //hack for ISPN-586. This should be dropped once a proper fix for ISPN-604 is in place
+            Transaction xaTx = null;
+            if (transactionManager != null) {
+               xaTx = transactionManager.suspend();
+            }
+
             try {
                store.commit(tx);
             } catch (Throwable t) {
                throw t;
             } finally {
                // Regardless of outcome, remove from preparing txs
                preparingTxs.remove(tx);
+
+               //part of the hack for ISPN-586
+               if (transactionManager != null && xaTx != null) {
+                  transactionManager.resume(xaTx);
+               }
             }
             if (getStatisticsEnabled()) {
                Integer puts = txStores.get(tx);",2012-05-11T14:12:02Z,145
"@@ -26,8 +26,8 @@
 import org.infinispan.context.impl.NonTxInvocationContext;
 import org.infinispan.context.impl.RemoteTxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
+import org.infinispan.transaction.xa.LocalTransaction;
 import org.infinispan.transaction.xa.TransactionTable;
-import org.infinispan.transaction.xa.TransactionXaAdapter;
 
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
@@ -64,8 +64,8 @@ public InvocationContext createInvocationContext() {
          } else {
             localContext = (LocalTxInvocationContext) existing;
          }
-         TransactionXaAdapter xaAdapter = transactionTable.getXaCacheAdapter(tx);
-         localContext.setXaCache(xaAdapter);
+         LocalTransaction localTransaction = transactionTable.getLocalTransaction(tx);
+         localContext.setLocalTransaction(localTransaction);
          return localContext;
       } else {
          NonTxInvocationContext nonTxContext;",2010-12-09T08:05:14Z,85
"@@ -4,7 +4,7 @@
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.xa.GlobalTransaction;
-import org.infinispan.transaction.xa.TransactionXaAdapter;
+import org.infinispan.transaction.xa.LocalTransaction;
 import org.infinispan.util.BidirectionalMap;
 
 import javax.transaction.Transaction;
@@ -20,10 +20,10 @@
  */
 public class LocalTxInvocationContext extends AbstractTxInvocationContext {
 
-   private volatile TransactionXaAdapter xaAdapter;
+   private volatile LocalTransaction localTransaction;
 
    public Transaction getRunningTransaction() {
-      return xaAdapter.getTransaction();
+      return localTransaction.getTransaction();
    }
 
    public boolean isOriginLocal() {
@@ -35,53 +35,53 @@ public boolean isInTxScope() {
    }
 
    public Object getLockOwner() {
-      return xaAdapter.getGlobalTx();
+      return localTransaction.getGlobalTransaction();
    }
 
    public GlobalTransaction getGlobalTransaction() {
-      return xaAdapter.getGlobalTx();
+      return localTransaction.getGlobalTransaction();
    }
 
    public List<WriteCommand> getModifications() {
-      return xaAdapter == null ? null : xaAdapter.getModifications();
+      return localTransaction == null ? null : localTransaction.getModifications();
    }
 
-   public void setXaCache(TransactionXaAdapter xaAdapter) {
-      this.xaAdapter = xaAdapter;
+   public void setLocalTransaction(LocalTransaction localTransaction) {
+      this.localTransaction = localTransaction;
    }
 
    public CacheEntry lookupEntry(Object key) {
-      return xaAdapter != null ? xaAdapter.lookupEntry(key) : null;
+      return localTransaction != null ? localTransaction.lookupEntry(key) : null;
    }
 
    public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
-      return xaAdapter.getLookedUpEntries();
+      return localTransaction.getLookedUpEntries();
    }
 
    public void putLookedUpEntry(Object key, CacheEntry e) {
-      xaAdapter.putLookedUpEntry(key, e);
+      localTransaction.putLookedUpEntry(key, e);
    }
 
    public void putLookedUpEntries(Map<Object, CacheEntry> lookedUpEntries) {
       for (Map.Entry<Object, CacheEntry> ce: lookedUpEntries.entrySet()) {
-         xaAdapter.putLookedUpEntry(ce.getKey(), ce.getValue());
+         localTransaction.putLookedUpEntry(ce.getKey(), ce.getValue());
       }
    }
 
    public void removeLookedUpEntry(Object key) {
-      xaAdapter.removeLookedUpEntry(key);
+      localTransaction.removeLookedUpEntry(key);
    }
 
    public void clearLookedUpEntries() {
-      xaAdapter.clearLookedUpEntries();
+      localTransaction.clearLookedUpEntries();
    }
 
    @Override
    public boolean hasLockedKey(Object key) {
-      return xaAdapter != null && super.hasLockedKey(key);
+      return localTransaction != null && super.hasLockedKey(key);
    }
 
    public void remoteLocksAcquired(Collection<Address> nodes) {
-      xaAdapter.locksAcquired(nodes);
+      localTransaction.locksAcquired(nodes);
    }
 }",2010-12-09T08:05:14Z,86
"@@ -1,5 +1,7 @@
 package org.infinispan.interceptors;
 
+import org.infinispan.CacheException;
+import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.GetKeyValueCommand;
@@ -16,6 +18,7 @@
 import org.infinispan.config.Configuration;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
+import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
@@ -24,6 +27,7 @@
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.transaction.TransactionLog;
+import org.infinispan.transaction.xa.LocalTransaction;
 import org.infinispan.transaction.xa.TransactionTable;
 import org.infinispan.transaction.xa.TransactionXaAdapter;
 import org.rhq.helpers.pluginAnnotations.agent.DataType;
@@ -61,14 +65,20 @@ public class TxInterceptor extends CommandInterceptor {
    private final AtomicLong rollbacks = new AtomicLong(0);
    @ManagedAttribute(description = ""Enables or disables the gathering of statistics by this component"", writable = true)
    private boolean statisticsEnabled;
+   private CommandsFactory commandsFactory;
+   private InvocationContextContainer icc;
+   private InterceptorChain invoker;
 
 
    @Inject
-   public void init(TransactionManager tm, TransactionTable txTable, TransactionLog transactionLog, Configuration c) {
+   public void init(TransactionManager tm, TransactionTable txTable, TransactionLog transactionLog, Configuration c, CommandsFactory commandsFactory, InvocationContextContainer icc, InterceptorChain invoker) {
       this.configuration = c;
       this.tm = tm;
       this.transactionLog = transactionLog;
       this.txTable = txTable;
+      this.commandsFactory = commandsFactory;
+      this.icc = icc;
+      this.invoker = invoker;
       setStatisticsEnabled(configuration.isExposeJmxStatistics());
    }
 
@@ -152,37 +162,46 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
 
    private Object enlistReadAndInvokeNext(InvocationContext ctx, VisitableCommand command) throws Throwable {
       if (shouldEnlist(ctx)) {
-         TransactionXaAdapter xaAdapter = enlist(ctx);
+         LocalTransaction localTransaction = enlist(ctx);
          LocalTxInvocationContext localTxContext = (LocalTxInvocationContext) ctx;
-         localTxContext.setXaCache(xaAdapter);
+         localTxContext.setLocalTransaction(localTransaction);
       }
       return invokeNextInterceptor(ctx, command);
    }
 
    private Object enlistWriteAndInvokeNext(InvocationContext ctx, WriteCommand command) throws Throwable {
-      TransactionXaAdapter xaAdapter = null;
+      LocalTransaction localTransaction = null;
       boolean shouldAddMod = false;
       if (shouldEnlist(ctx)) {
-         xaAdapter = enlist(ctx);
+         localTransaction = enlist(ctx);
          LocalTxInvocationContext localTxContext = (LocalTxInvocationContext) ctx;
          if (localModeNotForced(ctx)) shouldAddMod = true;
-         localTxContext.setXaCache(xaAdapter);
+         localTxContext.setLocalTransaction(localTransaction);
       }
       Object rv;
       rv = invokeNextInterceptor(ctx, command);
       if (!ctx.isInTxScope())
          transactionLog.logNoTxWrite(command);
-      if (command.isSuccessful() && shouldAddMod) xaAdapter.addModification(command);
+      if (command.isSuccessful() && shouldAddMod) localTransaction.addModification(command);
       return rv;
    }
 
-   public TransactionXaAdapter enlist(InvocationContext ctx) throws SystemException, RollbackException {
+   public LocalTransaction enlist(InvocationContext ctx) throws SystemException, RollbackException {
       Transaction transaction = tm.getTransaction();
       if (transaction == null) throw new IllegalStateException(""This should only be called in an tx scope"");
       int status = transaction.getStatus();
       if (isNotValid(status)) throw new IllegalStateException(""Transaction "" + transaction +
             "" is not in a valid state to be invoking cache operations on."");
-      return txTable.getOrCreateXaAdapter(transaction, ctx);
+      LocalTransaction localTransaction = txTable.getOrCreateLocalTransaction(transaction, ctx);
+      if (!localTransaction.isEnlisted()) { //make sure that you only enlist it once
+         try {
+            transaction.enlistResource(new TransactionXaAdapter(localTransaction, txTable, commandsFactory, configuration, invoker, icc));
+         } catch (Exception e) {
+            log.error(""Failed to enlist TransactionXaAdapter to transaction"");
+            throw new CacheException(e);
+         }
+      }
+      return localTransaction;
    }
 
    private boolean isNotValid(int status) {",2010-12-09T08:05:14Z,87
"@@ -0,0 +1,46 @@
+package org.infinispan.transaction.xa;
+
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.util.BidirectionalLinkedHashMap;
+import org.infinispan.util.BidirectionalMap;
+
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * Base class for local and remote transaction.
+ * Impl note: The aggregated modification list and lookedUpEntries are not instantiated here but in subclasses.
+ * This is done in order to take advantage of the fact that, for remote transactions we already know the size of the
+ * modifications list at creation time.
+ *
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+public abstract class AbstractCacheTransaction implements CacheTransaction {
+
+   protected List<WriteCommand> modifications;
+   protected BidirectionalLinkedHashMap<Object, CacheEntry> lookedUpEntries;
+   protected GlobalTransaction tx;
+
+
+   public GlobalTransaction getGlobalTransaction() {
+      return tx;
+   }
+
+   public List<WriteCommand> getModifications() {
+      return modifications;
+   }
+
+   public void setModifications(WriteCommand[] modifications) {
+      this.modifications = Arrays.asList(modifications);
+   }
+
+   public CacheEntry lookupEntry(Object key) {
+      return lookedUpEntries.get(key);
+   }
+
+   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
+      return lookedUpEntries;
+   }
+}",2010-12-09T08:05:14Z,88
"@@ -0,0 +1,117 @@
+package org.infinispan.transaction.xa;
+
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.util.BidirectionalLinkedHashMap;
+import org.infinispan.util.BidirectionalMap;
+import org.infinispan.util.InfinispanCollections;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+import javax.transaction.Transaction;
+import javax.transaction.xa.Xid;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+/**
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+public class LocalTransaction extends AbstractCacheTransaction {
+
+   private static Log log = LogFactory.getLog(LocalTransaction.class);
+   private static final boolean trace = log.isTraceEnabled();
+
+   private Set<Address> remoteLockedNodes;
+
+   /** mark as volatile as this might be set from the tx thread code on view change*/
+   private volatile boolean isMarkedForRollback;
+
+   private final Transaction transaction;
+   private Xid xid;
+
+   public LocalTransaction(Transaction transaction, GlobalTransaction tx) {
+      super.tx = tx;
+      this.transaction = transaction;
+   }
+
+   public void addModification(WriteCommand mod) {
+      if (trace) log.trace(""Adding modification {0}. Mod list is {1}"", mod, modifications);
+      if (modifications == null) {
+         modifications = new ArrayList<WriteCommand>(8);
+      }
+      modifications.add(mod);
+   }
+
+   public boolean hasRemoteLocksAcquired(List<Address> leavers) {
+      if (log.isTraceEnabled()) {
+         log.trace(""My remote locks: "" + remoteLockedNodes + "", leavers are:"" + leavers);
+      }
+      return (remoteLockedNodes != null) && !Collections.disjoint(remoteLockedNodes, leavers);
+   }
+
+   public void locksAcquired(Collection<Address> nodes) {
+      if (remoteLockedNodes == null) remoteLockedNodes = new HashSet<Address>();
+      remoteLockedNodes.addAll(nodes);
+   }
+
+   public void markForRollback() {
+      isMarkedForRollback = true;
+   }
+
+   public boolean isMarkedForRollback() {
+      return isMarkedForRollback;
+   }
+
+   public Transaction getTransaction() {
+      return transaction;
+   }
+
+   public CacheEntry lookupEntry(Object key) {
+      if (lookedUpEntries == null) return null;
+      return lookedUpEntries.get(key);
+   }
+
+   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
+      return (BidirectionalMap<Object, CacheEntry>)
+            (lookedUpEntries == null ? InfinispanCollections.emptyBidirectionalMap() : lookedUpEntries);
+   }
+
+   public void putLookedUpEntry(Object key, CacheEntry e) {
+      if (lookedUpEntries == null) lookedUpEntries = new BidirectionalLinkedHashMap<Object, CacheEntry>(4);
+      lookedUpEntries.put(key, e);
+   }
+
+   public void removeLookedUpEntry(Object key) {
+      if (lookedUpEntries != null) lookedUpEntries.remove(key);
+   }
+
+   public void clearLookedUpEntries() {
+      if (lookedUpEntries != null) lookedUpEntries.clear();
+   }
+
+   public boolean isReadOnly() {
+      return (modifications == null || modifications.isEmpty()) && (lookedUpEntries == null || lookedUpEntries.isEmpty());
+   }
+
+   public void setXid(Xid xid) {
+      this.xid = xid;
+   }
+
+   public Xid getXid() {
+      return xid;
+   }
+
+   /**
+    * As per the JTA spec, XAResource.start is called on enlistment. That method also sets the xid for this local
+    * transaction.
+    */
+   public boolean isEnlisted() {
+      return xid != null;
+   }
+}",2010-12-09T08:05:14Z,89
"@@ -21,19 +21,12 @@
  * @author Mircea.Markus@jboss.com
  * @since 4.0
  */
-public class RemoteTransaction implements CacheTransaction, Cloneable {
+public class RemoteTransaction extends AbstractCacheTransaction implements Cloneable {
 
    private static Log log = LogFactory.getLog(RemoteTransaction.class);
 
-   private List<WriteCommand> modifications;
-
-   private BidirectionalLinkedHashMap<Object, CacheEntry> lookedUpEntries;
-
-   private GlobalTransaction tx;
-
    private volatile boolean valid = true;
 
-
    public RemoteTransaction(WriteCommand[] modifications, GlobalTransaction tx) {
       this.modifications = modifications == null || modifications.length == 0 ? Collections.<WriteCommand>emptyList() : Arrays.asList(modifications);
       lookedUpEntries = new BidirectionalLinkedHashMap<Object, CacheEntry>(this.modifications.size());
@@ -50,26 +43,6 @@ public void invalidate() {
       valid = false;
    }
 
-   public GlobalTransaction getGlobalTransaction() {
-      return tx;
-   }
-
-   public List<WriteCommand> getModifications() {
-      return modifications;
-   }
-
-   public void setModifications(WriteCommand[] modifications) {
-      this.modifications = Arrays.asList(modifications);
-   }
-
-   public CacheEntry lookupEntry(Object key) {
-      return lookedUpEntries.get(key);
-   }
-
-   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
-      return lookedUpEntries;
-   }
-
    public void putLookedUpEntry(Object key, CacheEntry e) {
       if (valid) {
          if (log.isTraceEnabled()) {",2010-12-09T08:05:14Z,90
"@@ -1,7 +1,5 @@
 package org.infinispan.transaction.xa;
 
-import org.infinispan.CacheException;
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.tx.RollbackCommand;
 import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.config.Configuration;
@@ -23,6 +21,7 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.Transaction;
+import javax.transaction.xa.Xid;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -46,13 +45,14 @@ public class TransactionTable {
    private static final Log log = LogFactory.getLog(TransactionTable.class);
    private static boolean trace = log.isTraceEnabled();
 
-   private final Map<Transaction, TransactionXaAdapter> localTransactions = new ConcurrentHashMap<Transaction, TransactionXaAdapter>();
+   private final Map<Transaction, LocalTransaction> localTransactions = new ConcurrentHashMap<Transaction, LocalTransaction>();
 
    private final Map<GlobalTransaction, RemoteTransaction> remoteTransactions = new ConcurrentHashMap<GlobalTransaction, RemoteTransaction>();
 
+   private final Map<Xid, LocalTransaction> xid2LocalTx = new ConcurrentHashMap<Xid, LocalTransaction>();
+
    private final Object listener = new StaleTransactionCleanup();
    
-   private CommandsFactory commandsFactory;
    private Configuration configuration;
    private InvocationContextContainer icc;
    private InterceptorChain invoker;
@@ -63,10 +63,9 @@ public class TransactionTable {
    private EmbeddedCacheManager cm;
 
    @Inject
-   public void initialize(CommandsFactory commandsFactory, RpcManager rpcManager, Configuration configuration,
+   public void initialize(RpcManager rpcManager, Configuration configuration,
                           InvocationContextContainer icc, InterceptorChain invoker, CacheNotifier notifier,
                           GlobalTransactionFactory gtf, EmbeddedCacheManager cm) {
-      this.commandsFactory = commandsFactory;
       this.rpcManager = rpcManager;
       this.configuration = configuration;
       this.icc = icc;
@@ -94,6 +93,15 @@ public Set<Object> getLockedKeysForRemoteTransaction(GlobalTransaction gtx) {
       return transaction.getLockedKeys();
    }
 
+   public LocalTransaction getLocalTransaction(Xid xid) {
+      return this.xid2LocalTx.get(xid);
+   }
+
+   public void addLocalTransactionMapping(LocalTransaction localTransaction) {
+      if (localTransaction.getXid() == null) throw new IllegalStateException(""Initialize xid first!"");
+      this.xid2LocalTx.put(localTransaction.getXid(), localTransaction);
+   }
+
    @Listener
    public class StaleTransactionCleanup {
       @ViewChanged
@@ -103,9 +111,9 @@ public void onViewChange(ViewChangedEvent vce) {
             if (trace) log.trace(""Saw {0} leavers - kicking off a lock breaking task"", leavers.size());
             cleanTxForWhichTheOwnerLeft(leavers);
             if (configuration.isUseEagerLocking() && configuration.isEagerLockSingleNode() && configuration.getCacheMode().isDistributed()) {
-               for (TransactionXaAdapter xaAdapter : localTransactions.values()) {
-                  if (xaAdapter.hasRemoteLocksAcquired(leavers)) {
-                     xaAdapter.markForRollback();
+               for (LocalTransaction localTx : localTransactions.values()) {
+                  if (localTx.hasRemoteLocksAcquired(leavers)) {
+                     localTx.markForRollback();
                   }
                }
             }
@@ -198,20 +206,14 @@ private void registerRemoteTransaction(GlobalTransaction gtx, RemoteTransaction
     * Returns the {@link org.infinispan.transaction.xa.TransactionXaAdapter} corresponding to the supplied transaction.
     * If none exists, will be created first.
     */
-   public TransactionXaAdapter getOrCreateXaAdapter(Transaction transaction, InvocationContext ctx) {
-      TransactionXaAdapter current = localTransactions.get(transaction);
+   public LocalTransaction getOrCreateLocalTransaction(Transaction transaction, InvocationContext ctx) {
+      LocalTransaction current = localTransactions.get(transaction);
       if (current == null) {
          Address localAddress = rpcManager != null ? rpcManager.getTransport().getAddress() : null;
          GlobalTransaction tx = gtf.newGlobalTransaction(localAddress, false);
          if (trace) log.trace(""Created a new GlobalTransaction {0}"", tx);
-         current = new TransactionXaAdapter(tx, icc, invoker, commandsFactory, configuration, this, transaction);
+         current = new LocalTransaction(transaction, tx);
          localTransactions.put(transaction, current);
-         try {
-            transaction.enlistResource(current);
-         } catch (Exception e) {
-            log.error(""Failed to enlist TransactionXaAdapter to transaction"");
-            throw new CacheException(e);
-         }
          notifier.notifyTransactionRegistered(tx, ctx);
       }
       return current;
@@ -221,8 +223,9 @@ public TransactionXaAdapter getOrCreateXaAdapter(Transaction transaction, Invoca
     * Removes the {@link org.infinispan.transaction.xa.TransactionXaAdapter} corresponding to the given tx. Returns true
     * if such an tx exists.
     */
-   public boolean removeLocalTransaction(Transaction tx) {
-      return localTransactions.remove(tx) != null;
+   public boolean removeLocalTransaction(LocalTransaction localTransaction) {
+      xid2LocalTx.remove(localTransaction.getXid());
+      return localTransactions.remove(localTransaction.getTransaction()) != null;
    }
 
    /**
@@ -245,13 +248,11 @@ public int getLocalTxCount() {
       return localTransactions.size();
    }
 
-   public TransactionXaAdapter getXaCacheAdapter(Transaction tx) {
+   public LocalTransaction getLocalTransaction(Transaction tx) {
       return localTransactions.get(tx);
    }
 
    public boolean containRemoteTx(GlobalTransaction globalTransaction) {
       return remoteTransactions.containsKey(globalTransaction);
    }
-
-
 }",2010-12-09T08:05:14Z,91
"@@ -4,29 +4,16 @@
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.tx.RollbackCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.config.Configuration;
-import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.interceptors.InterceptorChain;
-import org.infinispan.remoting.transport.Address;
-import org.infinispan.util.BidirectionalLinkedHashMap;
-import org.infinispan.util.BidirectionalMap;
-import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import javax.transaction.Transaction;
 import javax.transaction.xa.XAException;
 import javax.transaction.xa.XAResource;
 import javax.transaction.xa.Xid;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
 
 /**
  * This acts both as an local {@link org.infinispan.transaction.xa.CacheTransaction} and implementor of an {@link
@@ -35,91 +22,94 @@
  * @author Mircea.Markus@jboss.com
  * @since 4.0
  */
-public class TransactionXaAdapter implements CacheTransaction, XAResource {
+public class TransactionXaAdapter implements XAResource {
 
    private static final Log log = LogFactory.getLog(TransactionXaAdapter.class);
    private static boolean trace = log.isTraceEnabled();
 
    private int txTimeout;
 
-   private volatile List<WriteCommand> modifications;
-   private BidirectionalMap<Object, CacheEntry> lookedUpEntries;
+   private final InvocationContextContainer icc;
+   private final InterceptorChain invoker;
 
-   private GlobalTransaction globalTx;
-   private InvocationContextContainer icc;
-   private InterceptorChain invoker;
+   private final CommandsFactory commandsFactory;
+   private final Configuration configuration;
 
-   private CommandsFactory commandsFactory;
-   private Configuration configuration;
+   private final TransactionTable txTable;
 
-   private TransactionTable txTable;
-   private Transaction transaction;
+   /**
+    * XAResource is associated with a transaction between enlistment (XAResource.start()) XAResource.end(). It's only the
+    * boundary methods (prepare, commit, rollback) that need to be ""stateless"".
+    * Reefer to section 3.4.4 from JTA spec v.1.1
+    */
+   private final LocalTransaction localTransaction;
 
-   private Set<Address> remoteLockedNodes;
-   private boolean isMarkedForRollback;
 
-
-   public TransactionXaAdapter(GlobalTransaction globalTx, InvocationContextContainer icc, InterceptorChain invoker,
-                               CommandsFactory commandsFactory, Configuration configuration, TransactionTable txTable,
-                               Transaction transaction) {
-      this.globalTx = globalTx;
-      this.icc = icc;
-      this.invoker = invoker;
+   public TransactionXaAdapter(LocalTransaction localTransaction, TransactionTable txTable, CommandsFactory commandsFactory,
+                               Configuration configuration, InterceptorChain invoker, InvocationContextContainer icc) {
+      this.localTransaction = localTransaction;
+      this.txTable = txTable;
       this.commandsFactory = commandsFactory;
       this.configuration = configuration;
-      this.txTable = txTable;
-      this.transaction = transaction;
-   }
-
-   public void addModification(WriteCommand mod) {
-      if (trace) log.trace(""Adding modification {0}. Mod list is {1}"", mod, modifications);
-      if (modifications == null) {
-         modifications = new ArrayList<WriteCommand>(8);
-      }
-      modifications.add(mod);
+      this.invoker = invoker;
+      this.icc = icc;
    }
 
+   /**
+    * This can be call for any transaction object. See Section 3.4.6 (Resource Sharing) from JTA spec v1.1.
+    */
    public int prepare(Xid xid) throws XAException {
-      checkMarkedForRollback();
+      LocalTransaction localTransaction = getLocalTransactionAndValidate(xid);
+      
+      validateNotMarkedForRollback(localTransaction);
+
       if (configuration.isOnePhaseCommit()) {
-         if (trace)
-            log.trace(""Received prepare for tx: "" + xid + "" . Skipping call as 1PC will be used."");
+         if (trace) log.trace(""Received prepare for tx: {0}. Skipping call as 1PC will be used."", xid);
          return XA_OK;
       }
 
-      PrepareCommand prepareCommand = commandsFactory.buildPrepareCommand(globalTx, modifications, configuration.isOnePhaseCommit());
+      PrepareCommand prepareCommand = commandsFactory.buildPrepareCommand(localTransaction.getGlobalTransaction(), localTransaction.getModifications(), configuration.isOnePhaseCommit());
       if (trace) log.trace(""Sending prepare command through the chain: "" + prepareCommand);
 
       LocalTxInvocationContext ctx = icc.createTxInvocationContext();
-      ctx.setXaCache(this);
+      ctx.setLocalTransaction(localTransaction);
       try {
          invoker.invoke(ctx, prepareCommand);
-         return XA_OK;
+         if (localTransaction.isReadOnly()) {
+            if (trace) log.trace(""Readonly transaction: "" + localTransaction.getGlobalTransaction());
+            return XA_RDONLY;
+         } else {
+            return XA_OK;
+         }
       } catch (Throwable e) {
          log.error(""Error while processing PrepareCommand"", e);
          throw new XAException(XAException.XAER_RMERR);
       }
    }
 
+   /**
+    * Same comment as for {@link #prepare(javax.transaction.xa.Xid)} applies for commit.
+    */
    public void commit(Xid xid, boolean isOnePhase) throws XAException {
-      // always call prepare() - even if this is just a 1PC!
-      if (isOnePhase) prepare(xid);
-      if (trace) log.trace(""committing transaction: "" + globalTx);
+      LocalTransaction localTransaction = getLocalTransactionAndValidate(xid);
+
+      if (trace) log.trace(""committing transaction {0}"" + localTransaction.getGlobalTransaction());
       try {
          LocalTxInvocationContext ctx = icc.createTxInvocationContext();
-         ctx.setXaCache(this);
-         if (configuration.isOnePhaseCommit()) {
-            checkMarkedForRollback();
+         ctx.setLocalTransaction(localTransaction);
+         if (configuration.isOnePhaseCommit() || isOnePhase) {
+            validateNotMarkedForRollback(localTransaction);
+
             if (trace) log.trace(""Doing an 1PC prepare call on the interceptor chain"");
-            PrepareCommand command = commandsFactory.buildPrepareCommand(globalTx, modifications, true);
+            PrepareCommand command = commandsFactory.buildPrepareCommand(localTransaction.getGlobalTransaction(), localTransaction.getModifications(), true);
             try {
                invoker.invoke(ctx, command);
             } catch (Throwable e) {
                log.error(""Error while processing 1PC PrepareCommand"", e);
                throw new XAException(XAException.XAER_RMERR);
             }
          } else {
-            CommitCommand commitCommand = commandsFactory.buildCommitCommand(globalTx);
+            CommitCommand commitCommand = commandsFactory.buildCommitCommand(localTransaction.getGlobalTransaction());
             try {
                invoker.invoke(ctx, commitCommand);
             } catch (Throwable e) {
@@ -128,35 +118,46 @@ public void commit(Xid xid, boolean isOnePhase) throws XAException {
             }
          }
       } finally {
-         txTable.removeLocalTransaction(transaction);
-         icc.suspend();
-         this.modifications = null;
+         cleanup(localTransaction);
       }
    }
 
-   public void rollback(Xid xid) throws XAException {
-      if (trace) log.trace(""rollback transaction: "" + globalTx);
-      RollbackCommand rollbackCommand = commandsFactory.buildRollbackCommand(globalTx);
+   /**
+    * Same comment as for {@link #prepare(javax.transaction.xa.Xid)} applies for commit.
+    */   
+   public void rollback(Xid xid) throws XAException {      
+      LocalTransaction localTransaction = getLocalTransactionAndValidate(xid);
+      if (trace) log.trace(""rollback transaction {0} "", localTransaction.getGlobalTransaction());
+      RollbackCommand rollbackCommand = commandsFactory.buildRollbackCommand(localTransaction.getGlobalTransaction());
       LocalTxInvocationContext ctx = icc.createTxInvocationContext();
-      ctx.setXaCache(this);
+      ctx.setLocalTransaction(localTransaction);
       try {
          invoker.invoke(ctx, rollbackCommand);
       } catch (Throwable e) {
          log.error(""Exception while rollback"", e);
          throw new XAException(XAException.XA_HEURHAZ);
       } finally {
-         txTable.removeLocalTransaction(transaction);
-         icc.suspend();
-         this.modifications = null;
+         cleanup(localTransaction);
+      }
+   }
+
+   private LocalTransaction getLocalTransactionAndValidate(Xid xid) throws XAException {
+      LocalTransaction localTransaction = txTable.getLocalTransaction(xid);
+      if  (localTransaction == null) {
+         if (trace) log.trace(""no tx found for {0}"", xid);
+         throw new XAException(XAException.XAER_NOTA);
       }
+      return localTransaction;
    }
 
    public void start(Xid xid, int i) throws XAException {
-      if (trace) log.trace(""start called on tx "" + this.globalTx);
+      localTransaction.setXid(xid);
+      txTable.addLocalTransactionMapping(localTransaction);
+      if (trace) log.trace(""start called on tx "" + this.localTransaction.getGlobalTransaction());
    }
 
    public void end(Xid xid, int i) throws XAException {
-      if (trace) log.trace(""end called on tx "" + this.globalTx);
+      if (trace) log.trace(""end called on tx "" + this.localTransaction.getGlobalTransaction());
    }
 
    public void forget(Xid xid) throws XAException {
@@ -186,95 +187,35 @@ public boolean setTransactionTimeout(int i) throws XAException {
       return true;
    }
 
-   public CacheEntry lookupEntry(Object key) {
-      if (lookedUpEntries == null) return null;
-      return lookedUpEntries.get(key);
-   }
-
-   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
-      return (BidirectionalMap<Object, CacheEntry>)
-            (lookedUpEntries == null ? InfinispanCollections.emptyBidirectionalMap() : lookedUpEntries);
-   }
-
-   public void putLookedUpEntry(Object key, CacheEntry e) {
-      initLookedUpEntries();
-      lookedUpEntries.put(key, e);
-   }
-
-   private void initLookedUpEntries() {
-      if (lookedUpEntries == null) lookedUpEntries = new BidirectionalLinkedHashMap<Object, CacheEntry>(4);
-   }
-
-   public GlobalTransaction getGlobalTx() {
-      return globalTx;
-   }
-
-   public List<WriteCommand> getModifications() {
-      if (trace) log.trace(""Retrieving modification list {0}."", modifications);
-      return modifications;
-   }
-
-   public Transaction getTransaction() {
-      return transaction;
-   }
-
-   public GlobalTransaction getGlobalTransaction() {
-      return globalTx;
-   }
-
-   public void removeLookedUpEntry(Object key) {
-      if (lookedUpEntries != null) lookedUpEntries.remove(key);
-   }
-
-   public void clearLookedUpEntries() {
-      if (lookedUpEntries != null) lookedUpEntries.clear();
-   }
-
    @Override
    public boolean equals(Object o) {
       if (this == o) return true;
       if (!(o instanceof TransactionXaAdapter)) return false;
-
       TransactionXaAdapter that = (TransactionXaAdapter) o;
-
-      if (!globalTx.equals(that.globalTx)) return false;
-
-      return true;
+      return this.localTransaction.equals(that.localTransaction);
    }
 
    @Override
    public int hashCode() {
-      return globalTx.hashCode();
+      return localTransaction.getGlobalTransaction().hashCode();
    }
 
    @Override
    public String toString() {
       return ""TransactionXaAdapter{"" +
-            ""modifications="" + modifications +
-            "", lookedUpEntries="" + lookedUpEntries +
-            "", globalTx="" + globalTx +
-            "", transaction="" + transaction +
-            "", txTimeout="" + txTimeout +
+            ""localTransaction="" + localTransaction +
             '}';
    }
 
-   public boolean hasRemoteLocksAcquired(List<Address> leavers) {
-      if (log.isTraceEnabled()) {
-         log.trace(""My remote locks: "" + remoteLockedNodes + "", leavers are:"" + leavers);
+   private void validateNotMarkedForRollback(LocalTransaction localTransaction) throws XAException {
+      if (localTransaction.isMarkedForRollback()) {
+         if (trace) log.trace(""Transaction already marked for rollback: {0}"", localTransaction);
+         throw new XAException(XAException.XA_RBROLLBACK);
       }
-      return (remoteLockedNodes != null) && !Collections.disjoint(remoteLockedNodes, leavers);
-   }
-
-   public void locksAcquired(Collection<Address> nodes) {
-      if (remoteLockedNodes == null) remoteLockedNodes = new HashSet<Address>();
-      remoteLockedNodes.addAll(nodes);
-   }
-
-   public void markForRollback() {
-      isMarkedForRollback = true;
    }
 
-   private void checkMarkedForRollback() throws XAException {
-      if (isMarkedForRollback) throw new XAException(XAException.XA_RBOTHER);
+   private void cleanup(LocalTransaction localTransaction) {
+      txTable.removeLocalTransaction(localTransaction);
+      icc.suspend();
    }   
 }",2010-12-09T08:05:14Z,92
"@@ -0,0 +1,61 @@
+package org.infinispan.tx;
+
+import org.infinispan.config.Configuration;
+import org.infinispan.context.Flag;
+import org.infinispan.manager.DefaultCacheManager;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.SingleCacheManagerTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.transaction.xa.LocalTransaction;
+import org.infinispan.transaction.xa.TransactionTable;
+import org.testng.annotations.Test;
+
+import javax.transaction.Transaction;
+
+/**
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+@Test (groups = ""functional"", testName = ""tx.ReadOnlyTxTest"")
+@CleanupAfterMethod
+public class ReadOnlyTxTest extends SingleCacheManagerTest {
+
+   @Override
+   protected EmbeddedCacheManager createCacheManager() throws Exception {
+      Configuration configuration = getDefaultClusteredConfig(Configuration.CacheMode.LOCAL, true);
+      return new DefaultCacheManager(configuration);
+   }
+
+   public void testSimpleReadOnlTx() throws Exception {
+      tm().begin();
+      assert cache.get(""k"") == null;
+      Transaction transaction = tm().suspend();
+      LocalTransaction localTransaction = txTable().getLocalTransaction(transaction);
+      assert localTransaction != null && localTransaction.isReadOnly();
+   }
+
+   public void testNotROWhenHasWrites() throws Exception {
+      tm().begin();
+      cache.put(""k"", ""v"");
+      assert TestingUtil.extractLockManager(cache).isLocked(""k"");
+      Transaction transaction = tm().suspend();
+      LocalTransaction localTransaction = txTable().getLocalTransaction(transaction);
+      assert localTransaction != null && !localTransaction.isReadOnly();
+   }
+
+   public void testNotROWhenHasOnlyLocks() throws Exception {
+      cache.put(""k"", ""v"");
+      tm().begin();
+      cache.getAdvancedCache().withFlags(Flag.FORCE_WRITE_LOCK).get(""k"");
+      assert TestingUtil.extractLockManager(cache).isLocked(""k"");
+      Transaction transaction = tm().suspend();
+      LocalTransaction localTransaction = txTable().getLocalTransaction(transaction);
+      assert localTransaction != null && !localTransaction.isReadOnly();
+   }
+
+
+   private TransactionTable txTable() {
+      return TestingUtil.getTransactionTable(cache);
+   }
+}",2010-12-09T08:05:14Z,93
"@@ -0,0 +1,110 @@
+package org.infinispan.tx;
+
+import org.infinispan.config.Configuration;
+import org.infinispan.transaction.tm.DummyTransaction;
+import org.infinispan.transaction.tm.DummyXid;
+import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.transaction.xa.GlobalTransactionFactory;
+import org.infinispan.transaction.xa.LocalTransaction;
+import org.infinispan.transaction.xa.TransactionTable;
+import org.infinispan.transaction.xa.TransactionXaAdapter;
+import org.testng.annotations.BeforeMethod;
+import org.testng.annotations.Test;
+
+import javax.transaction.xa.XAException;
+import javax.transaction.xa.XAResource;
+
+/**
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+@Test(testName = ""tx.TransactionXaAdapterTest"", groups = ""unit"")
+public class TransactionXaAdapterTmIntegrationTest {
+   private Configuration configuration;
+   private TransactionTable txTable;
+   private GlobalTransaction globalTransaction;
+   private LocalTransaction localTx;
+   private TransactionXaAdapter xaAdapter;
+   private DummyXid xid;
+
+   @BeforeMethod
+   public void setUp() {
+      txTable = new TransactionTable();
+      GlobalTransactionFactory gtf = new GlobalTransactionFactory();
+      globalTransaction = gtf.newGlobalTransaction(null, false);
+      localTx = new LocalTransaction(new DummyTransaction(null), globalTransaction);
+      xid = new DummyXid();
+      localTx.setXid(xid);
+      txTable.addLocalTransactionMapping(localTx);      
+
+      configuration = new Configuration();
+      xaAdapter = new TransactionXaAdapter(localTx, txTable, null, configuration, null, null);
+   }
+
+   public void testPrepareOnNonexistentXid() {
+      DummyXid xid = new DummyXid();
+      try {
+         xaAdapter.prepare(xid);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void testCommitOnNonexistentXid() {
+      DummyXid xid = new DummyXid();
+      try {
+         xaAdapter.commit(xid, false);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void testRollabckOnNonexistentXid() {
+      DummyXid xid = new DummyXid();
+      try {
+         xaAdapter.rollback(xid);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void testPrepareTxMarkedForRollback() {
+      localTx.markForRollback();
+      try {
+         xaAdapter.prepare(xid);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XA_RBROLLBACK;
+      }
+   }
+
+   public void testOnePhaseCommitConfigured() throws XAException {
+      configuration.setCacheMode(Configuration.CacheMode.INVALIDATION_ASYNC);//this would force 1pc
+      assert XAResource.XA_OK == xaAdapter.prepare(xid);
+   }
+
+   public void test1PcAndNonExistentXid() {
+      configuration.setCacheMode(Configuration.CacheMode.INVALIDATION_ASYNC);
+      try {
+         DummyXid doesNotExists = new DummyXid();
+         xaAdapter.commit(doesNotExists, false);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void test1PcAndNonExistentXid2() {
+      configuration.setCacheMode(Configuration.CacheMode.DIST_SYNC);
+      try {
+         DummyXid doesNotExists = new DummyXid();
+         xaAdapter.commit(doesNotExists, true);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+}",2010-12-09T08:05:14Z,94
"@@ -43,14 +43,12 @@
 		<dependency>
 			<groupId>net.dataforte.cassandra</groupId>
 			<artifactId>cassandra-connection-pool</artifactId>
-			<version>${version.cassandra.connection.pool}</version>
+			<version>${version.cassandra.pool}</version>
 		</dependency>
-
 		<dependency>
 			<groupId>org.apache.cassandra</groupId>
-			<artifactId>apache-cassandra</artifactId>
+			<artifactId>cassandra-all</artifactId>
 			<version>${version.cassandra}</version>
-			<scope>test</scope>
 		</dependency>
 		<dependency>
 			<groupId>org.slf4j</groupId>
@@ -74,7 +72,7 @@
 				<artifactId>maven-surefire-plugin</artifactId>
 				<version>2.4.3</version>
 				<configuration>
-					<forkMode>once</forkMode>
+					<forkMode>pertest</forkMode>
 					<parallel>false</parallel>
 				</configuration>
 			</plugin>
@@ -91,14 +89,4 @@
 			</plugin>
 		</plugins>
 	</build>
-
-	<repositories>
-		<repository>
-			<id>dataforte</id>
-			<url>http://www.dataforte.net/listing/maven/releases</url>
-			<snapshots>
-				<enabled>false</enabled>
-			</snapshots>
-		</repository>
-	</repositories>
 </project>",2011-04-28T09:57:29Z,146
"@@ -25,8 +25,10 @@
 import java.io.IOException;
 import java.io.ObjectInput;
 import java.io.ObjectOutput;
+import java.nio.ByteBuffer;
+import java.nio.charset.Charset;
 import java.util.ArrayList;
-import java.util.Arrays;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
@@ -35,9 +37,9 @@
 import java.util.Set;
 
 import net.dataforte.cassandra.pool.DataSource;
+import net.dataforte.cassandra.thrift.CassandraThriftDataSource;
 
 import org.apache.cassandra.thrift.Cassandra;
-import org.apache.cassandra.thrift.CassandraThriftDataSource;
 import org.apache.cassandra.thrift.Column;
 import org.apache.cassandra.thrift.ColumnOrSuperColumn;
 import org.apache.cassandra.thrift.ColumnParent;
@@ -51,6 +53,7 @@
 import org.apache.cassandra.thrift.SlicePredicate;
 import org.apache.cassandra.thrift.SliceRange;
 import org.apache.cassandra.thrift.SuperColumn;
+import org.apache.cassandra.utils.ByteBufferUtil;
 import org.infinispan.Cache;
 import org.infinispan.config.ConfigurationException;
 import org.infinispan.container.entries.InternalCacheEntry;
@@ -97,10 +100,10 @@ public class CassandraCacheStore extends AbstractCacheStore {
 	private ColumnParent entryColumnParent;
 	private ColumnParent expirationColumnParent;
 	private String entryKeyPrefix;
-	private String expirationKey;
+	private ByteBuffer expirationKey;
 	private TwoWayKey2StringMapper keyMapper;
-
-	static private byte emptyByteArray[] = {};
+	
+	static private Charset UTF8Charset = Charset.forName(""UTF-8"");
 
 	public Class<? extends CacheLoaderConfig> getConfigurationClass() {
 		return CassandraCacheStoreConfig.class;
@@ -120,11 +123,11 @@ public void start() throws CacheLoaderException {
 			dataSource = new DataSource(config.getPoolProperties());
 			readConsistencyLevel = ConsistencyLevel.valueOf(config.readConsistencyLevel);
 			writeConsistencyLevel = ConsistencyLevel.valueOf(config.writeConsistencyLevel);
-			entryColumnPath = new ColumnPath(config.entryColumnFamily).setColumn(ENTRY_COLUMN_NAME.getBytes(""UTF-8""));
+			entryColumnPath = new ColumnPath(config.entryColumnFamily).setColumn(ENTRY_COLUMN_NAME.getBytes(UTF8Charset));
 			entryColumnParent = new ColumnParent(config.entryColumnFamily);
 			entryKeyPrefix = ENTRY_KEY_PREFIX + (config.isSharedKeyspace() ? cacheName + ""_"" : """");
 			expirationColumnParent = new ColumnParent(config.expirationColumnFamily);
-			expirationKey = EXPIRATION_KEY + (config.isSharedKeyspace() ? ""_"" + cacheName : """");
+			expirationKey = ByteBufferUtil.bytes(EXPIRATION_KEY + (config.isSharedKeyspace() ? ""_"" + cacheName : """"));
 			keyMapper = (TwoWayKey2StringMapper) Util.getInstance(config.getKeyMapper());
 		} catch (Exception e) {
 			throw new ConfigurationException(e);
@@ -143,7 +146,7 @@ public InternalCacheEntry load(Object key) throws CacheLoaderException {
 		Cassandra.Client cassandraClient = null;
 		try {
 			cassandraClient = dataSource.getConnection();
-			ColumnOrSuperColumn column = cassandraClient.get(config.keySpace, hashKey, entryColumnPath, readConsistencyLevel);
+			ColumnOrSuperColumn column = cassandraClient.get(ByteBufferUtil.bytes(hashKey), entryColumnPath, readConsistencyLevel);
 			InternalCacheEntry ice = unmarshall(column.getColumn().getValue(), key);
 			if (ice != null && ice.isExpired()) {
 				remove(key);
@@ -171,8 +174,8 @@ public Set<InternalCacheEntry> load(int numEntries) throws CacheLoaderException
 		try {
 			cassandraClient = dataSource.getConnection();
 			Set<InternalCacheEntry> s = new HashSet<InternalCacheEntry>();
-			SlicePredicate slicePredicate = new SlicePredicate();
-			slicePredicate.setSlice_range(new SliceRange(entryColumnPath.getColumn(), emptyByteArray, false, 1));
+			SlicePredicate slicePredicate = new SlicePredicate();		
+			slicePredicate.setSlice_range(new SliceRange(ByteBuffer.wrap(entryColumnPath.getColumn()), ByteBufferUtil.EMPTY_BYTE_BUFFER, false, 1));
 			String startKey = """";
 
 			// Get the keys in SLICE_SIZE blocks
@@ -181,7 +184,7 @@ public Set<InternalCacheEntry> load(int numEntries) throws CacheLoaderException
 				KeyRange keyRange = new KeyRange(sliceSize);
 				keyRange.setStart_token(startKey);
 				keyRange.setEnd_token("""");
-				List<KeySlice> keySlices = cassandraClient.get_range_slices(config.keySpace, entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
+				List<KeySlice> keySlices = cassandraClient.get_range_slices(entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
 
 				// Cycle through all the keys
 				for (KeySlice keySlice : keySlices) {
@@ -213,7 +216,7 @@ public Set<InternalCacheEntry> load(int numEntries) throws CacheLoaderException
 					if (sliceSize == 0) {
 						complete = true;
 					} else {
-						startKey = keySlices.get(keySlices.size() - 1).getKey();
+						startKey = new String(keySlices.get(keySlices.size() - 1).getKey(), UTF8Charset);
 					}
 				}
 
@@ -233,19 +236,19 @@ public Set<Object> loadAllKeys(Set<Object> keysToExclude) throws CacheLoaderExce
 			cassandraClient = dataSource.getConnection();
 			Set<Object> s = new HashSet<Object>();
 			SlicePredicate slicePredicate = new SlicePredicate();
-			slicePredicate.setSlice_range(new SliceRange(entryColumnPath.getColumn(), emptyByteArray, false, 1));
+			slicePredicate.setSlice_range(new SliceRange(ByteBuffer.wrap(entryColumnPath.getColumn()), ByteBufferUtil.EMPTY_BYTE_BUFFER, false, 1));
 			String startKey = """";
 			boolean complete = false;
 			// Get the keys in SLICE_SIZE blocks
 			while (!complete) {
 				KeyRange keyRange = new KeyRange(SLICE_SIZE);
 				keyRange.setStart_token(startKey);
 				keyRange.setEnd_token("""");
-				List<KeySlice> keySlices = cassandraClient.get_range_slices(config.keySpace, entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
+				List<KeySlice> keySlices = cassandraClient.get_range_slices(entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
 				if (keySlices.size() < SLICE_SIZE) {
 					complete = true;
 				} else {
-					startKey = keySlices.get(keySlices.size() - 1).getKey();
+					startKey = new String(keySlices.get(keySlices.size() - 1).getKey(), UTF8Charset);
 				}
 
 				for (KeySlice keySlice : keySlices) {
@@ -279,27 +282,26 @@ public void clear() throws CacheLoaderException {
 		try {
 			cassandraClient = dataSource.getConnection();
 			SlicePredicate slicePredicate = new SlicePredicate();
-			slicePredicate.setSlice_range(new SliceRange(entryColumnPath.getColumn(), emptyByteArray, false, 1));
+			slicePredicate.setSlice_range(new SliceRange(ByteBuffer.wrap(entryColumnPath.getColumn()), ByteBufferUtil.EMPTY_BYTE_BUFFER, false, 1));
 			String startKey = """";
 			boolean complete = false;
 			// Get the keys in SLICE_SIZE blocks
 			while (!complete) {
 				KeyRange keyRange = new KeyRange(SLICE_SIZE);
 				keyRange.setStart_token(startKey);
 				keyRange.setEnd_token("""");
-				List<KeySlice> keySlices = cassandraClient.get_range_slices(config.keySpace, entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
+				List<KeySlice> keySlices = cassandraClient.get_range_slices(entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
 				if (keySlices.size() < SLICE_SIZE) {
 					complete = true;
 				} else {
-					startKey = keySlices.get(keySlices.size() - 1).getKey();
+					startKey = new String(keySlices.get(keySlices.size() - 1).getKey(), UTF8Charset);
 				}
-				Map<String, Map<String, List<Mutation>>> mutationMap = new HashMap<String, Map<String, List<Mutation>>>();
+				Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap = new HashMap<ByteBuffer, Map<String, List<Mutation>>>();
 
 				for (KeySlice keySlice : keySlices) {
-					String cassandraKey = keySlice.getKey();
-					remove0(cassandraKey, mutationMap);
+					remove0(ByteBuffer.wrap(keySlice.getKey()), mutationMap);
 				}
-				cassandraClient.batch_mutate(config.keySpace, mutationMap, ConsistencyLevel.ALL);
+				cassandraClient.batch_mutate(mutationMap, ConsistencyLevel.ALL);
 			}
 		} catch (Exception e) {
 			throw new CacheLoaderException(e);
@@ -316,9 +318,9 @@ public boolean remove(Object key) throws CacheLoaderException {
 		Cassandra.Client cassandraClient = null;
 		try {
 			cassandraClient = dataSource.getConnection();
-			Map<String, Map<String, List<Mutation>>> mutationMap = new HashMap<String, Map<String, List<Mutation>>>();
-			remove0(hashKey(key), mutationMap);
-			cassandraClient.batch_mutate(config.keySpace, mutationMap, writeConsistencyLevel);
+			Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap = new HashMap<ByteBuffer, Map<String, List<Mutation>>>();
+			remove0(ByteBufferUtil.bytes(hashKey(key)), mutationMap);
+			cassandraClient.batch_mutate(mutationMap, writeConsistencyLevel);
 			return true;
 		} catch (Exception e) {
 			log.errorRemovingKey(key, e);
@@ -328,7 +330,7 @@ public boolean remove(Object key) throws CacheLoaderException {
 		}
 	}
 
-	private void remove0(String key, Map<String, Map<String, List<Mutation>>> mutationMap) {
+	private void remove0(ByteBuffer key, Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap) {
 		addMutation(mutationMap, key, config.entryColumnFamily, null, null);
 	}
 
@@ -349,24 +351,24 @@ public void store(InternalCacheEntry entry) throws CacheLoaderException {
 
 		try {
 			cassandraClient = dataSource.getConnection();
-			Map<String, Map<String, List<Mutation>>> mutationMap = new HashMap<String, Map<String, List<Mutation>>>(2);
+			Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap = new HashMap<ByteBuffer, Map<String, List<Mutation>>>(2);
 			store0(entry, mutationMap);
 
-			cassandraClient.batch_mutate(config.keySpace, mutationMap, writeConsistencyLevel);
+			cassandraClient.batch_mutate(mutationMap, writeConsistencyLevel);
 		} catch (Exception e) {
 			throw new CacheLoaderException(e);
 		} finally {
 			dataSource.releaseConnection(cassandraClient);
 		}
 	}
 
-	private void store0(InternalCacheEntry entry, Map<String, Map<String, List<Mutation>>> mutationMap) throws IOException, UnsupportedKeyTypeException {
+	private void store0(InternalCacheEntry entry, Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap) throws IOException, UnsupportedKeyTypeException {
 		Object key = entry.getKey();
 		if (trace)
 			log.tracef(""store(\""%s\"") "", key);
 		String cassandraKey = hashKey(key);
 		try {
-			addMutation(mutationMap, cassandraKey, config.entryColumnFamily, entryColumnPath.getColumn(), marshall(entry));
+			addMutation(mutationMap, ByteBufferUtil.bytes(cassandraKey), config.entryColumnFamily, ByteBuffer.wrap(entryColumnPath.getColumn()), ByteBuffer.wrap(marshall(entry)));
 			if (entry.canExpire()) {
 				addExpiryEntry(cassandraKey, entry.getExpiryTime(), mutationMap);
 			}
@@ -377,9 +379,9 @@ private void store0(InternalCacheEntry entry, Map<String, Map<String, List<Mutat
 		}
 	}
 
-	private void addExpiryEntry(String cassandraKey, long expiryTime, Map<String, Map<String, List<Mutation>>> mutationMap) {
+	private void addExpiryEntry(String cassandraKey, long expiryTime, Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap) {
 		try {
-			addMutation(mutationMap, expirationKey, config.expirationColumnFamily, longToBytes(expiryTime), cassandraKey.getBytes(""UTF-8""), emptyByteArray);
+			addMutation(mutationMap, expirationKey, config.expirationColumnFamily, ByteBufferUtil.bytes(expiryTime), ByteBufferUtil.bytes(cassandraKey), ByteBufferUtil.EMPTY_BYTE_BUFFER);
 		} catch (Exception e) {
 			// Should not happen
 		}
@@ -444,25 +446,25 @@ protected void purgeInternal() throws CacheLoaderException {
 			// We need to get all supercolumns from the beginning of time until
 			// now, in SLICE_SIZE chunks
 			SlicePredicate predicate = new SlicePredicate();
-			predicate.setSlice_range(new SliceRange(emptyByteArray, longToBytes(System.currentTimeMillis()), false, SLICE_SIZE));
-			Map<String, Map<String, List<Mutation>>> mutationMap = new HashMap<String, Map<String, List<Mutation>>>();
+			predicate.setSlice_range(new SliceRange(ByteBufferUtil.EMPTY_BYTE_BUFFER, ByteBufferUtil.bytes(System.currentTimeMillis()), false, SLICE_SIZE));
+			Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap = new HashMap<ByteBuffer, Map<String, List<Mutation>>>();
 			for (boolean complete = false; !complete;) {
 				// Get all columns
-				List<ColumnOrSuperColumn> slice = cassandraClient.get_slice(config.keySpace, expirationKey, expirationColumnParent, predicate, readConsistencyLevel);
+				List<ColumnOrSuperColumn> slice = cassandraClient.get_slice(expirationKey, expirationColumnParent, predicate, readConsistencyLevel);
 				complete = slice.size() < SLICE_SIZE;
 				// Delete all keys returned by the slice
 				for (ColumnOrSuperColumn crumb : slice) {
 					SuperColumn scol = crumb.getSuper_column();
 					for (Iterator<Column> i = scol.getColumnsIterator(); i.hasNext();) {
 						Column col = i.next();
 						// Remove the entry row
-						remove0(new String(col.getName(), ""UTF-8""), mutationMap);
+						remove0(ByteBuffer.wrap(col.getName()), mutationMap);
 					}
 					// Remove the expiration supercolumn
-					addMutation(mutationMap, expirationKey, config.expirationColumnFamily, scol.getName(), null, null);
+					addMutation(mutationMap, expirationKey, config.expirationColumnFamily, ByteBuffer.wrap(scol.getName()), null, null);
 				}
 			}
-			cassandraClient.batch_mutate(config.keySpace, mutationMap, writeConsistencyLevel);
+			cassandraClient.batch_mutate(mutationMap, writeConsistencyLevel);
 		} catch (Exception e) {
 			throw new CacheLoaderException(e);
 		} finally {
@@ -477,7 +479,7 @@ protected void applyModifications(List<? extends Modification> mods) throws Cach
 
 		try {
 			cassandraClient = dataSource.getConnection();
-			Map<String, Map<String, List<Mutation>>> mutationMap = new HashMap<String, Map<String, List<Mutation>>>();
+			Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap = new HashMap<ByteBuffer, Map<String, List<Mutation>>>();
 
 			for (Modification m : mods) {
 				switch (m.getType()) {
@@ -488,14 +490,15 @@ protected void applyModifications(List<? extends Modification> mods) throws Cach
 					clear();
 					break;
 				case REMOVE:
-					remove0(hashKey(((Remove) m).getKey()), mutationMap);
+					remove0(ByteBufferUtil.bytes(hashKey(((Remove) m).getKey())), mutationMap);
 					break;
 				default:
 					throw new AssertionError();
 				}
 			}
-
-			cassandraClient.batch_mutate(config.keySpace, mutationMap, writeConsistencyLevel);
+			
+			cassandraClient.batch_mutate(mutationMap, writeConsistencyLevel);
+			
 		} catch (Exception e) {
 			throw new CacheLoaderException(e);
 		} finally {
@@ -517,18 +520,20 @@ private String hashKey(Object key) throws UnsupportedKeyTypeException {
 		return entryKeyPrefix + keyMapper.getStringMapping(key);
 	}
 
-	private Object unhashKey(String key) {
-		if (key.startsWith(entryKeyPrefix))
-			return keyMapper.getKeyMapping(key.substring(entryKeyPrefix.length()));
+	private Object unhashKey(byte[] key) {
+		String skey = new String(key, UTF8Charset);
+		
+		if (skey.startsWith(entryKeyPrefix))
+			return keyMapper.getKeyMapping(skey.substring(entryKeyPrefix.length()));
 		else
 			return null;
 	}
 
-	private static void addMutation(Map<String, Map<String, List<Mutation>>> mutationMap, String key, String columnFamily, byte[] column, byte[] value) {
+	private static void addMutation(Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap, ByteBuffer key, String columnFamily, ByteBuffer column, ByteBuffer value) {
 		addMutation(mutationMap, key, columnFamily, null, column, value);
 	}
 
-	private static void addMutation(Map<String, Map<String, List<Mutation>>> mutationMap, String key, String columnFamily, byte[] superColumn, byte[] column, byte[] value) {
+	private static void addMutation(Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap, ByteBuffer key, String columnFamily, ByteBuffer superColumn, ByteBuffer column, ByteBuffer value) {
 		Map<String, List<Mutation>> keyMutations = mutationMap.get(key);
 		// If the key doesn't exist yet, create the mutation holder
 		if (keyMutations == null) {
@@ -543,37 +548,28 @@ private static void addMutation(Map<String, Map<String, List<Mutation>>> mutatio
 		}
 
 		if (value == null) { // Delete
-			Deletion deletion = new Deletion(System.currentTimeMillis());
+			Deletion deletion = new Deletion(microTimestamp());
 			if (superColumn != null) {
 				deletion.setSuper_column(superColumn);
 			}
-			if (column != null) { // Single column delete
-				deletion.setPredicate(new SlicePredicate().setColumn_names(Arrays.asList(new byte[][] { column })));
+			if (column != null) { // Single column delete				
+				deletion.setPredicate(new SlicePredicate().setColumn_names(Collections.singletonList(column)));
 			} // else Delete entire column family or supercolumn
 			columnFamilyMutations.add(new Mutation().setDeletion(deletion));
 		} else { // Insert/update
 			ColumnOrSuperColumn cosc = new ColumnOrSuperColumn();
 			if (superColumn != null) {
 				List<Column> columns = new ArrayList<Column>();
-				columns.add(new Column(column, value, System.currentTimeMillis()));
+				columns.add(new Column(column, value, microTimestamp()));
 				cosc.setSuper_column(new SuperColumn(superColumn, columns));
 			} else {
-				cosc.setColumn(new Column(column, value, System.currentTimeMillis()));
+				cosc.setColumn(new Column(column, value, microTimestamp()));
 			}
 			columnFamilyMutations.add(new Mutation().setColumn_or_supercolumn(cosc));
 		}
 	}
-
-	private static final byte[] longToBytes(long v) {
-		byte b[] = new byte[8];
-		b[0] = (byte) (v >>> 56);
-		b[1] = (byte) (v >>> 48);
-		b[2] = (byte) (v >>> 40);
-		b[3] = (byte) (v >>> 32);
-		b[4] = (byte) (v >>> 24);
-		b[5] = (byte) (v >>> 16);
-		b[6] = (byte) (v >>> 8);
-		b[7] = (byte) (v >>> 0);
-		return b;
+	
+	private static long microTimestamp() {
+		return System.currentTimeMillis()*1000l;
 	}
 }",2011-04-28T09:57:29Z,144
"@@ -93,6 +93,7 @@ public String getKeySpace() {
 
 	public void setKeySpace(String keySpace) {
 		this.keySpace = keySpace;
+		poolProperties.setKeySpace(keySpace);
 	}
 
 	public String getEntryColumnFamily() {",2011-04-28T09:57:29Z,147
"@@ -22,11 +22,9 @@
  */
 package org.infinispan.loaders.cassandra;
 
-import java.io.File;
 import java.io.IOException;
-import java.net.URL;
 
-import org.apache.cassandra.service.EmbeddedCassandraService;
+import org.apache.cassandra.config.ConfigurationException;
 import org.apache.thrift.transport.TTransportException;
 import org.infinispan.loaders.BaseCacheStoreTest;
 import org.infinispan.loaders.CacheStore;
@@ -36,43 +34,34 @@
 
 @Test(groups = ""unit"", testName = ""loaders.cassandra.CassandraCacheStoreTest"")
 public class CassandraCacheStoreTest extends BaseCacheStoreTest {
-	private static EmbeddedCassandraService cassandra;
+	private static EmbeddedServerHelper embedded;
 
 	/**
 	 * Set embedded cassandra up and spawn it in a new thread.
 	 * 
 	 * @throws TTransportException
 	 * @throws IOException
 	 * @throws InterruptedException
+	 * @throws ConfigurationException
 	 */
 	@BeforeClass
-	public static void setup() throws TTransportException, IOException, InterruptedException {
-		// Tell cassandra where the configuration files are.
-		// Use the test configuration file.
-		URL resource = Thread.currentThread().getContextClassLoader().getResource(""storage-conf.xml"");
-		String configPath = resource.getPath().substring(0, resource.getPath().lastIndexOf(File.separatorChar));
-		
-		System.setProperty(""storage-config"", configPath);
-
-		CassandraServiceDataCleaner cleaner = new CassandraServiceDataCleaner();
-		cleaner.prepare();
-		cassandra = new EmbeddedCassandraService();
-		cassandra.init();
-		Thread t = new Thread(cassandra);
-		t.setDaemon(true);
-		t.start();
+	public static void setup() throws TTransportException, IOException, InterruptedException, ConfigurationException {
+		embedded = new EmbeddedServerHelper();
+		embedded.setup();
 	}
 	
 	@AfterClass
 	public static void cleanup() {
-		System.exit(0);
+		EmbeddedServerHelper.teardown();
+		embedded = null;
 	}
 
 	@Override
 	protected CacheStore createCacheStore() throws Exception {
 		CassandraCacheStore cs = new CassandraCacheStore();
 		CassandraCacheStoreConfig clc = new CassandraCacheStoreConfig();
 		clc.setHost(""localhost"");
+		clc.setKeySpace(""Infinispan"");
 		cs.init(clc, getCache(), getMarshaller());
 		cs.start();
 		return cs;",2011-04-28T09:57:29Z,81
"@@ -1,94 +0,0 @@
-/*
- * JBoss, Home of Professional Open Source
- * Copyright 2010 Red Hat Inc. and/or its affiliates and other
- * contributors as indicated by the @author tags. All rights reserved.
- * See the copyright.txt in the distribution for a full listing of
- * individual contributors.
- *
- * This is free software; you can redistribute it and/or modify it
- * under the terms of the GNU Lesser General Public License as
- * published by the Free Software Foundation; either version 2.1 of
- * the License, or (at your option) any later version.
- *
- * This software is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this software; if not, write to the Free
- * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
- * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
- */
-package org.infinispan.loaders.cassandra;
-
-import java.io.IOException;
-import java.util.HashSet;
-import java.util.Set;
-
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.io.util.FileUtils;
-import org.infinispan.test.TestingUtil;
-
-public class CassandraServiceDataCleaner {
-	/**
-	 * Creates all data dir if they don't exist and cleans them
-	 * 
-	 * @throws IOException
-	 */
-	public void prepare() throws IOException {
-		makeDirsIfNotExist();
-		cleanupDataDirectories();
-	}
-
-	/**
-	 * Deletes all data from cassandra data directories, including the commit
-	 * log.
-	 * 
-	 * @throws IOException
-	 *             in case of permissions error etc.
-	 */
-	public void cleanupDataDirectories() throws IOException {
-		for (String s : getDataDirs()) {
-			TestingUtil.recursiveFileRemove(s);
-		}
-	}
-
-	/**
-	 * Creates the data diurectories, if they didn't exist.
-	 * 
-	 * @throws IOException
-	 *             if directories cannot be created (permissions etc).
-	 */
-	public void makeDirsIfNotExist() throws IOException {
-		for (String s : getDataDirs()) {
-			mkdir(s);
-		}
-	}
-
-	/**
-	 * Collects all data dirs and returns a set of String paths on the file
-	 * system.
-	 * 
-	 * @return
-	 */
-	private Set<String> getDataDirs() {
-		Set<String> dirs = new HashSet<String>();
-		for (String s : DatabaseDescriptor.getAllDataFileLocations()) {
-			dirs.add(s);
-		}
-		dirs.add(DatabaseDescriptor.getLogFileLocation());
-		return dirs;
-	}
-
-	/**
-	 * Creates a directory
-	 * 
-	 * @param dir
-	 * @throws IOException
-	 */
-	private void mkdir(String dir) throws IOException {
-		FileUtils.createDirectory(dir);
-	}
-
-}",2011-04-28T09:57:29Z,148
"@@ -0,0 +1,179 @@
+package org.infinispan.loaders.cassandra;
+
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.cassandra.config.CFMetaData;
+import org.apache.cassandra.config.ConfigurationException;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.config.KSMetaData;
+import org.apache.cassandra.db.commitlog.CommitLog;
+import org.apache.cassandra.io.util.FileUtils;
+import org.apache.cassandra.thrift.CassandraDaemon;
+import org.apache.thrift.transport.TTransportException;
+
+/**
+ * Taken from Hector (MIT license).
+ * 
+ * Copyright (c) 2010 Ran Tavory
+ * 
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ * 
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ */
+public class EmbeddedServerHelper {	
+	private static final String TMP = ""tmp"";
+
+	private final String yamlFile;
+	static CassandraDaemon cassandraDaemon;
+
+	public EmbeddedServerHelper() {
+		this(""/cassandra.yaml"");
+	}
+
+	public EmbeddedServerHelper(String yamlFile) {
+		this.yamlFile = yamlFile;
+	}
+
+	static ExecutorService executor = Executors.newSingleThreadExecutor();
+
+	/**
+	 * Set embedded cassandra up and spawn it in a new thread.
+	 * 
+	 * @throws TTransportException
+	 * @throws IOException
+	 * @throws InterruptedException
+	 */
+	public void setup() throws TTransportException, IOException, InterruptedException, ConfigurationException {
+		// delete tmp dir first
+		rmdir(TMP);
+		// make a tmp dir and copy cassandra.yaml and log4j.properties to it
+		copy(""/log4j.properties"", TMP);
+		copy(yamlFile, TMP);
+		System.setProperty(""cassandra.config"", ""file:"" + TMP + yamlFile);
+		System.setProperty(""log4j.configuration"", ""file:"" + TMP + ""/log4j.properties"");
+		System.setProperty(""cassandra-foreground"", ""true"");
+
+		cleanupAndLeaveDirs();
+		loadSchemaFromYaml();
+
+		executor.execute(new CassandraRunner());
+		try {
+			TimeUnit.SECONDS.sleep(3);
+		} catch (InterruptedException e) {
+			throw new AssertionError(e);
+		}
+	}
+
+	public static void teardown() {
+		executor.shutdown();
+		executor.shutdownNow();
+	}
+
+	private static void rmdir(String dir) throws IOException {
+		File dirFile = new File(dir);
+		if (dirFile.exists()) {
+			FileUtils.deleteRecursive(new File(dir));
+		}
+	}
+
+	/**
+	 * Copies a resource from within the jar to a directory.
+	 * 
+	 * @param resource
+	 * @param directory
+	 * @throws IOException
+	 */
+	private static void copy(String resource, String directory) throws IOException {
+		mkdir(directory);
+		InputStream is = EmbeddedServerHelper.class.getResourceAsStream(resource);
+		String fileName = resource.substring(resource.lastIndexOf(""/"") + 1);
+		File file = new File(directory + System.getProperty(""file.separator"") + fileName);
+		OutputStream out = new FileOutputStream(file);
+		byte buf[] = new byte[1024];
+		int len;
+		while ((len = is.read(buf)) > 0) {
+			out.write(buf, 0, len);
+		}
+		out.close();
+		is.close();
+	}
+
+	/**
+	 * Creates a directory
+	 * 
+	 * @param dir
+	 * @throws IOException
+	 */
+	private static void mkdir(String dir) throws IOException {
+		FileUtils.createDirectory(dir);
+	}
+
+	public static void cleanupAndLeaveDirs() throws IOException {
+		mkdirs();
+		cleanup();
+		mkdirs();
+		CommitLog.instance.resetUnsafe(); // cleanup screws w/ CommitLog, this
+											// brings it back to safe state
+	}
+
+	public static void cleanup() throws IOException {
+		// clean up commitlog
+		String[] directoryNames = { DatabaseDescriptor.getCommitLogLocation(), };
+		for (String dirName : directoryNames) {
+			File dir = new File(dirName);
+			if (!dir.exists())
+				throw new RuntimeException(""No such directory: "" + dir.getAbsolutePath());
+			FileUtils.deleteRecursive(dir);
+		}
+
+		// clean up data directory which are stored as data directory/table/data
+		// files
+		for (String dirName : DatabaseDescriptor.getAllDataFileLocations()) {
+			File dir = new File(dirName);
+			if (!dir.exists())
+				throw new RuntimeException(""No such directory: "" + dir.getAbsolutePath());
+			FileUtils.deleteRecursive(dir);
+		}
+	}
+
+	public static void mkdirs() {
+		try {
+			DatabaseDescriptor.createAllDirectories();
+		} catch (IOException e) {
+			throw new RuntimeException(e);
+		}
+	}
+
+	public static void loadSchemaFromYaml() {
+		try {
+			for (KSMetaData ksm : DatabaseDescriptor.readTablesFromYaml()) {
+				for (CFMetaData cfm : ksm.cfMetaData().values())
+					CFMetaData.map(cfm);
+				DatabaseDescriptor.setTableDefinition(ksm, DatabaseDescriptor.getDefsVersion());
+			}
+		} catch (ConfigurationException e) {
+			throw new RuntimeException(e);
+		}
+	}
+
+	class CassandraRunner implements Runnable {
+		@Override
+		public void run() {
+			cassandraDaemon = new CassandraDaemon();
+			cassandraDaemon.activate();
+		}
+	}
+}",2011-04-28T09:57:29Z,149
"@@ -0,0 +1,81 @@
+authenticator: org.apache.cassandra.auth.AllowAllAuthenticator
+auto_bootstrap: false
+binary_memtable_throughput_in_mb: 256
+cluster_name: Infinispan
+column_index_size_in_kb: 64
+commitlog_directory: ${java.io.tmpdir}/infinispan-cassandra-cachestore/commitlog
+commitlog_rotation_threshold_in_mb: 128
+commitlog_sync: periodic
+commitlog_sync_period_in_ms: 10000
+compaction_preheat_key_cache: true
+compaction_thread_priority: 1
+concurrent_reads: 8
+concurrent_writes: 32
+data_file_directories:
+- ${java.io.tmpdir}/infinispan-cassandra-cachestore/data
+disk_access_mode: auto
+dynamic_snitch: false
+dynamic_snitch_badness_threshold: 0.0
+dynamic_snitch_reset_interval_in_ms: 600000
+dynamic_snitch_update_interval_in_ms: 100
+endpoint_snitch: org.apache.cassandra.locator.RackInferringSnitch
+flush_largest_memtables_at: 1.0
+hinted_handoff_enabled: true
+hinted_handoff_throttle_delay_in_ms: 0
+in_memory_compaction_limit_in_mb: 256
+incremental_backups: false
+index_interval: 128
+keyspaces:
+- column_families:
+  - column_metadata: []
+    column_type: Standard
+    compare_with: BytesType
+    gc_grace_seconds: 86400
+    key_cache_save_period_in_seconds: 14400
+    keys_cached: 0.1
+    max_compaction_threshold: 32
+    memtable_flush_after_mins: 60
+    memtable_operations_in_millions: 0.3
+    memtable_throughput_in_mb: 64
+    min_compaction_threshold: 4
+    name: InfinispanEntries
+    read_repair_chance: 1.0
+    row_cache_save_period_in_seconds: 0
+    rows_cached: 0.0
+  - column_metadata: []
+    column_type: Super
+    compare_subcolumns_with: BytesType
+    compare_with: LongType
+    gc_grace_seconds: 86400
+    key_cache_save_period_in_seconds: 14400
+    keys_cached: 0.1
+    max_compaction_threshold: 32
+    memtable_flush_after_mins: 60
+    memtable_operations_in_millions: 0.3
+    memtable_throughput_in_mb: 64
+    min_compaction_threshold: 4
+    name: InfinispanExpiration
+    read_repair_chance: 1.0
+    row_cache_save_period_in_seconds: 0
+    rows_cached: 0.0
+  name: Infinispan
+  replica_placement_strategy: org.apache.cassandra.locator.RackUnawareStrategy
+  replication_factor: 1
+max_hint_window_in_ms: 2147483647
+partitioner: org.apache.cassandra.dht.OrderPreservingPartitioner
+phi_convict_threshold: 8
+reduce_cache_capacity_to: 0.6
+reduce_cache_sizes_at: 1.0
+rpc_keepalive: true
+rpc_max_threads: 2147483647
+rpc_min_threads: 16
+rpc_port: 9160
+rpc_timeout_in_ms: 10000
+saved_caches_directory: ${java.io.tmpdir}/infinispan-cassandra-cachestore/savedcaches
+seeds:
+- 127.0.0.1
+sliced_buffer_size_in_kb: 64
+snapshot_before_compaction: false
+storage_port: 7000
+thrift_framed_transport_size_in_mb: 15
+thrift_max_message_length_in_mb: 16",2011-04-28T09:57:29Z,150
"@@ -1,370 +0,0 @@
-<!--
-  ~ JBoss, Home of Professional Open Source
-  ~ Copyright 2010 Red Hat Inc. and/or its affiliates and other
-  ~ contributors as indicated by the @author tags. All rights reserved.
-  ~ See the copyright.txt in the distribution for a full listing of
-  ~ individual contributors.
-  ~
-  ~ This is free software; you can redistribute it and/or modify it
-  ~ under the terms of the GNU Lesser General Public License as
-  ~ published by the Free Software Foundation; either version 2.1 of
-  ~ the License, or (at your option) any later version.
-  ~
-  ~ This software is distributed in the hope that it will be useful,
-  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
-  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
-  ~ Lesser General Public License for more details.
-  ~
-  ~ You should have received a copy of the GNU Lesser General Public
-  ~ License along with this software; if not, write to the Free
-  ~ Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
-  ~ 02110-1301 USA, or see the FSF site: http://www.fsf.org.
-  -->
-<Storage>
-  <!--======================================================================-->
-  <!-- Basic Configuration                                                  -->
-  <!--======================================================================-->
-
-  <!--
-   ~ The name of this cluster.  This is mainly used to prevent machines in
-   ~ one logical cluster from joining another.
-  -->
-  <ClusterName>Infinispan</ClusterName>
-
-  <!--
-   ~ Turn on to make new [non-seed] nodes automatically migrate the right data
-   ~ to themselves.  (If no InitialToken is specified, they will pick one
-   ~ such that they will get half the range of the most-loaded node.)
-   ~ If a node starts up without bootstrapping, it will mark itself bootstrapped
-   ~ so that you can't subsequently accidently bootstrap a node with
-   ~ data on it.  (You can reset this by wiping your data and commitlog
-   ~ directories.)
-   ~
-   ~ Off by default so that new clusters and upgraders from 0.4 don't
-   ~ bootstrap immediately.  You should turn this on when you start adding
-   ~ new nodes to a cluster that already has data on it.  (If you are upgrading
-   ~ from 0.4, start your cluster with it off once before changing it to true.
-   ~ Otherwise, no data will be lost but you will incur a lot of unnecessary
-   ~ I/O before your cluster starts up.)
-  -->
-  <AutoBootstrap>false</AutoBootstrap>
-
-  <!--
-   ~ Keyspaces and ColumnFamilies:
-   ~ A ColumnFamily is the Cassandra concept closest to a relational
-   ~ table.  Keyspaces are separate groups of ColumnFamilies.  Except in
-   ~ very unusual circumstances you will have one Keyspace per application.
-
-   ~ There is an implicit keyspace named 'system' for Cassandra internals.
-  -->
-  <Keyspaces>
-    <Keyspace Name=""Infinispan"">
-      <!--
-       ~ ColumnFamily definitions have one required attribute (Name)
-       ~ and several optional ones.
-       ~
-       ~ The CompareWith attribute tells Cassandra how to sort the columns
-       ~ for slicing operations.  The default is BytesType, which is a
-       ~ straightforward lexical comparison of the bytes in each column.
-       ~ Other options are AsciiType, UTF8Type, LexicalUUIDType, TimeUUIDType,
-       ~ and LongType.  You can also specify the fully-qualified class
-       ~ name to a class of your choice extending
-       ~ org.apache.cassandra.db.marshal.AbstractType.
-       ~
-       ~ SuperColumns have a similar CompareSubcolumnsWith attribute.
-       ~
-       ~ BytesType: Simple sort by byte value.  No validation is performed.
-       ~ AsciiType: Like BytesType, but validates that the input can be
-       ~            parsed as US-ASCII.
-       ~ UTF8Type: A string encoded as UTF8
-       ~ LongType: A 64bit long
-       ~ LexicalUUIDType: A 128bit UUID, compared lexically (by byte value)
-       ~ TimeUUIDType: a 128bit version 1 UUID, compared by timestamp
-       ~
-       ~ (To get the closest approximation to 0.3-style supercolumns, you
-       ~ would use CompareWith=UTF8Type CompareSubcolumnsWith=LongType.)
-       ~
-       ~ An optional `Comment` attribute may be used to attach additional
-       ~ human-readable information about the column family to its definition.
-       ~
-       ~ The optional KeysCached attribute specifies
-       ~ the number of keys per sstable whose locations we keep in
-       ~ memory in ""mostly LRU"" order.  (JUST the key locations, NOT any
-       ~ column values.) Specify a fraction (value less than 1), a percentage
-       ~ (ending in a % sign) or an absolute number of keys to cache.
-       ~
-       ~ The optional RowsCached attribute specifies the number of rows
-       ~ whose entire contents we cache in memory. Do not use this on
-       ~ ColumnFamilies with large rows, or ColumnFamilies with high write:read
-       ~ ratios. Specify a fraction (value less than 1), a percentage (ending in
-       ~ a % sign) or an absolute number of rows to cache.
-      -->
-
-      <ColumnFamily CompareWith=""BytesType"" Name=""InfinispanEntries"" KeysCached=""10%"" />
-      <ColumnFamily CompareWith=""LongType"" Name=""InfinispanExpiration"" KeysCached=""10%"" ColumnType=""Super"" CompareSubcolumnsWith=""BytesType""/>
-
-      <!--
-       ~ Strategy: Setting this to the class that implements
-       ~ IReplicaPlacementStrategy will change the way the node picker works.
-       ~ Out of the box, Cassandra provides
-       ~ org.apache.cassandra.locator.RackUnawareStrategy and
-       ~ org.apache.cassandra.locator.RackAwareStrategy (place one replica in
-       ~ a different datacenter, and the others on different racks in the same
-       ~ one.)
-      -->
-      <ReplicaPlacementStrategy>org.apache.cassandra.locator.RackUnawareStrategy</ReplicaPlacementStrategy>
-
-      <!-- Number of replicas of the data -->
-      <ReplicationFactor>1</ReplicationFactor>
-
-      <!--
-       ~ EndPointSnitch: Setting this to the class that implements
-       ~ AbstractEndpointSnitch, which lets Cassandra know enough
-       ~ about your network topology to route requests efficiently.
-       ~ Out of the box, Cassandra provides org.apache.cassandra.locator.EndPointSnitch,
-       ~ and PropertyFileEndPointSnitch is available in contrib/.
-      -->
-      <EndPointSnitch>org.apache.cassandra.locator.EndPointSnitch</EndPointSnitch>
-
-    </Keyspace>
-  </Keyspaces>
-
-  <!--
-   ~ Authenticator: any IAuthenticator may be used, including your own as long
-   ~ as it is on the classpath.  Out of the box, Cassandra provides
-   ~ org.apache.cassandra.auth.AllowAllAuthenticator and,
-   ~ org.apache.cassandra.auth.SimpleAuthenticator
-   ~ (SimpleAuthenticator uses access.properties and passwd.properties by
-   ~ default).
-   ~
-   ~ If you don't specify an authenticator, AllowAllAuthenticator is used.
-  -->
-  <Authenticator>org.apache.cassandra.auth.AllowAllAuthenticator</Authenticator>
-
-  <!--
-   ~ Partitioner: any IPartitioner may be used, including your own as long
-   ~ as it is on the classpath.  Out of the box, Cassandra provides
-   ~ org.apache.cassandra.dht.RandomPartitioner,
-   ~ org.apache.cassandra.dht.OrderPreservingPartitioner, and
-   ~ org.apache.cassandra.dht.CollatingOrderPreservingPartitioner.
-   ~ (CollatingOPP colates according to EN,US rules, not naive byte
-   ~ ordering.  Use this as an example if you need locale-aware collation.)
-   ~ Range queries require using an order-preserving partitioner.
-   ~
-   ~ Achtung!  Changing this parameter requires wiping your data
-   ~ directories, since the partitioner can modify the sstable on-disk
-   ~ format.
-  -->
-  <Partitioner>org.apache.cassandra.dht.OrderPreservingPartitioner</Partitioner>
-
-  <!--
-   ~ If you are using an order-preserving partitioner and you know your key
-   ~ distribution, you can specify the token for this node to use. (Keys
-   ~ are sent to the node with the ""closest"" token, so distributing your
-   ~ tokens equally along the key distribution space will spread keys
-   ~ evenly across your cluster.)  This setting is only checked the first
-   ~ time a node is started.
-
-   ~ This can also be useful with RandomPartitioner to force equal spacing
-   ~ of tokens around the hash space, especially for clusters with a small
-   ~ number of nodes.
-  -->
-  <InitialToken></InitialToken>
-
-  <!--
-   ~ Directories: Specify where Cassandra should store different data on
-   ~ disk.  Keep the data disks and the CommitLog disks separate for best
-   ~ performance
-  -->
-  <SavedCachesDirectory>${java.io.tmpdir}/infinispan-cassandra-cachestore/savedcaches</SavedCachesDirectory>
-  <CommitLogDirectory>${java.io.tmpdir}/infinispan-cassandra-cachestore/commitlog</CommitLogDirectory>
-  <DataFileDirectories>
-      <DataFileDirectory>${java.io.tmpdir}/infinispan-cassandra-cachestore/data</DataFileDirectory>
-  </DataFileDirectories>
-  <CalloutLocation>${java.io.tmpdir}/infinispan-cassandra-cachestore/callouts</CalloutLocation>
-  <StagingFileDirectory>${java.io.tmpdir}/infinispan-cassandra-cachestore/staging</StagingFileDirectory>
-
-
-  <!--
-   ~ Addresses of hosts that are deemed contact points. Cassandra nodes
-   ~ use this list of hosts to find each other and learn the topology of
-   ~ the ring. You must change this if you are running multiple nodes!
-  -->
-  <Seeds>
-      <Seed>127.0.0.1</Seed>
-  </Seeds>
-
-
-  <!-- Miscellaneous -->
-
-  <!-- Time to wait for a reply from other nodes before failing the command -->
-  <RpcTimeoutInMillis>10000</RpcTimeoutInMillis>
-  <!-- Size to allow commitlog to grow to before creating a new segment -->
-  <CommitLogRotationThresholdInMB>128</CommitLogRotationThresholdInMB>
-
-
-  <!-- Local hosts and ports -->
-
-  <!--
-   ~ Address to bind to and tell other nodes to connect to.  You _must_
-   ~ change this if you want multiple nodes to be able to communicate!
-   ~
-   ~ Leaving it blank leaves it up to InetAddress.getLocalHost(). This
-   ~ will always do the Right Thing *if* the node is properly configured
-   ~ (hostname, name resolution, etc), and the Right Thing is to use the
-   ~ address associated with the hostname (it might not be).
-  -->
-  <ListenAddress></ListenAddress>
-  <!-- internal communications port -->
-  <StoragePort>7000</StoragePort>
-
-  <!--
-   ~ The address to bind the Thrift RPC service to. Unlike ListenAddress
-   ~ above, you *can* specify 0.0.0.0 here if you want Thrift to listen on
-   ~ all interfaces.
-   ~
-   ~ Leaving this blank has the same effect it does for ListenAddress,
-   ~ (i.e. it will be based on the configured hostname of the node).
-  -->
-  <ThriftAddress>localhost</ThriftAddress>
-  <!-- Thrift RPC port (the port clients connect to). -->
-  <ThriftPort>9160</ThriftPort>
-  <!--
-   ~ Whether or not to use a framed transport for Thrift. If this option
-   ~ is set to true then you must also use a framed transport on the
-   ~ client-side, (framed and non-framed transports are not compatible).
-  -->
-  <ThriftFramedTransport>false</ThriftFramedTransport>
-
-
-  <!--======================================================================-->
-  <!-- Memory, Disk, and Performance                                        -->
-  <!--======================================================================-->
-
-  <!--
-   ~ Access mode.  mmapped i/o is substantially faster, but only practical on
-   ~ a 64bit machine (which notably does not include EC2 ""small"" instances)
-   ~ or relatively small datasets.  ""auto"", the safe choice, will enable
-   ~ mmapping on a 64bit JVM.  Other values are ""mmap"", ""mmap_index_only""
-   ~ (which may allow you to get part of the benefits of mmap on a 32bit
-   ~ machine by mmapping only index files) and ""standard"".
-   ~ (The buffer size settings that follow only apply to standard,
-   ~ non-mmapped i/o.)
-   -->
-  <DiskAccessMode>auto</DiskAccessMode>
-
-  <!--
-   ~ Size of compacted row above which to log a warning.  (If compacted
-   ~ rows do not fit in memory, Cassandra will crash.  This is explained
-   ~ in http://wiki.apache.org/cassandra/CassandraLimitations and is
-   ~ scheduled to be fixed in 0.7.)
-  -->
-  <RowWarningThresholdInMB>512</RowWarningThresholdInMB>
-
-  <!--
-   ~ Buffer size to use when performing contiguous column slices. Increase
-   ~ this to the size of the column slices you typically perform.
-   ~ (Name-based queries are performed with a buffer size of
-   ~ ColumnIndexSizeInKB.)
-  -->
-  <SlicedBufferSizeInKB>64</SlicedBufferSizeInKB>
-
-  <!--
-   ~ Buffer size to use when flushing memtables to disk. (Only one
-   ~ memtable is ever flushed at a time.) Increase (decrease) the index
-   ~ buffer size relative to the data buffer if you have few (many)
-   ~ columns per key.  Bigger is only better _if_ your memtables get large
-   ~ enough to use the space. (Check in your data directory after your
-   ~ app has been running long enough.) -->
-  <FlushDataBufferSizeInMB>32</FlushDataBufferSizeInMB>
-  <FlushIndexBufferSizeInMB>8</FlushIndexBufferSizeInMB>
-
-  <!--
-   ~ Add column indexes to a row after its contents reach this size.
-   ~ Increase if your column values are large, or if you have a very large
-   ~ number of columns.  The competing causes are, Cassandra has to
-   ~ deserialize this much of the row to read a single column, so you want
-   ~ it to be small - at least if you do many partial-row reads - but all
-   ~ the index data is read for each access, so you don't want to generate
-   ~ that wastefully either.
-  -->
-  <ColumnIndexSizeInKB>64</ColumnIndexSizeInKB>
-
-  <!--
-   ~ Flush memtable after this much data has been inserted, including
-   ~ overwritten data.  There is one memtable per column family, and
-   ~ this threshold is based solely on the amount of data stored, not
-   ~ actual heap memory usage (there is some overhead in indexing the
-   ~ columns).
-  -->
-  <MemtableThroughputInMB>64</MemtableThroughputInMB>
-  <!--
-   ~ Throughput setting for Binary Memtables.  Typically these are
-   ~ used for bulk load so you want them to be larger.
-  -->
-  <BinaryMemtableThroughputInMB>256</BinaryMemtableThroughputInMB>
-  <!--
-   ~ The maximum number of columns in millions to store in memory per
-   ~ ColumnFamily before flushing to disk.  This is also a per-memtable
-   ~ setting.  Use with MemtableThroughputInMB to tune memory usage.
-  -->
-  <MemtableOperationsInMillions>0.3</MemtableOperationsInMillions>
-  <!--
-   ~ The maximum time to leave a dirty memtable unflushed.
-   ~ (While any affected columnfamilies have unflushed data from a
-   ~ commit log segment, that segment cannot be deleted.)
-   ~ This needs to be large enough that it won't cause a flush storm
-   ~ of all your memtables flushing at once because none has hit
-   ~ the size or count thresholds yet.  For production, a larger
-   ~ value such as 1440 is recommended.
-  -->
-  <MemtableFlushAfterMinutes>60</MemtableFlushAfterMinutes>
-
-  <!--
-   ~ Unlike most systems, in Cassandra writes are faster than reads, so
-   ~ you can afford more of those in parallel.  A good rule of thumb is 2
-   ~ concurrent reads per processor core.  Increase ConcurrentWrites to
-   ~ the number of clients writing at once if you enable CommitLogSync +
-   ~ CommitLogSyncDelay. -->
-  <ConcurrentReads>8</ConcurrentReads>
-  <ConcurrentWrites>32</ConcurrentWrites>
-
-  <!--
-   ~ CommitLogSync may be either ""periodic"" or ""batch.""  When in batch
-   ~ mode, Cassandra won't ack writes until the commit log has been
-   ~ fsynced to disk.  It will wait up to CommitLogSyncBatchWindowInMS
-   ~ milliseconds for other writes, before performing the sync.
-
-   ~ This is less necessary in Cassandra than in traditional databases
-   ~ since replication reduces the odds of losing data from a failure
-   ~ after writing the log entry but before it actually reaches the disk.
-   ~ So the other option is ""timed,"" where writes may be acked immediately
-   ~ and the CommitLog is simply synced every CommitLogSyncPeriodInMS
-   ~ milliseconds.
-  -->
-  <CommitLogSync>periodic</CommitLogSync>
-  <!--
-   ~ Interval at which to perform syncs of the CommitLog in periodic mode.
-   ~ Usually the default of 10000ms is fine; increase it if your i/o
-   ~ load is such that syncs are taking excessively long times.
-  -->
-  <CommitLogSyncPeriodInMS>10000</CommitLogSyncPeriodInMS>
-  <!--
-   ~ Delay (in milliseconds) during which additional commit log entries
-   ~ may be written before fsync in batch mode.  This will increase
-   ~ latency slightly, but can vastly improve throughput where there are
-   ~ many writers.  Set to zero to disable (each entry will be synced
-   ~ individually).  Reasonable values range from a minimal 0.1 to 10 or
-   ~ even more if throughput matters more than latency.
-  -->
-  <!-- <CommitLogSyncBatchWindowInMS>1</CommitLogSyncBatchWindowInMS> -->
-
-  <!--
-   ~ Time to wait before garbage-collection deletion markers.  Set this to
-   ~ a large enough value that you are confident that the deletion marker
-   ~ will be propagated to all replicas by the time this many seconds has
-   ~ elapsed, even in the face of hardware failures.  The default value is
-   ~ ten days.
-  -->
-  <GCGraceSeconds>86400</GCGraceSeconds>
-</Storage>",2011-04-28T09:57:29Z,151
"@@ -102,8 +102,8 @@
       <version.apacheds.jdbm>1.5.4</version.apacheds.jdbm>
       <version.bdbje>4.0.92</version.bdbje>
       <version.c3p0>0.9.1.2</version.c3p0>
-      <version.cassandra>0.6.6</version.cassandra>
-      <version.cassandra.connection.pool>0.3.2</version.cassandra.connection.pool>
+      <version.cassandra>0.7.4</version.cassandra>
+      <version.cassandra.pool>0.7.1</version.cassandra.pool>
       <version.com.intellij.forms_rt>6.0.5</version.com.intellij.forms_rt>
       <version.commons.compress>1.0</version.commons.compress>
       <version.commons.pool>1.5.4</version.commons.pool>",2011-04-28T09:57:29Z,152
"@@ -121,17 +121,20 @@ class Server(@Context request: Request, @HeaderParam(""performAsync"") useAsync: B
             Response.status(Status.CONFLICT).build()
          } else {
             ManagerInstance.getEntry(cacheName, key) match {
-               case b: MIMECacheEntry => {
+               case mime: MIMECacheEntry => {
                   // The item already exists in the cache, evaluate preconditions based on its attributes and the headers
-                  val lastMod = new Date(b.lastModified)
-                  request.evaluatePreconditions(lastMod, calcETAG(b)) match {
+                  val lastMod = new Date(mime.lastModified)
+                  request.evaluatePreconditions(lastMod, calcETAG(mime)) match {
                      // One of the preconditions failed, build a response
                      case bldr: ResponseBuilder => bldr.build
                      // Preconditions passed
                      case null => putInCache(cache, mediaType, key, data, ttl, idleTime)
                   }
                }
-               case null => putInCache(cache, mediaType, key, data, ttl, idleTime)
+               case binary: Array[Byte] =>
+                  putInCache(cache, mediaType, key, data, ttl, idleTime)
+               case null =>
+                  putInCache(cache, mediaType, key, data, ttl, idleTime)
             }
          }
       }",2011-12-01T11:04:52Z,153
"@@ -46,6 +46,7 @@ import org.testng.AssertJUnit._
  *
  * @author Michael Neale
  * @author Galder Zamarreño
+ * @author Michal Linhard
  * @since 4.0
  */
 @Test(groups = Array(""functional""), testName = ""rest.IntegrationTest"")
@@ -681,6 +682,25 @@ class IntegrationTest {
       assertEquals(HttpServletResponse.SC_NOT_FOUND, Client.call(new GetMethod(fullPathKey)).getStatusCode)
    }
 
+   def testPutByteArrayTwice(m: Method) {
+      val fullPathKey = fullPath + ""/"" + m.getName
+      val put = new PutMethod(fullPathKey)
+      val data = new Array[Byte](3);
+      data(0) = 42
+      data(1) = 42
+      data(2) = 42
+
+      put.setRequestEntity(new ByteArrayRequestEntity(data, ""application/x-java-serialized-object""))
+      assertEquals(HttpServletResponse.SC_OK, Client.call(put).getStatusCode)
+
+      val get = Client.call(new GetMethod(fullPathKey))
+      assertEquals(HttpServletResponse.SC_OK, get.getStatusCode)
+
+      val reput = new PutMethod(fullPathKey)
+      reput.setRequestEntity(new ByteArrayRequestEntity(data, ""application/x-java-serialized-object""))
+      assertEquals(HttpServletResponse.SC_OK, Client.call(reput).getStatusCode)
+   }
+
    private def waitNotFound(startTime: Long, lifespan: Int, fullPathKey: String) {
       if (System.currentTimeMillis < startTime + lifespan + 20000) {
          if (!SC_NOT_FOUND.equals(Client.call(new GetMethod(fullPathKey)).getStatusCode)) {",2011-12-01T11:04:52Z,154
"@@ -63,7 +63,7 @@ abstract class AbstractProtocolDecoder[K, V <: CacheValue](transport: NettyTrans
    override def decode(ctx: ChannelHandlerContext, ch: Channel, buffer: ChannelBuffer, state: DecoderState): AnyRef = {
       val ch = ctx.getChannel
       try {
-         if (isTraceEnabled) // To aid debugging
+         if (isTrace) // To aid debugging
             trace(""Decode using instance @%x"", System.identityHashCode(this))
          state match {
             case DECODE_HEADER => decodeHeader(ch, buffer, state)",2012-04-02T10:56:22Z,155
"@@ -63,6 +63,7 @@ class NettyTransport(server: ProtocolServer, encoder: ChannelDownstreamHandler,
 
    private val totalBytesWritten, totalBytesRead = new AtomicLong
    private val userBytesWritten, userBytesRead = new AtomicLong
+   private val isTrace = isTraceEnabled
 
    override def start {
       ThreadRenamingRunnable.setThreadNameDeterminer(new ThreadNameDeterminer {
@@ -75,7 +76,7 @@ class NettyTransport(server: ProtocolServer, encoder: ChannelDownstreamHandler,
                else ""ClientMaster-""
             // Set thread name to be: <prefix><ServerWorker-|ServerMaster-|ClientWorker-|ClientMaster-><number>
             val name = threadNamePrefix + typeInFix + proposedThreadName.substring(index + 1, proposedThreadName.length)
-            if (isTraceEnabled)
+            if (isTrace)
                trace(""Thread name will be %s, with current thread name being %s and proposed name being '%s'"",
                   name, currentThread, proposedThreadName)
             name",2012-04-02T10:56:22Z,156
"@@ -50,6 +50,7 @@ object Decoder10 extends AbstractVersionedDecoder with Log {
    import OperationResponse._
    import ProtocolFlag._
    type SuitableHeader = HotRodHeader
+   private val isTrace = isTraceEnabled
 
    override def readHeader(buffer: ChannelBuffer, version: Byte, messageId: Long): (HotRodHeader, Boolean) = {
       val streamOp = buffer.readUnsignedByte
@@ -70,7 +71,7 @@ object Decoder10 extends AbstractVersionedDecoder with Log {
          case _ => throw new HotRodUnknownOperationException(
                ""Unknown operation: "" + streamOp, version, messageId)
       }
-      if (isTraceEnabled) trace(""Operation code: %d has been matched to %s"", streamOp, op)
+      if (isTrace) trace(""Operation code: %d has been matched to %s"", streamOp, op)
       
       val cacheName = readString(buffer)
       val flag = readUnsignedInt(buffer) match {
@@ -203,7 +204,7 @@ object Decoder10 extends AbstractVersionedDecoder with Log {
          }
          case BulkGetRequest => {
             val count = readUnsignedInt(buffer)
-            if (isTraceEnabled) trace(""About to create bulk response, count = %d"", count)
+            if (isTrace) trace(""About to create bulk response, count = %d"", count)
             new BulkGetResponse(h.version, h.messageId, h.cacheName, h.clientIntel,
                                 BulkGetResponse, Success, h.topologyId, count)
          }",2012-04-02T10:56:22Z,157
"@@ -59,6 +59,7 @@ class HotRodServer extends AbstractProtocolServer(""HotRod"") with Log {
    private var addressCache: Cache[Address, ServerAddress] = _
    private var topologyUpdateTimeout: Long = _
    private var viewId: Int = _
+   private val isTrace = isTraceEnabled
 
    def getAddress: ServerAddress = address
 
@@ -184,7 +185,7 @@ class HotRodServer extends AbstractProtocolServer(""HotRod"") with Log {
          if (!event.isPre) {
             val localViewId = transport.getViewId
             setViewId(localViewId)
-            if (isTraceEnabled) {
+            if (isTrace) {
                log.tracef(""Address cache had %s for key %s. View id is now %d"",
                           event.getType, event.getKey, localViewId)
             }",2012-04-02T10:56:22Z,158
"@@ -66,6 +66,7 @@ class MemcachedDecoder(memcachedCache: Cache[String, MemcachedValue], scheduler:
    private final val replaceIfUnmodifiedMisses = new AtomicLong(0)
    private final val replaceIfUnmodifiedHits = new AtomicLong(0)
    private final val replaceIfUnmodifiedBadval = new AtomicLong(0)
+   private val isTrace = isTraceEnabled
 
    override def readHeader(buffer: ChannelBuffer): (Option[RequestHeader], Boolean) = {
       var (streamOp, endOfOp) = readElement(buffer)
@@ -122,7 +123,7 @@ class MemcachedDecoder(memcachedCache: Cache[String, MemcachedValue], scheduler:
       var endOfOp = false
       params =
          if (!line.isEmpty) {
-            if (isTraceEnabled) trace(""Operation parameters: %s"", line)
+            if (isTrace) trace(""Operation parameters: %s"", line)
             val args = line.trim.split("" +"")
             try {
                header.op match {
@@ -632,8 +633,9 @@ private class DelayedFlushAll(cache: Cache[String, MemcachedValue],
 }
 
 private object RequestResolver extends Log {
+   private val isTrace = isTraceEnabled
    def toRequest(commandName: String, endOfOp: Boolean, buffer: ChannelBuffer): Enumeration#Value = {
-      if (isTraceEnabled) trace(""Operation: %s"", commandName)
+      if (isTrace) trace(""Operation: %s"", commandName)
       val op = commandName match {
          case ""get"" => GetRequest
          case ""set"" => PutRequest",2012-04-02T10:56:22Z,159
"@@ -1732,6 +1732,14 @@ public boolean isHashActivated() {
       return clustering.hash.activated;
    }
 
+   public long getL1InvalidationCleanupTaskFrequency() {
+      return clustering.l1.getL1InvalidationCleanupTaskFrequency();
+   }
+
+   public void setL1InvalidationCleanupTaskFrequency(long frequencyMillis) {
+      clustering.l1.setL1InvalidationCleanupTaskFrequency(frequencyMillis);
+   }
+
    /**
     * Defines transactional (JTA) characteristics of the cache.
     *
@@ -3772,6 +3780,10 @@ public HashType clone() throws CloneNotSupportedException {
       
       @ConfigurationDocRef(bean = Configuration.class, targetElement = ""setL1InvalidationThreshold"")
       protected Integer invalidationThreshold = 0;
+
+      @ConfigurationDocRef(bean = Configuration.class, targetElement = ""setL1InvalidationReaperThreadFrequency"")
+      protected Long frequency = 600000L;
+
       @XmlTransient
       public boolean activated = false;
 
@@ -3816,6 +3828,25 @@ public L1Config setLifespan(Long lifespan) {
          return this;
       }
 
+      /**
+       * @deprecated The visibility of this will be reduced, use {@link #invalidationReaperThreadFrequency(Long)}
+       */
+      @Deprecated
+      public L1Config setL1InvalidationCleanupTaskFrequency(long frequencyMillis) {
+         testImmutability(""frequency"");
+         this.frequency = frequencyMillis;
+         return this;
+      }
+
+      public L1Config cleanupTaskFrequency(Long frequencyMillis) {
+         return setL1InvalidationCleanupTaskFrequency(frequencyMillis);
+      }
+
+      @XmlAttribute (name = ""cleanupTaskFrequency"")
+      public Long getL1InvalidationCleanupTaskFrequency() {
+         return frequency;
+      }
+
       @Override
       public L1Config lifespan(Long lifespan) {
          setLifespan(lifespan);",2012-03-22T09:39:02Z,160
"@@ -638,6 +638,12 @@ public FluentConfiguration(Configuration config) {
        * 
        */
       L1Config invalidationThreshold(Integer threshold);
+
+      /**
+       * Determines how often a cleanup thread runs to clean up an internal log of requestors for a specific key
+       * @param frequencyMillis frequency in milliseconds
+       */
+      L1Config cleanupTaskFrequency(Long frequencyMillis);
    }
 
    /**",2012-03-22T09:39:02Z,161
"@@ -29,14 +29,16 @@ public class L1Configuration {
    private final int invalidationThreshold;
    private final long lifespan;
    private final boolean onRehash;
+   private final long cleanupTaskFrequency;
    // For use by the LegacyConfigurationAdapter
    final boolean activated;
 
-   L1Configuration(boolean enabled, int invalidationThreshold, long lifespan, boolean onRehash, boolean activated) {
+   L1Configuration(boolean enabled, int invalidationThreshold, long lifespan, boolean onRehash, long cleanupTaskFrequency, boolean activated) {
       this.enabled = enabled;
       this.invalidationThreshold = invalidationThreshold;
       this.lifespan = lifespan;
       this.onRehash = onRehash;
+      this.cleanupTaskFrequency = cleanupTaskFrequency;
       this.activated = activated;
    }
 
@@ -62,6 +64,14 @@ public int invalidationThreshold() {
       return invalidationThreshold;
    }
 
+   /**
+    * Determines how often a cleanup thread runs to clean up an internal log of requestors for a specific key
+    */
+   public long cleanupTaskFrequency() {
+      return cleanupTaskFrequency;
+   }
+
+
    /**
     * Maximum lifespan of an entry placed in the L1 cache. Default 10 minutes.
     */
@@ -85,6 +95,7 @@ public String toString() {
             "", invalidationThreshold="" + invalidationThreshold +
             "", lifespan="" + lifespan +
             "", onRehash="" + onRehash +
+            "", cleanupTaskFrequency="" + cleanupTaskFrequency +
             '}';
    }
 
@@ -100,6 +111,7 @@ public boolean equals(Object o) {
       if (invalidationThreshold != that.invalidationThreshold) return false;
       if (lifespan != that.lifespan) return false;
       if (onRehash != that.onRehash) return false;
+      if (cleanupTaskFrequency != that.cleanupTaskFrequency) return false;
 
       return true;
    }
@@ -111,6 +123,7 @@ public int hashCode() {
       result = 31 * result + (int) (lifespan ^ (lifespan >>> 32));
       result = 31 * result + (onRehash ? 1 : 0);
       result = 31 * result + (activated ? 1 : 0);
+      result = 31 * result + (int) (cleanupTaskFrequency ^ (cleanupTaskFrequency >>> 32));
       return result;
    }
 ",2012-03-22T09:39:02Z,162
"@@ -37,6 +37,7 @@ public class L1ConfigurationBuilder extends AbstractClusteringConfigurationChild
    private int invalidationThreshold = 0;
    private long lifespan = TimeUnit.MINUTES.toMillis(10);
    private Boolean onRehash = null;
+   private long cleanupTaskFrequency = TimeUnit.MINUTES.toMillis(10);
    boolean activated = false;
 
    L1ConfigurationBuilder(ClusteringConfigurationBuilder builder) {
@@ -69,8 +70,17 @@ public L1ConfigurationBuilder invalidationThreshold(int invalidationThreshold) {
    /**
     * Maximum lifespan of an entry placed in the L1 cache.
     */
-   public L1ConfigurationBuilder lifespan(long livespan) {
-      this.lifespan = livespan;
+   public L1ConfigurationBuilder lifespan(long lifespan) {
+      this.lifespan = lifespan;
+      activated = true;
+      return this;
+   }
+
+   /**
+    * How often the L1 requestors map is cleaned up of stale items
+    */
+   public L1ConfigurationBuilder cleanupTaskFrequency(long frequencyMillis) {
+      this.cleanupTaskFrequency = frequencyMillis;
       activated = true;
       return this;
    }
@@ -130,6 +140,7 @@ void validate() {
 
          if (lifespan < 1)
             throw new ConfigurationException(""Using a L1 lifespan of 0 or a negative value is meaningless"");
+
       } else {
          // If L1 is disabled, L1ForRehash should also be disabled
          if (onRehash != null && onRehash)
@@ -148,7 +159,7 @@ L1Configuration create() {
          onRehash = false;
       }
 
-      return new L1Configuration(enabled, invalidationThreshold, lifespan, onRehash, activated);
+      return new L1Configuration(enabled, invalidationThreshold, lifespan, onRehash, cleanupTaskFrequency, activated);
    }
 
    @Override
@@ -157,6 +168,7 @@ public L1ConfigurationBuilder read(L1Configuration template) {
       invalidationThreshold = template.invalidationThreshold();
       lifespan = template.lifespan();
       onRehash = template.onRehash();
+      cleanupTaskFrequency = template.cleanupTaskFrequency();
       activated = template.activated;
       return this;
    }
@@ -168,8 +180,8 @@ public String toString() {
             "", enabled="" + enabled +
             "", invalidationThreshold="" + invalidationThreshold +
             "", lifespan="" + lifespan +
+            "", cleanupTaskFrequency="" + cleanupTaskFrequency +
             "", onRehash="" + onRehash +
             '}';
    }
-
 }",2012-03-22T09:39:02Z,163
"@@ -98,7 +98,8 @@ public static org.infinispan.config.Configuration adapt(org.infinispan.configura
             .l1()
                .invalidationThreshold(config.clustering().l1().invalidationThreshold())
                .lifespan(config.clustering().l1().lifespan())
-               .onRehash(config.clustering().l1().onRehash());
+               .onRehash(config.clustering().l1().onRehash())
+               .cleanupTaskFrequency(config.clustering().l1().cleanupTaskFrequency());
       } else {
          legacy.clustering()
             .l1()
@@ -333,7 +334,8 @@ public static org.infinispan.configuration.cache.Configuration adapt(org.infinis
             .l1().enable()
                .invalidationThreshold(legacy.getL1InvalidationThreshold())
                .lifespan(legacy.getL1Lifespan())
-               .onRehash(legacy.isL1OnRehash());
+               .onRehash(legacy.isL1OnRehash())
+               .cleanupTaskFrequency(legacy.getL1InvalidationCleanupTaskFrequency());
       } else {
          builder.clustering()
             .l1()",2012-03-22T09:39:02Z,164
"@@ -66,6 +66,7 @@ public enum Attribute {
     ISOLATION_LEVEL(""isolationLevel""),
     JMX_DOMAIN(""jmxDomain""),
     LIFESPAN(""lifespan""),
+    INVALIDATION_CLEANUP_TASK_FREQUENCY(""cleanupTaskFrequency""),
     LOCK_ACQUISITION_TIMEOUT(""lockAcquisitionTimeout""),
     LOCKING_MODE(""lockingMode""),
     LOG_FLUSH_TIMEOUT(""logFlushTimeout""),",2012-03-22T09:39:02Z,165
"@@ -1107,6 +1107,9 @@ private void parseL1reader(XMLStreamReader reader, ConfigurationBuilder builder)
             case LIFESPAN:
                builder.clustering().l1().lifespan(Long.parseLong(value));
                break;
+            case INVALIDATION_CLEANUP_TASK_FREQUENCY:
+               builder.clustering().l1().cleanupTaskFrequency(Long.parseLong(value));
+               break;
             case ON_REHASH:
                if (Boolean.parseBoolean(value))
                   builder.clustering().l1().enableOnRehash();",2012-03-22T09:39:02Z,166
"@@ -22,13 +22,14 @@
  */
 package org.infinispan.distribution;
 
-import java.util.Collection;
-
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 
+import java.util.Collection;
+import java.util.concurrent.Future;
+
 /**
  * Manages the L1 Cache, in particular recording anyone who is going to cache an
  * a command that a node responds to so that a unicast invalidation can be sent
@@ -43,12 +44,12 @@ public interface L1Manager {
 	/**
 	 * Records a request that will be cached in another nodes L1
 	 */
-	public void addRequestor(Object key, Address requestor);
+	void addRequestor(Object key, Address requestor);
 
 	/**
 	 * Flushes a cache (using unicast or multicast) for a set of keys
 	 */
-	public NotifyingNotifiableFuture<Object> flushCache(Collection<Object> keys,
-	      Object retval, Address origin);
+	NotifyingNotifiableFuture<Object> flushCache(Collection<Object> keys, Object retval, Address origin);
 
+   Future<Object> flushCacheWithSimpleFuture(Collection<Object> keys, Object retval, Address origin);
 }",2012-03-22T09:39:02Z,167
"@@ -23,70 +23,145 @@
 package org.infinispan.distribution;
 
 import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.commands.write.InvalidateCommand;
 import org.infinispan.config.Configuration;
+import org.infinispan.factories.KnownComponentNames;
+import org.infinispan.factories.annotations.ComponentName;
 import org.infinispan.factories.annotations.Inject;
+import org.infinispan.factories.annotations.Start;
+import org.infinispan.factories.annotations.Stop;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.util.concurrent.AggregatingNotifyingFutureImpl;
-import org.infinispan.util.concurrent.ConcurrentHashSet;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
+import org.infinispan.util.concurrent.NoOpFuture;
+import org.infinispan.util.concurrent.NotifyingFutureImpl;
 import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 import java.util.Collection;
 import java.util.HashSet;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.Callable;
 import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Future;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.ScheduledFuture;
+import java.util.concurrent.TimeUnit;
+
+import static org.infinispan.factories.KnownComponentNames.ASYNC_TRANSPORT_EXECUTOR;
 
 public class L1ManagerImpl implements L1Manager {
 
    private static final Log log = LogFactory.getLog(L1ManagerImpl.class);
    private final boolean trace = log.isTraceEnabled();
 
+   private Configuration configuration;
    private RpcManager rpcManager;
    private CommandsFactory commandsFactory;
    private int threshold;
    private long rpcTimeout;
+   private long l1Lifespan;
+   private ExecutorService asyncTransportExecutor;
+
+   // TODO replace this with a custom, expirable collection
+   private final ConcurrentMap<Object, ConcurrentMap<Address, Long>> requestors;
+   private ScheduledExecutorService scheduledExecutor;
+   private ScheduledFuture<?> scheduledRequestorsCleanupTask;
 
-   private final ConcurrentMap<Object, Collection<Address>> requestors;
 
    public L1ManagerImpl() {
 	   requestors = ConcurrentMapFactory.makeConcurrentMap();
    }
 
    @Inject
-   public void init(Configuration configuration, RpcManager rpcManager, CommandsFactory commandsFactory) {
+   public void init(Configuration configuration, RpcManager rpcManager, CommandsFactory commandsFactory,
+                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService asyncTransportExecutor,
+                    @ComponentName(KnownComponentNames.EVICTION_SCHEDULED_EXECUTOR) ScheduledExecutorService scheduledExecutor) {
       this.rpcManager = rpcManager;
       this.commandsFactory = commandsFactory;
+      this.configuration = configuration;
+      this.asyncTransportExecutor = asyncTransportExecutor;
+      this.scheduledExecutor = scheduledExecutor;
+   }
+   
+   @Start (priority = 3)
+   public void start() {
       this.threshold = configuration.getL1InvalidationThreshold();
       this.rpcTimeout = configuration.getSyncReplTimeout();
+      this.l1Lifespan = configuration.getL1Lifespan();
+      if (configuration.getL1InvalidationCleanupTaskFrequency() > 0) {
+         scheduledRequestorsCleanupTask = scheduledExecutor.scheduleAtFixedRate(new Runnable() {
+            @Override
+            public void run() {
+               cleanUpRequestors();
+            }
+         }, configuration.getL1InvalidationCleanupTaskFrequency(),
+            configuration.getL1InvalidationCleanupTaskFrequency(), TimeUnit.MILLISECONDS);
+      } else {
+         log.warn(""Not using an L1 invalidation reaper thread. This could lead to memory leaks as the requestors map may grow indefinitely!"");
+      }
    }
 
+   @Stop (priority = 3)
+   public void stop() {
+      if (scheduledRequestorsCleanupTask != null) scheduledRequestorsCleanupTask.cancel(true);
+   }
+
+   private void cleanUpRequestors() {
+      int sz = requestors.size();
+      long expiryTime = System.currentTimeMillis() - l1Lifespan;
+      for (Map.Entry<Object, ConcurrentMap<Address, Long>> entry: requestors.entrySet()) {
+         Object key = entry.getKey();
+         ConcurrentMap<Address, Long> reqs = entry.getValue();
+         prune(reqs, expiryTime);
+         if (reqs.isEmpty()) requestors.remove(key);
+      }
+   }
+   
+   private void prune(ConcurrentMap<Address, Long> reqs, long expiryTime) {
+      for (Map.Entry<Address, Long> req: reqs.entrySet()) {
+         if (req.getValue() < expiryTime) reqs.remove(req.getKey());
+      }
+   }
+   
    public void addRequestor(Object key, Address origin) {
       //we do a plain get first as that's likely to be enough
-      Collection<Address> as = requestors.get(key);
-
+      ConcurrentMap<Address, Long> as = requestors.get(key);
+      long now = System.currentTimeMillis();
       if (as == null) {
          // only if needed we create a new HashSet, but make sure we don't replace another one being created
-         as = new ConcurrentHashSet<Address>();
-         as.add(origin);
-         Collection<Address> previousAs = requestors.putIfAbsent(key, as);
+         as = ConcurrentMapFactory.makeConcurrentMap();
+         as.put(origin, now);
+         ConcurrentMap<Address, Long> previousAs = requestors.putIfAbsent(key, as);
          if (previousAs != null) {
             //another thread added it already, so use his copy and discard our proposed instance
-            previousAs.add(origin);
+            previousAs.put(origin, now);
          }
       } else {
-         as.add(origin);
+         as.put(origin, now);
       }
    }
 
+   @Override
+   public Future<Object> flushCacheWithSimpleFuture(Collection<Object> keys, Object retval, Address origin) {
+      return flushCache(keys, retval, origin, false);
+   }
+
+   @Override
    public NotifyingNotifiableFuture<Object> flushCache(Collection<Object> keys, Object retval, Address origin) {
-      if (trace) log.tracef(""Invalidating L1 caches for keys %s"", keys);
+      return (NotifyingNotifiableFuture<Object>) flushCache(keys, retval, origin, true);
+   }
 
-      NotifyingNotifiableFuture<Object> future = new AggregatingNotifyingFutureImpl(retval, 2);
+   private Future<Object> flushCache(Collection<Object> keys, final Object retval, Address origin, boolean useNotifyingFuture) {
+      if (trace) log.tracef(""Invalidating L1 caches for keys %s"", keys);
 
-      Collection<Address> invalidationAddresses = buildInvalidationAddressList(keys, origin);
+      final Collection<Address> invalidationAddresses = buildInvalidationAddressList(keys, origin);
 
       int nodes = invalidationAddresses.size();
 
@@ -99,32 +174,61 @@ public NotifyingNotifiableFuture<Object> flushCache(Collection<Object> keys, Obj
 
          if (multicast) {
             if (trace) log.tracef(""Invalidating keys %s via multicast"", keys);
-            InvalidateCommand ic = commandsFactory.buildInvalidateFromL1Command(origin, false, keys);
-            rpcManager.broadcastRpcCommandInFuture(ic, future);
+            final InvalidateCommand ic = commandsFactory.buildInvalidateFromL1Command(origin, false, keys);
+            if (useNotifyingFuture) {
+               NotifyingNotifiableFuture<Object> future = new AggregatingNotifyingFutureImpl(retval, 2);
+               rpcManager.broadcastRpcCommandInFuture(ic, future);
+               return future;
+            } else {
+               return asyncTransportExecutor.submit(new Callable<Object>() {
+                  @Override
+                  public Object call() throws Exception {
+                     rpcManager.broadcastRpcCommand(ic, true);
+                     return retval;
+                  }
+               });
+            }
          } else {
-            InvalidateCommand ic = commandsFactory.buildInvalidateFromL1Command(origin, false, keys);
-
+            final CacheRpcCommand rpc = commandsFactory.buildSingleRpcCommand(commandsFactory.buildInvalidateFromL1Command(origin, false, keys));
             // Ask the caches who have requested from us to remove
             if (trace) log.tracef(""Keys %s needs invalidation on %s"", keys, invalidationAddresses);
-            rpcManager.invokeRemotelyInFuture(invalidationAddresses, ic, true, future, rpcTimeout, true);
-            return future;
+            if (useNotifyingFuture) {
+               NotifyingNotifiableFuture<Object> future = new AggregatingNotifyingFutureImpl(retval, 2);
+               rpcManager.invokeRemotelyInFuture(invalidationAddresses, rpc, true, future, rpcTimeout, true);
+               return future;
+            } else {
+               return asyncTransportExecutor.submit(new Callable<Object>() {
+                  @Override
+                  public Object call() throws Exception {
+                     rpcManager.invokeRemotely(invalidationAddresses, rpc, ResponseMode.SYNCHRONOUS, rpcTimeout, true);
+                     return retval;
+                  }
+               });
+            }
          }
-      } else if (trace) log.trace(""No L1 caches to invalidate"");
-      return future;
+      } else {
+         if (trace) log.trace(""No L1 caches to invalidate"");
+         return useNotifyingFuture ? new NotifyingFutureImpl(retval) : new NoOpFuture<Object>(retval);
+      }
    }
 
    private Collection<Address> buildInvalidationAddressList(Collection<Object> keys, Address origin) {
       Collection<Address> addresses = new HashSet<Address>(2);
-
+      boolean originIsInRequestorsList = false;
       for (Object key : keys) {
-         Collection<Address> as = requestors.remove(key);
+         ConcurrentMap<Address, Long> as = requestors.remove(key);
          if (as != null) {
-            addresses.addAll(as);
-            if (origin != null && as.contains(origin)) addRequestor(key, origin);
+            Set<Address> requestorAddresses = as.keySet();
+            addresses.addAll(requestorAddresses);
+            if (origin != null && requestorAddresses.contains(origin)) {
+               originIsInRequestorsList = true;
+               // re-add the origin as a requestor since the key will still be in the origin's L1 cache
+               addRequestor(key, origin);
+            }
          }
       }
-      if (origin != null)
-         addresses.remove(origin);
+      // Prevent a loop by not sending the invalidation message to the origin
+      if (originIsInRequestorsList) addresses.remove(origin);
       return addresses;
    }
 
@@ -138,5 +242,4 @@ private boolean isUseMulticast(int nodes) {
       // we decide:
       return nodes > threshold;
    }
-
 }",2012-03-22T09:39:02Z,168
"@@ -139,12 +139,9 @@ public void start() {
    public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand command) throws Throwable {
       try {
          Object returnValue = invokeNextInterceptor(ctx, command);
-
          // If L1 caching is enabled, this is a remote command, and we found a value in our cache
          // we store it so that we can later invalidate it
-         if (isL1CacheEnabled && !ctx.isOriginLocal() && returnValue != null) {
-           l1Manager.addRequestor(command.getKey(), ctx.getOrigin());
-         }
+         if (returnValue != null && isL1CacheEnabled && !ctx.isOriginLocal()) l1Manager.addRequestor(command.getKey(), ctx.getOrigin());
 
          // need to check in the context as well since a null retval is not necessarily an indication of the entry not being
          // available.  It could just have been removed in the same tx beforehand.  Also don't bother with a remote get if
@@ -271,14 +268,15 @@ private boolean isNotInL1(Object key) {
 
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
-      Object returnValue = handleWriteCommand(ctx, command, new SingleKeyRecipientGenerator(command.getKey()), false, false);
+      SingleKeyRecipientGenerator skrg = new SingleKeyRecipientGenerator(command.getKey());
+      Object returnValue = handleWriteCommand(ctx, command, skrg, false, false);
       // If this was a remote put record that which sent it
-      if (isL1CacheEnabled && !ctx.isOriginLocal()) {
-      	l1Manager.addRequestor(command.getKey(), ctx.getOrigin());
-      }
+      if (isL1CacheEnabled && !ctx.isOriginLocal() && !skrg.generateRecipients().contains(ctx.getOrigin()))
+         l1Manager.addRequestor(command.getKey(), ctx.getOrigin());
+
       return returnValue;
    }
-
+   
    @Override
    public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
       // don't bother with a remote get for the PutMapCommand!
@@ -345,7 +343,8 @@ public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command)
    }
 
    private Future<?> flushL1Caches(InvocationContext ctx) {
-      return isL1CacheEnabled ? l1Manager.flushCache(ctx.getLockedKeys(), null, ctx.getOrigin()) : null;
+      // TODO how do we tell the L1 manager which keys are removed and which keys may still exist in remote L1?
+      return isL1CacheEnabled ? l1Manager.flushCacheWithSimpleFuture(ctx.getLockedKeys(), null, ctx.getOrigin()) : null;
    }
 
    private void blockOnL1FutureIfNeeded(Future<?> f) {
@@ -466,7 +465,8 @@ private Object handleWriteCommand(InvocationContext ctx, WriteCommand command, R
       if (command.isSuccessful()) {
 
          if (!ctx.isInTxScope()) {
-            NotifyingNotifiableFuture<Object> future = null;
+            NotifyingNotifiableFuture<Object> futureToReturn = null;
+            Future<?> invalidationFuture = null;
             if (ctx.isOriginLocal()) {
                int newCacheViewId = -1;
                stateTransferLock.waitForStateTransferToEnd(ctx, command, newCacheViewId);
@@ -481,33 +481,40 @@ private Object handleWriteCommand(InvocationContext ctx, WriteCommand command, R
                	if (rpcManager.getTransport().getMembers().size() > numCallRecipients) {
                		// Command was successful, we have a number of receipients and L1 should be flushed, so request any L1 invalidations from this node
                		if (trace) log.tracef(""Put occuring on node, requesting L1 cache invalidation for keys %s. Other data owners are %s"", command.getAffectedKeys(), dm.getAffectedNodes(command.getAffectedKeys()));
-               		future = l1Manager.flushCache(recipientGenerator.getKeys(), returnValue, null);
+                     if (useFuture) {
+               		   futureToReturn = l1Manager.flushCache(recipientGenerator.getKeys(), returnValue, null);
+                     } else {
+                        invalidationFuture = l1Manager.flushCacheWithSimpleFuture(recipientGenerator.getKeys(), returnValue, null);
+                     }
                	} else {
                      if (trace) log.tracef(""Not performing invalidation! numCallRecipients=%s"", numCallRecipients);
                   }
                if (!isSingleOwnerAndLocal(recipientGenerator)) {
                   if (useFuture) {
-                     if (future == null) future = new NotifyingFutureImpl(returnValue);
-                     rpcManager.invokeRemotelyInFuture(rec, command, future);
-                     return future;
+                     if (futureToReturn == null) futureToReturn = new NotifyingFutureImpl(returnValue);
+                     rpcManager.invokeRemotelyInFuture(rec, command, futureToReturn);
+                     return futureToReturn;
                   } else {
                      rpcManager.invokeRemotely(rec, command, sync);
                   }
-               } else if (useFuture && future != null) {
-                  return future;
+               } else if (useFuture && futureToReturn != null) {
+                  return futureToReturn;
                }
-               if (future != null && sync) {
-                  future.get(); // wait for the inval command to complete
+               if (invalidationFuture != null && sync) {
+                  invalidationFuture.get(); // wait for the inval command to complete
                   if (trace) log.tracef(""Finished invalidating keys %s "", recipientGenerator.getKeys());
                }
             } else {
             	// Piggyback remote puts and cause L1 invalidations
             	if (isL1CacheEnabled && !skipL1Invalidation) {
                	// Command was successful and L1 should be flushed, so request any L1 invalidations from this node
             		if (trace) log.tracef(""Put occuring on node, requesting cache invalidation for keys %s. Origin of command is remote"", command.getAffectedKeys());
-            		future = l1Manager.flushCache(recipientGenerator.getKeys(), returnValue, ctx.getOrigin());
+                  // If this is a remove command, then don't pass in the origin - since the entru would be removed from the origin's L1 cache.
+            		invalidationFuture = l1Manager.flushCacheWithSimpleFuture(recipientGenerator.getKeys(),
+                                                                            returnValue,
+                                                                            command instanceof RemoveCommand ? null : ctx.getOrigin());
             		if (sync) {
-            			future.get(); // wait for the inval command to complete
+                     invalidationFuture.get(); // wait for the inval command to complete
                      if (trace) log.tracef(""Finished invalidating keys %s "", recipientGenerator.getKeys());
             		}
             	}",2012-03-22T09:39:02Z,101
"@@ -0,0 +1,77 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.util.concurrent;
+
+import java.util.concurrent.*;
+import java.util.concurrent.TimeoutException;
+
+/**
+ * A future that doesn't do anything and simply returns a given return value.
+ *
+ * @author Manik Surtani
+ * @since 5.1
+ */
+public class NoOpFuture<E> implements NotifyingNotifiableFuture<E> {
+   private final E returnValue;
+
+   public NoOpFuture(E returnValue) {
+      this.returnValue = returnValue;
+   }
+
+   @Override
+   public boolean cancel(boolean b) {
+      return false;
+   }
+
+   @Override
+   public boolean isCancelled() {
+      return false;
+   }
+
+   @Override
+   public boolean isDone() {
+      return true;
+   }
+
+   @Override
+   public E get() throws InterruptedException, ExecutionException {
+      return returnValue;
+   }
+
+   @Override
+   public E get(long l, TimeUnit timeUnit) throws InterruptedException, ExecutionException, TimeoutException {
+      return returnValue;
+   }
+
+   @Override
+   public void notifyDone() {      
+   }
+
+   @Override
+   public void setNetworkFuture(Future<E> eFuture) {
+      throw new UnsupportedOperationException();
+   }
+
+   @Override
+   public NotifyingFuture<E> attachListener(FutureListener<E> eFutureListener) {
+      eFutureListener.futureDone(this);
+      return this;
+   }
+}",2012-03-22T09:39:02Z,169
"@@ -1,4 +1,23 @@
 <?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?>
+<!--
+  ~ Copyright 2012 Red Hat, Inc. and/or its affiliates.
+  ~
+  ~ This is free software; you can redistribute it and/or modify it
+  ~ under the terms of the GNU Lesser General Public License as
+  ~ published by the Free Software Foundation; either version 2.1 of
+  ~ the License, or (at your option) any later version.
+  ~
+  ~ This software is distributed in the hope that it will be useful,
+  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
+  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  ~ Lesser General Public License for more details.
+  ~
+  ~ You should have received a copy of the GNU Lesser General Public
+  ~ License along with this library; if not, write to the Free Software
+  ~ Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+  ~ 02110-1301 USA
+  -->
+
 <xs:schema attributeFormDefault=""unqualified"" elementFormDefault=""qualified"" version=""1.0"" targetNamespace=""urn:infinispan:config:5.2"" xmlns:tns=""urn:infinispan:config:5.2"" xmlns:xs=""http://www.w3.org/2001/XMLSchema"">
 
   <xs:element name=""infinispan"">
@@ -883,6 +902,13 @@
                     </xs:documentation>
                   </xs:annotation>
                 </xs:attribute>
+                <xs:attribute name=""cleanupTaskFrequency"" type=""xs:long"">
+                   <xs:annotation>
+                      <xs:documentation>
+                         Controls how often a cleanup task to prune L1 tracking data is run.
+                      </xs:documentation>
+                   </xs:annotation>
+                </xs:attribute>
                 <xs:attribute name=""onRehash"" type=""xs:boolean"">
                   <xs:annotation>
                     <xs:documentation>",2012-03-22T09:39:02Z,170
"@@ -295,6 +295,7 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm) {
       assert c.clustering().l1().lifespan() == 600000;
       assert c.clustering().hash().rehashRpcTimeout() == 120000;
       assert c.clustering().stateTransfer().timeout() == 120000;
+      assert c.clustering().l1().cleanupTaskFrequency() == 1200;
       assert c.clustering().hash().consistentHash() == null; // this is just an override.
       assert c.clustering().hash().numOwners() == 3;
       assert c.clustering().l1().enabled();",2012-03-22T09:39:02Z,128
"@@ -174,7 +174,7 @@
       <clustering mode=""distribution"">
          <sync/>
          <hash numOwners=""3"" rehashRpcTimeout=""120000""/>
-         <l1 enabled=""true"" lifespan=""600000""/>
+         <l1 enabled=""true"" lifespan=""600000"" cleanupTaskFrequency=""1200""/>
       </clustering>
    </namedCache>
 ",2012-03-22T09:39:02Z,171
"@@ -34,6 +34,7 @@
 import org.infinispan.container.versioning.EntryVersionsMap;
 import org.infinispan.container.versioning.IncrementableEntryVersion;
 import org.infinispan.container.versioning.VersionGenerator;
+import org.infinispan.context.Flag;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.DistributionManager;
 import org.infinispan.factories.annotations.Inject;
@@ -134,6 +135,12 @@ public EntryVersionsMap createNewVersionsAndCheckForWriteSkews(VersionGenerator
                                                                             keySpecificLogic);
             context.getCacheTransaction().setUpdatedEntryVersions(uv);
             return uv;
+         } else if (prepareCommand.getModifications().length == 0) {
+            // For situations when there's a local-only put in the prepare,
+            // simply add an empty entry version map. This works because when
+            // a local-only put is executed, this is not added to the prepare
+            // modification list.
+            context.getCacheTransaction().setUpdatedEntryVersions(new EntryVersionsMap());
          }
          return null;
       }",2012-03-21T10:18:43Z,172
"@@ -52,17 +52,17 @@
  */
 @MBean(objectName = ""Statistics"", description = ""General statistics such as timings, hit/miss ratio, etc."")
 public class CacheMgmtInterceptor extends JmxStatsCommandInterceptor {
-   private AtomicLong hitTimes = new AtomicLong(0);
-   private AtomicLong missTimes = new AtomicLong(0);
-   private AtomicLong storeTimes = new AtomicLong(0);
-   private AtomicLong hits = new AtomicLong(0);
-   private AtomicLong misses = new AtomicLong(0);
-   private AtomicLong stores = new AtomicLong(0);
-   private AtomicLong evictions = new AtomicLong(0);
-   private AtomicLong start = new AtomicLong(System.currentTimeMillis());
-   private AtomicLong reset = new AtomicLong(start.get());
-   private AtomicLong removeHits = new AtomicLong(0);
-   private AtomicLong removeMisses = new AtomicLong(0);
+   private final AtomicLong hitTimes = new AtomicLong(0);
+   private final AtomicLong missTimes = new AtomicLong(0);
+   private final AtomicLong storeTimes = new AtomicLong(0);
+   private final AtomicLong hits = new AtomicLong(0);
+   private final AtomicLong misses = new AtomicLong(0);
+   private final AtomicLong stores = new AtomicLong(0);
+   private final AtomicLong evictions = new AtomicLong(0);
+   private final AtomicLong startNanoseconds = new AtomicLong(System.nanoTime());
+   private final AtomicLong resetNanoseconds = new AtomicLong(startNanoseconds.get());
+   private final AtomicLong removeHits = new AtomicLong(0);
+   private final AtomicLong removeMisses = new AtomicLong(0);
 
    private DataContainer dataContainer;
 
@@ -80,14 +80,15 @@ public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) thr
 
    @Override
    public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand command) throws Throwable {
-      long t1 = System.currentTimeMillis();
+      long t1 = System.nanoTime();
       Object retval = invokeNextInterceptor(ctx, command);
-      long t2 = System.currentTimeMillis();
+      long t2 = System.nanoTime();
+      long intervalMilliseconds = nanosecondsIntervalToMilliseconds(t1, t2);
       if (retval == null) {
-         missTimes.getAndAdd(t2 - t1);
+         missTimes.getAndAdd(intervalMilliseconds);
          misses.incrementAndGet();
       } else {
-         hitTimes.getAndAdd(t2 - t1);
+         hitTimes.getAndAdd(intervalMilliseconds);
          hits.incrementAndGet();
       }
       return retval;
@@ -96,12 +97,12 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
    @Override
    public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
       Map data = command.getMap();
-      long t1 = System.currentTimeMillis();
+      long t1 = System.nanoTime();
       Object retval = invokeNextInterceptor(ctx, command);
-      long t2 = System.currentTimeMillis();
-
+      long t2 = System.nanoTime();
+      long intervalMilliseconds = nanosecondsIntervalToMilliseconds(t1, t2);
       if (data != null && !data.isEmpty()) {
-         storeTimes.getAndAdd(t2 - t1);
+         storeTimes.getAndAdd(intervalMilliseconds);
          stores.getAndAdd(data.size());
       }
       return retval;
@@ -110,10 +111,11 @@ public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) t
    @Override
    //Map.put(key,value) :: oldValue
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
-      long t1 = System.currentTimeMillis();
+      long t1 = System.nanoTime();
       Object retval = invokeNextInterceptor(ctx, command);
-      long t2 = System.currentTimeMillis();
-      storeTimes.getAndAdd(t2 - t1);
+      long t2 = System.nanoTime();
+      long intervalMilliseconds = nanosecondsIntervalToMilliseconds(t1, t2);
+      storeTimes.getAndAdd(intervalMilliseconds);
       stores.incrementAndGet();
       return retval;
    }
@@ -211,13 +213,13 @@ public int getNumberOfEntries() {
    @ManagedAttribute(description = ""Number of seconds since cache started"")
    @Metric(displayName = ""Seconds since cache started"", units = Units.SECONDS, measurementType = MeasurementType.TRENDSUP, displayType = DisplayType.SUMMARY)
    public long getElapsedTime() {
-      return TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis() - start.get());
+      return TimeUnit.NANOSECONDS.toSeconds(System.nanoTime() - startNanoseconds.get());
    }
 
    @ManagedAttribute(description = ""Number of seconds since the cache statistics were last reset"")
    @Metric(displayName = ""Seconds since cache statistics were reset"", units = Units.SECONDS, displayType = DisplayType.SUMMARY)
    public long getTimeSinceReset() {
-      return TimeUnit.MILLISECONDS.toSeconds(System.currentTimeMillis() - reset.get());
+      return TimeUnit.NANOSECONDS.toSeconds(System.nanoTime() - resetNanoseconds.get());
    }
 
    @ManagedOperation(description = ""Resets statistics gathered by this component"")
@@ -232,7 +234,16 @@ public void resetStatistics() {
       storeTimes.set(0);
       removeHits.set(0);
       removeMisses.set(0);
-      reset.set(System.currentTimeMillis());
+      resetNanoseconds.set(System.nanoTime());
+   }
+
+   /**
+    * @param nanoStart
+    * @param nanoEnd
+    * @return the interval rounded in milliseconds
+    */
+   private final long nanosecondsIntervalToMilliseconds(final long nanoStart, final long nanoEnd) {
+      return TimeUnit.MILLISECONDS.convert(nanoEnd - nanoStart, TimeUnit.NANOSECONDS);
    }
 }
 ",2011-10-19T13:56:13Z,173
"@@ -262,16 +262,19 @@ public Object readObject(Unmarshaller input) throws IOException, ClassNotFoundEx
       if (adapter == null) {
          if (!started) {
             if (log.isTraceEnabled())
-               log.tracef(""Either the marshaller has stopped or hasn't started. Read externalizers are not propery populated: %s"", readers);
+               log.tracef(""Either the marshaller has stopped or hasn't started. Read externalizers are not properly populated: %s"", readers);
 
-            if (Thread.currentThread().isInterrupted())
+            if (Thread.currentThread().isInterrupted()) {
                throw new IOException(String.format(
                      ""Cache manager is shutting down, so type (id=%d) cannot be resolved. Interruption being pushed up."",
                      readerIndex), new InterruptedException());
-            else
+            } else if (gcr.getStatus().isStopping()) {
+               log.tracef(""Cache manager is shutting down and type (id=%d) cannot be resolved (thread not interrupted)"", readerIndex);
+            } else {
                throw new CacheException(String.format(
-                     ""Cache manager is either starting up or shutting down but it's not interrupted, so type (id=%d) cannot be resolved."",
+                     ""Cache manager is either starting up and type (id=%d) cannot be resolved (thread not interrupted)"",
                      readerIndex));
+            }
          } else {
             if (log.isTraceEnabled()) {
                log.tracef(""Unknown type. Input stream has %s to read"", input.available());",2012-02-22T14:06:56Z,174
"@@ -201,7 +201,12 @@ protected void loopOverBuckets(BucketHandler handler) throws CacheLoaderExceptio
          Bucket bucket = readFromBlob(entry.getValue(), entry.getKey());
          if (bucket != null) {
             if (bucket.removeExpiredEntries()) {
-               updateBucket(bucket);
+               upgradeLock(bucket.getBucketId());
+               try {
+                  updateBucket(bucket);
+               } finally {
+                  downgradeLock(bucket.getBucketId());
+               }
             }
             if (handler.handle(bucket)) {
                break;
@@ -287,7 +292,12 @@ private void scanBlobForExpiredEntries(String blobName) {
          Bucket bucket = readFromBlob(blob, blobName);
          if (bucket != null) {
             if (bucket.removeExpiredEntries()) {
-               updateBucket(bucket);
+               lockForWriting(bucket.getBucketId());
+               try {
+                  updateBucket(bucket);
+               } finally {
+                  unlock(bucket.getBucketId());
+               }
            }
          } else {
             throw new CacheLoaderException(""Blob not found: "" + blobName);",2012-03-27T08:54:50Z,175
"@@ -99,6 +99,20 @@ protected final void lockForReading(L key) {
       locks.acquireLock(key, false);
    }
 
+   /**
+    * Upgrades a read lock to a write lock.
+    */
+   protected final void upgradeLock(L key) {
+      locks.upgradeLock(key);
+   }
+
+   /**
+    * Downgrade a write lock to a read lock
+    */
+   protected final void downgradeLock(L key) {
+      locks.downgradeLock(key);
+   }
+
    /**
     * Same as {@link #lockForWriting(Object)}, but with 0 timeout.
     */",2012-03-27T08:54:50Z,176
"@@ -156,7 +156,12 @@ protected abstract class CollectionGeneratingBucketHandler<T> implements BucketH
       public boolean handle(Bucket bucket) throws CacheLoaderException {
          if (bucket != null) {
             if (bucket.removeExpiredEntries()) {
-               updateBucket(bucket);
+               upgradeLock(bucket.getBucketId());
+               try {
+                  updateBucket(bucket);
+               } finally {
+                  downgradeLock(bucket.getBucketId());
+               }
             }
             boolean enoughLooping = consider(bucket.getStoredEntries());
             if (enoughLooping) {",2012-03-27T08:54:50Z,177
"@@ -199,7 +199,8 @@ protected void clearLockSafe() throws CacheLoaderException {
          return;
       }
       for (File f : toDelete) {
-         if (!deleteFile(f)) {
+         deleteFile(f);
+         if (f.exists()) {
             log.problemsRemovingFile(f);
          }
       }
@@ -244,23 +245,22 @@ public void run() {
     */
    private boolean doPurge(File bucketFile) {
       Integer bucketKey = Integer.valueOf(bucketFile.getName());
-      boolean lockAcquired = false;
       boolean interrupted = false;
       try {
+         lockForReading(bucketKey);
          Bucket bucket = loadBucket(bucketFile);
 
          if (bucket != null) {
             if (bucket.removeExpiredEntries()) {
-               lockForWriting(bucketKey);
-               lockAcquired = true;
+               upgradeLock(bucketKey);
+               updateBucket(bucket);
             }
-            updateBucket(bucket);
          } else {
             // Bucket may be an empty 0-length file
             if (bucketFile.exists() && bucketFile.length() == 0) {
-               lockForWriting(bucketKey);
-               lockAcquired = true;
-               if (!bucketFile.delete())
+               upgradeLock(bucketKey);
+               fileSync.deleteFile(bucketFile);
+               if (bucketFile.exists())
                   log.info(""Unable to remove empty file "" + bucketFile + "" - will try again later."");
             }
          }
@@ -269,9 +269,7 @@ private boolean doPurge(File bucketFile) {
       } catch (CacheLoaderException e) {
          log.problemsPurgingFile(bucketFile, e);
       } finally {
-         if (lockAcquired) {
-            unlock(bucketKey);
-         }
+         unlock(bucketKey);
       }
       return !interrupted;
    }
@@ -398,11 +396,11 @@ public Bucket loadBucketContainingKey(String key) throws CacheLoaderException {
       return loadBucket(getLockFromKey(key));
    }
 
-   private boolean deleteFile(File f) {
+   private void deleteFile(File f) {
       if (trace) {
          log.tracef(""Really delete file %s"", f);
       }
-      return f.delete();
+      fileSync.deleteFile(f);
    }
 
    private boolean purgeFile(File f) {
@@ -505,6 +503,7 @@ private interface FileSync {
        */
       void stop();
 
+      void deleteFile(File f);
    }
 
    private static class BufferedFileSync implements FileSync {
@@ -513,8 +512,8 @@ private static class BufferedFileSync implements FileSync {
       @Override
       public void write(byte[] bytes, File f) throws IOException {
          if (bytes.length == 0) {
-            // Short circuit
-            if (f.exists()) f.delete();
+            // Short circuit for deleting files
+            deleteFile(f);
             return;
          }
 
@@ -542,6 +541,17 @@ public void write(byte[] bytes, File f) throws IOException {
          channel.write(ByteBuffer.wrap(bytes));
       }
 
+      @Override
+      public void deleteFile(File f) {
+         String path = f.getPath();
+         // First remove the channel from the map
+         FileChannel fc = streams.remove(path);
+         // Then close the channel (handles null params)
+         Util.close(fc);
+         // Now that the channel is closed we can delete the file
+         f.delete();
+      }
+
       private FileChannel createChannel(File f) throws FileNotFoundException {
          return new RandomAccessFile(f, ""rw"").getChannel();
       }
@@ -644,8 +654,9 @@ public void write(byte[] bytes, File f) throws IOException {
                fos = new FileOutputStream(f);
                fos.write(bytes);
                fos.flush();
-            } else if (f.exists()) {
-               f.delete();
+               fos.getChannel().force(true);
+            } else {
+               deleteFile(f);
             }
          } finally {
             if (fos != null)
@@ -660,13 +671,18 @@ public void flush(File f) throws IOException {
 
       @Override
       public void purge(File f) throws IOException {
-         f.delete();
+         deleteFile(f);
       }
 
       @Override
       public void stop() {
          // No-op
       }
+
+      @Override
+      public void deleteFile(File f) {
+         f.delete();
+      }
    }
 
    /**",2012-03-27T08:54:50Z,178
"@@ -50,6 +50,7 @@
 public class StripedLock {
 
    private static final Log log = LogFactory.getLog(StripedLock.class);
+   private static final boolean trace = log.isTraceEnabled();
 
    private static final int DEFAULT_CONCURRENCY = 20;
    private final int lockSegmentMask;
@@ -95,24 +96,24 @@ public void acquireLock(Object key, boolean exclusive) {
       ReentrantReadWriteLock lock = getLock(key);
       if (exclusive) {
          lock.writeLock().lock();
-         if (log.isTraceEnabled()) {
-            log.tracef(""WL acquired for '%s'"", key);
-        }
+         if (trace) log.tracef(""WL acquired for '%s'"", key);
       } else {
          lock.readLock().lock();
-         if (log.isTraceEnabled()) {
-            log.tracef(""RL acquired for '%s'"", key);
-        }
+         if (trace) log.tracef(""RL acquired for '%s'"", key);
       }
    }
 
    public boolean acquireLock(Object key, boolean exclusive, long millis) {
       ReentrantReadWriteLock lock = getLock(key);
       try {
          if (exclusive) {
-            return lock.writeLock().tryLock(millis, TimeUnit.MILLISECONDS);
+            boolean success = lock.writeLock().tryLock(millis, TimeUnit.MILLISECONDS);
+            if (success && trace) log.tracef(""WL acquired for '%s'"", key);
+            return success;
          } else {
-            return lock.readLock().tryLock(millis, TimeUnit.MILLISECONDS);
+            boolean success = lock.readLock().tryLock(millis, TimeUnit.MILLISECONDS);
+            if (success && trace) log.tracef(""RL acquired for '%s'"", key);
+            return success;
          }
       } catch (InterruptedException e) {
          log.interruptedAcquiringLock(millis, e);
@@ -127,13 +128,28 @@ public void releaseLock(Object key) {
       ReentrantReadWriteLock lock = getLock(key);
       if (lock.isWriteLockedByCurrentThread()) {
          lock.writeLock().unlock();
-         log.tracef(""WL released for '%s'"", key);
+         if (trace) log.tracef(""WL released for '%s'"", key);
       } else {
          lock.readLock().unlock();
-         log.tracef(""RL released for '%s'"", key);
+         if (trace) log.tracef(""WL released for '%s'"", key);
       }
    }
 
+   public void upgradeLock(Object key) {
+      ReentrantReadWriteLock lock = getLock(key);
+      lock.readLock().unlock();
+      // another thread could come here and take the RL or WL, forcing us to wait
+      lock.writeLock().lock();
+      if (trace) log.tracef(""RL upgraded to WL for '%s'"", key);
+   }
+
+   public void downgradeLock(Object key) {
+      ReentrantReadWriteLock lock = getLock(key);
+      lock.readLock().lock();
+      lock.writeLock().unlock();
+      if (trace) log.tracef(""WL downgraded to RL for '%s'"", key);
+   }
+
    final ReentrantReadWriteLock getLock(Object o) {
       return sharedLocks[hashToIndex(o)];
    }
@@ -201,15 +217,11 @@ public boolean aquireGlobalLock(boolean exclusive, long timeout) {
          try {
             success = toAcquire.tryLock(timeout, TimeUnit.MILLISECONDS);
             if (!success) {
-               if (log.isTraceEnabled()) {
-                log.tracef(""Could not aquire lock on %s. Exclusive? %b"", toAcquire, exclusive);
-            }
+               if (trace) log.tracef(""Could not aquire lock on %s. Exclusive? %b"", toAcquire, exclusive);
                break;
             }
          } catch (InterruptedException e) {
-            if (log.isTraceEnabled()) {
-                log.trace(""Cought InterruptedException while trying to aquire global lock"", e);
-            }
+            if (trace) log.trace(""Cought InterruptedException while trying to aquire global lock"", e);
             success = false;
             Thread.currentThread().interrupt(); // Restore interrupted status
          } finally {",2012-03-27T08:54:50Z,179
"@@ -56,12 +56,13 @@ class CrashedMemberDetectorListener(cache: Cache[Address, ServerAddress], server
          val newMembers = collectionAsScalaIterable(e.getNewMembers)
          val oldMembers = collectionAsScalaIterable(e.getOldMembers)
          val goneMembers = oldMembers.filterNot(newMembers contains _)
-         // Consider doing removeAsync and then waiting for all removals...
-         goneMembers.foreach { addr =>
-            trace(""Remove %s from address cache"", addr)
-            addressCache.remove(addr)
+         if (!goneMembers.isEmpty) {
+            // Consider doing removeAsync and then waiting for all removals...
+            goneMembers.foreach(addressCache.remove(_))
+            // Only update view id once we've removed all addresses to
+            // guarantee that the cache will be up to date
+            updateViewdId(e)
          }
-         updateViewdId(e)
       } catch {
          case t: Throwable => logErrorDetectingCrashedMember(t)
       }",2012-02-18T17:53:18Z,180
"@@ -64,7 +64,10 @@ class HotRodServer extends AbstractProtocolServer(""HotRod"") with Log {
 
    def getViewId: Int = viewId
 
-   def setViewId(viewId: Int) = this.viewId = viewId
+   def setViewId(viewId: Int) {
+      trace(""Set view id to %d"", viewId)
+      this.viewId = viewId
+   }
 
    override def getEncoder = new HotRodEncoder(getCacheManager, this)
 
@@ -180,7 +183,7 @@ class HotRodServer extends AbstractProtocolServer(""HotRod"") with Log {
          // Only update view id once cache has been updated
          if (!event.isPre) {
             val localViewId = transport.getViewId
-            viewId = localViewId
+            setViewId(localViewId)
             if (isTraceEnabled) {
                log.tracef(""Address cache had %s for key %s. View id is now %d"",
                           event.getType, event.getKey, localViewId)",2012-02-18T17:53:18Z,158
"@@ -360,7 +360,8 @@ public void start() throws CacheLoaderException {
       }
       streamBufferSize = config.getStreamBufferSize();
 
-      switch (config.getFsyncMode()) {
+      FileCacheStoreConfig.FsyncMode fsyncMode = config.getFsyncMode();
+      switch (fsyncMode) {
          case DEFAULT:
             fileSync = new BufferedFileSync();
             break;
@@ -371,6 +372,8 @@ public void start() throws CacheLoaderException {
             fileSync = new PeriodicFileSync(config.getFsyncInterval());
             break;
       }
+      
+      log.debugf(""Using %s file sync mode"", fsyncMode);
    }
 
    @Override",2012-02-18T17:59:55Z,178
"@@ -46,19 +46,18 @@
  * before timing out and throwing an exception.  By default, this is set to <tt>60000</tt>.</li>
  *    <li><tt>fsyncMode</tt> - configures how the file changes will be
  * synchronized with the underlying file system. This property has three
- * possible values:
+ * possible values (The default mode configured is <tt>default</tt>):
  *       <ul>
- *          <li><tt>default</tt> means that the file system will be
+ *          <li><tt>default</tt> - means that the file system will be
  *       synchronized when the OS buffer is full or when the bucket is read.</li>
- *          <li><tt>perWrite<tt/> configures the file cache store to sync up
- *       changes after each write request<li/>
- *          <li><tt>periodic<tt/> enables sync operations to happen as per a
- *       defined interval, or when the bucket is about to be read.<li/>
- *   The default mode configured is <tt>default</tt>
- *   </li>
+ *          <li><tt>perWrite</tt> - configures the file cache store to sync up
+ *       changes after each write request</li>
+ *          <li><tt>periodic</tt> - enables sync operations to happen as per a
+ *       defined interval, or when the bucket is about to be read.</li>
+ *       </ul>
  *   <li><tt>fsyncInterval</tt> - specifies the time after which the file
  * changes in the cache need to be flushed. This option has only effect when
- * <tt>periodic<tt/> fsync mode is in use. The default fsync interval is 1
+ * <tt>periodic</tt> fsync mode is in use. The default fsync interval is 1
  * second.</li>
  *
  * </ul>",2012-02-18T17:59:55Z,178
"@@ -9,7 +9,7 @@
          + lib (contains dependencies)
       + tree
          - infinispan-tree.jar
-         + lib (excluding core and transitive dependencies)
+         + lib (excluding core)
 
       .. etc ...
 
@@ -35,9 +35,90 @@
 
       <moduleSet>
          <includeSubModules>false</includeSubModules>
-         <excludes>
-            <exclude>org.infinispan:infinispan-tools</exclude>
-         </excludes>
+         <includes>
+            <include>org.infinispan:infinispan-core</include>
+         </includes>
+         <sources>
+            <includeModuleDirectory>false</includeModuleDirectory>
+
+            <fileSets>
+
+               <!-- resources -->
+               <fileSet>
+                  <directory>src/main/resources</directory>
+                  <outputDirectory>etc</outputDirectory>
+                  <excludes>
+                     <exclude>**/*.sh</exclude>
+                     <exclude>**/*.bat</exclude>
+                     <exclude>**/*.cmd</exclude>
+                     <exclude>**/*.py</exclude>
+                  </excludes>
+               </fileSet>
+
+               <!-- Executable resources -->
+               <fileSet>
+                  <directory>src/main/resources</directory>
+                  <outputDirectory>bin</outputDirectory>
+                  <includes>
+                     <include>**/*.sh</include>
+                     <include>**/*.bat</include>
+                     <include>**/*.cmd</include>
+                     <include>**/*.py</include>
+                  </includes>
+                  <fileMode>0777</fileMode>
+               </fileSet>
+
+               <!-- Log4j XML -->
+               <fileSet>
+                  <directory>src/test/resources</directory>
+                  <outputDirectory>etc</outputDirectory>
+                  <includes>
+                     <include>log4j.xml</include>
+                  </includes>
+               </fileSet>
+
+               <!-- EULAs and license files -->
+               <fileSet>
+                  <directory>src/main/release</directory>
+                  <outputDirectory></outputDirectory>
+                  <includes>
+                     <include>**/*.txt</include>
+                  </includes>
+               </fileSet>
+
+            </fileSets>
+
+         </sources>
+
+         <binaries>
+
+            <outputDirectory>modules/${module.basedir.name}</outputDirectory>
+            <outputFileNameMapping>
+               ${module.artifactId}.${module.extension}
+            </outputFileNameMapping>
+            <unpack>false</unpack>
+
+            <dependencySets>
+               <dependencySet>
+                  <useTransitiveDependencies>false</useTransitiveDependencies>
+                  <outputDirectory>modules/${module.basedir.name}/lib</outputDirectory>
+               </dependencySet>
+            </dependencySets>
+
+         </binaries>
+      </moduleSet>
+
+      <moduleSet>
+         <includeSubModules>false</includeSubModules>
+         <includes>
+            <include>org.infinispan:infinispan-cachestore-bdbje</include>
+            <include>org.infinispan:infinispan-cachestore-jdbc</include>
+            <include>org.infinispan:infinispan-cachestore-jdbm</include>
+            <include>org.infinispan:infinispan-cachestore-s3</include>
+            <include>org.infinispan:infinispan-gui-demo</include>
+            <include>org.infinispan:infinispan-jopr-plugin</include>
+            <include>org.infinispan:infinispan-tree</include>
+         </includes>
          <sources>
             <includeModuleDirectory>false</includeModuleDirectory>
 
@@ -103,7 +184,8 @@
                   <excludes>
                      <exclude>infinispan-core*</exclude>
                   </excludes>
-                  <useTransitiveDependencies>false</useTransitiveDependencies>
+                  <useTransitiveDependencies>true</useTransitiveDependencies>
+                  <useTransitiveFiltering>true</useTransitiveFiltering>
                   <outputDirectory>modules/${module.basedir.name}/lib</outputDirectory>
                </dependencySet>
             </dependencySets>",2009-07-23T15:01:14Z,181
"@@ -7,7 +7,7 @@
          + lib (contains dependencies)
       + tree
          - infinispan-tree.jar
-         + lib (excluding core and transitive dependencies)
+         + lib (excluding core)
 
       .. etc ...
 
@@ -28,9 +28,93 @@
    <moduleSets>
       <moduleSet>
          <includeSubModules>false</includeSubModules>
-         <excludes>
-            <exclude>org.infinispan:infinispan-tools</exclude>
-         </excludes>
+         <includes>
+            <include>org.infinispan:infinispan-core</include>
+         </includes>
+         <sources>
+            <includeModuleDirectory>false</includeModuleDirectory>
+
+            <fileSets>
+
+               <!-- resources -->
+               <fileSet>
+                  <directory>src/main/resources</directory>
+                  <outputDirectory>etc</outputDirectory>
+                  <excludes>
+                     <exclude>**/*.sh</exclude>
+                     <exclude>**/*.bat</exclude>
+                     <exclude>**/*.cmd</exclude>
+                     <exclude>**/*.py</exclude>
+                  </excludes>
+               </fileSet>
+
+               <!-- Executable resources -->
+               <fileSet>
+                  <directory>src/main/resources</directory>
+                  <outputDirectory>bin</outputDirectory>
+                  <includes>
+                     <include>**/*.sh</include>
+                     <include>**/*.bat</include>
+                     <include>**/*.cmd</include>
+                     <include>**/*.py</include>
+                  </includes>
+                  <fileMode>0777</fileMode>
+               </fileSet>
+
+               <!-- Log4j XML -->
+               <fileSet>
+                  <directory>src/test/resources</directory>
+                  <outputDirectory>etc</outputDirectory>
+                  <includes>
+                     <include>log4j.xml</include>
+                  </includes>
+               </fileSet>
+
+               <!-- EULAs and license files -->
+               <fileSet>
+                  <directory>src/main/release</directory>
+                  <outputDirectory></outputDirectory>
+                  <includes>
+                     <include>**/*.txt</include>
+                  </includes>
+               </fileSet>
+
+               <fileSet>
+                  <directory>target/docbook</directory>
+                  <outputDirectory>doc/</outputDirectory>
+               </fileSet>
+            </fileSets>
+
+         </sources>
+
+         <binaries>
+
+            <outputDirectory>modules/${module.basedir.name}</outputDirectory>
+            <unpack>false</unpack>
+            <outputFileNameMapping>
+               ${module.artifactId}.${module.extension}
+            </outputFileNameMapping>
+            <dependencySets>
+               <dependencySet>
+                  <useTransitiveDependencies>false</useTransitiveDependencies>
+                  <outputDirectory>modules/${module.basedir.name}/lib</outputDirectory>
+               </dependencySet>
+            </dependencySets>
+
+         </binaries>
+      </moduleSet>
+
+      <moduleSet>
+         <includeSubModules>false</includeSubModules>
+         <includes>
+            <include>org.infinispan:infinispan-cachestore-bdbje</include>
+            <include>org.infinispan:infinispan-cachestore-jdbc</include>
+            <include>org.infinispan:infinispan-cachestore-jdbm</include>
+            <include>org.infinispan:infinispan-cachestore-s3</include>
+            <include>org.infinispan:infinispan-gui-demo</include>
+            <include>org.infinispan:infinispan-jopr-plugin</include>
+            <include>org.infinispan:infinispan-tree</include>
+         </includes>
          <sources>
             <includeModuleDirectory>false</includeModuleDirectory>
 
@@ -99,7 +183,8 @@
                   <excludes>
                      <exclude>infinispan-core*</exclude>
                   </excludes>
-                  <useTransitiveDependencies>false</useTransitiveDependencies>
+                  <useTransitiveDependencies>true</useTransitiveDependencies>
+                  <useTransitiveFiltering>true</useTransitiveFiltering>
                   <outputDirectory>modules/${module.basedir.name}/lib</outputDirectory>
                </dependencySet>
             </dependencySets>",2009-07-23T15:01:14Z,182
"@@ -48,6 +48,9 @@
 import org.infinispan.factories.annotations.NonVolatile;
 import org.infinispan.interceptors.InterceptorChain;
 import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.jmx.annotations.MBean;
+import org.infinispan.jmx.annotations.ManagedAttribute;
+import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.manager.CacheManager;
 import org.infinispan.marshall.MarshalledValue;
@@ -79,7 +82,9 @@
  * @since 4.0
  */
 @NonVolatile
+@MBean(objectName = CacheDelegate.OBJECT_NAME, description = ""Component that acts as a manager, factory and container for caches in the system."")
 public class CacheDelegate<K, V> implements AdvancedCache<K, V> {
+   public static final String OBJECT_NAME = ""Cache"";
    protected InvocationContextContainer icc;
    protected CommandsFactory commandsFactory;
    protected InterceptorChain invoker;
@@ -245,12 +250,14 @@ public void lock(Collection<? extends K> keys) {
       invoker.invoke(getInvocationContext(), command);
    }
 
+   @ManagedOperation(description = ""Starts the cache."")
    public void start() {
       componentRegistry.start();
       defaultLifespan = config.getExpirationLifespan();
       defaultMaxIdleTime = config.getExpirationMaxIdle();
    }
 
+   @ManagedOperation(description = ""Stops the cache."")
    public void stop() {
       componentRegistry.stop();
    }
@@ -485,6 +492,7 @@ public final V get(Object key, Flag... flags) {
       return (V) invoker.invoke(ctx, command);
    }
 
+   @ManagedAttribute(description = ""Returns the cache status"")
    public ComponentStatus getStatus() {
       return componentRegistry.getStatus();
    }",2009-10-06T07:17:20Z,183
"@@ -0,0 +1,89 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2009, Red Hat, Inc. and/or its affiliates, and
+ * individual contributors as indicated by the @author tags. See the
+ * copyright.txt file in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.jmx;
+
+import java.util.Set;
+
+import javax.management.MBeanServer;
+
+import org.infinispan.CacheException;
+import org.infinispan.config.GlobalConfiguration;
+import org.infinispan.factories.AbstractComponentRegistry;
+import org.infinispan.util.Util;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+/**
+ * Parent class for top level JMX component registration.
+ * 
+ * @author Galder Zamarreño
+ * @since 4.0
+ */
+public abstract class AbstractJmxRegistration {
+   private static final Log log = LogFactory.getLog(AbstractJmxRegistration.class);
+   String jmxDomain;
+   MBeanServer mBeanServer;
+   GlobalConfiguration globalConfig;
+   
+   protected abstract ComponentsJmxRegistration buildRegistrator(Set<AbstractComponentRegistry.Component> components);
+   
+   protected void registerMBeans(Set<AbstractComponentRegistry.Component> components, GlobalConfiguration globalConfig) {
+      mBeanServer = getMBeanServer(globalConfig);
+      ComponentsJmxRegistration registrator = buildRegistrator(components);
+      registrator.registerMBeans();
+   }
+   
+   protected void unregisterMBeans(Set<AbstractComponentRegistry.Component> components) {
+      ComponentsJmxRegistration registrator = buildRegistrator(components);
+      registrator.unregisterMBeans();
+   }
+   
+   protected MBeanServer getMBeanServer(GlobalConfiguration configuration) {
+      String serverLookup = configuration.getMBeanServerLookup();
+      try {
+         MBeanServerLookup lookup = (MBeanServerLookup) Util.getInstance(serverLookup);
+         return lookup.getMBeanServer();
+      } catch (Exception e) {
+         log.error(""Could not instantiate MBeanServerLookup('"" + serverLookup + ""')"", e);
+         throw new CacheException(e);
+      }
+   }
+   
+   protected String getJmxDomain(String jmxDomain, MBeanServer mBeanServer) {
+      String[] registeredDomains = mBeanServer.getDomains();
+      int index = 2;
+      String finalName = jmxDomain;
+      boolean done = false;
+      while (!done) {
+         done = true;
+         for (String domain : registeredDomains) {
+            if (domain.equals(finalName)) {
+               finalName = jmxDomain + index++;
+               done = false;
+               break;
+            }
+         }
+      }
+      return finalName;
+   }
+}",2009-10-06T07:17:20Z,184
"@@ -22,52 +22,64 @@
 package org.infinispan.jmx;
 
 import org.infinispan.AdvancedCache;
+import org.infinispan.Cache;
+import org.infinispan.CacheDelegate;
 import org.infinispan.CacheException;
 import org.infinispan.config.Configuration;
 import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.factories.AbstractComponentRegistry;
 import org.infinispan.factories.GlobalComponentRegistry;
+import org.infinispan.factories.AbstractComponentRegistry.Component;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.NonVolatile;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.factories.annotations.Stop;
-import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import javax.management.InstanceNotFoundException;
+import javax.management.MBeanRegistrationException;
 import javax.management.MBeanServer;
+import javax.management.MalformedObjectNameException;
+import javax.management.ObjectName;
+
+import java.util.HashSet;
 import java.util.Set;
 
 /**
  * If {@link Configuration#isExposeJmxStatistics()} is true, then class will register all the MBeans from cache local's
  * ConfigurationRegistry to the MBean server.
  *
  * @author Mircea.Markus@jboss.com
+ * @author Galder Zamarreño
  * @see java.lang.management.ManagementFactory#getPlatformMBeanServer()
  * @since 4.0
  */
 @NonVolatile
-public class CacheJmxRegistration {
+public class CacheJmxRegistration extends AbstractJmxRegistration {
    private static final Log log = LogFactory.getLog(CacheJmxRegistration.class);
 
    private AdvancedCache cache;
+   private Set<Component> nonCacheComponents;
 
    @Inject
-   public void initialize(AdvancedCache cache) {
+   public void initialize(AdvancedCache cache, GlobalConfiguration globalConfig) {
       this.cache = cache;
+      this.globalConfig = globalConfig;
    }
 
    /**
     * Here is where the registration is being performed.
     */
    @Start(priority = 14)
-   public void registerToMBeanServer() {
+   public void start() {
       if (cache == null)
          throw new IllegalStateException(""The cache should had been injected before a call to this method"");
       Configuration config = cache.getConfiguration();
       if (config.isExposeJmxStatistics()) {
-         ComponentsJmxRegistration registrator = buildRegistrator();
-         registrator.registerMBeans();
+         Set<Component> components = cache.getComponentRegistry().getRegisteredComponents();
+         nonCacheComponents = getNonCacheComponents(components);
+         registerMBeans(components, cache.getConfiguration().getGlobalConfiguration());
          log.info(""MBeans were successfully registered to the platform mbean server."");
       }
    }
@@ -76,76 +88,89 @@ public void registerToMBeanServer() {
     * Unregister when the cache is being stoped.
     */
    @Stop
-   public void unregisterMBeans() {
-      //this method might get called several times.
+   public void stop() {
+      // This method might get called several times.
       // After the first call the cache will become null, so we guard this
       if (cache == null) return;
       Configuration config = cache.getConfiguration();
       if (config.isExposeJmxStatistics()) {
-         ComponentsJmxRegistration componentsJmxRegistration = buildRegistrator();
-         componentsJmxRegistration.unregisterMBeans();
+         // Only unregister the non cache MBean so that it can be restarted
+         unregisterMBeans(nonCacheComponents);
          log.trace(""MBeans were successfully unregistered from the mbean server."");
       }
       cache = null;
    }
+   
+   public void unregisterCacheMBean() {
+      String pattern = jmxDomain + "":"" + ComponentsJmxRegistration.JMX_RESOURCE_KEY + ""="" + CacheDelegate.OBJECT_NAME + "",*"";
+      try {
+         Set<ObjectName> names = mBeanServer.queryNames(new ObjectName(pattern), null);
+         for (ObjectName name : names) {
+            mBeanServer.unregisterMBean(name);
+         }
+      } catch (MBeanRegistrationException e) {
+         String message = ""Unable to unregister Cache MBeans with pattern "" + pattern;
+         log.warn(message, e);
+      } catch (InstanceNotFoundException e) {
+         // Ignore if Cache MBeans not present
+      } catch (MalformedObjectNameException e) {
+         String message = ""Malformed pattern "" + pattern;
+         log.error(message, e);
+         throw new CacheException(message, e);
+      }
+   }
+
 
-   private ComponentsJmxRegistration buildRegistrator() {
-      Set<AbstractComponentRegistry.Component> components = cache.getComponentRegistry().getRegisteredComponents();
-      GlobalConfiguration configuration = cache.getConfiguration().getGlobalConfiguration();
-      MBeanServer beanServer = getMBeanServer(configuration);
-      ComponentsJmxRegistration registrator = new ComponentsJmxRegistration(beanServer, components, getGroupName());
-      updateDomain(registrator, cache.getAdvancedCache().getComponentRegistry().getGlobalComponentRegistry(), beanServer);
+   @Override
+   protected ComponentsJmxRegistration buildRegistrator(Set<AbstractComponentRegistry.Component> components) {
+      ComponentsJmxRegistration registrator = new ComponentsJmxRegistration(mBeanServer, components, getGroupName());
+      updateDomain(registrator, cache.getComponentRegistry().getGlobalComponentRegistry(), mBeanServer);
       return registrator;
    }
-
-   static void updateDomain(ComponentsJmxRegistration registrator, GlobalComponentRegistry componentRegistry, MBeanServer mBeanServer) {
+   
+   protected void updateDomain(ComponentsJmxRegistration registrator, GlobalComponentRegistry componentRegistry, MBeanServer mBeanServer) {
       GlobalConfiguration gc = componentRegistry.getComponent(GlobalConfiguration.class);
-      String componentName = CacheJmxRegistration.class.getName() + ""_jmxDomain"";
-      String jmxDomain = componentRegistry.getComponent(String.class, componentName);
-      if (jmxDomain == null) {
-         jmxDomain = getJmxDomain(gc.getJmxDomain(), mBeanServer);
-         if (!jmxDomain.equals(gc.getJmxDomain()) && !gc.isAllowDuplicateDomains()) {
-            String message = ""There's already an cache manager instance registered under '"" + gc.getJmxDomain() +
-                  ""' JMX domain. If you want to allow multiple instances configured with same JMX domain enable "" +
-                  ""'allowDuplicateDomains' attribute in 'globalJmxStatistics' config element"";
-            if (log.isErrorEnabled()) log.error(message);
-            throw new JmxDomainConflictException(message);
+      CacheManagerJmxRegistration managerJmxReg = componentRegistry.getComponent(CacheManagerJmxRegistration.class);
+      if (!gc.isExposeGlobalJmxStatistics() && jmxDomain == null) {
+         String tmpJmxDomain = getJmxDomain(gc.getJmxDomain(), mBeanServer);
+         synchronized (managerJmxReg) {
+            if (managerJmxReg.jmxDomain == null) {
+               if (!tmpJmxDomain.equals(gc.getJmxDomain()) && !gc.isAllowDuplicateDomains()) {
+                  String message = ""There's already an cache manager instance registered under '"" + gc.getJmxDomain() +
+                        ""' JMX domain. If you want to allow multiple instances configured with same JMX domain enable "" +
+                        ""'allowDuplicateDomains' attribute in 'globalJmxStatistics' config element"";
+                  if (log.isErrorEnabled()) log.error(message);
+                  throw new JmxDomainConflictException(message);
+               }
+               // Set manager component's jmx domain so that other caches under same manager 
+               // can see it, particularly important when jmx is only enabled at the cache level
+               managerJmxReg.jmxDomain = tmpJmxDomain;
+            }
+            // So that all caches share the same domain, regardless of whether dups are 
+            // allowed or not, simply assign the manager's calculated jmxDomain
+            jmxDomain = managerJmxReg.jmxDomain;
          }
-         componentRegistry.registerComponent(jmxDomain, componentName);
+      } else {
+         // If global stats were enabled, manager's jmxDomain would have been populated 
+         // when cache manager was started, so no need for synchronization here.
+         jmxDomain = managerJmxReg.jmxDomain == null ? gc.getJmxDomain() : managerJmxReg.jmxDomain;
       }
       registrator.setJmxDomain(jmxDomain);
    }
 
-   private static String getJmxDomain(String jmxDomain, MBeanServer mBeanServer) {
-      String[] registeredDomains = mBeanServer.getDomains();
-      int index = 2;
-      String finalName = jmxDomain;
-      boolean done = false;
-      while (!done) {
-         done = true;
-         for (String domain : registeredDomains) {
-            if (domain.equals(finalName)) {
-               finalName = jmxDomain + index++;
-               done = false;
-               break;
-            }
+   protected Set<Component> getNonCacheComponents(Set<Component> components) {
+      Set<Component> componentsExceptCache = new HashSet<AbstractComponentRegistry.Component>();
+      for (AbstractComponentRegistry.Component component : components) {
+         String name = component.getName();
+         if (!name.equals(Cache.class.getName()) && !name.equals(AdvancedCache.class.getName())) {
+            componentsExceptCache.add(component);
          }
       }
-      return finalName;
-   }
-
-   static MBeanServer getMBeanServer(GlobalConfiguration configuration) {
-      String serverLookup = configuration.getMBeanServerLookup();
-      try {
-         MBeanServerLookup lookup = (MBeanServerLookup) Util.getInstance(serverLookup);
-         return lookup.getMBeanServer();
-      } catch (Exception e) {
-         log.error(""Could not instantiate MBeanServerLookup('"" + serverLookup + ""')"", e);
-         throw new CacheException(e);
-      }
+      return componentsExceptCache;
    }
 
    private String getGroupName() {
       return cache.getName() + ""("" + cache.getConfiguration().getCacheModeString().toLowerCase() + "")"";
    }
+
 }",2009-10-06T07:17:20Z,185
"@@ -5,67 +5,74 @@
 import org.infinispan.factories.GlobalComponentRegistry;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.NonVolatile;
-import org.infinispan.factories.annotations.Start;
-import org.infinispan.factories.annotations.Stop;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
 
 import javax.management.MBeanServer;
+
 import java.util.Set;
 
 /**
  * Registers all the components from global component registry to the mbean server.
  *
  * @author Mircea.Markus@jboss.com
+ * @author Galder Zamarreño
  * @since 4.0
  */
 @NonVolatile
-public class CacheManagerJmxRegistration {
-
+public class CacheManagerJmxRegistration extends AbstractJmxRegistration {
+   private static final Log log = LogFactory.getLog(CacheManagerJmxRegistration.class);
    public static final String GLOBAL_JMX_GROUP = ""[global]"";
-   private GlobalComponentRegistry registry;
-   private GlobalConfiguration globalConfiguration;
-   private MBeanServer mBeanServer;
+   private GlobalComponentRegistry globalReg;
 
    @Inject
    public void init(GlobalComponentRegistry registry, GlobalConfiguration configuration) {
-      this.registry = registry;
-      this.globalConfiguration = configuration;
+      this.globalReg = registry;
+      this.globalConfig = configuration;
    }
 
    /**
     * On start, the mbeans are registered.
     */
-   @Start(priority = 20)
    public void start() {
-      if (globalConfiguration.isExposeGlobalJmxStatistics()) {
-         ComponentsJmxRegistration registrator = buildRegistrator();
-         registrator.registerMBeans();
+      if (globalConfig.isExposeGlobalJmxStatistics()) {
+         registerMBeans(globalReg.getRegisteredComponents(), globalConfig);
       }
    }
 
-   public void setMBeanServer(MBeanServer mBeanServer) {
-      this.mBeanServer = mBeanServer;
-   }
-
    /**
     * On stop, the mbeans are unregistered.
     */
-   @Stop
    public void stop() {
-      //this method might get called several times.
+      // This method might get called several times.
       // After the first call the cache will become null, so we guard this
-      if (registry == null) return;
-      if (globalConfiguration.isExposeGlobalJmxStatistics()) {
-         ComponentsJmxRegistration componentsJmxRegistration = buildRegistrator();
-         componentsJmxRegistration.unregisterMBeans();
+      if (globalReg == null) return;
+      if (globalConfig.isExposeGlobalJmxStatistics()) {
+         unregisterMBeans(globalReg.getRegisteredComponents());
       }
-      registry = null;
+      globalReg = null;
    }
 
-   private ComponentsJmxRegistration buildRegistrator() {
-      Set<AbstractComponentRegistry.Component> components = registry.getRegisteredComponents();
-      mBeanServer = CacheJmxRegistration.getMBeanServer(globalConfiguration);
+   @Override
+   protected ComponentsJmxRegistration buildRegistrator(Set<AbstractComponentRegistry.Component> components) {
       ComponentsJmxRegistration registrator = new ComponentsJmxRegistration(mBeanServer, components, GLOBAL_JMX_GROUP);
-      CacheJmxRegistration.updateDomain(registrator, registry, mBeanServer);
+      updateDomain(registrator, globalReg, mBeanServer);
       return registrator;
    }
+
+   protected void updateDomain(ComponentsJmxRegistration registrator, GlobalComponentRegistry componentRegistry, MBeanServer mBeanServer) {
+      if (jmxDomain == null) {
+         jmxDomain = getJmxDomain(globalConfig.getJmxDomain(), mBeanServer);
+         String configJmxDomain = globalConfig.getJmxDomain();
+         if (!jmxDomain.equals(configJmxDomain) && !globalConfig.isAllowDuplicateDomains()) {
+            String message = ""There's already an cache manager instance registered under '"" + configJmxDomain +
+                  ""' JMX domain. If you want to allow multiple instances configured with same JMX domain enable "" +
+                  ""'allowDuplicateDomains' attribute in 'globalJmxStatistics' config element"";
+            if (log.isErrorEnabled()) log.error(message);
+            throw new JmxDomainConflictException(message);
+         }
+      }
+      registrator.setJmxDomain(jmxDomain);
+   }
+
 }",2009-10-06T07:17:20Z,186
"@@ -80,12 +80,14 @@ public void setJmxDomain(String jmxDomain) {
    public void registerMBeans() throws CacheException {
       try {
          List<ResourceDMBean> resourceDMBeans = getResourceDMBeansFromComponents();
+         boolean trace = log.isTraceEnabled();
          for (ResourceDMBean resource : resourceDMBeans) {
             String resourceName = resource.getObjectName();
             ObjectName objectName = new ObjectName(getObjectName(resourceName));
             if (!mBeanServer.isRegistered(objectName)) {
                try {
                   mBeanServer.registerMBean(resource, objectName);
+                  if (trace) log.trace(""Registered "" + resource + "" under "" + objectName);
                } catch (InstanceAlreadyExistsException e) {
                   //this might happen if multiple instances are trying to concurrently register same objectName
                   log.info(""Could not register object with name:"" + objectName + ""("" + e.getMessage() + "")"");
@@ -108,11 +110,13 @@ public void unregisterMBeans() throws CacheException {
       log.trace(""Unregistering jmx resources.."");
       try {
          List<ResourceDMBean> resourceDMBeans = getResourceDMBeansFromComponents();
+         boolean trace = log.isTraceEnabled();
          for (ResourceDMBean resource : resourceDMBeans) {
             String resourceName = resource.getObjectName();
             ObjectName objectName = new ObjectName(getObjectName(resourceName));
             if (mBeanServer.isRegistered(objectName)) {
                mBeanServer.unregisterMBean(objectName);
+               if (trace) log.trace(""Unregistered "" + objectName);
             }
          }
       }",2009-10-06T07:17:20Z,187
"@@ -34,8 +34,11 @@
 import org.infinispan.factories.annotations.NonVolatile;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
+import org.infinispan.jmx.CacheJmxRegistration;
+import org.infinispan.jmx.CacheManagerJmxRegistration;
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.jmx.annotations.ManagedAttribute;
+import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.lifecycle.Lifecycle;
 import org.infinispan.notifications.cachemanagerlistener.CacheManagerNotifier;
@@ -93,9 +96,10 @@
  */
 @Scope(Scopes.GLOBAL)
 @NonVolatile
-@MBean(objectName = ""CacheManager"", description = ""Component that acts as a manager, factory and container for caches in the system."")
+@MBean(objectName = DefaultCacheManager.OBJECT_NAME, description = ""Component that acts as a manager, factory and container for caches in the system."")
 public class DefaultCacheManager implements CacheManager {
    public static final String DEFAULT_CACHE_NAME = ""org.infinispan.manager.DefaultCacheManager.DEFAULT_CACHE_NAME"";
+   public static final String OBJECT_NAME = ""CacheManager"";
    protected GlobalConfiguration globalConfiguration;
    private final ConcurrentMap<String, Cache> caches = new ConcurrentHashMap<String, Cache>();
    private final ConcurrentMap<String, Configuration> configurationOverrides = new ConcurrentHashMap<String, Configuration>();
@@ -313,6 +317,7 @@ private Configuration defineConfiguration(String cacheName, Configuration config
     *
     * @return the default cache.
     */
+   @ManagedOperation(description = ""Starts the default cache."")
    public <K, V> Cache<K, V> getCache() {
       return getCache(DEFAULT_CACHE_NAME);
    }
@@ -330,6 +335,7 @@ public <K, V> Cache<K, V> getCache() {
     * @return a cache instance identified by cacheName
     */
    @SuppressWarnings(""unchecked"")
+   @ManagedOperation(description = ""Starts a cache with the given name."")
    public <K, V> Cache<K, V> getCache(String cacheName) {
       if (cacheName == null)
          throw new NullPointerException(""Null arguments not allowed"");
@@ -381,7 +387,7 @@ private Cache createCache(String cacheName) {
    }
 
    public void start() {
-      // nothing to do
+      globalComponentRegistry.getComponent(CacheManagerJmxRegistration.class).start();
    }
 
    public void stop() {
@@ -391,14 +397,25 @@ public void stop() {
          if (entry.getKey().equals(DEFAULT_CACHE_NAME)) {
             defaultCache = entry.getValue();
          } else {
+            unregisterCacheMBean(entry.getValue());
             entry.getValue().stop();
          }
       }
 
-      if (defaultCache != null) defaultCache.stop();
+      if (defaultCache != null) {
+         unregisterCacheMBean(defaultCache);
+         defaultCache.stop();
+      }
+      globalComponentRegistry.getComponent(CacheManagerJmxRegistration.class).stop();
       globalComponentRegistry.stop();
    }
 
+   private void unregisterCacheMBean(Cache cache) {
+      if (cache.getConfiguration().isExposeJmxStatistics()) {
+         cache.getAdvancedCache().getComponentRegistry().getComponent(CacheJmxRegistration.class).unregisterCacheMBean();
+      }
+   }
+   
    public void addListener(Object listener) {
       CacheManagerNotifier notifier = globalComponentRegistry.getComponent(CacheManagerNotifier.class);
       notifier.addListener(listener);
@@ -447,11 +464,20 @@ public String getDefinedCacheCount() {
       return String.valueOf(this.configurationOverrides.keySet().size());
    }
 
-   @ManagedAttribute(description = ""The total number of running caches, including the default cache."")
+   @ManagedAttribute(description = ""The total number of created caches, including the default cache."")
    public String getCreatedCacheCount() {
       return String.valueOf(this.caches.keySet().size());
    }
 
+   @ManagedAttribute(description = ""The total number of running caches, including the default cache."")
+   public String getRunningCacheCount() {
+      int running = 0;
+      for (Cache cache : caches.values()) {
+         if (cache.getStatus() == ComponentStatus.RUNNING) running++;
+      }
+      return String.valueOf(running);
+   }
+
    @ManagedAttribute(description = ""Infinispan version"")
    public String getVersion() {
       return Version.printVersion();",2009-10-06T07:17:20Z,188
"@@ -0,0 +1,141 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2009, Red Hat, Inc. and/or its affiliates, and
+ * individual contributors as indicated by the @author tags. See the
+ * copyright.txt file in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.jmx;
+
+import java.lang.reflect.Method;
+
+import javax.management.InstanceNotFoundException;
+import javax.management.MBeanServer;
+import javax.management.ObjectName;
+
+import org.infinispan.CacheException;
+import org.infinispan.config.Configuration;
+import org.infinispan.config.GlobalConfiguration;
+import org.infinispan.lifecycle.ComponentStatus;
+import org.infinispan.manager.CacheManager;
+import org.infinispan.manager.DefaultCacheManager;
+import org.infinispan.test.SingleCacheManagerTest;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.testng.annotations.Test;
+
+@Test(groups = ""functional"", testName = ""jmx.CacheMBeanTest"")
+public class CacheMBeanTest extends SingleCacheManagerTest {
+   private static final Log log = LogFactory.getLog(CacheMBeanTest.class);
+   public static final String JMX_DOMAIN = CacheMBeanTest.class.getSimpleName();
+   private MBeanServer server;
+
+   @Override
+   protected CacheManager createCacheManager() throws Exception {
+      GlobalConfiguration globalConfiguration = GlobalConfiguration.getNonClusteredDefault();
+      globalConfiguration.setJmxDomain(JMX_DOMAIN);
+      globalConfiguration.setMBeanServerLookup(PerThreadMBeanServerLookup.class.getName());
+      globalConfiguration.setExposeGlobalJmxStatistics(true);
+      Configuration configuration = new Configuration();
+      configuration.setExposeJmxStatistics(true);
+      cacheManager = TestCacheManagerFactory.createCacheManager(globalConfiguration, configuration);
+      server = PerThreadMBeanServerLookup.getThreadMBeanServer();
+      return cacheManager;
+   }
+   
+   public void testStartStopManagedOperations() throws Exception {
+      ObjectName defaultOn = new ObjectName(JMX_DOMAIN + "":cache-name="" + DefaultCacheManager.DEFAULT_CACHE_NAME + ""(local),jmx-resource=Cache"");
+      ObjectName managerON = new ObjectName(JMX_DOMAIN + "":cache-name=[global],jmx-resource=CacheManager"");
+      server.invoke(managerON, ""getCache"", new Object[]{}, new String[]{});
+      assert ComponentStatus.RUNNING == server.getAttribute(defaultOn, ""Status"");
+      assert server.getAttribute(managerON, ""CreatedCacheCount"").equals(""1"");
+      assert server.getAttribute(managerON, ""RunningCacheCount"").equals(""1"");
+      server.invoke(defaultOn, ""stop"", new Object[]{}, new String[]{});
+      assert ComponentStatus.TERMINATED == server.getAttribute(defaultOn, ""Status"");
+      assert server.getAttribute(managerON, ""CreatedCacheCount"").equals(""1"");
+      assert server.getAttribute(managerON, ""RunningCacheCount"").equals(""0"");
+      server.invoke(defaultOn, ""start"", new Object[]{}, new String[]{});
+      assert ComponentStatus.RUNNING == server.getAttribute(defaultOn, ""Status"");
+      assert server.getAttribute(managerON, ""CreatedCacheCount"").equals(""1"");
+      assert server.getAttribute(managerON, ""RunningCacheCount"").equals(""1"");
+      server.invoke(defaultOn, ""stop"", new Object[]{}, new String[]{});
+      assert server.getAttribute(managerON, ""CreatedCacheCount"").equals(""1"");
+      assert server.getAttribute(managerON, ""RunningCacheCount"").equals(""0"");
+      assert ComponentStatus.TERMINATED == server.getAttribute(defaultOn, ""Status"");
+      server.invoke(defaultOn, ""start"", new Object[]{}, new String[]{});
+      assert server.getAttribute(managerON, ""CreatedCacheCount"").equals(""1"");
+      assert server.getAttribute(managerON, ""RunningCacheCount"").equals(""1"");
+      assert ComponentStatus.RUNNING == server.getAttribute(defaultOn, ""Status"");
+      server.invoke(defaultOn, ""stop"", new Object[]{}, new String[]{});
+      assert server.getAttribute(managerON, ""CreatedCacheCount"").equals(""1"");
+      assert server.getAttribute(managerON, ""RunningCacheCount"").equals(""0"");
+      assert ComponentStatus.TERMINATED == server.getAttribute(defaultOn, ""Status"");
+   }
+   
+   public void testManagerStopRemovesCacheMBean(Method method) throws Exception {
+      GlobalConfiguration globalConfiguration = GlobalConfiguration.getNonClusteredDefault();
+      final String otherJmxDomain = JMX_DOMAIN + '.' + method.getName();
+      globalConfiguration.setJmxDomain(otherJmxDomain);
+      globalConfiguration.setMBeanServerLookup(PerThreadMBeanServerLookup.class.getName());
+      globalConfiguration.setExposeGlobalJmxStatistics(true);
+      Configuration configuration = new Configuration();
+      configuration.setExposeJmxStatistics(true);
+      ObjectName defaultOn = new ObjectName(otherJmxDomain + "":cache-name="" + DefaultCacheManager.DEFAULT_CACHE_NAME + ""(local),jmx-resource=Cache"");
+      ObjectName galderOn = new ObjectName(otherJmxDomain + "":cache-name=galder(local),jmx-resource=Cache"");
+      ObjectName managerON = new ObjectName(otherJmxDomain + "":cache-name=[global],jmx-resource=CacheManager"");
+      CacheManager otherManager = TestCacheManagerFactory.createCacheManager(globalConfiguration, configuration);
+      server.invoke(managerON, ""getCache"", new Object[]{}, new String[]{});
+      server.invoke(managerON, ""getCache"", new Object[]{""galder""}, new String[]{String.class.getName()});
+      assert ComponentStatus.RUNNING == server.getAttribute(defaultOn, ""Status"");
+      assert ComponentStatus.RUNNING == server.getAttribute(galderOn, ""Status"");
+      otherManager.stop();
+      try {
+         log.info(server.getMBeanInfo(managerON));
+         assert false : ""Failure expected, "" + managerON + "" shouldn't be registered in mbean server"";
+      } catch (InstanceNotFoundException e) {
+      }
+      try {
+         log.info(server.getMBeanInfo(defaultOn));
+         assert false : ""Failure expected, "" + defaultOn + "" shouldn't be registered in mbean server"";
+      } catch (InstanceNotFoundException e) {
+      }
+      try {
+         log.info(server.getMBeanInfo(galderOn));
+         assert false : ""Failure expected, "" + galderOn + "" shouldn't be registered in mbean server"";
+      } catch (InstanceNotFoundException e) {
+      }
+   }
+
+
+   public void testDuplicateJmxDomainOnlyCacheExposesJmxStatistics() throws Exception {
+      GlobalConfiguration globalConfiguration = GlobalConfiguration.getNonClusteredDefault();
+      final String otherJmxDomain = JMX_DOMAIN;
+      globalConfiguration.setJmxDomain(otherJmxDomain);
+      globalConfiguration.setMBeanServerLookup(PerThreadMBeanServerLookup.class.getName());
+      Configuration configuration = new Configuration();
+      configuration.setExposeJmxStatistics(true);
+      CacheManager otherManager = TestCacheManagerFactory.createCacheManager(globalConfiguration, configuration);
+      try {
+         otherManager.getCache();
+         assert false : ""Failure expected, "" + otherJmxDomain + "" is a duplicate!"";
+      } catch (CacheException e) {
+         assert e.getCause().getCause() instanceof JmxDomainConflictException;
+      }
+   }
+}",2009-10-06T07:17:20Z,189
"@@ -1,12 +1,15 @@
 package org.infinispan.jmx;
 
+import java.lang.reflect.Method;
+
 import org.infinispan.config.Configuration;
 import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.manager.CacheManager;
 import org.infinispan.test.SingleCacheManagerTest;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
 import org.testng.annotations.Test;
 
+import javax.management.InstanceNotFoundException;
 import javax.management.MBeanException;
 import javax.management.MBeanServer;
 import javax.management.ObjectName;
@@ -32,34 +35,36 @@ protected CacheManager createCacheManager() throws Exception {
       globalConfiguration.setMBeanServerLookup(PerThreadMBeanServerLookup.class.getName());
       globalConfiguration.setExposeGlobalJmxStatistics(true);
       cacheManager = TestCacheManagerFactory.createCacheManager(globalConfiguration);
-      cacheManager.start();
-      cacheManager.getCache();
-      name = new ObjectName(""CacheManagerMBeanTest:cache-name=[global],jmx-resource=CacheManager"");
+      name = new ObjectName(JMX_DOMAIN + "":cache-name=[global],jmx-resource=CacheManager"");
       server = PerThreadMBeanServerLookup.getThreadMBeanServer();
+      server.invoke(name, ""getCache"", new Object[]{}, new String[]{});
       return cacheManager;
    }
 
    public void testJmxOperations() throws Exception {
       assert server.getAttribute(name, ""CreatedCacheCount"").equals(""1"");
       assert server.getAttribute(name, ""DefinedCacheCount"").equals(""0"") : ""Was "" + server.getAttribute(name, ""DefinedCacheCount"");
       assert server.getAttribute(name, ""DefinedCacheNames"").equals(""[]"");
+      assert server.getAttribute(name, ""RunningCacheCount"").equals(""1"");
 
       //now define some new caches
       cacheManager.defineConfiguration(""a"", new Configuration());
       cacheManager.defineConfiguration(""b"", new Configuration());
       cacheManager.defineConfiguration(""c"", new Configuration());
       assert server.getAttribute(name, ""CreatedCacheCount"").equals(""1"");
       assert server.getAttribute(name, ""DefinedCacheCount"").equals(""3"");
+      assert server.getAttribute(name, ""RunningCacheCount"").equals(""1"");
       String attribute = (String) server.getAttribute(name, ""DefinedCacheNames"");
       assert attribute.contains(""a("");
       assert attribute.contains(""b("");
       assert attribute.contains(""c("");
 
       //now start some caches
-      cacheManager.getCache(""a"");
-      cacheManager.getCache(""b"");
+      server.invoke(name, ""getCache"", new Object[]{""a""}, new String[]{String.class.getName()});
+      server.invoke(name, ""getCache"", new Object[]{""b""}, new String[]{String.class.getName()});
       assert server.getAttribute(name, ""CreatedCacheCount"").equals(""3"");
       assert server.getAttribute(name, ""DefinedCacheCount"").equals(""3"");
+      assert server.getAttribute(name, ""RunningCacheCount"").equals(""3"");
       attribute = (String) server.getAttribute(name, ""DefinedCacheNames"");
       assert attribute.contains(""a("");
       assert attribute.contains(""b("");
@@ -75,4 +80,25 @@ public void testInvokeJmxOperationNotExposed() throws Exception {
       }
       
    }
+   
+   public void testJmxRegistrationAtStartupAndStop(Method method) throws Exception {
+      GlobalConfiguration globalConfiguration = GlobalConfiguration.getNonClusteredDefault();
+      final String otherJmxDomain = JMX_DOMAIN + '.' + method.getName();
+      globalConfiguration.setJmxDomain(otherJmxDomain);
+      globalConfiguration.setMBeanServerLookup(PerThreadMBeanServerLookup.class.getName());
+      globalConfiguration.setExposeGlobalJmxStatistics(true);
+      CacheManager otherManager = TestCacheManagerFactory.createCacheManager(globalConfiguration);
+      ObjectName otherName = new ObjectName(otherJmxDomain + "":cache-name=[global],jmx-resource=CacheManager"");
+      try {
+         assert server.getAttribute(otherName, ""CreatedCacheCount"").equals(""0"");
+      } finally {
+         otherManager.stop();
+      }
+      
+      try {
+         server.getAttribute(otherName, ""CreatedCacheCount"").equals(""0"");
+         assert false : ""Failure expected, "" + otherName + "" shouldn't be registered in mbean server"";
+      } catch (InstanceNotFoundException e) {
+      }
+   }
 }",2009-10-06T07:17:20Z,190
"@@ -1,6 +1,5 @@
 package org.infinispan.jmx;
 
-import org.infinispan.CacheException;
 import org.infinispan.config.Configuration;
 import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.manager.CacheManager;
@@ -12,6 +11,8 @@
 import javax.management.MBeanServer;
 import javax.management.MalformedObjectNameException;
 import javax.management.ObjectName;
+
+import java.lang.reflect.Method;
 import java.util.Arrays;
 import java.util.HashSet;
 import java.util.Set;
@@ -25,6 +26,8 @@
 @Test(groups = ""functional"", testName = ""jmx.JmxStatsFunctionalTest"")
 public class JmxStatsFunctionalTest {
 
+   public static final String JMX_DOMAIN = JmxStatsFunctionalTest.class.getSimpleName();
+   private MBeanServer server;
    private CacheManager cm, cm2, cm3;
 
 
@@ -134,30 +137,39 @@ public void testOnlyPerCacheJmxStatsEnabled() {
       assert existsObject(""infinispan:cache-name=remote1(repl_sync),jmx-resource=Statistics"");
    }
 
-   public void testMultipleManagersOnSameServerFails() {
+   public void testMultipleManagersOnSameServerFails(Method method) throws Exception {
       assert !existsDomains(""infinispan"");
+      final String jmxDomain = JMX_DOMAIN + '.' + method.getName();
       GlobalConfiguration globalConfiguration = GlobalConfiguration.getClusteredDefault();
+      globalConfiguration.setJmxDomain(jmxDomain);
       globalConfiguration.setMBeanServerLookup(PerThreadMBeanServerLookup.class.getName());
       cm = TestCacheManagerFactory.createCacheManager(globalConfiguration);
       Configuration localCache = config();//local by default
       localCache.setExposeJmxStatistics(true);
       cm.defineConfiguration(""local_cache"", localCache);
       cm.getCache(""local_cache"");
-      assert existsObject(""infinispan:cache-name=local_cache(local),jmx-resource=Statistics"");
+      assert existsObject(jmxDomain + "":cache-name=local_cache(local),jmx-resource=Statistics"");
 
       GlobalConfiguration globalConfiguration2 = GlobalConfiguration.getClusteredDefault();
+      globalConfiguration2.setJmxDomain(jmxDomain);
       globalConfiguration2.setExposeGlobalJmxStatistics(true);
       globalConfiguration2.setAllowDuplicateDomains(false);
       globalConfiguration2.setMBeanServerLookup(PerThreadMBeanServerLookup.class.getName());
-      cm2 = TestCacheManagerFactory.createCacheManager(globalConfiguration2);
-      Configuration localCache2 = config();//local by default
-      localCache2.setExposeJmxStatistics(true);
-      cm2.defineConfiguration(""local_cache"", localCache);
       try {
-         cm2.getCache(""local_cache"");
-         assert false : ""exception expected"";
-      } catch (CacheException e) {
-         //expected
+         TestCacheManagerFactory.createCacheManager(globalConfiguration2);
+         assert false : ""Failure expected, '"" + jmxDomain + ""' duplicate!"";
+      } catch (JmxDomainConflictException e) {
+      }
+      
+      server = PerThreadMBeanServerLookup.getThreadMBeanServer();
+      globalConfiguration2.setAllowDuplicateDomains(true);
+      CacheManager duplicateAllowedManager = TestCacheManagerFactory.createCacheManager(globalConfiguration2);
+      try {
+         final String duplicateName = jmxDomain + ""2"";
+         ObjectName duplicateObjectName = new ObjectName(duplicateName + "":cache-name=[global],jmx-resource=CacheManager"");
+         server.getAttribute(duplicateObjectName, ""CreatedCacheCount"").equals(""0"");
+      } finally {
+         duplicateAllowedManager.stop();
       }
    }
    
@@ -176,15 +188,10 @@ public void testMultipleManagersOnSameServerWithCloneFails() {
       globalConfigurationClone.setExposeGlobalJmxStatistics(true);
       globalConfigurationClone.setAllowDuplicateDomains(false);
       globalConfigurationClone.setMBeanServerLookup(PerThreadMBeanServerLookup.class.getName());
-      cm2 = TestCacheManagerFactory.createCacheManager(globalConfigurationClone);
-      Configuration localCache2 = config();//local by default
-      localCache2.setExposeJmxStatistics(true);
-      cm2.defineConfiguration(""local_cache"", localCache);
       try {
-         cm2.getCache(""local_cache"");
-         assert false : ""exception expected"";
-      } catch (CacheException e) {
-         //expected
+         TestCacheManagerFactory.createCacheManager(globalConfigurationClone);
+         assert false : ""Failure expected, 'infinispan' duplicate!"";
+      } catch (JmxDomainConflictException e) {
       }
    }
 
@@ -251,6 +258,7 @@ public void testCorrectUnregistering() {
       cm.defineConfiguration(""local_cache"", localCache);
       cm.getCache(""local_cache"");
       assert existsObject(""infinispan:cache-name=local_cache(local),jmx-resource=Statistics"");
+      assert existsObject(""infinispan:cache-name=local_cache(local),jmx-resource=Cache"");
 
       //now register a global one
       GlobalConfiguration globalConfiguration2 = GlobalConfiguration.getClusteredDefault();
@@ -263,10 +271,12 @@ public void testCorrectUnregistering() {
       remoteCache.setCacheMode(Configuration.CacheMode.REPL_SYNC);
       cm2.defineConfiguration(""remote_cache"", remoteCache);
       cm2.getCache(""remote_cache"");
+      assert existsObject(""infinispan2:cache-name=remote_cache(repl_sync),jmx-resource=Cache"");
       assert existsObject(""infinispan2:cache-name=remote_cache(repl_sync),jmx-resource=Statistics"");
 
       cm2.stop();
       assert existsObject(""infinispan:cache-name=local_cache(local),jmx-resource=Statistics"");
+      assert !existsObject(""infinispan2:cache-name=remote_cache(repl_sync),jmx-resource=Cache"");
       assert !existsObject(""infinispan2:cache-name=remote_cache(repl_sync),jmx-resource=Statistics"");
 
       cm.stop();",2009-10-06T07:17:20Z,191
"@@ -17,8 +17,12 @@
 
 import java.io.IOException;
 import java.io.InputStream;
+import java.net.InetSocketAddress;
 import java.net.URL;
+import java.util.HashSet;
 import java.util.Properties;
+import java.util.Set;
+import java.util.StringTokenizer;
 
 /**
  * // TODO: Document this
@@ -30,10 +34,16 @@ public class RemoteCacheManager implements CacheContainer, Lifecycle {
 
    private static Log log = LogFactory.getLog(RemoteCacheManager.class);
 
+   public static final String HOTROD_CLIENT_PROPERTIES = ""hotrod-client.properties"";
+
+   public static final String CONF_HOTROD_SERVERS = ""hotrod-servers"";
+
+   public static final String OVERRIDE_HOTROD_SERVERS = ""infinispan.hotrod-client.servers-default"";
+
+
    private Properties props;
    private TransportFactory transportFactory;
    private String hotrodMarshaller;
-   private static final String HOTROD_CLIENT_PROPERTIES = ""hotrod-client.properties"";
    private boolean started = false;
 
 
@@ -139,7 +149,7 @@ public void start() {
          log.info(""'transport-factory' factory not specified, using "" + factory);
       }
       transportFactory = (TransportFactory) VHelper.newInstance(factory);
-      transportFactory.init(props);
+      transportFactory.start(props, getStaticConfiguredServers(props));
       hotrodMarshaller = props.getProperty(""marshaller"");
       if (hotrodMarshaller == null) {
          hotrodMarshaller = SerializationMarshaller.class.getName();
@@ -175,4 +185,36 @@ private <K, V> RemoteCache<K, V> createRemoteCache(String cacheName) {
       HotrodOperations hotrodOperations = new HotrodOperationsImpl(cacheName, transportFactory);
       return new RemoteCacheImpl<K, V>(hotrodOperations, marshaller, cacheName);
    }
+
+   private Set<InetSocketAddress> getStaticConfiguredServers(Properties props) {
+      Set<InetSocketAddress> serverAddresses = new HashSet<InetSocketAddress>();
+      String servers = props.getProperty(CONF_HOTROD_SERVERS);
+      if (servers == null) {
+         servers = System.getProperty(OVERRIDE_HOTROD_SERVERS);
+         if (servers != null) {
+            log.info(""Overwriting default server properties (-D"" + OVERRIDE_HOTROD_SERVERS + "") with "" + servers);
+         } else {
+            servers = ""127.0.0.1:11311"";
+         }
+         log.info(""'hotrod-servers' property not specified in config, using "" + servers);
+      }
+      StringTokenizer tokenizer = new StringTokenizer(servers, "";"");
+      while (tokenizer.hasMoreTokens()) {
+         String server = tokenizer.nextToken();
+         String[] serverDef = tokenizeServer(server);
+         String serverHost = serverDef[0];
+         int serverPort = Integer.parseInt(serverDef[1]);
+         serverAddresses.add(new InetSocketAddress(serverHost, serverPort));
+      }
+      if (serverAddresses.isEmpty()) {
+         throw new IllegalStateException(""No hot-rod servers specified!"");
+      }
+      return serverAddresses;
+   }
+
+   private String[] tokenizeServer(String server) {
+      StringTokenizer t = new StringTokenizer(server, "":"");
+      return new String[]{t.nextToken(), t.nextToken()};
+   }  
+
 }",2010-04-15T23:22:48Z,192
"@@ -1,6 +1,9 @@
 package org.infinispan.client.hotrod.impl;
 
+import java.net.InetSocketAddress;
+import java.util.Collection;
 import java.util.Properties;
+import java.util.Set;
 
 /**
  * // TODO: Document this
@@ -12,15 +15,13 @@ public interface TransportFactory {
 
    public static final String CONF_HOTROD_SERVERS = ""hotrod-servers"";
 
-   public static final String CONF_TCP_CONNECTION_POOL = ""tcp-connection-pool"";
-
-   public static final String OVERRIDE_HOTROD_SERVERS = ""infinispan.hotrod-client.servers-default"";
-
    public Transport getTransport();
 
    public void releaseTransport(Transport transport);
 
-   void init(Properties props);
+   void start(Properties props, Collection<InetSocketAddress> staticConfiguredServers);
+
+   void updateServers(Collection<InetSocketAddress> newServers);
 
    void destroy();
 }",2010-04-15T23:22:48Z,193
"@@ -1,54 +0,0 @@
-package org.infinispan.client.hotrod.impl.transport;
-
-import org.infinispan.client.hotrod.impl.TransportFactory;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
-
-import java.net.InetSocketAddress;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Properties;
-import java.util.Set;
-import java.util.StringTokenizer;
-
-/**
- * // TODO: Document this
- *
- * @author Mircea.Markus@jboss.com
- * @since 4.1
- */
-public abstract class AbstractTransportFactory implements TransportFactory {
-
-   private static Log log = LogFactory.getLog(AbstractTransportFactory.class);
-
-   protected Set<InetSocketAddress> serverAddresses = new HashSet<InetSocketAddress>();
-
-   public void init(Properties props) {
-      String servers = props.getProperty(CONF_HOTROD_SERVERS);
-      if (servers == null) {
-         servers = System.getProperty(OVERRIDE_HOTROD_SERVERS);
-         if (servers != null) {
-            log.info(""Overwriting default server properties (-D"" + OVERRIDE_HOTROD_SERVERS + "") with "" + servers);
-         } else {
-            servers = ""127.0.0.1:11311"";
-         }
-         log.info(""'hotrod-servers' property not specified in config, using "" + servers);
-      }
-      StringTokenizer tokenizer = new StringTokenizer(servers, "";"");
-      while (tokenizer.hasMoreTokens()) {
-         String server = tokenizer.nextToken();
-         String[] serverDef = tokenizeServer(server);
-         String serverHost = serverDef[0];
-         int serverPort = Integer.parseInt(serverDef[1]);
-         serverAddresses.add(new InetSocketAddress(serverHost, serverPort));
-      }
-      if (serverAddresses.isEmpty()) {
-         throw new IllegalStateException(""No hot-rod servers specified!"");
-      }
-   }
-
-   private String[] tokenizeServer(String server) {
-      StringTokenizer t = new StringTokenizer(server, "":"");
-      return new String[]{t.nextToken(), t.nextToken()};
-   }
-}",2010-04-15T23:22:48Z,194
"@@ -1,11 +1,12 @@
 package org.infinispan.client.hotrod.impl.transport.netty;
 
 import org.infinispan.client.hotrod.impl.Transport;
-import org.infinispan.client.hotrod.impl.transport.AbstractTransportFactory;
+import org.infinispan.client.hotrod.impl.TransportFactory;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 import java.net.InetSocketAddress;
+import java.util.Collection;
 import java.util.Properties;
 
 /**
@@ -14,16 +15,22 @@
  * @author Mircea.Markus@jboss.com
  * @since 4.1
  */
-public class NettyTransportFactory extends AbstractTransportFactory {
+public class NettyTransportFactory implements TransportFactory {
 
    private static Log log = LogFactory.getLog(NettyTransportFactory.class);
 
    private InetSocketAddress serverAddr;
+   private Collection<InetSocketAddress> serverAddresses;
 
    @Override
-   public void init(Properties props) {
-      super.init(props);
-      serverAddr = super.serverAddresses.iterator().next();
+   public void start(Properties props, Collection<InetSocketAddress> staticConfiguredServers) {
+      this.serverAddresses = staticConfiguredServers;
+      serverAddr = serverAddresses.iterator().next();
+   }
+
+   @Override
+   public void updateServers(Collection<InetSocketAddress> newServers) {
+      throw new IllegalStateException();
    }
 
    @Override
@@ -34,7 +41,7 @@ public Transport getTransport() {
 
    @Override
    public void destroy() {
-      // TODO: Customise this generated block
+      //nothing to do here as this no pooling is available
    }
 
    @Override",2010-04-15T23:22:48Z,195
"@@ -1,107 +0,0 @@
-package org.infinispan.client.hotrod.impl.transport.tcp;
-
-import org.apache.commons.pool.impl.GenericKeyedObjectPool;
-import org.apache.commons.pool.impl.GenericKeyedObjectPoolFactory;
-import org.apache.commons.pool.impl.GenericObjectPoolFactory;
-import org.infinispan.client.hotrod.impl.transport.TransportException;
-import org.infinispan.client.hotrod.impl.transport.VHelper;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
-
-import java.net.InetAddress;
-import java.net.InetSocketAddress;
-import java.net.Socket;
-import java.net.SocketAddress;
-import java.util.Collection;
-import java.util.Properties;
-
-/**
- * // TODO: Document this
- *
- * @author Mircea.Markus@jboss.com
- * @since 4.1
- *
- * todo - all methods but init and start can be called from multiple threads, add proper sync
- */
-public class DefaultTcpConnectionPool implements TcpConnectionPool {
-
-   private static Log log = LogFactory.getLog(DefaultTcpConnectionPool.class);
-
-   private GenericKeyedObjectPool connectionPool;
-   private PropsKeyedObjectPoolFactory poolFactory;
-   private RequestBalancingStrategy balancer;
-   private Collection<InetSocketAddress> servers;
-
-   @Override
-   public void init(Properties props) {
-      String balancerClass = props.getProperty(""requestBalancingStrategy"", RoundRobinBalancingStrategy.class.getName());
-      balancer = (RequestBalancingStrategy) VHelper.newInstance(balancerClass);
-      poolFactory = new PropsKeyedObjectPoolFactory(new TcpConnectionFactory(), props);
-   }
-
-   @Override
-   public void start(Collection<InetSocketAddress> servers) {
-      connectionPool = (GenericKeyedObjectPool) poolFactory.createPool();
-      balancer.setServers(servers);
-      this.servers = servers;
-   }
-
-   @Override
-   public Socket getConnection() {
-      InetSocketAddress server = balancer.nextServer();
-      try {
-         return (Socket) connectionPool.borrowObject(server);
-      } catch (Exception e) {
-         String message = ""Could not fetch connection"";
-         log.error(message, e);
-         throw new TransportException(message, e);
-      }
-   }
-
-   @Override
-   public void releaseConnection(Socket socket) {
-      SocketAddress remoteAddress = socket.getRemoteSocketAddress();
-      if (!servers.contains(remoteAddress)) throw new IllegalStateException(remoteAddress.toString());
-      try {
-         connectionPool.returnObject(remoteAddress, socket);
-      } catch (Exception e) {
-         log.warn(""Could not release connection"",e);
-      }
-   }
-
-   @Override
-   public void updateServers(Collection<InetSocketAddress> newServers) {
-      if (newServers.containsAll(servers) && servers.containsAll(newServers)) {
-         log.info(""Same list of servers, not changing the pool"");
-         return;
-      }
-      for (InetSocketAddress server : newServers) {
-         if (!servers.contains(server)) {
-            log.info(""New server added("" + server + ""), adding to the pool."");
-            try {
-               connectionPool.addObject(server);
-            } catch (Exception e) {
-               log.warn(""Failed adding server "" + server, e);
-            }
-         }
-      }
-      for (InetSocketAddress server : servers) {
-         if (!newServers.contains(server)) {
-            log.info(""Server not in cluster anymore("" + server + ""), removing from the pool."");
-            connectionPool.clear(server);
-         }
-      }
-      servers.clear();
-      servers.addAll(newServers);
-   }
-
-   @Override
-   public void destroy() {
-      connectionPool.clear();
-      try {
-         connectionPool.close();
-      } catch (Exception e) {
-         log.warn(""Exception while shutting down the connection pool."", e);
-      }
-   }
-}",2010-04-15T23:22:48Z,196
"@@ -1,15 +1,10 @@
 package org.infinispan.client.hotrod.impl.transport.tcp;
 
 import org.apache.commons.pool.BaseKeyedPoolableObjectFactory;
-import org.apache.commons.pool.BasePoolableObjectFactory;
-import org.apache.commons.pool.KeyedPoolableObjectFactory;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.io.IOException;
 import java.net.InetSocketAddress;
-import java.net.Socket;
-import java.nio.channels.SocketChannel;
 
 /**
  * // TODO: Document this
@@ -24,38 +19,26 @@ public class TcpConnectionFactory extends BaseKeyedPoolableObjectFactory {
    @Override
    public Object makeObject(Object key) throws Exception {
       InetSocketAddress serverAddress = (InetSocketAddress) key;
+      TcpTransport tcpTransport = new TcpTransport(serverAddress);
       if (log.isTraceEnabled()) {
-         log.trace(""Creating connection to server: "" + serverAddress);
-      }
-      try {
-         SocketChannel socketChannel = SocketChannel.open(serverAddress);
-         return socketChannel.socket();
-      } catch (IOException e) {
-         log.warn(""Could not create connection to "" + serverAddress, e);
-         throw e;
+         log.trace(""Created tcp transport: "" + tcpTransport);
       }
+      return tcpTransport;
    }
 
    @Override
    public boolean validateObject(Object key, Object obj) {
-      Socket socket = (Socket) obj;
+      TcpTransport transport = (TcpTransport) obj;
       if (log.isTraceEnabled()) {
-         log.trace(""About to validate(ping) connection to server "" + key + "". socket is "" + socket);
+         log.trace(""About to validate(ping) connection to server "" + key + "". TcpTransport is "" + transport);
       }
       //todo implement
       return true;
    }
 
    @Override
    public void destroyObject(Object key, Object obj) throws Exception {
-      Socket socket = (Socket) obj;
-      if (log.isTraceEnabled()) {
-         log.trace(""About to destroy socket "" + socket);
-      }
-      try {
-         socket.close();
-      } catch (IOException e) {
-         log.warn(""Issues closing the socket: "" + socket, e);
-      }
+      TcpTransport transport = (TcpTransport) obj;
+      transport.destroy();
    }
 }",2010-04-15T23:22:48Z,197
"@@ -1,28 +0,0 @@
-package org.infinispan.client.hotrod.impl.transport.tcp;
-
-import java.net.InetSocketAddress;
-import java.net.Socket;
-import java.util.Collection;
-import java.util.Properties;
-
-/**
- * // TODO: Document this
- *
- * @author Mircea.Markus@jboss.com
- * @since 4.1
- */
-public interface
-      TcpConnectionPool {
-
-   public void init(Properties props);
-
-   public void start(Collection<InetSocketAddress> servers);
-
-   public Socket getConnection();
-
-   public void releaseConnection(Socket socket);
-
-   public void updateServers(Collection<InetSocketAddress> newServers);
-
-   public void destroy();
-}",2010-04-15T23:22:48Z,198
"@@ -9,7 +9,6 @@
 import java.io.IOException;
 import java.net.InetSocketAddress;
 import java.net.Socket;
-import java.net.SocketAddress;
 import java.nio.channels.SocketChannel;
 
 /**
@@ -23,6 +22,7 @@ public class TcpTransport extends AbstractTransport {
    private static Log log = LogFactory.getLog(TcpTransport.class);
 
    private Socket socket;
+   private InetSocketAddress serverAddress;
 
    public void writeVInt(int vInt) {
       try {
@@ -68,8 +68,16 @@ public int readVInt() {
       }
    }
 
-   public TcpTransport(Socket socket) {
-      this.socket = socket;
+   public TcpTransport(InetSocketAddress serverAddress) {
+      this.serverAddress = serverAddress;
+      try {
+         SocketChannel socketChannel = SocketChannel.open(serverAddress);
+         socket = socketChannel.socket();
+      } catch (IOException e) {
+         String message = ""Could not connect to server: "" + serverAddress;
+         log.error(message, e);
+         throw new TransportException(message, e);
+      }
    }
 
    protected void writeBytes(byte[] toAppend) {
@@ -156,8 +164,47 @@ public byte[] readByteArray(final int size) {
       }
       return result;
    }
+   
+   public InetSocketAddress getServerAddress() {
+     return serverAddress;
+   }
+
+   @Override
+   public String toString() {
+      return ""TcpTransport{"" +
+            ""socket="" + socket +
+            "", serverAddress="" + serverAddress +
+            ""} "" + super.toString();
+   }
+
+   @Override
+   public boolean equals(Object o) {
+      if (this == o) return true;
+      if (o == null || getClass() != o.getClass()) return false;
+
+      TcpTransport that = (TcpTransport) o;
+
+      if (serverAddress != null ? !serverAddress.equals(that.serverAddress) : that.serverAddress != null) return false;
+      if (socket != null ? !socket.equals(that.socket) : that.socket != null) return false;
+
+      return true;
+   }
+
+   @Override
+   public int hashCode() {
+      int result = socket != null ? socket.hashCode() : 0;
+      result = 31 * result + (serverAddress != null ? serverAddress.hashCode() : 0);
+      return result;
+   }
 
-   public Socket getSocket() {
-      return socket;
+   public void destroy() {
+      try {
+         socket.close();
+         if (log.isTraceEnabled()) {
+            log.trace(""Successfully closed socket: "" + socket);
+         }
+      } catch (IOException e) {
+         log.warn(""Issues closing transport: "" + this, e);
+      }
    }
 }",2010-04-15T23:22:48Z,199
"@@ -1,56 +1,101 @@
 package org.infinispan.client.hotrod.impl.transport.tcp;
 
+import org.apache.commons.pool.impl.GenericKeyedObjectPool;
 import org.infinispan.client.hotrod.impl.Transport;
 import org.infinispan.client.hotrod.impl.TransportFactory;
-import org.infinispan.client.hotrod.impl.transport.AbstractTransportFactory;
+import org.infinispan.client.hotrod.impl.transport.TransportException;
 import org.infinispan.client.hotrod.impl.transport.VHelper;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 import java.net.InetSocketAddress;
+import java.util.Collection;
 import java.util.Properties;
-import java.util.StringTokenizer;
+import java.util.Set;
 
 /**
  * // TODO: Document this
  *
+ * todo - all methods but start and start can be called from multiple threads, add proper sync
+ *
  * @author Mircea.Markus@jboss.com
  * @since 4.1
  */
-public class TcpTransportFactory extends AbstractTransportFactory {
+public class TcpTransportFactory implements TransportFactory {
 
    private static Log log = LogFactory.getLog(TcpTransportFactory.class);
 
-   private TcpConnectionPool connectionPool;
+   private GenericKeyedObjectPool connectionPool;
+   private PropsKeyedObjectPoolFactory poolFactory;
+   private RequestBalancingStrategy balancer;
+   private Collection<InetSocketAddress> servers;
 
    @Override
-   public void init(Properties props) {
-      super.init(props);
-      String tcpConnectionPool = props.getProperty(CONF_TCP_CONNECTION_POOL);
-      if (tcpConnectionPool == null) {
-         tcpConnectionPool = DefaultTcpConnectionPool.class.getName();
-         log.trace(""No tcp connection pools specified, using the default: "" + tcpConnectionPool);
-      }
-      connectionPool = (TcpConnectionPool) VHelper.newInstance(tcpConnectionPool);
-      connectionPool.init(props);
-      connectionPool.start(serverAddresses);
+   public void start(Properties props, Collection<InetSocketAddress> staticConfiguredServers) {
+      servers = staticConfiguredServers;
+      String balancerClass = props.getProperty(""requestBalancingStrategy"", RoundRobinBalancingStrategy.class.getName());
+      balancer = (RequestBalancingStrategy) VHelper.newInstance(balancerClass);
+      poolFactory = new PropsKeyedObjectPoolFactory(new TcpConnectionFactory(), props);
+      connectionPool = (GenericKeyedObjectPool) poolFactory.createPool();
+      balancer.setServers(servers);
    }
 
    @Override
    public void destroy() {
-      if (connectionPool != null) {
-         connectionPool.destroy();
+      connectionPool.clear();
+      try {
+         connectionPool.close();
+      } catch (Exception e) {
+         log.warn(""Exception while shutting down the connection pool."", e);
       }
    }
 
    @Override
    public Transport getTransport() {
-      return new TcpTransport(connectionPool.getConnection());
+      InetSocketAddress server = balancer.nextServer();
+      try {
+         return (Transport) connectionPool.borrowObject(server);
+      } catch (Exception e) {
+         String message = ""Could not fetch transport"";
+         log.error(message, e);
+         throw new TransportException(message, e);
+      }
    }
 
    @Override
    public void releaseTransport(Transport transport) {
       TcpTransport tcpTransport = (TcpTransport) transport;
-      connectionPool.releaseConnection(tcpTransport.getSocket());
+      try {
+         connectionPool.returnObject(tcpTransport.getServerAddress(), tcpTransport);
+      } catch (Exception e) {
+         log.warn(""Could not release connection: "" + tcpTransport,e);
+      }
    }
+
+   @Override
+   public void updateServers(Collection<InetSocketAddress> newServers) {
+      if (newServers.containsAll(servers) && servers.containsAll(newServers)) {
+         log.info(""Same list of servers, not changing the pool"");
+         return;
+      }
+      for (InetSocketAddress server : newServers) {
+         if (!servers.contains(server)) {
+            log.info(""New server added("" + server + ""), adding to the pool."");
+            try {
+               connectionPool.addObject(server);
+            } catch (Exception e) {
+               log.warn(""Failed adding server "" + server, e);
+            }
+         }
+      }
+      for (InetSocketAddress server : servers) {
+         if (!newServers.contains(server)) {
+            log.info(""Server not in cluster anymore("" + server + ""), removing from the pool."");
+            connectionPool.clear(server);
+         }
+      }
+      servers.clear();
+      servers.addAll(newServers);
+   }
+
 }",2010-04-15T23:22:48Z,200
"@@ -1,3 +1,70 @@
 hotrod-servers=127.0.0.1:11311
 transport-factory=org.infinispan.client.hotrod.impl.transport.tcp.TcpTransportFactory
-force-return-value=false
\ No newline at end of file
+force-return-value=false
+
+
+##bellow is connection pooling config
+
+#controls the maximum number of connections per server that are allocated (checked out to client threads, or idle in the pool) at one time.
+#When non-positive, there is no limit to the number of connections per server. When maxActive is reached, the 
+#connection pool for that server is said to be exhausted.
+#The default setting for this parameter is 1.
+maxActive=1
+
+##sets a global limit on the number persistent connections that can be in circulation within the combined set of servers.
+#When non-positive, there is no limit to the total number of persistent connections in circulation.
+#When maxTotal is exceeded, all connections pools are exhausted. The default setting for this parameter is -1 (no limit).
+maxTotal = -1
+
+#controls the maximum number of persistent connections, per server, at any time. When negative, there is no limit to the
+#number of connections that may be idle per server. The default setting for this parameter is 4.
+maxIdle = 4
+
+#Specifies what happens when asking for a connection from a server pool, and that pool is exhausted. Possible values:
+# - 0 - an exception will be thrown to the calling user
+# - 1 - the caller will block (invoke waits until a new or idle connections is available.
+# - 2 - a new persistent connection will be created and and returned (essentially making maxActive meaningless.)
+#                        If a positive maxWait value is supplied, will block for at most that many milliseconds,
+#                         after which a an exception will be thrown. If maxWait is non-positive, call will block indefinitely.
+#The default whenExhaustedAction setting is 1.
+whenExhaustedAction = 1
+
+#When testOnBorrow is set, the pool will attempt to validate each connection before it is returned, by sending an TCP packet to the server.
+#Connections that fail to validate will be dropped from the pool, and a different connection will be taken. The default setting for this parameter is false.
+testOnBorrow = false
+
+#when testOnReturn is set, the pool will attempt to validate each connection before it is returned to the pool by sending an TCP packet to the server.
+#Connections that fail to validate will be dropped from the pool. The default setting for this parameter is false.
+testOnReturn = false
+
+##Optionally, one may configure the pool to examine and possibly evict connections as they sit idle in the pool and to
+#ensure that a minimum number of idle connections is maintained for each server. This is performed by an ""idle object eviction"" thread,
+#which runs asynchronously. Caution should be used when configuring this optional feature. Eviction runs require an
+#exclusive synchronization lock on the pool, so if they run too frequently and / or incur excessive latency when creating,
+#destroying or validating connection instances, performance issues may result. The idle connection eviction thread may be
+#configured using the following attributes:
+
+#timeBetweenEvictionRunsMillis indicates how long the eviction thread should sleep before ""runs"" of examining idle connections. When non-positive,
+#no eviction thread will be launched. The default setting for this parameter is -1 (i.e., by default, idle connections eviction is disabled).
+timeBetweenEvictionRunsMillis=-1
+
+#minEvictableIdleTimeMillis specifies the minimum amount of time that an connection may sit idle in the pool before it is
+#eligible for eviction due to idle time. When non-positive, no connection will be dropped from the pool due to idle time alone.
+#This setting has no effect unless timeBetweenEvictionRunsMillis > 0. The default setting for this parameter is 30 minutes.
+minEvictableIdleTimeMillis=1800000
+
+#testWhileIdle indicates whether or not idle connections should be validated by sending an TCP packet to the server, during idle connection eviction runs.
+# Connections that fail to validate will be dropped from the pool. This setting has no effect unless timeBetweenEvictionRunsMillis > 0.
+# The default setting for this parameter is false.
+testWhileIdle = false
+
+#minIdle sets a target value for the minimum number of idle connections (per server) that should always be available.
+#If this parameter is set to a positive number and timeBetweenEvictionRunsMillis > 0, each time the idle connection eviction thread runs,
+#it will try to create enough idle instances so that there will be minIdle idle instances available for each server.
+# The default setting for this parameter is 0.
+minIdle = 0
+
+#lifo determines whether or not the pools return idle connection in last-in-first-out order. False means that the pools
+#behave as FIFO queues - connections are taken from idle connections pools in the order that they are returned.
+#The default setting for this parameter is true.
+lifo = true",2010-04-15T23:22:48Z,201
"@@ -0,0 +1,17 @@
+package org.infinispan.client.hotrod;
+
+/**
+ * // TODO: Document this
+ *
+ * @author Mircea.Markus@jboss.com
+ * @since 4.1
+ */
+public class ClientConnectionPoolingTest {
+
+   /**
+    * What happens if a server goes down and after that, we try to create a connection to that server.
+    */
+   public void testServerGoesDown() {
+
+   }
+}",2010-04-15T23:22:48Z,202
"@@ -53,9 +53,8 @@ protected RemoteCacheManager getRemoteCacheManager() {
 
    @AfterClass(enabled = true)
    public void testDestroyRemoteCacheFactory() {
-      assert remoteCache.ping();
+      remoteCacheManager.stop();
       hotrodServer.stop();
-      assert !remoteCache.ping();
    }
 
    public void testPut() {",2010-04-15T23:22:48Z,203
"@@ -72,41 +72,10 @@ protected RemoteCacheManager getRemoteCacheManager() {
 
    @AfterClass 
    public void testDestroyRemoteCacheFactory() {
-      assert remoteCache.ping();
+      remoteCacheManager.stop();
+//      assert remoteCache.ping();
       hotrodServer.stop();
-      assert !remoteCache.ping();
-//      try {
-//         remoteCache.get(""aKey"");
-//         assert false;
-//      } catch (ClientDisconnectedException e) {}
-//      try {
-//         remoteCache.clear();
-//         assert false;
-//      } catch (ClientDisconnectedException e) {}
-//      try {
-//         remoteCache.put(""aKey"", ""aValue"");
-//         assert false;
-//      } catch (ClientDisconnectedException e) {}
-//      try {
-//         remoteCache.putIfAbsent(""aKey"", ""aValue"");
-//         assert false;
-//      } catch (ClientDisconnectedException e) {}
-//      try {
-//         remoteCache.remove(""aKey"", 0);
-//         assert false;
-//      } catch (ClientDisconnectedException e) {}
-//      try {
-//         remoteCache.remove(""aKey"");
-//         assert false;
-//      } catch (ClientDisconnectedException e) {}
-//      try {
-//         remoteCache.replace(""aKey"", ""aNewValue"");
-//         assert false;
-//      } catch (ClientDisconnectedException e) {}
-//      try {
-//         remoteCache.replace(""aKey"", ""aNewValue"");
-//         assert false;
-//      } catch (ClientDisconnectedException e) {}
+//      assert !remoteCache.ping();
    }
 
    public void testPut() {
@@ -125,7 +94,7 @@ public void testRemove() {
       assertCacheContains(cache, ""aKey"", ""aValue"");
 
       assert remoteCache.get(""aKey"").equals(""aValue"");
-      
+
       assert null == remoteCache.remove(""aKey"");
       assertCacheContains(cache, ""aKey"", null);
       assert !remoteCache.containsKey(""aKey"");
@@ -172,7 +141,7 @@ public void testReplace() {
 
    public void testReplaceIfUnmodified() {
       assert null == remoteCache.replace(""aKey"", ""aValue"");
-      
+
 
       remoteCache.put(""aKey"", ""aValue"");
       VersionedValue valueBinary = remoteCache.getVersioned(""aKey"");
@@ -222,10 +191,6 @@ public void testClear() {
       assert cache.isEmpty();
    }
 
-   public void testStats() {
-      //todo implement
-   }
-
    private void assertCacheContains(Cache cache, String key, String value) {
       SerializationMarshaller marshaller = new SerializationMarshaller();
       byte[] keyBytes = marshaller.marshallObject(key);
@@ -238,9 +203,4 @@ private void assertCacheContains(Cache cache, String key, String value) {
          assert Arrays.equals(valueBytes, cacheValue.data());
       }
    }
-
-   private Object get(Cache cache, String s) {
-
-      return new String((byte[])cache.get(s));
-   }
 }",2010-04-15T23:22:48Z,204
"@@ -41,8 +41,8 @@ protected void setup() throws Exception {
    @AfterMethod
    void tearDown() {
       TestingUtil.killCacheManagers(cacheManager);
-      hotrodServer.stop();
       rcm.stop();
+      hotrodServer.stop();
    }
 
    public void testAllStatsArePresent() {",2010-04-15T23:22:48Z,205
"@@ -1,6 +1,5 @@
 package org.infinispan.client.hotrod;
 
-import org.infinispan.client.hotrod.impl.transport.AbstractTransportFactory;
 import org.infinispan.manager.CacheManager;
 import org.infinispan.server.hotrod.HotRodServer;
 import org.infinispan.test.SingleCacheManagerTest;
@@ -28,18 +27,18 @@ public class RemoteCacheManagerTest extends SingleCacheManagerTest {
    protected CacheManager createCacheManager() throws Exception {
       cacheManager = TestCacheManagerFactory.createLocalCacheManager();
       hotrodServer = HotRodServerStarter.startHotRodServer(cacheManager);
-      prevValue = System.setProperty(AbstractTransportFactory.OVERRIDE_HOTROD_SERVERS, ""localhost:"" + hotrodServer.getPort());
+      prevValue = System.setProperty(RemoteCacheManager.OVERRIDE_HOTROD_SERVERS, ""localhost:"" + hotrodServer.getPort());
       return cacheManager;
    }
 
    @AfterTest(alwaysRun = true)
    public void release() {
-      if (hotrodServer != null) hotrodServer.stop();
       if (cacheManager != null) cacheManager.stop();
+      if (hotrodServer != null) hotrodServer.stop();
       if (prevValue != null) {
-         System.setProperty(AbstractTransportFactory.OVERRIDE_HOTROD_SERVERS, prevValue);
+         System.setProperty(RemoteCacheManager.OVERRIDE_HOTROD_SERVERS, prevValue);
       } else {
-         System.getProperties().remove(AbstractTransportFactory.OVERRIDE_HOTROD_SERVERS);
+         System.getProperties().remove(RemoteCacheManager.OVERRIDE_HOTROD_SERVERS);
       }
    }
 ",2010-04-15T23:22:48Z,206
"@@ -0,0 +1,49 @@
+package org.infinispan.client.hotrod;
+
+import org.infinispan.manager.CacheManager;
+import org.infinispan.server.hotrod.HotRodServer;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.Test;
+
+import java.util.Properties;
+
+import static junit.framework.Assert.assertEquals;
+
+/**
+ * // TODO: Document this
+ *
+ * @author Mircea.Markus@jboss.com
+ * @since 4.1
+ */
+@Test(testName = ""client.hotrod.ServerShutdownTest"", groups = ""functional"")
+public class ServerShutdownTest {
+
+   @Test(enabled = false)
+   public void testServerShutdownWithConnectedClient() {
+      CacheManager cacheManager = TestCacheManagerFactory.createLocalCacheManager();
+      HotRodServer hotrodServer = HotRodServerStarter.startHotRodServer(cacheManager);
+      RemoteCacheManager remoteCacheManager = new RemoteCacheManager(""localhost"", hotrodServer.getPort());
+      RemoteCache remoteCache = remoteCacheManager.getCache();
+
+      remoteCache.put(""k"",""v"");
+      assertEquals(""v"", remoteCache.get(""k""));
+
+      hotrodServer.stop();
+      cacheManager.stop();
+      remoteCacheManager.stop();
+   }
+
+   public void testServerShutdownWithoutConnectedClient() {
+      CacheManager cacheManager = TestCacheManagerFactory.createLocalCacheManager();
+      HotRodServer hotrodServer = HotRodServerStarter.startHotRodServer(cacheManager);
+      RemoteCacheManager remoteCacheManager = new RemoteCacheManager(""localhost"", hotrodServer.getPort());
+      RemoteCache remoteCache = remoteCacheManager.getCache();
+
+      remoteCache.put(""k"",""v"");
+      assertEquals(""v"", remoteCache.get(""k""));
+
+      remoteCacheManager.stop();
+      hotrodServer.stop();
+      cacheManager.stop();
+   }
+}",2010-04-15T23:22:48Z,207
"@@ -56,10 +56,6 @@
       <priority value=""TRACE""/>
    </category>
 
-   <category name=""org.infinispan"">
-      <priority value=""INFO""/>
-   </category>
-
    <category name=""com.mchange"">
       <priority value=""TRACE""/>
    </category>",2010-04-15T23:22:48Z,208
"@@ -32,7 +32,7 @@
 import static org.testng.AssertJUnit.assertEquals;
 
 @Test(groups = ""functional"", testName = ""util.ClusterIdGeneratorTest"")
-   public class ClusterIdGeneratorTest {
+public class ClusterIdGeneratorTest {
 
    public void testGenerateVersion() {
       ClusterIdGenerator vg = new ClusterIdGenerator(null, null);",2012-01-05T15:13:16Z,209
"@@ -0,0 +1,65 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.server.hotrod
+
+import logging.Log
+import org.infinispan.notifications.Listener
+import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged
+import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent
+import scala.collection.JavaConversions._
+import org.infinispan.Cache
+import org.infinispan.remoting.transport.Address
+
+/**
+ * Listener that detects crashed or stopped members and removes them from
+ * the address cache.
+ *
+ * @author Galder Zamarreño
+ * @since 5.1
+ */
+@Listener(sync = false) // Use a separate thread to avoid blocking the view handler thread
+class CrashedMemberDetectorListener(addressCache: Cache[Address, ServerAddress]) extends Log {
+
+   @ViewChanged
+   def handleViewChange(e: ViewChangedEvent) {
+      val cacheManager = e.getCacheManager
+      // Only the coordinator can potentially make modifications related to
+      // crashed members. This is to avoid all nodes trying to make the same
+      // modification which would be wasteful and lead to deadlocks.
+      if (cacheManager.isCoordinator)
+         detectCrashedMember(e)
+   }
+
+   private[hotrod] def detectCrashedMember(e: ViewChangedEvent) {
+      trace(""View change received on coordinator: %s"", e)
+      try {
+         val newMembers = collectionAsScalaIterable(e.getNewMembers)
+         val oldMembers = collectionAsScalaIterable(e.getOldMembers)
+         val goneMembers = oldMembers.filterNot(newMembers contains _)
+         goneMembers.foreach { addr =>
+            trace(""Remove %s from address cache"", addr)
+            addressCache.remove(addr)
+         }
+      } catch {
+         case t: Throwable => logErrorDetectingCrashedMember(t)
+      }
+   }
+
+}
\ No newline at end of file",2012-01-05T15:13:16Z,180
"@@ -110,7 +110,7 @@ class HotRodServer extends AbstractProtocolServer(""HotRod"") with Log {
       addressCache = cacheManager.getCache(ADDRESS_CACHE_NAME)
       clusterAddress = cacheManager.getAddress
       address = new ServerAddress(host, port)
-      cacheManager.addListener(new CrashedMemberDetectorListener)
+      cacheManager.addListener(new CrashedMemberDetectorListener(addressCache))
       // Map cluster address to server endpoint address
       debug(""Map %s cluster address with %s server endpoint in address cache"", clusterAddress, address)
       addressCache.put(clusterAddress, address)
@@ -153,35 +153,6 @@ class HotRodServer extends AbstractProtocolServer(""HotRod"") with Log {
 
    private[hotrod] def getAddressCache = addressCache
 
-   @Listener(sync = false) // Use a separate thread to avoid blocking the view handler thread
-   class CrashedMemberDetectorListener {
-
-      @ViewChanged
-      def handleViewChange(e: ViewChangedEvent) {
-         val cacheManager = e.getCacheManager
-         // Only the coordinator can potentially make modifications related to crashed members.
-         // This is to avoid all nodes trying to make the same modification which would be wasteful and lead to deadlocks.
-         if (cacheManager.isCoordinator) {
-            trace(""View change received on coordinator: %s"", e)
-            try {
-               val newMembers = asScalaIterator(e.getNewMembers.iterator())
-               val oldMembers = asScalaIterator(e.getOldMembers.iterator())
-               val goneMembers = oldMembers.filterNot(newMembers contains)
-               if (goneMembers.hasNext) {
-                  trace(""Somone left the cluster, oldMembers=%s newMembers=%s"", oldMembers, newMembers)
-                  goneMembers.foreach { addr =>
-                     trace(""Remove %s from address cache"", addr)
-                     addressCache.remove(addr)
-                  }
-               }
-            } catch {
-               case t: Throwable => logErrorDetectingCrashedMember(t)
-            }
-         }
-      }
-
-   }
-
 }
 
 object HotRodServer {",2012-01-05T15:13:16Z,158
"@@ -0,0 +1,70 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.server.hotrod
+
+import org.testng.annotations.Test
+import org.infinispan.test.fwk.TestCacheManagerFactory
+import org.infinispan.remoting.transport.Address
+import org.infinispan.notifications.cachemanagerlistener.event.EventImpl
+import org.infinispan.notifications.cachemanagerlistener.event.Event.Type
+import org.infinispan.distribution.TestAddress
+import java.util.ArrayList
+import org.testng.AssertJUnit._
+import org.infinispan.test.SingleCacheManagerTest
+
+/**
+ * Tests crashed or stopped member logic.
+ *
+ * @author Galder Zamarreño
+ * @since 5.1
+ */
+@Test(groups = Array(""functional""), testName = ""server.hotrod.CrashedMemberDetectorTest"")
+class CrashedMemberDetectorTest extends SingleCacheManagerTest {
+
+   protected def createCacheManager() =
+      TestCacheManagerFactory.createLocalCacheManager(false)
+
+   def testDetectCrashedMembers() {
+      val cache = cacheManager.getCache[Address, ServerAddress]()
+      cache.put(new TestAddress(1), new ServerAddress(""a"", 123))
+      cache.put(new TestAddress(2), new ServerAddress(""b"", 456))
+      cache.put(new TestAddress(3), new ServerAddress(""c"", 789))
+
+      val detector = new CrashedMemberDetectorListener(cache)
+
+      val oldMembers = new ArrayList[Address]()
+      oldMembers.add(new TestAddress(1))
+      oldMembers.add(new TestAddress(3))
+      oldMembers.add(new TestAddress(2))
+
+      val newMembers = new ArrayList[Address]()
+      newMembers.add(new TestAddress(1))
+      newMembers.add(new TestAddress(2))
+
+      val e = new EventImpl("""", cacheManager, Type.VIEW_CHANGED, newMembers,
+                            oldMembers, new TestAddress(1), 99)
+
+      detector.detectCrashedMember(e)
+
+      assertTrue(cache.containsKey(new TestAddress(1)))
+      assertTrue(cache.containsKey(new TestAddress(2)))
+   }
+
+}
\ No newline at end of file",2012-01-05T15:13:16Z,210
"@@ -1393,6 +1393,10 @@ public boolean isL1CacheEnabled() {
       return clustering.l1.enabled;
    }
 
+   public boolean isL1CacheActivated() {
+      return clustering.l1.activated && isL1CacheEnabled();
+   }
+
    public long getL1Lifespan() {
       return clustering.l1.lifespan;
    }
@@ -1412,6 +1416,17 @@ public boolean hasConsistentHashClass() {
       return clustering.hash.consistentHashClass != null;
    }
 
+   public boolean isCustomConsistentHashClass() {
+      return clustering.hash.consistentHashClass != null &&
+            !clustering.hash.consistentHashClass.equals(DefaultConsistentHash.class.getName()) &&
+            !clustering.hash.consistentHashClass.equals(TopologyAwareConsistentHash.class.getName());
+   }
+
+   public boolean isCustomHashFunctionClass() {
+      return clustering.hash.hashFunctionClass != null &&
+            !clustering.hash.hashFunctionClass.equals(MurmurHash3.class.getName());
+   }
+
    public String getHashFunctionClass() {
       return clustering.hash.hashFunctionClass;
    }
@@ -1709,7 +1724,11 @@ public boolean isTransactionalCache() {
    public boolean isExpirationReaperEnabled() {
        return expiration.reaperEnabled;
     }
- 
+
+   public boolean isHashActivated() {
+      return clustering.hash.activated;
+   }
+
    /**
     * Defines transactional (JTA) characteristics of the cache.
     *
@@ -3491,6 +3510,8 @@ public void willUnmarshall(Object parent) {
       
       @ConfigurationDocRef(bean = HashConfig.class, targetElement = ""groups"")
       protected GroupsConfiguration groups = new GroupsConfiguration();
+      @XmlTransient
+      public boolean activated = false;
 
       public void accept(ConfigurationBeanVisitor v) {
          groups.accept(v);
@@ -3508,6 +3529,7 @@ public String getConsistentHashClass() {
       @Deprecated
       public void setConsistentHashClass(String consistentHashClass) {
          testImmutability(""consistentHashClass"");
+         activated = true;
          this.consistentHashClass = consistentHashClass;
       }
 
@@ -3529,6 +3551,7 @@ public String getHashFunctionClass() {
       @Deprecated
       public void setHashFunctionClass(String hashFunctionClass) {
          testImmutability(""hashFunctionClass"");
+         activated = true;
          this.hashFunctionClass = hashFunctionClass;
       }
 
@@ -3559,6 +3582,7 @@ public HashConfig numVirtualNodes(Integer numVirtualNodes) {
       @Deprecated
       public void setNumVirtualNodes(Integer numVirtualNodes) {
          testImmutability(""numVirtualNodes"");
+         activated = true;
          this.numVirtualNodes = numVirtualNodes;
       }
 
@@ -3569,6 +3593,7 @@ public void setNumVirtualNodes(Integer numVirtualNodes) {
       @Deprecated
       public void setNumOwners(Integer numOwners) {
          testImmutability(""numOwners"");
+         activated = true;
          this.numOwners = numOwners;
       }
 
@@ -3590,6 +3615,7 @@ public Long getRehashWait() {
       @Deprecated
       public void setRehashWait(Long rehashWaitTime) {
          testImmutability(""rehashWait"");
+         activated = true;
          this.rehashWait = rehashWaitTime;
       }
 
@@ -3611,6 +3637,7 @@ public Long getRehashRpcTimeout() {
       @Deprecated
       public void setRehashRpcTimeout(Long rehashRpcTimeout) {
          testImmutability(""rehashRpcTimeout"");
+         activated = true;
          this.rehashRpcTimeout = rehashRpcTimeout;
       }
 
@@ -3632,6 +3659,7 @@ public Boolean isRehashEnabled() {
       @Deprecated
       public void setRehashEnabled(Boolean rehashEnabled) {
          testImmutability(""rehashEnabled"");
+         activated = true;
          this.rehashEnabled = rehashEnabled;
       }
 
@@ -3643,6 +3671,7 @@ public HashConfig rehashEnabled(Boolean rehashEnabled) {
       
       public GroupsConfiguration groups() {
          groups.setConfiguration(config);
+         activated = true;
          return groups;
       }
       
@@ -3733,7 +3762,9 @@ public HashType clone() throws CloneNotSupportedException {
       
       @ConfigurationDocRef(bean = Configuration.class, targetElement = ""setL1InvalidationThreshold"")
       protected Integer invalidationThreshold = 0;
-      
+      @XmlTransient
+      public boolean activated = false;
+
       public void accept(ConfigurationBeanVisitor v) {
          v.visitL1Type(this);
       }
@@ -3749,6 +3780,7 @@ public Boolean isEnabled() {
       @Deprecated
       public L1Config setEnabled(Boolean enabled) {
          testImmutability(""enabled"");
+         activated = true;
          this.enabled = enabled;
          return this;
       }
@@ -3764,6 +3796,7 @@ public Long getLifespan() {
       @Deprecated
       public L1Config setLifespan(Long lifespan) {
          testImmutability(""lifespan"");
+         activated = true;
          this.lifespan = lifespan;
          return this;
       }
@@ -3786,6 +3819,7 @@ public Boolean isOnRehash() {
       @Deprecated
       public L1Config setOnRehash(Boolean onRehash) {
          testImmutability(""onRehash"");
+         activated = true;
          this.onRehash = onRehash;
          return this;
       }
@@ -3805,6 +3839,7 @@ public L1Config invalidationThreshold(Integer threshold) {
      
       public void setInvalidationThreshold(Integer threshold) {
          testImmutability(""invalidationThreshold"");
+         activated = true;
          this.invalidationThreshold = threshold;
       }
       ",2012-01-20T20:11:51Z,160
"@@ -87,4 +87,21 @@ public CacheMode toAsync() {
             return this;
       }
    }
+   
+   public String friendlyCacheModeString() {
+      switch (this) {
+         case REPL_SYNC:
+         case REPL_ASYNC:
+            return ""REPLICATED"";
+         case INVALIDATION_SYNC:
+         case INVALIDATION_ASYNC:
+            return ""INVALIDATED"";
+         case DIST_SYNC:
+         case DIST_ASYNC:
+            return ""DISTRIBUTED"";
+         case LOCAL:
+            return ""LOCAL"";
+      }
+      throw new IllegalArgumentException(""Unknown cache mode "" + this);
+   }
 }
\ No newline at end of file",2012-01-20T20:11:51Z,211
"@@ -16,15 +16,18 @@ public class HashConfiguration {
    private final int numVirtualNodes;
    private final GroupsConfiguration groupsConfiguration;
    private final StateTransferConfiguration stateTransferConfiguration;
+   // For use by the LegacyConfigurationAdapter
+   final boolean activated;
 
    HashConfiguration(ConsistentHash consistentHash, Hash hash, int numOwners, int numVirtualNodes,
-         GroupsConfiguration groupsConfiguration, StateTransferConfiguration stateTransferConfiguration) {
+                     GroupsConfiguration groupsConfiguration, StateTransferConfiguration stateTransferConfiguration, boolean activated) {
       this.consistentHash = consistentHash;
       this.hash = hash;
       this.numOwners = numOwners;
       this.numVirtualNodes = numVirtualNodes;
       this.groupsConfiguration = groupsConfiguration;
       this.stateTransferConfiguration = stateTransferConfiguration;
+      this.activated = activated;
    }
 
    /**",2012-01-20T20:11:51Z,212
"@@ -2,8 +2,12 @@
 
 import org.infinispan.commons.hash.Hash;
 import org.infinispan.commons.hash.MurmurHash3;
+import org.infinispan.config.ConfigurationException;
 import org.infinispan.distribution.ch.ConsistentHash;
 
+import static org.infinispan.configuration.cache.CacheMode.REPL_ASYNC;
+import static org.infinispan.configuration.cache.CacheMode.REPL_SYNC;
+
 /**
  * Allows fine-tuning of rehashing characteristics. Must only used with 'distributed' cache mode.
  * 
@@ -16,6 +20,7 @@ public class HashConfigurationBuilder extends AbstractClusteringConfigurationChi
    private Hash hash = new MurmurHash3();
    private int numOwners = 2;
    private int numVirtualNodes = 1;
+   private boolean activated = false;
 
    private final GroupsConfigurationBuilder groupsConfigurationBuilder;
 
@@ -33,14 +38,17 @@ public class HashConfigurationBuilder extends AbstractClusteringConfigurationChi
     */
    public HashConfigurationBuilder consistentHash(ConsistentHash consistentHash) {
       this.consistentHash = consistentHash;
+      activated = true;
       return this;
    }
 
    /**
     * Number of cluster-wide replicas for each cache entry.
     */
    public HashConfigurationBuilder numOwners(int numOwners) {
+      if (numVirtualNodes < 1) throw new IllegalArgumentException(""numOwners cannot be less than 1"");
       this.numOwners = numOwners;
+      activated = true;
       return this;
    }
 
@@ -65,6 +73,7 @@ public HashConfigurationBuilder numOwners(int numOwners) {
    public HashConfigurationBuilder numVirtualNodes(int numVirtualNodes) {
       if (numVirtualNodes < 1) throw new IllegalArgumentException(""numVirtualNodes cannot be less than 1"");
       this.numVirtualNodes = numVirtualNodes;
+      activated = true;
       return this;
    }
 
@@ -75,6 +84,7 @@ public HashConfigurationBuilder numVirtualNodes(int numVirtualNodes) {
     */
    public HashConfigurationBuilder rehashEnabled() {
       stateTransfer().fetchInMemoryState(true);
+      activated = true;
       return this;
    }
    
@@ -85,6 +95,7 @@ public HashConfigurationBuilder rehashEnabled() {
     */
    public HashConfigurationBuilder rehashEnabled(boolean enabled) {
       stateTransfer().fetchInMemoryState(enabled);
+      activated = true;
       return this;
    }
 
@@ -95,6 +106,7 @@ public HashConfigurationBuilder rehashEnabled(boolean enabled) {
     */
    public HashConfigurationBuilder rehashDisabled() {
       stateTransfer().fetchInMemoryState(false);
+      activated = true;
       return this;
    }
 
@@ -104,6 +116,7 @@ public HashConfigurationBuilder rehashDisabled() {
     */
    public HashConfigurationBuilder rehashRpcTimeout(long rehashRpcTimeout) {
       stateTransfer().timeout(rehashRpcTimeout);
+      activated = true;
       return this;
    }
 
@@ -125,23 +138,27 @@ public HashConfigurationBuilder rehashWait(long rehashWait) {
     */
    public HashConfigurationBuilder hash(Hash hash) {
       this.hash = hash;
+      activated = true;
       return this;
    }
 
    public GroupsConfigurationBuilder groups() {
+      activated = true;
       return groupsConfigurationBuilder;
    }
 
    @Override
    void validate() {
+      if (activated && !clustering().cacheMode().isDistributed())
+         throw new ConfigurationException(""Configuring the hashing behavior of entries is only supported when using DISTRIBUTED as a cache mode.  Your cache mode is set to "" + clustering().cacheMode().friendlyCacheModeString());
       groupsConfigurationBuilder.validate();
    }
 
    @Override
    HashConfiguration create() {
       // TODO stateTransfer().create() will create a duplicate StateTransferConfiguration instance
       return new HashConfiguration(consistentHash, hash, numOwners, numVirtualNodes,
-            groupsConfigurationBuilder.create(), stateTransfer().create());
+            groupsConfigurationBuilder.create(), stateTransfer().create(), activated);
    }
 
    @Override",2012-01-20T20:11:51Z,213
"@@ -11,12 +11,15 @@ public class L1Configuration {
    private final int invalidationThreshold;
    private final long lifespan;
    private final boolean onRehash;
+   // For use by the LegacyConfigurationAdapter
+   final boolean activated;
 
-   L1Configuration(boolean enabled, int invalidationThreshold, long lifespan, boolean onRehash) {
+   L1Configuration(boolean enabled, int invalidationThreshold, long lifespan, boolean onRehash, boolean activated) {
       this.enabled = enabled;
       this.invalidationThreshold = invalidationThreshold;
       this.lifespan = lifespan;
       this.onRehash = onRehash;
+      this.activated = activated;
    }
 
    public boolean enabled() {",2012-01-20T20:11:51Z,162
"@@ -19,6 +19,7 @@ public class L1ConfigurationBuilder extends AbstractClusteringConfigurationChild
    private int invalidationThreshold = 0;
    private long lifespan = TimeUnit.MINUTES.toMillis(10);
    private Boolean onRehash = null;
+   boolean activated = false;
 
    L1ConfigurationBuilder(ClusteringConfigurationBuilder builder) {
       super(builder);
@@ -43,6 +44,7 @@ public class L1ConfigurationBuilder extends AbstractClusteringConfigurationChild
     */
    public L1ConfigurationBuilder invalidationThreshold(int invalidationThreshold) {
       this.invalidationThreshold = invalidationThreshold;
+      activated = true;
       return this;
    }
 
@@ -51,6 +53,7 @@ public L1ConfigurationBuilder invalidationThreshold(int invalidationThreshold) {
     */
    public L1ConfigurationBuilder lifespan(long livespan) {
       this.lifespan = livespan;
+      activated = true;
       return this;
    }
 
@@ -59,6 +62,7 @@ public L1ConfigurationBuilder lifespan(long livespan) {
     */
    public L1ConfigurationBuilder enableOnRehash() {
       this.onRehash = true;
+      activated = true;
       return this;
    }
    
@@ -67,6 +71,7 @@ public L1ConfigurationBuilder enableOnRehash() {
     */
    public L1ConfigurationBuilder onRehash(boolean enabled) {
       this.onRehash = enabled;
+      activated = true;
       return this;
    }
 
@@ -75,26 +80,33 @@ public L1ConfigurationBuilder onRehash(boolean enabled) {
     */
    public L1ConfigurationBuilder disableOnRehash() {
       this.onRehash = false;
+      activated = true;
       return this;
    }
    
    public L1ConfigurationBuilder enable() {
       this.enabled = true;
+      activated = true;
       return this;
    }
    
    public L1ConfigurationBuilder disable() {
       this.enabled = false;
+      activated = true;
       return this;
    }
    
    public L1ConfigurationBuilder enabled(boolean enabled) {
       this.enabled = enabled;
+      activated = true;
       return this;
    }
 
    @Override
    void validate() {
+      if (enabled && !clustering().cacheMode().isDistributed() && activated)
+         throw new ConfigurationException(""Enabling the L1 cache is only supported when using DISTRIBUTED as a cache mode.  Your cache mode is set to "" + clustering().cacheMode().friendlyCacheModeString());
+
       // If L1 is disabled, L1ForRehash should also be disabled
       if (!enabled && onRehash != null && onRehash)
          throw new ConfigurationException(""Can only move entries to L1 on rehash when L1 is enabled"");
@@ -109,7 +121,7 @@ L1Configuration create() {
       } else
          onRehash = false;
       
-      return new L1Configuration(enabled, invalidationThreshold, lifespan, onRehash);
+      return new L1Configuration(enabled, invalidationThreshold, lifespan, onRehash, activated);
    }
    
    @Override",2012-01-20T20:11:51Z,163
"@@ -1,6 +1,7 @@
 package org.infinispan.configuration.cache;
 
 import org.infinispan.commons.hash.Hash;
+import org.infinispan.commons.hash.MurmurHash3;
 import org.infinispan.config.Configuration;
 import org.infinispan.config.Configuration.CacheMode;
 import org.infinispan.config.CustomInterceptorConfig;
@@ -52,23 +53,26 @@ public static org.infinispan.config.Configuration adapt(org.infinispan.configura
                .consistentHashClass(config.clustering().hash().consistentHash().getClass());
       
       }
-      if (config.clustering().hash().hash() != null) {
+      if (config.clustering().hash().activated) {
+         if (config.clustering().hash().hash() != null) {
+            legacy.clustering()
+               .hash()
+                  .hashFunctionClass(config.clustering().hash().hash().getClass());
+         }
+
          legacy.clustering()
             .hash()
-               .hashFunctionClass(config.clustering().hash().hash().getClass());
+               .numOwners(config.clustering().hash().numOwners())
+               .numVirtualNodes(config.clustering().hash().numVirtualNodes())
+               .rehashEnabled(config.clustering().hash().rehashEnabled())
+               .rehashRpcTimeout(config.clustering().hash().rehashRpcTimeout())
+               .rehashWait(config.clustering().hash().rehashWait())
+               .groups()
+                  .enabled(config.clustering().hash().groups().enabled())
+                  .groupers(config.clustering().hash().groups().groupers());
       }
-      legacy.clustering()
-      .hash()
-            .numOwners(config.clustering().hash().numOwners())
-            .numVirtualNodes(config.clustering().hash().numVirtualNodes())
-            .rehashEnabled(config.clustering().hash().rehashEnabled())
-            .rehashRpcTimeout(config.clustering().hash().rehashRpcTimeout())
-            .rehashWait(config.clustering().hash().rehashWait())
-            .groups()
-               .enabled(config.clustering().hash().groups().enabled())
-               .groupers(config.clustering().hash().groups().groupers());
-      
-      if (config.clustering().l1().enabled()) {
+      
+      if (config.clustering().l1().activated) {
          legacy.clustering()
             .l1()
                .invalidationThreshold(config.clustering().l1().invalidationThreshold())
@@ -273,29 +277,31 @@ public static org.infinispan.configuration.cache.Configuration adapt(org.infinis
                .useReplQueue(legacy.isUseReplQueue());
       }
       
-      if (legacy.hasConsistentHashClass()) {
+      if (legacy.isCustomConsistentHashClass()) {
          builder.clustering()
             .hash()
                .consistentHash(Util.<ConsistentHash>getInstance(legacy.getConsistentHashClass(), legacy.getClassLoader()));
       
       }
-      if (legacy.getHashFunctionClass() != null) {
+      if (legacy.isCustomHashFunctionClass()) {
          builder.clustering()
             .hash()
                .hash(Util.<Hash>getInstance(legacy.getHashFunctionClass(), legacy.getClassLoader()));
       }
-      builder.clustering()
-      .hash()
-            .numOwners(legacy.getNumOwners())
-            .numVirtualNodes(legacy.getNumVirtualNodes())
-            .rehashEnabled(legacy.isRehashEnabled())
-            .rehashRpcTimeout(legacy.getRehashRpcTimeout())
-            .rehashWait(legacy.getRehashWaitTime())
-            .groups()
-               .enabled(legacy.isGroupsEnabled())
-               .withGroupers(legacy.getGroupers());
-      
-      if (legacy.isL1CacheEnabled()) {
+      if (legacy.isHashActivated()) {
+         builder.clustering()
+            .hash()
+               .numOwners(legacy.getNumOwners())
+               .numVirtualNodes(legacy.getNumVirtualNodes())
+               .rehashEnabled(legacy.isRehashEnabled())
+               .rehashRpcTimeout(legacy.getRehashRpcTimeout())
+               .rehashWait(legacy.getRehashWaitTime())
+               .groups()
+                  .enabled(legacy.isGroupsEnabled())
+                  .withGroupers(legacy.getGroupers());
+      }
+      
+      if (legacy.isL1CacheActivated()) {
          builder.clustering()
             .l1().enable()
                .invalidationThreshold(legacy.getL1InvalidationThreshold())
@@ -325,7 +331,7 @@ public static org.infinispan.configuration.cache.Configuration adapt(org.infinis
             interceptorConfigurationBuilder.after(Util.<CommandInterceptor>loadClass(interceptor.getAfter(), legacy.getClassLoader()));
          if (interceptor.getBefore() != null && !interceptor.getBefore().isEmpty())
             interceptorConfigurationBuilder.before(Util.<CommandInterceptor>loadClass(interceptor.getBefore(), legacy.getClassLoader()));
-         interceptorConfigurationBuilder.index(interceptor.getIndex());
+         if (interceptor.getIndex() > -1) interceptorConfigurationBuilder.index(interceptor.getIndex());
          interceptorConfigurationBuilder.interceptor(interceptor.getInterceptor());
          interceptorConfigurationBuilder.position(Position.valueOf(interceptor.getPositionAsString()));
       }",2012-01-20T20:11:51Z,164
"@@ -71,13 +71,18 @@
 import static org.infinispan.factories.KnownComponentNames.GLOBAL_MARSHALLER;
 
 /**
- * An encapsulation of a JGroups transport.  JGroups transports can be configured using a variety of methods, usually by
- * passing in one of the following properties: <ul> <li><tt>configurationString</tt> - a JGroups configuration
- * String</li> <li><tt>configurationXml</tt> - JGroups configuration XML as a String</li> <li><tt>configurationFile</tt>
- * - String pointing to a JGroups XML configuration file</li> <li><tt>channelLookup</tt> - Fully qualified class name of
- * a {@link org.infinispan.remoting.transport.jgroups.JGroupsChannelLookup} instance</li> </ul> These are normally
- * passed in as Properties in {@link org.infinispan.config.GlobalConfiguration#setTransportProperties(java.util.Properties)}
- * or in the Infinispan XML configuration file.
+ * An encapsulation of a JGroups transport. JGroups transports can be configured using a variety of
+ * methods, usually by passing in one of the following properties:
+ * <ul>
+ * <li><tt>configurationString</tt> - a JGroups configuration String</li>
+ * <li><tt>configurationXml</tt> - JGroups configuration XML as a String</li>
+ * <li><tt>configurationFile</tt> - String pointing to a JGroups XML configuration file</li>
+ * <li><tt>channelLookup</tt> - Fully qualified class name of a
+ * {@link org.infinispan.remoting.transport.jgroups.JGroupsChannelLookup} instance</li>
+ * </ul>
+ * These are normally passed in as Properties in
+ * {@link org.infinispan.config.GlobalConfiguration#setTransportProperties(java.util.Properties)} or
+ * in the Infinispan XML configuration file.
  *
  * @author Manik Surtani
  * @author Galder Zamarreño
@@ -118,19 +123,24 @@ public class JGroupsTransport extends AbstractTransport implements MembershipLis
    protected CountDownLatch channelConnectedLatch = new CountDownLatch(1);
 
    /**
-    * This form is used when the transport is created by an external source and passed in to the GlobalConfiguration.
+    * This form is used when the transport is created by an external source and passed in to the
+    * GlobalConfiguration.
     *
-    * @param channel created and running channel to use
+    * @param channel
+    *           created and running channel to use
     */
    public JGroupsTransport(Channel channel) {
       this.channel = channel;
-      if (channel == null) throw new IllegalArgumentException(""Cannot deal with a null channel!"");
-      if (channel.isConnected()) throw new IllegalArgumentException(""Channel passed in cannot already be connected!"");
+      if (channel == null)
+         throw new IllegalArgumentException(""Cannot deal with a null channel!"");
+      if (channel.isConnected())
+         throw new IllegalArgumentException(""Channel passed in cannot already be connected!"");
    }
 
    public JGroupsTransport() {
    }
 
+   @Override
    public Log getLog() {
       return log;
    }
@@ -139,19 +149,21 @@ public Log getLog() {
    // Lifecycle and setup stuff
    // ------------------------------------------------------------------------------------------------------------------
 
-   public void initialize(@ComponentName(GLOBAL_MARSHALLER) StreamingMarshaller marshaller,
-                          ExecutorService asyncExecutor, InboundInvocationHandler inboundInvocationHandler,
-                          CacheManagerNotifier notifier) {
+   @Override
+   public void initialize(@ComponentName(GLOBAL_MARSHALLER) StreamingMarshaller marshaller, ExecutorService asyncExecutor, InboundInvocationHandler inboundInvocationHandler,
+            CacheManagerNotifier notifier) {
       this.marshaller = marshaller;
       this.asyncExecutor = asyncExecutor;
       this.inboundInvocationHandler = inboundInvocationHandler;
       this.notifier = notifier;
    }
 
+   @Override
    public void start() {
       props = TypedProperties.toTypedProperties(configuration.getTransportProperties());
 
-      if (log.isInfoEnabled()) log.startingJGroupsChannel();
+      if (log.isInfoEnabled())
+         log.startingJGroupsChannel();
 
       initChannelAndRPCDispatcher();
       startJGroupsChannelIfNeeded();
@@ -192,6 +204,7 @@ protected void startJGroupsChannelIfNeeded() {
          log.localAndPhysicalAddress(getAddress(), getPhysicalAddresses());
    }
 
+   @Override
    public int getViewId() {
       if (channel == null)
          throw new CacheException(""The cache has been stopped and invocations are not allowed!"");
@@ -201,6 +214,7 @@ public int getViewId() {
       return (int) view.getVid().getId();
    }
 
+   @Override
    public void stop() {
       try {
          if (stopChannel && channel != null && channel.isOpen()) {
@@ -209,8 +223,7 @@ public void stop() {
             // Unregistering before disconnecting/closing because
             // after that the cluster name is null
             if (globalStatsEnabled) {
-               JmxConfigurator.unregisterChannel((JChannel) channel,
-                  mbeanServer, domain, channel.getClusterName());
+               JmxConfigurator.unregisterChannel((JChannel) channel, mbeanServer, domain, channel.getClusterName());
             }
 
             channel.disconnect();
@@ -232,7 +245,6 @@ public void stop() {
       dispatcher = null;
    }
 
-
    protected void initChannel() {
       if (channel == null) {
          buildChannel();
@@ -245,35 +257,47 @@ protected void initChannel() {
          }
       }
 
-      // Channel.LOCAL *must* be set to false so we don't see our own messages - otherwise invalidations targeted at
-      // remote instances will be received by self.
+      // Channel.LOCAL *must* be set to false so we don't see our own messages - otherwise
+      // invalidations targeted at remote instances will be received by self.
       channel.setDiscardOwnMessages(true);
 
-      // if we have a TopologyAwareConsistentHash, we need to set our own address generator in JGroups:
-      if(configuration.hasTopologyInfo()) {
-         ((JChannel)channel).setAddressGenerator(new AddressGenerator() {
-
-            public org.jgroups.Address generateAddress() {
-               return TopologyUUID.randomUUID(channel.getName(),
-                     configuration.getSiteId(), configuration.getRackId(), configuration.getMachineId());
-
+      // if we have a TopologyAwareConsistentHash, we need to set our own address generator in
+      // JGroups
+      if (configuration.hasTopologyInfo()) {
+         // We can do this only if the channel hasn't been started already
+         if (!startChannel) {
+            ((JChannel) channel).setAddressGenerator(new AddressGenerator() {
+
+               @Override
+               public org.jgroups.Address generateAddress() {
+                  return TopologyUUID.randomUUID(channel.getName(), configuration.getSiteId(), configuration.getRackId(), configuration.getMachineId());
+               }
+            });
+         } else {
+            if (channel.getAddress() instanceof TopologyUUID) {
+               TopologyUUID topologyAddress = (TopologyUUID) channel.getAddress();
+               if (!configuration.getSiteId().equals(topologyAddress.getSiteId()) || !configuration.getRackId().equals(topologyAddress.getSiteId()) || !configuration.getMachineId().equals(topologyAddress.getMachineId())) {
+                  throw new CacheException(""Topology information does not match the one set by the provided JGroups channel"");
+               }
+            } else {
+               throw new CacheException(""JGroups address does not contain topology coordinates"");
             }
-         });
+         }
       }
    }
 
    private void initChannelAndRPCDispatcher() throws CacheException {
       initChannel();
-      dispatcher = new CommandAwareRpcDispatcher(channel, this,
-              asyncExecutor, inboundInvocationHandler);
+      dispatcher = new CommandAwareRpcDispatcher(channel, this, asyncExecutor, inboundInvocationHandler);
       MarshallerAdapter adapter = new MarshallerAdapter(marshaller);
       dispatcher.setRequestMarshaller(adapter);
       dispatcher.setResponseMarshaller(adapter);
    }
 
    // This is per CM, so the CL in use should be the CM CL
    private void buildChannel() {
-      // in order of preference - we first look for an external JGroups file, then a set of XML properties, and
+      // in order of preference - we first look for an external JGroups file, then a set of XML
+      // properties, and
       // finally the legacy JGroups String properties.
       String cfg;
       if (props != null) {
@@ -342,16 +366,19 @@ private void buildChannel() {
    // querying cluster status
    // ------------------------------------------------------------------------------------------------------------------
 
+   @Override
    public boolean isCoordinator() {
       return isCoordinator;
    }
 
+   @Override
    public Address getCoordinator() {
       return coordinator;
    }
 
    public void waitForChannelToConnect() {
-      if (channel == null) return;
+      if (channel == null)
+         return;
       log.debug(""Waiting on view being accepted"");
       try {
          channelConnectedLatch.await();
@@ -360,22 +387,25 @@ public void waitForChannelToConnect() {
       }
    }
 
+   @Override
    public List<Address> getMembers() {
-      return members != null ? members : Collections.<Address>emptyList();
+      return members != null ? members : Collections.<Address> emptyList();
    }
 
    @Override
    public boolean isMulticastCapable() {
       return channel.getProtocolStack().getTransport().supportsMulticasting();
    }
 
+   @Override
    public Address getAddress() {
       if (address == null && channel != null) {
          address = fromJGroupsAddress(channel.getAddress());
       }
       return address;
    }
 
+   @Override
    public List<Address> getPhysicalAddresses() {
       if (physicalAddress == null && channel != null) {
          org.jgroups.Address addr = (org.jgroups.Address) channel.down(new Event(Event.GET_PHYSICAL_ADDRESS, channel.getAddress()));
@@ -388,17 +418,18 @@ public List<Address> getPhysicalAddresses() {
    // outbound RPC
    // ------------------------------------------------------------------------------------------------------------------
 
-   public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout,
-                                        boolean usePriorityQueue, ResponseFilter responseFilter, boolean supportReplay)
-           throws Exception {
+   @Override
+   public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout, boolean usePriorityQueue, ResponseFilter responseFilter,
+            boolean supportReplay) throws Exception {
 
       if (recipients != null && recipients.isEmpty()) {
          // don't send if dest list is empty
          log.trace(""Destination list is empty: no need to send message"");
          return Collections.emptyMap();
       }
 
-      if (trace) log.tracef(""dests=%s, command=%s, mode=%s, timeout=%s"", recipients, rpcCommand, mode, timeout);
+      if (trace)
+         log.tracef(""dests=%s, command=%s, mode=%s, timeout=%s"", recipients, rpcCommand, mode, timeout);
 
       if (mode == ResponseMode.SYNCHRONOUS && recipients != null && !getMembers().containsAll(recipients)) {
          throw new SuspectException(""One or more nodes have left the cluster while replicating command "" + rpcCommand);
@@ -408,24 +439,26 @@ public Map<Address, Response> invokeRemotely(Collection<Address> recipients, Rep
          usePriorityQueue = true;
 
       boolean broadcast = recipients == null || recipients.size() == members.size();
-      RspList<Object> rsps = dispatcher.invokeRemoteCommands(toJGroupsAddressVector(recipients), rpcCommand, toJGroupsMode(mode),
-              timeout, recipients != null, usePriorityQueue,
-              toJGroupsFilter(responseFilter), supportReplay, asyncMarshalling, broadcast);
+      RspList<Object> rsps = dispatcher.invokeRemoteCommands(toJGroupsAddressVector(recipients), rpcCommand, toJGroupsMode(mode), timeout, recipients != null, usePriorityQueue,
+               toJGroupsFilter(responseFilter), supportReplay, asyncMarshalling, broadcast);
 
-      if (mode.isAsynchronous()) return Collections.emptyMap();// async case
+      if (mode.isAsynchronous())
+         return Collections.emptyMap();// async case
 
       // short-circuit no-return-value calls.
-      if (rsps == null) return Collections.emptyMap();
+      if (rsps == null)
+         return Collections.emptyMap();
       Map<Address, Response> retval = new HashMap<Address, Response>(rsps.size());
 
       boolean ignoreLeavers = mode == ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS || mode == ResponseMode.WAIT_FOR_VALID_RESPONSE;
       boolean noValidResponses = true;
       for (Rsp<Object> rsp : rsps.values()) {
-         noValidResponses &= parseResponseAndAddToResponseList(rsp.getValue(), rsp.getException(), retval, rsp.wasSuspected(),
-               rsp.wasReceived(), fromJGroupsAddress(rsp.getSender()), responseFilter != null, ignoreLeavers);
+         noValidResponses &= parseResponseAndAddToResponseList(rsp.getValue(), rsp.getException(), retval, rsp.wasSuspected(), rsp.wasReceived(), fromJGroupsAddress(rsp.getSender()),
+                  responseFilter != null, ignoreLeavers);
       }
 
-      if (noValidResponses) throw new TimeoutException(""Timed out waiting for valid responses!"");
+      if (noValidResponses)
+         throw new TimeoutException(""Timed out waiting for valid responses!"");
       return retval;
    }
 
@@ -475,11 +508,13 @@ public void emitNotification(List<Address> oldMembers, View newView) {
 
       private List<List<Address>> getSubgroups(List<View> subviews) {
          List<List<Address>> l = new ArrayList<List<Address>>(subviews.size());
-         for (View v: subviews) l.add(fromJGroupsAddressList(v.getMembers()));
-         return l;         
+         for (View v : subviews)
+            l.add(fromJGroupsAddressList(v.getMembers()));
+         return l;
       }
    }
 
+   @Override
    public void viewAccepted(View newView) {
       log.debugf(""New view accepted: %s"", newView);
       List<org.jgroups.Address> newMembers = newView.getMembers();
@@ -518,14 +553,17 @@ public void viewAccepted(View newView) {
       }
    }
 
+   @Override
    public void suspect(org.jgroups.Address suspected_mbr) {
       // no-op
    }
 
+   @Override
    public void block() {
       // no-op since ISPN-83 has been resolved
    }
 
+   @Override
    public void unblock() {
       // no-op since ISPN-83 has been resolved
    }
@@ -539,29 +577,32 @@ protected static org.jgroups.Address toJGroupsAddress(Address a) {
    }
 
    static Address fromJGroupsAddress(org.jgroups.Address addr) {
-      if(addr instanceof TopologyUUID)
+      if (addr instanceof TopologyUUID)
          return new JGroupsTopologyAwareAddress(addr);
       else
          return new JGroupsAddress(addr);
    }
 
-
    private static Vector<org.jgroups.Address> toJGroupsAddressVector(Collection<Address> list) {
-      if (list == null) return null;
-      if (list.isEmpty()) return new Vector<org.jgroups.Address>();
+      if (list == null)
+         return null;
+      if (list.isEmpty())
+         return new Vector<org.jgroups.Address>();
 
       Vector<org.jgroups.Address> retval = new Vector<org.jgroups.Address>(list.size());
-      for (Address a : list) retval.add(toJGroupsAddress(a));
+      for (Address a : list)
+         retval.add(toJGroupsAddress(a));
 
       return retval;
    }
 
-
    private static List<Address> fromJGroupsAddressList(List<org.jgroups.Address> list) {
-      if (list == null || list.isEmpty()) return Collections.emptyList();
+      if (list == null || list.isEmpty())
+         return Collections.emptyList();
 
       List<Address> retval = new ArrayList<Address>(list.size());
-      for (org.jgroups.Address a : list) retval.add(fromJGroupsAddress(a));
+      for (org.jgroups.Address a : list)
+         retval.add(fromJGroupsAddress(a));
       return Collections.unmodifiableList(retval);
    }
 ",2011-12-16T14:56:33Z,214
"@@ -125,7 +125,8 @@ public enum Attribute {
     VALUE(""value""),
     VERSION(""version""),
     WAKE_UP_INTERVAL(""wakeUpInterval""),
-    WRITE_SKEW_CHECK(""writeSkewCheck"")
+    WRITE_SKEW_CHECK(""writeSkewCheck""),
+    USE_1PC_FOR_AUTOCOMMIT_TX(""use1PcForAutoCommitTransactions"")
     ;
 
     private final String name;",2012-01-07T18:17:10Z,165
"@@ -110,8 +110,8 @@ private ConfigurationBuilderHolder doParse(XMLStreamReader reader) throws XMLStr
       
       Element root = ParseUtils.nextElement(reader);
       
-      if (root.getLocalName() != Element.ROOT.getLocalName()) {
-         ParseUtils.missingRequiredElement(reader, Collections.singleton(Element.ROOT));
+      if (!root.getLocalName().equals(Element.ROOT.getLocalName())) {
+         throw ParseUtils.missingRequiredElement(reader, Collections.singleton(Element.ROOT));
       }
 
       while (reader.hasNext() && (reader.nextTag() != XMLStreamConstants.END_ELEMENT)) {
@@ -227,22 +227,22 @@ private void parseTransaction(XMLStreamReader reader, ConfigurationBuilder build
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case AUTO_COMMIT:
-               builder.transaction().autoCommit(Boolean.valueOf(value).booleanValue());
+               builder.transaction().autoCommit(Boolean.valueOf(value));
                break;
             case CACHE_STOP_TIMEOUT:
-               builder.transaction().cacheStopTimeout(Integer.valueOf(value).intValue());
+               builder.transaction().cacheStopTimeout(Integer.valueOf(value));
                break;
             case EAGER_LOCK_SINGLE_NODE:
-               builder.transaction().eagerLockingSingleNode(Boolean.valueOf(value).booleanValue());
+               builder.transaction().eagerLockingSingleNode(Boolean.valueOf(value));
                break;
             case LOCKING_MODE:
                builder.transaction().lockingMode(LockingMode.valueOf(value));
                break;
             case SYNC_COMMIT_PHASE:
-               builder.transaction().syncCommitPhase(Boolean.valueOf(value).booleanValue());
+               builder.transaction().syncCommitPhase(Boolean.valueOf(value));
                break;
             case SYNC_ROLLBACK_PHASE:
-               builder.transaction().syncRollbackPhase(Boolean.valueOf(value).booleanValue());
+               builder.transaction().syncRollbackPhase(Boolean.valueOf(value));
                break;
             case TRANSACTION_MANAGER_LOOKUP_CLASS:
                builder.transaction().transactionManagerLookup(Util.<TransactionManagerLookup>getInstance(value, cl));
@@ -253,11 +253,13 @@ private void parseTransaction(XMLStreamReader reader, ConfigurationBuilder build
                transactionModeSpecified = true;
                break;
             case USE_EAGER_LOCKING:
-               builder.transaction().useEagerLocking(Boolean.valueOf(value).booleanValue());
+               builder.transaction().useEagerLocking(Boolean.valueOf(value));
                break;
             case USE_SYNCHRONIZAION:
-               builder.transaction().useSynchronization(Boolean.valueOf(value).booleanValue());
+               builder.transaction().useSynchronization(Boolean.valueOf(value));
                break;
+            case USE_1PC_FOR_AUTOCOMMIT_TX:
+               builder.transaction().use1PcForAutoCommitTransactions(Boolean.valueOf(value));
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
          }
@@ -285,7 +287,7 @@ private void parseRecovery(XMLStreamReader reader, ConfigurationBuilder builder)
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.transaction().recovery().enable();
                else
                   builder.transaction().recovery().disable();
@@ -308,7 +310,7 @@ private void parseUnsafe(XMLStreamReader reader, ConfigurationBuilder builder) t
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case UNRELIABLE_RETURN_VALUES:
-               builder.unsafe().unreliableReturnValues(Boolean.valueOf(value).booleanValue());
+               builder.unsafe().unreliableReturnValues(Boolean.valueOf(value));
                break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
@@ -326,16 +328,16 @@ private void parseStoreAsBinary(XMLStreamReader reader, ConfigurationBuilder bui
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.storeAsBinary().enable();
                else
                   builder.storeAsBinary().disable();
                break;
             case STORE_KEYS_AS_BINARY:
-               builder.storeAsBinary().storeKeysAsBinary(Boolean.valueOf(value).booleanValue());
+               builder.storeAsBinary().storeKeysAsBinary(Boolean.valueOf(value));
                break;
             case STORE_VALUES_AS_BINARY:
-               builder.storeAsBinary().storeValuesAsBinary(Boolean.valueOf(value).booleanValue());
+               builder.storeAsBinary().storeValuesAsBinary(Boolean.valueOf(value));
                break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
@@ -353,19 +355,19 @@ private void parseLocking(XMLStreamReader reader, ConfigurationBuilder builder)
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case CONCURRENCY_LEVEL:
-               builder.locking().concurrencyLevel(Integer.valueOf(value).intValue());
+               builder.locking().concurrencyLevel(Integer.valueOf(value));
                break;
             case ISOLATION_LEVEL:
                builder.locking().isolationLevel(IsolationLevel.valueOf(value));
                break;
             case LOCK_ACQUISITION_TIMEOUT:
-               builder.locking().lockAcquisitionTimeout(Long.valueOf(value).longValue());
+               builder.locking().lockAcquisitionTimeout(Long.valueOf(value));
                break;
             case USE_LOCK_STRIPING:
-               builder.locking().useLockStriping(Boolean.valueOf(value).booleanValue());
+               builder.locking().useLockStriping(Boolean.valueOf(value));
                break;
             case WRITE_SKEW_CHECK:
-               builder.locking().writeSkewCheck(Boolean.valueOf(value).booleanValue());
+               builder.locking().writeSkewCheck(Boolean.valueOf(value));
                break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
@@ -383,13 +385,13 @@ private void parseLoaders(XMLStreamReader reader, ConfigurationBuilder builder)
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case PASSIVATION:
-               builder.loaders().passivation(Boolean.valueOf(value).booleanValue());
+               builder.loaders().passivation(Boolean.valueOf(value));
                break;
             case PRELOAD:
-               builder.loaders().preload(Boolean.valueOf(value).booleanValue());
+               builder.loaders().preload(Boolean.valueOf(value));
                break;
             case SHARED:
-               builder.loaders().shared(Boolean.valueOf(value).booleanValue());
+               builder.loaders().shared(Boolean.valueOf(value));
                break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
@@ -409,7 +411,6 @@ private void parseLoaders(XMLStreamReader reader, ConfigurationBuilder builder)
    }
 
    private void parseLoader(XMLStreamReader reader, ConfigurationBuilder builder) throws XMLStreamException {
-      
       CacheLoader loader = null;
       Boolean fetchPersistentState = null;
       Boolean ignoreModifications = null;
@@ -423,7 +424,7 @@ private void parseLoader(XMLStreamReader reader, ConfigurationBuilder builder) t
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case CLASS:
-               loader = Util.<CacheLoader>getInstance(value, cl);
+               loader = Util.getInstance(value, cl);
                break;
             case FETCH_PERSISTENT_STATE:
                fetchPersistentState = Boolean.valueOf(value);
@@ -435,10 +436,10 @@ private void parseLoader(XMLStreamReader reader, ConfigurationBuilder builder) t
                purgeOnStartup = Boolean.valueOf(value);
                break;
             case PURGER_THREADS:
-               purgerThreads = Integer.valueOf(value).intValue();
+               purgerThreads = Integer.valueOf(value);
                break;
             case PURGE_SYNCHRONOUSLY:
-               purgeSynchronously = Boolean.valueOf(value).booleanValue();
+               purgeSynchronously = Boolean.valueOf(value);
                break; 
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
@@ -449,27 +450,27 @@ private void parseLoader(XMLStreamReader reader, ConfigurationBuilder builder) t
          if (loader instanceof FileCacheStore) {
             FileCacheStoreConfigurationBuilder fcscb = builder.loaders().addFileCacheStore();
             if (fetchPersistentState != null)
-               fcscb.fetchPersistentState(fetchPersistentState.booleanValue());
+               fcscb.fetchPersistentState(fetchPersistentState);
             if (ignoreModifications != null)
-               fcscb.ignoreModifications(ignoreModifications.booleanValue());
+               fcscb.ignoreModifications(ignoreModifications);
             if (purgeOnStartup != null)
-               fcscb.purgeOnStartup(purgeOnStartup.booleanValue());
+               fcscb.purgeOnStartup(purgeOnStartup);
             if (purgeSynchronously != null)
-               fcscb.purgeSynchronously(purgeSynchronously.booleanValue());
+               fcscb.purgeSynchronously(purgeSynchronously);
             parseLoaderChildren(reader, fcscb);
          } else {
             LoaderConfigurationBuilder lcb = builder.loaders().addCacheLoader();
             lcb.cacheLoader(loader);
             if (fetchPersistentState != null)
-               lcb.fetchPersistentState(fetchPersistentState.booleanValue());
+               lcb.fetchPersistentState(fetchPersistentState);
             if (ignoreModifications != null)
-               lcb.ignoreModifications(ignoreModifications.booleanValue());
+               lcb.ignoreModifications(ignoreModifications);
             if (purgerThreads != null)
-               lcb.purgerThreads(purgerThreads.intValue());
+               lcb.purgerThreads(purgerThreads);
             if (purgeOnStartup != null)
-               lcb.purgeOnStartup(purgeOnStartup.booleanValue());
+               lcb.purgeOnStartup(purgeOnStartup);
             if (purgeSynchronously != null)
-               lcb.purgeSynchronously(purgeSynchronously.booleanValue());
+               lcb.purgeSynchronously(purgeSynchronously);
             parseLoaderChildren(reader, lcb);
          }
          
@@ -503,16 +504,16 @@ private void parseSingletonStore(XMLStreamReader reader, AbstractLoaderConfigura
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   loaderBuilder.singletonStore().enable();
                else
                   loaderBuilder.singletonStore().disable();
                break;
             case PUSH_STATE_TIMEOUT:
-               loaderBuilder.singletonStore().pushStateTimeout(Long.valueOf(value).longValue());
+               loaderBuilder.singletonStore().pushStateTimeout(Long.valueOf(value));
                break;
             case PUSH_STATE_WHEN_COORDINATOR:
-               loaderBuilder.singletonStore().pushStateWhenCoordinator(Boolean.valueOf(value).booleanValue());
+               loaderBuilder.singletonStore().pushStateWhenCoordinator(Boolean.valueOf(value));
                break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
@@ -529,22 +530,22 @@ private void parseAsyncLoader(XMLStreamReader reader, AbstractLoaderConfiguratio
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   loaderBuilder.async().enable();
                else
                   loaderBuilder.async().disable();
                break;
             case FLUSH_LOCK_TIMEOUT:
-               loaderBuilder.async().flushLockTimeout(Long.valueOf(value).longValue());
+               loaderBuilder.async().flushLockTimeout(Long.valueOf(value));
                break;
             case MODIFICTION_QUEUE_SIZE:
-               loaderBuilder.async().modificationQueueSize(Integer.valueOf(value).intValue());
+               loaderBuilder.async().modificationQueueSize(Integer.valueOf(value));
                break;
             case SHUTDOWN_TIMEOUT:
-               loaderBuilder.async().shutdownTimeout(Long.valueOf(value).longValue());
+               loaderBuilder.async().shutdownTimeout(Long.valueOf(value));
                break;
             case THREAD_POOL_SIZE:
-               loaderBuilder.async().threadPoolSize(Integer.valueOf(value).intValue());
+               loaderBuilder.async().threadPoolSize(Integer.valueOf(value));
                break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
@@ -562,7 +563,7 @@ private void parseJmxStatistics(XMLStreamReader reader, ConfigurationBuilder bui
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.jmxStatistics().enable();
                else
                   builder.jmxStatistics().disable();
@@ -582,7 +583,7 @@ private void parseInvocationBatching(XMLStreamReader reader, ConfigurationBuilde
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.invocationBatching().enable();
                else
                   builder.invocationBatching().disable();
@@ -603,7 +604,7 @@ private void parseIndexing(XMLStreamReader reader, ConfigurationBuilder builder)
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.indexing().enable();
                else
                   builder.indexing().disable();
@@ -641,19 +642,19 @@ private void parseExpiration(XMLStreamReader reader, ConfigurationBuilder builde
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case LIFESPAN:
-               builder.expiration().lifespan(Long.valueOf(value).longValue());
+               builder.expiration().lifespan(Long.valueOf(value));
                break;
             case MAX_IDLE:
-               builder.expiration().maxIdle(Long.valueOf(value).longValue());
+               builder.expiration().maxIdle(Long.valueOf(value));
                break;
             case REAPER_ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.expiration().enableReaper();
                else
                   builder.expiration().disableReaper();
                break;
             case WAKE_UP_INTERVAL:
-               builder.expiration().wakeUpInterval(Long.valueOf(value).longValue());
+               builder.expiration().wakeUpInterval(Long.valueOf(value));
                break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
@@ -671,7 +672,7 @@ private void parseEviction(XMLStreamReader reader, ConfigurationBuilder builder)
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case MAX_ENTRIES:
-               builder.eviction().maxEntries(Integer.valueOf(value).intValue());
+               builder.eviction().maxEntries(Integer.valueOf(value));
                break;
             case STRATEGY:
                builder.eviction().strategy(EvictionStrategy.valueOf(value));
@@ -696,7 +697,7 @@ private void parseDeadlockDetection(XMLStreamReader reader, ConfigurationBuilder
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.deadlockDetection().enable();
                else
                   builder.deadlockDetection().disable();
@@ -774,7 +775,7 @@ private void parseInterceptor(XMLStreamReader reader, ConfigurationBuilder build
                interceptorBuilder.interceptor(Util.<CommandInterceptor>getInstance(value, cl));
                break;
             case INDEX:
-               interceptorBuilder.index(Integer.valueOf(value).intValue());
+               interceptorBuilder.index(Integer.valueOf(value));
                break;
             case POSITION:
                interceptorBuilder.position(Position.valueOf(value.toUpperCase()));
@@ -876,7 +877,7 @@ private void parseSync(XMLStreamReader reader, ConfigurationBuilder builder) thr
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case REPL_TIMEOUT:
-               builder.clustering().sync().replTimeout(Long.valueOf(value).longValue());
+               builder.clustering().sync().replTimeout(Long.valueOf(value));
                break;
            
             default:
@@ -896,28 +897,28 @@ private void parseStateRetrieval(XMLStreamReader reader, ConfigurationBuilder bu
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ALWAYS_PROVIDE_IN_MEMORY_STATE:
-               builder.clustering().stateRetrieval().alwaysProvideInMemoryState(Boolean.valueOf(value).booleanValue());
+               builder.clustering().stateRetrieval().alwaysProvideInMemoryState(Boolean.valueOf(value));
                break;
             case FETCH_IN_MEMORY_STATE:
-               builder.clustering().stateRetrieval().fetchInMemoryState(Boolean.valueOf(value).booleanValue());
+               builder.clustering().stateRetrieval().fetchInMemoryState(Boolean.valueOf(value));
                break;
             case INITIAL_RETRY_WAIT_TIME:
-               builder.clustering().stateRetrieval().initialRetryWaitTime(Long.valueOf(value).longValue());
+               builder.clustering().stateRetrieval().initialRetryWaitTime(Long.valueOf(value));
                break;
             case LOG_FLUSH_TIMEOUT:
-               builder.clustering().stateRetrieval().logFlushTimeout(Long.valueOf(value).longValue());
+               builder.clustering().stateRetrieval().logFlushTimeout(Long.valueOf(value));
                break;
             case MAX_NON_PROGRESSING_LOG_WRITES:
-               builder.clustering().stateRetrieval().maxNonProgressingLogWrites(Integer.valueOf(value).intValue());
+               builder.clustering().stateRetrieval().maxNonProgressingLogWrites(Integer.valueOf(value));
                break;
             case NUM_RETRIES:
-               builder.clustering().stateRetrieval().numRetries(Integer.valueOf(value).intValue());
+               builder.clustering().stateRetrieval().numRetries(Integer.valueOf(value));
                break;
             case RETRY_WAIT_TIME_INCREASE_FACTOR:
-               builder.clustering().stateRetrieval().retryWaitTimeIncreaseFactor(Integer.valueOf(value).intValue());
+               builder.clustering().stateRetrieval().retryWaitTimeIncreaseFactor(Integer.valueOf(value));
                break;
             case TIMEOUT:
-               builder.clustering().stateRetrieval().timeout(Long.valueOf(value).longValue());
+               builder.clustering().stateRetrieval().timeout(Long.valueOf(value));
                break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
@@ -936,19 +937,19 @@ private void parseL1reader(XMLStreamReader reader, ConfigurationBuilder builder)
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.clustering().l1().enable();
                else
                   builder.clustering().l1().disable();
                break;
             case INVALIDATION_THRESHOLD:
-               builder.clustering().l1().invalidationThreshold(Integer.valueOf(value).intValue());
+               builder.clustering().l1().invalidationThreshold(Integer.valueOf(value));
                break;
             case LIFESPAN:
-               builder.clustering().l1().lifespan(Long.valueOf(value).longValue());
+               builder.clustering().l1().lifespan(Long.valueOf(value));
                break;
             case ON_REHASH:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.clustering().l1().enableOnRehash();
                else
                   builder.clustering().l1().disableOnRehash();
@@ -973,22 +974,22 @@ private void parseHash(XMLStreamReader reader, ConfigurationBuilder builder) thr
                builder.clustering().hash().consistentHash(Util.<ConsistentHash> getInstance(value, cl));
                break;
             case NUM_OWNERS:
-               builder.clustering().hash().numOwners(Integer.valueOf(value).intValue());
+               builder.clustering().hash().numOwners(Integer.valueOf(value));
                break;
             case NUM_VIRTUAL_NODES:
-               builder.clustering().hash().numVirtualNodes(Integer.valueOf(value).intValue());
+               builder.clustering().hash().numVirtualNodes(Integer.valueOf(value));
                break;
             case REHASH_ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.clustering().hash().rehashEnabled();
                else
                   builder.clustering().hash().rehashDisabled();
                break;
             case REHASH_RPC_TIMEOUT:
-               builder.clustering().hash().rehashRpcTimeout(Long.valueOf(value).longValue());
+               builder.clustering().hash().rehashRpcTimeout(Long.valueOf(value));
                break;
             case REHASH_WAIT:
-               builder.clustering().hash().rehashWait(Long.valueOf(value).longValue());
+               builder.clustering().hash().rehashWait(Long.valueOf(value));
                break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
@@ -1018,7 +1019,7 @@ private void parseGroups(XMLStreamReader reader, ConfigurationBuilder builder) t
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ENABLED:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.clustering().hash().groups().enabled();
                else
                   builder.clustering().hash().groups().disabled();
@@ -1049,7 +1050,7 @@ private void parseAsync(XMLStreamReader reader, ConfigurationBuilder builder) th
          Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
          switch (attribute) {
             case ASYNC_MARSHALLING:
-               if (Boolean.valueOf(value).booleanValue())
+               if (Boolean.valueOf(value))
                   builder.clustering().async().asyncMarshalling();
                else
                   builder.clustering().async().syncMarshalling();
@@ -1058,13 +1059,13 @@ private void parseAsync(XMLStreamReader reader, ConfigurationBuilder builder) th
                builder.clustering().async().replQueue(Util.<ReplicationQueue> getInstance(value, cl));
                break;
             case REPL_QUEUE_INTERVAL:
-               builder.clustering().async().replQueueInterval(Long.valueOf(value).longValue());
+               builder.clustering().async().replQueueInterval(Long.valueOf(value));
                break;
             case REPL_QUEUE_MAX_ELEMENTS:
-               builder.clustering().async().replQueueMaxElements(Integer.valueOf(value).intValue());
+               builder.clustering().async().replQueueMaxElements(Integer.valueOf(value));
                break;
             case USE_REPL_QUEUE:
-               builder.clustering().async().useReplQueue(Boolean.valueOf(value).booleanValue());
+               builder.clustering().async().useReplQueue(Boolean.valueOf(value));
                break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);",2012-01-07T18:17:10Z,166
"@@ -8,10 +8,8 @@
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheStore;
 import org.infinispan.loaders.modifications.Clear;
-import org.infinispan.loaders.modifications.Commit;
 import org.infinispan.loaders.modifications.Modification;
-import org.infinispan.loaders.modifications.Prepare;
-import org.infinispan.loaders.modifications.PurgeExpired;
+import org.infinispan.loaders.modifications.ModificationsList;
 import org.infinispan.loaders.modifications.Remove;
 import org.infinispan.loaders.modifications.Store;
 import org.infinispan.marshall.StreamingMarshaller;
@@ -20,8 +18,6 @@
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.ArrayList;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -30,12 +26,12 @@
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
+import java.util.concurrent.LinkedBlockingQueue;
 import java.util.concurrent.ThreadFactory;
+import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.locks.Condition;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReadWriteLock;
 import java.util.concurrent.locks.ReentrantLock;
@@ -61,31 +57,39 @@
  *
  * @author Manik Surtani
  * @author Galder Zamarreño
+ * @author Sanne Grinovero
  * @since 4.0
  */
 public class AsyncStore extends AbstractDelegatingStore {
    private static final Log log = LogFactory.getLog(AsyncStore.class);
    private static final boolean trace = log.isTraceEnabled();
    private static final AtomicInteger threadId = new AtomicInteger(0);
    private final AtomicBoolean stopped = new AtomicBoolean(true);
+   
    private final AsyncStoreConfig asyncStoreConfig;
-
+   private Map<GlobalTransaction, List<? extends Modification>> transactions;
+   
    /**
-    * Approximate count of number of modified keys. At points, it could contain negative values.
+    * This is used as marker to shutdown the AsyncStoreCoordinator
     */
-   private final AtomicInteger count = new AtomicInteger(0);
-   private final ReentrantLock lock = new ReentrantLock();
-   private final Condition notEmpty = lock.newCondition();
-
+   private static final Modification QUIT_SIGNAL = new Clear();
+   
+   /**
+    * clear() is performed in sync by the one thread of storeCoordinator, while blocking all
+    * other threads interacting with the decorated store.
+    */
+   private final ReadWriteLock clearAllLock = new ReentrantReadWriteLock();
+   private final Lock clearAllReadLock = clearAllLock.readLock();
+   private final Lock clearAllWriteLock = clearAllLock.writeLock();
+   private final Lock stateMapLock = new ReentrantLock();
+   
    ExecutorService executor;
-   private List<Future> processorFutures;
-   private final ReadWriteLock mapLock = new ReentrantReadWriteLock();
-   private final Lock read = mapLock.readLock();
-   private final Lock write = mapLock.writeLock();
    private int concurrencyLevel;
-   @GuardedBy(""mapLock"")
+   @GuardedBy(""stateMapLock"")
    protected ConcurrentMap<Object, Modification> state;
    private ReleaseAllLockContainer lockContainer;
+   private final LinkedBlockingQueue<Modification> changesDeque = new LinkedBlockingQueue<Modification>();
+   public volatile boolean lastAsyncProcessorShutsDownExecutor = false;
 
    public AsyncStore(CacheStore delegate, AsyncStoreConfig asyncStoreConfig) {
       super(delegate);
@@ -97,77 +101,97 @@ public void init(CacheLoaderConfig config, Cache<?, ?> cache, StreamingMarshalle
       super.init(config, cache, m);
       concurrencyLevel = cache == null || cache.getConfiguration() == null ? 16 : cache.getConfiguration().getConcurrencyLevel();
       lockContainer = new ReleaseAllLockContainer(concurrencyLevel);
+      transactions = new ConcurrentHashMap<GlobalTransaction, List<? extends Modification>>(64, 0.75f, concurrencyLevel);
    }
 
    @Override
    public void store(InternalCacheEntry ed) {
-      enqueue(ed.getKey(), new Store(ed));
+      enqueue(new Store(ed));
    }
 
    @Override
    public boolean remove(Object key) {
-      enqueue(key, new Remove(key));
+      enqueue(new Remove(key));
       return true;
    }
 
    @Override
    public void clear() {
       Clear clear = new Clear();
-      enqueue(clear, clear);
+      checkNotStopped(); //check we can change the changesDeque
+      changesDeque.clear();
+      enqueue(clear);
    }
 
    @Override
-   public void purgeExpired() {
-      PurgeExpired purge = new PurgeExpired();
-      enqueue(purge, purge);
+   public void prepare(List<? extends Modification> mods, GlobalTransaction tx, boolean isOnePhase) throws CacheLoaderException {
+      if (isOnePhase) {
+         enqueueModificationsList(mods);
+      } else {
+         transactions.put(tx, mods);
+      }
    }
-
+   
    @Override
-   public void prepare(List<? extends Modification> list, GlobalTransaction tx, boolean isOnePhase) {
-      Prepare prepare = new Prepare(list, tx, isOnePhase);
-      enqueue(prepare, prepare);
+   public void rollback(GlobalTransaction tx) {
+      transactions.remove(tx);
    }
 
    @Override
    public void commit(GlobalTransaction tx) throws CacheLoaderException {
-      Commit commit = new Commit(tx);
-      enqueue(commit, commit);
+      List<? extends Modification> list = transactions.remove(tx);
+      enqueueModificationsList(list);
+   }
+   
+   protected void enqueueModificationsList(List<? extends Modification> mods) throws CacheLoaderException {
+      if (mods != null && !mods.isEmpty()) {
+         enqueue(new ModificationsList(mods));
+      }
    }
 
    @Override
    public void start() throws CacheLoaderException {
       state = newStateMap();
       log.info(""Async cache loader starting {0}"", this);
       stopped.set(false);
+      lastAsyncProcessorShutsDownExecutor = false;
       super.start();
       int poolSize = asyncStoreConfig.getThreadPoolSize();
-      executor = Executors.newFixedThreadPool(poolSize, new ThreadFactory() {
-         public Thread newThread(Runnable r) {
-            Thread t = new Thread(r, ""CoalescedAsyncStore-"" + threadId.getAndIncrement());
-            t.setDaemon(true);
-            return t;
-         }
-      });
-      processorFutures = new ArrayList<Future>(poolSize);
-      for (int i = 0; i < poolSize; i++) processorFutures.add(executor.submit(createAsyncProcessor()));
+      executor = new ThreadPoolExecutor(poolSize, poolSize, 0L, TimeUnit.MILLISECONDS,
+               // note the use of poolSize+1 as maximum workingQueue together with DiscardPolicy:
+               // this way when a new AsyncProcessor is started unnecessarily we discard it
+               // before it takes locks to perform no work
+               // this way we save memory from the executor queue, CPU, and also avoid
+               // any possible RejectedExecutionException.
+               new LinkedBlockingQueue<Runnable>(poolSize + 1),
+               new ThreadFactory() {
+                  public Thread newThread(Runnable r) {
+                     Thread t = new Thread(r, ""CoalescedAsyncStore-"" + threadId.getAndIncrement());
+                     t.setDaemon(true);
+                     return t;
+                  }
+               },
+               new ThreadPoolExecutor.DiscardPolicy()
+         );
+      startStoreCoordinator();
+   }
+
+   private void startStoreCoordinator() {
+      ExecutorService storeCoordinator = Executors.newFixedThreadPool(1);
+      storeCoordinator.execute( new AsyncStoreCoordinator() );
+      storeCoordinator.shutdown();
    }
 
    @Override
    public void stop() throws CacheLoaderException {
       stopped.set(true);
-      if (executor != null) {
-         for (Future f : processorFutures) f.cancel(true);
-         executor.shutdown();
-         try {
-            boolean terminated = executor.isTerminated();
-            while (!terminated) {
-               terminated = executor.awaitTermination(60, TimeUnit.SECONDS);
-            }
-         } catch (InterruptedException e) {
-            Thread.currentThread().interrupt();
-         }
+      try {
+         changesDeque.put(QUIT_SIGNAL);
+         executor.awaitTermination(asyncStoreConfig.getShutdownTimeout(), TimeUnit.SECONDS);
+      } catch (InterruptedException e) {
+         log.error(""Interrupted or timeout while waiting for AsyncStore worker threads to push all state to the decorated store"", e);
+         Thread.currentThread().interrupt();
       }
-      executor = null;
       super.stop();
    }
 
@@ -182,81 +206,46 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
             case REMOVE:
                super.remove(entry.getKey());
                break;
-            case CLEAR:
-               super.clear();
-               break;
-            case PURGE_EXPIRED:
-               super.purgeExpired();
-               break;
-            case PREPARE:
-               List<? extends Modification> coalesced = coalesceModificationList(((Prepare) mod).getList());
-               super.prepare(coalesced, ((Prepare) mod).getTx(), ((Prepare) mod).isOnePhase());
-               break;
-            case COMMIT:
-               super.commit(((Commit) mod).getTx());
-               break;
+            default:
+               throw new IllegalArgumentException(""Unexpected modification type "" + mod.getType());
          }
       }
    }
-
-   protected Runnable createAsyncProcessor() {
-      return new AsyncProcessor();
+   
+   protected boolean applyClear() {
+      try {
+         super.clear();
+         return true;
+      } catch (CacheLoaderException e) {
+         log.error(""Error performing clear in AsyncStore"", e);
+         return false;
+      }
    }
-
-   private List<? extends Modification> coalesceModificationList(List<? extends Modification> mods) {
-      Map<Object, Modification> keyMods = new HashMap<Object, Modification>();
-      List<Modification> coalesced = new ArrayList<Modification>();
-      for (Modification mod : mods) {
-         switch (mod.getType()) {
-            case STORE:
-               keyMods.put(((Store) mod).getStoredEntry().getKey(), mod);
-               break;
-            case CLEAR:
-               keyMods.clear(); // remove all pending key modifications
-               coalesced.add(mod); // add a clear so that future put/removes do not need to do anything
-               break;
-            case REMOVE:
-               if (!coalesced.isEmpty() && keyMods.containsKey(((Remove) mod).getKey())) {
-                  keyMods.remove(((Remove) mod).getKey()); // clear, p(k), r(k) sequence should result in no-op for k
-               } else if (coalesced.isEmpty()) {
-                  keyMods.put(((Remove) mod).getKey(), mod);
-               }
-               break;
-            default:
-               throw new IllegalArgumentException(""Unknown modification type "" + mod.getType());
-         }
+   
+   protected void delegatePurgeExpired() {
+      try {
+         super.purgeExpired();
+      } catch (CacheLoaderException e) {
+         log.error(""Error performing PurgeExpired in AsyncStore"", e);
       }
-      coalesced.addAll(keyMods.values());
-      return coalesced;
    }
 
-   private void enqueue(Object key, Modification mod) {
+   private void enqueue(Modification mod) {
       try {
-         if (stopped.get()) {
-            throw new CacheException(""AsyncStore stopped; no longer accepting more entries."");
-         }
+         checkNotStopped();
          if (trace) log.trace(""Enqueuing modification {0}"", mod);
-         Modification prev = null;
-         int c = -1;
-         boolean unlock = false;
-         try {
-            acquireLock(read);
-            unlock = true;
-            prev = state.put(key, mod); // put the key's latest state in updates
-         } finally {
-            if (unlock) read.unlock();
-         }
-         /* Increment can happen outside the lock cos worst case scenario a false not empty would 
-          * be sent if the swap and decrement happened between the put and the increment. In this 
-          * case, the corresponding processor would see the map empty and would wait again. This 
-          * means that we're allowing count to potentially go negative but that's not a problem. */
-         if (prev == null) c = count.getAndIncrement();
-         if (c == 0) signalNotEmpty();
+         changesDeque.add(mod);
       } catch (Exception e) {
          throw new CacheException(""Unable to enqueue asynchronous task"", e);
       }
    }
 
+   private void checkNotStopped() {
+      if (stopped.get()) {
+         throw new CacheException(""AsyncStore stopped; no longer accepting more entries."");
+      }
+   }
+
    private void acquireLock(Lock lock) {
       try {
          if (!lock.tryLock(asyncStoreConfig.getFlushLockTimeout(), TimeUnit.MILLISECONDS))
@@ -267,105 +256,85 @@ private void acquireLock(Lock lock) {
       }
    }
 
-   private void signalNotEmpty() {
-      lock.lock();
-      try {
-         notEmpty.signal();
-      } finally {
-         lock.unlock();
-      }
-   }
-
-   private void awaitNotEmptyOrStopped() throws InterruptedException {
-      lock.lockInterruptibly();
-      try {
-         try {
-            while (count.get() == 0) {
-               if (stopped.get()) {
-                  notEmpty.signal();
-                  return;
-               }
-               notEmpty.await();
-            }
-         } catch (InterruptedException ie) {
-            notEmpty.signal(); // propagate to a non-interrupted thread
-            throw ie;
-         }
-      } finally {
-         lock.unlock();
-      }
-   }
-
-   private int decrementAndGet(int delta) {
-      for (; ;) {
-         int current = count.get();
-         int next = current - delta;
-         if (count.compareAndSet(current, next)) return next;
-      }
-   }
-
    /**
     * Processes modifications taking the latest updates from a state map.
     */
    class AsyncProcessor implements Runnable {
-      private ConcurrentMap<Object, Modification> swap = newStateMap();
       private final Set<Object> lockedKeys = new HashSet<Object>();
+      boolean runAgainAfterWaiting = false;
 
       public void run() {
-         while (!Thread.interrupted() && !stopped.get()) {
+         clearAllReadLock.lock();
+         try {
+            innerRun();
+         } catch (Throwable t) {
+            runAgainAfterWaiting = false;
+            log.error(""Unexpected error"", t);
+         } finally {
+            clearAllReadLock.unlock();
+         }
+         if (runAgainAfterWaiting) {
             try {
-               run0();
-            }
-            catch (InterruptedException e) {
-               break;
+               Thread.sleep(10);
+            } catch (InterruptedException e) {
+               // just speedup ignoring more sleep but still make sure to store all data
             }
-         }
-
-         try {
-            if (trace) log.trace(""Process remaining batch {0}"", swap.size());
-            put(swap);
-            if (trace) log.trace(""Process remaining queued {0}"", state.size());
-            while (!state.isEmpty()) run0();
-         } catch (InterruptedException e) {
-            if (trace) log.trace(""Remaining interrupted"");
+            ensureMoreWorkIsHandled();
          }
       }
-
-      void run0() throws InterruptedException {
+      
+      private void innerRun() {
+         final ConcurrentMap<Object, Modification> swap;
          if (trace) log.trace(""Checking for modifications"");
-         boolean unlock = false;
-
          try {
-            acquireLock(write);
-            unlock = true;
-            swap = state;
-            state = newStateMap();
-
-            // This needs doing within the WL section, because if a key is in use, we need to put it back in the state
-            // map for later processing and we don't wanna do it in such way that we override a newer value that might 
-            // have been enqueued by a user thread.
-            for (Object key : swap.keySet()) {
-               boolean acquired = lockContainer.acquireLock(key, 0, TimeUnit.NANOSECONDS) != null;
-               if (trace) log.trace(""Lock for key {0} was acquired={1}"", key, acquired);
-               if (!acquired) {
-                  Modification prev = swap.remove(key);
-                  state.put(key, prev);
-               } else {
-                  lockedKeys.add(key);
+            acquireLock(stateMapLock);
+            try {
+               swap = state;
+               state = newStateMap();
+
+               // This needs to be done within the stateMapLock section, because if a key is in use,
+               // we need to put it back in the state
+               // map for later processing and we don't wanna do it in such way that we override a
+               // newer value that might
+               // have been taken already for processing by another instance of this same code.
+               // AsyncStoreCoordinator doesn't need to acquired the same lock as values put by it
+               // will never be overwritten (putIfAbsent below)
+               for (Object key : swap.keySet()) {
+                  if (trace) log.trace(""Going to process mod key: {0}"", key);
+                  boolean acquired = false;
+                  try {
+                     acquired = lockContainer.acquireLock(key, 0, TimeUnit.NANOSECONDS) != null;
+                  } catch (InterruptedException e) {
+                     log.error(""interrupted on acquireLock {0}, 0 nanoseconds!"", e);
+                     Thread.currentThread().interrupt();
+                     return;
+                  }
+                  if (trace)
+                     log.trace(""Lock for key {0} was acquired={1}"", key, acquired);
+                  if (!acquired) {
+                     Modification prev = swap.remove(key);
+                     Modification didPut = state.putIfAbsent(key, prev); // don't overwrite more recently put work
+                     if (didPut == null) {
+                        // otherwise a new job is being spawned by the arbiter, so no need to create
+                        // a new worker
+                        runAgainAfterWaiting = true;
+                     }
+                  } else {
+                     lockedKeys.add(key);
+                  }
                }
+            } finally {
+               stateMapLock.unlock();
             }
-         } finally {
-            if (unlock) write.unlock();
-         }
 
-         try {
-            int size = swap.size();
             if (swap.isEmpty()) {
-               awaitNotEmptyOrStopped();
+               if (lastAsyncProcessorShutsDownExecutor && runAgainAfterWaiting == false) {
+                  executor.shutdown();
+               }
+               return;
             } else {
-               decrementAndGet(size);
-
-               if (trace) log.trace(""Apply {0} modifications"", size);
+               if (trace)
+                  log.trace(""Apply {0} modifications"", swap.size());
                int maxRetries = 3;
                int attemptNumber = 0;
                boolean successful;
@@ -386,22 +355,12 @@ void run0() throws InterruptedException {
          }
       }
 
-      boolean put(ConcurrentMap<Object, Modification> mods) throws InterruptedException {
+      boolean put(ConcurrentMap<Object, Modification> mods) {
          try {
             AsyncStore.this.applyModificationsSync(mods);
             return true;
          } catch (Exception e) {
-            boolean isDebug = log.isDebugEnabled();
-            if (isDebug) log.debug(""Failed to process async modifications"", e);
-            Throwable cause = e;
-            while (cause != null) {
-                if (cause instanceof InterruptedException) {
-                    // 3rd party code may have cleared the thread interrupt status
-                    if (isDebug) log.debug(""Rethrowing InterruptedException"");
-                    throw (InterruptedException) cause;
-                }
-                cause = cause.getCause();
-            }
+            if (log.isDebugEnabled()) log.debug(""Failed to process async modifications"", e);
             return false;
          }
       }
@@ -410,7 +369,7 @@ boolean put(ConcurrentMap<Object, Modification> mods) throws InterruptedExceptio
    private ConcurrentMap<Object, Modification> newStateMap() {
       return new ConcurrentHashMap<Object, Modification>(64, 0.75f, concurrencyLevel);
    }
-
+   
    private static class ReleaseAllLockContainer extends ReentrantPerEntryLockContainer {
       private ReleaseAllLockContainer(int concurrencyLevel) {
          super(concurrencyLevel);
@@ -423,4 +382,112 @@ void releaseLocks(Set<Object> keys) {
          }
       }
    }
+
+   private void ensureMoreWorkIsHandled() {
+           executor.execute(new AsyncProcessor());
+   }
+   
+   private class AsyncStoreCoordinator implements Runnable {
+
+      @Override
+      public void run() {
+         while (true) {
+            try {
+               Modification take = changesDeque.take();
+               if (take == QUIT_SIGNAL) {
+                  lastAsyncProcessorShutsDownExecutor = true;
+                  ensureMoreWorkIsHandled();
+                  return;
+               }
+               else {
+                  handleSafely(take);
+               }
+            } catch (InterruptedException e) {
+               log.error(""AsyncStoreCoordinator interrupted"", e);
+               return;
+            } catch (Throwable t) {
+               log.error(""Unexpected error in AsyncStoreCoordinator thread. AsyncStore is dead!"", t);
+            }
+         }
+      }
+
+      private void handleSafely(Modification mod) {
+         try {
+            if (trace) log.trace(""taking from modification queue: {0}"", mod);
+            handle(mod, false);
+         } catch (Exception e) {
+            log.error(""Error while handling Modification in AsyncStore"", e);
+         }
+      }
+
+      private void handle(Modification mod, boolean nested) {
+         boolean asyncProcessorNeeded = false;
+         switch (mod.getType()) {
+            case STORE:
+               Store store = (Store) mod;
+               stateMapLock.lock();
+               state.put(store.getStoredEntry().getKey(), store);
+               stateMapLock.unlock();
+               asyncProcessorNeeded = true;
+               break;
+            case REMOVE:
+               Remove remove = (Remove) mod;
+               stateMapLock.lock();
+               state.put(remove.getKey(), remove);
+               stateMapLock.unlock();
+               asyncProcessorNeeded = true;
+               break;
+            case CLEAR:
+               performClear();
+               break;
+            case PURGE_EXPIRED:
+               delegatePurgeExpired();
+               break;
+            case LIST:
+               applyModificationsList((ModificationsList) mod);
+               asyncProcessorNeeded = true;
+               break;
+            default:
+               throw new IllegalArgumentException(""Unexpected modification type "" + mod.getType());
+         }
+         if (asyncProcessorNeeded && !nested) {
+            // we know when it's possible for some work to be done, starting short-lived
+            // AsyncProcessor(s) simplifies shutdown process.
+             ensureMoreWorkIsHandled();
+         }
+      }
+
+      private void applyModificationsList(ModificationsList mod) {
+         for (Modification m : mod.getList()) {
+            handle(m, true);
+         }
+      }
+
+      private void performClear() {
+         state.clear(); // cancel any other scheduled changes
+         clearAllWriteLock.lock(); // ensure no other tasks concurrently working
+         try {
+            // to acquire clearAllWriteLock we might have had to wait for N AsyncProcessor to have finished
+            // (as they have to release all clearAllReadLock),
+            // so as they might have put back some work to the state map, clear the state map again inside the writeLock:
+            state.clear();
+            if (trace) log.trace(""Performed clear operation"");
+            int maxRetries = 3;
+            int attemptNumber = 0;
+            boolean successful = false;
+            do {
+               if (attemptNumber > 0 && log.isDebugEnabled())
+                  log.debug(""Retrying clear() due to previous failure. {0} attempts left."", maxRetries - attemptNumber);
+               successful = applyClear();
+               attemptNumber++;
+            } while (!successful && attemptNumber <= maxRetries);
+            if (!successful) {
+               log.error(""Clear() operation in async store could not be performed"");
+            }
+         } finally {
+            clearAllWriteLock.unlock();
+         }
+      }
+
+   }
 }",2010-08-31T22:18:46Z,30
"@@ -42,6 +42,11 @@ public class AsyncStoreConfig extends AbstractNamedCacheConfigurationBean {
    @Dynamic
    protected Long flushLockTimeout = 5000L;
 
+   /** @configRef desc=""Timeout to stop the cache store. When the store is stopped it's possible that some modifications still need to be applied;
+    *             you likely want to set a very large timeout to make sure to not loose data."" */
+   @Dynamic
+   protected Long shutdownTimeout = 7200L;
+
    @XmlAttribute
    public Boolean isEnabled() {
       return enabled;
@@ -70,7 +75,17 @@ public Long getFlushLockTimeout() {
    public void setFlushLockTimeout(Long stateLockTimeout) {
       testImmutability(""flushLockTimeout"");
       this.flushLockTimeout = stateLockTimeout;
-   }   
+   }
+
+   @XmlAttribute
+   public Long getShutdownTimeout() {
+      return shutdownTimeout;
+   }
+
+   public void setShutdownTimeout(Long shutdownTimeout) {
+      testImmutability(""shutdownTimeout"");
+      this.shutdownTimeout = shutdownTimeout;
+   }
 
    @Override
    public AsyncStoreConfig clone() {",2010-08-31T22:18:46Z,30
"@@ -62,5 +62,10 @@ public boolean equals(Object obj) {
       Commit other = (Commit) obj;
       return tx.equals(other.tx);
    }
+   
+   @Override
+   public String toString() {
+      return ""Commit: "" + tx;
+   }
 
 }",2010-08-31T22:18:46Z,215
"@@ -8,7 +8,7 @@
  */
 public interface Modification {
    public static enum Type {
-      STORE, REMOVE, CLEAR, PURGE_EXPIRED, PREPARE, COMMIT
+      STORE, REMOVE, CLEAR, PURGE_EXPIRED, PREPARE, COMMIT, LIST
    }
 
    Type getType();",2010-08-31T22:18:46Z,216
"@@ -0,0 +1,79 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2009, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.loaders.modifications;
+
+import java.util.List;
+
+/**
+ * ModificationsList contains a List<Modification>
+ * 
+ * @author Sanne Grinovero
+ * @since 4.1
+ */
+public class ModificationsList implements Modification {
+   
+   private final List<? extends Modification> list;
+
+   public ModificationsList(List<? extends Modification> list) {
+      this.list = list;
+   }
+
+   @Override
+   public Type getType() {
+      return Modification.Type.LIST;
+   }
+
+   public List<? extends Modification> getList() {
+      return list;
+   }
+
+   @Override
+   public int hashCode() {
+      final int prime = 31;
+      int result = 1;
+      result = prime * result + ((list == null) ? 0 : list.hashCode());
+      return result;
+   }
+
+   @Override
+   public boolean equals(Object obj) {
+      if (this == obj)
+         return true;
+      if (obj == null)
+         return false;
+      if (getClass() != obj.getClass())
+         return false;
+      ModificationsList other = (ModificationsList) obj;
+      if (list == null) {
+         if (other.list != null)
+            return false;
+      } else if (!list.equals(other.list))
+         return false;
+      return true;
+   }
+   
+   @Override
+   public String toString() {
+      return ""ModificationsList: ["" + list + ""]"";
+   }
+
+}",2010-08-31T22:18:46Z,217
"@@ -80,5 +80,16 @@ public int hashCode() {
       result = 31 * result + (isOnePhase ? 1 : 0);
       return result;
    }
+   
+   @Override
+   public String toString() {
+      StringBuilder sb = new StringBuilder();
+      sb.append(""Prepare:"");
+      sb.append(tx);
+      sb.append("" isOnePhase:"");
+      sb.append(String.valueOf(isOnePhase));
+      sb.append("";["").append(list).append(""]"");
+      return sb.toString();
+   }
 
 }",2010-08-31T22:18:46Z,218
"@@ -3,7 +3,6 @@
 import java.io.IOException;
 import java.sql.SQLException;
 
-import org.apache.commons.math.stat.inference.TestUtils;
 import org.infinispan.config.CacheLoaderManagerConfig;
 import org.infinispan.config.Configuration;
 import org.infinispan.container.entries.InternalCacheEntry;
@@ -13,7 +12,6 @@
 import org.infinispan.test.SingleCacheManagerTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
-import org.testng.annotations.AfterClass;
 import org.testng.annotations.Test;
 
 /**
@@ -45,7 +43,7 @@ protected EmbeddedCacheManager createCacheManager() throws Exception {
       return TestCacheManagerFactory.createCacheManager(config);
    }
 
-   @Test (timeOut = 10000)
+   @Test(timeOut = 10000)
    public void writeOnStorage() throws IOException, ClassNotFoundException, SQLException, InterruptedException {
       cache = cacheManager.getCache(""AsyncStoreInMemory"");
       cache.put(""key1"", ""value"");
@@ -60,11 +58,6 @@ public void verifyStorageContent() throws IOException {
       assert ""value"".equals(cache.get(""key1""));
    }
    
-   @AfterClass
-   public void removeStore(){
-      TestUtils a; 
-   }
-
    public static class SlowCacheStoreConfig extends DummyInMemoryCacheStore.Cfg {
       public SlowCacheStoreConfig() {
          setCacheLoaderClassName(SlowCacheStore.class.getName());",2010-08-31T22:18:46Z,219
"@@ -45,6 +45,7 @@ protected EmbeddedCacheManager createCacheManager() throws Exception {
       return cm;
    }
 
+   @Test
    public void testRepeatedLoads() throws CacheLoaderException {
       CacheLoaderManager clm = TestingUtil.extractComponent(cache, CacheLoaderManager.class);
       ChainingCacheStore ccs = (ChainingCacheStore) clm.getCacheLoader();
@@ -66,6 +67,7 @@ public void testRepeatedLoads() throws CacheLoaderException {
       assert countingCS.numContains == 0 : ""Expected 0, was "" + countingCS.numContains;
    }
 
+   @Test
    public void testSkipCacheFlagUsage() throws CacheLoaderException {
       CacheLoaderManager clm = TestingUtil.extractComponent(cache, CacheLoaderManager.class);
       ChainingCacheStore ccs = (ChainingCacheStore) clm.getCacheLoader();",2010-08-31T22:18:46Z,220
"@@ -8,7 +8,6 @@
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
 import org.infinispan.loaders.modifications.Clear;
 import org.infinispan.loaders.modifications.Modification;
-import org.infinispan.loaders.modifications.Prepare;
 import org.infinispan.loaders.modifications.Remove;
 import org.infinispan.loaders.modifications.Store;
 import org.infinispan.test.AbstractInfinispanTest;
@@ -37,7 +36,7 @@
 import static org.infinispan.test.TestingUtil.k;
 import static org.infinispan.test.TestingUtil.v;
 
-@Test(groups = ""unit"", testName = ""loaders.decorators.AsyncTest"")
+@Test(groups = ""unit"", testName = ""loaders.decorators.AsyncTest"", sequential=true)
 public class AsyncTest extends AbstractInfinispanTest {
    private static final Log log = LogFactory.getLog(AsyncTest.class);
    AsyncStore store;
@@ -52,7 +51,7 @@ public void setUp() throws CacheLoaderException {
       asyncConfig = new AsyncStoreConfig();
       asyncConfig.setThreadPoolSize(10);
       store = new AsyncStore(underlying, asyncConfig);
-      dummyCfg = new DummyInMemoryCacheStore.Cfg();
+      dummyCfg = new DummyInMemoryCacheStore.Cfg(""AsyncStoreTests"",false);
       dummyCfg.setStore(AsyncTest.class.getName());
       store.init(dummyCfg, null, null);
       store.start();
@@ -64,6 +63,7 @@ public void tearDown() throws CacheLoaderException {
       if (store != null) store.stop();
    }
 
+   @Test(timeOut=10000)
    public void testPutRemove() throws Exception {
       final int number = 1000;
       String key = ""testPutRemove-k-"";
@@ -72,6 +72,7 @@ public void testPutRemove() throws Exception {
       doTestRemove(number, key);
    }
 
+   @Test(timeOut=10000)
    public void testPutClearPut() throws Exception {
       final int number = 1000;
       String key = ""testPutClearPut-k-"";
@@ -80,10 +81,10 @@ public void testPutClearPut() throws Exception {
       doTestClear(number, key);
       value = ""testPutClearPut-v[2]-"";
       doTestPut(number, key, value);
-
       doTestRemove(number, key);
    }
 
+   @Test(timeOut=10000)
    public void testMultiplePutsOnSameKey() throws Exception {
       final int number = 1000;
       String key = ""testMultiplePutsOnSameKey-k"";
@@ -92,6 +93,7 @@ public void testMultiplePutsOnSameKey() throws Exception {
       doTestSameKeyRemove(key);
    }
 
+   @Test(timeOut=10000)
    public void testRestrictionOnAddingToAsyncQueue() throws Exception {
       store.remove(""blah"");
 
@@ -174,17 +176,17 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          mods.add(new Remove(k1));
          GlobalTransaction tx = gtf.newGlobalTransaction(null, false);
          store.prepare(mods, tx, false);
-         barrier.await(5, TimeUnit.SECONDS);
 
-         assert 1 == localMods.size();
-         assert localMods.entrySet().iterator().next().getKey() instanceof Prepare;
+         assert 0 == localMods.size();
          assert !store.containsKey(k1);
          assert !store.containsKey(k2);
 
          store.commit(tx);
          barrier.await(5, TimeUnit.SECONDS);
          assert store.load(k2).getValue().equals(v2);
          assert !store.containsKey(k1);
+         assert 2 == localMods.size();
+         assert new Remove(k1).equals(localMods.get(k1));
       } finally {
          store.delegate.clear();
          store.stop();
@@ -246,12 +248,12 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          mods.add(new Remove(k1));
          GlobalTransaction tx = gtf.newGlobalTransaction(null, false);
          store.prepare(mods, tx, false);
-         barrier.await(5, TimeUnit.SECONDS);
+         Thread.sleep(200); //verify that work is not performed until commit
          assert 0 == storeCount.get();
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(5, TimeUnit.SECONDS); //modifications applied all at once
          assert 1 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 1 == removeCount.get();
          assert 0 == clearCount.get();
@@ -267,14 +269,14 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          mods.add(new Remove(k2));
          tx = gtf.newGlobalTransaction(null, false);
          store.prepare(mods, tx, false);
-         barrier.await(5, TimeUnit.SECONDS);
+         Thread.sleep(200); //verify that work is not performed until commit
          assert 0 == storeCount.get();
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
          barrier.await(5, TimeUnit.SECONDS);
          assert 0 == storeCount.get() : ""Store count was "" + storeCount.get();
-         assert 0 == removeCount.get();
+         assert 1 == removeCount.get();
          assert 1 == clearCount.get();
 
          storeCount.set(0);
@@ -288,7 +290,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          mods.add(new Store(InternalEntryFactory.create(k3, v3)));         
          tx = gtf.newGlobalTransaction(null, false);
          store.prepare(mods, tx, false);
-         barrier.await(5, TimeUnit.SECONDS);
+         Thread.sleep(200);
          assert 0 == storeCount.get();
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
@@ -306,14 +308,14 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          mods.add(new Remove(k1));
          tx = gtf.newGlobalTransaction(null, false);
          store.prepare(mods, tx, false);
-         barrier.await(5, TimeUnit.SECONDS);
+         Thread.sleep(200);
          assert 0 == storeCount.get();
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
          barrier.await(5, TimeUnit.SECONDS);
          assert 0 == storeCount.get() : ""Store count was "" + storeCount.get();
-         assert 0 == removeCount.get();
+         assert 1 == removeCount.get();
          assert 1 == clearCount.get();
 
          storeCount.set(0);
@@ -324,7 +326,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          mods.add(new Store(InternalEntryFactory.create(k1, v1)));         
          tx = gtf.newGlobalTransaction(null, false);
          store.prepare(mods, tx, false);
-         barrier.await(5, TimeUnit.SECONDS);
+         Thread.sleep(200);
          assert 0 == storeCount.get();
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
@@ -341,9 +343,13 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
    }
 
    private void doTestPut(int number, String key, String value) throws Exception {
-      for (int i = 0; i < number; i++) store.store(InternalEntryFactory.create(key + i, value + i));
+      for (int i = 0; i < number; i++) {
+         InternalCacheEntry cacheEntry = InternalEntryFactory.create(key + i, value + i);
+         store.store(cacheEntry);
+      }
 
-      TestingUtil.sleepRandom(1000);
+      store.stop();
+      store.start();
 
       InternalCacheEntry[] entries = new InternalCacheEntry[number];
       for (int i = 0; i < number; i++) {
@@ -360,22 +366,24 @@ private void doTestPut(int number, String key, String value) throws Exception {
                if (entry != null) {
                   assert entry.getValue().equals(value + i);
                } else {
-                  TestingUtil.sleepRandom(1000);
+                  TestingUtil.sleepThread(20, ""still waiting for key to appear: "" + key + i);
                }
             }
          }
       }
    }
 
    private void doTestSameKeyPut(int number, String key, String value) throws Exception {
-      for (int i = 0; i < number; i++)
+      for (int i = 0; i < number; i++) {
          store.store(InternalEntryFactory.create(key, value + i));
+      }
 
-      TestingUtil.sleepThread(5000);
+      store.stop();
+      store.start();
       InternalCacheEntry entry;
       boolean success = false;
       for (int i = 0; i < 120; i++) {
-         TestingUtil.sleepRandom(1000);
+         TestingUtil.sleepThread(20);
          entry = store.load(key);
          success = entry.getValue().equals(value + (number - 1));
          if (success) break;
@@ -386,7 +394,8 @@ private void doTestSameKeyPut(int number, String key, String value) throws Excep
    private void doTestRemove(int number, String key) throws Exception {
       for (int i = 0; i < number; i++) store.remove(key + i);
 
-      TestingUtil.sleepRandom(1000);
+      store.stop();//makes sure the store is flushed
+      store.start();
 
       InternalCacheEntry[] entries = new InternalCacheEntry[number];
       for (int i = 0; i < number; i++) {
@@ -396,8 +405,7 @@ private void doTestRemove(int number, String key) throws Exception {
       for (int i = 0; i < number; i++) {
          InternalCacheEntry entry = entries[i];
          while (entry != null) {
-            log.info(""Entry still not null {0}"", entry);
-            TestingUtil.sleepRandom(1000);
+            TestingUtil.sleepThread(20, ""still waiting for key to be removed: "" + key + i);
             entry = store.load(key + i);
          }
       }
@@ -407,14 +415,15 @@ private void doTestSameKeyRemove(String key) throws Exception {
       store.remove(key);
       InternalCacheEntry entry;
       do {
-         TestingUtil.sleepRandom(1000);
+         TestingUtil.sleepThread(20, ""still waiting for key to be removed: "" + key);
          entry = store.load(key);
       } while (entry != null);
    }
 
    private void doTestClear(int number, String key) throws Exception {
       store.clear();
-      TestingUtil.sleepRandom(1000);
+      store.stop();
+      store.start();
 
       InternalCacheEntry[] entries = new InternalCacheEntry[number];
       for (int i = 0; i < number; i++) {
@@ -424,8 +433,7 @@ private void doTestClear(int number, String key) throws Exception {
       for (int i = 0; i < number; i++) {
          InternalCacheEntry entry = entries[i];
          while (entry != null) {
-            log.info(""Entry still not null {0}"", entry);
-            TestingUtil.sleepRandom(1000);
+            TestingUtil.sleepThread(20, ""still waiting for key to be removed: "" + key + i);
             entry = store.load(key + i);
          }
       }",2010-08-31T22:18:46Z,221
"@@ -0,0 +1,142 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2009, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.loaders.decorators;
+
+import java.io.File;
+import java.io.IOException;
+import java.sql.SQLException;
+import java.util.HashMap;
+
+import org.infinispan.AdvancedCache;
+import org.infinispan.config.CacheLoaderManagerConfig;
+import org.infinispan.config.Configuration;
+import org.infinispan.loaders.CacheStoreConfig;
+import org.infinispan.loaders.decorators.AsyncStoreConfig;
+import org.infinispan.loaders.file.FileCacheStoreConfig;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.SingleCacheManagerTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.Assert;
+import org.testng.annotations.AfterClass;
+import org.testng.annotations.BeforeClass;
+import org.testng.annotations.Optional;
+import org.testng.annotations.Parameters;
+import org.testng.annotations.Test;
+
+/**
+ * BatchAsyncCacheStoreTest performs some additional tests on the AsyncStore
+ * but using batches.
+ * 
+ * @author Sanne Grinovero
+ * @since 4.1
+ */
+@Test(groups = ""functional"", testName = ""loaders.AsyncCacheStoreTest"")
+public class BatchAsyncCacheStoreTest extends SingleCacheManagerTest {
+
+   private final HashMap cacheCopy = new HashMap();
+
+   public BatchAsyncCacheStoreTest() {
+      cleanup = CleanupPhase.AFTER_METHOD;
+   }
+
+   @Override
+   protected EmbeddedCacheManager createCacheManager() throws Exception {
+      Configuration configuration = new Configuration();
+      configuration.setCacheMode(Configuration.CacheMode.LOCAL);
+      configuration.setInvocationBatchingEnabled(true);
+      enableTestJdbcStorage(configuration);
+      return TestCacheManagerFactory.createCacheManager(configuration);
+   }
+
+   private void enableTestJdbcStorage(Configuration configuration) throws Exception {
+      CacheStoreConfig fileStoreConfiguration = createCacheStoreConfig();
+      AsyncStoreConfig asyncStoreConfig = new AsyncStoreConfig();
+      asyncStoreConfig.setEnabled(true);
+      asyncStoreConfig.setThreadPoolSize(1);
+      fileStoreConfiguration.setAsyncStoreConfig(asyncStoreConfig);
+      CacheLoaderManagerConfig loaderManagerConfig = configuration.getCacheLoaderManagerConfig();
+      loaderManagerConfig.setPassivation(false);
+      loaderManagerConfig.setPreload(false);
+      loaderManagerConfig.setShared(true);
+      loaderManagerConfig.addCacheLoaderConfig(fileStoreConfiguration);
+   }
+
+   @Test
+   public void sequantialOvewritingInBatches() throws IOException, ClassNotFoundException, SQLException, InterruptedException {
+      cache = cacheManager.getCache();
+      AdvancedCache<Object,Object> advancedCache = cache.getAdvancedCache();
+      for (int i = 0; i < 2000;) {
+         advancedCache.startBatch();
+         putAValue(advancedCache, i++);
+         putAValue(advancedCache, i++);
+         advancedCache.endBatch(true);
+      }
+      cacheCopy.putAll(cache);
+      cache.stop();
+      cacheManager.stop();
+   }
+
+   private void putAValue(AdvancedCache<Object, Object> advancedCache, int i) {
+      String key = ""k"" + (i % 13);
+      String value = ""V"" + i;
+      advancedCache.put(key, value);
+   }
+
+   @Test(dependsOnMethods = ""sequantialOvewritingInBatches"")
+   public void indexWasStored() throws IOException {
+      cache = cacheManager.getCache();
+      assert cache.isEmpty();
+      boolean failed = false;
+      for (Object key : cacheCopy.keySet()) {
+         Object expected = cacheCopy.get(key);
+         Object actual = cache.get(key);
+         if (!expected.equals(actual)) {
+            System.out.println(""Failure on key '"" + key.toString() + ""' expected value: '"" + expected + ""' actual value: '"" + actual + ""'"");
+            failed = true;
+         }
+      }
+      Assert.assertFalse(failed);
+      Assert.assertEquals(cacheCopy.keySet().size(), cache.keySet().size(), ""have a different number of keys"");
+   }
+
+   private String tmpDirectory;
+
+   @BeforeClass
+   @Parameters( { ""basedir"" })
+   protected void setUpTempDir(@Optional(value = ""/tmp"") String basedir) {
+      tmpDirectory = TestingUtil.tmpDirectory(basedir, this);
+      new File(tmpDirectory).mkdirs();
+   }
+
+   @AfterClass
+   protected void clearTempDir() {
+      TestingUtil.recursiveFileRemove(tmpDirectory);
+   }
+
+   protected CacheStoreConfig createCacheStoreConfig() throws Exception {
+      FileCacheStoreConfig cfg = new FileCacheStoreConfig();
+      cfg.setLocation(tmpDirectory);
+      return cfg;
+   }
+
+}",2010-08-31T22:18:46Z,222
"@@ -73,10 +73,10 @@ protected Boolean initialValue() {
    @BeforeTest
    @Parameters({""basedir""})
    protected void setUpTempDir(@Optional(value = ""/tmp"") String basedir) {
-      tmpDirectory1 = basedir + TestingUtil.TEST_PATH + File.separator + ""1"" + File.separator + getClass().getSimpleName();
-      tmpDirectory2 = basedir + TestingUtil.TEST_PATH + File.separator + ""2"" + File.separator + getClass().getSimpleName();
-      tmpDirectory3 = basedir + TestingUtil.TEST_PATH + File.separator + ""3"" + File.separator + getClass().getSimpleName();
-      tmpDirectory4 = basedir + TestingUtil.TEST_PATH + File.separator + ""4"" + File.separator + getClass().getSimpleName();
+      tmpDirectory1 = basedir + File.separator + TestingUtil.TEST_PATH + File.separator + ""1"" + File.separator + getClass().getSimpleName();
+      tmpDirectory2 = basedir + File.separator + TestingUtil.TEST_PATH + File.separator + ""2"" + File.separator + getClass().getSimpleName();
+      tmpDirectory3 = basedir + File.separator + TestingUtil.TEST_PATH + File.separator + ""3"" + File.separator + getClass().getSimpleName();
+      tmpDirectory4 = basedir + File.separator + TestingUtil.TEST_PATH + File.separator + ""4"" + File.separator + getClass().getSimpleName();
    }
 
    @AfterMethod(alwaysRun = true)",2010-08-31T22:18:46Z,223
"@@ -373,10 +373,16 @@ public static boolean isCacheViewComplete(List members, Address address, int mem
     * @param sleeptime number of ms to sleep
     */
    public static void sleepThread(long sleeptime) {
+      sleepThread(sleeptime, null);
+   }
+   
+   public static void sleepThread(long sleeptime, String messageOnInterrupt) {
       try {
          Thread.sleep(sleeptime);
       }
       catch (InterruptedException ie) {
+         if (messageOnInterrupt != null)
+            log.error(messageOnInterrupt);
       }
    }
 ",2010-08-31T22:18:46Z,50
"@@ -475,7 +475,7 @@ public void handleCommitView(String cacheName, int viewId) {
    public void handleRollbackView(String cacheName, int newViewId, int committedViewId) {
       CacheViewInfo cacheViewInfo = viewsInfo.get(cacheName);
       if (cacheViewInfo == null) {
-         log.tracef(""Ignoring view rollback for unknown cache %s"", cacheName);
+         log.tracef(""Ignoring cache view rollback for unknown cache %s"", cacheName);
          return;
       }
 ",2011-10-27T11:25:21Z,224
"@@ -26,21 +26,31 @@
  * Most of the time the operation will just wait for the rehash to complete and continue,
  * but if the rehash is taking too long this exception will be thrown.
  *
- * @author Dan Berindei <dberinde@redhat.com>
+ * @author Dan Berindei <dan@infinispan.org>
  */
-public class RehashInProgressException extends CacheException {
-   public RehashInProgressException() {
+public class StateTransferInProgressException extends CacheException {
+   private final int newCacheViewId;
+
+   public StateTransferInProgressException(int newCacheViewId) {
+      this.newCacheViewId = newCacheViewId;
    }
 
-   public RehashInProgressException(Throwable cause) {
+   public StateTransferInProgressException(int newCacheViewId, Throwable cause) {
       super(cause);
+      this.newCacheViewId = newCacheViewId;
    }
 
-   public RehashInProgressException(String msg) {
+   public StateTransferInProgressException(int newCacheViewId, String msg) {
       super(msg);
+      this.newCacheViewId = newCacheViewId;
    }
 
-   public RehashInProgressException(String msg, Throwable cause) {
+   public StateTransferInProgressException(int newCacheViewId, String msg, Throwable cause) {
       super(msg, cause);
+      this.newCacheViewId = newCacheViewId;
+   }
+
+   public int getNewCacheViewId() {
+      return newCacheViewId;
    }
 }",2011-10-27T11:25:21Z,225
"@@ -23,6 +23,7 @@
 package org.infinispan.interceptors;
 
 import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.GetKeyValueCommand;
 import org.infinispan.commands.tx.CommitCommand;
@@ -45,15 +46,15 @@
 import org.infinispan.distribution.DataLocality;
 import org.infinispan.distribution.DistributionManager;
 import org.infinispan.distribution.L1Manager;
-import org.infinispan.distribution.RehashInProgressException;
+import org.infinispan.distribution.StateTransferInProgressException;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.interceptors.base.BaseRpcInterceptor;
 import org.infinispan.remoting.responses.Response;
 import org.infinispan.remoting.responses.SuccessfulResponse;
 import org.infinispan.remoting.transport.Address;
-import org.infinispan.statetransfer.StateTransferLock;
 import org.infinispan.remoting.transport.jgroups.SuspectException;
+import org.infinispan.statetransfer.StateTransferLock;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.concurrent.NotifyingFutureImpl;
 import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
@@ -275,8 +276,7 @@ public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command)
    @Override
    public Object visitLockControlCommand(TxInvocationContext ctx, LockControlCommand command) throws Throwable {
       if (ctx.isOriginLocal()) {
-         allowRehashToComplete(ctx);
-
+         allowStateTransferToComplete(ctx, command, -1);
          if (configuration.isEagerLockSingleNode()) {
             //only main data owner is locked, see: https://jira.jboss.org/browse/ISPN-615
             Map<Object, List<Address>> toMulticast = dm.locateAll(command.getKeys(), 1);
@@ -312,7 +312,7 @@ private boolean needToResendPrepare(Response r) {
    @Override
    public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command) throws Throwable {
       if (shouldInvokeRemoteTxCommand(ctx)) {
-         allowRehashToComplete(ctx);
+         allowStateTransferToComplete(ctx, command, -1);
 
          Collection<Address> preparedOn = ((LocalTxInvocationContext) ctx).getRemoteLocksAcquired();
 
@@ -365,11 +365,11 @@ private void sendCommitCommand(TxInvocationContext ctx, CommitCommand command, C
                rpcManager.invokeRemotely(resendTo, pc, true, true);
             }
          }
-      } catch (RehashInProgressException e) {
+      } catch (StateTransferInProgressException e) {
          // we are assuming the current node is also trying to start the rehash, but it can't
          // because we're holding the tx lock
          // there is no problem if some nodes already applied the commit
-         allowRehashToComplete(ctx);
+         allowStateTransferToComplete(ctx, command, e.getNewCacheViewId());
 
          if (retries > 0) {
             sendCommitCommand(ctx, command, preparedOn, retries - 1);
@@ -380,7 +380,7 @@ private void sendCommitCommand(TxInvocationContext ctx, CommitCommand command, C
          // we are assuming the current node is also trying to start the rehash, but it can't
          // because we're holding the tx lock
          // there is no problem if some nodes already applied the commit
-         allowRehashToComplete(ctx);
+         allowStateTransferToComplete(ctx, command, -1);
 
          if (retries > 0) {
             sendCommitCommand(ctx, command, preparedOn, retries - 1);
@@ -394,8 +394,8 @@ private void sendCommitCommand(TxInvocationContext ctx, CommitCommand command, C
     * If there is a pending rehash, suspend the tx lock and wait until the rehash is completed.
     * Otherwise, do nothing.
     */
-   private void allowRehashToComplete(InvocationContext ctx) throws TimeoutException, InterruptedException {
-      stateTransferLock.waitForStateTransferToEnd(ctx, null);
+   private void allowStateTransferToComplete(InvocationContext ctx, VisitableCommand command, int newCacheViewId) throws TimeoutException, InterruptedException {
+      stateTransferLock.waitForStateTransferToEnd(ctx, command, newCacheViewId);
    }
 
 
@@ -406,8 +406,7 @@ public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand comman
       boolean sync = isSynchronous(ctx);
 
       if (shouldInvokeRemoteTxCommand(ctx)) {
-         allowRehashToComplete(ctx);
-
+         allowStateTransferToComplete(ctx, command, -1);
          Collection<Address> recipients = dm.getAffectedNodes(ctx.getAffectedKeys());
          NotifyingNotifiableFuture<Object> f = null;
          if (isL1CacheEnabled && command.isOnePhaseCommit())
@@ -465,8 +464,7 @@ private Object handleWriteCommand(InvocationContext ctx, WriteCommand command, R
          if (!ctx.isInTxScope()) {
             NotifyingNotifiableFuture<Object> future = null;
             if (ctx.isOriginLocal()) {
-               allowRehashToComplete(ctx);
-
+               allowStateTransferToComplete(ctx, command, -1);
                List<Address> rec = recipientGenerator.generateRecipients();
                int numCallRecipients = rec == null ? 0 : rec.size();
                if (trace) log.tracef(""Invoking command %s on hosts %s"", command, rec);",2011-10-27T11:25:21Z,101
"@@ -23,6 +23,7 @@
 package org.infinispan.interceptors;
 
 import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.tx.RollbackCommand;
@@ -35,7 +36,7 @@
 import org.infinispan.config.Configuration;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.RehashInProgressException;
+import org.infinispan.distribution.StateTransferInProgressException;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.BaseRpcInterceptor;
 import org.infinispan.remoting.responses.Response;
@@ -73,7 +74,7 @@ public void init(StateTransferLock stateTransferLock, CommandsFactory cf) {
    public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command) throws Throwable {
       if (!ctx.isInTxScope()) throw new IllegalStateException(""This should not be possible!"");
       if (shouldInvokeRemoteTxCommand(ctx)) {
-         allowStateTransferToComplete(ctx);
+         allowStateTransferToComplete(ctx, command, -1);
          sendCommitCommand(ctx, command, 3);
       }
       return invokeNextInterceptor(ctx, command);
@@ -106,11 +107,11 @@ private void sendCommitCommand(TxInvocationContext ctx, CommitCommand command, i
                rpcManager.invokeRemotely(resendTo, pc, true, true);
             }
          }
-      } catch (RehashInProgressException e) {
+      } catch (StateTransferInProgressException e) {
          // we are assuming the current node is also trying to start the rehash, but it can't
          // because we're holding the tx lock
          // there is no problem if some nodes already applied the commit
-         allowStateTransferToComplete(ctx);
+         allowStateTransferToComplete(ctx, command, e.getNewCacheViewId());
 
          if (retries > 0) {
             sendCommitCommand(ctx, command, retries - 1);
@@ -121,7 +122,7 @@ private void sendCommitCommand(TxInvocationContext ctx, CommitCommand command, i
          // we are assuming the current node is also trying to start the rehash, but it can't
          // because we're holding the tx lock
          // there is no problem if some nodes already applied the commit
-         allowStateTransferToComplete(ctx);
+         allowStateTransferToComplete(ctx, command, -1);
 
          if (retries > 0) {
             sendCommitCommand(ctx, command, retries - 1);
@@ -135,15 +136,15 @@ private void sendCommitCommand(TxInvocationContext ctx, CommitCommand command, i
     * If there is a pending rehash, suspend the tx lock and wait until the rehash is completed.
     * Otherwise, do nothing.
     */
-   private void allowStateTransferToComplete(InvocationContext ctx) throws TimeoutException, InterruptedException {
-      stateTransferLock.waitForStateTransferToEnd(ctx, null);
+   private void allowStateTransferToComplete(InvocationContext ctx, VisitableCommand command, int newCacheViewId) throws TimeoutException, InterruptedException {
+      stateTransferLock.waitForStateTransferToEnd(ctx, command, newCacheViewId);
    }
 
    @Override
    public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand command) throws Throwable {
       Object retVal = invokeNextInterceptor(ctx, command);
       if (shouldInvokeRemoteTxCommand(ctx)) {
-         allowStateTransferToComplete(ctx);
+         allowStateTransferToComplete(ctx, command, -1);
          boolean async = configuration.getCacheMode() == Configuration.CacheMode.REPL_ASYNC;
          rpcManager.broadcastRpcCommand(command, !async, false);
       }
@@ -192,7 +193,7 @@ private Object handleCrudMethod(final InvocationContext ctx, final WriteCommand
       final Object returnValue = invokeNextInterceptor(ctx, command);
       populateCommandFlags(command, ctx);
       if (!isLocalModeForced(ctx) && command.isSuccessful() && ctx.isOriginLocal() && !ctx.isInTxScope()) {
-         allowStateTransferToComplete(ctx);
+         allowStateTransferToComplete(ctx, command, -1);
          if (ctx.isUseFutureReturnType()) {
             NotifyingNotifiableFuture<Object> future = new NotifyingFutureImpl(returnValue);
             rpcManager.broadcastRpcCommandInFuture(command, future);",2011-10-27T11:25:21Z,103
"@@ -29,7 +29,7 @@
 import org.infinispan.commands.write.ReplaceCommand;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.RehashInProgressException;
+import org.infinispan.distribution.StateTransferInProgressException;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.statetransfer.StateTransferLock;
@@ -50,61 +50,61 @@ public void injectDistributionManager(StateTransferLock stateTransferLock) {
    }
 
    @Override
-   public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand cmd) throws Throwable {
-      if (!stateTransferLock.acquireForCommand(ctx, cmd)) {
-         // TODO If the super call throws a RehashInProgressException, we should release the state transfer lock
+   public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand command) throws Throwable {
+      if (!stateTransferLock.acquireForCommand(ctx, command)) {
+         // TODO If the super call throws a StateTransferInProgressException, we should release the state transfer lock
          // to allow any pending rehash to finish and then retry the operation
-         // Then we could throw a RehashInProgressException only on remote nodes and include the view id in the
+         // Then we could throw a StateTransferInProgressException only on remote nodes and include the view id in the
          // exception message to make sure we got the right rehash
-         throw new RehashInProgressException(""Timed out waiting for the transaction lock"");
+         throw new StateTransferInProgressException(stateTransferLock.getBlockingCacheViewId(), ""Timed out waiting for the transaction lock"");
       }
       try {
-         return super.visitPrepareCommand(ctx, cmd);
+         return super.visitPrepareCommand(ctx, command);
       } finally {
-         stateTransferLock.releaseForCommand(ctx, cmd);
+         stateTransferLock.releaseForCommand(ctx, command);
       }
    }
 
    @Override
-   public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand cmd) throws Throwable {
-      if (!stateTransferLock.acquireForCommand(ctx, cmd)) {
-         throw new RehashInProgressException(""Timed out waiting for the transaction lock"");
+   public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand command) throws Throwable {
+      if (!stateTransferLock.acquireForCommand(ctx, command)) {
+         throw new StateTransferInProgressException(stateTransferLock.getBlockingCacheViewId(), ""Timed out waiting for the transaction lock"");
       }
       try {
-         return super.visitRollbackCommand(ctx, cmd);
+         return super.visitRollbackCommand(ctx, command);
       } finally {
-         stateTransferLock.releaseForCommand(ctx, cmd);
+         stateTransferLock.releaseForCommand(ctx, command);
       }
    }
 
    @Override
-   public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand cmd) throws Throwable {
-      if (!stateTransferLock.acquireForCommand(ctx, cmd)) {
-         throw new RehashInProgressException(""Timed out waiting for the transaction lock"");
+   public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command) throws Throwable {
+      if (!stateTransferLock.acquireForCommand(ctx, command)) {
+         throw new StateTransferInProgressException(stateTransferLock.getBlockingCacheViewId(), ""Timed out waiting for the transaction lock"");
       }
       try {
-         return super.visitCommitCommand(ctx, cmd);
+         return super.visitCommitCommand(ctx, command);
       } finally {
-         stateTransferLock.releaseForCommand(ctx, cmd);
+         stateTransferLock.releaseForCommand(ctx, command);
       }
    }
 
    @Override
-   public Object visitLockControlCommand(TxInvocationContext ctx, LockControlCommand cmd) throws Throwable {
-      if (!stateTransferLock.acquireForCommand(ctx, cmd)) {
-         throw new RehashInProgressException(""Timed out waiting for the transaction lock"");
+   public Object visitLockControlCommand(TxInvocationContext ctx, LockControlCommand command) throws Throwable {
+      if (!stateTransferLock.acquireForCommand(ctx, command)) {
+         throw new StateTransferInProgressException(stateTransferLock.getBlockingCacheViewId(), ""Timed out waiting for the transaction lock"");
       }
       try {
-         return super.visitLockControlCommand(ctx, cmd);
+         return super.visitLockControlCommand(ctx, command);
       } finally {
-         stateTransferLock.releaseForCommand(ctx, cmd);
+         stateTransferLock.releaseForCommand(ctx, command);
       }
    }
 
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
       if (!stateTransferLock.acquireForCommand(ctx, command)) {
-         throw new RehashInProgressException(""Timed out waiting for the transaction lock"");
+         throw new StateTransferInProgressException(stateTransferLock.getBlockingCacheViewId(), ""Timed out waiting for the transaction lock"");
       }
       try {
          return super.visitPutKeyValueCommand(ctx, command);
@@ -116,7 +116,7 @@ public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand
    @Override
    public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
       if (!stateTransferLock.acquireForCommand(ctx, command)) {
-         throw new RehashInProgressException(""Timed out waiting for the transaction lock"");
+         throw new StateTransferInProgressException(stateTransferLock.getBlockingCacheViewId(), ""Timed out waiting for the transaction lock"");
       }
       try {
          return super.visitRemoveCommand(ctx, command);
@@ -128,7 +128,7 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
    @Override
    public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
       if (!stateTransferLock.acquireForCommand(ctx, command)) {
-         throw new RehashInProgressException(""Timed out waiting for the transaction lock"");
+         throw new StateTransferInProgressException(stateTransferLock.getBlockingCacheViewId(), ""Timed out waiting for the transaction lock"");
       }
       try {
          return super.visitReplaceCommand(ctx, command);
@@ -140,7 +140,7 @@ public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command)
    @Override
    public Object visitClearCommand(InvocationContext ctx, ClearCommand command) throws Throwable {
       if (!stateTransferLock.acquireForCommand(ctx, command)) {
-         throw new RehashInProgressException(""Timed out waiting for the transaction lock"");
+         throw new StateTransferInProgressException(stateTransferLock.getBlockingCacheViewId(), ""Timed out waiting for the transaction lock"");
       }
       try {
          return super.visitClearCommand(ctx, command);
@@ -152,7 +152,7 @@ public Object visitClearCommand(InvocationContext ctx, ClearCommand command) thr
    @Override
    public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
       if (!stateTransferLock.acquireForCommand(ctx, command)) {
-         throw new RehashInProgressException(""Timed out waiting for the transaction lock"");
+         throw new StateTransferInProgressException(stateTransferLock.getBlockingCacheViewId(), ""Timed out waiting for the transaction lock"");
       }
       try {
          return super.visitPutMapCommand(ctx, command);",2011-10-27T11:25:21Z,226
"@@ -239,7 +239,7 @@ private Collection<Object> keys(Collection<InternalCacheEntry> state) {
    /**
     * @return <code>true</code> if the state transfer started successfully, <code>false</code> otherwise
     */
-   public boolean startStateTransfer(int viewId, Collection<Address> members, boolean initialView) throws TimeoutException, InterruptedException, PendingStateTransferException {
+   public boolean startStateTransfer(int viewId, Collection<Address> members, boolean initialView) throws TimeoutException, InterruptedException, StateTransferCancelledException {
       if (newView == null || viewId != newView.getViewId()) {
          log.debugf(""Cannot start state transfer for view %d, we should be starting state transfer for view %s"", viewId, newView);
          return false;
@@ -259,7 +259,7 @@ public void endStateTransfer() {
 
    public abstract CacheStore getCacheStoreForStateTransfer();
 
-   public void pushStateToNode(NotifyingNotifiableFuture<Object> stateTransferFuture, int viewId, Address target, Collection<InternalCacheEntry> state) throws PendingStateTransferException {
+   public void pushStateToNode(NotifyingNotifiableFuture<Object> stateTransferFuture, int viewId, Address target, Collection<InternalCacheEntry> state) throws StateTransferCancelledException {
       if (leavers.contains(target)) {
          log.debugf(""Not pushing state to node %s since it has already left"", target);
          return;
@@ -278,12 +278,6 @@ public boolean isLastViewId(int viewId) {
       return viewId == newView.getViewId();
    }
 
-   protected void checkIfCancelled(int viewId) throws PendingStateTransferException {
-      if (viewId != newView.getViewId()) {
-         throw new PendingStateTransferException();
-      }
-   }
-
    @Override
    public void prepareView(CacheView pendingView, CacheView committedView) throws Exception {
       log.tracef(""Received new cache view: %s %s"", configuration.getName(), pendingView);
@@ -299,12 +293,37 @@ public void prepareView(CacheView pendingView, CacheView committedView) throws E
 
    @Override
    public void commitView(int viewId) {
+      if (stateTransferTask == null) {
+         if (viewId == oldView.getViewId()) {
+            log.tracef(""Ignoring commit for cache view %d as we have already committed it"", viewId);
+            return;
+         } else {
+            throw new IllegalArgumentException(String.format(""Cannot commit view %d, we are at view %d"",
+                  viewId, oldView.getViewId()));
+         }
+      }
+
       stateTransferTask.commitStateTransfer();
+      stateTransferTask = null;
       endStateTransfer();
    }
 
    @Override
    public void rollbackView(int committedViewId) {
+      if (stateTransferTask == null) {
+         if (committedViewId == oldView.getViewId()) {
+            log.tracef(""Ignoring rollback for cache view %d as we don't have a state transfer in progress"",
+                  committedViewId);
+            return;
+         } else {
+            throw new IllegalArgumentException(String.format(""Cannot rollback to view %d, we are at view %d"",
+                  committedViewId, oldView.getViewId()));
+         }
+      }
+
+      stateTransferTask.cancelStateTransfer();
+      stateTransferTask = null;
+
       // TODO Use the new view id
       newView = oldView;
       chNew = chOld;",2011-10-27T11:25:21Z,227
"@@ -26,6 +26,7 @@
 import org.infinispan.notifications.cachelistener.CacheNotifier;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.util.Util;
 import org.infinispan.util.concurrent.AggregatingNotifyingFutureImpl;
 import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
@@ -56,8 +57,16 @@ public abstract class BaseStateTransferTask {
    protected final ConsistentHash chOld;
    protected final ConsistentHash chNew;
    protected final boolean initialView;
+   private long stateTransferStartMillis;
 
-   public BaseStateTransferTask(BaseStateTransferManagerImpl stateTransferManager, RpcManager rpcManager, StateTransferLock stateTransferLock, CacheNotifier cacheNotifier, Configuration configuration, DataContainer dataContainer, Collection<Address> members, int newViewId, ConsistentHash chNew, ConsistentHash chOld, boolean initialView) {
+   private boolean running;
+   private boolean cancelled;
+   private final Object lock = new Object();
+
+   public BaseStateTransferTask(BaseStateTransferManagerImpl stateTransferManager, RpcManager rpcManager,
+                                StateTransferLock stateTransferLock, CacheNotifier cacheNotifier,
+                                Configuration configuration, DataContainer dataContainer, Collection<Address> members,
+                                int newViewId, ConsistentHash chNew, ConsistentHash chOld, boolean initialView) {
       this.stateTransferLock = stateTransferLock;
       this.initialView = initialView;
       this.stateTransferManager = stateTransferManager;
@@ -71,21 +80,82 @@ public BaseStateTransferTask(BaseStateTransferManagerImpl stateTransferManager,
       this.chOld = chOld;
    }
 
-   protected abstract void performStateTransfer() throws Exception;
+   public void performStateTransfer() throws Exception {
+      stateTransferStartMillis = System.currentTimeMillis();
+      synchronized (lock) {
+         running = true;
+      }
+
+      try {
+         doPerformStateTransfer();
+      } finally {
+         synchronized (lock) {
+            running = false;
+            lock.notifyAll();
+         }
+      }
+   }
+
+   public abstract void doPerformStateTransfer() throws Exception;
+
+   public void commitStateTransfer() {
+      if (running)
+         throw new IllegalStateException(""State transfer has not finished, cannot commit"");
+
+      try {
+         stateTransferLock.unblockNewTransactions(newViewId);
+      } catch (Exception e) {
+         log.errorUnblockingTransactions(e);
+      }
+      stateTransferManager.endStateTransfer();
+      log.debugf(""Node %s completed state transfer for view %d in %s!"", self, newViewId,
+            Util.prettyPrintTime(System.currentTimeMillis() - stateTransferStartMillis));
+   }
+
+   public void cancelStateTransfer() {
+      synchronized (lock) {
+         cancelled = true;
+         while (running) {
+            try {
+               lock.wait();
+            } catch (InterruptedException e) {
+               // restore the interrupted flag
+               Thread.currentThread().interrupt();
+               break;
+            }
+         }
+      }
+
+      try {
+         stateTransferLock.unblockNewTransactions(newViewId);
+      } catch (Exception e) {
+         log.errorUnblockingTransactions(e);
+      }
+      log.debugf(""Node %s cancelled state transfer for view %d after %s!"", self, newViewId,
+            Util.prettyPrintTime(System.currentTimeMillis() - stateTransferStartMillis));
+   }
 
-   protected abstract void commitStateTransfer();
 
    protected void pushState(Map<Address, Collection<InternalCacheEntry>> states)
-         throws InterruptedException, ExecutionException, PendingStateTransferException, TimeoutException {
+         throws InterruptedException, ExecutionException, StateTransferCancelledException, TimeoutException {
       NotifyingNotifiableFuture<Object> stateTransferFuture = new AggregatingNotifyingFutureImpl(null, states.size());
       for (Map.Entry<Address, Collection<InternalCacheEntry>> entry : states.entrySet()) {
+         checkIfCancelled();
          final Address target = entry.getKey();
          Collection<InternalCacheEntry> state = entry.getValue();
          stateTransferManager.pushStateToNode(stateTransferFuture, newViewId, target, state);
       }
 
       // wait to see if all servers received the new state
       stateTransferFuture.get(configuration.getRehashRpcTimeout(), TimeUnit.MILLISECONDS);
-      log.debugf(""Node finished pushing data for rehash %d."", newViewId);
+      log.debugf(""Node finished pushing data for cache views %d."", newViewId);
    }
+
+   protected void checkIfCancelled() throws StateTransferCancelledException {
+      synchronized (lock) {
+         if (cancelled)
+            throw new StateTransferCancelledException();
+      }
+   }
+
 }",2011-10-27T11:25:21Z,228
"@@ -31,7 +31,6 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
-import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -70,7 +69,6 @@ public class DistributedStateTransferTask extends BaseStateTransferTask {
    private List<Object> keysToRemove;
    private Collection<Address> oldCacheSet;
    private Collection<Address> newCacheSet;
-   private long stateTransferStartMillis;
 
    public DistributedStateTransferTask(RpcManager rpcManager, Configuration configuration, DataContainer dataContainer,
                                        DistributedStateTransferManagerImpl stateTransferManager,
@@ -88,11 +86,10 @@ public DistributedStateTransferTask(RpcManager rpcManager, Configuration configu
 
 
    @Override
-   protected void performStateTransfer() throws Exception {
+   public void doPerformStateTransfer() throws Exception {
       if (!stateTransferManager.startStateTransfer(newViewId, members, initialView))
          return;
 
-      stateTransferStartMillis = System.currentTimeMillis();
       if (log.isDebugEnabled())
          log.debugf(""Commencing rehash %d on node: %s. Before start, data container had %d entries"",
                newViewId, self, dataContainer.size());
@@ -102,7 +99,7 @@ protected void performStateTransfer() throws Exception {
 
       // Don't need to log anything, all transactions will be blocked
       //distributionManager.getTransactionLogger().enable();
-      stateTransferLock.blockNewTransactions();
+      stateTransferLock.blockNewTransactions(newViewId);
 
       if (trace) {
          log.tracef(""Rebalancing: chOld = %s, chNew = %s"", chOld, chNew);
@@ -122,7 +119,7 @@ protected void performStateTransfer() throws Exception {
             rebalance(ice.getKey(), ice, numOwners, chOld, chNew, null, states, keysToRemove);
          }
 
-         stateTransferManager.checkIfCancelled(newViewId);
+         checkIfCancelled();
 
          // Only fetch the data from the cache store if the cache store is not shared
          CacheStore cacheStore = stateTransferManager.getCacheStoreForStateTransfer();
@@ -134,7 +131,7 @@ protected void performStateTransfer() throws Exception {
             if (trace) log.trace(""No cache store or cache store is shared, not rebalancing stored keys"");
          }
 
-         stateTransferManager.checkIfCancelled(newViewId);
+         checkIfCancelled();
 
          // Now for each server S in states.keys(): push states.get(S) to S via RPC
          pushState(states);
@@ -154,14 +151,7 @@ public void commitStateTransfer() {
          cacheNotifier.notifyDataRehashed(oldCacheSet, newCacheSet, newViewId, false);
       }
 
-      try {
-         stateTransferLock.unblockNewTransactions();
-      } catch (Exception e) {
-         log.errorUnblockingTransactions(e);
-      }
-      stateTransferManager.endStateTransfer();
-      log.debugf(""Node %s completed rehash for view %d in %s!"", self, newViewId,
-            Util.prettyPrintTime(System.currentTimeMillis() - stateTransferStartMillis));
+      super.commitStateTransfer();
    }
 
 ",2011-10-27T11:25:21Z,229
"@@ -30,7 +30,6 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
-import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -75,19 +74,17 @@ public ReplicatedStateTransferTask(RpcManager rpcManager, Configuration configur
 
 
    @Override
-   protected void performStateTransfer() throws Exception {
+   public void doPerformStateTransfer() throws Exception {
       if (!stateTransferManager.startStateTransfer(newViewId, members, initialView))
          return;
 
-      stateTransferStartMillis = System.currentTimeMillis();
       if (log.isDebugEnabled())
          log.debugf(""Commencing state transfer %d on node: %s. Before start, data container had %d entries"",
                newViewId, self, dataContainer.size());
-      boolean unblockTransactions = true;
 
       // Don't need to log anything, all transactions will be blocked
       //distributionManager.getTransactionLogger().enable();
-      stateTransferLock.blockNewTransactions();
+      stateTransferLock.blockNewTransactions(newViewId);
 
       Set<Address> joiners = chOld != null ? MembershipArithmetic.getMembersJoined(chOld.getCaches(), chNew.getCaches()) : chNew.getCaches();
       if (joiners.isEmpty()) {
@@ -126,18 +123,6 @@ protected void performStateTransfer() throws Exception {
       }
    }
 
-   public void commitStateTransfer() {
-      try {
-         stateTransferLock.unblockNewTransactions();
-      } catch (Exception e) {
-         log.errorUnblockingTransactions(e);
-      }
-      stateTransferManager.endStateTransfer();
-
-      log.debugf(""Node %s completed rehash for view %d in %s!"", self, newViewId,
-            Util.prettyPrintTime(System.currentTimeMillis() - stateTransferStartMillis));
-   }
-
 
    /**
     * Computes the list of old and new servers for a given key K and value V. Adds (K, V) to the <code>states</code> map",2011-10-27T11:25:21Z,230
"@@ -22,5 +22,5 @@
 /**
  * Thrown when a state transfer is interrupted because there is another state transfer pending.
  */
-public class PendingStateTransferException extends StateTransferException {
+public class StateTransferCancelledException extends StateTransferException {
 }",2011-10-27T11:25:21Z,231
"@@ -18,7 +18,7 @@
  */
 package org.infinispan.statetransfer;
 
-import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
@@ -45,7 +45,7 @@
  * }
  * </code>
  *
- * @author Dan Berindei <dberinde@redhat.com>
+ * @author Dan Berindei &lt;dan@infinispan.org&gt;
  * @since 5.1
  */
 @Scope(Scopes.NAMED_CACHE)
@@ -72,11 +72,13 @@ public interface StateTransferLock {
    void releaseForCommand(TxInvocationContext ctx, LockControlCommand cmd);
 
 
-   void blockNewTransactions() throws InterruptedException;
+   void blockNewTransactions(int cacheViewId) throws InterruptedException;
 
-   void unblockNewTransactions() throws InterruptedException;
+   void unblockNewTransactions(int cacheViewId) throws InterruptedException;
 
    boolean areNewTransactionsBlocked();
 
-   void waitForStateTransferToEnd(InvocationContext ctx, ReplicableCommand command) throws TimeoutException, InterruptedException;
+   int getBlockingCacheViewId();
+
+   void waitForStateTransferToEnd(InvocationContext ctx, VisitableCommand command, int newCacheViewId) throws TimeoutException, InterruptedException;
 }",2011-10-27T11:25:21Z,122
"@@ -18,81 +18,95 @@
  */
 package org.infinispan.statetransfer;
 
-import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.CacheException;
+import org.infinispan.commands.AbstractVisitor;
+import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.tx.RollbackCommand;
+import org.infinispan.commands.write.ClearCommand;
+import org.infinispan.commands.write.PutKeyValueCommand;
+import org.infinispan.commands.write.PutMapCommand;
+import org.infinispan.commands.write.RemoveCommand;
+import org.infinispan.commands.write.ReplaceCommand;
 import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.config.Configuration;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.util.concurrent.ReclosableLatch;
+import org.infinispan.transaction.LockingMode;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
+import java.util.concurrent.atomic.AtomicInteger;
 
 /**
- * A transaction logger to log ongoing transactions in an efficient and thread-safe manner while a rehash is going on.
+ * This class implements a specialized lock that allows the state transfer process (which is not a single thread)
+ * to block new write commands for the duration of the state transfer.
  * <p/>
- * Transaction logs can then be replayed after the state transferred during a rehash has been written.
+ * At the same time the block call will not return until any running write commands have finished executing.
+ * <p/>
+ * Write commands in a transaction scope don't actually write anything, so they are ignored. Lock commands on
+ * the other hand, both explicit and implicit, are considered as write commands for the purpose of this lock.
+ * <p/>
+ * Commit commands, rollback commands and unlock commands are special in that letting them proceed may speed up other
+ * running commands, so they are allowed to proceed as long as there are any running write commands. Commit is also
+ * a write command, so the block call will wait until all commit commands have finished.
  *
  * @author Manik Surtani
- * @author Dan Berindei <dberinde@redhat.com>
- * @since 4.0
+ * @author Dan Berindei &lt;dan@infinispan.org&gt;
+ * @since 5.1
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
    private static final boolean trace = log.isTraceEnabled();
-
-   // This lock is used to block new transactions during rehash
-   // Write commands must acquire the read lock for the duration of the command
-   // We acquire the write lock to block new transactions
-   // That means we wait for pending write commands to finish, and we might have to wait a lot if
-   // a command is deadlocked
-   // TODO Find a way to interrupt all transactions waiting for answers from remote nodes, instead
-   // of waiting for all of them to finish
-   // Could also suspend the tx lock during any key lock operation > 1s (configurable)
-   // but we would need to retry the whole command after the consistent hash has been changed
-   private ReentrantReadWriteLock txLock = new ReentrantReadWriteLock();
-   private ReclosableLatch txLockLatch = new ReclosableLatch(true);
-
+   private static final int NO_BLOCKING_CACHE_VIEW = -1;
+
+   // TODO Find a way to interrupt all transactions waiting for answers from remote nodes or waiting on key locks
+   // TODO Reuse the ReentrantReadWriteLock's Sync and put all the state in one volatile
+   private AtomicInteger runningWritesCount = new AtomicInteger(0);
+   private volatile boolean writesShouldBlock;
+   private volatile boolean writesBlocked;
+   private ThreadLocal<Boolean> traceThreadWrites = new ThreadLocal<Boolean>();
+   private int blockingCacheViewId = NO_BLOCKING_CACHE_VIEW;
+   // blockingCacheViewId, writesShouldBlock and writesBlocked should only be modified while holding lock and always in this order
+   private final Object lock = new Object();
+
+   // stored configuration options
+   private boolean stateTransferEnabled;
+   private boolean pessimisticLocking;
    private long lockTimeout;
-   private boolean eagerLockingEnabled;
 
    public StateTransferLockImpl() {
    }
 
    @Inject
    public void injectDependencies(Configuration config) {
-      this.lockTimeout = config.getRehashWaitTime();
+      stateTransferEnabled = (config.getCacheMode().isDistributed() && config.isRehashEnabled())
+            || (config.getCacheMode().isReplicated() && config.isStateTransferEnabled());
+      pessimisticLocking = config.isEagerLockingSingleNodeInUse() || config.getTransactionLockingMode() == LockingMode.PESSIMISTIC;
+      lockTimeout = config.getRehashWaitTime();
    }
 
    @Override
    public void releaseForCommand(InvocationContext ctx, WriteCommand command) {
-      // for transactions the real work starts with the prepare command, so don't log anything here
-      if (ctx.isInTxScope() && !eagerLockingEnabled)
-         return;
-
-      if (!ctx.hasFlag(Flag.SKIP_LOCKING))
-         releaseLockForTx();
+      if (shouldAcquireLock(ctx, command))
+         releaseLockForWrite();
    }
 
    @Override
    public void releaseForCommand(TxInvocationContext ctx, PrepareCommand command) {
-      if (!ctx.hasFlag(Flag.SKIP_LOCKING))
-         releaseLockForTx();
+      if (shouldAcquireLock(ctx, command))
+         releaseLockForWrite();
    }
 
    @Override
    public void releaseForCommand(TxInvocationContext ctx, CommitCommand command) {
-      if (!ctx.hasFlag(Flag.SKIP_LOCKING))
-         releaseLockForTx();
+      if (shouldAcquireLock(ctx, command))
+         releaseLockForWrite();
    }
 
    @Override
@@ -102,34 +116,32 @@ public void releaseForCommand(TxInvocationContext ctx, RollbackCommand command)
 
    @Override
    public void releaseForCommand(TxInvocationContext ctx, LockControlCommand command) {
-      if (!command.isUnlock())
-         releaseLockForTx();
+      if (shouldAcquireLock(ctx, command))
+         releaseLockForWrite();
    }
 
    @Override
    public boolean acquireForCommand(InvocationContext ctx, WriteCommand command) throws InterruptedException, TimeoutException {
-      // for transactions the real work starts with the prepare command, so don't block here
-      if ((ctx.isInTxScope() && !eagerLockingEnabled) || ctx.hasFlag(Flag.SKIP_LOCKING))
+      if (!shouldAcquireLock(ctx, command))
          return true;
 
-      return acquireLockForTx(ctx);
+      return acquireLockForWriteCommand(ctx);
    }
 
    @Override
    public boolean acquireForCommand(TxInvocationContext ctx, PrepareCommand command) throws InterruptedException, TimeoutException {
-      if (ctx.hasFlag(Flag.SKIP_LOCKING))
+      if (!shouldAcquireLock(ctx, command))
          return true;
 
-      return acquireLockForTx(ctx);
+      return acquireLockForWriteCommand(ctx);
    }
 
    @Override
    public boolean acquireForCommand(TxInvocationContext ctx, CommitCommand command) throws InterruptedException, TimeoutException {
-      if (!ctx.hasFlag(Flag.SKIP_LOCKING)) {
-         if (!acquireLockForTx(ctx))
-            return false;
-      }
-      return true;
+      if (!shouldAcquireLock(ctx, command))
+         return true;
+
+      return acquireLockForCommitCommand(ctx);
    }
 
    @Override
@@ -139,117 +151,303 @@ public boolean acquireForCommand(TxInvocationContext ctx, RollbackCommand comman
    }
 
    @Override
-   public boolean acquireForCommand(TxInvocationContext ctx, LockControlCommand cmd) throws TimeoutException, InterruptedException {
-      if (cmd.isUnlock())
+   public boolean acquireForCommand(TxInvocationContext ctx, LockControlCommand command) throws TimeoutException, InterruptedException {
+      if (!shouldAcquireLock(ctx, command))
          return true;
 
-      return acquireLockForTx(ctx);
+      return acquireLockForWriteCommand(ctx);
+   }
+
+
+   private boolean shouldAcquireLock(InvocationContext ctx, WriteCommand command) {
+      // For transactions with optimistic locking the real work starts with the prepare command, so don't block here.
+      // With pessimistic locking an implicit lock command is created, but the invocation skips some interceptors
+      // so we need to block for write commands as well.
+      return !(ctx.isInTxScope() && !pessimisticLocking) && !ctx.hasFlag(Flag.SKIP_LOCKING);
+   }
+
+   private boolean shouldAcquireLock(TxInvocationContext ctx, PrepareCommand command) {
+      return !ctx.hasFlag(Flag.SKIP_LOCKING);
+   }
+
+   private boolean shouldAcquireLock(TxInvocationContext ctx, CommitCommand command) {
+      return !ctx.hasFlag(Flag.SKIP_LOCKING);
+   }
+
+   private boolean shouldAcquireLock(TxInvocationContext ctx, RollbackCommand command) {
+      return false;
+   }
+
+   private boolean shouldAcquireLock(TxInvocationContext ctx, LockControlCommand command) {
+      return !command.isUnlock();
    }
 
+
    @Override
-   public void waitForStateTransferToEnd(InvocationContext ctx, ReplicableCommand cmd) throws TimeoutException, InterruptedException {
-      if (areNewTransactionsBlocked()) {
-         if (releaseLockForTx()) {
-            acquireLockForTx(ctx);
+   public void waitForStateTransferToEnd(InvocationContext ctx, VisitableCommand command, int newCacheViewId) throws TimeoutException, InterruptedException {
+      // if state transfer is disabled we never have to wait
+      if (!stateTransferEnabled)
+         return;
+
+      // in the most common case there we don't know anything about a state transfer in progress so we return immediately
+      // it's ok to access blockingCacheViewId without a lock here, in the worst case scenario we do the lock below
+      if (!writesShouldBlock && newCacheViewId <= blockingCacheViewId)
+         return;
+
+      boolean shouldSuspendLock;
+      try {
+         shouldSuspendLock = (Boolean)command.acceptVisitor(ctx, new ShouldAcquireLockVisitor());
+      } catch (Throwable throwable) {
+         throw new CacheException(""Unexpected exception"", throwable);
+      }
+
+      if (shouldSuspendLock) {
+         log.tracef(""Suspending shared state transfer lock to allow state transfer to start (and end)"");
+         releaseLockForWrite();
+
+         // we got a newer cache view id from a remote node, so we know it will be installed on this node as well
+         // even if the cache view installation is cancelled, the rollback will advance the view id so we won't wait forever
+         if (blockingCacheViewId < newCacheViewId) {
+            long end = System.currentTimeMillis() + lockTimeout;
+            long timeout = lockTimeout;
+            synchronized (lock) {
+               while (timeout >= 0 && blockingCacheViewId < newCacheViewId) {
+                  if (trace) log.tracef(""We are waiting for cache view %d, right now we have %d"", newCacheViewId, blockingCacheViewId);
+                  lock.wait(timeout);
+                  timeout = end - System.currentTimeMillis();
+               }
+            }
          }
+
+         acquireLockForWriteCommand(ctx);
       }
    }
 
    @Override
-   public void blockNewTransactions() throws InterruptedException {
-      if (!txLock.isWriteLockedByCurrentThread()) {
-         log.debug(""Blocking new transactions"");
-         if (trace) log.tracef(""Acquiring exclusive state transfer shared lock, shared holders: %d"", txLock.getReadLockCount());
-         txLockLatch.close();
-         // we want to ensure that all the modifications that passed through the tx gate have ended
-         txLock.writeLock().lockInterruptibly();
-         log.trace(""Acquired state transfer lock in exclusive mode"");
-         // need to unlock here because the unlock call may arrive on a different thread
-         txLock.writeLock().unlock();
-      } else {
-         if (trace) log.debug(""New transactions were not unblocked by the previous rehash"");
+   public void blockNewTransactions(int cacheViewId) throws InterruptedException {
+      log.debugf(""Blocking new write commands for cache view %d"", cacheViewId);
+
+      synchronized (lock) {
+         writesShouldBlock = true;
+         if (writesBlocked == true)
+            throw new IllegalStateException(""Trying to block write commands but they are already blocked"");
+
+         // TODO Add a timeout parameter
+         while (runningWritesCount.get() != 0) {
+            lock.wait();
+         }
+         writesBlocked = true;
+         blockingCacheViewId = cacheViewId;
       }
+      log.tracef(""New write commands blocked"");
    }
 
    @Override
-   public void unblockNewTransactions() {
-      log.debug(""Unblocking new transactions"");
-      // only for lock commands
-      txLockLatch.open();
+   public void unblockNewTransactions(int cacheViewId) {
+      synchronized (lock) {
+         if (!writesBlocked)
+            throw new IllegalStateException(String.format(""Trying to unblock write commands for cache view %d but they were not blocked"", cacheViewId));
+         if (cacheViewId != blockingCacheViewId && blockingCacheViewId != NO_BLOCKING_CACHE_VIEW)
+            throw new IllegalStateException(String.format(""Trying to unblock write commands for cache view %d, but they were blocked with view id %d"",
+                  cacheViewId, blockingCacheViewId));
+         writesShouldBlock = false;
+         writesBlocked = false;
+         lock.notifyAll();
+      }
+      log.debugf(""Unblocked write commands for cache view %d"", cacheViewId);
    }
 
    @Override
    public boolean areNewTransactionsBlocked() {
-      try {
-         return !txLockLatch.await(0, TimeUnit.MILLISECONDS);
-      } catch (InterruptedException e) {
-         Thread.currentThread().interrupt();
+      return writesShouldBlock;
+   }
+
+   @Override
+   public int getBlockingCacheViewId() {
+      return blockingCacheViewId;
+   }
+
+   private boolean acquireLockForWriteCommand(InvocationContext ctx) throws InterruptedException, TimeoutException {
+      // first we handle the fast path, when writes are not blocked
+      if (acquireLockForWriteNoWait()) return true;
+
+      // When the command is being replicated, the caller already holds the tx lock for read on the
+      // origin since DistributionInterceptor is above DistTxInterceptor in the interceptor chain.
+      // In order to allow the rehashing thread on the origin to obtain the tx lock for write on the
+      // origin, we never wait for the state transfer lock on remote nodes.
+      // The originator should wait for the state transfer to end and retry the command
+      if (!ctx.isOriginLocal())
          return false;
+
+      // A state transfer is in progress, wait for it to end
+      long timeout = lockTimeout;
+      long endTime = System.currentTimeMillis() + lockTimeout;
+      synchronized (lock) {
+         while (true) {
+            // wait for the unblocker thread to notify us
+            lock.wait(timeout);
+
+            if (acquireLockForWriteNoWait())
+               return true;
+
+            // retry, unless the timeout expired
+            timeout = endTime - System.currentTimeMillis();
+            if (timeout < 0)
+               return false;
+         }
       }
    }
 
-   private boolean acquireLockForTx(InvocationContext ctx) throws InterruptedException, TimeoutException {
-      // hold the read lock to ensure the rehash process waits for the tx to end
-      // first try with 0 timeout, in case a rehash is not in progress
-      if (txLockLatch.await(0, TimeUnit.MILLISECONDS)) {
-         if (txLock.readLock().tryLock(0, TimeUnit.MILLISECONDS)) {
-            if (trace) log.tracef(""Acquired shared state transfer shared lock, remaining holders: %d"", txLock.getReadLockCount());
+   private boolean acquireLockForWriteNoWait() {
+      // Because we use multiple volatile variables for the state this involves a lot of volatile reads
+      // (at least 2 reads of writesShouldBlock, 1 read+write of runningWritesCount)
+      // With one state variable the fast path should go down to 1 read + 1 cas
+      if (!writesShouldBlock) {
+         int previousWrites = runningWritesCount.getAndIncrement();
+         // someone could have blocked new writes, check again
+         if (!writesShouldBlock) {
+            if (trace) {
+               if (traceThreadWrites.get() == Boolean.TRUE)
+                  log.error(""Trying to acquire state transfer shared lock, but this thread already has it"", new Exception());
+               traceThreadWrites.set(Boolean.TRUE);
+               log.tracef(""Acquired shared state transfer shared lock, total holders: %d"", runningWritesCount.get());
+            }
             return true;
          }
+
+         // roll back the runningWritesCount, we didn't get the lock
+         runningWritesCount.decrementAndGet();
       }
+      return false;
+   }
+
+   // Duplicated acquireLockForWriteCommand to allow commits while writesShouldBlock == true but writesBlocked == false
+   private boolean acquireLockForCommitCommand(InvocationContext ctx) throws InterruptedException, TimeoutException {
+      // first we handle the fast path, when writes are not blocked
+      if (acquireLockForCommitNoWait()) return true;
 
       // When the command is being replicated, the caller already holds the tx lock for read on the
       // origin since DistributionInterceptor is above DistTxInterceptor in the interceptor chain.
       // In order to allow the rehashing thread on the origin to obtain the tx lock for write on the
-      // origin, we only lock on the remote nodes with 0 timeout.
+      // origin, we never wait for the state transfer lock on remote nodes.
+      // The originator should wait for the state transfer to end and retry the command
       if (!ctx.isOriginLocal())
          return false;
 
-      // A rehash may be in progress, wait for it to end
-      // But another transaction may have obtained the tx lock and be waiting on one of the keys locked by us
-      // So if we have any locks wait for a much shorter amount of time
-      // We do a separate wait here because we don't want to call ctx.getLockedKeys() all the time
-      boolean hasAcquiredLocks = ctx.getLockedKeys().size() > 0;
-      long timeout = hasAcquiredLocks ? lockTimeout / 100 : lockTimeout;
-      long endTime = System.currentTimeMillis() + timeout;
-      while (true) {
-         // first check the latch
-         if (!txLockLatch.await(timeout, TimeUnit.MILLISECONDS))
-            return false;
-
-         // hold the read lock to ensure the rehash process waits for the tx to end
-         if (txLock.readLock().tryLock(0, TimeUnit.MILLISECONDS)) {
-            if (trace) log.tracef(""Acquired shared state transfer shared lock, remaining holders: %d"", txLock.getReadLockCount());
+      // A state transfer is in progress, wait for it to end
+      // A commit command should never fail on the originator, so wait forever
+      synchronized (lock) {
+         while (true) {
+            // wait for the unblocker thread to notify us
+            lock.wait();
+
+            if (acquireLockForCommitNoWait())
+               return true;
+         }
+      }
+   }
+
+   private boolean acquireLockForCommitNoWait() {
+      // Because we use multiple volatile for the state this involves a lot of volatile reads
+      // (at least 1 read of writesShouldBlock, 1 read+write of runningWritesCount)
+      if (!writesBlocked) {
+         int previousWrites = runningWritesCount.getAndIncrement();
+         // if there were no other write commands running someone could have blocked new writes
+         // check the local first to skip a volatile read on writesBlocked
+         if (previousWrites != 0 || !writesBlocked) {
+            if (trace) {
+               if (traceThreadWrites.get() == Boolean.TRUE)
+                  log.error(""Trying to acquire state transfer shared lock, but this thread already has it"", new Exception());
+               traceThreadWrites.set(Boolean.TRUE);
+               log.tracef(""Acquired shared state transfer shared lock (for commit), total holders: %d"", runningWritesCount.get());
+            }
             return true;
          }
 
-         // the rehashing thread has acquired the write lock between our latch check and our read lock attempt
-         // retry, unless the timeout expired
-         timeout = endTime - System.currentTimeMillis();
-         if (timeout < 0)
-            return false;
+         // roll back the runningWritesCount, we didn't get the lock
+         runningWritesCount.decrementAndGet();
       }
+      return false;
    }
 
-   private boolean releaseLockForTx() {
-      int holdCount = txLock.getReadHoldCount();
-      if (holdCount > 1)
-         throw new IllegalStateException(""Transaction lock should not be acquired more than once by any thread"");
-      if (holdCount == 1) {
-         if (trace) log.tracef(""Releasing shared state transfer shared lock, remaining holders: %d"", txLock.getReadLockCount());
-         txLock.readLock().unlock();
-         return true;
-      } else {
-         log.trace(""Transaction lock was not previously previously acquired by this thread, not releasing"");
-         return false;
+   private void releaseLockForWrite() {
+      if (trace) {
+         if (traceThreadWrites.get() != Boolean.TRUE)
+            log.error(""Trying to release state transfer shared lock without acquiring it first"", new Exception());
+         traceThreadWrites.set(null);
+      }
+      int remainingWrites = runningWritesCount.decrementAndGet();
+      if (remainingWrites < 0) {
+         throw new IllegalStateException(""Trying to release state transfer shared lock without acquiring it first"");
+      } else if (remainingWrites == 0) {
+         synchronized (lock) {
+            lock.notifyAll();
+         }
       }
+
+      if (trace) log.tracef(""Released shared state transfer shared lock, remaining holders: %d"", remainingWrites);
    }
 
 
    @Override
    public String toString() {
-      return ""TransactionLoggerImpl{"" +
-            ""transactions blocked="" + areNewTransactionsBlocked() +
+      return ""StateTransferLockImpl{"" +
+            ""runningWritesCount="" + runningWritesCount +
+            "", writesShouldBlock="" + writesShouldBlock +
+            "", writesBlocked="" + writesBlocked +
+            "", blockingCacheViewId="" + blockingCacheViewId +
             '}';
    }
+
+   private class ShouldAcquireLockVisitor extends AbstractVisitor {
+      @Override
+      public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand command) throws Throwable {
+         return shouldAcquireLock(ctx, command);
+      }
+
+      @Override
+      public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand command) throws Throwable {
+         return shouldAcquireLock(ctx, command);
+      }
+
+      @Override
+      public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command) throws Throwable {
+         return shouldAcquireLock(ctx, command);
+      }
+
+      @Override
+      public Object visitLockControlCommand(TxInvocationContext ctx, LockControlCommand command) throws Throwable {
+         return shouldAcquireLock(ctx, command);
+      }
+
+      @Override
+      public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
+         return shouldAcquireLock(ctx, command);
+      }
+
+      @Override
+      public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
+         return shouldAcquireLock(ctx, command);
+      }
+
+      @Override
+      public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
+         return shouldAcquireLock(ctx, command);
+      }
+
+      @Override
+      public Object visitClearCommand(InvocationContext ctx, ClearCommand command) throws Throwable {
+         return shouldAcquireLock(ctx, command);
+      }
+
+      @Override
+      public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
+         return shouldAcquireLock(ctx, command);
+      }
+
+      @Override
+      protected Object handleDefault(InvocationContext ctx, VisitableCommand command) throws Throwable {
+         return Boolean.FALSE;
+      }
+   }
 }",2011-10-27T11:25:21Z,123
"@@ -0,0 +1,133 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2010 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.config.Configuration;
+import org.infinispan.distribution.MagicKey;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.transaction.LocalTransaction;
+import org.infinispan.transaction.TransactionCoordinator;
+import org.infinispan.transaction.TransactionTable;
+import org.testng.annotations.Test;
+
+@Test(testName = ""lock.StaleLocksWithCommitDuringStateTransferTest"", groups = ""functional"")
+@CleanupAfterMethod
+public class StaleLocksWithCommitDuringStateTransferTest extends MultipleCacheManagersTest {
+
+   public static final int BLOCKING_CACHE_VIEW_ID = 1000;
+   Cache<MagicKey, String> c1, c2;
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      Configuration cfg = TestCacheManagerFactory.getDefaultConfiguration(true, Configuration.CacheMode.DIST_SYNC);
+      cfg.setLockAcquisitionTimeout(100);
+      cfg.setCacheStopTimeout(100);
+      EmbeddedCacheManager cm1 = TestCacheManagerFactory.createClusteredCacheManager(cfg);
+      EmbeddedCacheManager cm2 = TestCacheManagerFactory.createClusteredCacheManager(cfg);
+      registerCacheManager(cm1, cm2);
+      c1 = cm1.getCache();
+      c2 = cm2.getCache();
+   }
+
+   public void testRollbackLocalFailure() throws Exception {
+      doTest(false, true);
+   }
+
+   public void testCommitLocalFailure() throws Exception {
+      doTest(true, true);
+   }
+
+   public void testRollbackRemoteFailure() throws Exception {
+      doTest(false, false);
+   }
+
+   public void testCommitRemoteFailure() throws Exception {
+      doTest(true, false);
+   }
+
+   private void doTest(boolean commit, boolean failOnOriginator) throws Exception {
+      MagicKey k1 = new MagicKey(c1, ""k1"");
+      MagicKey k2 = new MagicKey(c2, ""k2"");
+
+      tm(c1).begin();
+      c1.put(k1, ""v1"");
+      c1.put(k2, ""v2"");
+
+      // We split the transaction commit in two phases by calling the TransactionCoordinator methods directly
+      TransactionTable txTable = TestingUtil.extractComponent(c1, TransactionTable.class);
+      TransactionCoordinator txCoordinator = TestingUtil.extractComponent(c1, TransactionCoordinator.class);
+
+      // Execute the prepare on both nodes
+      LocalTransaction localTx = txTable.getLocalTransaction(tm(c1).getTransaction());
+      txCoordinator.prepare(localTx);
+
+      // Before calling commit we block transactions on one of the nodes to simulate a state transfer
+      final StateTransferLock blockFirst = TestingUtil.extractComponent(failOnOriginator ? c1 : c2, StateTransferLock.class);
+      final StateTransferLock blockSecond = TestingUtil.extractComponent(failOnOriginator ? c2 : c1, StateTransferLock.class);
+      blockFirst.blockNewTransactions(1000);
+
+      // Schedule the unblock on another thread since the main thread will be busy with the commit call
+      Thread worker = new Thread(""RehasherSim,StaleLocksWithCommitDuringStateTransferTest"") {
+         @Override
+         public void run() {
+            try {
+               // should be much larger than the lock acquisition timeout
+               Thread.sleep(1000);
+               blockSecond.blockNewTransactions(BLOCKING_CACHE_VIEW_ID);
+               blockFirst.unblockNewTransactions(BLOCKING_CACHE_VIEW_ID);
+               blockSecond.unblockNewTransactions(BLOCKING_CACHE_VIEW_ID);
+            } catch (InterruptedException e) {
+               log.errorf(e, ""Error blocking/unblocking transactions"");
+            }
+         }
+      };
+      worker.start();
+
+      try {
+         // finally commit or rollback the transaction
+         if (commit) {
+            txCoordinator.commit(localTx, false);
+         } else {
+            txCoordinator.rollback(localTx);
+         }
+
+         // make the transaction manager forget about our tx so that we don't get rollback exceptions in the log
+         tm(c1).suspend();
+      } finally {
+         // don't leak threads
+         worker.join();
+      }
+
+      // test that we don't leak locks
+      assertNotLocked(c1, k1);
+      assertNotLocked(c2, k1);
+      assertNotLocked(c1, k2);
+      assertNotLocked(c2, k2);
+   }
+}
+",2011-10-27T11:25:21Z,232
"@@ -63,8 +63,7 @@
    <FD_SOCK/>
    <FD_ALL/>
    <BARRIER />
-   <pbcast.NAKACK use_stats_for_retransmission=""false""
-                   exponential_backoff=""0""
+   <pbcast.NAKACK  exponential_backoff=""0""
                    use_mcast_xmit=""true""
                    retransmit_timeout=""300,600,1200""
                    discard_delivered_msgs=""true""/>",2011-09-26T16:30:50Z,233
"@@ -64,8 +64,7 @@
    <FD_SOCK/>
    <FD_ALL/>   
    <BARRIER />
-   <pbcast.NAKACK use_stats_for_retransmission=""false""
-                   exponential_backoff=""0""
+   <pbcast.NAKACK  exponential_backoff=""0""
                    use_mcast_xmit=""true""
                    retransmit_timeout=""50,300,600,1200""
                    discard_delivered_msgs=""true""/>",2011-09-26T16:30:50Z,234
"@@ -60,8 +60,7 @@
     <FD_ALL />
     <VERIFY_SUSPECT timeout=""1500""  />
     <BARRIER />
-    <pbcast.NAKACK use_stats_for_retransmission=""false""
-                   use_mcast_xmit=""true"" gc_lag=""0""
+    <pbcast.NAKACK use_mcast_xmit=""true"" gc_lag=""0""
                    retransmit_timeout=""100,300,600,1200""
                    discard_delivered_msgs=""true""/>
     <UNICAST timeout=""300,600,1200""/>",2011-09-26T16:30:50Z,235
"@@ -61,8 +61,7 @@
     <FD_ALL/>
     <VERIFY_SUSPECT timeout=""1500""  />
     <BARRIER />
-    <pbcast.NAKACK use_stats_for_retransmission=""false""
-                   use_mcast_xmit=""true"" gc_lag=""0""
+    <pbcast.NAKACK use_mcast_xmit=""true"" gc_lag=""0""
                    retransmit_timeout=""100,300,600,1200""
                    discard_delivered_msgs=""true""/>
     <UNICAST timeout=""300,600,1200""/>",2011-09-26T16:30:50Z,236
"@@ -57,8 +57,7 @@
     <FD_ALL interval=""2000"" timeout=""5000"" />
     <VERIFY_SUSPECT timeout=""500""  />
     <BARRIER />
-    <pbcast.NAKACK use_stats_for_retransmission=""false""
-                   use_mcast_xmit=""false"" gc_lag=""0""
+    <pbcast.NAKACK use_mcast_xmit=""false"" gc_lag=""0""
                    retransmit_timeout=""100,300,600,1200""
                    discard_delivered_msgs=""true"" />
     <UNICAST2 timeout=""300,600,1200"" />",2011-09-26T16:30:50Z,237
"@@ -61,9 +61,6 @@ public abstract class AbstractConfigurationBean implements CloneableConfiguratio
    protected AbstractConfigurationBean() {
    }
    
-   public void accept(ConfigurationBeanVisitor v){
-       v.visit(this);      
-   }
 
    /**
     * Safely converts a String to upper case.",2009-09-11T01:37:44Z,238
"@@ -21,8 +21,28 @@
  */
 package org.infinispan.config;
 
-import java.lang.reflect.Method;
-
+import org.infinispan.config.Configuration.AsyncType;
+import org.infinispan.config.Configuration.BooleanAttributeType;
+import org.infinispan.config.Configuration.ClusteringType;
+import org.infinispan.config.Configuration.CustomInterceptorsType;
+import org.infinispan.config.Configuration.DeadlockDetectionType;
+import org.infinispan.config.Configuration.EvictionType;
+import org.infinispan.config.Configuration.ExpirationType;
+import org.infinispan.config.Configuration.HashType;
+import org.infinispan.config.Configuration.L1Type;
+import org.infinispan.config.Configuration.LockingType;
+import org.infinispan.config.Configuration.StateRetrievalType;
+import org.infinispan.config.Configuration.SyncType;
+import org.infinispan.config.Configuration.TransactionType;
+import org.infinispan.config.Configuration.UnsafeType;
+import org.infinispan.config.GlobalConfiguration.FactoryClassWithPropertiesType;
+import org.infinispan.config.GlobalConfiguration.GlobalJmxStatisticsType;
+import org.infinispan.config.GlobalConfiguration.SerializationType;
+import org.infinispan.config.GlobalConfiguration.ShutdownType;
+import org.infinispan.config.GlobalConfiguration.TransportType;
+import org.infinispan.loaders.CacheLoaderConfig;
+import org.infinispan.loaders.decorators.AsyncStoreConfig;
+import org.infinispan.loaders.decorators.SingletonStoreConfig;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -48,47 +68,117 @@
  */
 public abstract class AbstractConfigurationBeanVisitor implements ConfigurationBeanVisitor {
 
-    protected transient Log log = LogFactory.getLog(getClass());
-
-    private Method findVisitMethod(AbstractConfigurationBean bean) throws Exception {
-        Class<?> cl = bean.getClass();
-        while (!cl.equals(AbstractConfigurationBean.class)) {
-            try {
-                return this.getClass().getDeclaredMethod(""visit"", new Class[] { cl });
-            } catch (NoSuchMethodException ex) {
-                cl = cl.getSuperclass();
-            }
-        }
-        // Check through interfaces for matching method
-        Class<?>[] interfaces = bean.getClass().getInterfaces();
-        for (int i = 0; i < interfaces.length; i++) {
-            try {
-                return this.getClass().getDeclaredMethod(""visit"", new Class[] { interfaces[i] });
-            } catch (NoSuchMethodException ex) {
-            }
-        }
-        return null;
-    }
-
-    public void visit(AbstractConfigurationBean bean) {
-        Method m = null;
-        try {
-            m = findVisitMethod(bean);
-        } catch (Exception e) {
-            log.warn(""Could not reflect visit method for bean "" + bean, e);
-        }
-        if (m == null) {
-            defaultVisit(bean);
-        } else {
-            try {
-                m.invoke(this, new Object[] { bean });
-            } catch (Exception e) {
-                log.warn(""Invocation for visitor method "" + m + "" on bean "" + bean
-                                + "" has thrown exception"", e);               
-            }
-        }
-    }
-
-    public void defaultVisit(AbstractConfigurationBean c) {}
+   protected transient Log log = LogFactory.getLog(getClass());
+
+   public void visitInfinispanConfiguration(InfinispanConfiguration bean) {
+   }
+   
+   public void visitAsyncStoreConfig(AsyncStoreConfig bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitAsyncType(AsyncType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitBooleanAttributeType(BooleanAttributeType bean) {
+      defaultVisit(bean);
+
+   }
+
+   public void visitCacheLoaderConfig(CacheLoaderConfig bean) {
+
+   }
+
+   public void visitCacheLoaderManagerConfig(CacheLoaderManagerConfig bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitClusteringType(ClusteringType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitConfiguration(Configuration bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitCustomInterceptorsType(CustomInterceptorsType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitDeadlockDetectionType(DeadlockDetectionType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitEvictionType(EvictionType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitExpirationType(ExpirationType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitFactoryClassWithPropertiesType(FactoryClassWithPropertiesType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitGlobalConfiguration(GlobalConfiguration bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitGlobalJmxStatisticsType(GlobalJmxStatisticsType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitHashType(HashType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitL1Type(L1Type bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitLockingType(LockingType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitSerializationType(SerializationType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitShutdownType(ShutdownType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitSingletonStoreConfig(SingletonStoreConfig bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitStateRetrievalType(StateRetrievalType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitSyncType(SyncType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitTransactionType(TransactionType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitTransportType(TransportType bean) {
+      defaultVisit(bean);
+   }
+
+   public void visitUnsafeType(UnsafeType bean) {
+      defaultVisit(bean);
+   }
+   
+   public void visitCustomInterceptorConfig(CustomInterceptorConfig bean) {
+      defaultVisit(bean);
+   }
+
+   public void defaultVisit(AbstractConfigurationBean c) {
+   }
 
 }",2009-09-11T01:37:44Z,238
"@@ -148,14 +148,13 @@ public boolean equals(Object obj) {
       }
       return false;
    }
-   
-    @Override
-    public void accept(ConfigurationBeanVisitor v) {
-        super.accept(v);
-        for (CacheLoaderConfig clc : cacheLoaderConfigs) {
-            ((AbstractConfigurationBean) clc).accept(v);
-        }
-    }
+       
+   public void accept(ConfigurationBeanVisitor v) {
+      for (CacheLoaderConfig clc : cacheLoaderConfigs) {
+         clc.accept(v);
+      }
+      v.visitCacheLoaderManagerConfig(this);
+   }
 
    @Override
    public int hashCode() {",2009-09-11T01:37:44Z,239
"@@ -538,21 +538,20 @@ public long getRehashWaitTime() {
    //   OVERRIDDEN METHODS
    // ------------------------------------------------------------------------------------------------------------
 
-   @Override
-   public void accept(ConfigurationBeanVisitor v) {        
-       super.accept(v);
-       clustering.accept(v);
-       customInterceptors.accept(v);
-       deadlockDetection.accept(v);
-       eviction.accept(v);
-       expiration.accept(v);
-       invocationBatching.accept(v);
-       jmxStatistics.accept(v);
-       lazyDeserialization.accept(v);
-       loaders.accept(v);
-       locking.accept(v);
-       transaction.accept(v);
-       unsafe.accept(v);
+   public void accept(ConfigurationBeanVisitor v) {      
+      clustering.accept(v);
+      customInterceptors.accept(v);
+      deadlockDetection.accept(v);
+      eviction.accept(v);
+      expiration.accept(v);
+      invocationBatching.accept(v);
+      jmxStatistics.accept(v);
+      lazyDeserialization.accept(v);
+      loaders.accept(v);
+      locking.accept(v);
+      transaction.accept(v);
+      unsafe.accept(v);
+      v.visitConfiguration(this);
    }
 
    @Override
@@ -701,6 +700,10 @@ public TransactionType(String transactionManagerLookupClass) {
          this.transactionManagerLookupClass = transactionManagerLookupClass;
       }
       
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitTransactionType(this);
+      }
+
       public TransactionType() {
          this.transactionManagerLookupClass = GenericTransactionManagerLookup.class.getName();
       }
@@ -797,6 +800,11 @@ public void setLockAcquisitionTimeout(Long lockAcquisitionTimeout) {
       }
 
     
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitLockingType(this);
+      }
+
+
       @XmlAttribute
       public void setIsolationLevel(IsolationLevel isolationLevel) {
          testImmutability(""isolationLevel"");
@@ -910,14 +918,13 @@ public ClusteringType clone() throws CloneNotSupportedException {
          return dolly;
       }
       
-      @Override
-      public void accept(ConfigurationBeanVisitor v) {        
-          super.accept(v);
+      public void accept(ConfigurationBeanVisitor v) {                  
           async.accept(v);
           hash.accept(v);
           l1.accept(v);
           stateRetrieval.accept(v);
           sync.accept(v);
+          v.visitClusteringType(this);
       }
 
       @Override
@@ -1018,6 +1025,10 @@ private AsyncType(boolean readFromXml) {
          this.readFromXml = readFromXml;
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitAsyncType(this);
+      }
+
       @Override
       public boolean equals(Object o) {
          if (this == o) return true;
@@ -1099,6 +1110,10 @@ public void setLifespan(Long lifespan) {
          this.lifespan = lifespan;
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitExpirationType(this);         
+      }
+
       @XmlAttribute
       public void setMaxIdle(Long maxIdle) {
          testImmutability(""maxIdle"");
@@ -1151,6 +1166,10 @@ public void setWakeUpInterval(Long wakeUpInterval) {
          this.wakeUpInterval = wakeUpInterval;
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitEvictionType(this);
+      }
+
       @XmlAttribute
       public void setStrategy(EvictionStrategy strategy) {
          testImmutability(""strategy"");
@@ -1212,6 +1231,10 @@ public void setFetchInMemoryState(Boolean fetchInMemoryState) {
          this.fetchInMemoryState = fetchInMemoryState;
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitStateRetrievalType(this);
+      }
+
       @XmlAttribute
       public void setTimeout(Long timeout) {
          testImmutability(""timeout"");
@@ -1261,6 +1284,10 @@ public void setReplTimeout(Long replTimeout) {
          this.replTimeout = replTimeout;
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitSyncType(this);
+      }
+
       @Override
       public boolean equals(Object o) {
          if (this == o) return true;
@@ -1313,6 +1340,10 @@ public void setConsistentHashClass(String consistentHashClass) {
          this.consistentHashClass = consistentHashClass;
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitHashType(this);
+      }
+
       @XmlAttribute
       public void setNumOwners(Integer numOwners) {
          testImmutability(""numOwners"");
@@ -1384,6 +1415,10 @@ public void setEnabled(Boolean enabled) {
          this.enabled = enabled;
       }
       
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitL1Type(this);
+      }
+
       @XmlAttribute
       public void setLifespan(Long lifespan) {
          testImmutability(""lifespan"");
@@ -1441,6 +1476,10 @@ public void setEnabled(Boolean enabled) {
          this.enabled = enabled;
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitBooleanAttributeType(this);
+      }
+
       @Override
       public boolean equals(Object o) {
          if (this == o) return true;
@@ -1483,6 +1522,10 @@ public void setEnabled(Boolean enabled) {
          this.enabled = enabled;
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitDeadlockDetectionType(this);
+      }
+
       @XmlAttribute
       public void setSpinDuration(Long spinDuration) {
          testImmutability(""spinDuration"");
@@ -1532,6 +1575,10 @@ public void setUnreliableReturnValues(Boolean unreliableReturnValues) {
          this.unreliableReturnValues = unreliableReturnValues;
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitUnsafeType(this);
+      }
+
       @Override
       public boolean equals(Object o) {
          if (this == o) return true;
@@ -1576,13 +1623,16 @@ public CustomInterceptorsType clone() throws CloneNotSupportedException {
          }
          return dolly;
       }
+            
+      public void accept(ConfigurationBeanVisitor v) {
+         for (CustomInterceptorConfig i : customInterceptors) {            
+            i.accept(v);
+         }
+         v.visitCustomInterceptorsType(this);
+      }
       
-      @Override
-      public void accept(ConfigurationBeanVisitor v) {        
-          super.accept(v);
-          for (CustomInterceptorConfig cic : customInterceptors) {
-            cic.accept(v);
-        }
+      public List<CustomInterceptorConfig> getCustomInterceptors(){
+         return customInterceptors;
       }
 
       @Override",2009-09-11T01:37:44Z,160
"@@ -21,6 +21,29 @@
  */
 package org.infinispan.config;
 
+import org.infinispan.config.Configuration.AsyncType;
+import org.infinispan.config.Configuration.BooleanAttributeType;
+import org.infinispan.config.Configuration.ClusteringType;
+import org.infinispan.config.Configuration.CustomInterceptorsType;
+import org.infinispan.config.Configuration.DeadlockDetectionType;
+import org.infinispan.config.Configuration.EvictionType;
+import org.infinispan.config.Configuration.ExpirationType;
+import org.infinispan.config.Configuration.HashType;
+import org.infinispan.config.Configuration.L1Type;
+import org.infinispan.config.Configuration.LockingType;
+import org.infinispan.config.Configuration.StateRetrievalType;
+import org.infinispan.config.Configuration.SyncType;
+import org.infinispan.config.Configuration.TransactionType;
+import org.infinispan.config.Configuration.UnsafeType;
+import org.infinispan.config.GlobalConfiguration.FactoryClassWithPropertiesType;
+import org.infinispan.config.GlobalConfiguration.GlobalJmxStatisticsType;
+import org.infinispan.config.GlobalConfiguration.SerializationType;
+import org.infinispan.config.GlobalConfiguration.ShutdownType;
+import org.infinispan.config.GlobalConfiguration.TransportType;
+import org.infinispan.loaders.CacheLoaderConfig;
+import org.infinispan.loaders.decorators.AsyncStoreConfig;
+import org.infinispan.loaders.decorators.SingletonStoreConfig;
+
 /**
  * ConfigurationBeanVisitor implementations are passed through InfinispanConfiguration object tree
  * visiting each configuration element of InfinispanConfiguration instance.
@@ -36,15 +59,60 @@
  * @see AbstractConfigurationBeanVisitor
  * @since 4.0
  */
-public interface ConfigurationBeanVisitor {
-
-   void visit(AbstractConfigurationBean bean);
+public interface ConfigurationBeanVisitor { 
+   
+   void visitInfinispanConfiguration(InfinispanConfiguration bean);
+   
+   void visitGlobalConfiguration(GlobalConfiguration bean);
+   
+   void visitFactoryClassWithPropertiesType(FactoryClassWithPropertiesType bean);
+   
+   void visitGlobalJmxStatisticsType(GlobalJmxStatisticsType bean);
+   
+   void visitSerializationType(SerializationType bean);
+   
+   void visitShutdownType(ShutdownType bean);
+   
+   void visitTransportType(TransportType bean);
+   
+   void visitConfiguration(Configuration bean);
+   
+   void visitAsyncType(AsyncType bean);
+   
+   void visitBooleanAttributeType(BooleanAttributeType bean);
+   
+   void visitClusteringType(ClusteringType bean);
+   
+   void visitCustomInterceptorsType(CustomInterceptorsType bean);
+   
+   void visitDeadlockDetectionType(DeadlockDetectionType bean);
+   
+   void visitEvictionType(EvictionType bean);
+   
+   void visitExpirationType(ExpirationType bean);
+   
+   void visitHashType(HashType bean);
+   
+   void visitL1Type(L1Type bean);
+   
+   void visitLockingType(LockingType bean);
+   
+   void visitStateRetrievalType(StateRetrievalType bean);
+   
+   void visitSyncType(SyncType bean);
+   
+   void visitTransactionType(TransactionType bean);
+   
+   void visitUnsafeType(UnsafeType bean);
+   
+   void visitCacheLoaderManagerConfig(CacheLoaderManagerConfig bean);
+   
+   void visitCacheLoaderConfig(CacheLoaderConfig bean);
+   
+   void visitSingletonStoreConfig(SingletonStoreConfig bean);
+   
+   void visitAsyncStoreConfig(AsyncStoreConfig bean);
 
-   /**
-    * Signals end of traversal over InfinispanConfiguration instance 
-    * 
-    * @param infinispanConfiguration
-    */
-   void traversalCompleted(InfinispanConfiguration infinispanConfiguration);
+   void visitCustomInterceptorConfig(CustomInterceptorConfig customInterceptorConfig);   
 
 }",2009-09-11T01:37:44Z,160
"@@ -32,21 +32,15 @@
  * @since 4.0
  */
 public class ConfigurationValidatingVisitor extends AbstractConfigurationBeanVisitor {
-   private SingletonStoreConfig ssc = null;
    private TransportType tt = null;
 
-   public void visit(SingletonStoreConfig ssc) {
-      this.ssc = ssc;
+   public void visitSingletonStoreConfig(SingletonStoreConfig ssc) {
+      if (tt == null) {
+         throw new ConfigurationException(""Singleton store configured without transport being configured"");
+      }
    }
-
-   public void visit(TransportType tt) {
+   
+   public void visitTransportType(TransportType tt) {
       this.tt = tt;
    }
-
-   public void traversalCompleted(InfinispanConfiguration infinispanConfiguration) {
-      if (ssc != null && tt == null) {
-         throw new ConfigurationException(""Singleton store configured without transport being configured for ""
-                           + infinispanConfiguration);
-      }
-   }
 }",2009-09-11T01:37:44Z,160
"@@ -336,4 +336,8 @@ protected String uc(String s) {
    enum Position {
       FIRST,LAST;
    }
+
+   public void accept(ConfigurationBeanVisitor v) {
+      v.visitCustomInterceptorConfig(this);
+   }
 }",2009-09-11T01:37:44Z,240
"@@ -330,17 +330,16 @@ public void setDistributedSyncTimeout(long distributedSyncTimeout) {
       transport.distributedSyncTimeout = distributedSyncTimeout;
    }
    
-    @Override
     public void accept(ConfigurationBeanVisitor v) {        
-        super.accept(v);
         asyncListenerExecutor.accept(v);
         asyncTransportExecutor.accept(v);
         evictionScheduledExecutor.accept(v);
         globalJmxStatistics.accept(v);
         replicationQueueScheduledExecutor.accept(v);
         serialization.accept(v);
         shutdown.accept(v);
-        transport.accept(v);        
+        transport.accept(v);   
+        v.visitGlobalConfiguration(this);
     }
 
 @Override
@@ -466,6 +465,10 @@ public FactoryClassWithPropertiesType(String factory) {
          this.factory = factory;
       }   
       
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitFactoryClassWithPropertiesType(this);
+      }
+
       public FactoryClassWithPropertiesType() {
          super();
          this.factory = """";
@@ -512,6 +515,10 @@ public TransportType() {
          transportClass = JGroupsTransport.class.getName();
       }
       
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitTransportType(this);
+      }
+
       public TransportType(String transportClass) {
          super();
          this.transportClass = transportClass;
@@ -567,6 +574,10 @@ public SerializationType() {
          super();
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitSerializationType(this);
+      }
+
       @XmlAttribute
       public void setMarshallerClass(String marshallerClass) {
          testImmutability(""marshallerClass"");
@@ -605,6 +616,10 @@ public void setEnabled(Boolean enabled) {
          this.enabled = enabled;
       }
 
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitGlobalJmxStatisticsType(this);
+      }
+
       @XmlAttribute
       public void setJmxDomain(String jmxDomain) {
          testImmutability(""jmxDomain"");
@@ -639,11 +654,15 @@ public static class ShutdownType extends AbstractConfigurationBeanWithGCR {
       public void setHookBehavior(ShutdownHookBehavior hookBehavior) {
          testImmutability(""hookBehavior"");
          this.hookBehavior = hookBehavior;
+      }
+
+      public void accept(ConfigurationBeanVisitor v) {
+         v.visitShutdownType(this);
       }               
    }
 }
 
-class AbstractConfigurationBeanWithGCR extends AbstractConfigurationBean{
+abstract class AbstractConfigurationBeanWithGCR extends AbstractConfigurationBean{
 
    GlobalComponentRegistry gcr = null;
    ",2009-09-11T01:37:44Z,12
"@@ -257,8 +257,8 @@ public void accept(ConfigurationBeanVisitor v) {
          for (Configuration c : namedCaches) {
             c.accept(v);
          }
-      }
-      v.traversalCompleted(this);
+      }      
+      v.visitInfinispanConfiguration(this);
    }
 
    private static InputStream findInputStream(String fileName) throws FileNotFoundException {",2009-09-11T01:37:44Z,241
"@@ -5,6 +5,7 @@
 import javax.xml.bind.annotation.XmlAttribute;
 
 import org.infinispan.CacheException;
+import org.infinispan.config.ConfigurationBeanVisitor;
 import org.infinispan.config.PluggableConfigurationComponent;
 
 /**
@@ -48,4 +49,6 @@ public AbstractCacheLoaderConfig clone() {
          throw new CacheException(e);
       }
    }
+   
+   public void accept(ConfigurationBeanVisitor v) {}
 }",2009-09-11T01:37:44Z,242
"@@ -1,5 +1,6 @@
 package org.infinispan.loaders;
 
+import org.infinispan.config.ConfigurationBeanVisitor;
 import org.infinispan.loaders.decorators.AsyncStoreConfig;
 import org.infinispan.loaders.decorators.SingletonStoreConfig;
 import org.infinispan.util.Util;
@@ -119,6 +120,12 @@ public void setAsyncStoreConfig(AsyncStoreConfig asyncStoreConfig) {
       testImmutability(""async"");
       this.async = asyncStoreConfig;
    }
+   
+   public void accept(ConfigurationBeanVisitor v) {
+      singletonStore.accept(v);
+      async.accept(v);
+      v.visitCacheLoaderConfig(this);
+   }
 
    @Override
    public boolean equals(Object obj) {",2009-09-11T01:37:44Z,243
"@@ -1,5 +1,6 @@
 package org.infinispan.loaders;
 
+import org.infinispan.config.ConfigurationBeanVisitor;
 import org.infinispan.config.ConfigurationException;
 import org.infinispan.config.parsing.XmlConfigHelper;
 import org.infinispan.util.Util;
@@ -26,6 +27,8 @@
  */
 @XmlJavaTypeAdapter(CacheLoaderConfigAdapter.class)
 public interface CacheLoaderConfig extends Cloneable, Serializable {
+   
+   void accept(ConfigurationBeanVisitor visitor);
 
    CacheLoaderConfig clone();
 ",2009-09-11T01:37:44Z,244
"@@ -5,6 +5,7 @@
 import javax.xml.bind.annotation.XmlAttribute;
 
 import org.infinispan.config.AbstractNamedCacheConfigurationBean;
+import org.infinispan.config.ConfigurationBeanVisitor;
 import org.infinispan.config.Dynamic;
 
 /**
@@ -79,4 +80,8 @@ public AsyncStoreConfig clone() {
          throw new RuntimeException(""Should not happen!"", e);
       }
    }
+
+   public void accept(ConfigurationBeanVisitor v) {
+      v.visitAsyncStoreConfig(this);
+   }
 }",2009-09-11T01:37:44Z,30
"@@ -5,6 +5,7 @@
 import javax.xml.bind.annotation.XmlAttribute;
 
 import org.infinispan.config.AbstractNamedCacheConfigurationBean;
+import org.infinispan.config.ConfigurationBeanVisitor;
 
 /**
  * Configuration for a singleton store
@@ -84,4 +85,8 @@ public SingletonStoreConfig clone() {
          throw new RuntimeException(""Should not happen"", e);
       }
    }
+
+   public void accept(ConfigurationBeanVisitor v) {
+      v.visitSingletonStoreConfig(this);
+   }
 }",2009-09-11T01:37:44Z,245
"@@ -1645,8 +1645,7 @@ public static class TransactionType extends AbstractFluentConfigurationBean impl
       @XmlElement
       protected RecoveryType recovery = new RecoveryType();
 
-      @ConfigurationDoc(desc = ""Defines whether this is a transactional(default) cache or not."")
-      @XmlAttribute (name = ""transactionalCache"", required = false)
+      @ConfigurationDocRef(bean = Configuration.class, targetElement = ""isTransactionalCache"")
       protected boolean transactionalCache = true;
 
 
@@ -1697,6 +1696,16 @@ public Boolean isSyncCommitPhase() {
          return syncCommitPhase;
       }
 
+      @XmlAttribute
+      public Boolean isAutoCommit() {
+         return autoCommit;
+      }
+
+      @XmlAttribute
+      public Boolean isTransactionalCache() {
+         return transactionalCache;
+      }
+
       /**
        * @deprecated The visibility of this will be reduced, use {@link #syncCommitPhase(Boolean)} instead
        */",2011-09-13T13:04:20Z,160
"@@ -49,6 +49,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,246
"@@ -79,6 +79,7 @@
 			<plugin>
 				<groupId>org.apache.felix</groupId>
 				<artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
 				<configuration>
 					<instructions>
 						<Export-Package>",2011-07-27T16:52:02Z,146
"@@ -105,6 +105,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,247
"@@ -65,6 +65,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,248
"@@ -62,6 +62,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,249
"@@ -71,6 +71,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,250
"@@ -122,6 +122,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,251
"@@ -98,6 +98,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,252
"@@ -96,6 +96,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,253
"@@ -106,7 +106,7 @@
       <version.c3p0>0.9.1.2</version.c3p0>
       <version.cassandra>0.8.0</version.cassandra>
       <version.cassandra.pool>0.8.1</version.cassandra.pool>
-      <version.cdi>1.0-SP4</version.cdi> 
+      <version.cdi>1.0-SP4</version.cdi>
       <version.com.intellij.forms_rt>6.0.5</version.com.intellij.forms_rt>
       <version.commons.compress>1.0</version.commons.compress>
       <version.commons.pool>1.5.4</version.commons.pool>
@@ -162,6 +162,9 @@
       <version.xsom>20081112</version.xsom>
       <version.xstream>1.3.1</version.xstream>
       <version.javassist>3.12.1.GA</version.javassist>
+
+      <!-- Maven dependencies -->
+      <version.maven.bundle>2.3.5</version.maven.bundle>
    </properties>
 
    <dependencies>
@@ -208,6 +211,18 @@
                <groupId>org.jboss.logging</groupId>
                <artifactId>jboss-logging-spi</artifactId>
             </exclusion>
+            <exclusion>
+               <groupId>org.jboss.logging</groupId>
+               <artifactId>jboss-logging</artifactId>
+            </exclusion>
+            <exclusion>
+               <groupId>org.jboss.logging</groupId>
+               <artifactId>jboss-logging-processor</artifactId>
+            </exclusion>
+            <exclusion>
+               <groupId>org.jboss.logging</groupId>
+               <artifactId>jboss-logging-generator</artifactId>
+            </exclusion>
             <exclusion>
                 <groupId>org.jboss.ws.native</groupId>
                 <artifactId>jbossws-native-core</artifactId>
@@ -744,7 +759,7 @@
                <plugin>
                   <groupId>org.apache.felix</groupId>
                   <artifactId>maven-bundle-plugin</artifactId>
-                  <version>2.0.1</version>
+                  <version>${version.maven.bundle}</version>
                   <extensions>true</extensions>
                   <configuration>
                      <instructions>",2011-07-27T16:52:02Z,152
"@@ -87,6 +87,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,254
"@@ -94,6 +94,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,255
"@@ -90,6 +90,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,256
"@@ -90,6 +90,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,257
"@@ -57,6 +57,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,258
"@@ -246,6 +246,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,259
"@@ -99,6 +99,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,260
"@@ -62,6 +62,7 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
+            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2011-07-27T16:52:02Z,261
"@@ -38,8 +38,8 @@
 import org.jgroups.Address;
 import org.jgroups.Channel;
 import org.jgroups.Message;
-import org.jgroups.blocks.GroupRequest;
 import org.jgroups.blocks.RequestOptions;
+import org.jgroups.blocks.ResponseMode;
 import org.jgroups.blocks.RpcDispatcher;
 import org.jgroups.blocks.RspFilter;
 import org.jgroups.util.Buffer;
@@ -95,7 +95,7 @@ protected final boolean isValid(Message req) {
       return true;
    }
 
-   public RspList invokeRemoteCommands(Vector<Address> dests, ReplicableCommand command, int mode, long timeout,
+   public RspList invokeRemoteCommands(Vector<Address> dests, ReplicableCommand command, ResponseMode mode, long timeout,
                                        boolean anycasting, boolean oob, RspFilter filter, boolean supportReplay, boolean asyncMarshalling,
                                        boolean broadcast) {
 
@@ -111,15 +111,15 @@ public RspList invokeRemoteCommands(Vector<Address> dests, ReplicableCommand com
          } catch (Exception e) {
             throw rewrapAsCacheException(e);
          }
-         if (mode == GroupRequest.GET_NONE) return null; // ""Traditional"" async.
+         if (mode == ResponseMode.GET_NONE) return null; // ""Traditional"" async.
          if (response.isEmpty() || containsOnlyNulls(response))
             return null;
          else
             return response;
       }
    }
 
-   private boolean containsOnlyNulls(RspList l) {
+   private boolean containsOnlyNulls(RspList<Object> l) {
       for (Rsp r : l.values()) {
          if (r.getValue() != null || !r.wasReceived() || r.wasSuspected()) return false;
       }
@@ -134,7 +134,7 @@ public Object handle(Message req) {
       if (isValid(req)) {
          ReplicableCommand cmd = null;
          try {
-            cmd = (ReplicableCommand) req_marshaller.objectFromByteBuffer(req.getBuffer(), req.getOffset(), req.getLength());
+            cmd = (ReplicableCommand) req_marshaller.objectFromBuffer(req.getBuffer(), req.getOffset(), req.getLength());
             if (cmd instanceof CacheRpcCommand)
                return executeCommand((CacheRpcCommand) cmd, req);
             else
@@ -170,15 +170,15 @@ private class ReplicationTask implements Callable<RspList> {
       private ReplicableCommand command;
       private boolean oob;
       private Vector<Address> dests;
-      private int mode;
+      private ResponseMode mode;
       private long timeout;
       private boolean anycasting;
       private RspFilter filter;
       boolean supportReplay = false;
       boolean broadcast = false;
 
       private ReplicationTask(ReplicableCommand command, boolean oob, Vector<Address> dests,
-                              int mode, long timeout,
+                              ResponseMode mode, long timeout,
                               boolean anycasting, RspFilter filter, boolean supportReplay, boolean broadcast) {
          this.command = command;
          this.oob = oob;
@@ -195,7 +195,7 @@ private Message constructMessage(Buffer buf, Address recipient) {
          Message msg = new Message();
          msg.setBuffer(buf);
          if (oob) msg.setFlag(Message.OOB);
-         if (mode != GroupRequest.GET_NONE) {
+         if (mode != ResponseMode.GET_NONE) {
             msg.setFlag(Message.DONT_BUNDLE);
             msg.setFlag(Message.NO_FC);
          }
@@ -217,11 +217,11 @@ public RspList call() throws Exception {
          if (trace) log.tracef(""Replication task sending %s to addresses %s"", command, dests);
 
          // Replay capability requires responses from all members!
-         int mode = supportReplay ? GroupRequest.GET_ALL : this.mode;
+         ResponseMode mode = supportReplay ? ResponseMode.GET_ALL : this.mode;
 
-         if (filter != null) mode = GroupRequest.GET_FIRST;
+         if (filter != null) mode = ResponseMode.GET_FIRST;
 
-         RspList retval = null;
+         RspList<Object> retval = null;
          Buffer buf;
          if (broadcast || FORCE_MCAST) {
             RequestOptions opts = new RequestOptions();
@@ -252,7 +252,7 @@ public RspList call() throws Exception {
                   futureCollator.watchFuture(f, a);
                }
                retval = futureCollator.getResponseList();
-            } else if (mode == GroupRequest.GET_ALL) {
+            } else if (mode == ResponseMode.GET_ALL) {
                // A SYNC call that needs to go everywhere
                Map<Address, Future<Object>> futures = new HashMap<Address, Future<Object>>(targets.size());
 
@@ -270,14 +270,14 @@ public RspList call() throws Exception {
                   }
                }
 
-            } else if (mode == GroupRequest.GET_NONE) {
+            } else if (mode == ResponseMode.GET_NONE) {
                // An ASYNC call.  We don't care about responses.
                for (Address dest : targets) sendMessage(constructMessage(buf, dest), opts);
             }
          }
 
          // we only bother parsing responses if we are not in ASYNC mode.
-         if (mode != GroupRequest.GET_NONE) {
+         if (mode != ResponseMode.GET_NONE) {
 
             if (trace) log.tracef(""Responses: %s"", retval);
 
@@ -291,7 +291,7 @@ public RspList call() throws Exception {
             if (supportReplay) {
                boolean replay = false;
                Vector<Address> ignorers = new Vector<Address>();
-               for (Map.Entry<Address, Rsp> entry : retval.entrySet()) {
+               for (Map.Entry<Address, Rsp<Object>> entry : retval.entrySet()) {
                   Object value = entry.getValue().getValue();
                   if (value instanceof RequestIgnoredResponse) {
                      ignorers.add(entry.getKey());
@@ -311,7 +311,7 @@ public RspList call() throws Exception {
                   if (trace)
                      log.tracef(""Replaying message to ignoring senders: %s"", ignorers);
                   RequestOptions opts = new RequestOptions();
-                  opts.setMode(GroupRequest.GET_ALL);
+                  opts.setMode(ResponseMode.GET_ALL);
                   opts.setTimeout(timeout);
                   opts.setAnycasting(anycasting);
                   opts.setRspFilter(filter);",2011-09-20T16:25:33Z,262
"@@ -42,13 +42,11 @@
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.jgroups.Channel;
-import org.jgroups.ChannelException;
 import org.jgroups.Event;
-import org.jgroups.ExtendedMembershipListener;
 import org.jgroups.JChannel;
+import org.jgroups.MembershipListener;
 import org.jgroups.MergeView;
 import org.jgroups.View;
-import org.jgroups.blocks.Request;
 import org.jgroups.blocks.RspFilter;
 import org.jgroups.jmx.JmxConfigurator;
 import org.jgroups.stack.AddressGenerator;
@@ -85,7 +83,7 @@
  * @author Galder Zamarreño
  * @since 4.0
  */
-public class JGroupsTransport extends AbstractTransport implements ExtendedMembershipListener {
+public class JGroupsTransport extends AbstractTransport implements MembershipListener {
    public static final String CONFIGURATION_STRING = ""configurationString"";
    public static final String CONFIGURATION_XML = ""configurationXml"";
    public static final String CONFIGURATION_FILE = ""configurationFile"";
@@ -162,10 +160,14 @@ public void start() {
 
    protected void startJGroupsChannelIfNeeded() {
       if (startChannel) {
+         String clusterName = configuration.getClusterName();
          try {
-            String clusterName = configuration.getClusterName();
             channel.connect(clusterName);
+         } catch (Exception e) {
+            throw new CacheException(""Unable to start JGroups Channel"", e);
+         }
 
+         try {
             // Normally this would be done by CacheManagerJmxRegistration but
             // the channel is not started when the cache manager starts but
             // when first cache starts, so it's safer to do it here.
@@ -176,8 +178,6 @@ protected void startJGroupsChannelIfNeeded() {
                domain = JmxUtil.buildJmxDomain(configuration, mbeanServer, groupName);
                JmxConfigurator.registerChannel((JChannel) channel, mbeanServer, domain, clusterName, true);
             }
-         } catch (ChannelException e) {
-            throw new CacheException(""Unable to start JGroups Channel"", e);
          } catch (Exception e) {
             throw new CacheException(""Channel connected, but unable to register MBeans"", e);
          }
@@ -242,7 +242,7 @@ protected void initChannel() {
          }
       }
 
-      channel.setOpt(Channel.LOCAL, false);
+      channel.setDiscardOwnMessages(true);
 
       // if we have a TopologyAwareConsistentHash, we need to set our own address generator in JGroups:
       if(configuration.hasTopologyInfo()) {
@@ -324,7 +324,7 @@ private void buildChannel() {
          log.unableToUseJGroupsPropertiesProvided(props);
          try {
             channel = new JChannel(FileLookupFactory.newInstance().lookupFileLocation(DEFAULT_JGROUPS_CONFIGURATION_FILE, configuration.getClassLoader()));
-         } catch (ChannelException e) {
+         } catch (Exception e) {
             throw new CacheException(""Unable to start JGroups channel"", e);
          }
       }
@@ -370,7 +370,7 @@ public Address getAddress() {
 
    public List<Address> getPhysicalAddresses() {
       if (physicalAddress == null && channel != null) {
-         org.jgroups.Address addr = (org.jgroups.Address) channel.downcall(new Event(Event.GET_PHYSICAL_ADDRESS, channel.getAddress()));
+         org.jgroups.Address addr = (org.jgroups.Address) channel.down(new Event(Event.GET_PHYSICAL_ADDRESS, channel.getAddress()));
          physicalAddress = new JGroupsAddress(addr);
       }
       return Collections.singletonList(physicalAddress);
@@ -398,7 +398,7 @@ public Map<Address, Response> invokeRemotely(Collection<Address> recipients, Rep
       boolean asyncMarshalling = mode == ResponseMode.ASYNCHRONOUS;
       if (!usePriorityQueue && ResponseMode.SYNCHRONOUS == mode) usePriorityQueue = true;
 
-      RspList rsps = dispatcher.invokeRemoteCommands(toJGroupsAddressVector(recipients), rpcCommand, toJGroupsMode(mode),
+      RspList<Object> rsps = dispatcher.invokeRemoteCommands(toJGroupsAddressVector(recipients), rpcCommand, toJGroupsMode(mode),
               timeout, recipients != null, usePriorityQueue,
               toJGroupsFilter(responseFilter), supportReplay, asyncMarshalling, recipients == null || recipients.size() == members.size());
 
@@ -409,23 +409,23 @@ public Map<Address, Response> invokeRemotely(Collection<Address> recipients, Rep
       Map<Address, Response> retval = new HashMap<Address, Response>(rsps.size());
 
       boolean noValidResponses = true;
-      for (Rsp rsp : rsps.values()) {
+      for (Rsp<Object> rsp : rsps.values()) {
          noValidResponses = parseResponseAndAddToResponseList(rsp.getValue(), retval, rsp.wasSuspected(), rsp.wasReceived(), fromJGroupsAddress(rsp.getSender()), responseFilter != null) && noValidResponses;
       }
 
       if (noValidResponses) throw new TimeoutException(""Timed out waiting for valid responses!"");
       return retval;
    }
 
-   private static int toJGroupsMode(ResponseMode mode) {
+   private static org.jgroups.blocks.ResponseMode toJGroupsMode(ResponseMode mode) {
       switch (mode) {
          case ASYNCHRONOUS:
          case ASYNCHRONOUS_WITH_SYNC_MARSHALLING:
-            return Request.GET_NONE;
+            return org.jgroups.blocks.ResponseMode.GET_NONE;
          case SYNCHRONOUS:
-            return Request.GET_ALL;
+            return org.jgroups.blocks.ResponseMode.GET_ALL;
          case WAIT_FOR_VALID_RESPONSE:
-            return Request.GET_MAJORITY;
+            return org.jgroups.blocks.ResponseMode.GET_MAJORITY;
       }
       throw new CacheException(""Unknown response mode "" + mode);
    }
@@ -460,7 +460,7 @@ public void emitNotification(List<Address> oldMembers, View newView) {
          notifier.notifyMerge(members, oldMembers, address, viewId, getSubgroups(mv.getSubgroups()));
       }
 
-      private List<List<Address>> getSubgroups(Vector<View> subviews) {
+      private List<List<Address>> getSubgroups(List<View> subviews) {
          List<List<Address>> l = new ArrayList<List<Address>>(subviews.size());
          for (View v: subviews) l.add(fromJGroupsAddressList(v.getMembers()));
          return l;         
@@ -469,7 +469,7 @@ private List<List<Address>> getSubgroups(Vector<View> subviews) {
 
    public void viewAccepted(View newView) {
       log.debugf(""New view accepted: %s"", newView);
-      Vector<org.jgroups.Address> newMembers = newView.getMembers();
+      List<org.jgroups.Address> newMembers = newView.getMembers();
       if (newMembers == null || newMembers.isEmpty()) {
          log.debugf(""Received null or empty member list from JGroups channel: "" + newView);
          return;",2011-09-20T16:25:33Z,214
"@@ -33,29 +33,23 @@
  * @author Manik Surtani
  * @since 4.0
  */
-public class MarshallerAdapter implements RpcDispatcher.Marshaller2 {
+public class MarshallerAdapter implements RpcDispatcher.Marshaller {
    StreamingMarshaller m;
 
    public MarshallerAdapter(StreamingMarshaller m) {
       this.m = m;
    }
 
+   @Override
    public Buffer objectToBuffer(Object obj) throws Exception {
       return toBuffer(m.objectToBuffer(obj));
    }
 
-   public Object objectFromByteBuffer(byte[] buf, int offset, int length) throws Exception {
+   @Override
+   public Object objectFromBuffer(byte[] buf, int offset, int length) throws Exception {
       return m.objectFromByteBuffer(buf, offset, length);
    }
 
-   public byte[] objectToByteBuffer(Object obj) throws Exception {
-      return m.objectToByteBuffer(obj);
-   }
-
-   public Object objectFromByteBuffer(byte[] buf) throws Exception {
-      return m.objectFromByteBuffer(buf);
-   }
-
    private Buffer toBuffer(ByteBuffer bb) {
       return new Buffer(bb.getBuf(), bb.getOffset(), bb.getLength());
    }",2011-09-20T16:25:33Z,263
"@@ -22,10 +22,6 @@
  */
 package org.infinispan.remoting;
 
-import static org.easymock.EasyMock.*;
-
-import java.io.EOFException;
-
 import org.infinispan.Cache;
 import org.infinispan.CacheException;
 import org.infinispan.commands.remote.SingleRpcCommand;
@@ -37,9 +33,13 @@
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
-import org.jgroups.blocks.RpcDispatcher.Marshaller2;
+import org.jgroups.blocks.RpcDispatcher;
 import org.testng.annotations.Test;
 
+import java.io.EOFException;
+
+import static org.easymock.EasyMock.*;
+
 @Test(groups = ""functional"", testName = ""remoting.TransportSenderExceptionHandlingTest"")
 public class TransportSenderExceptionHandlingTest extends MultipleCacheManagersTest {
    final String key = ""k-illyria"", value = ""v-illyria"", value2 = ""v2-illyria"";
@@ -57,32 +57,32 @@ public void testInvokeAndExceptionWhileUnmarshalling() throws Exception {
       Cache cache2 = cache(1, ""replSync"");
       JGroupsTransport transport1 = (JGroupsTransport) TestingUtil.extractComponent(cache1, Transport.class);
       CommandAwareRpcDispatcher dispatcher1 = transport1.getCommandAwareRpcDispatcher();
-      Marshaller2 originalMarshaller1 = (Marshaller2) dispatcher1.getMarshaller();
+      RpcDispatcher.Marshaller originalMarshaller1 = dispatcher1.getMarshaller();
       JGroupsTransport transport2 = (JGroupsTransport) TestingUtil.extractComponent(cache2, Transport.class);
       CommandAwareRpcDispatcher dispatcher2 = transport2.getCommandAwareRpcDispatcher();
-      Marshaller2 originalMarshaller2 = (Marshaller2) dispatcher2.getMarshaller();
+      RpcDispatcher.Marshaller originalMarshaller = dispatcher2.getMarshaller();
       try {
-         Marshaller2 mockMarshaller1 = createMock(Marshaller2.class);
-         Marshaller2 mockMarshaller2 = createMock(Marshaller2.class);
+         RpcDispatcher.Marshaller mockMarshaller1 = createMock(RpcDispatcher.Marshaller.class);
+         RpcDispatcher.Marshaller mockMarshaller = createMock(RpcDispatcher.Marshaller.class);
          PutKeyValueCommand putCommand = new PutKeyValueCommand();
          putCommand.setKey(key);
          putCommand.setValue(value);
          SingleRpcCommand rpcCommand = new SingleRpcCommand(""replSync"");
          Object[] params = new Object[]{putCommand};
          rpcCommand.setParameters(SingleRpcCommand.COMMAND_ID, params);
          expect(mockMarshaller1.objectToBuffer(anyObject())).andReturn(originalMarshaller1.objectToBuffer(rpcCommand));
-         expect(mockMarshaller2.objectFromByteBuffer((byte[]) anyObject(), anyInt(), anyInt())).andThrow(new EOFException());
+         expect(mockMarshaller.objectFromBuffer((byte[]) anyObject(), anyInt(), anyInt())).andThrow(new EOFException());
          dispatcher1.setRequestMarshaller(mockMarshaller1);
-         dispatcher2.setRequestMarshaller(mockMarshaller2);
-         replay(mockMarshaller1, mockMarshaller2);
+         dispatcher2.setRequestMarshaller(mockMarshaller);
+         replay(mockMarshaller1, mockMarshaller);
          cache1.put(key, value);
          assert false : ""Should have thrown an exception"";
       } catch(CacheException ce) {
          assert !(ce.getCause() instanceof ClassCastException) : ""No way a ClassCastException must be sent back to user!"";
          assert ce.getCause() instanceof EOFException;
       } finally {
          dispatcher1.setMarshaller(originalMarshaller1);
-         dispatcher2.setMarshaller(originalMarshaller2);
+         dispatcher2.setMarshaller(originalMarshaller);
       }
    }
 }",2011-09-20T16:25:33Z,264
"@@ -23,7 +23,6 @@
 package org.infinispan.test.fwk;
 
 import org.infinispan.util.LegacyKeySupportSystemProperties;
-import org.jgroups.ChannelException;
 import org.jgroups.conf.ConfiguratorFactory;
 import org.jgroups.conf.ProtocolConfiguration;
 import org.jgroups.conf.ProtocolStackConfigurator;
@@ -189,15 +188,15 @@ private static String replaceProperties(
    private static ProtocolStackConfigurator loadTcp() {
       try {
          return ConfiguratorFactory.getStackConfigurator(""stacks/tcp.xml"");
-      } catch (ChannelException e) {
+      } catch (Exception e) {
          throw new RuntimeException(e);
       }
    }
 
    private static ProtocolStackConfigurator loadUdp() {
       try {
          return ConfiguratorFactory.getStackConfigurator(""stacks/udp.xml"");
-      } catch (ChannelException e) {
+      } catch (Exception e) {
          throw new RuntimeException(e);
       }
    }",2011-09-20T16:25:33Z,265
"@@ -135,7 +135,7 @@
       <version.jclouds>1.1.0</version.jclouds>
       <version.jetty>6.1.25</version.jetty>
       <version.jgoodies.forms>1.0.5</version.jgoodies.forms>
-      <version.jgroups>2.12.1.3.Final</version.jgroups>
+      <version.jgroups>3.0.0.CR1</version.jgroups>
       <version.json>20090211</version.json>
       <version.jstl>1.2</version.jstl>
       <version.jta>1.0.1.GA</version.jta>",2011-09-20T16:25:33Z,152
"@@ -35,6 +35,7 @@
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.distribution.ch.ConsistentHashHelper;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.factories.annotations.Stop;
@@ -66,23 +67,10 @@
 import org.rhq.helpers.pluginAnnotations.agent.Operation;
 import org.rhq.helpers.pluginAnnotations.agent.Parameter;
 
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.LinkedBlockingQueue;
-import java.util.concurrent.ThreadFactory;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
+import java.util.*;
+import java.util.concurrent.*;
 
 import static org.infinispan.context.Flag.*;
-import static org.infinispan.distribution.ch.ConsistentHashHelper.createConsistentHash;
 
 /**
  * The default distribution manager implementation
@@ -98,19 +86,28 @@ public class DistributionManagerImpl implements DistributionManager {
    private static final Log log = LogFactory.getLog(DistributionManagerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
-   private Configuration configuration;
-   private volatile ConsistentHash consistentHash;
-   private Address self;
+   // Injected components
    private CacheLoaderManager cacheLoaderManager;
+   private Configuration configuration;
    private RpcManager rpcManager;
    private CacheManagerNotifier notifier;
-
-   private ViewChangeListener listener;
    private CommandsFactory cf;
+   private TransactionLogger transactionLogger;
+   private DataContainer dataContainer;
+   private InterceptorChain interceptorChain;
+   private InvocationContextContainer icc;
+   private InboundInvocationHandler inboundInvocationHandler;
+   private CacheNotifier cacheNotifier;
 
+   private final ViewChangeListener listener;
    private final ExecutorService rehashExecutor;
 
-   private TransactionLogger transactionLogger;
+   // consistentHash and self are not valid in the inbound threads until
+   // joinStartedLatch has been signaled by the starting thread
+   // we don't have a getSelf() that waits on joinS
+   private volatile ConsistentHash consistentHash;
+   private Address self;
+   private final CountDownLatch joinStartedLatch = new CountDownLatch(1);
 
    /**
     * Set if the cluster is in rehash mode, i.e. not all the nodes have applied the new state.
@@ -123,16 +120,10 @@ public class DistributionManagerImpl implements DistributionManager {
    private final Map<Address, Integer> pushConfirmations = new HashMap<Address, Integer>(1);
    private final Object pushConfirmationsLock = new Object();
 
-   private DataContainer dataContainer;
-   private InterceptorChain interceptorChain;
-   private InvocationContextContainer icc;
-
    @ManagedAttribute(description = ""If true, the node has successfully joined the grid and is considered to hold state.  If false, the join process is still in progress."")
    @Metric(displayName = ""Is join completed?"", dataType = DataType.TRAIT)
    private volatile boolean joinComplete = false;
-
-   InboundInvocationHandler inboundInvocationHandler;
-   private CacheNotifier cacheNotifier;
+   private final CountDownLatch joinCompletedLatch = new CountDownLatch(1);
 
    /**
     * Default constructor
@@ -151,6 +142,7 @@ public Thread newThread(Runnable r) {
       };
       rehashExecutor = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, rehashQueue, tf,
                                               new ThreadPoolExecutor.DiscardOldestPolicy());
+      listener = new ViewChangeListener();
    }
 
    @Inject
@@ -172,11 +164,9 @@ public void init(Configuration configuration, RpcManager rpcManager, CacheManage
    }
 
    // needs to be AFTER the RpcManager
-
    @Start(priority = 20)
    public void start() throws Exception {
       if (trace) log.trace(""starting distribution manager on "" + getMyAddress());
-      listener = new ViewChangeListener();
       notifier.addListener(listener);
       join();
    }
@@ -197,20 +187,19 @@ public RpcManager getRpcManager() {
 
    @Start(priority = 1000)
    public void waitForJoinToComplete() throws Throwable {
-      while (rehashInProgress) {
-         // TODO use a monitor instead
-         Thread.sleep(10);
-      }
+      joinCompletedLatch.await();
       joinComplete = true;
    }
 
    private void join() throws Exception {
       Transport t = rpcManager.getTransport();
       List<Address> members = t.getMembers();
-      consistentHash = createConsistentHash(configuration, members);
       self = t.getAddress();
-      rehashInProgress = true;
       lastViewId = t.getViewId();
+      consistentHash = ConsistentHashHelper.createConsistentHash(configuration, members);
+
+      // allow incoming requests
+      joinStartedLatch.countDown();
 
       // nothing to push, but we need to inform the coordinator that we have finished our push
       if (t.isCoordinator()) {
@@ -227,6 +216,8 @@ private void join() throws Exception {
    public void stop() {
       notifier.removeListener(listener);
       rehashExecutor.shutdownNow();
+      joinStartedLatch.countDown();
+      joinCompletedLatch.countDown();
       joinComplete = true;
    }
 
@@ -237,9 +228,7 @@ public boolean isLocal(Object key) {
    }
 
    public DataLocality getLocality(Object key) {
-      if (consistentHash == null) return DataLocality.LOCAL;
-
-      boolean local = consistentHash.isKeyLocalToAddress(self, key, getReplCount());
+      boolean local = getConsistentHash().isKeyLocalToAddress(getSelf(), key, getReplCount());
       if (isRehashInProgress()) {
          if (local) {
             return DataLocality.LOCAL_UNCERTAIN;
@@ -257,22 +246,26 @@ public DataLocality getLocality(Object key) {
 
 
    public List<Address> locate(Object key) {
-      if (consistentHash == null) return Collections.singletonList(self);
-      return consistentHash.locate(key, getReplCount());
+      return getConsistentHash().locate(key, getReplCount());
+   }
+
+   /**
+    * Hold up operations on incoming threads until the starting thread has finished initializing the consistent hash
+    */
+   private void waitForJoinToStart() {
+      try {
+         joinStartedLatch.await();
+      } catch (InterruptedException e) {
+         throw new IllegalStateException(""Thread interrupted"", e);
+      }
    }
 
    public Map<Object, List<Address>> locateAll(Collection<Object> keys) {
       return locateAll(keys, getReplCount());
    }
 
    public Map<Object, List<Address>> locateAll(Collection<Object> keys, int numOwners) {
-      if (consistentHash == null) {
-         Map<Object, List<Address>> m = new HashMap<Object, List<Address>>(keys.size());
-         List<Address> selfList = Collections.singletonList(self);
-         for (Object k : keys) m.put(k, selfList);
-         return m;
-      }
-      return consistentHash.locateAll(keys, numOwners);
+      return getConsistentHash().locateAll(keys, numOwners);
    }
 
    public void transformForL1(CacheEntry entry) {
@@ -299,8 +292,23 @@ public InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext
       return null;
    }
 
+   public Address getSelf() {
+      if (self == null) {
+         waitForJoinToStart();
+      }
+      // after the waitForJoinToStart call we must see the value of self set before joinStartedLatch.countDown()
+      return self;
+   }
+
    public ConsistentHash getConsistentHash() {
-      return consistentHash;
+      // avoid a duplicate volatile read in the common case
+      ConsistentHash ch = consistentHash;
+      if (ch == null) {
+         waitForJoinToStart();
+         // after the waitForJoinToStart call we must see the value of consistentHash set before joinStartedLatch.countDown()
+         ch = consistentHash;
+      }
+      return ch;
    }
 
    public void setConsistentHash(ConsistentHash consistentHash) {
@@ -312,7 +320,7 @@ public void setConsistentHash(ConsistentHash consistentHash) {
    @ManagedOperation(description = ""Determines whether a given key is affected by an ongoing rehash, if any."")
    @Operation(displayName = ""Could key be affected by rehash?"")
    public boolean isAffectedByRehash(@Parameter(name = ""key"", description = ""Key to check"") Object key) {
-      return transactionLogger.isEnabled() && consistentHash != null && !consistentHash.locate(key, getReplCount()).contains(self);
+      return isRehashInProgress() && !getConsistentHash().locate(key, getReplCount()).contains(getSelf());
    }
 
    public TransactionLogger getTransactionLogger() {
@@ -321,17 +329,16 @@ public TransactionLogger getTransactionLogger() {
 
    private Map<Object, InternalCacheValue> applyStateMap(ConsistentHash consistentHash, Map<Object, InternalCacheValue> state, boolean withRetry) {
       Map<Object, InternalCacheValue> retry = withRetry ? new HashMap<Object, InternalCacheValue>() : null;
-      Address myself=self;
-      if(myself == null) {
-         myself=rpcManager.getTransport().getAddress();
-         self=myself;
-      }
+      waitForJoinToStart();
 
       for (Map.Entry<Object, InternalCacheValue> e : state.entrySet()) {
-         if (consistentHash.locate(e.getKey(), configuration.getNumOwners()).contains(myself)) {
+         if (consistentHash.locate(e.getKey(), configuration.getNumOwners()).contains(getSelf())) {
             InternalCacheValue v = e.getValue();
             InvocationContext ctx = icc.createInvocationContext();
-            ctx.setFlags(CACHE_MODE_LOCAL, SKIP_REMOTE_LOOKUP, SKIP_SHARED_CACHE_STORE, SKIP_LOCKING, SKIP_OWNERSHIP_CHECK); // locking not necessary in the case of a join since the node isn't doing anything else.
+            // locking not necessary in the case of a join since the node isn't doing anything else
+            // TODO what if the node is already running?
+            ctx.setFlags(CACHE_MODE_LOCAL, SKIP_CACHE_LOAD, SKIP_REMOTE_LOOKUP, SKIP_SHARED_CACHE_STORE, SKIP_LOCKING,
+                         SKIP_OWNERSHIP_CHECK);
             try {
                PutKeyValueCommand put = cf.buildPutKeyValueCommand(e.getKey(), v.getValue(), v.getLifespan(), v.getMaxIdle(), ctx.getFlags());
                interceptorChain.invoke(ctx, put);
@@ -344,6 +351,8 @@ private Map<Object, InternalCacheValue> applyStateMap(ConsistentHash consistentH
                   log.problemApplyingStateForKey(ee.getMessage(), e.getKey());
                }
             }
+         } else {
+            log.warnf(""Received a key that doesn't map to this node: %s, mapped to %s"", e.getKey(), consistentHash.locate(e.getKey(), configuration.getNumOwners()));
          }
       }
       return retry;
@@ -376,8 +385,9 @@ public void markRehashCompleted(int viewId) {
          throw new IllegalStateException(""Received rehash completed confirmation before confirming it ourselves"");
       }
 
-      if (trace) log.tracef(""Rehash completed on node %s, data container has %d keys"", self, dataContainer.size());
+      if (trace) log.tracef(""Rehash completed on node %s, data container has %d keys"", getSelf(), dataContainer.size());
       rehashInProgress = false;
+      joinCompletedLatch.countDown();
    }
 
    @Override
@@ -422,7 +432,7 @@ public void markNodePushCompleted(int viewId, Address node) {
             log.tracef(""Coordinator: sending rehash completed notification for view %s"", viewId);
 
          // all the nodes are up-to-date, broadcast the rehash completed command
-         final RehashControlCommand cmd = cf.buildRehashControlCommand(RehashControlCommand.Type.REHASH_COMPLETED, self, viewId);
+         final RehashControlCommand cmd = cf.buildRehashControlCommand(RehashControlCommand.Type.REHASH_COMPLETED, getSelf(), viewId);
 
          // all nodes will eventually receive the command, no need to wait here
          rpcManager.broadcastRpcCommand(cmd, false);",2011-06-01T17:19:28Z,60
"@@ -193,7 +193,7 @@ protected void performRehash() throws Exception {
          // now we can inform the coordinator that we have finished our push
          Transport t = rpcManager.getTransport();
          if (t.isCoordinator()) {
-            distributionManager.markNodePushCompleted(t.getViewId(), t.getAddress());
+            distributionManager.markNodePushCompleted(newViewId, t.getAddress());
          } else {
             final RehashControlCommand cmd = cf.buildRehashControlCommand(RehashControlCommand.Type.NODE_PUSH_COMPLETED, self, newViewId);
 ",2011-06-01T17:19:28Z,266
"@@ -107,6 +107,9 @@ public void setNumVirtualNodes(Integer numVirtualNodes) {
 
    @Override
    public void setCaches(Set<Address> newCaches) {
+      if (newCaches.size() == 0 || newCaches.contains(null))
+         throw new IllegalArgumentException(""Invalid cache list for consistent hash: "" + newCaches);
+
       caches = new LinkedHashSet<Address>(newCaches.size());
 
       positions = new TreeMap<Integer, Address>();",2011-06-01T17:19:28Z,267
"@@ -37,7 +37,6 @@
 import org.infinispan.remoting.transport.DistributedSync;
 import org.infinispan.statetransfer.StateTransferException;
 import org.infinispan.util.FileLookup;
-import org.infinispan.util.StringPropertyReplacer;
 import org.infinispan.util.TypedProperties;
 import org.infinispan.util.Util;
 import org.infinispan.util.concurrent.TimeoutException;
@@ -47,7 +46,6 @@
 import org.jgroups.blocks.Request;
 import org.jgroups.blocks.RspFilter;
 import org.jgroups.jmx.JmxConfigurator;
-import org.jgroups.protocols.UDP;
 import org.jgroups.protocols.pbcast.STREAMING_STATE_TRANSFER;
 import org.jgroups.stack.AddressGenerator;
 import org.jgroups.stack.ProtocolStack;
@@ -56,14 +54,10 @@
 import org.jgroups.util.TopologyUUID;
 
 import javax.management.MBeanServer;
-import javax.management.MalformedObjectNameException;
-import javax.management.ObjectName;
 import java.io.InputStream;
 import java.io.OutputStream;
 import java.util.*;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.ExecutorService;
+import java.util.concurrent.*;
 
 import static java.util.concurrent.TimeUnit.MILLISECONDS;
 
@@ -86,30 +80,35 @@ public class JGroupsTransport extends AbstractTransport implements ExtendedMembe
    public static final String CONFIGURATION_FILE = ""configurationFile"";
    public static final String CHANNEL_LOOKUP = ""channelLookup"";
    protected static final String DEFAULT_JGROUPS_CONFIGURATION_FILE = ""jgroups-udp.xml"";
-   protected boolean startChannel = true, stopChannel = true;
 
-   protected Channel channel;
-   protected boolean createdChannel = false;
-   protected Address address;
-   protected Address physicalAddress;
-   protected volatile List<Address> members = Collections.emptyList();
-   protected volatile boolean coordinator = false;
-   protected final Object membersListLock = new Object(); // guards members
-   CommandAwareRpcDispatcher dispatcher;
    static final Log log = LogFactory.getLog(JGroupsTransport.class);
    static final boolean trace = log.isTraceEnabled();
+   final ConcurrentMap<String, StateTransferMonitor> stateTransfersInProgress = new ConcurrentHashMap<String, StateTransferMonitor>();
+
+   protected boolean startChannel = true, stopChannel = true;
+   private CommandAwareRpcDispatcher dispatcher;
    protected TypedProperties props;
    protected InboundInvocationHandler inboundInvocationHandler;
    protected StreamingMarshaller marshaller;
    protected ExecutorService asyncExecutor;
    protected CacheManagerNotifier notifier;
-   final ConcurrentMap<String, StateTransferMonitor> stateTransfersInProgress = new ConcurrentHashMap<String, StateTransferMonitor>();
    private final JGroupsDistSync flushTracker = new JGroupsDistSync();
-   long distributedSyncTimeout;
+   private long distributedSyncTimeout;
+
    private boolean globalStatsEnabled;
    private MBeanServer mbeanServer;
    private String domain;
 
+   protected Channel channel;
+   protected Address address;
+   protected Address physicalAddress;
+
+   // these members are not valid until we have received the first view on a second thread
+   // and channelConnectedLatch is signaled
+   protected volatile List<Address> members = null;
+   protected volatile boolean coordinator = false;
+   protected CountDownLatch channelConnectedLatch = new CountDownLatch(1);
+
    /**
     * This form is used when the transport is created by an external source and passed in to the GlobalConfiguration.
     *
@@ -148,6 +147,8 @@ public void start() {
 
       initChannelAndRPCDispatcher();
       startJGroupsChannelIfNeeded();
+
+      waitForChannelToConnect();
    }
 
    protected void startJGroupsChannelIfNeeded() {
@@ -172,6 +173,9 @@ protected void startJGroupsChannelIfNeeded() {
             throw new CacheException(""Channel connected, but unable to register MBeans"", e);
          }
       }
+      else {
+         channelConnectedLatch.countDown();
+      }
       address = fromJGroupsAddress(channel.getAddress());
       if (log.isInfoEnabled())
          log.localAndPhysicalAddress(getAddress(), getPhysicalAddresses());
@@ -219,7 +223,6 @@ public void stop() {
 
    protected void initChannel() {
       if (channel == null) {
-         createdChannel = true;
          buildChannel();
          // Channel.LOCAL *must* be set to false so we don't see our own messages - otherwise invalidations targeted at
          // remote instances will be received by self.
@@ -326,18 +329,16 @@ public boolean isCoordinator() {
    }
 
    public Address getCoordinator() {
-      if (channel == null) return null;
-      synchronized (membersListLock) {
-         while (members.isEmpty()) {
-            log.debug(""Waiting on view being accepted"");
-            try {
-               membersListLock.wait();
-            } catch (InterruptedException e) {
-               log.interruptedWaitingForCoordinator(e);
-               break;
-            }
-         }
-         return members.isEmpty() ? null : members.get(0);
+      return members.isEmpty() ? null : members.get(0);
+   }
+
+   public void waitForChannelToConnect() {
+      if (channel == null) return;
+      log.debug(""Waiting on view being accepted"");
+      try {
+         channelConnectedLatch.await();
+      } catch (InterruptedException e) {
+         log.interruptedWaitingForCoordinator(e);
       }
    }
 
@@ -523,23 +524,21 @@ public void viewAccepted(View newView) {
          }
       }
 
-      synchronized (membersListLock) {
-         boolean needNotification = false;
-         if (newMembers != null) {
-            oldMembers = members;
-            // we need a defensive copy anyway
-            members = fromJGroupsAddressList(newMembers);
-            needNotification = true;
-         }
-         // Now that we have a view, figure out if we are the coordinator
-         coordinator = (members != null && !members.isEmpty() && members.get(0).equals(getAddress()));
+      boolean needNotification = false;
+      if (newMembers != null) {
+         oldMembers = members;
+         // we need a defensive copy anyway
+         members = fromJGroupsAddressList(newMembers);
+         needNotification = true;
+      }
+      // Now that we have a view, figure out if we are the coordinator
+      coordinator = (members != null && !members.isEmpty() && members.get(0).equals(getAddress()));
 
-         // now notify listeners - *after* updating the coordinator. - JBCACHE-662
-         if (needNotification && n != null) n.emitNotification(oldMembers, newView);
+      // now notify listeners - *after* updating the coordinator. - JBCACHE-662
+      if (needNotification && n != null) n.emitNotification(oldMembers, newView);
 
-         // Wake up any threads that are waiting to know about who the coordinator is
-         membersListLock.notifyAll();
-      }
+      // Wake up any threads that are waiting to know about who the coordinator is
+      channelConnectedLatch.countDown();
    }
 
    public void suspect(org.jgroups.Address suspected_mbr) {
@@ -630,7 +629,6 @@ private static Vector<org.jgroups.Address> toJGroupsAddressVector(Collection<Add
       if (list == null) return null;
       if (list.isEmpty()) return new Vector<org.jgroups.Address>();
 
-      // optimize for the single node case
       Vector<org.jgroups.Address> retval = new Vector<org.jgroups.Address>(list.size());
       for (Address a : list) retval.add(toJGroupsAddress(a));
 
@@ -640,15 +638,10 @@ private static Vector<org.jgroups.Address> toJGroupsAddressVector(Collection<Add
 
    private static List<Address> fromJGroupsAddressList(List<org.jgroups.Address> list) {
       if (list == null || list.isEmpty()) return Collections.emptyList();
-      // optimize for the single node case
-      int sz = list.size();
-      List<Address> retval = new ArrayList<Address>(sz);
-      if (sz == 1) {
-         retval.add(fromJGroupsAddress(list.get(0)));
-      } else {
-         for (org.jgroups.Address a : list) retval.add(fromJGroupsAddress(a));
-      }
-      return retval;
+
+      List<Address> retval = new ArrayList<Address>(list.size());
+      for (org.jgroups.Address a : list) retval.add(fromJGroupsAddress(a));
+      return Collections.unmodifiableList(retval);
    }
 
    // mainly for unit testing",2011-06-01T17:19:28Z,214
"@@ -611,6 +611,20 @@ public void setEagerLockSingleNode(boolean eagerLockSingleNode) {
       this.transaction.setEagerLockSingleNode(eagerLockSingleNode);
    }
 
+   /**
+    * If there are any ongoing transactions when a cache is stopped,
+    * Infinispan waits for ongoing remote and local transactions to finish.
+    * The amount of time to wait for is defined by the cache stop timeout.
+    * It is recommended that this value does not exceed the transaction
+    * timeout because even if a new transaction was started just before the
+    * cache was stopped, this could only last as long as the transaction
+    * timeout allows it.
+    */
+   public Configuration setCacheStopTimeout(int cacheStopTimeout) {
+      this.transaction.setCacheStopTimeout(cacheStopTimeout);
+      return this;
+   }
+
    /**
     * If true, this forces all async communications to be queued up and sent out periodically as a batch.
     *
@@ -910,6 +924,10 @@ public boolean isEagerLockSingleNode() {
       return transaction.eagerLockSingleNode;
    }
 
+   public int getCacheStopTimeout() {
+      return transaction.cacheStopTimeout;
+   }
+
    public long getStateRetrievalTimeout() {
       return clustering.stateRetrieval.timeout;
    }
@@ -1144,6 +1162,9 @@ public static class TransactionType extends AbstractNamedCacheConfigurationBean
       @ConfigurationDocRef(bean = Configuration.class, targetElement = ""setEagerLockSingleNode"")
       protected Boolean eagerLockSingleNode = false;
 
+      @Dynamic
+      @ConfigurationDocRef(bean = Configuration.class, targetElement = ""setCacheStopTimeout"")
+      protected Integer cacheStopTimeout = 30000;
 
       public TransactionType(String transactionManagerLookupClass) {
          this.transactionManagerLookupClass = transactionManagerLookupClass;
@@ -1193,6 +1214,12 @@ public void setEagerLockSingleNode(Boolean eagerLockSingleNode) {
          this.eagerLockSingleNode = eagerLockSingleNode;
       }
 
+      @XmlAttribute
+      public void setCacheStopTimeout(Integer cacheStopTimeout) {
+         testImmutability(""cacheStopTimeout"");
+         this.cacheStopTimeout = cacheStopTimeout;
+      }
+
       @Override
       public boolean equals(Object o) {
          if (this == o) return true;
@@ -1210,6 +1237,8 @@ public boolean equals(Object o) {
             return false;
          if (useEagerLocking != null ? !useEagerLocking.equals(that.useEagerLocking) : that.useEagerLocking != null)
             return false;
+         if (cacheStopTimeout != null ? !cacheStopTimeout.equals(that.cacheStopTimeout) : that.cacheStopTimeout != null)
+            return false;
 
          return true;
       }
@@ -1221,6 +1250,7 @@ public int hashCode() {
          result = 31 * result + (syncCommitPhase != null ? syncCommitPhase.hashCode() : 0);
          result = 31 * result + (syncRollbackPhase != null ? syncRollbackPhase.hashCode() : 0);
          result = 31 * result + (useEagerLocking != null ? useEagerLocking.hashCode() : 0);
+         result = 31 * result + (cacheStopTimeout != null ? cacheStopTimeout.hashCode() : 0);
          return result;
       }
 ",2011-02-04T16:25:15Z,160
"@@ -33,6 +33,7 @@
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.manager.CacheContainer;
+import org.infinispan.transaction.xa.TransactionTable;
 
 import javax.transaction.Status;
 import javax.transaction.SystemException;
@@ -41,16 +42,19 @@
 
 /**
  * @author Mircea.Markus@jboss.com
+ * @author Galder Zamarreño
  */
 public class InvocationContextInterceptor extends CommandInterceptor {
 
    private TransactionManager tm;
    private ComponentRegistry componentRegistry;
+   private TransactionTable txTable;
 
    @Inject
-   public void init(TransactionManager tm, ComponentRegistry componentRegistry) {
+   public void init(TransactionManager tm, ComponentRegistry componentRegistry, TransactionTable txTable) {
       this.tm = tm;
       this.componentRegistry = componentRegistry;
+      this.txTable = txTable;
    }
 
    @Override
@@ -69,11 +73,15 @@ private Object handleAll(InvocationContext ctx, VisitableCommand command) throws
 
       ComponentStatus status = componentRegistry.getStatus();
       if (status.isTerminated()) {
-         String cacheName = componentRegistry.getCacheName();
-         String prefix = ""Cache '"" + cacheName + ""'"";
-         if (cacheName.equals(CacheContainer.DEFAULT_CACHE_NAME))
-            prefix = ""Default cache"";
-         throw new IllegalStateException(prefix + "" is in 'TERMINATED' state and so it does not accept new invocations. Either restart it or recreate the cache container."");
+         throw new IllegalStateException(String.format(
+               ""%s is in 'TERMINATED' state and so it does not accept new invocations. "" +
+                     ""Either restart it or recreate the cache container."",
+               getCacheNamePrefix()));
+      } else if (stoppingAndNotAllowed(status, ctx)) {
+         throw new IllegalStateException(String.format(
+               ""%s is in 'STOPPING' state and this is an invocation not belonging to an on-going transaction, so it does not accept new invocations. "" +
+                     ""Either restart it or recreate the cache container."",
+               getCacheNamePrefix()));
       }
 
       if (trace) log.trace(""Invoked with command "" + command + "" and InvocationContext ["" + ctx + ""]"");
@@ -104,6 +112,26 @@ private Object handleAll(InvocationContext ctx, VisitableCommand command) throws
       }
    }
 
+   private String getCacheNamePrefix() {
+      String cacheName = componentRegistry.getCacheName();
+      String prefix = ""Cache '"" + cacheName + ""'"";
+      if (cacheName.equals(CacheContainer.DEFAULT_CACHE_NAME))
+         prefix = ""Default cache"";
+      return prefix;
+   }
+
+   /**
+    * If the cache is STOPPING, non-transaction invocations, or transactional
+    * invocations for transaction others than the ongoing ones, are no allowed.
+    * This method returns true if under this circumstances meet.
+    * Otherwise, it returns false.
+    */
+   private boolean stoppingAndNotAllowed(ComponentStatus status, InvocationContext ctx) throws Exception {
+      return status.isStopping() &&
+         (!ctx.isInTxScope() ||
+                (ctx.isInTxScope() && txTable.getLocalTransaction(tm.getTransaction()) == null));
+   }
+
    private Object markTxForRollbackAndRethrow(InvocationContext ctx, Throwable te) throws Throwable {
       if (ctx.isOriginLocal() && ctx.isInTxScope()) {
          Transaction transaction = tm.getTransaction();",2011-02-04T16:25:15Z,268
"@@ -106,4 +106,9 @@ public boolean startingUp() {
    public boolean isTerminated() {
       return this == ComponentStatus.TERMINATED;
    }
+
+   public boolean isStopping() {
+      return this == ComponentStatus.STOPPING;
+   }
+
 }",2011-02-04T16:25:15Z,269
"@@ -1,3 +1,25 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2000 - 2011, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
 package org.infinispan.transaction.xa;
 
 import org.infinispan.commands.tx.RollbackCommand;
@@ -30,6 +52,7 @@
 import java.util.concurrent.ExecutorService;
 import java.util.concurrent.Executors;
 import java.util.concurrent.RejectedExecutionException;
+import java.util.concurrent.TimeUnit;
 
 import static java.util.Collections.emptySet;
 
@@ -38,6 +61,7 @@
  * org.infinispan.transaction.xa.TransactionXaAdapter}s (locally originated transactions).
  *
  * @author Mircea.Markus@jboss.com
+ * @author Galder Zamarreño
  * @since 4.0
  */
 public class TransactionTable {
@@ -85,6 +109,32 @@ private void start() {
    private void stop() {
       cm.removeListener(listener);
       lockBreakingService.shutdownNow();
+      if (trace) log.trace(""Wait for on-going transactions to finish for %d seconds."", TimeUnit.MILLISECONDS.toSeconds(configuration.getCacheStopTimeout()));
+      long failTime = System.currentTimeMillis() + configuration.getCacheStopTimeout();
+      boolean txsOnGoing = areTxsOnGoing();
+      while (txsOnGoing && System.currentTimeMillis() < failTime) {
+         try {
+            Thread.sleep(100);
+            txsOnGoing = areTxsOnGoing();
+         } catch (InterruptedException e) {
+            Thread.currentThread().interrupt();
+            if (trace) {
+               log.trace(""Interrupted waiting for on-going transactions to finish. localTransactions=%s, remoteTransactions%s"",
+                     localTransactions, remoteTransactions);
+            }
+         }
+      }
+
+      if (txsOnGoing) {
+         log.warn(""Stopping but there're transactions that did not finish in time: localTransactions=%s, remoteTransactions%s"",
+                  localTransactions, remoteTransactions);
+      } else {
+         if (trace) log.trace(""All transactions terminated"");
+      }
+   }
+
+   private boolean areTxsOnGoing() {
+      return !localTransactions.isEmpty() || !remoteTransactions.isEmpty();
    }
 
    public Set<Object> getLockedKeysForRemoteTransaction(GlobalTransaction gtx) {",2011-02-04T16:25:15Z,91
"@@ -1,4 +1,26 @@
 <?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ JBoss, Home of Professional Open Source.
+  ~ Copyright 2000 - 2011, Red Hat Middleware LLC, and individual contributors
+  ~ as indicated by the @author tags. See the copyright.txt file in the
+  ~ distribution for a full listing of individual contributors.
+  ~
+  ~ This is free software; you can redistribute it and/or modify it
+  ~ under the terms of the GNU Lesser General Public License as
+  ~ published by the Free Software Foundation; either version 2.1 of
+  ~ the License, or (at your option) any later version.
+  ~
+  ~ This software is distributed in the hope that it will be useful,
+  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
+  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+  ~ Lesser General Public License for more details.
+  ~
+  ~ You should have received a copy of the GNU Lesser General Public
+  ~ License along with this software; if not, write to the Free
+  ~ Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+  ~ 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+  -->
+
 <infinispan
       xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
       xsi:schemaLocation=""urn:infinispan:config:5.0 http://www.infinispan.org/schemas/infinispan-config-5.0.xsd""
@@ -185,7 +207,9 @@
             transactionManagerLookupClass=""org.infinispan.transaction.lookup.GenericTransactionManagerLookup""
             syncRollbackPhase=""false""
             syncCommitPhase=""false""
-            useEagerLocking=""false"" eagerLockSingleNode=""false""/>
+            useEagerLocking=""false""
+            eagerLockSingleNode=""false""
+            cacheStopTimeout=""30000"" />
       -->
       <!--
          Enables deadlock detection.  See:",2011-02-04T16:25:15Z,270
"@@ -1,3 +1,25 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2000 - 2011, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
 package org.infinispan.api;
 
 import org.infinispan.Cache;",2011-02-04T16:25:15Z,271
"@@ -177,6 +177,7 @@ private void testNamedCacheFile(XmlConfigurationParser parser) throws IOExceptio
 
       c = getNamedCacheConfig(namedCaches, ""transactional2"");
       assert c.getTransactionManagerLookupClass().equals(""org.something.Lookup"");
+      assert c.getCacheStopTimeout() == 10000;
 
       c = getNamedCacheConfig(namedCaches, ""syncRepl"");
 ",2011-02-04T16:25:15Z,272
"@@ -1,3 +1,25 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2000 - 2011, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
 package org.infinispan.lock;
 
 import org.infinispan.affinity.KeyAffinityService;",2011-02-04T16:25:15Z,273
"@@ -0,0 +1,127 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2000 - 2011, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.Cache;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.SingleCacheManagerTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.Test;
+
+import javax.transaction.TransactionManager;
+import java.lang.reflect.Method;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.concurrent.Callable;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.CyclicBarrier;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+
+import static org.infinispan.test.TestingUtil.k;
+import static org.infinispan.test.TestingUtil.v;
+
+/**
+ * Test that verifies that Cache.stop() waits for on-going transactions to
+ * finish before making the cache unavailable.
+ *
+ * @author Galder Zamarreño
+ * @since 4.2
+ * @since 5.0
+ */
+@Test(groups = ""functional"", testName = ""tx.TerminatedCacheWhileInTxTest"")
+public class TerminatedCacheWhileInTxTest extends SingleCacheManagerTest {
+
+   @Override
+   protected EmbeddedCacheManager createCacheManager() throws Exception {
+      return TestCacheManagerFactory.createLocalCacheManager(true);
+   }
+
+   public void testStopWhileInTx(Method m) throws Throwable {
+      stopCacheCalls(m, false);
+   }
+
+   /**
+    * The aim of this test is to make sure that invocations not belonging to
+    * on-going transactions or non-transactional invocations are not allowed
+    * once the cache is in stopping mode.
+    */
+   @Test(expectedExceptions = IllegalStateException.class)
+   public void testNotAllowCallsWhileStopping(Method m) throws Throwable {
+      stopCacheCalls(m, true);
+   }
+
+   private void stopCacheCalls(final Method m, boolean withCallStoppingCache) throws Throwable {
+      final Cache cache = cacheManager.getCache(""cache-"" + m.getName());
+      final ExecutorService executorService = Executors.newCachedThreadPool();
+      final CyclicBarrier barrier = new CyclicBarrier(2);
+      final CountDownLatch latch = new CountDownLatch(1);
+      final TransactionManager tm = TestingUtil.getTransactionManager(cache);
+
+      Callable<Void> waitAfterModCallable = new Callable<Void>() {
+         @Override
+         public Void call() throws Exception {
+            log.debug(""Wait for all executions paths to be ready to perform calls."");
+            tm.begin();
+            cache.put(k(m, 1), v(m, 1));
+            log.debug(""Cache modified, wait for cache to be stopped."");
+            barrier.await();
+            latch.await(10, TimeUnit.SECONDS);
+            tm.commit();
+            return null;
+         }
+      };
+      Future waitAfterModFuture = executorService.submit(waitAfterModCallable);
+
+      barrier.await(); // wait for all threads to have done their modifications
+      Future callStoppingCacheFuture = null;
+      if (withCallStoppingCache) {
+         Callable<Void> callStoppingCache = new Callable<Void>() {
+            @Override
+            public Void call() throws Exception {
+               log.debug(""Wait very briefly and then make call."");
+               Thread.sleep(1000);
+               cache.put(k(m, 2), v(m, 2));
+               return null;
+            }
+         };
+         callStoppingCacheFuture = executorService.submit(callStoppingCache);
+      }
+      cache.stop(); // now stop the cache
+      latch.countDown(); // now that cache has been stopped, let the thread continue
+
+      log.debug(""All threads finished, let's shutdown the executor and check whether any exceptions were reported"");
+      waitAfterModFuture.get();
+      if (callStoppingCacheFuture != null) {
+         try {
+            callStoppingCacheFuture.get();
+         } catch (ExecutionException e) {
+            throw e.getCause();
+         }
+      }
+   }
+}",2011-02-04T16:25:15Z,274
"@@ -65,7 +65,8 @@
    </namedCache>
 
    <namedCache name=""transactional2"">
-      <transaction transactionManagerLookupClass=""org.something.Lookup""/>
+      <transaction transactionManagerLookupClass=""org.something.Lookup""
+                   cacheStopTimeout=""10000""/>
    </namedCache>
 
 ",2011-02-04T16:25:15Z,171
"@@ -8,12 +8,9 @@
 import org.infinispan.factories.ComponentRegistry;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.util.concurrent.NotifyingFuture;
 
 import java.util.Collection;
 import java.util.List;
-import java.util.Map;
-import java.util.concurrent.TimeUnit;
 
 /**
  * Similar to {@link org.infinispan.AbstractDelegatingCache}, but for {@link AdvancedCache}.
@@ -78,112 +75,9 @@ public DataContainer getDataContainer() {
       return cache.getDataContainer();
    }
 
-   public void putForExternalRead(K key, V value, Flag... flags) {
-      cache.putForExternalRead(key, value, flags);
-   }
-
-   public V put(K key, V value, Flag... flags) {
-      return cache.put(key, value, flags);
-   }
-
-   public V put(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      return cache.put(key, value, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
-   }
-
-   public V putIfAbsent(K key, V value, Flag... flags) {
-      return cache.putIfAbsent(key, value, flags);
-   }
-
-   public V putIfAbsent(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      return cache.putIfAbsent(key, value, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
-   }
-
-   public void putAll(Map<? extends K, ? extends V> map, Flag... flags) {
-      cache.putAll(map, flags);
-   }
-
-   public void putAll(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      cache.putAll(map, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
-   }
-
-   public V remove(Object key, Flag... flags) {
-      return cache.remove(key, flags);
-   }
-
-   public void clear(Flag... flags) {
-      cache.clear(flags);
-   }
-
-   public V replace(K k, V v, Flag... flags) {
-      return cache.replace(k, v, flags);
-   }
-
-   public boolean replace(K k, V oV, V nV, Flag... flags) {
-      return cache.replace(k, oV, nV, flags);
-   }
-
-   public V replace(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
-      return cache.replace(k, v, lifespan, lifespanUnit, maxIdle, maxIdleUnit, flags);
-   }
-
-   public boolean replace(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
-      return cache.replace(k, oV, nV, lifespan, lifespanUnit, maxIdle, maxIdleUnit, flags);
-   }
-
-   public NotifyingFuture<V> putAsync(K key, V value, Flag... flags) {
-      return cache.putAsync(key, value, flags);
-   }
-
-   public NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      return cache.putAsync(key, value, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
-   }
-
-   public NotifyingFuture<V> putIfAbsentAsync(K key, V value, Flag... flags) {
-      return cache.putIfAbsentAsync(key, value, flags);
-   }
-
-   public NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      return cache.putIfAbsentAsync(key, value, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
-   }
-
-   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags) {
-      return cache.putAllAsync(map, flags);
-   }
-
-   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      return cache.putAllAsync(map, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
-   }
-
-   public NotifyingFuture<V> removeAsync(Object key, Flag... flags) {
-      return cache.removeAsync(key, flags);
-   }
-
-   public NotifyingFuture<Void> clearAsync(Flag... flags) {
-      return cache.clearAsync(flags);
-   }
-
-   public NotifyingFuture<V> replaceAsync(K k, V v, Flag... flags) {
-      return cache.replaceAsync(k, v, flags);
-   }
-
-   public NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags) {
-      return cache.replaceAsync(k, oV, nV, flags);
-   }
-
-   public NotifyingFuture<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
-      return cache.replaceAsync(k, v, lifespan, lifespanUnit, maxIdle, maxIdleUnit, flags);
-   }
-
-   public NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
-      return cache.replaceAsync(k, oV, nV, lifespan, lifespanUnit, maxIdle, maxIdleUnit, flags);
-   }
-
-   public boolean containsKey(Object key, Flag... flags) {
-      return cache.containsKey(key, flags);
-   }
-
-   public V get(Object key, Flag... flags) {
-      return cache.get(key, flags);
+   public AdvancedCache<K, V> withFlags(Flag... flags) {
+      cache.withFlags(flags);
+      return this;
    }
 
    public void lock(K key) {",2009-11-03T23:51:12Z,95
"@@ -8,12 +8,9 @@
 import org.infinispan.factories.ComponentRegistry;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.util.concurrent.NotifyingFuture;
 
 import java.util.Collection;
 import java.util.List;
-import java.util.Map;
-import java.util.concurrent.TimeUnit;
 
 /**
  * An advanced interface that exposes additional methods not available on {@link Cache}.
@@ -22,6 +19,18 @@
  * @since 4.0
  */
 public interface AdvancedCache<K, V> extends Cache<K, V> {
+
+   /**
+    * A builder-style method that adds flags to any API call.  For example, consider the following code snippet:
+    * <pre>
+    *   cache.withFlags(Flag.FORCE_WRITE_LOCK).get(key);
+    * </pre>
+    * will invoke a cache.get() with a write lock forced.
+    * @param flags a set of flags to apply.  See the {@link Flag} documentation.
+    * @return a cache on which a real operation is to be invoked.
+    */
+   AdvancedCache<K, V> withFlags(Flag... flags);
+
    /**
     * Adds a custom interceptor to the interceptor chain, at specified position, where the first interceptor in the
     * chain is at position 0 and the last one at NUM_INTERCEPTORS - 1.
@@ -109,60 +118,4 @@ public interface AdvancedCache<K, V> extends Cache<K, V> {
    InvocationContextContainer getInvocationContextContainer();
 
    DataContainer getDataContainer();
-
-   void putForExternalRead(K key, V value, Flag... flags);
-
-   V put(K key, V value, Flag... flags);
-
-   V put(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
-
-   V putIfAbsent(K key, V value, Flag... flags);
-
-   V putIfAbsent(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
-
-   void putAll(Map<? extends K, ? extends V> map, Flag... flags);
-
-   void putAll(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
-
-   V remove(Object key, Flag... flags);
-
-   void clear(Flag... flags);
-
-   V replace(K k, V v, Flag... flags);
-
-   boolean replace(K k, V oV, V nV, Flag... flags);
-
-   V replace(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
-
-   boolean replace(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
-
-
-   // -- async methods --
-   NotifyingFuture<V> putAsync(K key, V value, Flag... flags);
-
-   NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
-
-   NotifyingFuture<V> putIfAbsentAsync(K key, V value, Flag... flags);
-
-   NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
-
-   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags);
-
-   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
-
-   NotifyingFuture<V> removeAsync(Object key, Flag... flags);
-
-   NotifyingFuture<Void> clearAsync(Flag... flags);
-
-   NotifyingFuture<V> replaceAsync(K k, V v, Flag... flags);
-
-   NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags);
-
-   NotifyingFuture<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
-
-   NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
-
-   boolean containsKey(Object key, Flag... flags);
-
-   V get(Object key, Flag... flags);
 }",2009-11-03T23:51:12Z,97
"@@ -40,6 +40,7 @@
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.context.Flag;
+import static org.infinispan.context.Flag.*;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.eviction.EvictionManager;
@@ -71,8 +72,10 @@
 
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
+import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
+import java.util.EnumSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
@@ -110,6 +113,7 @@ public class CacheDelegate<K, V> implements AdvancedCache<K, V> {
    // as above for ResponseGenerator
    private ResponseGenerator responseGenerator;
    private long defaultLifespan, defaultMaxIdleTime;
+   private ThreadLocal<PreInvocationContext> flagHolder = new ThreadLocal<PreInvocationContext>();
 
    public CacheDelegate(String name) {
       this.name = name;
@@ -150,11 +154,9 @@ public final V putIfAbsent(K key, V value) {
    }
 
    public final boolean remove(Object key, Object value) {
-      if (value instanceof Flag) {
-         // this can happen!
-         log.warn(""Did you intend to call Cache.remove(Object, Object), with a Flag as value, or did you intend to call Cache.remove(Object, Flag... )?  If it was the latter and you are just passing in one flag, please cast this to an array of Flag, e.g., remove(key, new Flag[]{flag}) to ensure the correct method gets called!"");
-      }
-      return remove(key, value, (Flag[]) null);
+      InvocationContext ctx = getInvocationContext();
+      RemoveCommand command = commandsFactory.buildRemoveCommand(key, value);
+      return (Boolean) invoker.invoke(ctx, command);
    }
 
    public final boolean replace(K key, V oldValue, V newValue) {
@@ -175,50 +177,82 @@ public final boolean isEmpty() {
    }
 
    public final boolean containsKey(Object key) {
-      return containsKey(key, (Flag[]) null);
+      InvocationContext ctx = getInvocationContext();
+      GetKeyValueCommand command = commandsFactory.buildGetKeyValueCommand(key);
+      Object response = invoker.invoke(ctx, command);
+      return response != null;
    }
 
    public final boolean containsValue(Object value) {
       throw new UnsupportedOperationException(""Go away"");
    }
 
+   @SuppressWarnings(""unchecked"")
    public final V get(Object key) {
-      return get(key, (Flag[]) null);
+      InvocationContext ctx = getInvocationContext();
+      GetKeyValueCommand command = commandsFactory.buildGetKeyValueCommand(key);
+      return (V) invoker.invoke(ctx, command);
    }
 
    public final V put(K key, V value) {
       return put(key, value, defaultLifespan, MILLISECONDS, defaultMaxIdleTime, MILLISECONDS);
    }
 
+   @SuppressWarnings(""unchecked"")
    public final V remove(Object key) {
-      return remove(key, (Flag[]) null);
+      InvocationContext ctx = getInvocationContext();
+      RemoveCommand command = commandsFactory.buildRemoveCommand(key, null);
+      return (V) invoker.invoke(ctx, command);
    }
 
    public final void putAll(Map<? extends K, ? extends V> map) {
       putAll(map, defaultLifespan, MILLISECONDS, defaultMaxIdleTime, MILLISECONDS);
    }
 
    public final void clear() {
-      clear((Flag[]) null);
+      InvocationContext ctx = getInvocationContext();
+      ClearCommand command = commandsFactory.buildClearCommand();
+      invoker.invoke(ctx, command);
    }
 
+   @SuppressWarnings(""unchecked"")
    public Set<K> keySet() {
       KeySetCommand command = commandsFactory.buildKeySetCommand();
       return (Set<K>) invoker.invoke(icc.createNonTxInvocationContext(), command);
    }
 
+   @SuppressWarnings(""unchecked"")
    public Collection<V> values() {
       ValuesCommand command = commandsFactory.buildValuesCommand();
       return (Collection<V>) invoker.invoke(icc.createNonTxInvocationContext(), command);
    }
 
+   @SuppressWarnings(""unchecked"")
    public Set<Map.Entry<K, V>> entrySet() {
       EntrySetCommand command = commandsFactory.buildEntrySetCommand();
       return (Set<Map.Entry<K, V>>) invoker.invoke(icc.createNonTxInvocationContext(), command);
    }
 
    public final void putForExternalRead(K key, V value) {
-      putForExternalRead(key, value, (Flag[]) null);
+      Transaction ongoingTransaction = null;
+      try {
+         if (transactionManager != null && (ongoingTransaction = transactionManager.getTransaction()) != null) {
+            transactionManager.suspend();
+         }
+         // if the entry exists then this should be a no-op.
+         withFlags(FAIL_SILENTLY, FORCE_ASYNCHRONOUS, ZERO_LOCK_ACQUISITION_TIMEOUT, PUT_FOR_EXTERNAL_READ).putIfAbsent(key, value);
+      }
+      catch (Exception e) {
+         if (log.isDebugEnabled()) log.debug(""Caught exception while doing putForExternalRead()"", e);
+      }
+      finally {
+         try {
+            if (ongoingTransaction != null) transactionManager.resume(ongoingTransaction);
+         }
+         catch (Exception e) {
+            log.debug(""Had problems trying to resume a transaction after putForExternalread()"", e);
+         }
+      }
    }
 
    public final void evict(K key) {
@@ -243,7 +277,11 @@ public Set<Object> getListeners() {
    }
 
    private InvocationContext getInvocationContext() {
-      return icc.createInvocationContext();
+      InvocationContext ctx = icc.createInvocationContext();
+      PreInvocationContext pic = flagHolder.get();
+      if (pic != null && !pic.flags.isEmpty()) ctx.setFlags(pic.flags);
+      flagHolder.remove();
+      return ctx;
    }
 
    public void lock(K key) {
@@ -305,211 +343,13 @@ public ComponentRegistry getComponentRegistry() {
       return componentRegistry;
    }
 
-   public final void putForExternalRead(K key, V value, Flag... flags) {
-      InvocationContext invocationContext = getInvocationContext();
-      if (flags != null) invocationContext.setFlags(flags);
-      Transaction ongoingTransaction = null;
-      try {
-         if (transactionManager != null && (ongoingTransaction = transactionManager.getTransaction()) != null) {
-            transactionManager.suspend();
-         }
-         // if the entry exists then this should be a no-op.
-         putIfAbsent(key, value, Flag.FAIL_SILENTLY, Flag.FORCE_ASYNCHRONOUS, Flag.ZERO_LOCK_ACQUISITION_TIMEOUT, Flag.PUT_FOR_EXTERNAL_READ);
-      }
-      catch (Exception e) {
-         if (log.isDebugEnabled()) log.debug(""Caught exception while doing putForExternalRead()"", e);
-      }
-      finally {
-         try {
-            if (ongoingTransaction != null) transactionManager.resume(ongoingTransaction);
-         }
-         catch (Exception e) {
-            log.debug(""Had problems trying to resume a transaction after putForExternalread()"", e);
-         }
-      }
-   }
-
-   public final V put(K key, V value, Flag... flags) {
-      return put(key, value, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS, MILLISECONDS.toMillis(defaultMaxIdleTime), MILLISECONDS, flags);
-   }
-
-   @SuppressWarnings(""unchecked"")
-   public final V put(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      PutKeyValueCommand command = commandsFactory.buildPutKeyValueCommand(key, value, lifespanUnit.toMillis(lifespan), maxIdleTimeUnit.toMillis(maxIdleTime));
-      return (V) invoker.invoke(ctx, command);
-   }
-
-   public final V putIfAbsent(K key, V value, Flag... flags) {
-      return putIfAbsent(key, value, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS, MILLISECONDS.toMillis(defaultMaxIdleTime), MILLISECONDS, flags);
-   }
-
-   @SuppressWarnings(""unchecked"")
-   public final V putIfAbsent(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      InvocationContext context = getInvocationContext();
-      context.setFlags(flags);
-      PutKeyValueCommand command = commandsFactory.buildPutKeyValueCommand(key, value, lifespanUnit.toMillis(lifespan), maxIdleTimeUnit.toMillis(maxIdleTime));
-      command.setPutIfAbsent(true);
-      return (V) invoker.invoke(context, command);
-   }
-
-   public final void putAll(Map<? extends K, ? extends V> map, Flag... flags) {
-      putAll(map, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS, MILLISECONDS.toMillis(defaultMaxIdleTime), MILLISECONDS, flags);
-   }
-
-   public final void putAll(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      PutMapCommand command = commandsFactory.buildPutMapCommand(map, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS.toMillis(defaultMaxIdleTime));
-      invoker.invoke(ctx, command);
-   }
-
-   @SuppressWarnings(""unchecked"")
-   public final V remove(Object key, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      RemoveCommand command = commandsFactory.buildRemoveCommand(key, null);
-      return (V) invoker.invoke(ctx, command);
-   }
-
-   public final boolean remove(Object key, Object oldValue, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      RemoveCommand command = commandsFactory.buildRemoveCommand(key, oldValue);
-      return (Boolean) invoker.invoke(ctx, command);
-   }
-
-   public final void clear(Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      ClearCommand command = commandsFactory.buildClearCommand();
-      invoker.invoke(ctx, command);
-   }
-
-   public final V replace(K k, V v, Flag... flags) {
-      return replace(k, v, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS, MILLISECONDS.toMillis(defaultMaxIdleTime), MILLISECONDS, flags);
-   }
-
-   public final boolean replace(K k, V oV, V nV, Flag... flags) {
-      return replace(k, oV, nV, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS, MILLISECONDS.toMillis(defaultMaxIdleTime), MILLISECONDS, flags);
-   }
-
-   @SuppressWarnings(""unchecked"")
-   public final V replace(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      ReplaceCommand command = commandsFactory.buildReplaceCommand(k, null, v, lifespanUnit.toMillis(lifespan), maxIdleUnit.toMillis(maxIdle));
-      return (V) invoker.invoke(ctx, command);
-   }
-
-   public final boolean replace(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      ReplaceCommand command = commandsFactory.buildReplaceCommand(k, oV, nV, lifespanUnit.toMillis(lifespan), maxIdleUnit.toMillis(maxIdle));
-      return (Boolean) invoker.invoke(ctx, command);
-   }
-
-   public final NotifyingFuture<V> putAsync(K key, V value, Flag... flags) {
-      return putAsync(key, value, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS, MILLISECONDS.toMillis(defaultMaxIdleTime), MILLISECONDS, flags);
-   }
-
-   public final NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      ctx.setUseFutureReturnType(true);
-      PutKeyValueCommand command = commandsFactory.buildPutKeyValueCommand(key, value, lifespanUnit.toMillis(lifespan), maxIdleTimeUnit.toMillis(maxIdleTime));
-      return wrapInFuture(invoker.invoke(ctx, command));
-   }
-
-   public final NotifyingFuture<V> putIfAbsentAsync(K key, V value, Flag... flags) {
-      return putIfAbsentAsync(key, value, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS, MILLISECONDS.toMillis(defaultMaxIdleTime), MILLISECONDS, flags);
-   }
-
-   public final NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      ctx.setUseFutureReturnType(true);
-      PutKeyValueCommand command = commandsFactory.buildPutKeyValueCommand(key, value, lifespanUnit.toMillis(lifespan), maxIdleTimeUnit.toMillis(maxIdleTime));
-      command.setPutIfAbsent(true);
-      return wrapInFuture(invoker.invoke(ctx, command));
-   }
-
-   public final NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags) {
-      return putAllAsync(map, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS, MILLISECONDS.toMillis(defaultMaxIdleTime), MILLISECONDS, flags);
-   }
-
-   public final NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      ctx.setUseFutureReturnType(true);
-      PutMapCommand command = commandsFactory.buildPutMapCommand(map, MILLISECONDS.toMillis(MILLISECONDS.toMillis(defaultLifespan)), MILLISECONDS.toMillis(MILLISECONDS.toMillis(defaultMaxIdleTime)));
-      return wrapInFuture(invoker.invoke(ctx, command));
-   }
-
-   public final NotifyingFuture<V> removeAsync(Object key, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      ctx.setUseFutureReturnType(true);
-      RemoveCommand command = commandsFactory.buildRemoveCommand(key, null);
-      return wrapInFuture(invoker.invoke(ctx, command));
-   }
-
-   public final NotifyingFuture<Void> clearAsync(Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      ctx.setUseFutureReturnType(true);
-      ClearCommand command = commandsFactory.buildClearCommand();
-      return wrapInFuture(invoker.invoke(ctx, command));
-   }
-
-   public final NotifyingFuture<V> replaceAsync(K k, V v, Flag... flags) {
-      return replaceAsync(k, v, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS, MILLISECONDS.toMillis(defaultMaxIdleTime), MILLISECONDS, flags);
-   }
-
-   public final NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags) {
-      return replaceAsync(k, oV, nV, MILLISECONDS.toMillis(defaultLifespan), MILLISECONDS, MILLISECONDS.toMillis(defaultMaxIdleTime), MILLISECONDS, flags);
-   }
-
-   public final NotifyingFuture<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      ctx.setUseFutureReturnType(true);
-      ReplaceCommand command = commandsFactory.buildReplaceCommand(k, null, v, lifespanUnit.toMillis(lifespan), maxIdleUnit.toMillis(maxIdle));
-      return wrapInFuture(invoker.invoke(ctx, command));
-   }
-
-   public final NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      ctx.setUseFutureReturnType(true);
-      ReplaceCommand command = commandsFactory.buildReplaceCommand(k, oV, nV, lifespanUnit.toMillis(lifespan), maxIdleUnit.toMillis(maxIdle));
-      return wrapInFuture(invoker.invoke(ctx, command));
-   }
-
-   public final boolean containsKey(Object key, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      GetKeyValueCommand command = commandsFactory.buildGetKeyValueCommand(key);
-      Object response = invoker.invoke(ctx, command);
-      return response != null;
-   }
-
-   @SuppressWarnings(""unchecked"")
-   public final V get(Object key, Flag... flags) {
-      InvocationContext ctx = getInvocationContext();
-      if (flags != null) ctx.setFlags(flags);
-      GetKeyValueCommand command = commandsFactory.buildGetKeyValueCommand(key);
-      return (V) invoker.invoke(ctx, command);
-   }
-
    public ComponentStatus getStatus() {
       return componentRegistry.getStatus();
    }
 
-   /** 
-    * Returns String representation of ComponentStatus enumeration in order to avoid 
-    * class not found exceptions in JMX tools that don't have access to infinispan classes.
+   /**
+    * Returns String representation of ComponentStatus enumeration in order to avoid class not found exceptions in JMX
+    * tools that don't have access to infinispan classes.
     */
    @ManagedAttribute(description = ""Returns the cache status"")
    @Metric(displayName = ""Cache status"", dataType = DataType.TRAIT, displayType = DisplayType.SUMMARY)
@@ -533,8 +373,8 @@ public String getName() {
       return name;
    }
 
-   /** 
-    * Returns the cache name. If this is the default cache, it returns a more friendly name. 
+   /**
+    * Returns the cache name. If this is the default cache, it returns a more friendly name.
     */
    @ManagedAttribute(description = ""Returns the cache name"")
    @Metric(displayName = ""Cache name"", dataType = DataType.TRAIT, displayType = DisplayType.SUMMARY)
@@ -567,25 +407,38 @@ public CacheManager getCacheManager() {
       return cacheManager;
    }
 
+   @SuppressWarnings(""unchecked"")
    public final V put(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit idleTimeUnit) {
-      return put(key, value, lifespan, lifespanUnit, maxIdleTime, idleTimeUnit, (Flag[]) null);
+      InvocationContext ctx = getInvocationContext();
+      PutKeyValueCommand command = commandsFactory.buildPutKeyValueCommand(key, value, lifespanUnit.toMillis(lifespan), idleTimeUnit.toMillis(maxIdleTime));
+      return (V) invoker.invoke(ctx, command);
    }
 
+   @SuppressWarnings(""unchecked"")
    public final V putIfAbsent(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit idleTimeUnit) {
-      return putIfAbsent(key, value, lifespan, lifespanUnit, maxIdleTime, idleTimeUnit, (Flag[]) null);
+      InvocationContext context = getInvocationContext();
+      PutKeyValueCommand command = commandsFactory.buildPutKeyValueCommand(key, value, lifespanUnit.toMillis(lifespan), idleTimeUnit.toMillis(maxIdleTime));
+      command.setPutIfAbsent(true);
+      return (V) invoker.invoke(context, command);
    }
 
    public final void putAll(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit idleTimeUnit) {
       PutMapCommand command = commandsFactory.buildPutMapCommand(map, lifespanUnit.toMillis(lifespan), idleTimeUnit.toMillis(maxIdleTime));
       invoker.invoke(getInvocationContext(), command);
    }
 
+   @SuppressWarnings(""unchecked"")
    public final V replace(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit idleTimeUnit) {
-      return replace(key, value, lifespan, lifespanUnit, maxIdleTime, idleTimeUnit, (Flag[]) null);
+      InvocationContext ctx = getInvocationContext();
+      ReplaceCommand command = commandsFactory.buildReplaceCommand(key, null, value, lifespanUnit.toMillis(lifespan), idleTimeUnit.toMillis(maxIdleTime));
+      return (V) invoker.invoke(ctx, command);
+
    }
 
    public final boolean replace(K key, V oldValue, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit idleTimeUnit) {
-      return replace(key, oldValue, value, lifespan, lifespanUnit, maxIdleTime, idleTimeUnit, (Flag[]) null);
+      InvocationContext ctx = getInvocationContext();
+      ReplaceCommand command = commandsFactory.buildReplaceCommand(key, oldValue, value, lifespanUnit.toMillis(lifespan), idleTimeUnit.toMillis(maxIdleTime));
+      return (Boolean) invoker.invoke(ctx, command);
    }
 
    /**
@@ -711,7 +564,10 @@ public final NotifyingFuture<V> replaceAsync(K key, V value, long lifespan, Time
    }
 
    public final NotifyingFuture<V> replaceAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return replaceAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit, (Flag[]) null);
+      InvocationContext ctx = getInvocationContext();
+      ctx.setUseFutureReturnType(true);
+      ReplaceCommand command = commandsFactory.buildReplaceCommand(key, null, value, lifespanUnit.toMillis(lifespan), maxIdleUnit.toMillis(maxIdle));
+      return wrapInFuture(invoker.invoke(ctx, command));
    }
 
    public final NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue) {
@@ -763,4 +619,28 @@ public void compact() {
    public RpcManager getRpcManager() {
       return rpcManager;
    }
+
+   public AdvancedCache<K, V> withFlags(Flag... flags) {
+      if (flags != null && flags.length > 0) {
+         PreInvocationContext pic = flagHolder.get();
+         if (pic == null)
+            flagHolder.set(new PreInvocationContext(flags));
+         else
+            flagHolder.set(pic.add(flags));
+      }
+      return this;
+   }
+
+   private static final class PreInvocationContext {
+      EnumSet<Flag> flags;
+
+      private PreInvocationContext(Flag[] flags) {
+         this.flags = flags != null && flags.length > 0 ? EnumSet.copyOf(Arrays.asList(flags)) : EnumSet.noneOf(Flag.class);
+      }
+
+      private PreInvocationContext add(Flag[] newFlags) {
+         if (newFlags != null && newFlags.length > 0) flags.addAll(Arrays.asList(newFlags));
+         return this;
+      }
+   }
 }",2009-11-03T23:51:12Z,183
"@@ -123,8 +123,7 @@ public void preload() {
             }
 
             for (InternalCacheEntry e : state)
-               cache.getAdvancedCache().put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS,
-                                            e.getMaxIdle(), MILLISECONDS, SKIP_CACHE_STATUS_CHECK);
+               cache.getAdvancedCache().withFlags(SKIP_CACHE_STATUS_CHECK).put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
 
             if (log.isDebugEnabled()) stop = System.currentTimeMillis();
             if (log.isDebugEnabled()) total = stop - start;",2009-11-03T23:51:12Z,29
"@@ -32,6 +32,7 @@
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
+import static org.infinispan.context.Flag.CACHE_MODE_LOCAL;
 import org.infinispan.context.impl.RemoteTxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
@@ -67,7 +68,7 @@
 public class StateTransferManagerImpl implements StateTransferManager {
 
    RpcManager rpcManager;
-   AdvancedCache cache;
+   AdvancedCache<Object, Object> cache;
    Configuration configuration;
    DataContainer dataContainer;
    CacheLoaderManager clm;
@@ -87,6 +88,7 @@ public class StateTransferManagerImpl implements StateTransferManager {
    volatile Address stateSender;
 
    @Inject
+   @SuppressWarnings(""unchecked"")
    public void injectDependencies(RpcManager rpcManager, AdvancedCache cache, Configuration configuration,
                                   DataContainer dataContainer, CacheLoaderManager clm, Marshaller marshaller,
                                   TransactionLog transactionLog, InterceptorChain interceptorChain, InvocationContextContainer invocationContextContainer,
@@ -226,7 +228,7 @@ private void processCommitLog(ObjectInput oi) throws Exception {
          if (trace) log.trace(""Mods = {0}"", Arrays.toString(mods));
          for (WriteCommand mod : mods) {
             commandsFactory.initializeReplicableCommand(mod);
-            ctx.setFlags(Flag.CACHE_MODE_LOCAL, Flag.SKIP_CACHE_STATUS_CHECK);
+            ctx.setFlags(CACHE_MODE_LOCAL, Flag.SKIP_CACHE_STATUS_CHECK);
             interceptorChain.invoke(ctx, mod);
          }
 
@@ -262,7 +264,7 @@ private void applyTransactionLog(ObjectInput oi) throws Exception {
                RemoteTxInvocationContext ctx = invocationContextContainer.createRemoteTxInvocationContext();
                RemoteTransaction transaction = txTable.createRemoteTransaction(command.getGlobalTransaction(), command.getModifications());
                ctx.setRemoteTransaction(transaction);
-               ctx.setFlags(Flag.CACHE_MODE_LOCAL, Flag.SKIP_CACHE_STATUS_CHECK);
+               ctx.setFlags(CACHE_MODE_LOCAL, Flag.SKIP_CACHE_STATUS_CHECK);
                interceptorChain.invoke(ctx, command);
             } else {
                if (trace) log.trace(""Prepare {0} not in tx log; not applying"", command);
@@ -327,7 +329,7 @@ private void applyInMemoryState(ObjectInput i) throws StateTransferException {
       try {
          Set<InternalCacheEntry> set = (Set<InternalCacheEntry>) marshaller.objectFromObjectStream(i);
          for (InternalCacheEntry se : set)
-            cache.put(se.getKey(), se.getValue(), se.getLifespan(), MILLISECONDS, se.getMaxIdle(), MILLISECONDS, Flag.CACHE_MODE_LOCAL);
+            cache.withFlags(CACHE_MODE_LOCAL).put(se.getKey(), se.getValue(), se.getLifespan(), MILLISECONDS, se.getMaxIdle(), MILLISECONDS);
       } catch (Exception e) {
          dataContainer.clear();
          throw new StateTransferException(e);",2009-11-03T23:51:12Z,117
"@@ -32,7 +32,7 @@ public void testWriteLockIsAcquired() throws Exception {
       advancedCache.put(""k"",""v"");
       assertNotLocked(advancedCache,""k"");
       tm.begin();
-      advancedCache.get(""k"", Flag.FORCE_WRITE_LOCK);
+      advancedCache.withFlags(Flag.FORCE_WRITE_LOCK).get(""k"");
 
       InvocationContext ic = advancedCache.getInvocationContextContainer().getInvocationContext();
       CacheEntry cacheEntry = ic.getLookedUpEntries().get(""k"");",2009-11-03T23:51:12Z,275
"@@ -2,7 +2,7 @@
 
 import org.infinispan.AdvancedCache;
 import org.infinispan.config.Configuration;
-import org.infinispan.context.Flag;
+import static org.infinispan.context.Flag.CACHE_MODE_LOCAL;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
@@ -43,10 +43,10 @@ public void testMixedMode() {
       localCache1 = cache(0, ""local"").getAdvancedCache();
       localCache2 = cache(1, ""local"").getAdvancedCache();
 
-      invalSyncCache2.put(""k"", ""v"", Flag.CACHE_MODE_LOCAL);
+      invalSyncCache2.withFlags(CACHE_MODE_LOCAL).put(""k"", ""v"");
       assert invalSyncCache2.get(""k"").equals(""v"");
       assert invalSyncCache1.get(""k"") == null;
-      invalAsyncCache2.put(""k"", ""v"", Flag.CACHE_MODE_LOCAL);
+      invalAsyncCache2.withFlags(CACHE_MODE_LOCAL).put(""k"", ""v"");
       assert invalAsyncCache2.get(""k"").equals(""v"");
       assert invalAsyncCache1.get(""k"") == null;
 ",2009-11-03T23:51:12Z,276
"@@ -3,11 +3,11 @@
 import org.easymock.EasyMock;
 import static org.easymock.EasyMock.*;
 import org.infinispan.Cache;
+import static org.infinispan.context.Flag.CACHE_MODE_LOCAL;
 import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.commands.write.PutKeyValueCommand;
 import org.infinispan.commands.write.RemoveCommand;
 import org.infinispan.config.Configuration;
-import org.infinispan.context.Flag;
 import org.infinispan.remoting.rpc.ResponseFilter;
 import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
@@ -301,8 +301,8 @@ public void testMemLeakOnSuspendedTransactions() throws Exception {
     * @throws Exception
     */
    private void cacheModeLocalTest(boolean transactional) throws Exception {
-      Cache cache1 = cache(0, ""replSync"");
-      Cache cache2 = cache(1, ""replSync"");
+      Cache<Object, Object> cache1 = cache(0, ""replSync"");
+      Cache<Object, Object> cache2 = cache(1, ""replSync"");
       TransactionManager tm1 = TestingUtil.getTransactionManager(cache1);
       TransactionManager tm2 = TestingUtil.getTransactionManager(cache2);
       RpcManager rpcManager = EasyMock.createMock(RpcManager.class);
@@ -316,7 +316,7 @@ private void cacheModeLocalTest(boolean transactional) throws Exception {
          if (transactional)
             tm1.begin();
 
-         cache1.getAdvancedCache().putForExternalRead(key, value, Flag.CACHE_MODE_LOCAL);
+         cache1.getAdvancedCache().withFlags(CACHE_MODE_LOCAL).putForExternalRead(key, value);
 
          if (transactional)
             tm1.commit();",2009-11-03T23:51:12Z,277
"@@ -2,7 +2,7 @@
 
 import org.infinispan.Cache;
 import org.infinispan.config.Configuration;
-import org.infinispan.context.Flag;
+import static org.infinispan.context.Flag.SKIP_REMOTE_LOOKUP;
 import org.infinispan.replication.AsyncAPISyncReplTest;
 import org.infinispan.test.data.Key;
 import org.infinispan.util.Util;
@@ -31,7 +31,7 @@ protected void createCacheManagers() throws Throwable {
    @Override
    protected void assertOnAllCaches(Key k, String v) {
       Object real;
-      assert Util.safeEquals((real = c1.getAdvancedCache().get(k, Flag.SKIP_REMOTE_LOOKUP)), v) : ""Error on cache 1.  Expected "" + v + "" and got "" + real;
-      assert Util.safeEquals((real = c2.getAdvancedCache().get(k, Flag.SKIP_REMOTE_LOOKUP)), v) : ""Error on cache 2.  Expected "" + v + "" and got "" + real;
+      assert Util.safeEquals((real = c1.getAdvancedCache().withFlags(SKIP_REMOTE_LOOKUP).get(k)), v) : ""Error on cache 1.  Expected "" + v + "" and got "" + real;
+      assert Util.safeEquals((real = c2.getAdvancedCache().withFlags(SKIP_REMOTE_LOOKUP).get(k)), v) : ""Error on cache 2.  Expected "" + v + "" and got "" + real;
    }
 }
\ No newline at end of file",2009-11-03T23:51:12Z,278
"@@ -14,7 +14,7 @@ public void testSkipLookupOnGet() {
       assertIsNotInL1(c3, k1);
       assertIsNotInL1(c4, k1);
 
-      assert c4.getAdvancedCache().get(k1, SKIP_REMOTE_LOOKUP) == null;
+      assert c4.getAdvancedCache().withFlags(SKIP_REMOTE_LOOKUP).get(k1) == null;
 
       assertOwnershipAndNonOwnership(k1);
    }
@@ -28,7 +28,7 @@ public void testCorrectFunctionalityOnConditionalWrite() {
       assertIsNotInL1(c3, k1);
       assertIsNotInL1(c4, k1);
 
-      assert c4.getAdvancedCache().putIfAbsent(k1, ""new_val"", SKIP_REMOTE_LOOKUP) == null;
+      assert c4.getAdvancedCache().withFlags(SKIP_REMOTE_LOOKUP).putIfAbsent(k1, ""new_val"") == null;
 
       assertIsInContainerImmortal(c1, k1);
       assertIsInContainerImmortal(c2, k1);
@@ -45,7 +45,7 @@ public void testCorrectFunctionalityOnUnconditionalWrite() {
       assertIsNotInL1(c3, k1);
       assertIsNotInL1(c4, k1);
 
-      assert c4.getAdvancedCache().put(k1, ""new_val"", SKIP_REMOTE_LOOKUP) == null;
+      assert c4.getAdvancedCache().withFlags(SKIP_REMOTE_LOOKUP).put(k1, ""new_val"") == null;
       assert c3.get(k1).equals(""new_val"");
       assertOnAllCachesAndOwnership(k1, ""new_val"");
    }",2009-11-03T23:51:12Z,279
"@@ -3,7 +3,7 @@
 import org.infinispan.Cache;
 import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.config.Configuration;
-import org.infinispan.context.Flag;
+import static org.infinispan.context.Flag.CACHE_MODE_LOCAL;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.data.Key;
 import org.infinispan.util.Util;
@@ -44,7 +44,7 @@ private void assertInvalidated(Key k, String value) {
    private void initC2(Key k) {
       Cache c1 = cache(0,getClass().getSimpleName());
       Cache c2 = cache(1,getClass().getSimpleName());
-      c2.getAdvancedCache().put(k, ""v"", Flag.CACHE_MODE_LOCAL);
+      c2.getAdvancedCache().withFlags(CACHE_MODE_LOCAL).put(k, ""v"");
    }
 
    public void testAsyncMethods() throws ExecutionException, InterruptedException {",2009-11-03T23:51:12Z,280
"@@ -7,7 +7,7 @@
 import org.infinispan.commands.write.ClearCommand;
 import org.infinispan.commands.write.InvalidateCommand;
 import org.infinispan.config.Configuration;
-import org.infinispan.context.Flag;
+import static org.infinispan.context.Flag.CACHE_MODE_LOCAL;
 import org.infinispan.remoting.rpc.ResponseFilter;
 import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
@@ -45,9 +45,9 @@ protected void createCacheManagers() throws Throwable {
    public void testRemove() throws Exception {
       AdvancedCache cache1 = cache(0,""invalidation"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""invalidation"").getAdvancedCache();
-      cache1.put(""key"", ""value"", Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value"");
       assertEquals(""value"", cache1.get(""key""));
-      cache2.put(""key"", ""value"", Flag.CACHE_MODE_LOCAL);
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value"");
       assertEquals(""value"", cache2.get(""key""));
 
       replListener(cache2).expectAny();
@@ -214,7 +214,7 @@ public void testCacheMode() throws Exception {
    public void testPutIfAbsent() {
       AdvancedCache cache1 = cache(0,""invalidation"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""invalidation"").getAdvancedCache();
-      assert null == cache2.put(""key"", ""value"", Flag.CACHE_MODE_LOCAL);
+      assert null == cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value"");
       assert cache2.get(""key"").equals(""value"");
       assert cache1.get(""key"") == null;
 
@@ -225,7 +225,7 @@ public void testPutIfAbsent() {
       assert cache1.get(""key"").equals(""value"");
       assert cache2.get(""key"") == null;
 
-      assert null == cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      assert null == cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
 
       assert cache1.get(""key"").equals(""value"");
       assert cache2.get(""key"").equals(""value2"");
@@ -239,8 +239,8 @@ public void testPutIfAbsent() {
    public void testRemoveIfPresent() {
       AdvancedCache cache1 = cache(0,""invalidation"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""invalidation"").getAdvancedCache();
-      cache1.put(""key"", ""value1"", Flag.CACHE_MODE_LOCAL);
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value1"");
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
       assert cache1.get(""key"").equals(""value1"");
       assert cache2.get(""key"").equals(""value2"");
 
@@ -260,8 +260,8 @@ public void testRemoveIfPresent() {
    public void testClear() {
       AdvancedCache cache1 = cache(0,""invalidation"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""invalidation"").getAdvancedCache();
-      cache1.put(""key"", ""value1"", Flag.CACHE_MODE_LOCAL);
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value1"");
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
       assert cache1.get(""key"").equals(""value1"");
       assert cache2.get(""key"").equals(""value2"");
 
@@ -276,7 +276,7 @@ public void testClear() {
    public void testReplace() {
       AdvancedCache cache1 = cache(0,""invalidation"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""invalidation"").getAdvancedCache();
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"").equals(""value2"");
 
@@ -285,7 +285,7 @@ public void testReplace() {
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"").equals(""value2"");
 
-      assert null == cache1.put(""key"", ""valueN"", Flag.CACHE_MODE_LOCAL);
+      assert null == cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""valueN"");
 
       replListener(cache2).expect(InvalidateCommand.class);
       cache1.replace(""key"", ""value1"");
@@ -298,7 +298,7 @@ public void testReplace() {
    public void testReplaceWithOldVal() {
       AdvancedCache cache1 = cache(0,""invalidation"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""invalidation"").getAdvancedCache();
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"").equals(""value2"");
 
@@ -307,7 +307,7 @@ public void testReplaceWithOldVal() {
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"").equals(""value2"");
 
-      assert null == cache1.put(""key"", ""valueN"", Flag.CACHE_MODE_LOCAL);
+      assert null == cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""valueN"");
 
       assert !cache1.replace(""key"", ""valueOld"", ""value1""); // should do nothing since there is nothing to replace on cache1
 
@@ -325,12 +325,12 @@ public void testReplaceWithOldVal() {
    public void testLocalOnlyClear() {
       AdvancedCache cache1 = cache(0,""invalidation"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""invalidation"").getAdvancedCache();
-      cache1.put(""key"", ""value1"", Flag.CACHE_MODE_LOCAL);
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value1"");
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
       assert cache1.get(""key"").equals(""value1"");
       assert cache2.get(""key"").equals(""value2"");
 
-      cache1.clear(Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).clear();
 
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"") != null;",2009-11-03T23:51:12Z,281
"@@ -7,7 +7,7 @@
 import org.infinispan.commands.write.RemoveCommand;
 import org.infinispan.commands.write.ReplaceCommand;
 import org.infinispan.config.Configuration;
-import org.infinispan.context.Flag;
+import static org.infinispan.context.Flag.CACHE_MODE_LOCAL;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
@@ -58,7 +58,7 @@ public void put() {
    public void remove() {
       AdvancedCache cache1 = cache(0,""replication"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""replication"").getAdvancedCache();
-      cache2.put(""key"", ""value"", Flag.CACHE_MODE_LOCAL);
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value"");
       assert cache2.get(""key"").equals(""value"");
       assert cache1.get(""key"") == null;
 
@@ -69,8 +69,8 @@ public void remove() {
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"") == null;
 
-      cache1.put(""key"", ""value"", Flag.CACHE_MODE_LOCAL);
-      cache2.put(""key"", ""value"", Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value"");
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value"");
       assert cache1.get(""key"").equals(""value"");
       assert cache2.get(""key"").equals(""value"");
 
@@ -85,7 +85,7 @@ public void remove() {
    public void testPutIfAbsent() {
       AdvancedCache cache1 = cache(0,""replication"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""replication"").getAdvancedCache();
-      cache2.put(""key"", ""valueOld"", Flag.CACHE_MODE_LOCAL);
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""valueOld"");
       assert cache2.get(""key"").equals(""valueOld"");
       assert cache1.get(""key"") == null;
 
@@ -96,7 +96,7 @@ public void testPutIfAbsent() {
       assert cache1.get(""key"").equals(""value"");
       assert cache2.get(""key"").equals(""value"");
 
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
 
       assert cache1.get(""key"").equals(""value"");
       assert cache2.get(""key"").equals(""value2"");
@@ -110,8 +110,8 @@ public void testPutIfAbsent() {
    public void testRemoveIfPresent() {
       AdvancedCache cache1 = cache(0,""replication"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""replication"").getAdvancedCache();
-      cache1.put(""key"", ""value1"", Flag.CACHE_MODE_LOCAL);
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value1"");
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
       assert cache1.get(""key"").equals(""value1"");
       assert cache2.get(""key"").equals(""value2"");
 
@@ -131,8 +131,8 @@ public void testRemoveIfPresent() {
    public void testClear() {
       AdvancedCache cache1 = cache(0,""replication"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""replication"").getAdvancedCache();
-      cache1.put(""key"", ""value1"", Flag.CACHE_MODE_LOCAL);
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value1"");
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
       assert cache1.get(""key"").equals(""value1"");
       assert cache2.get(""key"").equals(""value2"");
 
@@ -147,7 +147,7 @@ public void testClear() {
    public void testReplace() {
       AdvancedCache cache1 = cache(0,""replication"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""replication"").getAdvancedCache();
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"").equals(""value2"");
 
@@ -156,7 +156,7 @@ public void testReplace() {
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"").equals(""value2"");
 
-      cache1.put(""key"", ""valueN"", Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""valueN"");
 
       replListener(cache2).expect(ReplaceCommand.class);
       cache1.replace(""key"", ""value1"");
@@ -169,7 +169,7 @@ public void testReplace() {
    public void testReplaceWithOldVal() {
       AdvancedCache cache1 = cache(0,""replication"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""replication"").getAdvancedCache();
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"").equals(""value2"");
 
@@ -178,7 +178,7 @@ public void testReplaceWithOldVal() {
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"").equals(""value2"");
 
-      cache1.put(""key"", ""valueN"", Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""valueN"");
 
       cache1.replace(""key"", ""valueOld"", ""value1""); // should do nothing since there is nothing to replace on cache1
 
@@ -196,12 +196,12 @@ public void testReplaceWithOldVal() {
    public void testLocalOnlyClear() {
       AdvancedCache cache1 = cache(0,""replication"").getAdvancedCache();
       AdvancedCache cache2 = cache(1,""replication"").getAdvancedCache();
-      cache1.put(""key"", ""value1"", Flag.CACHE_MODE_LOCAL);
-      cache2.put(""key"", ""value2"", Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value1"");
+      cache2.withFlags(CACHE_MODE_LOCAL).put(""key"", ""value2"");
       assert cache1.get(""key"").equals(""value1"");
       assert cache2.get(""key"").equals(""value2"");
 
-      cache1.clear(Flag.CACHE_MODE_LOCAL);
+      cache1.withFlags(CACHE_MODE_LOCAL).clear();
 
       assert cache1.get(""key"") == null;
       assert cache2.get(""key"") != null;",2009-11-03T23:51:12Z,282
"@@ -40,6 +40,7 @@
 import org.infinispan.remoting.ReplicationQueue;
 import org.infinispan.remoting.ReplicationQueueImpl;
 import org.infinispan.transaction.LockingMode;
+import org.infinispan.transaction.TransactionMode;
 import org.infinispan.transaction.lookup.GenericTransactionManagerLookup;
 import org.infinispan.transaction.lookup.TransactionManagerLookup;
 import org.infinispan.transaction.lookup.TransactionSynchronizationRegistryLookup;
@@ -1162,6 +1163,14 @@ public LockingMode getTransactionLockingMode() {
       return transaction.lockingMode;
    }
 
+   /**
+    * Returns cache's transaction mode.
+    * @see TransactionMode
+    */
+   public TransactionMode getTransactionMode() {
+      return transaction.transactionMode;
+   }
+
    /**
     * If the cache is transactional (i.e. {@link #isTransactionalCache()} == true) and transactionAutoCommit is enabled
     * then for single operation transactions the user doesn't need to manually start a transaction, but a transactions
@@ -1585,7 +1594,7 @@ public boolean isOnePhaseCommit() {
     * @see #isTransactionAutoCommit()
     */
    public boolean isTransactionalCache() {
-      return transaction.transactionalCache;
+      return transaction.transactionMode.equals(TransactionMode.TRANSACTIONAL);
    }
 
    public boolean isExpirationReaperEnabled() {
@@ -1642,6 +1651,9 @@ public static class TransactionType extends AbstractFluentConfigurationBean impl
       @ConfigurationDocRef(bean = Configuration.class, targetElement = ""getTransactionLockingMode"")
       protected LockingMode lockingMode = LockingMode.OPTIMISTIC;
 
+      @ConfigurationDocRef(bean = Configuration.class, targetElement = ""getTransactionMode"")
+      protected TransactionMode transactionMode = TransactionMode.TRANSACTIONAL;
+
       @ConfigurationDocRef(bean = Configuration.class, targetElement = ""isTransactionAutoCommit"")
       protected boolean autoCommit = true;
 
@@ -1672,9 +1684,9 @@ public String getTransactionManagerLookupClass() {
       }
 
       @Override
-      public FluentConfiguration.TransactionConfig transactionalCache(boolean isTransactionalCache) {
-         testImmutability(""transactionalCache"");
-         this.transactionalCache = isTransactionalCache;
+      public TransactionConfig transactionMode(TransactionMode txMode) {
+         testImmutability(""transactionMode"");
+         this.transactionMode = txMode;
          return this;
       }
 
@@ -2172,8 +2184,8 @@ public TransactionConfig autoCommit(boolean enabled) {
       }
 
       @Override
-      public TransactionConfig transactionalCache(boolean isTransactionalCache) {
-         return transaction().transactionalCache(isTransactionalCache);
+      public TransactionConfig transactionMode(TransactionMode transactionMode) {
+         return transaction().transactionMode(transactionMode);
       }
    }
 ",2011-09-26T15:43:15Z,160
"@@ -33,6 +33,7 @@
 import org.infinispan.loaders.CacheLoaderConfig;
 import org.infinispan.remoting.ReplicationQueue;
 import org.infinispan.transaction.LockingMode;
+import org.infinispan.transaction.TransactionMode;
 import org.infinispan.transaction.lookup.TransactionManagerLookup;
 import org.infinispan.transaction.lookup.TransactionSynchronizationRegistryLookup;
 import org.infinispan.util.concurrent.IsolationLevel;
@@ -225,11 +226,6 @@ public static interface TransactionConfig extends FluentTypes {
       @Deprecated
       TransactionConfig useEagerLocking(Boolean useEagerLocking);
 
-      /**
-       * Configures whether this cache is transactional or not.
-       */
-      FluentConfiguration.TransactionConfig transactionalCache(boolean isTransactionalCache);
-
       /**
        * Only has effect for DIST mode and when useEagerLocking is set to true. When this is
        * enabled, then only one node is locked in the cluster, disregarding numOwners config. On the
@@ -268,6 +264,12 @@ public static interface TransactionConfig extends FluentTypes {
        */
       TransactionConfig lockingMode(LockingMode lockingMode);
 
+      /**
+       * Configures whether the cache is transactional or not.
+       * @see TransactionMode
+       */
+      TransactionConfig transactionMode(TransactionMode transactionMode);
+
       /**
        * @see org.infinispan.config.Configuration#isTransactionAutoCommit().
        */",2011-09-26T15:43:15Z,161
"@@ -29,7 +29,7 @@
 import org.infinispan.factories.annotations.DefaultFactoryFor;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.transaction.lookup.TransactionManagerLookup;
+import org.infinispan.transaction.TransactionMode;
 import org.infinispan.transaction.xa.recovery.RecoveryManager;
 import org.infinispan.transaction.xa.recovery.RecoveryManagerImpl;
 
@@ -88,7 +88,7 @@ private Configuration getDefaultRecoveryCacheConfig() {
       Configuration config = new Configuration();
       //the recovery cache should not participate in main cache's transactions, especially because removals
       // from this cache are executed in the context of a finalised transaction and cause issues.
-      config.fluent().transaction().transactionalCache(false);
+      config.fluent().transaction().transactionMode(TransactionMode.NON_TRANSACTIONAL);
       config.fluent().clustering().mode(Configuration.CacheMode.LOCAL);
       config.fluent().expiration().lifespan(DEFAULT_EXPIRY);
       config.fluent().recovery().disable();",2011-09-26T15:43:15Z,283
"@@ -0,0 +1,35 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2011 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.transaction;
+
+/**
+ * Enumeration containing the available transaction modes for a cache.
+ *
+ * @author Mircea Markus
+ * @since 5.1
+ */
+public enum TransactionMode {
+   NON_TRANSACTIONAL,
+   TRANSACTIONAL
+}",2011-09-26T15:43:15Z,284
"@@ -28,6 +28,7 @@
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
 import org.infinispan.test.fwk.TransactionSetup;
+import org.infinispan.transaction.TransactionMode;
 import org.testng.annotations.AfterClass;
 import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
@@ -120,7 +121,7 @@ private Cache<String, String> createCache(String name) {
       Configuration c = new Configuration();
       c.setTransactionManagerLookupClass(TransactionSetup.getManagerLookup());
       c.setInvocationBatchingEnabled(true);
-      c.fluent().transaction().transactionalCache(true);
+      c.fluent().transaction().transactionMode(TransactionMode.TRANSACTIONAL);
       assert c.getTransactionManagerLookupClass() != null : ""Should have a transaction manager lookup class attached!!"";
       cm.defineConfiguration(name, c);
       return cm.getCache(name);",2011-09-26T15:43:15Z,285
"@@ -25,6 +25,7 @@
 
 import org.infinispan.test.AbstractCacheTest;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.transaction.TransactionMode;
 import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
 import org.testng.annotations.Test;
 
@@ -38,9 +39,9 @@ public class TransactionalCacheConfigTest extends AbstractCacheTest {
    public void test() {
       final Configuration c = TestCacheManagerFactory.getDefaultConfiguration(false);
       assert !c.isTransactionalCache();
-      c.fluent().transaction().transactionalCache(true);
+      c.fluent().transaction().transactionMode(TransactionMode.TRANSACTIONAL);
       assert c.isTransactionalCache();
-      c.fluent().transaction().transactionalCache(false);
+      c.fluent().transaction().transactionMode(TransactionMode.NON_TRANSACTIONAL);
       assert !c.isTransactionalCache();
       c.fluent().transaction().transactionManagerLookup(new DummyTransactionManagerLookup());
       assert c.isTransactionalCache();",2011-09-26T15:43:15Z,286
"@@ -37,6 +37,7 @@
 import org.infinispan.test.SingleCacheManagerTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.transaction.TransactionMode;
 import org.testng.annotations.Test;
 
 import java.util.concurrent.Callable;
@@ -69,7 +70,7 @@ protected EmbeddedCacheManager createCacheManager() throws Exception {
             .addCacheLoader(new DummyInMemoryCacheStore.Cfg())
          .customInterceptors()
             .add(sdi).after(InvocationContextInterceptor.class)
-         .transaction().transactionalCache(false)
+         .transaction().transactionMode(TransactionMode.NON_TRANSACTIONAL)
          .build();
 
       return TestCacheManagerFactory.createCacheManager(config);",2011-09-26T15:43:15Z,287
"@@ -33,6 +33,7 @@
 import org.infinispan.test.AbstractInfinispanTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.transaction.TransactionMode;
 import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
 import org.infinispan.transaction.tm.DummyTransactionManager;
 import org.testng.annotations.AfterMethod;
@@ -58,7 +59,7 @@ public void testForceSharedComponents() {
       Configuration defaultCfg = new Configuration();
       defaultCfg.setCacheMode(Configuration.CacheMode.REPL_SYNC);
       defaultCfg.setFetchInMemoryState(false);
-      defaultCfg.fluent().transaction().transactionalCache(false);
+      defaultCfg.fluent().transaction().transactionMode(TransactionMode.NON_TRANSACTIONAL);
       defaultCfg.setFetchInMemoryState(false);
 
       // cache manager with default configuration",2011-09-26T15:43:15Z,288
"@@ -30,6 +30,7 @@
 import org.infinispan.test.AbstractInfinispanTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.transaction.TransactionMode;
 import org.infinispan.util.concurrent.IsolationLevel;
 import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
@@ -59,7 +60,7 @@ public class CacheNotifierTest extends AbstractInfinispanTest {
    @BeforeMethod(alwaysRun = true)
    public void setUp() throws Exception {
       Configuration c = new Configuration();
-      c.fluent().transaction().transactionalCache(false);
+      c.fluent().transaction().transactionMode(TransactionMode.NON_TRANSACTIONAL);
       c.setCacheMode(Configuration.CacheMode.LOCAL);
       c.setIsolationLevel(IsolationLevel.REPEATABLE_READ);
       cm = TestCacheManagerFactory.createCacheManager(c);",2011-09-26T15:43:15Z,132
"@@ -30,6 +30,7 @@
 import org.infinispan.manager.DefaultCacheManager;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.remoting.transport.jgroups.JGroupsTransport;
+import org.infinispan.transaction.TransactionMode;
 import org.infinispan.util.LegacyKeySupportSystemProperties;
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
@@ -131,7 +132,7 @@ public static EmbeddedCacheManager createLocalCacheManager(boolean transactional
    }
 
    private static void markAsTransactional(boolean transactional, Configuration c) {
-      c.fluent().transaction().transactionalCache(transactional);
+      c.fluent().transaction().transactionMode(transactional ? TransactionMode.TRANSACTIONAL : TransactionMode.NON_TRANSACTIONAL);
    }
 
    private static void updateTransactionSupport(Configuration c) {",2011-09-26T15:43:15Z,130
"@@ -132,7 +132,6 @@ public void testNotLocalKeyChanged() throws Exception {
          List<Address> owners = advancedCache(2).getDistributionManager().getConsistentHash().locate(o, 2);
          boolean mainOwnerChanged = owners.get(0).equals(address(2));
          if (mainOwnerChanged) {
-            System.out.println(""Found local! "" + o);
             log.infof(""Found local! %s"", o);
             testCommitFailsAndOldValues(o, suspend);
             return;
@@ -156,7 +155,7 @@ private void testCommitFailsAndOldValues(Object o, Transaction t) throws Invalid
          assert false;
          //fail
       } catch (Exception e) {
-         e.printStackTrace();
+//         e.printStackTrace();
          //expected
       }
 ",2011-09-26T15:43:15Z,289
"@@ -28,6 +28,7 @@
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.transaction.TransactionMode;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.testng.annotations.Test;
@@ -53,7 +54,7 @@ protected void createCacheManagers() throws Throwable {
       c.setSyncCommitPhase(true);
       c.setSyncRollbackPhase(true);
       c.setUseLockStriping(false);
-      c.fluent().transaction().transactionalCache(true);
+      c.fluent().transaction().transactionMode(TransactionMode.TRANSACTIONAL);
 
       CacheContainer container = TestCacheManagerFactory.createClusteredCacheManager(c);
       container.start();",2011-09-26T15:43:15Z,290
"@@ -25,6 +25,7 @@
 import org.infinispan.config.Configuration;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
+import org.infinispan.transaction.TransactionMode;
 import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
 import org.infinispan.transaction.tm.DummyTransaction;
 import org.infinispan.transaction.xa.recovery.SerializableXid;
@@ -130,7 +131,7 @@ public boolean isSatisfied() throws Exception {
       assert inDoubtTransactions.contains(new SerializableXid(t1_2.getXid()));
       assert inDoubtTransactions.contains(new SerializableXid(t1_3.getXid()));
 
-      configuration.fluent().transaction().transactionalCache(true);
+      configuration.fluent().transaction().transactionMode(TransactionMode.NON_TRANSACTIONAL);
       addClusterEnabledCacheManager(configuration);
       defineRecoveryCache(1);
       TestingUtil.blockUntilViewsReceived(60000, cache(0), cache(1));",2011-09-26T15:43:15Z,291
"@@ -22,8 +22,6 @@
  */
 package org.infinispan.loaders;
 
-import org.infinispan.atomic.AtomicMap;
-import org.infinispan.config.CacheLoaderManagerConfig;
 import org.infinispan.config.Configuration;
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
 import org.infinispan.manager.EmbeddedCacheManager;
@@ -51,11 +49,11 @@ public class TreeCacheWithLoaderTest extends SingleCacheManagerTest {
    @Override
    protected EmbeddedCacheManager createCacheManager() throws Exception {
       // start a single cache instance
-      Configuration c = getDefaultStandaloneConfig(true);
-      c.setInvocationBatchingEnabled(true);
-      CacheLoaderManagerConfig clmc = new CacheLoaderManagerConfig();
-      clmc.addCacheLoaderConfig(new DummyInMemoryCacheStore.Cfg());
-      c.setCacheLoaderManagerConfig(clmc);
+      Configuration c = getDefaultStandaloneConfig(true).fluent()
+            .invocationBatching()
+            .loaders()
+               .addCacheLoader(new DummyInMemoryCacheStore.Cfg(getClass().getName()))
+            .build();
       EmbeddedCacheManager cm = TestCacheManagerFactory.createCacheManager(c, true);
       cache = new TreeCacheImpl<String, String>(cm.getCache());
       CacheLoaderManager m = TestingUtil.extractComponent(cache.getCache(), CacheLoaderManager.class);",2011-06-10T13:14:03Z,292
"@@ -87,7 +87,7 @@ protected Integer initialValue() {
    private static final Pattern TCP_INITIAL_HOST = Pattern.compile(""initial_hosts=[^;]*"");
    private static final Pattern UDP_MCAST_ADDRESS = Pattern.compile(""mcast_addr=[^;]*"");
    private static final Pattern UDP_MCAST_PORT = Pattern.compile(""mcast_port=[^;]*"");
-   private static final Pattern TEST_NAME = Pattern.compile(""testName=[^;]*"");
+   private static final Pattern TEST_NAME = Pattern.compile(""testName=[^;]"");
    private static final Pattern FD_PROT = Pattern.compile("":FD\\(max_tries=[0-9]+;timeout=[0-9]+\\)"");
    private static final Pattern FD_SOCK_PROT = Pattern.compile("":FD_SOCK"");
    private static final Pattern VER_SUSPECT_PROT = Pattern.compile("":VERIFY_SUSPECT\\(timeout=[0-9]+\\)"");
@@ -146,7 +146,7 @@ private static String removePattern(Matcher m) {
    private static String getTestPingDiscovery(String fullTestName, String transportCfg) {
       Matcher m = TEST_NAME.matcher(transportCfg);
       if (m.find()) {
-         return m.replaceFirst(""testName="" + fullTestName);
+         return m.replaceFirst(""testName="" + fullTestName + "")"");
       } else {
          throw new IllegalStateException();
       }",2011-07-21T12:11:50Z,265
"@@ -2,19 +2,23 @@
 
 import org.jgroups.Address;
 import org.jgroups.Event;
-import org.jgroups.Message;
 import org.jgroups.PhysicalAddress;
+import org.jgroups.View;
 import org.jgroups.annotations.Property;
+import org.jgroups.conf.ClassConfigurator;
 import org.jgroups.protocols.DISCARD;
 import org.jgroups.protocols.Discovery;
 import org.jgroups.protocols.PingData;
-import org.jgroups.protocols.PingHeader;
+import org.jgroups.protocols.pbcast.JoinRsp;
 import org.jgroups.stack.Protocol;
 import org.jgroups.util.Promise;
+import org.jgroups.util.Tuple;
 import org.jgroups.util.UUID;
 
 import java.util.Arrays;
+import java.util.Collections;
 import java.util.HashMap;
+import java.util.LinkedList;
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
@@ -27,9 +31,6 @@
  * method calls rather than network calls. Clearly, this protocol only works
  * for clusters that are created in memory.
  *
- * NOTE: This protocol implementation requires a new JGroups release cos it
- * relies on sendDiscoveryResponse() method being protected.
- *
  * @author Galder Zamarreño
  * @since 5.0
  */
@@ -38,162 +39,186 @@ public class TEST_PING extends Discovery {
    @Property(description=""Test name. Default is empty String."")
    private String testName = """";
 
-   private String clusterName;
-
    private DISCARD discard;
 
-   private boolean discardChecked;
-
-   // Note: Thread locals won't work cos by the time discovery gets around to
-   // sending messages, each cluster will be running a different thread.
+   // Note: Thread locals could work but if two nodes of the same cluster are
+   // started from different threads, a thread local based solution would not
+   // work, so we're sticking to an static solution
 
    // <Test Name, Cluster Name -> <Node Name -> Discovery>>
-   private static ConcurrentMap<DiscoveryKey, Map<Address, Discovery>> all =
-         new ConcurrentHashMap<DiscoveryKey, Map<Address, Discovery>>();
+   private static ConcurrentMap<DiscoveryKey, Map<Address, TEST_PING>> all =
+         new ConcurrentHashMap<DiscoveryKey, Map<Address, TEST_PING>>();
 
-   public TEST_PING() {
-      // Assign a user-defined id for the protocol which must be over 1000
-      id = 1320;
+   static {
+      ClassConfigurator.addProtocol((short) 1320, TEST_PING.class);
    }
 
    @Override
-   public boolean isDynamic() {
-      return false;
-   }
+   protected List<PingData> findInitialMembers(Promise<JoinRsp> promise,
+         int numExpectedRsps, boolean breakOnCoord, boolean returnViewsOnly) {
 
-   @Override
-   public void start() throws Exception {
-      super.start();
-   }
+      Map<Address, TEST_PING> discoveries = registerInDiscoveries();
 
-   @Override
-   public void stop() {
-      super.stop();
-      DiscoveryKey key = new DiscoveryKey(testName, clusterName);
-      Map<Address, Discovery> discoveries = all.get(key);
-      if (discoveries != null) {
-         discoveries.remove(local_addr);
-         if (discoveries.isEmpty()) {
-            boolean removed = all.remove(key, discoveries);
-            if (!removed && all.containsKey(key)) {
-               throw new IllegalStateException(String.format(
-                  ""Concurrent discovery removal for test=%s but not removed??"",
-                  testName));
+      // Only send message if DISCARD is not used, or if DISCARD is
+      // configured but it's not discarding messages.
+      boolean discardEnabled = isDiscardEnabled(this);
+      if (!discardEnabled) {
+         if (!discoveries.isEmpty()) {
+            LinkedList<PingData> rsps = new LinkedList<PingData>();
+            for (TEST_PING discovery : discoveries.values()) {
+               // Avoid sending to self! Since there are single instances of
+               // discovery protocol in each node, just compare them by ref.
+               boolean traceEnabled = log.isTraceEnabled();
+               if (discovery != this) {
+                  boolean remoteDiscardEnabled = isDiscardEnabled(discovery);
+                  if (!remoteDiscardEnabled) {
+                     addPingRsp(returnViewsOnly, rsps, discovery);
+                  } else {
+                     if (traceEnabled)
+                        log.trace(""Skipping sending response cos DISCARD is on"");
+                     return Collections.emptyList();
+                  }
+               } else {
+                  if (traceEnabled)
+                     log.trace(""Skipping sending discovery to self"");
+               }
             }
+            return rsps;
+         } else {
+            log.debug(""No other nodes yet, so skip sending get-members request"");
+            return Collections.emptyList();
          }
       } else {
-         log.debug(String.format(
-            ""Test (%s) started but not registered discovery"", key));
+         log.debug(""Not sending discovery because DISCARD is on"");
+         return Collections.emptyList();
       }
    }
 
-   @Override
-   public void sendGetMembersRequest(String cluster_name, Promise promise,
-                                     boolean returnViewsOnly) throws Exception {
-      clusterName = cluster_name;
+   private boolean isDiscardEnabled(TEST_PING discovery) {
+      // Not pretty but since this protocol does not rely on the transport, the
+      // only possible way to discard messages is by hacking the protocol itself.
+      List<Protocol> protocols = discovery.getProtocolStack().getProtocols();
+      for (Protocol protocol : protocols) {
+         if (protocol instanceof DISCARD) {
+            discovery.discard = (DISCARD) protocol;
+         }
+      }
+
+      return discovery.discard != null && discovery.discard.isDiscardAll();
+   }
+
+   private void addPingRsp(boolean returnViewsOnly, LinkedList<PingData> rsps,
+                           TEST_PING discovery) {
+      // Rather than relying on transport (PING) or your own multicast channel
+      // (MPING), talk to other discovery instances directly via Java method
+      // calls and discover the other nodes in the cluster.
+
+      // Add mapping of remote's address -> physical addr to the local cache
+      mapAddrWithPhysicalAddr(this, discovery);
 
-      DiscoveryKey key = new DiscoveryKey(testName, clusterName);
-      Map<Address, Discovery> discoveries = all.get(key);
+      // Add mapping of local's address -> physical addr to the remote cache
+      mapAddrWithPhysicalAddr(discovery, this);
+
+      Address localAddr = discovery.getLocalAddr();
+      List<PhysicalAddress> physicalAddrs = returnViewsOnly ? null :
+         Arrays.asList((PhysicalAddress) discovery.down(
+               new Event(Event.GET_PHYSICAL_ADDRESS, localAddr)));
+      String logicalName = UUID.get(localAddr);
+      PingData pingRsp = new PingData(localAddr, discovery.getJGroupsView(),
+         discovery.isServer(), logicalName, physicalAddrs);
+
+      if (log.isTraceEnabled())
+         log.trace(String.format(""Returning ping rsp: %s"", pingRsp));
+
+      rsps.add(pingRsp);
+   }
+
+   private void mapAddrWithPhysicalAddr(TEST_PING local, TEST_PING remote) {
+      PhysicalAddress physical_addr = (PhysicalAddress)
+         remote.down(new Event(Event.GET_PHYSICAL_ADDRESS, remote.getLocalAddr()));
+      local.down(new Event(Event.SET_PHYSICAL_ADDRESS,
+         new Tuple<Address, PhysicalAddress>(remote.getLocalAddr(), physical_addr)));
+
+      if (log.isTraceEnabled())
+         log.trace(String.format(""Map %s with physical address %s in %s"",
+                                 remote.getLocalAddr(), physical_addr, local));
+   }
+
+   private Map<Address, TEST_PING> registerInDiscoveries() {
+      DiscoveryKey key = new DiscoveryKey(testName, group_addr);
+      Map<Address, TEST_PING> discoveries = all.get(key);
       if (discoveries == null) {
-         discoveries = new HashMap<Address, Discovery>();
+         discoveries = new HashMap<Address, TEST_PING>();
          Map ret = all.putIfAbsent(key, discoveries);
          if (ret != null)
             discoveries = ret;
       }
-      if (log.isTraceEnabled())
-         log.trace(String.format(""Discoveries for %s are : %s"", key, discoveries));
+      boolean traceEnabled = log.isTraceEnabled();
+      if (traceEnabled)
+         log.trace(String.format(
+               ""Discoveries for %s are : %s"", key, discoveries));
 
       if (!discoveries.containsKey(local_addr)) {
          discoveries.put(local_addr, this);
 
-         if (log.isTraceEnabled())
+         if (traceEnabled)
             log.trace(String.format(
                   ""Add discovery for %s to cache.  The cache now contains: %s"",
                   local_addr, discoveries));
       }
+      return discoveries;
+   }
 
-      // Only send message if DISCARD is not used, or if DISCARD is
-      // configured but it's not discarding messages.
-      if (discard == null || !discard.isDiscardAll()) {
-         Message msg = createGetMbrsReqMsg(clusterName, returnViewsOnly);
-         if (!discoveries.isEmpty()) {
-            for (Discovery discovery : discoveries.values()) {
-               // Avoid sending to self! Since there are single instances of
-               // discovery protocol in each node, just compare them by ref.
-               if (discovery != this) {
-                  // Rather than relying on transport (PING) or your own multicast
-                  // channel (MPING), simply pass the get-members-request to the
-                  // discovery protocol instances of the other nodes in the cluster.
-                  discovery.up(new Event(Event.MSG, msg));
-               }
-            }
-         } else {
-            log.debug(""No other nodes yet, so skip sending get-members request"");
+   @Override
+   public void stop() {
+      super.stop();
+      DiscoveryKey key = new DiscoveryKey(testName, group_addr);
+      Map<Address, TEST_PING> discoveries = all.get(key);
+      if (discoveries != null) {
+         removeDiscovery(key, discoveries);
+      } else {
+         log.debug(String.format(
+            ""Test (%s) started but not registered discovery"", key));
+      }
+   }
+
+   private void removeDiscovery(DiscoveryKey key, Map<Address, TEST_PING> discoveries) {
+      discoveries.remove(local_addr);
+      if (discoveries.isEmpty()) {
+         boolean removed = all.remove(key, discoveries);
+         if (!removed && all.containsKey(key)) {
+            throw new IllegalStateException(String.format(
+               ""Concurrent discovery removal for test=%s but not removed??"",
+               testName));
          }
-      } else if (discard != null && discard.isDiscardAll()) {
-         log.debug(""Not sending discovery because DISCARD is on"");
       }
    }
 
-   private Message createGetMbrsReqMsg(String clusterName, boolean returnViewsOnly) {
-      PhysicalAddress physical_addr = (PhysicalAddress)
-            down(new Event(Event.GET_PHYSICAL_ADDRESS, local_addr));
-      List<PhysicalAddress> physical_addrs = Arrays.asList(physical_addr);
-      PingData data = new PingData(
-            local_addr, null, false, UUID.get(local_addr), physical_addrs);
-      PingHeader hdr = new PingHeader(
-            PingHeader.GET_MBRS_REQ, data, clusterName);
-      hdr.return_view_only = returnViewsOnly;
-      Message msg = new Message(null);
-      msg.setFlag(Message.OOB);
-      msg.setSrc(local_addr);
-      msg.putHeader(this.id, hdr);
+   protected Address getLocalAddr() {
+      return local_addr;
+   }
 
-      if (log.isTraceEnabled())
-         log.trace(""Create GET_MBRS_REQ message: "" + data);
+   protected View getJGroupsView() {
+      return view;
+   }
 
-      return msg;
+   protected boolean isServer() {
+      return is_server;
    }
 
    @Override
-   protected void sendDiscoveryResponse(Address logical_addr,
-         List<PhysicalAddress> physical_addrs, boolean is_server,
-         String logical_name, Address sender) {
-      // Not pretty but since this protocol does not rely on the transport, the
-      // only possible way to discard messages is by hacking the protocol itself.
-      if (!discardChecked) {
-         List<Protocol> protocols = getProtocolStack().getProtocols();
-         for (Protocol protocol : protocols) {
-            if (protocol instanceof DISCARD) {
-               discard = (DISCARD) protocol;
-               break;
-            }
-         }
-         discardChecked = true;
-      }
-
-      if (discard == null || !discard.isDiscardAll()) {
-         PingData ping_rsp=new PingData(logical_addr, view, is_server,
-                                        logical_name, physical_addrs);
-         Message rsp_msg=new Message(sender, logical_addr, null);
-         rsp_msg.setFlag(Message.OOB);
-         PingHeader rsp_hdr=new PingHeader(PingHeader.GET_MBRS_RSP, ping_rsp);
-         rsp_msg.putHeader(this.id, rsp_hdr);
-
-         if(log.isTraceEnabled())
-            log.trace(String.format(
-                  ""%s received GET_MBRS_REQ from %s"", this, sender));
+   public void sendGetMembersRequest(String cluster_name, Promise promise, boolean return_views_only) throws Exception {
+      // No-op because it won't get called
+   }
 
-         // Instead of sending a get-members-response down the transport,
-         // update the cached discovery instances directly.
-         DiscoveryKey key = new DiscoveryKey(testName, clusterName);
-         Discovery discovery = all.get(key).get(sender);
-         if(log.isTraceEnabled())
-            log.trace(String.format(
-                  ""%s sending (dest=%s) response: %s"", this, sender, ping_rsp));
+   @Override
+   public boolean isDynamic() {
+      return false;
+   }
 
-         discovery.up(new Event(Event.MSG, rsp_msg));
-      }
+   @Override
+   public String toString() {
+      return ""TEST_PING@"" + local_addr;
    }
 
    private class DiscoveryKey {
@@ -240,9 +265,4 @@ public String toString() {
       }
    }
 
-   @Override
-   public String toString() {
-      return ""TEST_PING@"" + local_addr;
-   }
-
 }",2011-07-21T12:11:50Z,293
"@@ -52,7 +52,7 @@
         oob_thread_pool.queue_max_size=""100""
         oob_thread_pool.rejection_policy=""Run""/>
 
-   <org.infinispan.test.fwk.TEST_PING timeout=""1000"" ergonomics=""false"" testName=""""/>
+   <org.infinispan.test.fwk.TEST_PING ergonomics=""false"" testName=""""/>
 
    <!-- Ergonomics, new in JGroups 2.11, are disabled by default until JGRP-1253 is resolved -->
    <!--<TCPPING timeout=""3000""-->",2011-07-21T12:11:50Z,294
"@@ -57,7 +57,7 @@
          oob_thread_pool.queue_max_size=""100""
          oob_thread_pool.rejection_policy=""Run""/>
 
-   <org.infinispan.test.fwk.TEST_PING timeout=""250"" ergonomics=""false"" testName=""""/>
+   <org.infinispan.test.fwk.TEST_PING ergonomics=""false"" testName=""""/>
 
    <!--<PING timeout=""3000"" num_initial_members=""3""/>-->
    <MERGE2 max_interval=""30000"" min_interval=""10000""/>",2011-07-21T12:11:50Z,234
"@@ -133,7 +133,7 @@
       <version.jclouds>1.0-beta-9b</version.jclouds>
       <version.jetty>6.1.25</version.jetty>
       <version.jgoodies.forms>1.0.5</version.jgoodies.forms>
-      <version.jgroups>2.12.1.1.Final</version.jgroups>
+      <version.jgroups>2.12.1.3.Final</version.jgroups>
       <version.json>20090211</version.json>
       <version.jsr107>0.2.20110718.jboss</version.jsr107>
       <version.jstl>1.2</version.jstl>",2011-07-21T12:11:50Z,152
"@@ -119,7 +119,7 @@
       <version.scala>2.8.0</version.scala>
       <version.slf4j>1.6.1</version.slf4j>
       <version.spymemcached>2.5</version.spymemcached>
-      <version.testng>5.12.1</version.testng>
+      <version.testng>5.11</version.testng>
       <version.webdav.servlet>2.0</version.webdav.servlet>
       <version.xsom>20081112</version.xsom>
       <version.xstream>1.3.1</version.xstream>
@@ -131,6 +131,7 @@
          <artifactId>testng</artifactId>
          <version>${version.testng}</version>
          <scope>test</scope>
+	 <classifier>jdk15</classifier>
       </dependency>
       <dependency>
          <groupId>net.jcip</groupId>",2010-11-03T14:38:27Z,152
"@@ -22,10 +22,13 @@
  */
 package org.infinispan.distribution.ch;
 
+import static java.util.Collections.emptyList;
+import static java.util.Collections.singletonList;
 
 import java.io.IOException;
 import java.io.ObjectInput;
 import java.io.ObjectOutput;
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
@@ -181,6 +184,21 @@ public List<Address> getBackupsForNode(Address node, int replCount) {
       return locate(node, replCount);
    }
 
+   @Override
+   public int getHashSpace() {
+      return HASH_SPACE;
+   }
+
+
+   @Override
+   public int getHashId(Address a) {
+      Integer hashId = addressToHashIds.get(a);
+      if (hashId == null)
+         return -1;
+      else
+         return hashId;
+   }
+
    public int getNormalizedHash(Object key) {
       // more efficient impl
       int keyHashCode = hashFunction.hash(key);",2011-04-26T07:58:34Z,267
"@@ -91,6 +91,22 @@ public interface ConsistentHash {
     */
    boolean isKeyLocalToAddress(Address a, Object key, int replCount);
 
+   /**
+    * Returns the value between 0 and the hash space limit, or hash id, for a particular address. If there's no such
+    * value for an address, this method will return -1.
+    *
+    * @return An int between 0 and hash space if the address is present in the hash wheel, otherwise it returns -1.
+    */
+   int getHashId(Address a);
+
+   /**
+    * Returns the hash space constant for this consistent hash algorithm class. This integer is often used as modulus
+    * for arithmetic operations within the algorithm, for example, limiting the range of possible hash values.
+    * 
+    * @return A positive integer containing the hash space constant or 0 is not supported by implementation. 
+    */
+   int getHashSpace();
+
    /**
     * Returns the nodes that need will replicate their state if the specified node crashes. The return collection
     * should contain all the nodes that backup-ed on leaver and one of the nodes which acted as a backup for the leaver .",2011-04-26T07:58:34Z,295
"@@ -298,6 +298,16 @@ private int hash(Object object) {
       return hash;
    }
 
+   @Override
+   public int getHashId(Address a) {
+      throw new RuntimeException(""Not yet implemented"");
+   }
+
+   @Override
+   public int getHashSpace() {
+      return Integer.MAX_VALUE; // Entire positive integer range
+   }
+
    /**
     * @return A String representing the object pool.
     */",2011-04-26T07:58:34Z,296
"@@ -73,6 +73,11 @@ public List<Address> locate(Object key, int replCount) {
       return Immutables.immutableListConvert(addresses);
    }
 
+   @Override
+   public int getHashId(Address a) {
+      throw new UnsupportedOperationException(""Unsupported!"");
+   }
+
    public List<Address> getStateProvidersOnLeave(Address leaver, int replCount) {
       throw new UnsupportedOperationException(""Unsupported!"");
    }
@@ -87,6 +92,14 @@ public List<Address> getBackupsForNode(Address node, int replCount) {
       return oldCH.locate(node, replCount);
    }
 
+   @Override
+   public int getHashSpace() {
+      int oldHashSpace = oldCH.getHashSpace();
+      int newHashSpace = newCH.getHashSpace();
+      // In a union, the hash space is the biggest of the hash spaces.
+      return oldHashSpace > newHashSpace ? oldHashSpace : newHashSpace;
+   }
+
    public ConsistentHash getNewConsistentHash() {
       return newCH;
    }",2011-04-26T07:58:34Z,297
"@@ -40,7 +40,7 @@
  * @since 4.0
  */
 @NotThreadSafe
-public class ExposedByteArrayOutputStream extends ByteArrayOutputStream {
+public final class ExposedByteArrayOutputStream extends ByteArrayOutputStream {
    /**
     * Default buffer size after which if more buffer capacity is needed the buffer will grow by 25% rather than 100%
     */
@@ -78,7 +78,7 @@ public final byte[] getRawBuffer() {
    }
 
    @Override
-   public void write(byte[] b, int off, int len) {
+   public final void write(byte[] b, int off, int len) {
       if ((off < 0) || (off > b.length) || (len < 0) ||
             ((off + len) > b.length) || ((off + len) < 0)) {
          throw new IndexOutOfBoundsException();
@@ -98,7 +98,7 @@ public void write(byte[] b, int off, int len) {
    }
 
    @Override
-   public void write(int b) {
+   public final void write(int b) {
       int newcount = count + 1;
       if (newcount > buf.length) {
          byte newbuf[] = new byte[getNewBufferSize(buf.length, newcount)];
@@ -130,4 +130,12 @@ public final int getNewBufferSize(int curSize, int minNewSize) {
       else
          return Math.max(curSize + (curSize >> 2), minNewSize);
    }
+   
+   /**
+    * Overriden only to avoid unneeded synchronization
+    */
+   @Override
+   public final int size() {
+      return count;
+   }
 }",2011-05-12T23:30:12Z,75
"@@ -57,6 +57,7 @@
  * @author Manik Surtani (<a href=""mailto:manik@jboss.org"">manik@jboss.org</a>)
  * @author Mircea.Markus@jboss.com
  * @author Galder Zamarreño
+ * @author Sanne Grinovero
  * @see org.infinispan.interceptors.MarshalledValueInterceptor
  * @since 4.0
  */
@@ -87,8 +88,9 @@ public void init(byte[] raw, int cachedHashCode) {
       this.cachedHashCode = cachedHashCode;
    }
 
-   public synchronized void serialize() {
-      if (raw == null) {
+   public synchronized byte[] serialize() {
+      byte[] rawValue = raw;
+      if (rawValue == null) {
          try {
             // Do NOT set instance to null over here, since it may be used elsewhere (e.g., in a cache listener).
             // this will be compacted by the MarshalledValueInterceptor when the call returns.
@@ -99,28 +101,38 @@ public synchronized void serialize() {
             } finally {
                marshaller.finishObjectOutput(out);
             }
-            byte[] buf = baos.getRawBuffer();
-            int length = baos.size();
-            raw = new byte[length];
-            System.arraycopy(buf, 0, raw, 0, length);
+            final byte[] buf = baos.getRawBuffer();
+            final int length = baos.size();
+            if (buf.length == length) {
+               // in this unlikely case we can avoid duplicating the buffer
+               rawValue = buf;
+            }
+            else {
+               rawValue = new byte[length];
+               System.arraycopy(buf, 0, rawValue, 0, length);
+            }
+            raw = rawValue;
          } catch (Exception e) {
             throw new CacheException(""Unable to marshall value "" + instance, e);
-         } finally {
-            
          }
       }
+      return rawValue;
    }
 
-   public synchronized void deserialize() {
-      if (instance == null) {
+   public synchronized Object deserialize() {
+      Object instanceValue = instance;
+      if (instanceValue == null) {
          try {
             // StreamingMarshaller underneath deals with making sure the right classloader is set.
-            instance = marshaller.objectFromByteBuffer(raw);
+            instanceValue = marshaller.objectFromByteBuffer(raw);
+            instance = instanceValue;
+            return instanceValue;
          }
          catch (Exception e) {
             throw new CacheException(""Unable to unmarshall value"", e);
          }
       }
+      return instanceValue;
    }
 
    /**
@@ -136,43 +148,51 @@ public synchronized void deserialize() {
     * @param force                          ensures the preferred representation is maintained and the other released,
     *                                       even if this means serializing or deserializing.
     */
-   public void compact(boolean preferSerializedRepresentation, boolean force) {
+   public synchronized void compact(boolean preferSerializedRepresentation, boolean force) {
       // reset the equalityPreference
       equalityPreferenceForInstance = true;
+      Object thisInstance = this.instance;
+      byte[] thisRaw = this.raw;
       if (force) {
-         if (preferSerializedRepresentation && raw == null) serialize();
-         else if (!preferSerializedRepresentation && instance == null) deserialize();
+         if (preferSerializedRepresentation && thisRaw == null) {
+            thisRaw = serialize();
+         }
+         else if (!preferSerializedRepresentation && thisInstance == null){
+            thisInstance = deserialize();
+         }
       }
 
-      if (instance != null && raw != null) {
-         // need to lose one representation!
-
+      if (thisInstance != null && thisRaw != null) {
+         // need to loose one representation!
          if (preferSerializedRepresentation) {
-            nullifyInstance();
+            //in both branches we first set one then null the other, so that there's always one available
+            //to read from those methods not being synchronized
+            raw = thisRaw;
+            instance = null;
          } else {
+            instance = thisInstance;
             raw = null;
          }
       }
    }
 
-   private synchronized void nullifyInstance() {
-      instance = null;
-   }
-
    public byte[] getRaw() {
-      if (raw == null) serialize();
-      return raw;
+      byte[] rawValue = raw;
+      if (rawValue == null){
+         rawValue = serialize();
+      }
+      return rawValue;
    }
 
    /**
-    * Returns the 'cached' instance. Impl note: this method is synchronized so that it synchronizez with the code that
-    * nullifies the instance.
-    *
-    * @see #nullifyInstance()
+    * Returns the 'cached' instance
     */
-   public synchronized Object get() {
-      if (instance == null) deserialize();
-      return instance;
+   public Object get() {
+      Object value = instance;
+      if (value == null) {
+         value = deserialize();
+      }
+      return value;
    }
 
    @Override
@@ -181,35 +201,54 @@ public boolean equals(Object o) {
       if (o == null || getClass() != o.getClass()) return false;
 
       MarshalledValue that = (MarshalledValue) o;
+      final boolean preferInstanceEquality = equalityPreferenceForInstance && that.equalityPreferenceForInstance;
 
-      // if both versions are serialized or deserialized, just compare the relevant representations.
-      if (raw != null && that.raw != null) return Arrays.equals(raw, that.raw);
-      if (instance != null && that.instance != null) return instance.equals(that.instance);
+      // if both versions are serialized or deserialized, just compare the relevant representations,
+      // but attempt the operations in order to respect the value of equalityPreferenceForInstance
+      Object thisInstance = this.instance;
+      Object thatInstance = that.instance;
+      //test the default equality first so we might skip some work:
+      if (preferInstanceEquality && thisInstance != null && thatInstance != null) return thisInstance.equals(thatInstance);
+      
+      byte[] thisRaw = this.raw;
+      byte[] thatRaw = that.raw;
+      if (thisRaw != null && thatRaw != null) return Arrays.equals(thisRaw, thatRaw);
+      if (thisInstance != null && thatInstance != null) return thisInstance.equals(thatInstance);
 
       // if conversion of one representation to the other is necessary, then see which we prefer converting.
-      if (equalityPreferenceForInstance && that.equalityPreferenceForInstance) {
-         if (instance == null) deserialize();
-         if (that.instance == null) that.deserialize();
-         return instance.equals(that.instance);
+      if (preferInstanceEquality) {
+         if (thisInstance == null) {
+            thisInstance = this.deserialize();
+         }
+         if (thatInstance == null) {
+            thatInstance = that.deserialize();
+         }
+         return thisInstance.equals(thatInstance);
       } else {
-         if (raw == null) serialize();
-         if (that.raw == null) that.serialize();
-         return Arrays.equals(raw, that.raw);
+         if (thisRaw == null) {
+            thisRaw = this.serialize();
+         }
+         if (thatRaw == null) {
+            thatRaw = that.serialize();
+         }
+         return Arrays.equals(thisRaw, thatRaw);
       }
    }
 
    @Override
    public int hashCode() {
-      if (cachedHashCode == 0) {
-         // always calculate the hashcode based on the instance since this is where we're getting the equals()
-         if (instance == null) deserialize();
-         cachedHashCode = instance.hashCode();
-         if (cachedHashCode == 0) // degenerate case
+      //make a local copy to avoid multiple read/writes on the volatile field
+      int value = cachedHashCode;
+      if (value == 0) {
+         Object localInstance = deserialize();
+         value = localInstance.hashCode();
+         if (value == 0) // degenerate case
          {
-            cachedHashCode = 0xFEED;
+            value = 0xFEED;
          }
+         cachedHashCode = value;
       }
-      return cachedHashCode;
+      return value;
    }
 
    @Override
@@ -259,7 +298,7 @@ public void writeObject(ObjectOutput output, MarshalledValue mv) throws IOExcept
       }
 
       @Override
-      public MarshalledValue readObject(ObjectInput input) throws IOException, ClassNotFoundException {
+      public MarshalledValue readObject(ObjectInput input) throws IOException {
          int length = UnsignedNumeric.readUnsignedInt(input);
          byte[] raw = new byte[length];
          input.readFully(raw);",2011-05-12T23:30:12Z,78
"@@ -146,12 +146,17 @@ public int getTransactionTimeout() throws XAException {
       return txTimeout;
    }
 
+   /**
+    * the only situation in which it returns true is when the other xa resource pertains to the same cache, on
+    * the same node.
+    */
    public boolean isSameRM(XAResource xaResource) throws XAException {
       if (!(xaResource instanceof TransactionXaAdapter)) {
          return false;
       }
       TransactionXaAdapter other = (TransactionXaAdapter) xaResource;
-      return other.equals(this);
+      //there is only one tx table per cache and this is more efficient that equals.
+      return this.txTable == other.txTable;
    }
 
    public Xid[] recover(int flag) throws XAException {",2011-04-29T17:56:30Z,92
"@@ -0,0 +1,68 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2011 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.Cache;
+import org.infinispan.config.Configuration;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.SingleCacheManagerTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.Test;
+
+import javax.transaction.HeuristicMixedException;
+import javax.transaction.HeuristicRollbackException;
+import javax.transaction.NotSupportedException;
+import javax.transaction.RollbackException;
+import javax.transaction.SystemException;
+import javax.transaction.TransactionManager;
+
+import static org.testng.Assert.assertEquals;
+import static org.testng.AssertJUnit.assertFalse;
+
+/**
+ * @author Mircea Markus
+ * @since 5.0
+ */
+@Test(groups = ""functional"", testName = ""tx.TransactionsSpanningDistributedCachesTest "")
+public class TransactionsSpanningDistributedCachesTest extends TransactionsSpanningReplicatedCaches {
+
+   @Override
+   protected Configuration getConfiguration() {
+      return getDefaultClusteredConfig(Configuration.CacheMode.DIST_SYNC, true);
+   }
+
+   @Override
+   protected void createCacheManagers() throws Exception {
+      super.createCacheManagers();
+      cache(0, ""cache1"");
+      cache(0, ""cache2"");
+      cache(1, ""cache1"");
+      cache(1, ""cache2"");
+      cache(0);
+      cache(1);
+   }
+
+}",2011-04-29T17:56:30Z,298
"@@ -33,6 +33,9 @@
 import javax.transaction.TransactionManager;
 import java.util.Arrays;
 
+import static org.testng.Assert.assertEquals;
+import static org.testng.AssertJUnit.assertFalse;
+
 @Test(groups = ""functional"", sequential = true, testName = ""tx.TransactionsSpanningReplicatedCaches"")
 public class TransactionsSpanningReplicatedCaches extends MultipleCacheManagersTest {
 
@@ -43,13 +46,29 @@ public TransactionsSpanningReplicatedCaches() {
    }
 
    protected void createCacheManagers() throws Exception {
-      cm1 = addClusterEnabledCacheManager();
+      Configuration c = getConfiguration();
+      cm1 = addClusterEnabledCacheManager(c);
       cm2 = addClusterEnabledCacheManager();
 
-      Configuration c = getDefaultClusteredConfig(Configuration.CacheMode.REPL_SYNC, true);
 
       defineConfigurationOnAllManagers(""c1"", c);
       defineConfigurationOnAllManagers(""c2"", c);
+
+      cache(0, ""c1"");
+      cache(0, ""c2"");
+      cache(1, ""c1"");
+      cache(1, ""c2"");
+      cache(0, ""cache1"");
+      cache(0, ""cache2"");
+      cache(1, ""cache1"");
+      cache(1, ""cache2"");
+      cache(0);
+      cache(1);
+
+   }
+
+   protected Configuration getConfiguration() {
+      return getDefaultClusteredConfig(Configuration.CacheMode.REPL_SYNC, true);
    }
 
    public void testCommitSpanningCaches() throws Exception {
@@ -212,4 +231,43 @@ public void testPutIfAbsent() throws Exception {
       assert c1.get(""c1key"").equals(""c1value"");
       assert c1Replica.get(""c1key"").equals(""c1value"");
    }
+
+   public void testTwoNamedCachesSameNode() throws Exception {
+      runTest(cache(0, ""cache1""), cache(0, ""cache2""));
+   }
+
+   public void testDefaultCacheAndNamedCacheSameNode() throws Exception {
+      runTest(cache(0), cache(0, ""cache1""));
+   }
+
+   public void testTwoNamedCachesDifferentNodes() throws Exception {
+      runTest(cache(0, ""cache1""), cache(1, ""cache2""));
+   }
+
+   public void testDefaultCacheAndNamedCacheDifferentNodes() throws Exception {
+      runTest(cache(0), cache(1, ""cache1""));
+   }
+
+   private void runTest(Cache cache1, Cache cache2) throws Exception {
+      assertFalse(cache1.containsKey(""a""));
+      assertFalse(cache2.containsKey(""b""));
+
+      TransactionManager tm = TestingUtil.getTransactionManager(cache1);
+      tm.begin();
+      cache1.put(""a"", ""value1"");
+      cache2.put(""b"", ""value2"");
+      tm.commit();
+
+      assertEquals(""value1"", cache1.get(""a""));
+      assertEquals(""value2"", cache2.get(""b""));
+
+      tm.begin();
+      cache1.remove(""a"");
+      cache2.remove(""b"");
+      tm.commit();
+
+      assertFalse(cache1.containsKey(""a""));
+      assertFalse(cache2.containsKey(""b""));
+   }
+
 }
\ No newline at end of file",2011-04-29T17:56:30Z,299
"@@ -43,14 +43,12 @@
 		<dependency>
 			<groupId>net.dataforte.cassandra</groupId>
 			<artifactId>cassandra-connection-pool</artifactId>
-			<version>${version.cassandra.connection.pool}</version>
+			<version>${version.cassandra.pool}</version>
 		</dependency>
-
 		<dependency>
 			<groupId>org.apache.cassandra</groupId>
-			<artifactId>apache-cassandra</artifactId>
+			<artifactId>cassandra-all</artifactId>
 			<version>${version.cassandra}</version>
-			<scope>test</scope>
 		</dependency>
 		<dependency>
 			<groupId>org.slf4j</groupId>
@@ -74,7 +72,7 @@
 				<artifactId>maven-surefire-plugin</artifactId>
 				<version>2.4.3</version>
 				<configuration>
-					<forkMode>once</forkMode>
+					<forkMode>pertest</forkMode>
 					<parallel>false</parallel>
 				</configuration>
 			</plugin>
@@ -91,14 +89,4 @@
 			</plugin>
 		</plugins>
 	</build>
-
-	<repositories>
-		<repository>
-			<id>dataforte</id>
-			<url>http://www.dataforte.net/listing/maven/releases</url>
-			<snapshots>
-				<enabled>false</enabled>
-			</snapshots>
-		</repository>
-	</repositories>
 </project>",2011-04-28T09:57:29Z,146
"@@ -25,8 +25,10 @@
 import java.io.IOException;
 import java.io.ObjectInput;
 import java.io.ObjectOutput;
+import java.nio.ByteBuffer;
+import java.nio.charset.Charset;
 import java.util.ArrayList;
-import java.util.Arrays;
+import java.util.Collections;
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.Iterator;
@@ -35,9 +37,9 @@
 import java.util.Set;
 
 import net.dataforte.cassandra.pool.DataSource;
+import net.dataforte.cassandra.thrift.CassandraThriftDataSource;
 
 import org.apache.cassandra.thrift.Cassandra;
-import org.apache.cassandra.thrift.CassandraThriftDataSource;
 import org.apache.cassandra.thrift.Column;
 import org.apache.cassandra.thrift.ColumnOrSuperColumn;
 import org.apache.cassandra.thrift.ColumnParent;
@@ -51,6 +53,7 @@
 import org.apache.cassandra.thrift.SlicePredicate;
 import org.apache.cassandra.thrift.SliceRange;
 import org.apache.cassandra.thrift.SuperColumn;
+import org.apache.cassandra.utils.ByteBufferUtil;
 import org.infinispan.Cache;
 import org.infinispan.config.ConfigurationException;
 import org.infinispan.container.entries.InternalCacheEntry;
@@ -97,10 +100,10 @@ public class CassandraCacheStore extends AbstractCacheStore {
 	private ColumnParent entryColumnParent;
 	private ColumnParent expirationColumnParent;
 	private String entryKeyPrefix;
-	private String expirationKey;
+	private ByteBuffer expirationKey;
 	private TwoWayKey2StringMapper keyMapper;
-
-	static private byte emptyByteArray[] = {};
+	
+	static private Charset UTF8Charset = Charset.forName(""UTF-8"");
 
 	public Class<? extends CacheLoaderConfig> getConfigurationClass() {
 		return CassandraCacheStoreConfig.class;
@@ -120,11 +123,11 @@ public void start() throws CacheLoaderException {
 			dataSource = new DataSource(config.getPoolProperties());
 			readConsistencyLevel = ConsistencyLevel.valueOf(config.readConsistencyLevel);
 			writeConsistencyLevel = ConsistencyLevel.valueOf(config.writeConsistencyLevel);
-			entryColumnPath = new ColumnPath(config.entryColumnFamily).setColumn(ENTRY_COLUMN_NAME.getBytes(""UTF-8""));
+			entryColumnPath = new ColumnPath(config.entryColumnFamily).setColumn(ENTRY_COLUMN_NAME.getBytes(UTF8Charset));
 			entryColumnParent = new ColumnParent(config.entryColumnFamily);
 			entryKeyPrefix = ENTRY_KEY_PREFIX + (config.isSharedKeyspace() ? cacheName + ""_"" : """");
 			expirationColumnParent = new ColumnParent(config.expirationColumnFamily);
-			expirationKey = EXPIRATION_KEY + (config.isSharedKeyspace() ? ""_"" + cacheName : """");
+			expirationKey = ByteBufferUtil.bytes(EXPIRATION_KEY + (config.isSharedKeyspace() ? ""_"" + cacheName : """"));
 			keyMapper = (TwoWayKey2StringMapper) Util.getInstance(config.getKeyMapper());
 		} catch (Exception e) {
 			throw new ConfigurationException(e);
@@ -143,7 +146,7 @@ public InternalCacheEntry load(Object key) throws CacheLoaderException {
 		Cassandra.Client cassandraClient = null;
 		try {
 			cassandraClient = dataSource.getConnection();
-			ColumnOrSuperColumn column = cassandraClient.get(config.keySpace, hashKey, entryColumnPath, readConsistencyLevel);
+			ColumnOrSuperColumn column = cassandraClient.get(ByteBufferUtil.bytes(hashKey), entryColumnPath, readConsistencyLevel);
 			InternalCacheEntry ice = unmarshall(column.getColumn().getValue(), key);
 			if (ice != null && ice.isExpired()) {
 				remove(key);
@@ -171,8 +174,8 @@ public Set<InternalCacheEntry> load(int numEntries) throws CacheLoaderException
 		try {
 			cassandraClient = dataSource.getConnection();
 			Set<InternalCacheEntry> s = new HashSet<InternalCacheEntry>();
-			SlicePredicate slicePredicate = new SlicePredicate();
-			slicePredicate.setSlice_range(new SliceRange(entryColumnPath.getColumn(), emptyByteArray, false, 1));
+			SlicePredicate slicePredicate = new SlicePredicate();		
+			slicePredicate.setSlice_range(new SliceRange(ByteBuffer.wrap(entryColumnPath.getColumn()), ByteBufferUtil.EMPTY_BYTE_BUFFER, false, 1));
 			String startKey = """";
 
 			// Get the keys in SLICE_SIZE blocks
@@ -181,7 +184,7 @@ public Set<InternalCacheEntry> load(int numEntries) throws CacheLoaderException
 				KeyRange keyRange = new KeyRange(sliceSize);
 				keyRange.setStart_token(startKey);
 				keyRange.setEnd_token("""");
-				List<KeySlice> keySlices = cassandraClient.get_range_slices(config.keySpace, entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
+				List<KeySlice> keySlices = cassandraClient.get_range_slices(entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
 
 				// Cycle through all the keys
 				for (KeySlice keySlice : keySlices) {
@@ -213,7 +216,7 @@ public Set<InternalCacheEntry> load(int numEntries) throws CacheLoaderException
 					if (sliceSize == 0) {
 						complete = true;
 					} else {
-						startKey = keySlices.get(keySlices.size() - 1).getKey();
+						startKey = new String(keySlices.get(keySlices.size() - 1).getKey(), UTF8Charset);
 					}
 				}
 
@@ -233,19 +236,19 @@ public Set<Object> loadAllKeys(Set<Object> keysToExclude) throws CacheLoaderExce
 			cassandraClient = dataSource.getConnection();
 			Set<Object> s = new HashSet<Object>();
 			SlicePredicate slicePredicate = new SlicePredicate();
-			slicePredicate.setSlice_range(new SliceRange(entryColumnPath.getColumn(), emptyByteArray, false, 1));
+			slicePredicate.setSlice_range(new SliceRange(ByteBuffer.wrap(entryColumnPath.getColumn()), ByteBufferUtil.EMPTY_BYTE_BUFFER, false, 1));
 			String startKey = """";
 			boolean complete = false;
 			// Get the keys in SLICE_SIZE blocks
 			while (!complete) {
 				KeyRange keyRange = new KeyRange(SLICE_SIZE);
 				keyRange.setStart_token(startKey);
 				keyRange.setEnd_token("""");
-				List<KeySlice> keySlices = cassandraClient.get_range_slices(config.keySpace, entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
+				List<KeySlice> keySlices = cassandraClient.get_range_slices(entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
 				if (keySlices.size() < SLICE_SIZE) {
 					complete = true;
 				} else {
-					startKey = keySlices.get(keySlices.size() - 1).getKey();
+					startKey = new String(keySlices.get(keySlices.size() - 1).getKey(), UTF8Charset);
 				}
 
 				for (KeySlice keySlice : keySlices) {
@@ -279,27 +282,26 @@ public void clear() throws CacheLoaderException {
 		try {
 			cassandraClient = dataSource.getConnection();
 			SlicePredicate slicePredicate = new SlicePredicate();
-			slicePredicate.setSlice_range(new SliceRange(entryColumnPath.getColumn(), emptyByteArray, false, 1));
+			slicePredicate.setSlice_range(new SliceRange(ByteBuffer.wrap(entryColumnPath.getColumn()), ByteBufferUtil.EMPTY_BYTE_BUFFER, false, 1));
 			String startKey = """";
 			boolean complete = false;
 			// Get the keys in SLICE_SIZE blocks
 			while (!complete) {
 				KeyRange keyRange = new KeyRange(SLICE_SIZE);
 				keyRange.setStart_token(startKey);
 				keyRange.setEnd_token("""");
-				List<KeySlice> keySlices = cassandraClient.get_range_slices(config.keySpace, entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
+				List<KeySlice> keySlices = cassandraClient.get_range_slices(entryColumnParent, slicePredicate, keyRange, readConsistencyLevel);
 				if (keySlices.size() < SLICE_SIZE) {
 					complete = true;
 				} else {
-					startKey = keySlices.get(keySlices.size() - 1).getKey();
+					startKey = new String(keySlices.get(keySlices.size() - 1).getKey(), UTF8Charset);
 				}
-				Map<String, Map<String, List<Mutation>>> mutationMap = new HashMap<String, Map<String, List<Mutation>>>();
+				Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap = new HashMap<ByteBuffer, Map<String, List<Mutation>>>();
 
 				for (KeySlice keySlice : keySlices) {
-					String cassandraKey = keySlice.getKey();
-					remove0(cassandraKey, mutationMap);
+					remove0(ByteBuffer.wrap(keySlice.getKey()), mutationMap);
 				}
-				cassandraClient.batch_mutate(config.keySpace, mutationMap, ConsistencyLevel.ALL);
+				cassandraClient.batch_mutate(mutationMap, ConsistencyLevel.ALL);
 			}
 		} catch (Exception e) {
 			throw new CacheLoaderException(e);
@@ -316,9 +318,9 @@ public boolean remove(Object key) throws CacheLoaderException {
 		Cassandra.Client cassandraClient = null;
 		try {
 			cassandraClient = dataSource.getConnection();
-			Map<String, Map<String, List<Mutation>>> mutationMap = new HashMap<String, Map<String, List<Mutation>>>();
-			remove0(hashKey(key), mutationMap);
-			cassandraClient.batch_mutate(config.keySpace, mutationMap, writeConsistencyLevel);
+			Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap = new HashMap<ByteBuffer, Map<String, List<Mutation>>>();
+			remove0(ByteBufferUtil.bytes(hashKey(key)), mutationMap);
+			cassandraClient.batch_mutate(mutationMap, writeConsistencyLevel);
 			return true;
 		} catch (Exception e) {
 			log.errorRemovingKey(key, e);
@@ -328,7 +330,7 @@ public boolean remove(Object key) throws CacheLoaderException {
 		}
 	}
 
-	private void remove0(String key, Map<String, Map<String, List<Mutation>>> mutationMap) {
+	private void remove0(ByteBuffer key, Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap) {
 		addMutation(mutationMap, key, config.entryColumnFamily, null, null);
 	}
 
@@ -349,24 +351,24 @@ public void store(InternalCacheEntry entry) throws CacheLoaderException {
 
 		try {
 			cassandraClient = dataSource.getConnection();
-			Map<String, Map<String, List<Mutation>>> mutationMap = new HashMap<String, Map<String, List<Mutation>>>(2);
+			Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap = new HashMap<ByteBuffer, Map<String, List<Mutation>>>(2);
 			store0(entry, mutationMap);
 
-			cassandraClient.batch_mutate(config.keySpace, mutationMap, writeConsistencyLevel);
+			cassandraClient.batch_mutate(mutationMap, writeConsistencyLevel);
 		} catch (Exception e) {
 			throw new CacheLoaderException(e);
 		} finally {
 			dataSource.releaseConnection(cassandraClient);
 		}
 	}
 
-	private void store0(InternalCacheEntry entry, Map<String, Map<String, List<Mutation>>> mutationMap) throws IOException, UnsupportedKeyTypeException {
+	private void store0(InternalCacheEntry entry, Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap) throws IOException, UnsupportedKeyTypeException {
 		Object key = entry.getKey();
 		if (trace)
 			log.tracef(""store(\""%s\"") "", key);
 		String cassandraKey = hashKey(key);
 		try {
-			addMutation(mutationMap, cassandraKey, config.entryColumnFamily, entryColumnPath.getColumn(), marshall(entry));
+			addMutation(mutationMap, ByteBufferUtil.bytes(cassandraKey), config.entryColumnFamily, ByteBuffer.wrap(entryColumnPath.getColumn()), ByteBuffer.wrap(marshall(entry)));
 			if (entry.canExpire()) {
 				addExpiryEntry(cassandraKey, entry.getExpiryTime(), mutationMap);
 			}
@@ -377,9 +379,9 @@ private void store0(InternalCacheEntry entry, Map<String, Map<String, List<Mutat
 		}
 	}
 
-	private void addExpiryEntry(String cassandraKey, long expiryTime, Map<String, Map<String, List<Mutation>>> mutationMap) {
+	private void addExpiryEntry(String cassandraKey, long expiryTime, Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap) {
 		try {
-			addMutation(mutationMap, expirationKey, config.expirationColumnFamily, longToBytes(expiryTime), cassandraKey.getBytes(""UTF-8""), emptyByteArray);
+			addMutation(mutationMap, expirationKey, config.expirationColumnFamily, ByteBufferUtil.bytes(expiryTime), ByteBufferUtil.bytes(cassandraKey), ByteBufferUtil.EMPTY_BYTE_BUFFER);
 		} catch (Exception e) {
 			// Should not happen
 		}
@@ -444,25 +446,25 @@ protected void purgeInternal() throws CacheLoaderException {
 			// We need to get all supercolumns from the beginning of time until
 			// now, in SLICE_SIZE chunks
 			SlicePredicate predicate = new SlicePredicate();
-			predicate.setSlice_range(new SliceRange(emptyByteArray, longToBytes(System.currentTimeMillis()), false, SLICE_SIZE));
-			Map<String, Map<String, List<Mutation>>> mutationMap = new HashMap<String, Map<String, List<Mutation>>>();
+			predicate.setSlice_range(new SliceRange(ByteBufferUtil.EMPTY_BYTE_BUFFER, ByteBufferUtil.bytes(System.currentTimeMillis()), false, SLICE_SIZE));
+			Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap = new HashMap<ByteBuffer, Map<String, List<Mutation>>>();
 			for (boolean complete = false; !complete;) {
 				// Get all columns
-				List<ColumnOrSuperColumn> slice = cassandraClient.get_slice(config.keySpace, expirationKey, expirationColumnParent, predicate, readConsistencyLevel);
+				List<ColumnOrSuperColumn> slice = cassandraClient.get_slice(expirationKey, expirationColumnParent, predicate, readConsistencyLevel);
 				complete = slice.size() < SLICE_SIZE;
 				// Delete all keys returned by the slice
 				for (ColumnOrSuperColumn crumb : slice) {
 					SuperColumn scol = crumb.getSuper_column();
 					for (Iterator<Column> i = scol.getColumnsIterator(); i.hasNext();) {
 						Column col = i.next();
 						// Remove the entry row
-						remove0(new String(col.getName(), ""UTF-8""), mutationMap);
+						remove0(ByteBuffer.wrap(col.getName()), mutationMap);
 					}
 					// Remove the expiration supercolumn
-					addMutation(mutationMap, expirationKey, config.expirationColumnFamily, scol.getName(), null, null);
+					addMutation(mutationMap, expirationKey, config.expirationColumnFamily, ByteBuffer.wrap(scol.getName()), null, null);
 				}
 			}
-			cassandraClient.batch_mutate(config.keySpace, mutationMap, writeConsistencyLevel);
+			cassandraClient.batch_mutate(mutationMap, writeConsistencyLevel);
 		} catch (Exception e) {
 			throw new CacheLoaderException(e);
 		} finally {
@@ -477,7 +479,7 @@ protected void applyModifications(List<? extends Modification> mods) throws Cach
 
 		try {
 			cassandraClient = dataSource.getConnection();
-			Map<String, Map<String, List<Mutation>>> mutationMap = new HashMap<String, Map<String, List<Mutation>>>();
+			Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap = new HashMap<ByteBuffer, Map<String, List<Mutation>>>();
 
 			for (Modification m : mods) {
 				switch (m.getType()) {
@@ -488,14 +490,15 @@ protected void applyModifications(List<? extends Modification> mods) throws Cach
 					clear();
 					break;
 				case REMOVE:
-					remove0(hashKey(((Remove) m).getKey()), mutationMap);
+					remove0(ByteBufferUtil.bytes(hashKey(((Remove) m).getKey())), mutationMap);
 					break;
 				default:
 					throw new AssertionError();
 				}
 			}
-
-			cassandraClient.batch_mutate(config.keySpace, mutationMap, writeConsistencyLevel);
+			
+			cassandraClient.batch_mutate(mutationMap, writeConsistencyLevel);
+			
 		} catch (Exception e) {
 			throw new CacheLoaderException(e);
 		} finally {
@@ -517,18 +520,20 @@ private String hashKey(Object key) throws UnsupportedKeyTypeException {
 		return entryKeyPrefix + keyMapper.getStringMapping(key);
 	}
 
-	private Object unhashKey(String key) {
-		if (key.startsWith(entryKeyPrefix))
-			return keyMapper.getKeyMapping(key.substring(entryKeyPrefix.length()));
+	private Object unhashKey(byte[] key) {
+		String skey = new String(key, UTF8Charset);
+		
+		if (skey.startsWith(entryKeyPrefix))
+			return keyMapper.getKeyMapping(skey.substring(entryKeyPrefix.length()));
 		else
 			return null;
 	}
 
-	private static void addMutation(Map<String, Map<String, List<Mutation>>> mutationMap, String key, String columnFamily, byte[] column, byte[] value) {
+	private static void addMutation(Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap, ByteBuffer key, String columnFamily, ByteBuffer column, ByteBuffer value) {
 		addMutation(mutationMap, key, columnFamily, null, column, value);
 	}
 
-	private static void addMutation(Map<String, Map<String, List<Mutation>>> mutationMap, String key, String columnFamily, byte[] superColumn, byte[] column, byte[] value) {
+	private static void addMutation(Map<ByteBuffer, Map<String, List<Mutation>>> mutationMap, ByteBuffer key, String columnFamily, ByteBuffer superColumn, ByteBuffer column, ByteBuffer value) {
 		Map<String, List<Mutation>> keyMutations = mutationMap.get(key);
 		// If the key doesn't exist yet, create the mutation holder
 		if (keyMutations == null) {
@@ -543,37 +548,28 @@ private static void addMutation(Map<String, Map<String, List<Mutation>>> mutatio
 		}
 
 		if (value == null) { // Delete
-			Deletion deletion = new Deletion(System.currentTimeMillis());
+			Deletion deletion = new Deletion(microTimestamp());
 			if (superColumn != null) {
 				deletion.setSuper_column(superColumn);
 			}
-			if (column != null) { // Single column delete
-				deletion.setPredicate(new SlicePredicate().setColumn_names(Arrays.asList(new byte[][] { column })));
+			if (column != null) { // Single column delete				
+				deletion.setPredicate(new SlicePredicate().setColumn_names(Collections.singletonList(column)));
 			} // else Delete entire column family or supercolumn
 			columnFamilyMutations.add(new Mutation().setDeletion(deletion));
 		} else { // Insert/update
 			ColumnOrSuperColumn cosc = new ColumnOrSuperColumn();
 			if (superColumn != null) {
 				List<Column> columns = new ArrayList<Column>();
-				columns.add(new Column(column, value, System.currentTimeMillis()));
+				columns.add(new Column(column, value, microTimestamp()));
 				cosc.setSuper_column(new SuperColumn(superColumn, columns));
 			} else {
-				cosc.setColumn(new Column(column, value, System.currentTimeMillis()));
+				cosc.setColumn(new Column(column, value, microTimestamp()));
 			}
 			columnFamilyMutations.add(new Mutation().setColumn_or_supercolumn(cosc));
 		}
 	}
-
-	private static final byte[] longToBytes(long v) {
-		byte b[] = new byte[8];
-		b[0] = (byte) (v >>> 56);
-		b[1] = (byte) (v >>> 48);
-		b[2] = (byte) (v >>> 40);
-		b[3] = (byte) (v >>> 32);
-		b[4] = (byte) (v >>> 24);
-		b[5] = (byte) (v >>> 16);
-		b[6] = (byte) (v >>> 8);
-		b[7] = (byte) (v >>> 0);
-		return b;
+	
+	private static long microTimestamp() {
+		return System.currentTimeMillis()*1000l;
 	}
 }",2011-04-28T09:57:29Z,144
"@@ -93,6 +93,7 @@ public String getKeySpace() {
 
 	public void setKeySpace(String keySpace) {
 		this.keySpace = keySpace;
+		poolProperties.setKeySpace(keySpace);
 	}
 
 	public String getEntryColumnFamily() {",2011-04-28T09:57:29Z,147
"@@ -22,11 +22,9 @@
  */
 package org.infinispan.loaders.cassandra;
 
-import java.io.File;
 import java.io.IOException;
-import java.net.URL;
 
-import org.apache.cassandra.service.EmbeddedCassandraService;
+import org.apache.cassandra.config.ConfigurationException;
 import org.apache.thrift.transport.TTransportException;
 import org.infinispan.loaders.BaseCacheStoreTest;
 import org.infinispan.loaders.CacheStore;
@@ -36,43 +34,34 @@
 
 @Test(groups = ""unit"", testName = ""loaders.cassandra.CassandraCacheStoreTest"")
 public class CassandraCacheStoreTest extends BaseCacheStoreTest {
-	private static EmbeddedCassandraService cassandra;
+	private static EmbeddedServerHelper embedded;
 
 	/**
 	 * Set embedded cassandra up and spawn it in a new thread.
 	 * 
 	 * @throws TTransportException
 	 * @throws IOException
 	 * @throws InterruptedException
+	 * @throws ConfigurationException
 	 */
 	@BeforeClass
-	public static void setup() throws TTransportException, IOException, InterruptedException {
-		// Tell cassandra where the configuration files are.
-		// Use the test configuration file.
-		URL resource = Thread.currentThread().getContextClassLoader().getResource(""storage-conf.xml"");
-		String configPath = resource.getPath().substring(0, resource.getPath().lastIndexOf(File.separatorChar));
-		
-		System.setProperty(""storage-config"", configPath);
-
-		CassandraServiceDataCleaner cleaner = new CassandraServiceDataCleaner();
-		cleaner.prepare();
-		cassandra = new EmbeddedCassandraService();
-		cassandra.init();
-		Thread t = new Thread(cassandra);
-		t.setDaemon(true);
-		t.start();
+	public static void setup() throws TTransportException, IOException, InterruptedException, ConfigurationException {
+		embedded = new EmbeddedServerHelper();
+		embedded.setup();
 	}
 	
 	@AfterClass
 	public static void cleanup() {
-		System.exit(0);
+		EmbeddedServerHelper.teardown();
+		embedded = null;
 	}
 
 	@Override
 	protected CacheStore createCacheStore() throws Exception {
 		CassandraCacheStore cs = new CassandraCacheStore();
 		CassandraCacheStoreConfig clc = new CassandraCacheStoreConfig();
 		clc.setHost(""localhost"");
+		clc.setKeySpace(""Infinispan"");
 		cs.init(clc, getCache(), getMarshaller());
 		cs.start();
 		return cs;",2011-04-28T09:57:29Z,81
"@@ -1,94 +0,0 @@
-/*
- * JBoss, Home of Professional Open Source
- * Copyright 2010 Red Hat Inc. and/or its affiliates and other
- * contributors as indicated by the @author tags. All rights reserved.
- * See the copyright.txt in the distribution for a full listing of
- * individual contributors.
- *
- * This is free software; you can redistribute it and/or modify it
- * under the terms of the GNU Lesser General Public License as
- * published by the Free Software Foundation; either version 2.1 of
- * the License, or (at your option) any later version.
- *
- * This software is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this software; if not, write to the Free
- * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
- * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
- */
-package org.infinispan.loaders.cassandra;
-
-import java.io.IOException;
-import java.util.HashSet;
-import java.util.Set;
-
-import org.apache.cassandra.config.DatabaseDescriptor;
-import org.apache.cassandra.io.util.FileUtils;
-import org.infinispan.test.TestingUtil;
-
-public class CassandraServiceDataCleaner {
-	/**
-	 * Creates all data dir if they don't exist and cleans them
-	 * 
-	 * @throws IOException
-	 */
-	public void prepare() throws IOException {
-		makeDirsIfNotExist();
-		cleanupDataDirectories();
-	}
-
-	/**
-	 * Deletes all data from cassandra data directories, including the commit
-	 * log.
-	 * 
-	 * @throws IOException
-	 *             in case of permissions error etc.
-	 */
-	public void cleanupDataDirectories() throws IOException {
-		for (String s : getDataDirs()) {
-			TestingUtil.recursiveFileRemove(s);
-		}
-	}
-
-	/**
-	 * Creates the data diurectories, if they didn't exist.
-	 * 
-	 * @throws IOException
-	 *             if directories cannot be created (permissions etc).
-	 */
-	public void makeDirsIfNotExist() throws IOException {
-		for (String s : getDataDirs()) {
-			mkdir(s);
-		}
-	}
-
-	/**
-	 * Collects all data dirs and returns a set of String paths on the file
-	 * system.
-	 * 
-	 * @return
-	 */
-	private Set<String> getDataDirs() {
-		Set<String> dirs = new HashSet<String>();
-		for (String s : DatabaseDescriptor.getAllDataFileLocations()) {
-			dirs.add(s);
-		}
-		dirs.add(DatabaseDescriptor.getLogFileLocation());
-		return dirs;
-	}
-
-	/**
-	 * Creates a directory
-	 * 
-	 * @param dir
-	 * @throws IOException
-	 */
-	private void mkdir(String dir) throws IOException {
-		FileUtils.createDirectory(dir);
-	}
-
-}",2011-04-28T09:57:29Z,148
"@@ -0,0 +1,179 @@
+package org.infinispan.loaders.cassandra;
+
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+
+import org.apache.cassandra.config.CFMetaData;
+import org.apache.cassandra.config.ConfigurationException;
+import org.apache.cassandra.config.DatabaseDescriptor;
+import org.apache.cassandra.config.KSMetaData;
+import org.apache.cassandra.db.commitlog.CommitLog;
+import org.apache.cassandra.io.util.FileUtils;
+import org.apache.cassandra.thrift.CassandraDaemon;
+import org.apache.thrift.transport.TTransportException;
+
+/**
+ * Taken from Hector (MIT license).
+ * 
+ * Copyright (c) 2010 Ran Tavory
+ * 
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ * 
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ */
+public class EmbeddedServerHelper {	
+	private static final String TMP = ""tmp"";
+
+	private final String yamlFile;
+	static CassandraDaemon cassandraDaemon;
+
+	public EmbeddedServerHelper() {
+		this(""/cassandra.yaml"");
+	}
+
+	public EmbeddedServerHelper(String yamlFile) {
+		this.yamlFile = yamlFile;
+	}
+
+	static ExecutorService executor = Executors.newSingleThreadExecutor();
+
+	/**
+	 * Set embedded cassandra up and spawn it in a new thread.
+	 * 
+	 * @throws TTransportException
+	 * @throws IOException
+	 * @throws InterruptedException
+	 */
+	public void setup() throws TTransportException, IOException, InterruptedException, ConfigurationException {
+		// delete tmp dir first
+		rmdir(TMP);
+		// make a tmp dir and copy cassandra.yaml and log4j.properties to it
+		copy(""/log4j.properties"", TMP);
+		copy(yamlFile, TMP);
+		System.setProperty(""cassandra.config"", ""file:"" + TMP + yamlFile);
+		System.setProperty(""log4j.configuration"", ""file:"" + TMP + ""/log4j.properties"");
+		System.setProperty(""cassandra-foreground"", ""true"");
+
+		cleanupAndLeaveDirs();
+		loadSchemaFromYaml();
+
+		executor.execute(new CassandraRunner());
+		try {
+			TimeUnit.SECONDS.sleep(3);
+		} catch (InterruptedException e) {
+			throw new AssertionError(e);
+		}
+	}
+
+	public static void teardown() {
+		executor.shutdown();
+		executor.shutdownNow();
+	}
+
+	private static void rmdir(String dir) throws IOException {
+		File dirFile = new File(dir);
+		if (dirFile.exists()) {
+			FileUtils.deleteRecursive(new File(dir));
+		}
+	}
+
+	/**
+	 * Copies a resource from within the jar to a directory.
+	 * 
+	 * @param resource
+	 * @param directory
+	 * @throws IOException
+	 */
+	private static void copy(String resource, String directory) throws IOException {
+		mkdir(directory);
+		InputStream is = EmbeddedServerHelper.class.getResourceAsStream(resource);
+		String fileName = resource.substring(resource.lastIndexOf(""/"") + 1);
+		File file = new File(directory + System.getProperty(""file.separator"") + fileName);
+		OutputStream out = new FileOutputStream(file);
+		byte buf[] = new byte[1024];
+		int len;
+		while ((len = is.read(buf)) > 0) {
+			out.write(buf, 0, len);
+		}
+		out.close();
+		is.close();
+	}
+
+	/**
+	 * Creates a directory
+	 * 
+	 * @param dir
+	 * @throws IOException
+	 */
+	private static void mkdir(String dir) throws IOException {
+		FileUtils.createDirectory(dir);
+	}
+
+	public static void cleanupAndLeaveDirs() throws IOException {
+		mkdirs();
+		cleanup();
+		mkdirs();
+		CommitLog.instance.resetUnsafe(); // cleanup screws w/ CommitLog, this
+											// brings it back to safe state
+	}
+
+	public static void cleanup() throws IOException {
+		// clean up commitlog
+		String[] directoryNames = { DatabaseDescriptor.getCommitLogLocation(), };
+		for (String dirName : directoryNames) {
+			File dir = new File(dirName);
+			if (!dir.exists())
+				throw new RuntimeException(""No such directory: "" + dir.getAbsolutePath());
+			FileUtils.deleteRecursive(dir);
+		}
+
+		// clean up data directory which are stored as data directory/table/data
+		// files
+		for (String dirName : DatabaseDescriptor.getAllDataFileLocations()) {
+			File dir = new File(dirName);
+			if (!dir.exists())
+				throw new RuntimeException(""No such directory: "" + dir.getAbsolutePath());
+			FileUtils.deleteRecursive(dir);
+		}
+	}
+
+	public static void mkdirs() {
+		try {
+			DatabaseDescriptor.createAllDirectories();
+		} catch (IOException e) {
+			throw new RuntimeException(e);
+		}
+	}
+
+	public static void loadSchemaFromYaml() {
+		try {
+			for (KSMetaData ksm : DatabaseDescriptor.readTablesFromYaml()) {
+				for (CFMetaData cfm : ksm.cfMetaData().values())
+					CFMetaData.map(cfm);
+				DatabaseDescriptor.setTableDefinition(ksm, DatabaseDescriptor.getDefsVersion());
+			}
+		} catch (ConfigurationException e) {
+			throw new RuntimeException(e);
+		}
+	}
+
+	class CassandraRunner implements Runnable {
+		@Override
+		public void run() {
+			cassandraDaemon = new CassandraDaemon();
+			cassandraDaemon.activate();
+		}
+	}
+}",2011-04-28T09:57:29Z,149
"@@ -0,0 +1,81 @@
+authenticator: org.apache.cassandra.auth.AllowAllAuthenticator
+auto_bootstrap: false
+binary_memtable_throughput_in_mb: 256
+cluster_name: Infinispan
+column_index_size_in_kb: 64
+commitlog_directory: ${java.io.tmpdir}/infinispan-cassandra-cachestore/commitlog
+commitlog_rotation_threshold_in_mb: 128
+commitlog_sync: periodic
+commitlog_sync_period_in_ms: 10000
+compaction_preheat_key_cache: true
+compaction_thread_priority: 1
+concurrent_reads: 8
+concurrent_writes: 32
+data_file_directories:
+- ${java.io.tmpdir}/infinispan-cassandra-cachestore/data
+disk_access_mode: auto
+dynamic_snitch: false
+dynamic_snitch_badness_threshold: 0.0
+dynamic_snitch_reset_interval_in_ms: 600000
+dynamic_snitch_update_interval_in_ms: 100
+endpoint_snitch: org.apache.cassandra.locator.RackInferringSnitch
+flush_largest_memtables_at: 1.0
+hinted_handoff_enabled: true
+hinted_handoff_throttle_delay_in_ms: 0
+in_memory_compaction_limit_in_mb: 256
+incremental_backups: false
+index_interval: 128
+keyspaces:
+- column_families:
+  - column_metadata: []
+    column_type: Standard
+    compare_with: BytesType
+    gc_grace_seconds: 86400
+    key_cache_save_period_in_seconds: 14400
+    keys_cached: 0.1
+    max_compaction_threshold: 32
+    memtable_flush_after_mins: 60
+    memtable_operations_in_millions: 0.3
+    memtable_throughput_in_mb: 64
+    min_compaction_threshold: 4
+    name: InfinispanEntries
+    read_repair_chance: 1.0
+    row_cache_save_period_in_seconds: 0
+    rows_cached: 0.0
+  - column_metadata: []
+    column_type: Super
+    compare_subcolumns_with: BytesType
+    compare_with: LongType
+    gc_grace_seconds: 86400
+    key_cache_save_period_in_seconds: 14400
+    keys_cached: 0.1
+    max_compaction_threshold: 32
+    memtable_flush_after_mins: 60
+    memtable_operations_in_millions: 0.3
+    memtable_throughput_in_mb: 64
+    min_compaction_threshold: 4
+    name: InfinispanExpiration
+    read_repair_chance: 1.0
+    row_cache_save_period_in_seconds: 0
+    rows_cached: 0.0
+  name: Infinispan
+  replica_placement_strategy: org.apache.cassandra.locator.RackUnawareStrategy
+  replication_factor: 1
+max_hint_window_in_ms: 2147483647
+partitioner: org.apache.cassandra.dht.OrderPreservingPartitioner
+phi_convict_threshold: 8
+reduce_cache_capacity_to: 0.6
+reduce_cache_sizes_at: 1.0
+rpc_keepalive: true
+rpc_max_threads: 2147483647
+rpc_min_threads: 16
+rpc_port: 9160
+rpc_timeout_in_ms: 10000
+saved_caches_directory: ${java.io.tmpdir}/infinispan-cassandra-cachestore/savedcaches
+seeds:
+- 127.0.0.1
+sliced_buffer_size_in_kb: 64
+snapshot_before_compaction: false
+storage_port: 7000
+thrift_framed_transport_size_in_mb: 15
+thrift_max_message_length_in_mb: 16",2011-04-28T09:57:29Z,150
"@@ -1,370 +0,0 @@
-<!--
-  ~ JBoss, Home of Professional Open Source
-  ~ Copyright 2010 Red Hat Inc. and/or its affiliates and other
-  ~ contributors as indicated by the @author tags. All rights reserved.
-  ~ See the copyright.txt in the distribution for a full listing of
-  ~ individual contributors.
-  ~
-  ~ This is free software; you can redistribute it and/or modify it
-  ~ under the terms of the GNU Lesser General Public License as
-  ~ published by the Free Software Foundation; either version 2.1 of
-  ~ the License, or (at your option) any later version.
-  ~
-  ~ This software is distributed in the hope that it will be useful,
-  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
-  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
-  ~ Lesser General Public License for more details.
-  ~
-  ~ You should have received a copy of the GNU Lesser General Public
-  ~ License along with this software; if not, write to the Free
-  ~ Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
-  ~ 02110-1301 USA, or see the FSF site: http://www.fsf.org.
-  -->
-<Storage>
-  <!--======================================================================-->
-  <!-- Basic Configuration                                                  -->
-  <!--======================================================================-->
-
-  <!--
-   ~ The name of this cluster.  This is mainly used to prevent machines in
-   ~ one logical cluster from joining another.
-  -->
-  <ClusterName>Infinispan</ClusterName>
-
-  <!--
-   ~ Turn on to make new [non-seed] nodes automatically migrate the right data
-   ~ to themselves.  (If no InitialToken is specified, they will pick one
-   ~ such that they will get half the range of the most-loaded node.)
-   ~ If a node starts up without bootstrapping, it will mark itself bootstrapped
-   ~ so that you can't subsequently accidently bootstrap a node with
-   ~ data on it.  (You can reset this by wiping your data and commitlog
-   ~ directories.)
-   ~
-   ~ Off by default so that new clusters and upgraders from 0.4 don't
-   ~ bootstrap immediately.  You should turn this on when you start adding
-   ~ new nodes to a cluster that already has data on it.  (If you are upgrading
-   ~ from 0.4, start your cluster with it off once before changing it to true.
-   ~ Otherwise, no data will be lost but you will incur a lot of unnecessary
-   ~ I/O before your cluster starts up.)
-  -->
-  <AutoBootstrap>false</AutoBootstrap>
-
-  <!--
-   ~ Keyspaces and ColumnFamilies:
-   ~ A ColumnFamily is the Cassandra concept closest to a relational
-   ~ table.  Keyspaces are separate groups of ColumnFamilies.  Except in
-   ~ very unusual circumstances you will have one Keyspace per application.
-
-   ~ There is an implicit keyspace named 'system' for Cassandra internals.
-  -->
-  <Keyspaces>
-    <Keyspace Name=""Infinispan"">
-      <!--
-       ~ ColumnFamily definitions have one required attribute (Name)
-       ~ and several optional ones.
-       ~
-       ~ The CompareWith attribute tells Cassandra how to sort the columns
-       ~ for slicing operations.  The default is BytesType, which is a
-       ~ straightforward lexical comparison of the bytes in each column.
-       ~ Other options are AsciiType, UTF8Type, LexicalUUIDType, TimeUUIDType,
-       ~ and LongType.  You can also specify the fully-qualified class
-       ~ name to a class of your choice extending
-       ~ org.apache.cassandra.db.marshal.AbstractType.
-       ~
-       ~ SuperColumns have a similar CompareSubcolumnsWith attribute.
-       ~
-       ~ BytesType: Simple sort by byte value.  No validation is performed.
-       ~ AsciiType: Like BytesType, but validates that the input can be
-       ~            parsed as US-ASCII.
-       ~ UTF8Type: A string encoded as UTF8
-       ~ LongType: A 64bit long
-       ~ LexicalUUIDType: A 128bit UUID, compared lexically (by byte value)
-       ~ TimeUUIDType: a 128bit version 1 UUID, compared by timestamp
-       ~
-       ~ (To get the closest approximation to 0.3-style supercolumns, you
-       ~ would use CompareWith=UTF8Type CompareSubcolumnsWith=LongType.)
-       ~
-       ~ An optional `Comment` attribute may be used to attach additional
-       ~ human-readable information about the column family to its definition.
-       ~
-       ~ The optional KeysCached attribute specifies
-       ~ the number of keys per sstable whose locations we keep in
-       ~ memory in ""mostly LRU"" order.  (JUST the key locations, NOT any
-       ~ column values.) Specify a fraction (value less than 1), a percentage
-       ~ (ending in a % sign) or an absolute number of keys to cache.
-       ~
-       ~ The optional RowsCached attribute specifies the number of rows
-       ~ whose entire contents we cache in memory. Do not use this on
-       ~ ColumnFamilies with large rows, or ColumnFamilies with high write:read
-       ~ ratios. Specify a fraction (value less than 1), a percentage (ending in
-       ~ a % sign) or an absolute number of rows to cache.
-      -->
-
-      <ColumnFamily CompareWith=""BytesType"" Name=""InfinispanEntries"" KeysCached=""10%"" />
-      <ColumnFamily CompareWith=""LongType"" Name=""InfinispanExpiration"" KeysCached=""10%"" ColumnType=""Super"" CompareSubcolumnsWith=""BytesType""/>
-
-      <!--
-       ~ Strategy: Setting this to the class that implements
-       ~ IReplicaPlacementStrategy will change the way the node picker works.
-       ~ Out of the box, Cassandra provides
-       ~ org.apache.cassandra.locator.RackUnawareStrategy and
-       ~ org.apache.cassandra.locator.RackAwareStrategy (place one replica in
-       ~ a different datacenter, and the others on different racks in the same
-       ~ one.)
-      -->
-      <ReplicaPlacementStrategy>org.apache.cassandra.locator.RackUnawareStrategy</ReplicaPlacementStrategy>
-
-      <!-- Number of replicas of the data -->
-      <ReplicationFactor>1</ReplicationFactor>
-
-      <!--
-       ~ EndPointSnitch: Setting this to the class that implements
-       ~ AbstractEndpointSnitch, which lets Cassandra know enough
-       ~ about your network topology to route requests efficiently.
-       ~ Out of the box, Cassandra provides org.apache.cassandra.locator.EndPointSnitch,
-       ~ and PropertyFileEndPointSnitch is available in contrib/.
-      -->
-      <EndPointSnitch>org.apache.cassandra.locator.EndPointSnitch</EndPointSnitch>
-
-    </Keyspace>
-  </Keyspaces>
-
-  <!--
-   ~ Authenticator: any IAuthenticator may be used, including your own as long
-   ~ as it is on the classpath.  Out of the box, Cassandra provides
-   ~ org.apache.cassandra.auth.AllowAllAuthenticator and,
-   ~ org.apache.cassandra.auth.SimpleAuthenticator
-   ~ (SimpleAuthenticator uses access.properties and passwd.properties by
-   ~ default).
-   ~
-   ~ If you don't specify an authenticator, AllowAllAuthenticator is used.
-  -->
-  <Authenticator>org.apache.cassandra.auth.AllowAllAuthenticator</Authenticator>
-
-  <!--
-   ~ Partitioner: any IPartitioner may be used, including your own as long
-   ~ as it is on the classpath.  Out of the box, Cassandra provides
-   ~ org.apache.cassandra.dht.RandomPartitioner,
-   ~ org.apache.cassandra.dht.OrderPreservingPartitioner, and
-   ~ org.apache.cassandra.dht.CollatingOrderPreservingPartitioner.
-   ~ (CollatingOPP colates according to EN,US rules, not naive byte
-   ~ ordering.  Use this as an example if you need locale-aware collation.)
-   ~ Range queries require using an order-preserving partitioner.
-   ~
-   ~ Achtung!  Changing this parameter requires wiping your data
-   ~ directories, since the partitioner can modify the sstable on-disk
-   ~ format.
-  -->
-  <Partitioner>org.apache.cassandra.dht.OrderPreservingPartitioner</Partitioner>
-
-  <!--
-   ~ If you are using an order-preserving partitioner and you know your key
-   ~ distribution, you can specify the token for this node to use. (Keys
-   ~ are sent to the node with the ""closest"" token, so distributing your
-   ~ tokens equally along the key distribution space will spread keys
-   ~ evenly across your cluster.)  This setting is only checked the first
-   ~ time a node is started.
-
-   ~ This can also be useful with RandomPartitioner to force equal spacing
-   ~ of tokens around the hash space, especially for clusters with a small
-   ~ number of nodes.
-  -->
-  <InitialToken></InitialToken>
-
-  <!--
-   ~ Directories: Specify where Cassandra should store different data on
-   ~ disk.  Keep the data disks and the CommitLog disks separate for best
-   ~ performance
-  -->
-  <SavedCachesDirectory>${java.io.tmpdir}/infinispan-cassandra-cachestore/savedcaches</SavedCachesDirectory>
-  <CommitLogDirectory>${java.io.tmpdir}/infinispan-cassandra-cachestore/commitlog</CommitLogDirectory>
-  <DataFileDirectories>
-      <DataFileDirectory>${java.io.tmpdir}/infinispan-cassandra-cachestore/data</DataFileDirectory>
-  </DataFileDirectories>
-  <CalloutLocation>${java.io.tmpdir}/infinispan-cassandra-cachestore/callouts</CalloutLocation>
-  <StagingFileDirectory>${java.io.tmpdir}/infinispan-cassandra-cachestore/staging</StagingFileDirectory>
-
-
-  <!--
-   ~ Addresses of hosts that are deemed contact points. Cassandra nodes
-   ~ use this list of hosts to find each other and learn the topology of
-   ~ the ring. You must change this if you are running multiple nodes!
-  -->
-  <Seeds>
-      <Seed>127.0.0.1</Seed>
-  </Seeds>
-
-
-  <!-- Miscellaneous -->
-
-  <!-- Time to wait for a reply from other nodes before failing the command -->
-  <RpcTimeoutInMillis>10000</RpcTimeoutInMillis>
-  <!-- Size to allow commitlog to grow to before creating a new segment -->
-  <CommitLogRotationThresholdInMB>128</CommitLogRotationThresholdInMB>
-
-
-  <!-- Local hosts and ports -->
-
-  <!--
-   ~ Address to bind to and tell other nodes to connect to.  You _must_
-   ~ change this if you want multiple nodes to be able to communicate!
-   ~
-   ~ Leaving it blank leaves it up to InetAddress.getLocalHost(). This
-   ~ will always do the Right Thing *if* the node is properly configured
-   ~ (hostname, name resolution, etc), and the Right Thing is to use the
-   ~ address associated with the hostname (it might not be).
-  -->
-  <ListenAddress></ListenAddress>
-  <!-- internal communications port -->
-  <StoragePort>7000</StoragePort>
-
-  <!--
-   ~ The address to bind the Thrift RPC service to. Unlike ListenAddress
-   ~ above, you *can* specify 0.0.0.0 here if you want Thrift to listen on
-   ~ all interfaces.
-   ~
-   ~ Leaving this blank has the same effect it does for ListenAddress,
-   ~ (i.e. it will be based on the configured hostname of the node).
-  -->
-  <ThriftAddress>localhost</ThriftAddress>
-  <!-- Thrift RPC port (the port clients connect to). -->
-  <ThriftPort>9160</ThriftPort>
-  <!--
-   ~ Whether or not to use a framed transport for Thrift. If this option
-   ~ is set to true then you must also use a framed transport on the
-   ~ client-side, (framed and non-framed transports are not compatible).
-  -->
-  <ThriftFramedTransport>false</ThriftFramedTransport>
-
-
-  <!--======================================================================-->
-  <!-- Memory, Disk, and Performance                                        -->
-  <!--======================================================================-->
-
-  <!--
-   ~ Access mode.  mmapped i/o is substantially faster, but only practical on
-   ~ a 64bit machine (which notably does not include EC2 ""small"" instances)
-   ~ or relatively small datasets.  ""auto"", the safe choice, will enable
-   ~ mmapping on a 64bit JVM.  Other values are ""mmap"", ""mmap_index_only""
-   ~ (which may allow you to get part of the benefits of mmap on a 32bit
-   ~ machine by mmapping only index files) and ""standard"".
-   ~ (The buffer size settings that follow only apply to standard,
-   ~ non-mmapped i/o.)
-   -->
-  <DiskAccessMode>auto</DiskAccessMode>
-
-  <!--
-   ~ Size of compacted row above which to log a warning.  (If compacted
-   ~ rows do not fit in memory, Cassandra will crash.  This is explained
-   ~ in http://wiki.apache.org/cassandra/CassandraLimitations and is
-   ~ scheduled to be fixed in 0.7.)
-  -->
-  <RowWarningThresholdInMB>512</RowWarningThresholdInMB>
-
-  <!--
-   ~ Buffer size to use when performing contiguous column slices. Increase
-   ~ this to the size of the column slices you typically perform.
-   ~ (Name-based queries are performed with a buffer size of
-   ~ ColumnIndexSizeInKB.)
-  -->
-  <SlicedBufferSizeInKB>64</SlicedBufferSizeInKB>
-
-  <!--
-   ~ Buffer size to use when flushing memtables to disk. (Only one
-   ~ memtable is ever flushed at a time.) Increase (decrease) the index
-   ~ buffer size relative to the data buffer if you have few (many)
-   ~ columns per key.  Bigger is only better _if_ your memtables get large
-   ~ enough to use the space. (Check in your data directory after your
-   ~ app has been running long enough.) -->
-  <FlushDataBufferSizeInMB>32</FlushDataBufferSizeInMB>
-  <FlushIndexBufferSizeInMB>8</FlushIndexBufferSizeInMB>
-
-  <!--
-   ~ Add column indexes to a row after its contents reach this size.
-   ~ Increase if your column values are large, or if you have a very large
-   ~ number of columns.  The competing causes are, Cassandra has to
-   ~ deserialize this much of the row to read a single column, so you want
-   ~ it to be small - at least if you do many partial-row reads - but all
-   ~ the index data is read for each access, so you don't want to generate
-   ~ that wastefully either.
-  -->
-  <ColumnIndexSizeInKB>64</ColumnIndexSizeInKB>
-
-  <!--
-   ~ Flush memtable after this much data has been inserted, including
-   ~ overwritten data.  There is one memtable per column family, and
-   ~ this threshold is based solely on the amount of data stored, not
-   ~ actual heap memory usage (there is some overhead in indexing the
-   ~ columns).
-  -->
-  <MemtableThroughputInMB>64</MemtableThroughputInMB>
-  <!--
-   ~ Throughput setting for Binary Memtables.  Typically these are
-   ~ used for bulk load so you want them to be larger.
-  -->
-  <BinaryMemtableThroughputInMB>256</BinaryMemtableThroughputInMB>
-  <!--
-   ~ The maximum number of columns in millions to store in memory per
-   ~ ColumnFamily before flushing to disk.  This is also a per-memtable
-   ~ setting.  Use with MemtableThroughputInMB to tune memory usage.
-  -->
-  <MemtableOperationsInMillions>0.3</MemtableOperationsInMillions>
-  <!--
-   ~ The maximum time to leave a dirty memtable unflushed.
-   ~ (While any affected columnfamilies have unflushed data from a
-   ~ commit log segment, that segment cannot be deleted.)
-   ~ This needs to be large enough that it won't cause a flush storm
-   ~ of all your memtables flushing at once because none has hit
-   ~ the size or count thresholds yet.  For production, a larger
-   ~ value such as 1440 is recommended.
-  -->
-  <MemtableFlushAfterMinutes>60</MemtableFlushAfterMinutes>
-
-  <!--
-   ~ Unlike most systems, in Cassandra writes are faster than reads, so
-   ~ you can afford more of those in parallel.  A good rule of thumb is 2
-   ~ concurrent reads per processor core.  Increase ConcurrentWrites to
-   ~ the number of clients writing at once if you enable CommitLogSync +
-   ~ CommitLogSyncDelay. -->
-  <ConcurrentReads>8</ConcurrentReads>
-  <ConcurrentWrites>32</ConcurrentWrites>
-
-  <!--
-   ~ CommitLogSync may be either ""periodic"" or ""batch.""  When in batch
-   ~ mode, Cassandra won't ack writes until the commit log has been
-   ~ fsynced to disk.  It will wait up to CommitLogSyncBatchWindowInMS
-   ~ milliseconds for other writes, before performing the sync.
-
-   ~ This is less necessary in Cassandra than in traditional databases
-   ~ since replication reduces the odds of losing data from a failure
-   ~ after writing the log entry but before it actually reaches the disk.
-   ~ So the other option is ""timed,"" where writes may be acked immediately
-   ~ and the CommitLog is simply synced every CommitLogSyncPeriodInMS
-   ~ milliseconds.
-  -->
-  <CommitLogSync>periodic</CommitLogSync>
-  <!--
-   ~ Interval at which to perform syncs of the CommitLog in periodic mode.
-   ~ Usually the default of 10000ms is fine; increase it if your i/o
-   ~ load is such that syncs are taking excessively long times.
-  -->
-  <CommitLogSyncPeriodInMS>10000</CommitLogSyncPeriodInMS>
-  <!--
-   ~ Delay (in milliseconds) during which additional commit log entries
-   ~ may be written before fsync in batch mode.  This will increase
-   ~ latency slightly, but can vastly improve throughput where there are
-   ~ many writers.  Set to zero to disable (each entry will be synced
-   ~ individually).  Reasonable values range from a minimal 0.1 to 10 or
-   ~ even more if throughput matters more than latency.
-  -->
-  <!-- <CommitLogSyncBatchWindowInMS>1</CommitLogSyncBatchWindowInMS> -->
-
-  <!--
-   ~ Time to wait before garbage-collection deletion markers.  Set this to
-   ~ a large enough value that you are confident that the deletion marker
-   ~ will be propagated to all replicas by the time this many seconds has
-   ~ elapsed, even in the face of hardware failures.  The default value is
-   ~ ten days.
-  -->
-  <GCGraceSeconds>86400</GCGraceSeconds>
-</Storage>",2011-04-28T09:57:29Z,151
"@@ -102,8 +102,8 @@
       <version.apacheds.jdbm>1.5.4</version.apacheds.jdbm>
       <version.bdbje>4.0.92</version.bdbje>
       <version.c3p0>0.9.1.2</version.c3p0>
-      <version.cassandra>0.6.6</version.cassandra>
-      <version.cassandra.connection.pool>0.3.2</version.cassandra.connection.pool>
+      <version.cassandra>0.7.4</version.cassandra>
+      <version.cassandra.pool>0.7.1</version.cassandra.pool>
       <version.com.intellij.forms_rt>6.0.5</version.com.intellij.forms_rt>
       <version.commons.compress>1.0</version.commons.compress>
       <version.commons.pool>1.5.4</version.commons.pool>",2011-04-28T09:57:29Z,152
"@@ -198,11 +198,21 @@ public Object visitApplyDeltaCommand(InvocationContext ctx, ApplyDeltaCommand co
 
    @Override
    public final Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
+      wrapEntryForRemoveIfNeeded(ctx, command);
+      return setSkipRemoteGetsAndInvokeNextForDataCommand(ctx, command, null);
+   }
+
+   private void wrapEntryForRemoveIfNeeded(InvocationContext ctx, RemoveCommand command) throws InterruptedException {
       if (shouldWrap(command.getKey(), ctx, command)) {
-         entryFactory.wrapEntryForRemove(ctx, command.getKey(),
-                                         command.hasFlag(Flag.IGNORE_RETURN_VALUES) && !command.isConditional());
+         if (command.isIgnorePreviousValue()) {
+            //wrap it for put, as the previous value might not be present by now (e.g. might have been deleted)
+            // but we still need to apply the new value.
+            entryFactory.wrapEntryForPut(ctx, command.getKey(), null, false, command, false);
+         } else {
+            entryFactory.wrapEntryForRemove(ctx, command.getKey(),
+                  command.hasFlag(Flag.IGNORE_RETURN_VALUES) && !command.isConditional());
+         }
       }
-      return setSkipRemoteGetsAndInvokeNextForDataCommand(ctx, command, null);
    }
 
    @Override
@@ -438,7 +448,13 @@ public Object visitInvalidateCommand(InvocationContext ctx, InvalidateCommand co
       @Override
       public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
          if (cdl.localNodeIsOwner(command.getKey())) {
-            entryFactory.wrapEntryForRemove(ctx, command.getKey(), false);
+            if (command.isIgnorePreviousValue()) {
+               //wrap it for put, as the previous value might not be present by now (e.g. might have been deleted)
+               // but we still need to apply the new value.
+               entryFactory.wrapEntryForPut(ctx, command.getKey(), null, false, command, false);
+            } else  {
+               entryFactory.wrapEntryForRemove(ctx, command.getKey(), false);
+            }
             invokeNextInterceptor(ctx, command);
          }
          return null;",2013-10-04T12:58:12Z,399
"@@ -3,6 +3,8 @@
 import org.infinispan.commands.VisitableCommand;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
 
 import java.util.concurrent.BrokenBarrierException;
 import java.util.concurrent.CyclicBarrier;
@@ -17,6 +19,8 @@
  * @since 6.0
  */
 public class BlockingInterceptor extends CommandInterceptor {
+   private static final Log log = LogFactory.getLog(BlockingInterceptor.class);
+
    private final CyclicBarrier barrier;
    private final AtomicBoolean firstBlocked = new AtomicBoolean();
    private final Class<? extends VisitableCommand> commandClass;
@@ -33,17 +37,17 @@ private void blockIfNeeded(VisitableCommand command) throws BrokenBarrierExcepti
       if (commandClass.isInstance(command)) {
          if (firstBlocked.compareAndSet(false, true)) {
             try {
-               getLog().tracef(""Command blocking %s completion of %s"", blockAfter ? ""after"" : ""before"", command);
+               log.tracef(""Command blocking %s completion of %s"", blockAfter ? ""after"" : ""before"", command);
                // The first arrive and await is to sync with main thread
                barrier.await();
                // Now we actually block until main thread lets us go
                barrier.await();
-               getLog().tracef(""Command completed blocking completion of %s"", command);
+               log.tracef(""Command completed blocking completion of %s"", command);
             } finally {
                firstBlocked.set(false);
             }
          } else {
-            getLog().trace(""Command arrived but already found a blocker"");
+            log.trace(""Command arrived but already found a blocker"");
          }
       }
    }",2013-10-04T12:58:12Z,400
"@@ -46,7 +46,7 @@
  *
  * @author Dan Berindei
  */
-@Test(groups = ""functional"", testName = ""distribution.rehash.NonTxPrimaryOwnerLeavingTest"")
+@Test(groups = ""functional"", testName = ""distribution.rehash.NonTxJoinerBecomingBackupOwnerTest"")
 @CleanupAfterMethod
 public class NonTxJoinerBecomingBackupOwnerTest extends MultipleCacheManagersTest {
 
@@ -87,6 +87,25 @@ private Object getPreviousValue() {
       private Object getReturnValue() {
          return returnValue;
       }
+
+      private Object perform(AdvancedCache<Object, Object> cache0, MagicKey key) {
+         switch (this) {
+            case PUT:
+               return cache0.put(key, getValue());
+            case PUT_IF_ABSENT:
+               return cache0.putIfAbsent(key, getValue());
+            case REPLACE:
+               return cache0.replace(key, getValue());
+            case REPLACE_EXACT:
+               return cache0.replace(key, getPreviousValue(), getValue());
+            case REMOVE:
+               return cache0.remove(key);
+            case REMOVE_EXACT:
+               return cache0.remove(key, getPreviousValue());
+            default:
+               throw new IllegalArgumentException(""Unsupported operation: "" + this);
+         }
+      }
    }
 
    @Override
@@ -196,22 +215,7 @@ public boolean isSatisfied() throws Exception {
       Future<Object> future = fork(new Callable<Object>() {
          @Override
          public Object call() throws Exception {
-            switch (op) {
-               case PUT:
-                  return cache0.put(key, op.getValue());
-               case PUT_IF_ABSENT:
-                  return cache0.putIfAbsent(key, op.getValue());
-               case REPLACE:
-                  return cache0.replace(key, op.getValue());
-               case REPLACE_EXACT:
-                  return cache0.replace(key, op.getPreviousValue(), op.getValue());
-               case REMOVE:
-                  return cache0.remove(key);
-               case REMOVE_EXACT:
-                  return cache0.remove(key, op.getPreviousValue());
-               default:
-                  throw new IllegalArgumentException(""Unsupported operation: "" + op);
-            }
+            return op.perform(cache0, key);
          }
       });
 ",2013-10-04T12:58:12Z,401
"@@ -0,0 +1,263 @@
+package org.infinispan.distribution.rehash;
+
+import org.infinispan.AdvancedCache;
+import org.infinispan.Cache;
+import org.infinispan.commands.VisitableCommand;
+import org.infinispan.commands.write.PutKeyValueCommand;
+import org.infinispan.commands.write.RemoveCommand;
+import org.infinispan.commands.write.ReplaceCommand;
+import org.infinispan.commons.api.BasicCacheContainer;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.container.DataContainer;
+import org.infinispan.distribution.BlockingInterceptor;
+import org.infinispan.distribution.MagicKey;
+import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.interceptors.EntryWrappingInterceptor;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.statetransfer.StateResponseCommand;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CheckPoint;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.topology.ClusterTopologyManager;
+import org.infinispan.transaction.TransactionMode;
+import org.infinispan.tx.dld.ControlledRpcManager;
+import org.mockito.invocation.InvocationOnMock;
+import org.mockito.stubbing.Answer;
+import org.testng.annotations.Test;
+
+import java.util.concurrent.Callable;
+import java.util.concurrent.CyclicBarrier;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+
+import static java.util.concurrent.TimeUnit.SECONDS;
+import static org.mockito.Matchers.*;
+import static org.mockito.Mockito.doAnswer;
+import static org.mockito.Mockito.spy;
+import static org.testng.AssertJUnit.assertEquals;
+import static org.testng.AssertJUnit.assertNotNull;
+
+/**
+ * Tests that state transfer can't overwrite a value written by a command during state transfer.
+ * See https://issues.jboss.org/browse/ISPN-3443
+ *
+ * @author Dan Berindei
+ */
+@Test(groups = ""functional"", testName = ""distribution.rehash.NonTxStateTransferOverwritingValueTest"")
+@CleanupAfterMethod
+public class NonTxStateTransferOverwritingValueTest extends MultipleCacheManagersTest {
+
+   private static final String CACHE_NAME = BasicCacheContainer.DEFAULT_CACHE_NAME;
+
+   private static enum Operation {
+      PUT(PutKeyValueCommand.class, ""v1"", null, null),
+      PUT_IF_ABSENT(PutKeyValueCommand.class, ""v1"", null, null),
+      REPLACE(ReplaceCommand.class, ""v1"", ""v0"", ""v0""),
+      REPLACE_EXACT(ReplaceCommand.class, ""v1"", ""v0"", true),
+      REMOVE(RemoveCommand.class, null, ""v0"", ""v0""),
+      REMOVE_EXACT(RemoveCommand.class, null, ""v0"", true);
+
+      private final Class<? extends VisitableCommand> commandClass;
+      private final Object value;
+      private final Object previousValue;
+      private final Object returnValue;
+
+      Operation(Class<? extends VisitableCommand> commandClass, Object value, Object previousValue, 
+                Object returnValue) {
+         this.commandClass = commandClass;
+         this.value = value;
+         this.previousValue = previousValue;
+         this.returnValue = returnValue;
+      }
+
+      private Class<? extends VisitableCommand> getCommandClass() {
+         return commandClass;
+      }
+
+      private Object getValue() {
+         return value;
+      }
+
+      private Object getPreviousValue() {
+         return previousValue;
+      }
+
+      private Object getReturnValue() {
+         return returnValue;
+      }
+
+      private Object perform(AdvancedCache<Object, Object> cache0, MagicKey key) {
+         switch (this) {
+            case PUT:
+               return cache0.put(key, value);
+            case PUT_IF_ABSENT:
+               return cache0.putIfAbsent(key, value);
+            case REPLACE:
+               return cache0.replace(key, value);
+            case REPLACE_EXACT:
+               return cache0.replace(key, previousValue, value);
+            case REMOVE:
+               return cache0.remove(key);
+            case REMOVE_EXACT:
+               return cache0.remove(key, previousValue);
+            default:
+               throw new IllegalArgumentException(""Unsupported operation: "" + this);
+         }
+      }
+   }
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      ConfigurationBuilder c = getConfigurationBuilder();
+
+      addClusterEnabledCacheManager(c);
+      waitForClusterToForm();
+   }
+
+   protected ConfigurationBuilder getConfigurationBuilder() {
+      ConfigurationBuilder c = new ConfigurationBuilder();
+      c.clustering().cacheMode(CacheMode.DIST_SYNC);
+      c.transaction().transactionMode(TransactionMode.NON_TRANSACTIONAL);
+      return c;
+   }
+
+   public void testBackupOwnerJoiningDuringPut() throws Exception {
+      doTest(Operation.PUT);
+   }
+
+   public void testBackupOwnerJoiningDuringPutIfAbsent() throws Exception {
+      doTest(Operation.PUT_IF_ABSENT);
+   }
+
+   public void testBackupOwnerJoiningDuringReplace() throws Exception {
+      doTest(Operation.REPLACE);
+   }
+
+   public void testBackupOwnerJoiningDuringReplaceWithPreviousValue() throws Exception {
+      doTest(Operation.REPLACE_EXACT);
+   }
+
+   public void testBackupOwnerJoiningDuringRemove() throws Exception {
+      doTest(Operation.REMOVE);
+   }
+
+   public void testBackupOwnerJoiningDuringRemoveWithPreviousValue() throws Exception {
+      doTest(Operation.REMOVE_EXACT);
+   }
+
+   private void doTest(final Operation op) throws Exception {
+      final AdvancedCache<Object, Object> cache0 = advancedCache(0);
+      final MagicKey key = new MagicKey(cache0);
+
+      // Prepare for replace/remove: put a previous value in cache0
+      final Object previousValue = op.getPreviousValue();
+      if (previousValue != null) {
+         cache0.put(key, previousValue);
+         assertEquals(previousValue, cache0.get(key));
+         log.tracef(""Previous value inserted: %s = %s"", key, previousValue);
+      }
+
+      int preJoinTopologyId = cache0.getComponentRegistry().getStateTransferManager().getCacheTopology().getTopologyId();
+
+      // Block any state response commands on cache0
+      CheckPoint checkPoint = new CheckPoint();
+      ControlledRpcManager blockingRpcManager0 = blockStateResponseCommand(cache0);
+
+      // Block the rebalance confirmation on cache0
+      blockRebalanceConfirmation(manager(0), checkPoint);
+
+      // Start the joiner
+      log.tracef(""Starting the cache on the joiner"");
+      ConfigurationBuilder c = getConfigurationBuilder();
+      c.clustering().stateTransfer().awaitInitialTransfer(false);
+      addClusterEnabledCacheManager(c);
+
+      final AdvancedCache<Object,Object> cache1 = advancedCache(1);
+      int rebalanceTopologyId = preJoinTopologyId + 1;
+
+      // Wait for the write CH to contain the joiner everywhere
+      eventually(new Condition() {
+         @Override
+         public boolean isSatisfied() throws Exception {
+            return cache0.getRpcManager().getMembers().size() == 2 &&
+                  cache1.getRpcManager().getMembers().size() == 2;
+         }
+      });
+
+      // Every PutKeyValueCommand will be blocked before committing the entry on cache1
+      CyclicBarrier beforeCommitCache1Barrier = new CyclicBarrier(2);
+      BlockingInterceptor blockingInterceptor1 = new BlockingInterceptor(beforeCommitCache1Barrier,
+            op.getCommandClass(), true);
+      cache1.addInterceptorAfter(blockingInterceptor1, EntryWrappingInterceptor.class);
+
+      // Wait for cache0 to collect the state to send to cache1 (including our previous value).
+      blockingRpcManager0.waitForCommandToBlock();
+
+      // Put/Replace/Remove from cache0 with cache0 as primary owner, cache1 will become a backup owner for the retry
+      // The put command will be blocked on cache1 just before committing the entry.
+      Future<Object> future = fork(new Callable<Object>() {
+         @Override
+         public Object call() throws Exception {
+            return op.perform(cache0, key);
+         }
+      });
+
+      // Wait for the entry to be wrapped on cache1
+      beforeCommitCache1Barrier.await(10, TimeUnit.SECONDS);
+
+      // Allow the state to be applied on cache1 (writing the old value for our entry)
+      blockingRpcManager0.stopBlocking();
+
+      // Wait for cache1 to finish applying the state, but don't allow the rebalance confirmation to be processed.
+      // (It would change the topology and it would trigger a retry for the command.)
+      checkPoint.awaitStrict(""pre_rebalance_confirmation_"" + rebalanceTopologyId + ""_from_"" + address(1), 10, SECONDS);
+
+      // Now allow the command to commit on cache1
+      beforeCommitCache1Barrier.await(10, TimeUnit.SECONDS);
+
+      // Wait for the command to finish and check that it didn't fail
+      Object result = future.get(10, TimeUnit.SECONDS);
+      assertEquals(op.getReturnValue(), result);
+      log.tracef(""%s operation is done"", op);
+
+      // Allow the rebalance confirmation to proceed and wait for the topology to change everywhere
+      checkPoint.trigger(""resume_rebalance_confirmation_"" + rebalanceTopologyId + ""_from_"" + address(0));
+      checkPoint.trigger(""resume_rebalance_confirmation_"" + rebalanceTopologyId + ""_from_"" + address(1));
+      TestingUtil.waitForRehashToComplete(cache0, cache1);
+
+      // Check the value on all the nodes
+      assertEquals(op.getValue(), cache0.get(key));
+      assertEquals(op.getValue(), cache1.get(key));
+   }
+
+   private ControlledRpcManager blockStateResponseCommand(final Cache cache) throws InterruptedException {
+      RpcManager rpcManager = TestingUtil.extractComponent(cache, RpcManager.class);
+      ControlledRpcManager controlledRpcManager = new ControlledRpcManager(rpcManager);
+      controlledRpcManager.blockBefore(StateResponseCommand.class);
+      TestingUtil.replaceComponent(cache, RpcManager.class, controlledRpcManager, true);
+      return controlledRpcManager;
+   }
+
+   private void blockRebalanceConfirmation(final EmbeddedCacheManager manager, final CheckPoint checkPoint)
+         throws Exception {
+      ClusterTopologyManager ctm = TestingUtil.extractGlobalComponent(manager, ClusterTopologyManager.class);
+      ClusterTopologyManager spyManager = spy(ctm);
+      TestingUtil.replaceComponent(manager, ClusterTopologyManager.class, spyManager, true);
+      doAnswer(new Answer<Object>() {
+         @Override
+         public Object answer(InvocationOnMock invocation) throws Throwable {
+            Object[] arguments = invocation.getArguments();
+            Address source = (Address) arguments[1];
+            int topologyId = (Integer) arguments[2];
+            checkPoint.trigger(""pre_rebalance_confirmation_"" + topologyId + ""_from_"" + source);
+            checkPoint.awaitStrict(""resume_rebalance_confirmation_"" + topologyId + ""_from_"" + source, 10, SECONDS);
+            return invocation.callRealMethod();
+         }
+      }).when(spyManager).handleRebalanceCompleted(anyString(), any(Address.class), anyInt(), any(Throwable.class),
+            anyInt());
+   }
+}
\ No newline at end of file",2013-10-04T12:58:12Z,402
"@@ -0,0 +1,25 @@
+package org.infinispan.distribution.rehash;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.transaction.TransactionMode;
+import org.testng.annotations.Test;
+
+/**
+ * Tests that state transfer can't overwrite a value written by a command during state transfer.
+ * See https://issues.jboss.org/browse/ISPN-3443
+ *
+ * @author Dan Berindei
+ * @since 6.0
+ */
+@Test(groups = ""functional"", testName = ""distribution.rehash.PessimisticStateTransferOverwritingValueTest"")
+public class OptimisticStateTransferOverwritingValueTest extends NonTxStateTransferOverwritingValueTest {
+   @Override
+   protected ConfigurationBuilder getConfigurationBuilder() {
+      ConfigurationBuilder c = new ConfigurationBuilder();
+      c.clustering().cacheMode(CacheMode.DIST_SYNC);
+      c.transaction().transactionMode(TransactionMode.TRANSACTIONAL).lockingMode(LockingMode.OPTIMISTIC);
+      return c;
+   }
+}",2013-10-04T12:58:12Z,403
"@@ -0,0 +1,25 @@
+package org.infinispan.distribution.rehash;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.transaction.TransactionMode;
+import org.testng.annotations.Test;
+
+/**
+ * Tests that state transfer can't overwrite a value written by a command during state transfer.
+ * See https://issues.jboss.org/browse/ISPN-3443
+ *
+ * @author Dan Berindei
+ * @since 6.0
+ */
+@Test(groups = ""functional"", testName = ""distribution.rehash.PessimisticStateTransferOverwritingValueTest"")
+public class PessimisticStateTransferOverwritingValueTest extends NonTxStateTransferOverwritingValueTest {
+   @Override
+   protected ConfigurationBuilder getConfigurationBuilder() {
+      ConfigurationBuilder c = new ConfigurationBuilder();
+      c.clustering().cacheMode(CacheMode.DIST_SYNC);
+      c.transaction().transactionMode(TransactionMode.TRANSACTIONAL).lockingMode(LockingMode.PESSIMISTIC);
+      return c;
+   }
+}",2013-10-04T12:58:12Z,404
"@@ -73,21 +73,23 @@ public final void fromStreamSupport(ObjectInput objectInput) throws CacheLoaderE
          ps = conn.prepareStatement(sql);
 
          int readCount = 0;
+         // BatchSize is always a power of two.
          int batchSize = tableManipulation.getBatchSize();
+         int batchSizeMinusOne = batchSize - 1;
 
          Object objFromStream = marshaller.objectFromObjectStream(objectInput);
          while (fromStreamProcess(objFromStream, ps, objectInput)) {
             ps.addBatch();
             readCount++;
-            if (readCount % batchSize == 0) {
+            if ((readCount & batchSizeMinusOne) == 0) {
                ps.executeBatch();
                if (log.isTraceEnabled()) {
                   log.tracef(""Executing batch %s, batch size is %d"", readCount / batchSize, batchSize);
                }
             }
             objFromStream = marshaller.objectFromObjectStream(objectInput);
          }
-         if (readCount % batchSize != 0) {
+         if ((readCount & batchSizeMinusOne) != 0) {
             ps.executeBatch();//flush the batch
          }
          if (log.isTraceEnabled()) {",2013-08-30T13:32:17Z,405
"@@ -26,7 +26,7 @@ public class TableManipulation implements Cloneable {
 
    public static final int DEFAULT_FETCH_SIZE = 100;
 
-   public static final int DEFAULT_BATCH_SIZE = 100;
+   public static final int DEFAULT_BATCH_SIZE = 128;
 
    private String identifierQuoteString;
    private String cacheName;
@@ -368,7 +368,7 @@ public int getFetchSize() {
    /**
     * When doing repetitive DB inserts (e.g. on {@link org.infinispan.loaders.spi.CacheStore#fromStream(java.io.ObjectInput)}
     * this will be batched according to this parameter. This is an optional parameter, and if it is not specified it
-    * will be defaulted to {@link #DEFAULT_BATCH_SIZE}.
+    * will be defaulted to {@link #DEFAULT_BATCH_SIZE}.  Guaranteed to be a power of two.
     */
    public int getBatchSize() {
       return config.batchSize();",2013-08-30T13:32:17Z,406
"@@ -55,6 +55,7 @@ public class JdbcBinaryCacheStore extends BucketBasedCacheStore {
    private static final Log log = LogFactory.getLog(JdbcBinaryCacheStore.class, Log.class);
 
    private final static byte BINARY_STREAM_DELIMITER = 100;
+   private final static int  PURGE_BATCH_SIZE = 128;
 
    private JdbcBinaryCacheStoreConfiguration configuration;
 
@@ -312,7 +313,6 @@ public void purgeInternal() throws CacheLoaderException {
       PreparedStatement ps = null;
       ResultSet rs = null;
       Set<Bucket> expiredBuckets = new HashSet<Bucket>();
-      final int batchSize = 100;
       try {
          try {
             String sql = tableManipulation.getSelectExpiredRowsSql();
@@ -378,7 +378,7 @@ public void purgeInternal() throws CacheLoaderException {
                   ps.setString(3, bucket.getBucketIdAsString());
                   ps.addBatch();
                   updateCount++;
-                  if (updateCount % batchSize == 0) {
+                  if (updateCount % PURGE_BATCH_SIZE == 0) {
                      ps.executeBatch();
                      if (log.isTraceEnabled()) {
                         log.tracef(""Flushing batch, update count is: %d"", updateCount);
@@ -390,7 +390,7 @@ public void purgeInternal() throws CacheLoaderException {
                }
             }
             // flush the batch
-            if (updateCount % batchSize != 0) {
+            if (updateCount % PURGE_BATCH_SIZE != 0) {
                if (log.isTraceEnabled()) {
                   log.tracef(""Flushing batch, update count is: %d"", updateCount);
                }
@@ -432,14 +432,14 @@ public void purgeInternal() throws CacheLoaderException {
                ps.setString(1, bucket.getBucketIdAsString());
                ps.addBatch();
                deletionCount++;
-               if (deletionCount % batchSize == 0) {
+               if (deletionCount % PURGE_BATCH_SIZE == 0) {
                   if (log.isTraceEnabled()) {
                      log.tracef(""Flushing deletion batch, total deletion count so far is %d"", deletionCount);
                   }
                   ps.executeBatch();
                }
             }
-            if (deletionCount % batchSize != 0) {
+            if (deletionCount % PURGE_BATCH_SIZE != 0) {
                int[] batchResult = ps.executeBatch();
                if (log.isTraceEnabled()) {
                   log.tracef(""Flushed the batch and received following results: %s"", Arrays.toString(batchResult));",2013-08-30T13:32:17Z,407
"@@ -1,5 +1,6 @@
 package org.infinispan.loaders.jdbc.configuration;
 
+import org.infinispan.commons.util.Util;
 import org.infinispan.loaders.jdbc.DatabaseType;
 
 public class TableManipulationConfiguration {
@@ -29,7 +30,7 @@ public class TableManipulationConfiguration {
       this.timestampColumnName = timestampColumnName;
       this.timestampColumnType = timestampColumnType;
       this.databaseType = databaseType;
-      this.batchSize = batchSize;
+      this.batchSize = Util.findNextHighestPowerOfTwo(batchSize);
       this.fetchSize = fetchSize;
       this.createOnStart = createOnStart;
       this.dropOnExit = dropOnExit;
@@ -83,6 +84,9 @@ public int fetchSize() {
       return fetchSize;
    }
 
+   /**
+    * @return the size of batches to process.  Guaranteed to be a power of two.
+    */
    public int batchSize() {
       return batchSize;
    }",2013-08-30T13:32:17Z,408
"@@ -30,7 +30,7 @@ public void testStringKeyedJdbcStore() throws Exception {
             ""     <loaders>\n"" +
             ""       <stringKeyedJdbcStore xmlns=\""urn:infinispan:config:jdbc:6.0\"" key2StringMapper=\""org.infinispan.loaders.jdbc.configuration.DummyKey2StringMapper\"">\n"" +
             ""         <connectionPool connectionUrl=\""jdbc:h2:mem:infinispan;DB_CLOSE_DELAY=-1\"" username=\""dbuser\"" password=\""dbpass\"" driverClass=\""org.h2.Driver\""/>\n"" +
-            ""         <stringKeyedTable prefix=\""entry\"" fetchSize=\""34\"" batchSize=\""99\"" >\n"" +
+            ""         <stringKeyedTable prefix=\""entry\"" fetchSize=\""34\"" batchSize=\""128\"" >\n"" +
             ""           <idColumn name=\""id\"" type=\""VARCHAR\"" />\n"" +
             ""           <dataColumn name=\""datum\"" type=\""BINARY\"" />\n"" +
             ""           <timestampColumn name=\""version\"" type=\""BIGINT\"" />\n"" +
@@ -42,7 +42,7 @@ public void testStringKeyedJdbcStore() throws Exception {
             TestingUtil.INFINISPAN_END_TAG;
 
       JdbcStringBasedCacheStoreConfiguration store = (JdbcStringBasedCacheStoreConfiguration) buildCacheManagerWithCacheStore(config);
-      assertEquals(99, store.table().batchSize());
+      assertEquals(128, store.table().batchSize());
       assertEquals(34, store.table().fetchSize());
       assertEquals(""BINARY"", store.table().dataColumnType());
       assertEquals(""version"", store.table().timestampColumnName());
@@ -61,7 +61,7 @@ public void testBinaryKeyedJdbcStore() throws Exception {
             ""     <loaders>\n"" +
             ""       <binaryKeyedJdbcStore xmlns=\""urn:infinispan:config:jdbc:6.0\"" ignoreModifications=\""true\"">\n"" +
             ""         <simpleConnection connectionUrl=\""jdbc:h2:mem:infinispan;DB_CLOSE_DELAY=-1\"" username=\""dbuser\"" password=\""dbpass\"" driverClass=\""org.h2.Driver\""/>\n"" +
-            ""         <binaryKeyedTable prefix=\""bucket\"" fetchSize=\""34\"" batchSize=\""99\"">\n"" +
+            ""         <binaryKeyedTable prefix=\""bucket\"" fetchSize=\""34\"" batchSize=\""128\"">\n"" +
             ""           <idColumn name=\""id\"" type=\""BINARY\"" />\n"" +
             ""           <dataColumn name=\""datum\"" type=\""BINARY\"" />\n"" +
             ""           <timestampColumn name=\""version\"" type=\""BIGINT\"" />\n"" +
@@ -75,7 +75,7 @@ public void testBinaryKeyedJdbcStore() throws Exception {
       JdbcBinaryCacheStoreConfiguration store = (JdbcBinaryCacheStoreConfiguration) buildCacheManagerWithCacheStore(config);
       assertTrue(store.ignoreModifications());
       assertEquals(""bucket"", store.table().tableNamePrefix());
-      assertEquals(99, store.table().batchSize());
+      assertEquals(128, store.table().batchSize());
       assertEquals(34, store.table().fetchSize());
       assertEquals(""BINARY"", store.table().dataColumnType());
       assertEquals(""version"", store.table().timestampColumnName());
@@ -93,12 +93,12 @@ public void testMixedKeyedJdbcStore() throws Exception {
             ""     <loaders>\n"" +
             ""       <mixedKeyedJdbcStore xmlns=\""urn:infinispan:config:jdbc:6.0\"" key2StringMapper=\""org.infinispan.loaders.jdbc.configuration.DummyKey2StringMapper\"">\n"" +
             ""         <dataSource jndiUrl=\""java:MyDataSource\"" />\n"" +
-            ""         <stringKeyedTable prefix=\""entry\"" fetchSize=\""34\"" batchSize=\""99\"">\n"" +
+            ""         <stringKeyedTable prefix=\""entry\"" fetchSize=\""34\"" batchSize=\""128\"">\n"" +
             ""           <idColumn name=\""id\"" type=\""VARCHAR\"" />\n"" +
             ""           <dataColumn name=\""datum\"" type=\""BINARY\"" />\n"" +
             ""           <timestampColumn name=\""version\"" type=\""BIGINT\"" />\n"" +
             ""         </stringKeyedTable>\n"" +
-            ""         <binaryKeyedTable prefix=\""bucket\"" fetchSize=\""44\"" batchSize=\""79\"">\n"" +
+            ""         <binaryKeyedTable prefix=\""bucket\"" fetchSize=\""44\"" batchSize=\""256\"">\n"" +
             ""           <idColumn name=\""id\"" type=\""BINARY\"" />\n"" +
             ""           <dataColumn name=\""datum\"" type=\""BINARY\"" />\n"" +
             ""           <timestampColumn name=\""version\"" type=\""BIGINT\"" />\n"" +
@@ -113,13 +113,13 @@ public void testMixedKeyedJdbcStore() throws Exception {
       JdbcMixedCacheStoreConfiguration store = (JdbcMixedCacheStoreConfiguration) buildCacheManagerWithCacheStore(config);
 
       assertEquals(""entry"", store.stringTable().tableNamePrefix());
-      assertEquals(99, store.stringTable().batchSize());
+      assertEquals(128, store.stringTable().batchSize());
       assertEquals(34, store.stringTable().fetchSize());
       assertEquals(""BINARY"", store.stringTable().dataColumnType());
       assertEquals(""version"", store.stringTable().timestampColumnName());
 
       assertEquals(""bucket"", store.binaryTable().tableNamePrefix());
-      assertEquals(79, store.binaryTable().batchSize());
+      assertEquals(256, store.binaryTable().batchSize());
       assertEquals(44, store.binaryTable().fetchSize());
       assertEquals(""BINARY"", store.binaryTable().dataColumnType());
       assertEquals(""version"", store.binaryTable().timestampColumnName());",2013-08-30T13:32:17Z,409
"@@ -31,6 +31,7 @@ public class ConsistentHashV1 implements ConsistentHash {
    private volatile SocketAddress[] addresses;
 
    private int hashSpace;
+   private boolean hashSpaceIsMaxInt;
 
    protected Hash hash = new MurmurHash2();
 
@@ -69,12 +70,22 @@ public void init(Map<SocketAddress, Set<Integer>> servers2Hash, int numKeyOwners
       addresses = positions.values().toArray(new SocketAddress[hashWheelSize]);
 
       this.hashSpace = hashSpace;
+
+      // This is true if we're talking to an instance of Infinispan 5.2 or newer.
+      this.hashSpaceIsMaxInt = hashSpace == Integer.MAX_VALUE;
+
       this.numKeyOwners = numKeyOwners;
    }
 
    @Override
    public SocketAddress getServer(byte[] key) {
-      int normalisedHashForKey = getNormalizedHash(key) % hashSpace;
+      int normalisedHashForKey;
+      if (hashSpaceIsMaxInt) {
+         normalisedHashForKey = getNormalizedHash(key);
+         if (normalisedHashForKey == Integer.MAX_VALUE) normalisedHashForKey = 0;
+      } else {
+         normalisedHashForKey = getNormalizedHash(key) % hashSpace;
+      }
 
       int mainOwner = getHashIndex(normalisedHashForKey);
 ",2013-08-30T13:32:17Z,410
"@@ -246,7 +246,8 @@ public static long[] MurmurHash3_x64_128(final long[] key, final int seed) {
 
       long tail = key[key.length - 1];
 
-      if (key.length % 2 != 0) {
+      // Key length is odd
+      if ((key.length & 1) == 1) {
          state.k1 ^= tail;
          bmix(state);
       }",2013-08-30T13:32:17Z,411
"@@ -643,4 +643,14 @@ public static String join(List<String> strings, String separator) {
 
       return sb.toString();
    }
+
+   /**
+    * Returns a number such that the number is a power of two that is equal to, or greater than, the number passed in as
+    * an argument.  The smallest number returned will be 1, not 0.
+    */
+   public static int findNextHighestPowerOfTwo(int num) {
+      if (num <= 0) return 1;
+      int highestBit = Integer.highestOneBit(num);
+      return num <= highestBit ? highestBit : highestBit << 1;
+   }
 }",2013-08-30T13:32:17Z,412
"@@ -53,7 +53,7 @@
 public class MapReduceManagerImpl implements MapReduceManager {
 
    private static final Log log = LogFactory.getLog(MapReduceManagerImpl.class);
-   private static final int CANCELLATION_CHECK_FREQUENCY = 20;
+   private static final int CANCELLATION_CHECK_FREQUENCY = 32; // Should be a power of two so that the compiler can replace a % with a bitmask
    private ClusteringDependentLogic cdl;
    private EmbeddedCacheManager cacheManager;
    private CacheLoaderManager cacheLoaderManager;",2013-08-30T13:32:17Z,413
"@@ -23,6 +23,9 @@ public FileChunkMapper(GridFile file, Cache<String, byte[]> cache) {
       this.cache = cache;
    }
 
+   /**
+    * Guaranteed to be a power of two
+    */
    public int getChunkSize() {
       return file.getChunkSize();
    }",2013-08-30T13:32:17Z,414
"@@ -38,12 +38,19 @@ public class GridFile extends File {
    private final String path;
    private int chunkSize;
 
+   /**
+    * Creates a GridFile instance
+    * @param pathname path of file
+    * @param metadataCache cache to use to store metadata
+    * @param chunkSize chunk size.  Will be upgraded to next highest power of two.
+    * @param fs GridFilesystem instance
+    */
    GridFile(String pathname, Cache<String, Metadata> metadataCache, int chunkSize, GridFilesystem fs) {
       super(pathname);
       this.fs = fs;
       this.path = formatPath(pathname);
       this.metadataCache = metadataCache.getAdvancedCache();
-      this.chunkSize = chunkSize;
+      this.chunkSize = ModularArithmetic.CANNOT_ASSUME_DENOM_IS_POWER_OF_TWO ? chunkSize : org.infinispan.commons.util.Util.findNextHighestPowerOfTwo(chunkSize);
       initChunkSizeFromMetadata();
    }
 
@@ -163,6 +170,9 @@ void setLength(int newLength) {
       metadataCache.put(getAbsolutePath(), metadata);
    }
 
+   /**
+    * Guaranteed to be a power of two
+    */
    public int getChunkSize() {
       return chunkSize;
    }
@@ -532,17 +542,19 @@ public static class Metadata implements Externalizable {
 
       private int length = 0;
       private long modificationTime = 0;
-      private int chunkSize = 0;
-      private byte flags = 0;
+      private int chunkSize;
+      private byte flags;
 
 
       public Metadata() {
+         chunkSize = 1;
+         flags = 0;
       }
 
       public Metadata(int length, long modificationTime, int chunkSize, byte flags) {
          this.length = length;
          this.modificationTime = modificationTime;
-         this.chunkSize = chunkSize;
+         this.chunkSize = ModularArithmetic.CANNOT_ASSUME_DENOM_IS_POWER_OF_TWO ? chunkSize : org.infinispan.commons.util.Util.findNextHighestPowerOfTwo(chunkSize);
          this.flags = flags;
       }
 ",2013-08-30T13:32:17Z,415
"@@ -2,6 +2,7 @@
 
 import org.infinispan.AdvancedCache;
 import org.infinispan.Cache;
+import org.infinispan.commons.util.Util;
 import org.infinispan.context.Flag;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
@@ -43,11 +44,11 @@ public GridFilesystem(Cache<String, byte[]> data, Cache<String, GridFile.Metadat
       }
       this.data = data;
       this.metadata = metadata;
-      this.defaultChunkSize = defaultChunkSize;
+      this.defaultChunkSize = ModularArithmetic.CANNOT_ASSUME_DENOM_IS_POWER_OF_TWO ? defaultChunkSize : Util.findNextHighestPowerOfTwo(defaultChunkSize);
    }
 
    public GridFilesystem(Cache<String, byte[]> data, Cache<String, GridFile.Metadata> metadata) {
-      this(data, metadata, 8000);
+      this(data, metadata, ModularArithmetic.CANNOT_ASSUME_DENOM_IS_POWER_OF_TWO ? 8000 : 8192);
    }
 
    /**",2013-08-30T13:32:17Z,416
"@@ -17,10 +17,12 @@ public class GridInputStream extends InputStream {
    private byte[] currentBuffer = null;
    private int fSize;
    private boolean streamClosed = false;
-   private FileChunkMapper fileChunkMapper;
+   private final FileChunkMapper fileChunkMapper;
+   private final int chunkSize; // Guaranteed to be a power of 2
 
    GridInputStream(GridFile file, Cache<String, byte[]> cache) {
       fileChunkMapper = new FileChunkMapper(file, cache);
+      chunkSize = fileChunkMapper.getChunkSize();
       fSize = (int)file.length();
    }
 
@@ -82,7 +84,7 @@ private int readFromChunk(byte[] b, int off, int len) {
          localIndex += bytesToSkip;
       } else {
          getChunk();
-         localIndex = index % getChunkSize();
+         localIndex = ModularArithmetic.mod(index, chunkSize);
       }
       return bytesToSkip;
    }
@@ -121,10 +123,6 @@ private void getChunk() {
    }
 
    private int getChunkNumber() {
-      return index / getChunkSize();
-   }
-
-   private int getChunkSize() {
-      return fileChunkMapper.getChunkSize();
+      return index / chunkSize;
    }
 }",2013-08-30T13:32:17Z,417
"@@ -17,27 +17,29 @@ public class GridOutputStream extends OutputStream {
    private final byte[] currentBuffer;
    private int numberOfChunksWhenOpened;
 
-   private FileChunkMapper fileChunkMapper;
+   private final FileChunkMapper fileChunkMapper;
+   private final int chunkSize; // Guaranteed to be a power of 2
    private GridFile file;
    private boolean streamClosed;
 
    GridOutputStream(GridFile file, boolean append, Cache<String, byte[]> cache) {
       fileChunkMapper = new FileChunkMapper(file, cache);
+      chunkSize = fileChunkMapper.getChunkSize();
       this.file = file;
 
       index = append ? (int) file.length() : 0;
-      localIndex = index % getChunkSize();
+      localIndex = ModularArithmetic.mod(index, chunkSize);
       currentBuffer = append && !isLastChunkFull() ? fetchLastChunk() : createEmptyChunk();
 
       numberOfChunksWhenOpened = getLastChunkNumber() + 1;
    }
 
    private byte[] createEmptyChunk() {
-      return new byte[getChunkSize()];
+      return new byte[chunkSize];
    }
 
    private boolean isLastChunkFull() {
-      long bytesRemainingInLastChunk = file.length() % getChunkSize();
+      long bytesRemainingInLastChunk = ModularArithmetic.mod(file.length(), chunkSize);
       return bytesRemainingInLastChunk == 0;
    }
 
@@ -97,7 +99,7 @@ private int writeToChunk(byte[] b, int off, int len) throws IOException {
       if (remaining == 0) {
          flush();
          localIndex = 0;
-         remaining = getChunkSize();
+         remaining = chunkSize;
       }
       int bytesToWrite = Math.min(remaining, len);
       System.arraycopy(b, off, currentBuffer, localIndex, bytesToWrite);
@@ -132,19 +134,14 @@ private void storeChunk() {
    }
 
    private int getBytesRemainingInChunk() {
-      return getChunkSize() - localIndex;
+      return chunkSize - localIndex;
    }
 
    private int getChunkNumber(int position) {
-      return position / getChunkSize();
+      return position / chunkSize;
    }
 
    private void reset() {
       index = localIndex = 0;
    }
-
-   private int getChunkSize() {
-      return fileChunkMapper.getChunkSize();
-   }
-
 }",2013-08-30T13:32:17Z,418
"@@ -0,0 +1,25 @@
+package org.infinispan.io;
+
+/**
+ * For compatibility
+ *
+ * @author Manik Surtani
+ */
+public class ModularArithmetic {
+   public static final boolean CANNOT_ASSUME_DENOM_IS_POWER_OF_TWO = Boolean.getBoolean(""infinispan.compat"");
+
+   public static final int mod(int numerator, int denominator) {
+      if (CANNOT_ASSUME_DENOM_IS_POWER_OF_TWO)
+         return numerator % denominator;
+      else
+         return numerator & (denominator - 1);
+   }
+
+   public static final long mod(long numerator, int denominator) {
+      if (CANNOT_ASSUME_DENOM_IS_POWER_OF_TWO)
+         return numerator % denominator;
+      else
+         return numerator & (denominator - 1);
+   }
+
+}",2013-08-30T13:32:17Z,419
"@@ -18,11 +18,14 @@ public class ReadableGridFileChannel implements ReadableByteChannel {
 
    private boolean closed;
 
-   private FileChunkMapper fileChunkMapper;
+   private final FileChunkMapper fileChunkMapper;
+   private final int chunkSize; // Guaranteed to be a power of 2
+
    private long fileLength;
 
    ReadableGridFileChannel(GridFile file, Cache<String, byte[]> cache) {
       fileChunkMapper = new FileChunkMapper(file, cache);
+      chunkSize = fileChunkMapper.getChunkSize();
       fileLength = (int) file.length();
    }
 
@@ -95,7 +98,7 @@ public void position(long newPosition) throws IOException {
          currentBuffer = fileChunkMapper.fetchChunk(chunkNumberOfNewPosition);
       }
       position = newPos;
-      localIndex = newPos % getChunkSize();
+      localIndex = ModularArithmetic.mod(newPos, chunkSize);
    }
 
    private void checkOpen() throws ClosedChannelException {
@@ -109,11 +112,7 @@ public long size() throws IOException {
    }
 
    private int getChunkNumber(int position) {
-      return position < 0 ? -1 : (position / getChunkSize());
-   }
-
-   private int getChunkSize() {
-      return fileChunkMapper.getChunkSize();
+      return position < 0 ? -1 : (position / chunkSize);
    }
 
    private void reset() {",2013-08-30T13:32:17Z,420
"@@ -18,11 +18,13 @@ public class WritableGridFileChannel implements WritableByteChannel {
 
    private boolean closed;
 
-   private FileChunkMapper fileChunkMapper;
+   private final FileChunkMapper fileChunkMapper;
+   private final int chunkSize; // Guaranteed to be a power of 2
    private GridFile file;
 
    WritableGridFileChannel(GridFile file, Cache<String, byte[]> cache, boolean append) {
       fileChunkMapper = new FileChunkMapper(file, cache);
+      chunkSize = fileChunkMapper.getChunkSize();
       this.file = file;
 
       if (append)
@@ -40,11 +42,11 @@ private void initForOverwriting() {
    private void initForAppending() {
       this.currentBuffer = lastChunkIsFull() ? createEmptyChunk() : fetchLastChunk();
       this.position = (int) file.length();
-      this.localIndex = position % getChunkSize();
+      this.localIndex = ModularArithmetic.mod(position, chunkSize);
    }
 
    private byte[] createEmptyChunk() {
-      return new byte[getChunkSize()];
+      return new byte[chunkSize];
    }
 
    private byte[] fetchLastChunk() {
@@ -65,7 +67,7 @@ private byte[] createFullSizeCopy(byte[] val) {
    }
 
    private boolean lastChunkIsFull() {
-      return file.length() % getChunkSize() == 0;
+      return ModularArithmetic.mod(file.length(), chunkSize) == 0;
    }
 
    @Override
@@ -85,7 +87,7 @@ private int writeToChunk(ByteBuffer src) throws IOException {
       if (remainingInChunk == 0) {
          flush();
          localIndex = 0;
-         remainingInChunk = getChunkSize();
+         remainingInChunk = chunkSize;
       }
 
       int bytesToWrite = Math.min(remainingInChunk, src.remaining());
@@ -117,7 +119,7 @@ private int getChunkNumberOfPreviousByte() {
    }
 
    private int getChunkNumber(int position) {
-      return position / getChunkSize();
+      return position / chunkSize;
    }
 
    @Override
@@ -137,8 +139,4 @@ private void checkOpen() throws ClosedChannelException {
          throw new ClosedChannelException();
       }
    }
-
-   private int getChunkSize() {
-      return fileChunkMapper.getChunkSize();
-   }
 }",2013-08-30T13:32:17Z,421
"@@ -240,10 +240,10 @@ public void testDeleteOnExit() {
    public void testOverwritingFileDoesNotLeaveExcessChunksInCache() throws Exception {
       assertEquals(numberOfChunksInCache(), 0);
 
-      writeToFile(""leak.txt"", ""12345abcde12345"", 5); // file length = 15, chunkSize = 5
-      assertEquals(numberOfChunksInCache(), 3);
+      writeToFile(""leak.txt"", ""12345abcde12345"", 5); // file length = 15, chunkSize = 5.  Chunk size should ""upgrade"" to 8
+      assertEquals(numberOfChunksInCache(), 2);
 
-      writeToFile(""leak.txt"", ""12345"", 5);           // file length = 5, chunkSize = 5
+      writeToFile(""leak.txt"", ""12345678"", 5);           // file length = 5, chunkSize = 5.  Chunk size should ""upgrade"" to 8
       assertEquals(numberOfChunksInCache(), 1);
    }
 
@@ -356,19 +356,19 @@ public void testSkip() throws Exception {
    @SuppressWarnings(""ResultOfMethodCallIgnored"")
    public void testAvailable() throws Exception {
       String filePath = ""available.txt"";
-      writeToFile(filePath, ""abcde"" + ""fghij"" + ""klmno"" + ""pqrst"" + ""uvwxy"" + ""z"", 5);
+      writeToFile(filePath, ""abcde"" + ""fghij"" + ""klmno"" + ""pqrst"" + ""uvwxy"" + ""z"", 5); // Chunk size should get ""upgraded"" to 8
 
       InputStream in = fs.getInput(filePath);
       try {
          assertEquals(in.available(), 0); // since first chunk hasn't been fetched yet
          in.read();
-         assertEquals(in.available(), 4);
+         assertEquals(in.available(), 7);
          in.skip(3);
-         assertEquals(in.available(), 1);
+         assertEquals(in.available(), 4);
          in.read();
-         assertEquals(in.available(), 0);
+         assertEquals(in.available(), 3);
          in.read();
-         assertEquals(in.available(), 4);
+         assertEquals(in.available(), 2);
       } finally {
          in.close();
       }",2013-08-30T13:32:17Z,415
"@@ -133,15 +133,15 @@ public IndexingConfigurationBuilder withProperties(Properties props) {
    @Override
    public void validate() {
       if (enabled) {
+         //Indexing is not conceptually compatible with Invalidation mode
+         if (clustering().cacheMode().isInvalidation()) {
+            throw log.invalidConfigurationIndexingWithInvalidation();
+         }
          // Check that the query module is on the classpath.
          try {
             Util.loadClassStrict(""org.infinispan.query.Search"", getBuilder().classLoader());
          } catch (ClassNotFoundException e) {
-            log.warnf(""Indexing can only be enabled if infinispan-query.jar is available on your classpath, and this jar has not been detected. Intended behavior may not be exhibited."");
-         }
-         //Indexing is not conceptually compatible with Invalidation mode
-         if (clustering().cacheMode().isInvalidation()) {
-            throw log.invalidConfigurationIndexingWithInvalidation();
+            throw log.invalidConfigurationIndexingWithoutModule();
          }
       }
    }",2013-11-06T13:41:43Z,42
"@@ -1019,5 +1019,8 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @LogMessage(level = ERROR)
    @Message(value = ""Persistence enabled without any CacheWriteInterceptor in InterceptorChain!"", id = 275)
    void persistenceWithoutCacheWriteInterceptor();
-}
 
+   @Message(value = ""Indexing can only be enabled if infinispan-query.jar is available on your classpath, and this jar has not been detected."", id = 276)
+   CacheConfigurationException invalidConfigurationIndexingWithoutModule();
+   
+}",2013-11-06T13:41:43Z,45
"@@ -81,6 +81,20 @@ public void testIndexingOnInvalidationCache() {
       }
    }
 
+   @Test(expectedExceptions = CacheConfigurationException.class, expectedExceptionsMessageRegExp =
+         ""ISPN(\\d)*: Indexing can only be enabled if infinispan-query.jar is available on your classpath, and this jar has not been detected."")
+   public void testIndexingRequiresOptionalModule() {
+      EmbeddedCacheManager ecm = null;
+      try {
+         ConfigurationBuilder c = new ConfigurationBuilder();
+         c.indexing().enable();
+         ecm = TestCacheManagerFactory.createClusteredCacheManager(c);
+         ecm.getCache();
+      } finally {
+         TestingUtil.killCacheManagers(ecm);
+      }
+   }
+
    private EmbeddedCacheManager createCacheManager() throws Exception {
       ConfigurationBuilder config = new ConfigurationBuilder();
       config.clustering().cacheMode(CacheMode.REPL_ASYNC);",2013-11-06T13:41:43Z,422
"@@ -4,7 +4,6 @@
 import org.apache.log4j.Level;
 import org.apache.log4j.Logger;
 import org.apache.log4j.spi.LoggingEvent;
-import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
@@ -72,17 +71,6 @@ public void testConfigWarnings() throws Exception {
       }
    }
 
-   public void testWarningForMissingQuery() {
-      EmbeddedCacheManager embeddedCacheManager = TestCacheManagerFactory.createCacheManager(CacheMode.LOCAL, true);
-      try {
-         embeddedCacheManager.getCache();
-         assert appender.isFoundUnknownWarning();
-         assert appender.unknownWarning().contains(""infinispan-query.jar"");
-      } finally {
-         TestingUtil.killCacheManagers(embeddedCacheManager);
-      }
-   }
-
    private String[] getConfigFileNames() {
       File file = getRootFolder();
       if (!file.isDirectory()) {",2013-11-06T13:41:43Z,423
"@@ -234,20 +234,18 @@ public void call() {
             Configuration cnf = cm.getCacheConfiguration(simpleCacheName);
             Assert.assertFalse(cnf.indexing().enabled());
 
-            Configuration conf = new ConfigurationBuilder().indexing().enable().indexLocalOnly(false)
+            Configuration conf = new ConfigurationBuilder().indexing().indexLocalOnly(false)
                   .addProperty(""default.directory_provider"", ""infinispan"").build();
 
             cm.defineConfiguration(simpleCacheName, conf);
 
             cnf = cm.getCacheConfiguration(simpleCacheName);
-            Assert.assertTrue(cnf.indexing().enabled());
+            Assert.assertFalse(cnf.indexing().enabled());
             Assert.assertFalse(cnf.indexing().indexLocalOnly());
             Assert.assertEquals(""infinispan"", cnf.indexing().properties().getProperty(""default.directory_provider""));
             Assert.assertFalse(cm.getCacheNames().contains(""LuceneIndexesMetadata""));
 
-            for (int i = 0; i < 10; i++) {
-               cm.getCache(simpleCacheName + 1).put(""key"" + i, new NonIndexedClass(""value"" + i));
-            }
+            cm.getCache(simpleCacheName).put(""key0"", new NonIndexedClass(""value0""));
 
             Assert.assertFalse(cm.getCacheNames().contains(""LuceneIndexesMetadata""));
          }",2013-11-06T13:41:43Z,424
"@@ -5,6 +5,7 @@
 import org.infinispan.configuration.global.GlobalConfiguration;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.annotations.Inject;
+import org.infinispan.factories.annotations.Start;
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
@@ -26,8 +27,14 @@ public CacheMarshaller(VersionAwareMarshaller marshaller) {
    @Inject
    public void inject(Cache cache, Configuration cfg, InvocationContextContainer icc,
             ExternalizerTable extTable, GlobalConfiguration globalCfg) {
-      ((VersionAwareMarshaller) this.marshaller).inject(
-            cache, cfg, null, icc, extTable, globalCfg);
+      ((VersionAwareMarshaller) this.marshaller)
+            .inject(cache, cfg, icc, extTable, globalCfg);
+   }
+
+   @Override
+   @Start(priority = 8) // Stop before RPCManager to avoid send/receive and marshaller not being ready
+   public void start() {
+      this.marshaller.start();
    }
 
    @Override",2012-10-17T11:35:07Z,16
"@@ -2,6 +2,7 @@
 
 import org.infinispan.configuration.global.GlobalConfiguration;
 import org.infinispan.factories.annotations.Inject;
+import org.infinispan.factories.annotations.Start;
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
@@ -23,10 +24,16 @@ public GlobalMarshaller(VersionAwareMarshaller marshaller) {
    }
 
    @Inject
-   public void inject(ClassLoader loader, ExternalizerTable extTable,
+   public void inject(ExternalizerTable extTable,
             GlobalConfiguration globalCfg) {
-      ((VersionAwareMarshaller) this.marshaller).inject(
-            null, null, loader, null, extTable, globalCfg);
+      ((VersionAwareMarshaller) this.marshaller)
+            .inject(null, null, null, extTable, globalCfg);
+   }
+
+   @Override
+   @Start(priority = 8) // Should start after the externalizer table and before transport
+   public void start() {
+      this.marshaller.start();
    }
 
    @Override",2012-10-17T11:35:07Z,17
"@@ -150,4 +150,6 @@ public interface StreamingMarshaller extends Marshaller {
     */
    void stop();
 
+   void start();
+
 }",2012-10-17T11:35:07Z,425
"@@ -63,19 +63,20 @@ public VersionAwareMarshaller() {
       defaultMarshaller = new JBossMarshaller();
    }
 
-   public void inject(Cache cache, Configuration cfg, ClassLoader loader,
-            InvocationContextContainer icc, ExternalizerTable extTable,
-            GlobalConfiguration globalCfg) {
-      ClassLoader myClassLoader;
+   public void inject(Cache cache, Configuration cfg, InvocationContextContainer icc,
+         ExternalizerTable extTable, GlobalConfiguration globalCfg) {
       if (cfg == null) {
-         myClassLoader = loader;
          this.cacheName = null;
       } else {
-         myClassLoader = cfg.classLoader();
          this.cacheName = cache.getName();
       }
 
-      this.defaultMarshaller.inject(extTable, myClassLoader, icc, globalCfg);
+      this.defaultMarshaller.inject(extTable, cfg, icc, globalCfg);
+   }
+
+   @Override
+   public void start() {
+      defaultMarshaller.start();
    }
 
    @Override",2012-10-17T11:35:07Z,18
"@@ -202,6 +202,11 @@ public boolean isMarshallable(Object o) throws Exception {
       }
    }
 
+   @Override
+   public void start() {
+      // No-op
+   }
+
    @Override
    public void stop() {
        // Clear class cache",2012-10-17T11:35:07Z,426
"@@ -24,6 +24,7 @@
 
 import java.io.IOException;
 
+import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.configuration.global.GlobalConfiguration;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
@@ -53,10 +54,24 @@ public class JBossMarshaller extends AbstractJBossMarshaller implements Streamin
 
    ExternalizerTable externalizerTable;
    ExternalizerTableProxy proxy;
+   GlobalConfiguration globalCfg;
+   Configuration cfg;
+   InvocationContextContainer icc;
 
-   public void inject(ExternalizerTable externalizerTable, ClassLoader cl, InvocationContextContainer icc, GlobalConfiguration globalCfg) {
+   public void inject(ExternalizerTable externalizerTable, Configuration cfg,
+         InvocationContextContainer icc, GlobalConfiguration globalCfg) {
       log.debug(""Using JBoss Marshalling"");
       this.externalizerTable = externalizerTable;
+      this.globalCfg = globalCfg;
+      this.cfg = cfg;
+      this.icc = icc;
+   }
+
+   @Override
+   public void start() {
+      super.start();
+
+      baseCfg.setObjectTable(externalizerTable);
 
       proxy = new ExternalizerTableProxy(externalizerTable);
       baseCfg.setObjectTable(proxy);
@@ -65,6 +80,7 @@ public void inject(ExternalizerTable externalizerTable, ClassLoader cl, Invocati
       if (classResolver == null) {
          // Override the class resolver with one that can detect injected
          // classloaders via AdvancedCache.with(ClassLoader) calls.
+         ClassLoader cl = cfg == null ? globalCfg.classLoader() : cfg.classLoader();
          classResolver = new EmbeddedContextClassResolver(cl, icc);
       }
 ",2012-10-17T11:35:07Z,19
"@@ -119,7 +119,13 @@ private void debug(String s) {
    }
 
    @Override
-   public void stop() {      
-      
+   public void stop() {
+      //No-op
    }
+
+   @Override
+   public void start() {
+      //No-op
+   }
+
 }",2012-10-17T11:35:07Z,427
"@@ -1,14 +1,12 @@
 package org.infinispan.query.impl;
 
+import java.util.Iterator;
 import java.util.Map;
 import java.util.Properties;
+import java.util.ServiceLoader;
 import java.util.TreeMap;
 
 import org.hibernate.search.Environment;
-import org.hibernate.search.annotations.Analyze;
-import org.hibernate.search.annotations.Norms;
-import org.hibernate.search.annotations.Store;
-import org.hibernate.search.bridge.FieldBridge;
 import org.hibernate.search.cfg.SearchMapping;
 import org.hibernate.search.cfg.spi.SearchConfiguration;
 import org.hibernate.search.jmx.StatisticsInfo;
@@ -43,11 +41,10 @@
 import org.infinispan.query.clustered.QueryBox;
 import org.infinispan.query.impl.massindex.MapReduceMassIndexer;
 import org.infinispan.query.logging.Log;
+import org.infinispan.query.spi.ProgrammaticSearchMappingProvider;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.util.logging.LogFactory;
 
-import org.infinispan.commons.util.Util;
-
 import javax.management.MBeanServer;
 import javax.management.ObjectName;
 
@@ -84,7 +81,7 @@ public void cacheManagerStarting(
    public void cacheStarting(ComponentRegistry cr, Configuration cfg, String cacheName) {
       if (cfg.indexing().enabled()) {
          log.registeringQueryInterceptor();
-         SearchFactoryIntegrator searchFactory = getSearchFactory(cfg.indexing().properties(), cr, cfg.classLoader());
+         SearchFactoryIntegrator searchFactory = getSearchFactory(cfg.indexing().properties(), cr);
          createQueryInterceptorIfNeeded(cr, cfg, searchFactory);
       }
    }
@@ -162,7 +159,7 @@ private void registerQueryMBeans(AdvancedCache cache,
          ComponentRegistry cr, String cacheName) {
       Configuration cfg = cache.getCacheConfiguration();
       SearchFactoryIntegrator sf = getSearchFactory(
-            cfg.indexing().properties(), cr, null);
+            cfg.indexing().properties(), cr);
 
       // Resolve MBean server instance
       GlobalConfiguration globalCfg =
@@ -210,7 +207,7 @@ private boolean verifyChainContainsQueryInterceptor(ComponentRegistry cr) {
       return interceptorChain.containsInterceptorType(QueryInterceptor.class, true);
    }
 
-   private SearchFactoryIntegrator getSearchFactory(Properties indexingProperties, ComponentRegistry cr, ClassLoader cl) {
+   private SearchFactoryIntegrator getSearchFactory(Properties indexingProperties, ComponentRegistry cr) {
       Object component = cr.getComponent(SearchFactoryIntegrator.class);
       SearchFactoryIntegrator searchFactory = null;
       if (component instanceof SearchFactoryIntegrator) { //could be the placeholder Object REMOVED_REGISTRY_COMPONENT
@@ -220,7 +217,7 @@ private SearchFactoryIntegrator getSearchFactory(Properties indexingProperties,
       if (searchFactory==null) {
          GlobalComponentRegistry globalComponentRegistry = cr.getGlobalComponentRegistry();
          EmbeddedCacheManager uninitializedCacheManager = globalComponentRegistry.getComponent(EmbeddedCacheManager.class);
-         indexingProperties = addMappingsForRemoteQuery(indexingProperties, cr, cl);
+         indexingProperties = addProgrammaticMappings(indexingProperties, cr);
          // Set up the search factory for Hibernate Search first.
          SearchConfiguration config = new SearchableCacheConfiguration(new Class[0], indexingProperties, uninitializedCacheManager, cr);
          searchFactory = new SearchFactoryBuilder().configuration(config).buildSearchFactory();
@@ -229,17 +226,9 @@ private SearchFactoryIntegrator getSearchFactory(Properties indexingProperties,
       return searchFactory;
    }
 
-   //todo [anistor] this method belongs to remote-query, but currently it is not possible to move it there because the SearchFactory programmatic mappings cannot be modified after instantiation
-   private Properties addMappingsForRemoteQuery(Properties indexingProperties, ComponentRegistry cr, ClassLoader cl) {
-      Class<?> fbClass;
-      try {
-         // proceed only if remote-query is in class path
-         fbClass = Util.loadClassStrict(""org.infinispan.query.remote.indexing.ProtobufValueWrapperFieldBridge"", cl);
-      } catch (ClassNotFoundException e) {
-         return indexingProperties;
-      }
-
-      try {
+   private Properties addProgrammaticMappings(Properties indexingProperties, ComponentRegistry cr) {
+      Iterator<ProgrammaticSearchMappingProvider> providers = ServiceLoader.load(ProgrammaticSearchMappingProvider.class).iterator();
+      if (providers.hasNext()) {
          SearchMapping mapping = (SearchMapping) indexingProperties.get(Environment.MODEL_MAPPING);
          if (mapping == null) {
             mapping = new SearchMapping();
@@ -249,11 +238,11 @@ private Properties addMappingsForRemoteQuery(Properties indexingProperties, Comp
             indexingProperties = amendedProperties;
          }
          Cache cache = cr.getComponent(Cache.class);
-         FieldBridge fb = (FieldBridge) fbClass.getConstructor(Cache.class).newInstance(cache);
-         mapping.entity(Util.loadClassStrict(""org.infinispan.query.remote.indexing.ProtobufValueWrapper"", cl))
-               .indexed().classBridgeInstance(fb).norms(Norms.NO).analyze(Analyze.YES).store(Store.YES);
-      } catch (Exception e) {
-         throw new CacheException(""Failed to configure indexing for remote query"", e);
+
+         while (providers.hasNext()) {
+            ProgrammaticSearchMappingProvider provider = providers.next();
+            provider.defineMappings(cache, mapping);
+         }
       }
       return indexingProperties;
    }",2013-10-15T14:23:52Z,353
"@@ -0,0 +1,13 @@
+package org.infinispan.query.spi;
+
+import org.hibernate.search.cfg.SearchMapping;
+import org.infinispan.Cache;
+
+/**
+ * @author anistor@redhat.com
+ * @since 6.0
+ */
+public interface ProgrammaticSearchMappingProvider {
+
+   void defineMappings(Cache cache, SearchMapping searchMapping);
+}",2013-10-15T14:23:52Z,428
"@@ -0,0 +1,27 @@
+package org.infinispan.query.remote;
+
+import org.hibernate.search.annotations.Analyze;
+import org.hibernate.search.annotations.Norms;
+import org.hibernate.search.annotations.Store;
+import org.hibernate.search.cfg.SearchMapping;
+import org.infinispan.Cache;
+import org.infinispan.query.remote.indexing.ProtobufValueWrapper;
+import org.infinispan.query.remote.indexing.ProtobufValueWrapperFieldBridge;
+import org.infinispan.query.spi.ProgrammaticSearchMappingProvider;
+
+/**
+ * @author anistor@redhat.com
+ * @since 6.0
+ */
+public class ProgrammaticSearchMappingProviderImpl implements ProgrammaticSearchMappingProvider {
+
+   @Override
+   public void defineMappings(Cache cache, SearchMapping searchMapping) {
+      searchMapping.entity(ProtobufValueWrapper.class)
+            .indexed()
+            .classBridgeInstance(new ProtobufValueWrapperFieldBridge(cache))
+            .norms(Norms.NO)
+            .analyze(Analyze.YES)
+            .store(Store.YES);
+   }
+}",2013-10-15T14:23:52Z,429
"@@ -0,0 +1 @@
+org.infinispan.query.remote.ProgrammaticSearchMappingProviderImpl",2013-10-15T14:23:52Z,430
"@@ -1,7 +1,5 @@
 package org.infinispan.jcache.annotation;
 
-import org.infinispan.jcache.annotation.solder.AnnotatedTypeBuilder;
-
 import javax.cache.annotation.CachePut;
 import javax.cache.annotation.CacheRemoveAll;
 import javax.cache.annotation.CacheRemoveEntry;
@@ -12,9 +10,10 @@
 import javax.enterprise.inject.spi.ProcessAnnotatedType;
 
 /**
- * CDI extension to allow injection of of cache values based on annotations
+ * CDI extension to register additional interceptor bindings
  *
  * @author Galder Zamarreño
+ * @author Pete Muir
  * @since 5.3
  */
 public class AnnotationInjectExtension implements Extension {
@@ -26,32 +25,4 @@ void registerInterceptorBindings(@Observes BeforeBeanDiscovery event) {
       event.addInterceptorBinding(CacheRemoveAll.class);
    }
 
-   void registerCacheResultInterceptor(@Observes ProcessAnnotatedType<CacheResultInterceptor> event) {
-      event.setAnnotatedType(new AnnotatedTypeBuilder<CacheResultInterceptor>()
-            .readFromType(event.getAnnotatedType())
-            .addToClass(CacheResultLiteral.INSTANCE)
-            .create());
-   }
-
-   void registerCachePutInterceptor(@Observes ProcessAnnotatedType<CachePutInterceptor> event) {
-      event.setAnnotatedType(new AnnotatedTypeBuilder<CachePutInterceptor>()
-            .readFromType(event.getAnnotatedType())
-            .addToClass(CachePutLiteral.INSTANCE)
-            .create());
-   }
-
-   void registerCacheRemoveEntryInterceptor(@Observes ProcessAnnotatedType<CacheRemoveEntryInterceptor> event) {
-      event.setAnnotatedType(new AnnotatedTypeBuilder<CacheRemoveEntryInterceptor>()
-            .readFromType(event.getAnnotatedType())
-            .addToClass(CacheRemoveEntryLiteral.INSTANCE)
-            .create());
-   }
-
-   void registerCacheRemoveAllInterceptor(@Observes ProcessAnnotatedType<CacheRemoveAllInterceptor> event) {
-      event.setAnnotatedType(new AnnotatedTypeBuilder<CacheRemoveAllInterceptor>()
-            .readFromType(event.getAnnotatedType())
-            .addToClass(CacheRemoveAllLiteral.INSTANCE)
-            .create());
-   }
-
 }",2013-07-22T15:02:36Z,431
"@@ -21,6 +21,7 @@
  * @author Kevin Pollet <kevin.pollet@serli.com> (C) 2011 SERLI
  */
 @Interceptor
+@CachePut
 public class CachePutInterceptor implements Serializable {
 
    private static final long serialVersionUID = 270924196162168618L;",2013-07-22T15:02:36Z,432
"@@ -26,6 +26,7 @@
  * @author Kevin Pollet <kevin.pollet@serli.com> (C) 2011 SERLI
  */
 @Interceptor
+@CacheRemoveAll
 public class CacheRemoveAllInterceptor implements Serializable {
 
    private static final long serialVersionUID = -8763819640664021763L;",2013-07-22T15:02:36Z,433
"@@ -29,6 +29,7 @@
  * @author Galder Zamarreño
  */
 @Interceptor
+@CacheRemoveEntry
 public class CacheRemoveEntryInterceptor implements Serializable {
 
    private static final long serialVersionUID = -9079291622309963969L;",2013-07-22T15:02:36Z,434
"@@ -36,6 +36,7 @@
  * @author Galder Zamarreño
  */
 @Interceptor
+@CacheResult
 public class CacheResultInterceptor implements Serializable {
 
    private static final long serialVersionUID = 5275055951121834315L;",2013-07-22T15:02:36Z,435
"@@ -689,7 +689,11 @@ private void internalStop() {
 
       List<PrioritizedMethod> stopMethods = new ArrayList<PrioritizedMethod>(componentLookup.size());
       for (Component c : componentLookup.values()) {
-         Collections.addAll(stopMethods, c.stopMethods);
+         // if one of the components threw an exception during startup
+         // the stop methods list may not have been initialized
+         if (c.stopMethods != null) {
+            Collections.addAll(stopMethods, c.stopMethods);
+         }
       }
 
       Collections.sort(stopMethods);",2011-12-19T08:34:27Z,23
"@@ -225,11 +225,7 @@ public void stop() {
          }
       }
 
-      // Grab the executor factory
-      NamedExecutorsFactory execFactory = getComponent(NamedExecutorsFactory.class);
       super.stop();
-      // Now that all components are stopped, shutdown their executors
-      execFactory.stop();
 
       if (state == ComponentStatus.TERMINATED && needToNotify) {
          for (ModuleLifecycle l : moduleLifecycles) {",2011-12-19T08:34:27Z,24
"@@ -26,6 +26,7 @@
 import org.infinispan.executors.ExecutorFactory;
 import org.infinispan.executors.ScheduledExecutorFactory;
 import org.infinispan.factories.annotations.DefaultFactoryFor;
+import org.infinispan.factories.annotations.Stop;
 import org.infinispan.util.Util;
 
 import java.util.Properties;
@@ -100,6 +101,7 @@ public <T> T construct(Class<T> componentType, String componentName) {
       }
    }
 
+   @Stop(priority = 999)
    public void stop() {
       if (notificationExecutor != null) notificationExecutor.shutdownNow();
       if (asyncTransportExecutor != null) asyncTransportExecutor.shutdownNow();",2011-12-19T08:34:27Z,436
"@@ -265,7 +265,7 @@ protected void initChannel() {
       // JGroups
       if (configuration.hasTopologyInfo()) {
          // We can do this only if the channel hasn't been started already
-         if (!startChannel) {
+         if (startChannel) {
             ((JChannel) channel).setAddressGenerator(new AddressGenerator() {
 
                @Override",2011-12-19T08:34:27Z,214
"@@ -168,6 +168,9 @@ public InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext
          }
       }
 
+      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
+      // Otherwise our get command might be processed by the old owners after they have invalidated their data
+      // and we'd return a null even though the key exists on
       return null;
    }
 ",2012-09-28T09:43:46Z,60
"@@ -37,6 +37,7 @@
 import org.infinispan.factories.scopes.Scopes;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.statetransfer.StateTransferLock;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.transaction.xa.CacheTransaction;
 import org.infinispan.util.logging.Log;
@@ -148,6 +149,7 @@ public static final class DistributionLogic implements ClusteringDependentLogic
       private DataContainer dataContainer;
       private Configuration configuration;
       private RpcManager rpcManager;
+      private StateTransferLock stateTransferLock;
       private final WriteSkewHelper.KeySpecificLogic keySpecificLogic = new WriteSkewHelper.KeySpecificLogic() {
          @Override
          public boolean performCheckOnKey(Object key) {
@@ -156,11 +158,13 @@ public boolean performCheckOnKey(Object key) {
       };
 
       @Inject
-      public void init(DistributionManager dm, DataContainer dataContainer, Configuration configuration, RpcManager rpcManager) {
+      public void init(DistributionManager dm, DataContainer dataContainer, Configuration configuration,
+                       RpcManager rpcManager, StateTransferLock stateTransferLock) {
          this.dm = dm;
          this.dataContainer = dataContainer;
          this.configuration = configuration;
          this.rpcManager = rpcManager;
+         this.stateTransferLock = stateTransferLock;
       }
 
       @Override
@@ -183,19 +187,26 @@ public boolean localNodeIsPrimaryOwner(Object key) {
 
       @Override
       public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipOwnershipCheck) {
-         boolean doCommit = true;
-         // ignore locality for removals, even if skipOwnershipCheck is not true
-         if (!skipOwnershipCheck && !entry.isRemoved() && !localNodeIsOwner(entry.getKey())) {
-            if (configuration.clustering().l1().enabled()) {
-               dm.transformForL1(entry);
-            } else {
-               doCommit = false;
+         // Don't allow the CH to change (and state transfer to invalidate entries)
+         // between the ownership check and the commit
+         stateTransferLock.acquireSharedTopologyLock();
+         try {
+            boolean doCommit = true;
+            // ignore locality for removals, even if skipOwnershipCheck is not true
+            if (!skipOwnershipCheck && !entry.isRemoved() && !localNodeIsOwner(entry.getKey())) {
+               if (configuration.clustering().l1().enabled()) {
+                  dm.transformForL1(entry);
+               } else {
+                  doCommit = false;
+               }
             }
+            if (doCommit)
+               entry.commit(dataContainer, newVersion);
+            else
+               entry.rollback();
+         } finally {
+            stateTransferLock.releaseSharedTopologyLock();
          }
-         if (doCommit)
-            entry.commit(dataContainer, newVersion);
-         else
-            entry.rollback();
       }
 
       @Override",2012-09-28T09:43:46Z,172
"@@ -177,9 +177,12 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
          rebalanceInProgress.set(true);
       }
       ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
+      // Ensures writes to the data container use the right consistent hash
+      // No need for a try/finally block, since it's just an assignment
+      stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
-
-      stateTransferLock.setTopologyId(cacheTopology.getTopologyId());
+      stateTransferLock.releaseExclusiveTopologyLock();
+      stateTransferLock.topologyInstalled(cacheTopology.getTopologyId());
 
       try {
          Set<Integer> addedSegments;
@@ -224,14 +227,11 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
          }
 
          if (addedSegments != null && !addedSegments.isEmpty()) {
-            stateTransferLock.commandsExclusiveLock();
-            try {
-               addTransfers(addedSegments);  // add transfers for new or restarted segments
-            } finally {
-               stateTransferLock.commandsExclusiveUnlock();
-            }
+            addTransfers(addedSegments);  // add transfers for new or restarted segments
          }
       } finally {
+         stateTransferLock.transactionDataReceived(cacheTopology.getTopologyId());
+
          if (activeTopologyUpdates.decrementAndGet() == 0 && !isStateTransferInProgress()) {
             notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
          }",2012-09-28T09:43:46Z,54
"@@ -70,7 +70,7 @@ public interface StateProvider {
     * @param topologyId
     * @param segments
     */
-   void startOutboundTransfer(Address destination, int topologyId, Set<Integer> segments);
+   void startOutboundTransfer(Address destination, int topologyId, Set<Integer> segments) throws InterruptedException;
 
    /**
     * Cancel sending of cache entries that belong to the given set of segments. This is invoked in response to a",2012-09-28T09:43:46Z,55
"@@ -76,7 +76,7 @@ public class StateProviderImpl implements StateProvider {
    private long timeout;
    private int chunkSize;
 
-   private volatile int topolopyId;
+   private volatile int topologyId;
    private volatile ConsistentHash readCh;
 
    /**
@@ -134,7 +134,7 @@ public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
 
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
       this.readCh = cacheTopology.getReadConsistentHash();
-      this.topolopyId = cacheTopology.getTopologyId();
+      this.topologyId = cacheTopology.getTopologyId();
 
       // cancel outbound state transfers for destinations that are no longer members in new topology
       Set<Address> members = new HashSet<Address>(cacheTopology.getWriteConsistentHash().getMembers());
@@ -182,19 +182,23 @@ public void stop() {
       }
    }
 
-   public List<TransactionInfo> getTransactionsForSegments(Address destination, int topologyId, Set<Integer> segments) throws InterruptedException {
+   public List<TransactionInfo> getTransactionsForSegments(Address destination, int requestTopologyId, Set<Integer> segments) throws InterruptedException {
       if (trace) {
-         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, topologyId);
+         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, requestTopologyId);
       }
 
       if (readCh == null) {
          throw new IllegalStateException(""No cache topology received yet"");  // no commands are processed until the join is complete, so this cannot normally happen
       }
 
-      //todo [anistor] here we should block until topologyId is installed so we are sure forwarding happens correctly
-      if (topologyId != this.topolopyId) {
-         log.warnf(""Transactions were requested by a node with topology (%d) that does not match local topology (%d)."", topologyId, this.topolopyId);
-         stateTransferLock.waitForTopology(topologyId);
+      if (requestTopologyId < topologyId) {
+         log.warnf(""Transactions were requested by node %s with topology %d, smaller than the local "" +
+               ""topology (%d)"", destination, requestTopologyId, topologyId);
+      } else if (requestTopologyId > topologyId) {
+         log.tracef(""Transactions were requested by node %s with topology %d, greater than the local "" +
+               ""topology (%d). Waiting for topology %d to be installed locally."", destination,
+               requestTopologyId, topologyId, requestTopologyId);
+         stateTransferLock.waitForTopology(requestTopologyId);
       }
       Set<Integer> ownedSegments = readCh.getSegmentsForOwner(rpcManager.getAddress());
       if (!ownedSegments.containsAll(segments)) {
@@ -205,17 +209,10 @@ public List<TransactionInfo> getTransactionsForSegments(Address destination, int
       List<TransactionInfo> transactions = new ArrayList<TransactionInfo>();
       //we migrate locks only if the cache is transactional and distributed
       if (configuration.transaction().transactionMode().isTransactional()) {
-         // all transactions should be briefly blocked now
-         stateTransferLock.transactionsExclusiveLock();
-         try {
-            collectTransactionsToTransfer(transactions, transactionTable.getRemoteTransactions(), segments);
-            collectTransactionsToTransfer(transactions, transactionTable.getLocalTransactions(), segments);
-            if (trace) {
-               log.tracef(""Found %d transaction(s) to transfer"", transactions.size());
-            }
-         } finally {
-            // all transactions should be unblocked now
-            stateTransferLock.transactionsExclusiveUnlock();
+         collectTransactionsToTransfer(transactions, transactionTable.getRemoteTransactions(), segments);
+         collectTransactionsToTransfer(transactions, transactionTable.getLocalTransactions(), segments);
+         if (trace) {
+            log.tracef(""Found %d transaction(s) to transfer"", transactions.size());
          }
       }
       return transactions;
@@ -249,15 +246,23 @@ private void collectTransactionsToTransfer(List<TransactionInfo> transactionsToT
    }
 
    @Override
-   public void startOutboundTransfer(Address destination, int topologyId, Set<Integer> segments) {
-      if (trace) {
-         log.tracef(""Starting outbound transfer of segments %s to node %s with topology id %d"", segments, destination, topologyId);
-      }
-      if (topologyId != this.topolopyId) {
-         log.warnf(""Segments were requested by a node with topology (%d) that does not match local topology (%d)."", topologyId, this.topolopyId);
+   public void startOutboundTransfer(Address destination, int requestTopologyId, Set<Integer> segments)
+         throws InterruptedException {
+      log.tracef(""Starting outbound transfer of segments %s to node %s with topology id %d"", segments,
+            destination, requestTopologyId);
+
+      if (requestTopologyId < topologyId) {
+         log.warnf(""Segments were requested by node %s with topology %d, smaller than the local "" +
+               ""topology (%d)"", destination, requestTopologyId, topologyId);
+      } else if (requestTopologyId > topologyId) {
+         log.tracef(""Segments were requested by node %s with topology %d, greater than the local "" +
+               ""topology (%d). Waiting for topology %d to be installed locally."", destination,
+               requestTopologyId, topologyId, requestTopologyId);
+         stateTransferLock.waitForTopology(requestTopologyId);
       }
+
       // the destination node must already have an InboundTransferTask waiting for these segments
-      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId,
+      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, requestTopologyId,
             readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);",2012-09-28T09:43:46Z,55
"@@ -28,8 +28,6 @@
 import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
-import org.infinispan.commands.read.GetKeyValueCommand;
-import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.tx.*;
 import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.Configuration;
@@ -198,132 +196,77 @@ public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) thr
     * @return
     * @throws Throwable
     */
-   private Object handleTxCommand(InvocationContext ctx, TransactionBoundaryCommand command) throws Throwable {
-      return handleTopologyAffectedCommand(ctx, command);
+   private Object handleTxCommand(TxInvocationContext ctx, TransactionBoundaryCommand command)
+         throws Throwable {
+      return handleTopologyAffectedCommand(ctx, command, ctx.getCacheTransaction() instanceof RemoteTransaction);
    }
 
    private Object handleWriteCommand(InvocationContext ctx, WriteCommand command) throws Throwable {
-      return handleTopologyAffectedCommand(ctx, command);
+      return handleTopologyAffectedCommand(ctx, command, ctx.isOriginLocal());
    }
 
    @Override
    protected Object handleDefault(InvocationContext ctx, VisitableCommand command) throws Throwable {
       if (command instanceof TopologyAffectedCommand) {
-         return handleTopologyAffectedCommand(ctx, (TopologyAffectedCommand) command);
+         return handleTopologyAffectedCommand(ctx, (TopologyAffectedCommand) command, ctx.isOriginLocal());
       } else {
          return invokeNextInterceptor(ctx, command);
       }
    }
 
-   private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffectedCommand command) throws Throwable {
-      final boolean isTxCommand = command instanceof TransactionBoundaryCommand;
+   private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffectedCommand command,
+                                                boolean originLocal) throws Throwable {
       boolean cacheModeLocal = false;
       if (command instanceof FlagAffectedCommand) {
          cacheModeLocal = ((FlagAffectedCommand)command).hasFlag(Flag.CACHE_MODE_LOCAL);
       }
-      if (cacheModeLocal) {
-         try {
-            if (isTxCommand) {
-               stateTransferLock.transactionsSharedLock();
-            }
-            return invokeNextInterceptor(ctx, command);
-         } finally {
-            if (isTxCommand) {
-               stateTransferLock.transactionsSharedUnlock();
-            }
-         }
+      if (originLocal || cacheModeLocal) {
+         return invokeNextInterceptor(ctx, command);
       }
 
-      stateTransferLock.commandsSharedLock();
-      final CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
-      final int topologyId = cacheTopology.getTopologyId();
-      final ConsistentHash readCh = cacheTopology.getReadConsistentHash();
-      final ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
-      Set<Address> newTargets = null;
-
-      // set the topology id if it was not set before (ie. this is not a remote or forwarded command)
+      // set the topology id if it was not set before (ie. this is local command)
+      // TODO Make tx commands extend FlagAffectedCommand so we can use CACHE_MODE_LOCAL in StaleTransactionCleanupService
       if (command.getTopologyId() == -1) {
-         command.setTopologyId(cacheTopology.getTopologyId());
+         command.setTopologyId(stateTransferManager.getCacheTopology().getTopologyId());
       }
-      try {
-         if (isTxCommand) {
-            stateTransferLock.transactionsSharedLock();
-         }
-         try {
-            // forward commands with older topology ids to their new targets
-            if (command.getTopologyId() < topologyId) {
-               // if it is a read request and comes from an older topology we need to check if we still hold the data
-               Object readKey = null;
-               if (command instanceof GetKeyValueCommand) {   //todo [anistor] would be nice to have a common ReadCommand interface for these
-                  readKey = ((GetKeyValueCommand) command).getKey();
-               } else if (command instanceof ClusteredGetCommand) {
-                  readKey = ((ClusteredGetCommand) command).getKey();
-               }
-               if (readKey != null) {
-                  // it's a read operation
-                  if (!readCh.isKeyLocalToNode(rpcManager.getAddress(), readKey)) {
-                     return null; //todo [anistor] throw an exception or return a special result that will cause the read command to be retried on the originator
-                  }
-               } else if (command instanceof PrepareCommand || command instanceof LockControlCommand || command instanceof WriteCommand) {  //todo a ClearCommand should be executed directly
-                  // a TX or a write command from an old topology should be forwarded unless it's a write and the context is transactional
-                  if (command instanceof WriteCommand && ctx instanceof TxInvocationContext) {
-                     // a transactional write is always local
-                     return invokeNextInterceptor(ctx, command);
-                  } else {
-                     Set<Object> affectedKeys = getAffectedKeys(ctx, command);
-                     newTargets = new HashSet<Address>();
-                     boolean localExecutionNeeded = false;
-                     for (Object key : affectedKeys) {
-                        if (writeCh.isKeyLocalToNode(rpcManager.getAddress(), key)) {
-                           localExecutionNeeded = true;
-                        } else {
-                           newTargets.addAll(writeCh.locateOwners(key));
-                        }
-                     }
-
-                     if (localExecutionNeeded) {
-                        return invokeNextInterceptor(ctx, command);
-                     }
-                  }
-               } else if (command instanceof CommitCommand || command instanceof RollbackCommand) {
-                  // for these commands we can determine affected keys only after they are executed
-                  try {
-                     // it does not harm to attempt to execute them if it might not be the proper destination
-                     return invokeNextInterceptor(ctx, command);
-                  } finally {
-                     newTargets = new HashSet<Address>();
-                     Set<Object> affectedKeys = ((TxInvocationContext) ctx).getAffectedKeys();
-                     for (Object key : affectedKeys) {
-                        if (!writeCh.isKeyLocalToNode(rpcManager.getAddress(), key)) {
-                           newTargets.addAll(writeCh.locateOwners(key));
-                        }
-                     }
-                  }
-               }
-            } else if (command.getTopologyId() > topologyId) {
-               // this means there will be a new topology installed soon
-               stateTransferLock.waitForTopology(command.getTopologyId());
-
-               // proceed normally
-            } else {
-               // proceed normally
-            }
 
-            // no special handling was needed, invoke normally (and do not forward)
-            return invokeNextInterceptor(ctx, command);
-         } finally {
-            if (isTxCommand) {
-               stateTransferLock.transactionsSharedUnlock();
+      // remote/forwarded command
+      int cmdTopologyId = command.getTopologyId();
+      stateTransferLock.waitForTransactionData(cmdTopologyId);
+
+      // TODO we may need to skip local invocation for read/write/tx commands if the command is too old and none of its keys are local
+      Object localResult = invokeNextInterceptor(ctx, command);
+
+      // forward commands with older topology ids to their new targets
+      // but we need to make sure we have the latest topology
+      CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
+      int localTopologyId = cacheTopology.getTopologyId();
+      // if it's a tx/lock/write command, forward it to the new owners
+      if (cmdTopologyId < localTopologyId) {
+         if (command instanceof TransactionBoundaryCommand || command instanceof LockControlCommand
+               || (command instanceof WriteCommand && !ctx.isInTxScope())) {
+            // We don't know the full topology history to send the command only to the new owners,
+            // but we do know two things:
+            // 1. The originator - which shouldn't receive the same command again
+            // 2. If the local topology = command topology + 1 and pendingCH = null, there are no new owners
+            ConsistentHash pendingCh = cacheTopology.getPendingCH();
+            if (pendingCh != null && cmdTopologyId < localTopologyId + 1) {
+               ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
+               Set<Object> affectedKeys = getAffectedKeys(ctx, command);
+               Set<Address> newTargets = writeCh.locateAllOwners(affectedKeys);
+               newTargets.remove(rpcManager.getAddress());
+               if (!newTargets.isEmpty()) {
+                  // Update the topology id to prevent cycles
+                  command.setTopologyId(localTopologyId);
+                  log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
+                  // TODO find a way to forward the command async if it was received async
+                  rpcManager.invokeRemotely(newTargets, command, true, false);
+               }
             }
          }
-      } finally {
-         stateTransferLock.commandsSharedUnlock();
-
-         if (newTargets != null && !newTargets.isEmpty()) {
-            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
-            rpcManager.invokeRemotely(newTargets, command, true);
-         }
       }
+
+      return localResult;
    }
 
    @SuppressWarnings(""unchecked"")",2012-09-28T09:43:46Z,115
"@@ -27,33 +27,44 @@
 import org.infinispan.factories.scopes.Scopes;
 
 /**
- * // TODO: Document this
+ * We use the state transfer lock for three different things:
+ * <ol>
+ *    <li>We don't want to execute a command until we have the transaction table for that topology id.
+ *    For this purpose it works like a latch, commands wait on the latch and state transfer opens the latch
+ *    when it has received all the transaction data for that topology id.</li>
+ *    <li>Do not write anything to the data container in a segment that we have already removed.
+ *    For this purpose, ownership checks and data container writes acquire a shared lock, and
+ *    the segment removal acquires an exclusive lock.</li>
+ *    <li>We want to handle state requests only after we have installed the same topology id, because
+ *    this guarantees that we also have installed the corresponding view id and we have all the joiners
+ *    in our JGroups view. Here it works like a latch as well, state requests wait on the latch and state
+ *    transfer opens the latch when it has received all the transaction data for that topology id.</li>
+ * </ol>
  *
  * @author anistor@redhat.com
+ * @author Dan Berindei
  * @since 5.2
  */
 @Scope(Scopes.NAMED_CACHE)
 public interface StateTransferLock {
 
-   void transactionsSharedLock();
+   // topology change lock
+   void acquireExclusiveTopologyLock();
 
-   void transactionsSharedUnlock();
+   void releaseExclusiveTopologyLock();
 
-   void transactionsExclusiveLock();
+   void acquireSharedTopologyLock();
 
-   void transactionsExclusiveUnlock();
+   void releaseSharedTopologyLock();
 
-   void commandsExclusiveLock();
+   // transaction data latch
+   void transactionDataReceived(int topologyId);
 
-   void commandsExclusiveUnlock();
+   void waitForTransactionData(int expectedTopologyId) throws InterruptedException;
 
-   void commandsSharedLock();
-
-   void commandsSharedUnlock();
-
-   int getTopologyId();
-
-   void setTopologyId(int topologyId);
+   // topology installation latch
+   // TODO move this to Cluster/LocalTopologyManagerImpl and don't start requesting state until every node has the jgroups view with the local node
+   void topologyInstalled(int topologyId);
 
    void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-09-28T09:43:46Z,122
"@@ -30,69 +30,69 @@
 import org.infinispan.util.logging.LogFactory;
 
 /**
- * // TODO: Document this
+ * {@code StateTransferLock} implementation.
  *
  * @author anistor@redhat.com
+ * @author Dan Berindei
  * @since 5.2
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
 
-   private final ReadWriteLock transactionTableLock = new ReentrantReadWriteLock();
-
-   private final ReadWriteLock commandLock = new ReentrantReadWriteLock();
+   private final ReadWriteLock ownershipLock = new ReentrantReadWriteLock();
 
    private volatile int topologyId;
-
    private final Object topologyLock = new Object();
 
-   @Override
-   public void transactionsSharedLock() {
-      transactionTableLock.readLock().lock();
-   }
-
-   @Override
-   public void transactionsSharedUnlock() {
-      transactionTableLock.readLock().unlock();
-   }
+   private volatile int transactionDataTopologyId;
+   private final Object transactionDataLock = new Object();
 
    @Override
-   public void transactionsExclusiveLock() {
-      transactionTableLock.writeLock().lock();
+   public void acquireExclusiveTopologyLock() {
+      ownershipLock.writeLock().lock();
    }
 
    @Override
-   public void transactionsExclusiveUnlock() {
-      transactionTableLock.writeLock().unlock();
+   public void releaseExclusiveTopologyLock() {
+      ownershipLock.writeLock().unlock();
    }
 
    @Override
-   public void commandsExclusiveLock() {
-      commandLock.writeLock().lock();
+   public void acquireSharedTopologyLock() {
+      ownershipLock.readLock().lock();
    }
 
    @Override
-   public void commandsExclusiveUnlock() {
-      commandLock.writeLock().unlock();
+   public void releaseSharedTopologyLock() {
+      ownershipLock.readLock().unlock();
    }
 
    @Override
-   public void commandsSharedLock() {
-      commandLock.readLock().lock();
+   public void transactionDataReceived(int topologyId) {
+      this.transactionDataTopologyId = topologyId;
+      synchronized (transactionDataLock) {
+         transactionDataLock.notifyAll();
+      }
    }
 
    @Override
-   public void commandsSharedUnlock() {
-      commandLock.readLock().unlock();
-   }
+   public void waitForTransactionData(int expectedTopologyId) throws InterruptedException {
+      if (transactionDataTopologyId >= expectedTopologyId)
+         return;
 
-   @Override
-   public int getTopologyId() {
-      return topologyId;
+      log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
+            transactionDataTopologyId);
+      synchronized (transactionDataLock) {
+         // Do the comparison inside the synchronized lock
+         // otherwise the setter might be able to call notifyAll before we wait()
+         while (transactionDataTopologyId < expectedTopologyId) {
+            transactionDataLock.wait();
+         }
+      }
    }
 
    @Override
-   public void setTopologyId(int topologyId) {
+   public void topologyInstalled(int topologyId) {
       this.topologyId = topologyId;
       synchronized (topologyLock) {
          topologyLock.notifyAll();
@@ -104,7 +104,8 @@ public void waitForTopology(int expectedTopologyId) throws InterruptedException
       if (topologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId, topologyId);
+      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId,
+            topologyId);
       synchronized (topologyLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()",2012-09-28T09:43:46Z,123
"@@ -82,8 +82,9 @@ public void testSequence1() throws ExecutionException, InterruptedException {
 
    }
 
-   // ****** This will probably always be an unsupported sequence of startup, in a single thread
-//   public void testSequence2() throws ExecutionException, InterruptedException {
+   @Test(timeOut = 60000)
+   public void testSequence2() throws ExecutionException, InterruptedException {
+      TestCacheManagerFactory.backgroundTestStarted(this);
       /*
 
       Sequence 2:
@@ -97,8 +98,8 @@ public void testSequence1() throws ExecutionException, InterruptedException {
 
        */
 
-//      doTest(false, false);
-//   }
+      doTest(false, false);
+   }
 
    @Test(timeOut = 60000)
    public void testSequence3() throws ExecutionException, InterruptedException {",2012-09-28T09:43:46Z,437
"@@ -48,13 +48,12 @@
 @CleanupAfterMethod
 public class StaleLocksWithCommitDuringStateTransferTest extends MultipleCacheManagersTest {
 
-   public static final int BLOCKING_CACHE_VIEW_ID = 1000;
    Cache<MagicKey, String> c1, c2;
 
    @Override
    protected void createCacheManagers() throws Throwable {
       Configuration cfg = TestCacheManagerFactory.getDefaultConfiguration(true, Configuration.CacheMode.DIST_SYNC);
-      cfg.setLockAcquisitionTimeout(100);
+      cfg.setSyncReplTimeout(100);
       cfg.setCacheStopTimeout(100);
       EmbeddedCacheManager cm1 = TestCacheManagerFactory.createClusteredCacheManager(cfg);
       EmbeddedCacheManager cm2 = TestCacheManagerFactory.createClusteredCacheManager(cfg);
@@ -107,15 +106,19 @@ public void run() {
                // Before calling commit we block transactions on one of the nodes to simulate a state transfer
                final StateTransferLock blockFirst = TestingUtil.extractComponent(failOnOriginator ? c1 : c2, StateTransferLock.class);
                final StateTransferLock blockSecond = TestingUtil.extractComponent(failOnOriginator ? c2 : c1, StateTransferLock.class);
-               blockFirst.transactionsExclusiveLock();
 
-               commitLatch.countDown();
+               try {
+                  blockFirst.acquireExclusiveTopologyLock();
+                  blockSecond.acquireExclusiveTopologyLock();
 
-               // should be much larger than the lock acquisition timeout
-               Thread.sleep(1000);
-               blockSecond.transactionsExclusiveLock();
-               blockFirst.transactionsExclusiveUnlock();
-               blockSecond.transactionsExclusiveUnlock();
+                  commitLatch.countDown();
+
+                  // should be much larger than the lock acquisition timeout
+                  Thread.sleep(1000);
+               } finally {
+                  blockSecond.releaseExclusiveTopologyLock();
+                  blockFirst.releaseExclusiveTopologyLock();
+               }
             } catch (Throwable t) {
                log.errorf(t, ""Error blocking/unblocking transactions"");
             }",2012-09-28T09:43:46Z,232
"@@ -181,9 +181,7 @@ public Iterator<InternalCacheEntry> answer(InvocationOnMock invocation) {
          // expected
       }
 
-      InOrder stateTransferLockVerifier = inOrder(stateTransferLock);
-      stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveLock();
-      stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveUnlock();
+      verifyNoMoreInteractions(stateTransferLock);
 
       stateProvider.startOutboundTransfer(new TestAddress(5), 1, Collections.singleton(0));
 
@@ -284,9 +282,7 @@ public Iterator<InternalCacheEntry> answer(InvocationOnMock invocation) {
          // expected
       }
 
-      InOrder stateTransferLockVerifier = inOrder(stateTransferLock);
-      stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveLock();
-      stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveUnlock();
+      verifyNoMoreInteractions(stateTransferLock);
 
       stateProvider.startOutboundTransfer(new TestAddress(5), 1, Collections.singleton(0));
 ",2012-09-28T09:43:46Z,57
"@@ -1054,7 +1054,7 @@ public AdvancedCache<K, V> with(ClassLoader classLoader) {
 
    @Override
    protected void set(K key, V value) {
-      withFlags(Flag.SKIP_REMOTE_LOOKUP, Flag.SKIP_CACHE_LOAD)
+      withFlags(Flag.IGNORE_RETURN_VALUES)
             .put(key, value, defaultLifespan, MILLISECONDS, defaultMaxIdleTime, MILLISECONDS);
    }
 }",2012-08-29T09:49:04Z,438
"@@ -99,6 +99,16 @@ public interface BasicCache<K, V> extends ConcurrentMap<K, V>, Lifecycle {
     */
    String getVersion();
 
+   /**
+    * {@inheritDoc}
+    *
+    * If the return value of this operation will be ignored by the application,
+    * the user is strongly encouraged to use the {@link org.infinispan.context.Flag#IGNORE_RETURN_VALUES}
+    * flag when invoking this method in order to make it behave as efficiently
+    * as possible (i.e. avoiding needless remote or network calls).
+    */
+   V put(K key, V value);
+
    /**
     * An overloaded form of {@link #put(Object, Object)}, which takes in lifespan parameters.
     *
@@ -347,6 +357,16 @@ public interface BasicCache<K, V> extends ConcurrentMap<K, V>, Lifecycle {
     */
    NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
+   /**
+    * {@inheritDoc}
+    *
+    * If the return value of this operation will be ignored by the application,
+    * the user is strongly encouraged to use the {@link org.infinispan.context.Flag#IGNORE_RETURN_VALUES}
+    * flag when invoking this method in order to make it behave as efficiently
+    * as possible (i.e. avoiding needless remote or network calls).
+    */
+   V remove(Object key);
+
    /**
     * Asynchronous version of {@link #remove(Object)}.  This method does not block on remote calls, even if your cache
     * mode is synchronous.  Has no benefit over {@link #remove(Object)} if used in LOCAL mode.",2012-08-29T09:49:04Z,439
"@@ -181,6 +181,6 @@ public static <MK, K, V> Map<K, V> getReadOnlyAtomicMap(Cache<MK, ?> cache, MK k
     * @param <MK>  key param of the cache
     */
    public static <MK> void removeAtomicMap(Cache<MK, ?> cache, MK key) {
-      cache.getAdvancedCache().withFlags(Flag.SKIP_REMOTE_LOOKUP, Flag.SKIP_CACHE_LOAD).remove(key);
+      cache.getAdvancedCache().withFlags(Flag.IGNORE_RETURN_VALUES).remove(key);
    }
 }",2012-08-29T09:49:04Z,440
"@@ -50,6 +50,7 @@ public Set<Object> getAffectedKeys() {
 
    @Override
    public boolean isReturnValueExpected() {
-      return flags == null || !flags.contains(Flag.SKIP_REMOTE_LOOKUP);
+      return flags == null || (!flags.contains(Flag.SKIP_REMOTE_LOOKUP)
+                                  && !flags.contains(Flag.IGNORE_RETURN_VALUES));
    }
 }",2012-08-29T09:49:04Z,441
"@@ -192,7 +192,20 @@ public enum Flag {
     * make decisions such as whether the cache store needs checking to see if
     * the previous value needs to be loaded and merged.
     */
-   DELTA_WRITE;
+   DELTA_WRITE,
+
+   /**
+    * Signals that an operation's return value will be ignored. Typical
+    * operations whose return value might be ignored include
+    * {@link java.util.Map#put(Object, Object)} whose return value indicates
+    * previous value. So, a user might decide to the put something in the
+    * cache but might not be interested in the return value.
+    *
+    * Not requiring return values makes the cache behave more efficiently by
+    * applying flags such as {@link Flag#SKIP_REMOTE_LOOKUP} or
+    * {@link Flag#SKIP_CACHE_LOAD}.
+    */
+   IGNORE_RETURN_VALUES;
 
    /**
     * Creates a copy of a Flag Set removing instances of FAIL_SILENTLY.",2012-08-29T09:49:04Z,442
"@@ -134,7 +134,8 @@ protected boolean forceLoad(Object key, Set<Flag> flags) {
    }
 
    private boolean loadIfNeeded(InvocationContext ctx, Object key, boolean isRetrieval, FlagAffectedCommand cmd) throws Throwable {
-      if (cmd.hasFlag(Flag.SKIP_CACHE_STORE) || cmd.hasFlag(Flag.SKIP_CACHE_LOAD)) {
+      if (cmd.hasFlag(Flag.SKIP_CACHE_STORE) || cmd.hasFlag(Flag.SKIP_CACHE_LOAD)
+            || cmd.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
          return false; //skip operation
       }
 ",2012-08-29T09:49:04Z,28
"@@ -163,6 +163,7 @@ private boolean needsRemoteGet(InvocationContext ctx, Object key, boolean retval
       return retvalCheck
             && !ctx.hasFlag(Flag.CACHE_MODE_LOCAL)
             && !ctx.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !ctx.hasFlag(Flag.IGNORE_RETURN_VALUES)
             && ((entry = ctx.lookupEntry(key)) == null || entry.isNull() || entry.isLockPlaceholder());
    }
 
@@ -448,7 +449,8 @@ private void remoteGetBeforeWrite(InvocationContext ctx, boolean isConditionalCo
    }
 
    private boolean isNeedReliableReturnValues(InvocationContext ctx) {
-      return !ctx.hasFlag(Flag.SKIP_REMOTE_LOOKUP) && needReliableReturnValues;
+      return !ctx.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !ctx.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
    }
 
    /**",2012-08-29T09:49:04Z,101
"@@ -157,6 +157,7 @@ private boolean getMightGoRemote(InvocationContext ctx, Object key) {
       return ctx.isOriginLocal()
             && cacheConfiguration.clustering().cacheMode().isDistributed()
             && !ctx.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !ctx.hasFlag(Flag.IGNORE_RETURN_VALUES)
             && !distManager.getLocality(key).isLocal();
    }
 ",2012-08-29T09:49:04Z,443
"@@ -23,7 +23,6 @@
 
 package org.infinispan.interceptors.locking;
 
-import org.infinispan.CacheException;
 import org.infinispan.InvalidCacheUsageException;
 import org.infinispan.commands.AbstractVisitor;
 import org.infinispan.commands.control.LockControlCommand;
@@ -42,6 +41,7 @@
 import org.infinispan.container.EntryFactory;
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.RepeatableReadEntry;
+import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
@@ -94,7 +94,8 @@ public void setDependencies(EntryFactory entryFactory) {
    public void start() {
       if (cacheConfiguration.clustering().cacheMode() == CacheMode.LOCAL &&
             cacheConfiguration.locking().writeSkewCheck() &&
-            cacheConfiguration.locking().isolationLevel() == IsolationLevel.REPEATABLE_READ) {
+            cacheConfiguration.locking().isolationLevel() == IsolationLevel.REPEATABLE_READ &&
+            !cacheConfiguration.unsafe().unreliableReturnValues()) {
          lockAcquisitionVisitor = new LocalWriteSkewCheckingLockAcquisitionVisitor();
          needToMarkReads = true;
       } else {
@@ -104,7 +105,7 @@ public void start() {
    }
 
    private void markKeyAsRead(InvocationContext ctx, Object key) {
-      if (needToMarkReads && ctx.isInTxScope()) {
+      if (needToMarkReads && !ctx.hasFlag(Flag.IGNORE_RETURN_VALUES) && ctx.isInTxScope()) {
          TxInvocationContext tctx = (TxInvocationContext) ctx;
          tctx.getCacheTransaction().addReadKey(key);
       }",2012-08-29T09:49:04Z,444
"@@ -28,7 +28,7 @@
 import static org.infinispan.context.Flag.SKIP_CACHE_STORE;
 import static org.infinispan.context.Flag.SKIP_INDEXING;
 import static org.infinispan.context.Flag.SKIP_OWNERSHIP_CHECK;
-import static org.infinispan.context.Flag.SKIP_REMOTE_LOOKUP;
+import static org.infinispan.context.Flag.IGNORE_RETURN_VALUES;
 import static org.infinispan.factories.KnownComponentNames.CACHE_MARSHALLER;
 
 import java.util.Collections;
@@ -192,11 +192,11 @@ public void preload() {
             for (InternalCacheEntry e : state) {
                if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
                   cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, SKIP_CACHE_STORE, SKIP_REMOTE_LOOKUP, SKIP_INDEXING)
+                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, SKIP_CACHE_STORE, IGNORE_RETURN_VALUES, SKIP_INDEXING)
                        .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
                } else {
                   cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, SKIP_REMOTE_LOOKUP, SKIP_INDEXING)
+                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES, SKIP_INDEXING)
                        .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
                }
             }",2012-08-29T09:49:04Z,29
"@@ -245,7 +245,7 @@ public void applyState(Collection<InternalCacheEntry> state,
          for (InternalCacheEntry e : state) {
             InvocationContext ctx = icc.createInvocationContext(false, 1);
             // locking not necessary as during rehashing we block all transactions
-            ctx.setFlags(CACHE_MODE_LOCAL, SKIP_CACHE_LOAD, SKIP_REMOTE_LOOKUP, SKIP_SHARED_CACHE_STORE, SKIP_LOCKING,
+            ctx.setFlags(CACHE_MODE_LOCAL, IGNORE_RETURN_VALUES, SKIP_SHARED_CACHE_STORE, SKIP_LOCKING,
                          SKIP_OWNERSHIP_CHECK);
             try {
                PutKeyValueCommand put = commandBuilder.buildPut(ctx, e);",2012-08-29T09:49:04Z,227
"@@ -50,7 +50,8 @@ final class FileListOperations {
 
    FileListOperations(AdvancedCache<?, ?> cache, String indexName){
       this.cache = (AdvancedCache<FileListCacheKey, Object>) cache.withFlags(Flag.SKIP_INDEXING);
-      this.cacheNoRetrieve = (AdvancedCache<FileListCacheKey, Set<String>>) cache.withFlags(Flag.SKIP_REMOTE_LOOKUP, Flag.SKIP_CACHE_LOAD, Flag.SKIP_INDEXING);
+      this.cacheNoRetrieve = (AdvancedCache<FileListCacheKey, Set<String>>)
+            cache.withFlags(Flag.IGNORE_RETURN_VALUES, Flag.SKIP_INDEXING);
       this.indexName = indexName;
       this.fileListCacheKey = new FileListCacheKey(indexName);
    }",2012-08-29T09:49:04Z,445
"@@ -235,7 +235,7 @@ public void renameFile(String from, String to) {
             break;
          }
          ChunkCacheKey toChunkKey = new ChunkCacheKey(indexName, to, i, bufferSize);
-         chunksCache.withFlags(Flag.SKIP_REMOTE_LOOKUP, Flag.SKIP_CACHE_LOAD).put(toChunkKey, ob);
+         chunksCache.withFlags(Flag.IGNORE_RETURN_VALUES).put(toChunkKey, ob);
       } while (true);
 
       // rename metadata first",2012-08-29T09:49:04Z,446
"@@ -69,7 +69,7 @@ public final class InfinispanIndexOutput extends IndexOutput {
    public InfinispanIndexOutput(final AdvancedCache<?, ?> metadataCache, final AdvancedCache<?, ?> chunksCache, final FileCacheKey fileKey, final int bufferSize, final FileListOperations fileList) {
       this.metadataCache = (AdvancedCache<FileCacheKey, FileMetadata>) metadataCache;
       this.chunksCache = (Cache<ChunkCacheKey, Object>) chunksCache;
-      this.chunksCacheForStorage = (Cache<ChunkCacheKey, Object>) chunksCache.withFlags(Flag.SKIP_REMOTE_LOOKUP, Flag.SKIP_CACHE_LOAD, Flag.SKIP_INDEXING);
+      this.chunksCacheForStorage = (Cache<ChunkCacheKey, Object>) chunksCache.withFlags(Flag.IGNORE_RETURN_VALUES, Flag.SKIP_INDEXING);
       this.fileKey = fileKey;
       this.bufferSize = bufferSize;
       this.fileOps = fileList;
@@ -205,7 +205,7 @@ public void close() {
       firstChunkBuffer = null;
       // override existing file header with updated accesstime
       file.touch();
-      metadataCache.withFlags(Flag.SKIP_REMOTE_LOOKUP, Flag.SKIP_CACHE_LOAD, Flag.SKIP_INDEXING).put(fileKey, file);
+      metadataCache.withFlags(Flag.IGNORE_RETURN_VALUES, Flag.SKIP_INDEXING).put(fileKey, file);
       fileOps.addFileName(this.fileKey.getFileName());
       if (trace) {
          log.tracef(""Closed IndexOutput for %s"", fileKey);",2012-08-29T09:49:04Z,447
"@@ -152,7 +152,7 @@ public boolean acquireReadLock(String filename) {
                // T1 fileKey exists - T2 delete file and remove readlock - T1 putIfAbsent(readlock, 2)
                final FileCacheKey fileKey = new FileCacheKey(indexName, filename);
                if (metadataCache.get(fileKey) == null) {
-                  locksCache.withFlags(Flag.SKIP_REMOTE_LOOKUP).removeAsync(readLockKey);
+                  locksCache.withFlags(Flag.IGNORE_RETURN_VALUES).removeAsync(readLockKey);
                   return false;
                }
             }
@@ -186,13 +186,13 @@ static void realFileDelete(FileReadLockKey readLockKey, AdvancedCache<Object, In
          for (int i = 0; i < file.getNumberOfChunks(); i++) {
             ChunkCacheKey chunkKey = new ChunkCacheKey(indexName, filename, i, bufferSize);
             if (trace) log.tracef(""deleting chunk: %s"", chunkKey);
-            chunksCache.withFlags(Flag.SKIP_REMOTE_LOOKUP, Flag.SKIP_CACHE_LOAD).removeAsync(chunkKey);
+            chunksCache.withFlags(Flag.IGNORE_RETURN_VALUES).removeAsync(chunkKey);
          }
       }
       // last operation, as being set as value==0 it prevents others from using it during the
       // deletion process:
       if (trace) log.tracef(""deleting readlock: %s"", readLockKey);
-      locksCache.withFlags(Flag.SKIP_REMOTE_LOOKUP).removeAsync(readLockKey);
+      locksCache.withFlags(Flag.IGNORE_RETURN_VALUES).removeAsync(readLockKey);
    }
    
    private static void verifyCacheHasNoEviction(AdvancedCache<?, ?> cache) {",2012-08-29T09:49:04Z,448
"@@ -33,8 +33,7 @@ import collection.mutable
 import collection.immutable
 import org.infinispan.util.concurrent.TimeoutException
 import java.io.IOException
-import org.infinispan.context.Flag.SKIP_REMOTE_LOOKUP
-import org.infinispan.context.Flag.SKIP_CACHE_LOAD
+import org.infinispan.context.Flag.IGNORE_RETURN_VALUES
 import org.infinispan.util.ByteArrayKey
 import org.jboss.netty.buffer.ChannelBuffer
 import org.infinispan.server.core.transport.ExtendedChannelBuffer._
@@ -254,7 +253,7 @@ object Decoder10 extends AbstractVersionedDecoder with Log {
 
    override def getOptimizedCache(h: HotRodHeader, c: Cache[ByteArrayKey, CacheValue]): Cache[ByteArrayKey, CacheValue] = {
       if (h.flag != ForceReturnPreviousValue) {
-         c.getAdvancedCache.withFlags(SKIP_REMOTE_LOOKUP, SKIP_CACHE_LOAD)
+         c.getAdvancedCache.withFlags(IGNORE_RETURN_VALUES)
       } else {
          c
       }",2012-08-29T09:49:04Z,157
"@@ -61,8 +61,8 @@
 public class InfinispanDirectory extends Directory {
    
    /**
-    * Used as default chunk size, can be overriden at construction time.
-    * Each Lucene index segment is splitted into parts with default size defined here
+    * Used as default chunk size, can be overridden at construction time.
+    * Each Lucene index segment is split into parts with default size defined here
     */
    public final static int DEFAULT_BUFFER_SIZE = 16 * 1024;
 
@@ -144,8 +144,7 @@ public InfinispanDirectory(Cache<?, ?> cache) {
    public String[] list() {
       ensureOpen();
       Set<String> filesList = fileOps.getFileList();
-      String[] array = filesList.toArray(new String[0]);
-      return array;
+      return filesList.toArray(new String[filesList.size()]);
    }
 
    /**
@@ -179,10 +178,7 @@ public long fileModified(String name) {
    public void touchFile(String fileName) {
       ensureOpen();
       FileMetadata file = fileOps.getFileMetadata(fileName);
-      if (file == null) {
-         return;
-      }
-      else {
+      if (file != null) {
          FileCacheKey key = new FileCacheKey(indexName, fileName);
          file.touch();
          metadataCache.put(key, file);
@@ -209,7 +205,7 @@ public void renameFile(String from, String to) {
       ensureOpen();
 
       final FileCacheKey fromKey = new FileCacheKey(indexName, from);
-      final FileMetadata metadata = (FileMetadata) metadataCache.get(fromKey);
+      final FileMetadata metadata = metadataCache.get(fromKey);
       final int bufferSize = metadata.getBufferSize();
       // preparation: copy all chunks to new keys
       int i = -1;
@@ -267,7 +263,7 @@ public IndexOutput createOutput(String name) {
    @Override
    public IndexInput openInput(String name) throws IOException {
       final FileCacheKey fileKey = new FileCacheKey(indexName, name);
-      FileMetadata fileMetadata = (FileMetadata) metadataCache.get(fileKey);
+      FileMetadata fileMetadata = metadataCache.get(fileKey);
       if (fileMetadata == null) {
          throw new FileNotFoundException(""Error loading metadata for index file: "" + fileKey);
       }",2013-10-03T19:00:15Z,446
"@@ -15,7 +15,7 @@ public class DirectoryBuilderImpl implements BuildContext {
    private static final Log log = LogFactory.getLog(DirectoryBuilderImpl.class, Log.class);
 
    /**
-    * Used as default chunk size: each Lucene index segment is splitted into smaller parts having a default size in bytes as
+    * Used as default chunk size: each Lucene index segment is split into smaller parts having a default size in bytes as
     * defined here
     */
    public final static int DEFAULT_BUFFER_SIZE = 16 * 1024;",2013-10-03T19:00:15Z,449
"@@ -52,8 +52,7 @@ public DirectoryImplementor(Cache<?, ?> metadataCache, Cache<?, ?> chunksCache,
 
     String[] list() {
        final Set<String> filesList = fileOps.getFileList();
-       final String[] array = filesList.toArray(new String[0]);
-       return array;
+       return filesList.toArray(new String[filesList.size()]);
     }
 
     boolean fileExists(final String name) {
@@ -78,10 +77,7 @@ long fileModified(final String name) {
      */
     void touchFile(final String fileName) {
        final FileMetadata file = fileOps.getFileMetadata(fileName);
-       if (file == null) {
-          return;
-       }
-       else {
+       if (file != null) {
           final FileCacheKey key = new FileCacheKey(indexName, fileName);
           file.touch();
           metadataCache.put(key, file);
@@ -98,7 +94,7 @@ void deleteFile(final String name) {
 
     void renameFile(final String from, final String to) {
        final FileCacheKey fromKey = new FileCacheKey(indexName, from);
-       final FileMetadata metadata = (FileMetadata) metadataCache.get(fromKey);
+       final FileMetadata metadata = metadataCache.get(fromKey);
        final int bufferSize = metadata.getBufferSize();
        // preparation: copy all chunks to new keys
        int i = -1;
@@ -143,7 +139,7 @@ IndexOutput createOutput(final String name) {
 
     IndexInputContext openInput(final String name) throws IOException {
        final FileCacheKey fileKey = new FileCacheKey(indexName, name);
-       final FileMetadata fileMetadata = (FileMetadata) metadataCache.get(fileKey);
+       final FileMetadata fileMetadata = metadataCache.get(fileKey);
        if (fileMetadata == null) {
           throw new FileNotFoundException(""Error loading metadata for index file: "" + fileKey);
        }",2013-10-03T19:00:15Z,450
"@@ -40,7 +40,7 @@ abstract class InfinispanIndexInput extends IndexInput {
 
    public InfinispanIndexInput(final IndexInputContext ctx) {
       super(ctx.fileKey.getFileName());
-      this.chunksCache = (Cache<ChunkCacheKey, Object>) ctx.chunksCache;
+      this.chunksCache = ctx.chunksCache;
       this.fileKey = ctx.fileKey;
       this.chunkSize = ctx.fileMetadata.getBufferSize();
       this.fileLength = ctx.fileMetadata.getSize();",2013-10-03T19:00:15Z,451
"@@ -9,7 +9,6 @@
 import org.infinispan.distexec.mapreduce.Reducer;
 import org.infinispan.query.backend.QueryInterceptor;
 import org.infinispan.query.impl.ComponentRegistryUtils;
-import org.infinispan.util.TimeService;
 
 /**
  * This Reduce doesn't really index the entries but forwards them to the",2013-10-03T19:00:15Z,452
"@@ -3,11 +3,10 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import junit.framework.Assert;
-
 import org.apache.lucene.search.Query;
 import org.hibernate.search.query.dsl.QueryBuilder;
 import org.infinispan.Cache;
+import org.infinispan.commons.api.BasicCacheContainer;
 import org.infinispan.context.Flag;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.query.CacheQuery;
@@ -16,6 +15,7 @@
 import org.infinispan.query.queries.faceting.Car;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.junit.Assert;
 import org.testng.annotations.Test;
 
 /**
@@ -26,18 +26,18 @@ public class DistributedMassIndexingTest extends MultipleCacheManagersTest {
 
    protected static final int NUM_NODES = 4;
    protected List<Cache> caches = new ArrayList<Cache>(NUM_NODES);
+
    protected static final String[] neededCacheNames = new String[] {
-      org.infinispan.api.BasicCacheContainer.DEFAULT_CACHE_NAME,
+      BasicCacheContainer.DEFAULT_CACHE_NAME,
       ""LuceneIndexesMetadata"",
       ""LuceneIndexesData"",
       ""LuceneIndexesLocking"",
    };
 
    @Override
    protected void createCacheManagers() throws Throwable {
-      EmbeddedCacheManager cacheManager = null;
       for (int i = 0; i < NUM_NODES; i++) {
-         cacheManager = TestCacheManagerFactory.fromXml(""dynamic-indexing-distribution.xml"");
+         EmbeddedCacheManager cacheManager = TestCacheManagerFactory.fromXml(""dynamic-indexing-distribution.xml"");
          registerCacheManager(cacheManager);
          Cache cache = cacheManager.getCache();
          caches.add(cache);",2013-10-03T19:00:15Z,453
"@@ -82,7 +82,6 @@ protected void populateCache() throws Exception {
 
       Account account3 = new Account();
       account3.setId(3);
-      account3.setDescription(""Spider Man's bank account"");
       account3.setCreationDate(DATE_FORMAT.parse(""2013-01-20""));
 
       Transaction transaction0 = new Transaction();
@@ -785,24 +784,6 @@ public void testSampleDomainQuery5() throws Exception {
       assertEquals(""John"", list.get(2)[0]);
    }
 
-   public void testProjectionOnOptionalField() throws Exception {
-      QueryFactory qf = Search.getSearchManager(cache).getQueryFactory();
-
-      Query q = qf.from(User.class)
-            .setProjection(""id"", ""addresses.postCode"")
-            .orderBy(""id"", SortOrder.ASC)
-            .build();
-
-      List<Object[]> list = q.list();
-      assertEquals(3, list.size());
-      assertEquals(1, list.get(0)[0]);
-      assertEquals(""X1234"", list.get(0)[1]);
-      assertEquals(2, list.get(1)[0]);
-      assertEquals(""Y12"", list.get(1)[1]);
-      assertEquals(3, list.get(2)[0]);
-      assertNull(list.get(2)[1]);
-   }
-
    public void testSampleDomainQuery6() throws Exception {
       QueryFactory qf = Search.getSearchManager(cache).getQueryFactory();
 
@@ -1017,6 +998,24 @@ public void testSampleDomainQuery18() throws Exception {
       assertEquals(""Feb. rent payment"", list.get(1).getDescription());
    }
 
+   public void testProjectionOnOptionalField() throws Exception {
+      QueryFactory qf = Search.getSearchManager(cache).getQueryFactory();
+
+      Query q = qf.from(User.class)
+            .setProjection(""id"", ""addresses.postCode"")
+            .orderBy(""id"", SortOrder.ASC)
+            .build();
+
+      List<Object[]> list = q.list();
+      assertEquals(3, list.size());
+      assertEquals(1, list.get(0)[0]);
+      assertEquals(""X1234"", list.get(0)[1]);
+      assertEquals(2, list.get(1)[0]);
+      assertEquals(""Y12"", list.get(1)[1]);
+      assertEquals(3, list.get(2)[0]);
+      assertNull(list.get(2)[1]);
+   }
+
    @Test(enabled = false, description = ""Nulls not correctly indexed for numeric properties"")  //todo [anistor] fix disabled test
    public void testNullOnIntegerField() throws Exception {
       QueryFactory qf = Search.getSearchManager(cache).getQueryFactory();",2013-10-03T19:00:15Z,317
"@@ -121,7 +121,7 @@ public void putLookedUpEntries(Map<Object, CacheEntry> entries) {
    }
 
    public boolean isReadOnly() {
-      return (modifications == null || modifications.isEmpty()) && (lookedUpEntries == null || lookedUpEntries.isEmpty());
+      return modifications == null || modifications.isEmpty();
    }
 
    public abstract boolean isEnlisted();",2013-09-24T13:58:18Z,454
"@@ -3,16 +3,23 @@
 import org.infinispan.Cache;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.context.Flag;
+import org.infinispan.distribution.MagicKey;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
+import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
+import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
 import org.testng.annotations.Test;
 
 import javax.transaction.TransactionManager;
+import java.util.Collection;
 import java.util.HashMap;
 import java.util.Map;
 
+import static org.jgroups.util.Util.assertFalse;
+import static org.testng.Assert.assertTrue;
 import static org.testng.AssertJUnit.assertEquals;
 import static org.testng.AssertJUnit.assertNull;
 
@@ -178,4 +185,60 @@ public void testSimpleRollabck() throws Throwable {
       assertEquals(cache(1, ""testcache"").get(""k""), null);
       assert !lockManager(0, ""testcache"").isLocked(""k"");
    }
+
+   @Test(enabled = false, description = ""This test should work when ISPN-3266 is fixed"")
+   public void testRemoteLocksReleasedWhenReadTransactionCommitted() throws Exception {
+      testRemoteLocksReleased(false, true);
+   }
+
+   @Test(enabled = false, description = ""This test should work when ISPN-3266 is fixed"")
+   public void testRemoteLocksReleasedWhenReadTransactionRolledBack() throws Exception {
+      testRemoteLocksReleased(false, false);
+   }
+
+   @Test
+   public void testRemoteLocksReleasedWhenWriteTransactionCommitted() throws Exception {
+      testRemoteLocksReleased(true, true);
+   }
+
+   @Test
+   public void testRemoteLocksReleasedWhenWriteTransactionRolledBack() throws Exception {
+      testRemoteLocksReleased(true, false);
+   }
+
+   private void testRemoteLocksReleased(boolean write, boolean commit) throws Exception {
+      MagicKey key = new MagicKey(cache(0, ""testcache""));
+      tm(1, ""testcache"").begin();
+      if (write) {
+         cache(1, ""testcache"").put(key, ""somevalue"");
+      } else {
+         cache(1, ""testcache"").getAdvancedCache().withFlags(Flag.FORCE_WRITE_LOCK).get(key);
+      }
+
+      Collection<LocalTransaction> localTxs = TestingUtil.getTransactionTable(cache(1, ""testcache"")).getLocalTransactions();
+      assertEquals(1, localTxs.size());
+      LocalTransaction localTx = localTxs.iterator().next();
+      if (write) {
+         assertFalse(localTx.isReadOnly());
+      } else {
+         assertTrue(localTx.isReadOnly());
+      }
+
+      Collection<RemoteTransaction> remoteTxs = TestingUtil.getTransactionTable(cache(0, ""testcache"")).getRemoteTransactions();
+      assertEquals(1, remoteTxs.size());
+      RemoteTransaction remoteTx = remoteTxs.iterator().next();
+      assertTrue(remoteTx.getLockedKeys().contains(key));
+      assertTrue(TestingUtil.extractLockManager(cache(0, ""testcache"")).isLocked(key));
+
+      if (commit) {
+         tm(1, ""testcache"").commit();
+         // Hack since commit releases locks async
+         Thread.sleep(100);
+      } else {
+         tm(1, ""testcache"").rollback();
+      }
+
+      assertEquals(0, TestingUtil.getTransactionTable(cache(0, ""testcache"")).getRemoteTxCount());
+      assertFalse(TestingUtil.extractLockManager(cache(0, ""testcache"")).isLocked(key));
+   }
 }",2013-09-24T13:58:18Z,455
"@@ -0,0 +1,29 @@
+package org.infinispan.tx;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.context.Flag;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.SingleCacheManagerTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.transaction.TransactionTable;
+import org.infinispan.transaction.xa.LocalXaTransaction;
+import org.infinispan.util.concurrent.IsolationLevel;
+import org.testng.annotations.Test;
+
+import javax.transaction.Transaction;
+
+/**
+ * @author William Burns
+ * @since 6.0
+ */
+@Test (groups = ""functional"", testName = ""tx.ReadOnlyRepeatableReadTxTest"")
+@CleanupAfterMethod
+public class ReadOnlyRepeatableReadTxTest extends ReadOnlyTxTest {
+   protected void configure(ConfigurationBuilder builder) {
+      super.configure(builder);
+      builder.locking().isolationLevel(IsolationLevel.REPEATABLE_READ);
+   }
+}",2013-09-24T13:58:18Z,456
"@@ -8,6 +8,7 @@
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.CleanupAfterMethod;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.xa.LocalXaTransaction;
 import org.testng.annotations.Test;
@@ -25,10 +26,15 @@ public class ReadOnlyTxTest extends SingleCacheManagerTest {
    @Override
    protected EmbeddedCacheManager createCacheManager() throws Exception {
       ConfigurationBuilder configuration = getDefaultClusteredCacheConfig(CacheMode.LOCAL, true);
-      configuration.transaction().useSynchronization(false);
+      configuration.transaction().lockingMode(LockingMode.PESSIMISTIC);
+      configure(configuration);
       return TestCacheManagerFactory.createCacheManager(configuration);
    }
 
+   protected void configure(ConfigurationBuilder builder) {
+      builder.transaction().useSynchronization(false);
+   }
+
    public void testSimpleReadOnlTx() throws Exception {
       tm().begin();
       assert cache.get(""k"") == null;
@@ -40,20 +46,26 @@ public void testSimpleReadOnlTx() throws Exception {
    public void testNotROWhenHasWrites() throws Exception {
       tm().begin();
       cache.put(""k"", ""v"");
-      assert !TestingUtil.extractLockManager(cache).isLocked(""k"");
+      assert TestingUtil.extractLockManager(cache).isLocked(""k"");
       Transaction transaction = tm().suspend();
       LocalXaTransaction localTransaction = (LocalXaTransaction) txTable().getLocalTransaction(transaction);
       assert localTransaction != null && !localTransaction.isReadOnly();
    }
 
-   public void testNotROWhenHasOnlyLocks() throws Exception {
+   public void testROWhenHasOnlyLocksAndReleasedProperly() throws Exception {
       cache.put(""k"", ""v"");
       tm().begin();
       cache.getAdvancedCache().withFlags(Flag.FORCE_WRITE_LOCK).get(""k"");
-      assert !TestingUtil.extractLockManager(cache).isLocked(""k"");
+      assert TestingUtil.extractLockManager(cache).isLocked(""k"");
       Transaction transaction = tm().suspend();
       LocalXaTransaction localTransaction = (LocalXaTransaction) txTable().getLocalTransaction(transaction);
-      assert localTransaction != null && !localTransaction.isReadOnly();
+      assert localTransaction != null && localTransaction.isReadOnly();
+
+      tm().resume(transaction);
+
+      tm().commit();
+
+      assert !TestingUtil.extractLockManager(cache).isLocked(""k"");
    }
 
 ",2013-09-24T13:58:18Z,93
"@@ -10,7 +10,6 @@
 import org.infinispan.test.fwk.TestCacheManagerFactory;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
-import org.testng.annotations.AfterClass;
 import org.testng.annotations.Test;
 
 import java.lang.reflect.Method;",2013-09-23T13:47:39Z,324
"@@ -4,32 +4,59 @@
 import org.hibernate.search.annotations.Field;
 import org.hibernate.search.annotations.Indexed;
 import org.hibernate.search.annotations.Store;
-import org.infinispan.protostream.sampledomain.Account;
 
 import java.util.Date;
 
 /**
+ * A class similar to {@code org.infinispan.protostream.sampledomain.Account}, that maps to the same protobuf type,
+ * {@code sample_bank_account.Account}.
+ *
  * @author anistor@redhat.com
  * @since 6.0
  */
 @Indexed
-public class EmbeddedAccount extends Account {
+public class EmbeddedAccount {
 
    @Field(store = Store.YES, analyze = Analyze.NO)
-   @Override
+   private int id;
+
+   @Field(store = Store.YES, analyze = Analyze.NO)
+   private String description;
+
+   @Field(store = Store.YES, analyze = Analyze.NO)
+   private Date creationDate;
+
    public int getId() {
-      return super.getId();
+      return id;
+   }
+
+   public void setId(int id) {
+      this.id = id;
    }
 
-   @Field(store = Store.YES, analyze = Analyze.NO)
-   @Override
    public String getDescription() {
-      return super.getDescription();
+      return description;
+   }
+
+   public void setDescription(String description) {
+      this.description = description;
    }
 
-   @Field(store = Store.YES, analyze = Analyze.NO)
-   @Override
    public Date getCreationDate() {
-      return super.getCreationDate();
+      return creationDate;
+   }
+
+   public void setCreationDate(Date creationDate) {
+      this.creationDate = creationDate;
+   }
+
+   @Override
+   public String toString() {
+      return ""EmbeddedAccount{"" +
+            ""id="" + id +
+            "", description='"" + description + '\'' +
+            "", creationDate='"" + creationDate + '\'' +
+            ""}"";
+
    }
 }",2013-09-23T13:47:39Z,325
"@@ -7,7 +7,6 @@
 import org.infinispan.client.hotrod.configuration.ConfigurationBuilder;
 import org.infinispan.commons.equivalence.AnyEquivalence;
 import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.protostream.SerializationContext;
 import org.infinispan.protostream.sampledomain.Account;
 import org.infinispan.protostream.sampledomain.marshallers.MarshallerRegistration;
 import org.infinispan.query.CacheQuery;
@@ -47,15 +46,15 @@ public class EmbeddedCompatTest extends SingleCacheManagerTest {
    @Override
    protected EmbeddedCacheManager createCacheManager() throws Exception {
       org.infinispan.configuration.cache.ConfigurationBuilder builder = hotRodCacheConfiguration();
-      CompatibilityProtoStreamMarshaller compatModeMarshaller = new CompatibilityProtoStreamMarshaller();
-      builder.compatibility().enable().marshaller(compatModeMarshaller);
-      builder.indexing().enable();
+      builder.compatibility().enable().marshaller(new CompatibilityProtoStreamMarshaller());
+      builder.indexing().enable()
+            .addProperty(""default.directory_provider"", ""ram"")
+            .addProperty(""lucene_version"", ""LUCENE_CURRENT"");
+
       builder.dataContainer().keyEquivalence(AnyEquivalence.getInstance());  // TODO [anistor] hacks!
       cacheManager = TestCacheManagerFactory.createCacheManager(builder);
       cache = cacheManager.getCache();
 
-      compatModeMarshaller.setCacheManager(cacheManager); //todo [anistor] this works only in programmatic config mode, but not in xml config!
-
       hotRodServer = TestHelper.startHotRodServer(cacheManager);
 
       ConfigurationBuilder clientBuilder = new ConfigurationBuilder();
@@ -66,13 +65,12 @@ protected EmbeddedCacheManager createCacheManager() throws Exception {
       remoteCache = remoteCacheManager.getCache();
 
       //initialize client-side serialization context
-      SerializationContext clientSerCtx = ProtoStreamMarshaller.getSerializationContext(remoteCacheManager);
-      MarshallerRegistration.registerMarshallers(clientSerCtx);
-      clientSerCtx.registerMarshaller(EmbeddedAccount.class, new EmbeddedAccountMarshaller());
+      MarshallerRegistration.registerMarshallers(ProtoStreamMarshaller.getSerializationContext(remoteCacheManager));
 
       //initialize server-side serialization context
-      MarshallerRegistration.registerMarshallers(ProtobufMetadataManager.getSerializationContext(cacheManager));
-      ProtobufMetadataManager.getSerializationContext(cacheManager).registerMarshaller(EmbeddedAccount.class, new EmbeddedAccountMarshaller());
+      ProtobufMetadataManager protobufMetadataManager = cacheManager.getGlobalComponentRegistry().getComponent(ProtobufMetadataManager.class);
+      protobufMetadataManager.registerProtofile(""/bank.protobin"");
+      protobufMetadataManager.registerMarshaller(EmbeddedAccount.class, new EmbeddedAccountMarshaller());
 
       return cacheManager;
    }
@@ -93,7 +91,7 @@ public void testPutAndGet() throws Exception {
       Object localObject = cache.get(key);
       assertNotNull(localObject);
       assertTrue(localObject instanceof EmbeddedAccount);
-      assertAccount((EmbeddedAccount) localObject);
+      assertEmbeddedAccount((EmbeddedAccount) localObject);
 
       // get the object through the remote cache interface and check it's the same object we put
       Account fromRemoteCache = remoteCache.get(1);
@@ -106,14 +104,14 @@ public void testRemoteQuery() throws Exception {
 
       // get account back from remote cache via query and check its attributes
       QueryFactory qf = Search.getQueryFactory(remoteCache);
-      Query query = qf.from(EmbeddedAccount.class)
+      Query query = qf.from(Account.class)
             .having(""description"").like(""%test%"").toBuilder()
             .build();
       List<Account> list = query.list();
 
       assertNotNull(list);
       assertEquals(1, list.size());
-      assertEquals(EmbeddedAccount.class, list.get(0).getClass());
+      assertEquals(Account.class, list.get(0).getClass());
       assertAccount(list.get(0));
    }
 
@@ -131,19 +129,26 @@ public void testEmbeddedQuery() throws Exception {
       assertNotNull(list);
       assertEquals(1, list.size());
       assertEquals(EmbeddedAccount.class, list.get(0).getClass());
-      assertAccount((Account) list.get(0));
+      assertEmbeddedAccount((EmbeddedAccount) list.get(0));
    }
 
    private Account createAccount() {
       Account account = new Account();
       account.setId(1);
       account.setDescription(""test description"");
-      account.setCreationDate(new Date());
+      account.setCreationDate(new Date(42));
       return account;
    }
 
    private void assertAccount(Account account) {
       assertEquals(1, account.getId());
       assertEquals(""test description"", account.getDescription());
+      assertEquals(42, account.getCreationDate().getTime());
+   }
+
+   private void assertEmbeddedAccount(EmbeddedAccount account) {
+      assertEquals(1, account.getId());
+      assertEquals(""test description"", account.getDescription());
+      assertEquals(42, account.getCreationDate().getTime());
    }
 }",2013-09-23T13:47:39Z,326
"@@ -64,13 +64,12 @@ protected EmbeddedCacheManager createCacheManager() throws Exception {
       ConfigurationBuilder builder = new ConfigurationBuilder();
       builder.dataContainer()
             .keyEquivalence(ByteArrayEquivalence.INSTANCE)
-            .valueEquivalence(ByteArrayEquivalence.INSTANCE)
             .indexing().enable()
             .indexLocalOnly(false)
             .addProperty(""default.directory_provider"", getLuceneDirectoryProvider())
             .addProperty(""lucene_version"", ""LUCENE_CURRENT"");
 
-      cacheManager = TestCacheManagerFactory.createCacheManager(gcb, builder, true);
+      cacheManager = TestCacheManagerFactory.createCacheManager(gcb, new ConfigurationBuilder(), true);
       cacheManager.defineConfiguration(TEST_CACHE_NAME, builder.build());
       cache = cacheManager.getCache(TEST_CACHE_NAME);
 
@@ -87,6 +86,7 @@ protected EmbeddedCacheManager createCacheManager() throws Exception {
                                                 + ObjectName.quote(""DefaultCacheManager"")
                                                 + "",component="" + ProtobufMetadataManager.OBJECT_NAME);
 
+      //initialize server-side serialization context via JMX
       byte[] descriptor = readClasspathResource(""/bank.protobin"");
       MBeanServer mBeanServer = PerThreadMBeanServerLookup.getThreadMBeanServer();
       mBeanServer.invoke(objName, ""registerProtofile"", new Object[]{descriptor}, new String[]{byte[].class.getName()});",2013-09-23T13:47:39Z,319
"@@ -34,8 +34,8 @@ public class MultiHotRodServerQueryTest extends MultiHotRodServersTest {
    protected void createCacheManagers() throws Throwable {
       ConfigurationBuilder builder = hotRodCacheConfiguration(getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, false));
       builder.indexing().enable()
-            .indexLocalOnly(true)
-            .addProperty(""default.directory_provider"", ""infinispan"")
+            .indexLocalOnly(false)
+            .addProperty(""default.directory_provider"", ""ram"")
             .addProperty(""lucene_version"", ""LUCENE_CURRENT"");
 
       createHotRodServers(2, builder);",2013-09-23T13:47:39Z,327
"@@ -3,6 +3,7 @@
 
 import org.infinispan.commons.CacheConfigurationException;
 import org.infinispan.commons.CacheException;
+import org.infinispan.commons.marshall.Marshaller;
 import org.infinispan.configuration.cache.*;
 import org.infinispan.factories.annotations.DefaultFactoryFor;
 import org.infinispan.interceptors.*;
@@ -88,8 +89,12 @@ public InterceptorChain buildInterceptorChain() {
 
       CompatibilityModeConfiguration compatibility = configuration.compatibility();
       if (compatibility.enabled()) {
+         Marshaller compatibilityMarshaller = compatibility.marshaller();
+         if (compatibilityMarshaller != null) {
+            componentRegistry.wireDependencies(compatibilityMarshaller);
+         }
          interceptorChain.appendInterceptor(createInterceptor(
-               new TypeConverterInterceptor(compatibility.marshaller()), TypeConverterInterceptor.class), false);
+               new TypeConverterInterceptor(compatibilityMarshaller), TypeConverterInterceptor.class), false);
       }
 
       // add marshallable check interceptor for situations where we want to figure out before marshalling",2013-09-23T13:47:39Z,328
"@@ -1,11 +1,13 @@
 package org.infinispan.query.remote;
 
+import org.infinispan.factories.annotations.Inject;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.protostream.SerializationContext;
 import org.infinispan.query.remote.client.BaseProtoStreamMarshaller;
 
 /**
- * A per EmbeddedCacheManager marshaller that can be used as compatibility mode marshaller.
+ * A per EmbeddedCacheManager marshaller that can be used as compatibility mode marshaller. An instance cannot be shared
+ * between multiple cache managers.
  *
  * @author anistor@redhat.com
  * @since 6.0
@@ -17,11 +19,8 @@ public class CompatibilityProtoStreamMarshaller extends BaseProtoStreamMarshalle
    public CompatibilityProtoStreamMarshaller() {
    }
 
-   public EmbeddedCacheManager getCacheManager() {
-      return cacheManager;
-   }
-
-   public void setCacheManager(EmbeddedCacheManager cacheManager) {  //todo [anistor] this cannot work in xml config mode ..
+   @Inject
+   protected void injectDependencies(EmbeddedCacheManager cacheManager) {
       this.cacheManager = cacheManager;
    }
 ",2013-09-23T13:47:39Z,329
"@@ -15,6 +15,7 @@
 import org.infinispan.notifications.cachelistener.annotation.CacheEntryModified;
 import org.infinispan.notifications.cachelistener.event.CacheEntryCreatedEvent;
 import org.infinispan.notifications.cachelistener.event.CacheEntryModifiedEvent;
+import org.infinispan.protostream.BaseMarshaller;
 import org.infinispan.protostream.ProtobufUtil;
 import org.infinispan.protostream.SerializationContext;
 import org.infinispan.transaction.TransactionMode;
@@ -88,6 +89,10 @@ private Configuration getMetadataCacheConfig() {
       return configurationBuilder.build();
    }
 
+   public <T> void registerMarshaller(Class<? extends T> clazz, BaseMarshaller<T> marshaller) {
+      serCtx.registerMarshaller(clazz, marshaller);
+   }
+
    @ManagedOperation(description = ""Registers a Protobuf definition file"", displayName = ""Register Protofile"")
    public void registerProtofile(byte[] descriptorFile) throws IOException, Descriptors.DescriptorValidationException {
       getMetadataCache().put(UUID.randomUUID().toString(), descriptorFile);
@@ -119,7 +124,7 @@ private byte[] readStream(InputStream is) throws IOException {
       }
    }
 
-   public SerializationContext getSerializationContext() {
+   SerializationContext getSerializationContext() {
       return serCtx;
    }
 ",2013-09-23T13:47:39Z,330
"@@ -2,6 +2,7 @@
 
 import static org.infinispan.client.hotrod.test.HotRodClientTestingUtil.killRemoteCacheManager;
 import static org.infinispan.client.hotrod.test.HotRodClientTestingUtil.killServers;
+import static org.infinispan.server.hotrod.test.HotRodTestingUtil.hotRodCacheConfiguration;
 
 import java.util.HashMap;
 import java.util.HashSet;
@@ -38,7 +39,7 @@ protected void createCacheManagers() throws Throwable {
 		final int numServers = numberOfHotRodServers();
 		hotrodServers = new HotRodServer[numServers];
 		
-		createCluster(clusterConfig(), numberOfHotRodServers());
+		createCluster(hotRodCacheConfiguration(clusterConfig()), numberOfHotRodServers());
 
 		for (int i = 0; i < numServers; i++) {
 			EmbeddedCacheManager cm = cacheManagers.get(i);",2013-09-16T13:43:13Z,457
"@@ -44,7 +44,7 @@ protected void createCacheManagers() throws Throwable {
       final int numServers = numberOfHotRodServers();
       hotrodServers = new HotRodServer[numServers];
 
-      createCluster(clusterConfig(), numberOfHotRodServers());
+      createCluster(hotRodCacheConfiguration(clusterConfig()), numberOfHotRodServers());
 
       for (int i = 0; i < numServers; i++) {
          EmbeddedCacheManager cm = cacheManagers.get(i);",2013-09-16T13:43:13Z,458
"@@ -5,7 +5,6 @@
 import org.infinispan.client.hotrod.Search;
 import org.infinispan.client.hotrod.TestHelper;
 import org.infinispan.client.hotrod.marshall.ProtoStreamMarshaller;
-import org.infinispan.commons.equivalence.AnyEquivalence;
 import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.protostream.sampledomain.Address;
@@ -59,8 +58,6 @@ protected EmbeddedCacheManager createCacheManager() throws Exception {
             .addProperty(""default.directory_provider"", getLuceneDirectoryProvider())
             .addProperty(""lucene_version"", ""LUCENE_CURRENT"");
 
-      builder.dataContainer().valueEquivalence(AnyEquivalence.getInstance());  // TODO [anistor] hacks!
-
       cacheManager = TestCacheManagerFactory.createCacheManager();
       cacheManager.defineConfiguration(TEST_CACHE_NAME, builder.build());
       cache = cacheManager.getCache(TEST_CACHE_NAME);",2013-09-16T13:43:13Z,319
"@@ -44,8 +44,6 @@ protected void createCacheManagers() throws Throwable {
             .addProperty(""default.directory_provider"", ""ram"")   //todo test with  ""infinispan"" provider too
             .addProperty(""lucene_version"", ""LUCENE_CURRENT"");
 
-      builder.dataContainer().valueEquivalence(AnyEquivalence.getInstance());  // TODO [anistor] hacks!
-
       createHotRodServers(2, builder);
    }
 ",2013-09-16T13:43:13Z,327
"@@ -72,8 +72,6 @@ protected EmbeddedCacheManager createCacheManager() throws Exception {
             .addProperty(""default.directory_provider"", ""ram"")
             .addProperty(""lucene_version"", ""LUCENE_CURRENT"");
 
-      builder.dataContainer().valueEquivalence(AnyEquivalence.getInstance());  // TODO [anistor] hacks!
-
       cacheManager = TestCacheManagerFactory.createCacheManager(builder);
       cache = cacheManager.getCache();
 ",2013-09-16T13:43:13Z,308
"@@ -6,14 +6,16 @@ import org.infinispan.manager.EmbeddedCacheManager
 import org.infinispan.server.core.{QueryFacade, AbstractProtocolServer}
 import org.infinispan.eviction.EvictionStrategy
 import org.infinispan.commons.util.CollectionFactory
-import org.infinispan.commons.equivalence.AnyEquivalence
+import org.infinispan.commons.equivalence.{Equivalence, AnyEquivalence}
 import org.infinispan.Cache
 import org.infinispan.remoting.transport.Address
-import org.infinispan.configuration.cache.{CacheMode, ConfigurationBuilder}
+import org.infinispan.configuration.cache.{Configuration, CacheMode, ConfigurationBuilder}
 import org.infinispan.context.Flag
 import org.infinispan.upgrade.RollingUpgradeManager
 import org.infinispan.server.hotrod.configuration.HotRodServerConfiguration
 import java.util.ServiceLoader
+import org.infinispan.commons.CacheConfigurationException
+import org.infinispan.util.concurrent.IsolationLevel
 
 /**
  * Hot Rod server, in charge of defining its encoder/decoder and, if clustered, update the topology information
@@ -77,18 +79,36 @@ class HotRodServer extends AbstractProtocolServer(""HotRod"") with Log {
    }
 
    override def startDefaultCache = {
-      cacheManager.getCache()
+      val cache = cacheManager.getCache[AnyRef, AnyRef]()
+      validateCacheConfiguration(cache.getCacheConfiguration)
+      cache
    }
 
    private def preStartCaches() {
       // Start defined caches to avoid issues with lazily started caches
       for (cacheName <- asScalaIterator(cacheManager.getCacheNames.iterator)) {
          if (!cacheName.startsWith(HotRodServerConfiguration.TOPOLOGY_CACHE_NAME_PREFIX)) {
-            cacheManager.getCache(cacheName)
+            val cache = cacheManager.getCache(cacheName)
+            validateCacheConfiguration(cache.getCacheConfiguration)
          }
       }
    }
 
+   private def validateCacheConfiguration(cacheCfg: Configuration) {
+      val keyEq = cacheCfg.dataContainer().keyEquivalence[Array[Byte]]()
+      if (!keyEq.equals(Array[Byte](1, 2, 3), Array[Byte](1, 2, 3)))
+         throw log.invalidKeyEquivalence(keyEq)
+
+      val valueEq = cacheCfg.dataContainer().valueEquivalence[Array[Byte]]()
+      if (!valueEq.equals(Array[Byte](1, 2, 3), Array[Byte](1, 2, 3)))
+         throw log.invalidValueEquivalence(valueEq)
+
+      val isolationLevel = cacheCfg.locking().isolationLevel()
+      if (isolationLevel == IsolationLevel.REPEATABLE_READ
+              || isolationLevel == IsolationLevel.SERIALIZABLE)
+         throw log.invalidIsolationLevel(isolationLevel)
+   }
+
    private def addSelfToTopologyView(cacheManager: EmbeddedCacheManager) {
       addressCache = cacheManager.getCache(configuration.topologyCacheName)
       clusterAddress = cacheManager.getAddress",2013-09-16T13:43:13Z,158
"@@ -1,6 +1,8 @@
 package org.infinispan.server.hotrod.logging;
 
 import org.infinispan.commons.CacheConfigurationException;
+import org.infinispan.commons.equivalence.Equivalence;
+import org.infinispan.util.concurrent.IsolationLevel;
 import org.jboss.logging.Cause;
 import org.jboss.logging.LogMessage;
 import org.jboss.logging.Message;
@@ -32,4 +34,14 @@ public interface JavaLog extends org.infinispan.util.logging.Log {
 
    @Message(value = ""A topology cache named '%s' has already been defined"", id = 6003)
    CacheConfigurationException invalidTopologyCache(String topologyCacheName);
+
+   @Message(value = ""Key equivalence must be able to compare arrays based on contents. Provided key equivalence instance '%s' is not possible to do so"", id = 6004)
+   CacheConfigurationException invalidKeyEquivalence(Equivalence keyEq);
+
+   @Message(value = ""Value equivalence must be able to compare arrays based on contents. Provided value equivalence instance '%s' is not possible to do so"", id = 6005)
+   CacheConfigurationException invalidValueEquivalence(Equivalence keyEq);
+
+   @Message(value = ""Isolation level must be READ_COMMITTED or lower: '%s'"", id = 6006)
+   CacheConfigurationException invalidIsolationLevel(IsolationLevel isolationLevel);
+
 }",2013-09-16T13:43:13Z,459
"@@ -6,10 +6,12 @@ import org.infinispan.test.fwk.TestCacheManagerFactory
 import org.testng.Assert._
 import org.testng.annotations.Test
 import org.infinispan.server.core.test.Stoppable
-import org.infinispan.configuration.cache.Configuration
+import org.infinispan.configuration.cache.{ConfigurationBuilder, Configuration}
 import org.infinispan.server.hotrod.configuration.HotRodServerConfigurationBuilder
 import org.infinispan.configuration.cache.ClusterStoreConfiguration
 import org.infinispan.server.hotrod.configuration.HotRodServerConfiguration
+import org.infinispan.util.concurrent.IsolationLevel
+import org.infinispan.commons.CacheConfigurationException
 
 /**
  * Test to verify that configuration changes are reflected in backend caches.
@@ -44,6 +46,16 @@ class HotRodConfigurationTest {
       }
    }
 
+   @Test(expectedExceptions = Array(classOf[CacheConfigurationException]))
+   def testRepeatableReadIsolationLevelValidation() {
+      validateIsolationLevel(IsolationLevel.REPEATABLE_READ)
+   }
+
+   @Test(expectedExceptions = Array(classOf[CacheConfigurationException]))
+   def testSerializableIsolationLevelValidation() {
+      validateIsolationLevel(IsolationLevel.SERIALIZABLE)
+   }
+
    private def withClusteredServer(builder: HotRodServerConfigurationBuilder) (assert: (Configuration, Long) => Unit) {
       Stoppable.useCacheManager(TestCacheManagerFactory.createClusteredCacheManager(hotRodCacheConfiguration())) { cm =>
          Stoppable.useServer(startHotRodServer(cm, UniquePortThreadLocal.get.intValue, builder)) { server =>
@@ -52,4 +64,15 @@ class HotRodConfigurationTest {
          }
       }
    }
+
+   private def validateIsolationLevel(isolationLevel: IsolationLevel) {
+      val hotRodBuilder = new HotRodServerConfigurationBuilder
+      val builder = new ConfigurationBuilder()
+      builder.locking().isolationLevel(isolationLevel)
+      Stoppable.useCacheManager(TestCacheManagerFactory.createClusteredCacheManager(hotRodCacheConfiguration(builder))) {
+         cm =>
+            startHotRodServer(cm, UniquePortThreadLocal.get.intValue, hotRodBuilder)
+      }
+   }
+
 }
\ No newline at end of file",2013-09-16T13:43:13Z,460
"@@ -292,7 +292,9 @@ object HotRodTestingUtil extends Log {
       hotRodCacheConfiguration(new ConfigurationBuilder())
 
    def hotRodCacheConfiguration(base: ConfigurationBuilder): ConfigurationBuilder = {
-      base.dataContainer().keyEquivalence(ByteArrayEquivalence.INSTANCE)
+      base.dataContainer()
+              .keyEquivalence(ByteArrayEquivalence.INSTANCE)
+              .valueEquivalence(ByteArrayEquivalence.INSTANCE)
       base
    }
 ",2013-09-16T13:43:13Z,461
"@@ -1,5 +1,6 @@
 package org.infinispan.spring.provider;
 
+import static org.infinispan.server.hotrod.test.HotRodTestingUtil.hotRodCacheConfiguration;
 import static org.testng.AssertJUnit.assertEquals;
 import static org.testng.AssertJUnit.assertFalse;
 import static org.testng.AssertJUnit.assertNotNull;
@@ -40,7 +41,7 @@ public class SpringRemoteCacheManagerTest extends SingleCacheManagerTest {
 
    @Override
    protected EmbeddedCacheManager createCacheManager() throws Exception {
-      cacheManager = TestCacheManagerFactory.createCacheManager(false);
+      cacheManager = TestCacheManagerFactory.createCacheManager(hotRodCacheConfiguration());
       cache = cacheManager.getCache(TEST_CACHE_NAME);
 
       return cacheManager;",2013-09-16T13:43:13Z,462
"@@ -1,5 +1,6 @@
 package org.infinispan.spring.support.remote;
 
+import static org.infinispan.server.hotrod.test.HotRodTestingUtil.hotRodCacheConfiguration;
 import static org.testng.AssertJUnit.assertEquals;
 import static org.testng.AssertJUnit.assertNotNull;
 import static org.testng.AssertJUnit.assertTrue;
@@ -37,7 +38,7 @@ public class InfinispanNamedRemoteCacheFactoryBeanTest extends SingleCacheManage
 
    @Override
    protected EmbeddedCacheManager createCacheManager() throws Exception {
-      cacheManager = TestCacheManagerFactory.createCacheManager(false);
+      cacheManager = TestCacheManagerFactory.createCacheManager(hotRodCacheConfiguration());
       cache = cacheManager.getCache(TEST_CACHE_NAME);
       cache = cacheManager.getCache(TEST_BEAN_NAME);
 ",2013-09-16T13:43:13Z,463
"@@ -54,6 +54,7 @@
 
    <properties>
       <!-- Versions for dependencies -->
+      <version.protostream>1.0.0.Alpha4</version.protostream>
       <version.aesh>0.33.1</version.aesh>
       <version.antlr>3.4</version.antlr>
       <version.gnu.getopt>1.0.13</version.gnu.getopt>
@@ -136,6 +137,17 @@
             <artifactId>infinispan-query</artifactId>
             <version>${project.version}</version>
          </dependency>
+         <dependency>
+            <groupId>${project.groupId}</groupId>
+            <artifactId>infinispan-remote-query</artifactId>
+            <version>${project.version}</version>
+         </dependency>
+         <dependency>
+            <groupId>${project.groupId}</groupId>
+            <artifactId>infinispan-remote-query</artifactId>
+            <classifier>client-jar</classifier>
+            <version>${project.version}</version>
+         </dependency>
          <dependency>
             <groupId>${project.groupId}</groupId>
             <artifactId>infinispan-server-core</artifactId>
@@ -271,6 +283,17 @@
             <artifactId>hibernate-search-infinispan</artifactId>
             <version>${version.hibernate.search}</version>
          </dependency>
+         <!-- Infinispan Remote Query module dependencies -->
+         <dependency>
+            <groupId>org.infinispan.protostream</groupId>
+            <artifactId>protostream</artifactId>
+            <version>${version.protostream}</version>
+         </dependency>
+         <dependency>
+            <groupId>org.infinispan.protostream</groupId>
+            <artifactId>sample-domain-implementation</artifactId>
+            <version>${version.protostream}</version>
+         </dependency>
          <!-- Infinispan Protocols module dependencies -->
          <dependency>
             <groupId>io.netty</groupId>",2013-09-05T15:37:07Z,307
"@@ -590,7 +590,7 @@ public void start() {
    private void initRemoteQuery() {
       SerializationContext serCtx = getSerializationContext();
       try {
-         serCtx.registerProtofile(""/query.protobin"");
+         serCtx.registerProtofile(RemoteCacheManager.class.getResourceAsStream(""/query.protobin""));
       } catch (Exception e) {
          throw new CacheException(e);  //todo [anistor] better exception handling
       }",2013-09-05T15:37:07Z,192
"@@ -86,8 +86,6 @@
       <module.skipComponentMetaDataProcessing>true</module.skipComponentMetaDataProcessing>
       <module.metadata.isCoreModule>false</module.metadata.isCoreModule>
       <!-- Versions for dependencies -->
-      <version.protostream>1.0.0.Alpha4</version.protostream>
-      <version.aesh>0.33.1</version.aesh>
       <version.antlr>3.4</version.antlr>
       <version.arquillian>1.0.3.Final</version.arquillian>
       <version.arquillian.container.managed>7.2.0.Final</version.arquillian.container.managed>
@@ -319,16 +317,6 @@
             <artifactId>infinispan-jcache</artifactId>
             <version>${project.version}</version>
          </dependency>
-         <dependency>
-            <groupId>org.infinispan.protostream</groupId>
-            <artifactId>protostream</artifactId>
-            <version>${version.protostream}</version>
-         </dependency>
-         <dependency>
-            <groupId>org.infinispan.protostream</groupId>
-            <artifactId>sample-domain-implementation</artifactId>
-            <version>${version.protostream}</version>
-         </dependency>
          <dependency>
             <groupId>c3p0</groupId>
             <artifactId>c3p0</artifactId>",2013-09-05T15:37:07Z,152
"@@ -55,9 +55,8 @@ public ClusteredCacheQueryImpl(Query luceneQuery, SearchFactoryIntegrator search
             ExecutorService asyncExecutor, AdvancedCache cache, Class<?>... classes) {
       super(luceneQuery, searchFactory, cache, classes);
       this.asyncExecutor = asyncExecutor;
-      hSearchQuery = searchFactory.createHSQuery()
-            .luceneQuery(luceneQuery)
-            .targetedEntities(Arrays.asList(classes));
+      hSearchQuery = searchFactory.createHSQuery().luceneQuery(luceneQuery)
+               .targetedEntities(Arrays.asList(classes));
    }
 
    @Override
@@ -69,7 +68,15 @@ public CacheQuery sort(Sort sort) {
    @Override
    public int getResultSize() {
       if (resultSize == null) {
-         // TODO fetch result size
+         ClusteredQueryCommand command = ClusteredQueryCommand.getResultSize(hSearchQuery, cache);
+
+         ClusteredQueryInvoker invoker = new ClusteredQueryInvoker(cache, asyncExecutor);
+         List<QueryResponse> responses = invoker.broadcast(command);
+
+         resultSize = 0;
+         for (QueryResponse response : responses) {
+            resultSize += response.getResultSize();
+         }
       }
       return resultSize;
    }
@@ -79,7 +86,7 @@ public QueryIterator iterator(int fetchSize) throws SearchException {
       ClusteredQueryCommand command = ClusteredQueryCommand
                .createEagerIterator(hSearchQuery, cache);
 
-      HashMap<UUID, ClusteredTopDocs> topDocsResponses = treatIteratorResponses(command);
+      HashMap<UUID, ClusteredTopDocs> topDocsResponses = broadcastQuery(command);
       DistributedIterator it = new DistributedIterator(sort, fetchSize, this.resultSize,
                topDocsResponses, cache);
 
@@ -89,26 +96,23 @@ public QueryIterator iterator(int fetchSize) throws SearchException {
    @Override
    public QueryIterator lazyIterator(int fetchSize) {
       UUID lazyItId = UUID.randomUUID();
+      ClusteredQueryCommand command = ClusteredQueryCommand.createLazyIterator(hSearchQuery, cache,
+               lazyItId);
 
-      ClusteredQueryCommand command = ClusteredQueryCommand.createLazyIterator(
-               hSearchQuery, cache, lazyItId);
-
-      HashMap<UUID, ClusteredTopDocs> topDocsResponses = treatIteratorResponses(command);
+      HashMap<UUID, ClusteredTopDocs> topDocsResponses = broadcastQuery(command);
       DistributedLazyIterator it = new DistributedLazyIterator(sort, fetchSize, this.resultSize,
                lazyItId, topDocsResponses, asyncExecutor, cache);
 
       return it;
    }
 
-   private HashMap<UUID, ClusteredTopDocs> treatIteratorResponses(ClusteredQueryCommand command) {
+   private HashMap<UUID, ClusteredTopDocs> broadcastQuery(ClusteredQueryCommand command) {
       ClusteredQueryInvoker invoker = new ClusteredQueryInvoker(cache, asyncExecutor);
 
-      HashMap<UUID, ClusteredTopDocs> topDocsResponses = null;
+      HashMap<UUID, ClusteredTopDocs> topDocsResponses = new HashMap<UUID, ClusteredTopDocs>();
       int resultSize = 0;
       List<QueryResponse> responses = invoker.broadcast(command);
 
-      topDocsResponses = new HashMap<UUID, ClusteredTopDocs>();
-
       for (Object response : responses) {
          QueryResponse queryResponse = (QueryResponse) response;
          ClusteredTopDocs topDocs = new ClusteredTopDocs(queryResponse.getTopDocs(),",2011-09-07T11:43:18Z,464
"@@ -71,12 +71,20 @@ private ClusteredQueryCommand(ClusteredQueryCommandType type, String cacheName)
    }
 
    public static ClusteredQueryCommand createLazyIterator(HSQuery query, Cache cache, UUID id) {
-      ClusteredQueryCommand clQuery = new ClusteredQueryCommand(ClusteredQueryCommandType.CREATE_LAZY_ITERATOR, cache.getName());
+      ClusteredQueryCommand clQuery = new ClusteredQueryCommand(
+               ClusteredQueryCommandType.CREATE_LAZY_ITERATOR, cache.getName());
       clQuery.query = query;
       clQuery.lazyQueryId = id;
       return clQuery;
    }
 
+   public static ClusteredQueryCommand getResultSize(HSQuery query, Cache cache) {
+      ClusteredQueryCommand clQuery = new ClusteredQueryCommand(
+               ClusteredQueryCommandType.GET_RESULT_SIZE, cache.getName());
+      clQuery.query = query;
+      return clQuery;
+   }
+
    public static ClusteredQueryCommand createEagerIterator(HSQuery query, Cache cache) {
       ClusteredQueryCommand clQuery = new ClusteredQueryCommand(
                ClusteredQueryCommandType.CREATE_EAGER_ITERATOR, cache.getName());
@@ -121,7 +129,8 @@ public Object perform(InvocationContext context) throws Throwable {
    }
 
    public QueryResponse perform(Cache cache) {
-      ClusteredQueryCommandWorker worker = commandType.getCommand(cache, query, lazyQueryId, docIndex);
+      ClusteredQueryCommandWorker worker = commandType.getCommand(cache, query, lazyQueryId,
+               docIndex);
       return worker.perform();
    }
 ",2011-09-07T11:43:18Z,388
"@@ -27,6 +27,7 @@
 import org.infinispan.Cache;
 import org.infinispan.query.clustered.commandworkers.CQCreateEagerQuery;
 import org.infinispan.query.clustered.commandworkers.CQCreateLazyQuery;
+import org.infinispan.query.clustered.commandworkers.CQGetResultSize;
 import org.infinispan.query.clustered.commandworkers.CQKillLazyIterator;
 import org.infinispan.query.clustered.commandworkers.CQLazyFetcher;
 import org.infinispan.query.clustered.commandworkers.ClusteredQueryCommandWorker;
@@ -47,11 +48,11 @@ public ClusteredQueryCommandWorker getNewInstance() {
       }
    },
    CREATE_EAGER_ITERATOR() {
-	      @Override
-	      public ClusteredQueryCommandWorker getNewInstance() {
-	         return new CQCreateEagerQuery();
-	      }
-	   },
+      @Override
+      public ClusteredQueryCommandWorker getNewInstance() {
+         return new CQCreateEagerQuery();
+      }
+   },
    DESTROY_LAZY_ITERATOR() {
       @Override
       public ClusteredQueryCommandWorker getNewInstance() {
@@ -63,6 +64,12 @@ public ClusteredQueryCommandWorker getNewInstance() {
       public ClusteredQueryCommandWorker getNewInstance() {
          return new CQLazyFetcher();
       }
+   },
+   GET_RESULT_SIZE() {
+      @Override
+      public ClusteredQueryCommandWorker getNewInstance() {
+         return new CQGetResultSize();
+      }
    };
 
    protected abstract ClusteredQueryCommandWorker getNewInstance();",2011-09-07T11:43:18Z,388
"@@ -41,7 +41,7 @@
 import org.infinispan.remoting.transport.Address;
 
 /**
- * Invoke a CusteredQueryCommand on the cluster, including on own node. 
+ * Invoke a CusteredQueryCommand on the cluster, including on own node.
  * 
  * @author Israel Lacerra <israeldl@gmail.com>
  * @author Sanne Grinovero <sanne@infinispan.org> (C) 2011 Red Hat Inc.
@@ -65,46 +65,53 @@ public class ClusteredQueryInvoker {
       this.myAddress = localCacheInstance.getAdvancedCache().getRpcManager().getAddress();
    }
 
+   /**
+    * Retrieves the value (using doc index) in a remote query instance
+    * 
+    * @param doc
+    *           Doc index of the value on remote query
+    * @param address
+    *           Address of the node who has the value
+    * @param queryId
+    *           Id of the query
+    * @return The value of index doc of the query with queryId on node at address
+    */
    public Object getValue(int doc, Address address, UUID queryId) {
       ClusteredQueryCommand clusteredQuery = ClusteredQueryCommand.retrieveKeyFromLazyQuery(
                localCacheInstance, queryId, doc);
 
       if (address.equals(myAddress)) {
          Future<QueryResponse> localResponse = localInvoke(clusteredQuery);
          try {
-            return localResponse.get();
+            return localResponse.get().getFetchedValue();
          } catch (InterruptedException e) {
-            //FIXME
-            e.printStackTrace();
-            return null;
+            throw new SearchException(""interrupted while searching locally"", e);
          } catch (ExecutionException e) {
-            //FIXME
-            e.printStackTrace();
-            return null;
+            throw new SearchException(""Exception while searching locally"", e);
          }
       } else {
-
          List<Address> addresss = new ArrayList<Address>(1);
          addresss.add(address);
 
-         try {
-            Map<Address, Response> responses = rpcManager.invokeRemotely(addresss, clusteredQuery,
-                     ResponseMode.SYNCHRONOUS, 10000);
-            List<QueryResponse> objects = cast(responses);
-            return objects.get(0);
-         } catch (Exception e) {
-            // FIXME
-            e.printStackTrace();
-            return null;
-         }
+         Map<Address, Response> responses = rpcManager.invokeRemotely(addresss, clusteredQuery,
+                  ResponseMode.SYNCHRONOUS, 10000);
+         List<QueryResponse> objects = cast(responses);
+         return objects.get(0).getFetchedValue();
       }
    }
 
+   /**
+    * Broadcast this ClusteredQueryCommand to all cluster nodes. The command will be also invoked on
+    * local node.
+    * 
+    * @param clusteredQuery
+    * @return A list with all responses
+    */
    public List<QueryResponse> broadcast(ClusteredQueryCommand clusteredQuery) {
       // invoke on own node
       Future<QueryResponse> localResponse = localInvoke(clusteredQuery);
       Map<Address, Response> responses = rpcManager.invokeRemotely(null, clusteredQuery,
-            ResponseMode.SYNCHRONOUS, 10000);
+               ResponseMode.SYNCHRONOUS, 10000);
 
       List<QueryResponse> objects = cast(responses);
       final QueryResponse localReturnValue;
@@ -120,7 +127,8 @@ public List<QueryResponse> broadcast(ClusteredQueryCommand clusteredQuery) {
    }
 
    private Future<QueryResponse> localInvoke(ClusteredQueryCommand clusteredQuery) {
-      ClusteredQueryCallable clusteredQueryCallable = new ClusteredQueryCallable(clusteredQuery, localCacheInstance);
+      ClusteredQueryCallable clusteredQueryCallable = new ClusteredQueryCallable(clusteredQuery,
+               localCacheInstance);
       return asyncExecutor.submit(clusteredQueryCallable);
    }
 
@@ -132,15 +140,15 @@ private List<QueryResponse> cast(Map<Address, Response> responses) {
             QueryResponse response = (QueryResponse) ((SuccessfulResponse) resp).getResponseValue();
             objects.add(response);
          } else {
-            //TODO
+            throw new SearchException(""Unexpected response: "" + resp);
          }
       }
 
       return objects;
    }
 
    /**
-    * Created to call a ClusteredQueryCommand on own node. 
+    * Created to call a ClusteredQueryCommand on own node.
     * 
     * @author Israel Lacerra <israeldl@gmail.com>
     * @since 5.1",2011-09-07T11:43:18Z,465
"@@ -30,10 +30,15 @@
 import org.infinispan.query.clustered.commandworkers.QueryExtractorUtil;
 
 /**
- * Each node in the cluster has a QueryBox instance. The QueryBox keep the active lazy iterators on
- * the cluster, so it can return values for the queries in a ""lazy"" way.
+ * Each node in the cluster has a QueryBox instance. The QueryBox keep the active lazy iterators
+ * (actually it keeps the DocumentExtractor of the searches) on the cluster, so it can return values
+ * for the queries in a ""lazy"" way.
  * 
- * EVICTION: Currently the QueryBox keeps the last BOX_LIMIT used... probably there is a better way.
+ * When a DistributedLazyIterator is created, every nodes creates a DocumentExtractor and register
+ * it in your own QueryBox. So, the LazyIterator can fetch the values in a lazy way.
+ * 
+ * EVICTION: Currently the QueryBox keeps the last BOX_LIMIT DocumentExtractor used... probably
+ * there is a better way.
  * 
  * @author Israel Lacerra <israeldl@gmail.com>
  * @since 5.1
@@ -52,11 +57,21 @@ public class QueryBox {
    // this id will be sent with the responses to rpcs
    private final UUID myId = UUID.randomUUID();
 
-   private AdvancedCache<Object,QueryResponse> cache;
+   // the local cache instance
+   private AdvancedCache cache;
 
    public org.infinispan.util.logging.Log log;
 
-   public QueryResponse getValue(UUID queryUuid, int docIndex) {
+   /**
+    * Get the ""docIndex"" value on the correct DocumentExtractor
+    * 
+    * @param queryUuid
+    *           The queryId, so we can get the correct DocumentExtractor
+    * @param docIndex
+    *           value index in the DocumentExtractor
+    * @return
+    */
+   public Object getValue(UUID queryUuid, int docIndex) {
       touch(queryUuid);
 
       DocumentExtractor extractor = queries.get(queryUuid);
@@ -76,13 +91,27 @@ private void touch(UUID id) {
       }
    }
 
+   /**
+    * Kill the query (DocumentExtractor)
+    * 
+    * @param id
+    *           The id of the query
+    */
    public void kill(UUID id) {
       DocumentExtractor extractor = queries.remove(id);
       ageOrderedQueries.remove(id);
       if (extractor != null)
          extractor.close();
    }
 
+   /**
+    * Register a query (DocumentExtractor), so we can lazily load the results.
+    * 
+    * @param id
+    *           The id of the query
+    * @param extractor
+    *           The query
+    */
    public synchronized void put(UUID id, DocumentExtractor extractor) {
       synchronized (ageOrderedQueries) {
          if (ageOrderedQueries.size() >= BOX_LIMIT) {
@@ -94,6 +123,11 @@ public synchronized void put(UUID id, DocumentExtractor extractor) {
       queries.put(id, extractor);
    }
 
+   /**
+    * Id of this QueryBox
+    * 
+    * @return
+    */
    public UUID getMyId() {
       return myId;
    }",2011-09-07T11:43:18Z,466
"@@ -39,18 +39,28 @@ public class QueryResponse implements Serializable {
 
    private static final long serialVersionUID = -2113889511877165954L;
 
-   private final UUID nodeUUID;
+   private UUID nodeUUID;
 
    private TopDocs topDocs;
 
    private Address address;
 
    private Integer resultSize;
-   
+
+   private Object fetchedValue;
+
    public TopDocs getTopDocs() {
       return topDocs;
    }
 
+   public QueryResponse(Object value) {
+      fetchedValue = value;
+   }
+
+   public QueryResponse(int resultSize) {
+      this.resultSize = resultSize;
+   }
+
    public QueryResponse(TopDocs topDocs, UUID nodeUUid, int resultSize) {
       this.nodeUUID = nodeUUid;
       this.topDocs = topDocs;
@@ -73,4 +83,8 @@ public Address getAddress() {
       return address;
    }
 
+   public Object getFetchedValue() {
+      return fetchedValue;
+   }
+
 }
\ No newline at end of file",2011-09-07T11:43:18Z,467
"@@ -30,8 +30,8 @@
 /**
  * CQCreateLazyQuery.
  * 
- * Creates a lazy iterator of a distributed query.
- * 
+ * Creates a DocumentExtractor and register it on the node QueryBox.
+ *  
  * @author Israel Lacerra <israeldl@gmail.com>
  * @since 5.1
  */
@@ -44,9 +44,12 @@ public QueryResponse perform() {
       int resultSize = query.queryResultSize();
 
       QueryBox box = getQueryBox();
+      
+      // registering...
       box.put(lazyQueryId, extractor);
+      
+      // returning the QueryResponse 
       TopDocs topDocs = extractor.getTopDocs();
-
       QueryResponse queryResponse = new QueryResponse(topDocs, box.getMyId(), resultSize);
       queryResponse.setAddress(cache.getAdvancedCache().getRpcManager().getAddress());
       return queryResponse;",2011-09-07T11:43:18Z,468
"@@ -0,0 +1,47 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2011, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.query.clustered.commandworkers;
+
+import org.hibernate.search.engine.spi.SearchFactoryImplementor;
+import org.infinispan.query.clustered.QueryResponse;
+
+/**
+ * CQGetResultSize.
+ * 
+ * Get the result size of this query on current node
+ * 
+ * @author Israel Lacerra <israeldl@gmail.com>
+ * @since 5.1
+ */
+public class CQGetResultSize extends ClusteredQueryCommandWorker {
+
+   @Override
+   public QueryResponse perform() {
+      query.afterDeserialise((SearchFactoryImplementor) getSearchFactory());
+      query.queryDocumentExtractor();
+      int resultSize = query.queryResultSize();
+
+      QueryResponse queryResponse = new QueryResponse(resultSize);
+      return queryResponse;
+   }
+
+}",2011-09-07T11:43:18Z,469
"@@ -37,7 +37,8 @@ public class CQLazyFetcher extends ClusteredQueryCommandWorker {
    @Override
    public QueryResponse perform() {
       QueryBox box = getQueryBox();
-      return box.getValue(lazyQueryId, docIndex);
+      Object value = box.getValue(lazyQueryId, docIndex);
+      return new QueryResponse(value);
    }
 
 }",2011-09-07T11:43:18Z,470
"@@ -180,6 +180,11 @@ public void testList() throws ParseException {
          previousAge = person.getAge();
       }
    }
+   
+   public void testGetResultSizeList() throws ParseException {
+      populateCache();
+      assert cacheQuery.getResultSize() == 4 : cacheQuery.getResultSize();
+   }
 
    private void populateCache() throws ParseException {
       prepareTestData();",2011-09-07T11:43:18Z,344
"@@ -0,0 +1,85 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.query.blackbox;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeMethod;
+import org.testng.annotations.Test;
+import java.io.File;
+
+/**
+ * Run the basic set of operations with filesystem-based index storage in replicated mode
+ * with transactional caches.
+ *
+ * The default FSDirectory implementation for non Windows systems should be NIOFSDirectory.
+ * SimpleFSDirectory implementation will be used on Windows.
+ *
+ * @author Martin Gencur
+ */
+@Test(groups = ""functional"", testName = ""query.blackbox.ClusteredCacheFSDirectoryTest"")
+public class ClusteredCacheFSDirectoryTest extends ClusteredCacheTest {
+
+   private String TMP_DIR;
+
+   @Override
+   protected void createCacheManagers() throws Exception {
+      addClusterEnabledCacheManager(buildCacheConfig(""index1""));
+      addClusterEnabledCacheManager(buildCacheConfig(""index2""));
+      waitForClusterToForm();
+      cache1 = cache(0);
+      cache2 = cache(1);
+   }
+
+   private ConfigurationBuilder buildCacheConfig(String indexName) {
+      ConfigurationBuilder cb = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, true);
+      cb.indexing()
+            .enable()
+            .indexLocalOnly(false) //index also changes originated on other nodes, the index is not shared
+            .addProperty(""default.directory_provider"", ""filesystem"")
+            .addProperty(""default.indexBase"", TMP_DIR + File.separator + indexName)
+            .addProperty(""lucene_version"", ""LUCENE_CURRENT"");
+      return cb;
+   }
+
+   @BeforeMethod
+   protected void setUpTempDir() {
+      TMP_DIR = TestingUtil.tmpDirectory(this);
+      new File(TMP_DIR).mkdirs();
+   }
+
+   @Override
+   @AfterMethod(alwaysRun = true)
+   protected void clearContent() throws Throwable {
+      try {
+         //first stop cache managers, then clear the index
+         super.clearContent();
+      } finally {
+         //delete the index otherwise it will mess up the index for next tests
+         TestingUtil.recursiveFileRemove(TMP_DIR);
+      }
+   }
+}",2013-04-23T12:45:35Z,471
"@@ -222,10 +222,10 @@ public void testRemoved() throws Exception {
 
       cache1.remove(key3);
 
-      queryParser = createQueryParser(""blurb"");
-      luceneQuery = queryParser.parse(""eats"");
-      cacheQuery = Search.getSearchManager(cache2).getQuery(luceneQuery);
       found = cacheQuery.list();
+      assert found.size() == 1;
+      assert found.contains(person2);
+      assert !found.contains(person3) : ""This should not contain object person3 anymore"";
    }
 
    public void testGetResultSize() throws Exception {",2013-04-23T12:45:35Z,472
"@@ -0,0 +1,75 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.query.blackbox;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeMethod;
+import org.testng.annotations.Test;
+import java.io.File;
+
+/**
+ * Run the basic set of operations with filesystem-based index storage.
+ * The default FSDirectory implementation for non Windows systems should be NIOFSDirectory.
+ * SimpleFSDirectory implementation will be used on Windows.
+ *
+ * @author Martin Gencur
+ */
+@Test(groups = ""functional"", testName = ""query.blackbox.LocalCacheFSDirectoryTest"")
+public class LocalCacheFSDirectoryTest extends LocalCacheTest {
+
+   private String TMP_DIR;
+
+   @Override
+   protected EmbeddedCacheManager createCacheManager() throws Exception {
+      ConfigurationBuilder cfg = getDefaultStandaloneCacheConfig(true);
+      cfg.indexing().enable()
+         .indexLocalOnly(false) //not meaningful
+         .addProperty(""default.directory_provider"", ""filesystem"")
+         .addProperty(""default.indexBase"", TMP_DIR + File.separator + ""index"")
+         .addProperty(""default.lucene_version"", ""LUCENE_CURRENT"");
+      return TestCacheManagerFactory.createCacheManager(cfg);
+   }
+
+   @BeforeMethod
+   protected void setUpTempDir() {
+      TMP_DIR = TestingUtil.tmpDirectory(this);
+      new File(TMP_DIR).mkdirs();
+   }
+
+   @Override
+   @AfterMethod(alwaysRun = true)
+   protected void destroyAfterMethod() {
+      try {
+         //first stop cache managers, then clear the index
+         super.destroyAfterMethod();
+      } finally {
+         //delete the index otherwise it will mess up the index for next tests
+         TestingUtil.recursiveFileRemove(TMP_DIR);
+      }
+   }
+}",2013-04-23T12:45:35Z,473
"@@ -93,9 +93,9 @@ public interface CacheQuery extends Iterable<Object> {
    FacetManager getFacetManager();
 
    /**
-    * Gets the integer number of results.
+    * Gets the total number of results matching the query, ignoring pagination (firstResult, maxResult).
     *
-    * @return integer number of results.
+    * @return total number of results.
     */
    int getResultSize();
 ",2013-03-04T17:20:26Z,474
"@@ -48,7 +48,7 @@ public LazyIterator(HSQuery hSearchQuery, QueryResultLoader resultLoader, int fe
       super(resultLoader, fetchSize);
       this.extractor = hSearchQuery.queryDocumentExtractor(); //triggers actual Lucene search
       this.index = extractor.getFirstIndex();
-      this.max = hSearchQuery.queryResultSize() - 1;
+      this.max = extractor.getMaxIndex();
    }
 
    @Override",2013-03-04T17:20:26Z,475
"@@ -397,16 +397,8 @@ public void testLazyIteratorWithOffset() throws ParseException {
       Query luceneQuery = queryParser.parse(""Eats"");
       CacheQuery cacheQuery = Search.getSearchManager(cache).getQuery(luceneQuery).firstResult(1);
 
-      ResultIterator found = cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.LAZY));
-
-      int count = 0;
-      //noinspection UnusedDeclaration
-      while(found.hasNext()) {
-          count++;
-          found.next();
-      }
-
-      assert (count == 2);
+      ResultIterator iterator = cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.LAZY));
+      Assert.assertEquals(2, countElements(iterator));
    }
 
    @Test(expectedExceptions = IllegalArgumentException.class)
@@ -461,16 +453,8 @@ public void testSearchKeyTransformer() throws ParseException {
 
       CacheQuery cacheQuery = manager.getQuery(luceneQuery);
 
-
-      ResultIterator found = cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.LAZY));
-
-      int counter = 0;
-      while(found.hasNext()) {
-         found.next();
-         counter++;
-      }
-
-      AssertJUnit.assertEquals(3, counter);
+      ResultIterator iterator = cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.LAZY));
+      Assert.assertEquals(3, countElements(iterator));
    }
 
    @Test(expectedExceptions = IllegalArgumentException.class)
@@ -507,6 +491,31 @@ public void testGetResultSize() throws ParseException {
       assert cacheQuery.getResultSize() == 1;
    }
 
+   public void testMaxResults() throws ParseException {
+      loadTestingData();
+
+      queryParser = createQueryParser(""blurb"");
+      Query luceneQuery = queryParser.parse(""eats"");
+
+      CacheQuery cacheQuery = Search.getSearchManager(cache).getQuery(luceneQuery)
+            .maxResults(1);
+
+      Assert.assertEquals(3, cacheQuery.getResultSize());   // NOTE: getResultSize() ignores pagination (maxResults, firstResult)
+      Assert.assertEquals(1, cacheQuery.list().size());
+      Assert.assertEquals(1, countElements(cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.EAGER))));
+      Assert.assertEquals(1, countElements(cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.LAZY))));
+      Assert.assertEquals(1, countElements(cacheQuery.iterator()));
+   }
+
+   private int countElements(ResultIterator iterator) {
+      int count = 0;
+      while (iterator.hasNext()) {
+         iterator.next();
+         count++;
+      }
+      return count;
+   }
+
    public void testClear() {
       loadTestingData();
 ",2013-03-04T17:20:26Z,476
"@@ -51,6 +51,7 @@ public void setUp() throws Exception {
       super.setUp();
 
       extractor = mock(DocumentExtractor.class);
+      when(extractor.getMaxIndex()).thenReturn(entityInfos.size() - 1);
       when(extractor.extract(anyInt())).thenAnswer(new Answer<EntityInfo>() {
          @Override
          public EntityInfo answer(InvocationOnMock invocation) throws Throwable {
@@ -61,7 +62,6 @@ public EntityInfo answer(InvocationOnMock invocation) throws Throwable {
 
       HSQuery hsQuery = mock(HSQuery.class);
       when(hsQuery.queryDocumentExtractor()).thenReturn(extractor);
-      when(hsQuery.queryResultSize()).thenReturn(entityInfos.size());
 
       iterator = new LazyIterator(hsQuery, new EntityLoader(cache, new KeyTransformationHandler()), getFetchSize());
    }",2013-03-04T17:20:26Z,477
"@@ -107,7 +107,13 @@ protected final Object handleNonTxWriteCommand(InvocationContext ctx, DataWriteC
                log.tracef(""Skipping the replication of the conditional command as it did not succeed on primary owner (%s)."", command);
                return returnValue;
             }
+            // Make sure we can't have a loop with 2 nodes both thinking they are the primary owners
+            // See https://issues.jboss.org/browse/ISPN-3281
+            int oldTopologyId = command.getTopologyId();
+            command.setTopologyId(stateTransferManager.getCacheTopology().getTopologyId());
             rpcManager.invokeRemotely(recipientGenerator.generateRecipients(), command, rpcManager.getDefaultRpcOptions(isSync));
+            // We don't need a finally block, because unsuccessful commands are not forwarded anyway
+            command.setTopologyId(oldTopologyId);
          }
          return returnValue;
       } else {
@@ -121,10 +127,7 @@ protected final Object handleNonTxWriteCommand(InvocationContext ctx, DataWriteC
             List<Address> recipients = recipientGenerator.generateRecipients();
             log.tracef(""I'm the primary owner, sending the command to all (%s) the recipients in order to be applied."", recipients);
             // check if a single owner has been configured and the target for the key is the local address
-            boolean isSingleOwnerAndLocal = cacheConfiguration.clustering().hash().numOwners() == 1
-                  && recipients != null
-                  && recipients.size() == 1
-                  && recipients.get(0).equals(rpcManager.getTransport().getAddress());
+            boolean isSingleOwnerAndLocal = cacheConfiguration.clustering().hash().numOwners() == 1;
             if (!isSingleOwnerAndLocal) {
                rpcManager.invokeRemotely(recipients, command, rpcManager.getDefaultRpcOptions(isSync));
             }",2013-07-04T08:19:25Z,478
"@@ -55,9 +55,8 @@ public ClusteredCacheQueryImpl(Query luceneQuery, SearchFactoryIntegrator search
             ExecutorService asyncExecutor, AdvancedCache cache, Class<?>... classes) {
       super(luceneQuery, searchFactory, cache, classes);
       this.asyncExecutor = asyncExecutor;
-      hSearchQuery = searchFactory.createHSQuery()
-            .luceneQuery(luceneQuery)
-            .targetedEntities(Arrays.asList(classes));
+      hSearchQuery = searchFactory.createHSQuery().luceneQuery(luceneQuery)
+               .targetedEntities(Arrays.asList(classes));
    }
 
    @Override
@@ -69,7 +68,15 @@ public CacheQuery sort(Sort sort) {
    @Override
    public int getResultSize() {
       if (resultSize == null) {
-         // TODO fetch result size
+         ClusteredQueryCommand command = ClusteredQueryCommand.getResultSize(hSearchQuery, cache);
+
+         ClusteredQueryInvoker invoker = new ClusteredQueryInvoker(cache, asyncExecutor);
+         List<QueryResponse> responses = invoker.broadcast(command);
+
+         resultSize = 0;
+         for (QueryResponse response : responses) {
+            resultSize += response.getResultSize();
+         }
       }
       return resultSize;
    }
@@ -79,7 +86,7 @@ public QueryIterator iterator(int fetchSize) throws SearchException {
       ClusteredQueryCommand command = ClusteredQueryCommand
                .createEagerIterator(hSearchQuery, cache);
 
-      HashMap<UUID, ClusteredTopDocs> topDocsResponses = treatIteratorResponses(command);
+      HashMap<UUID, ClusteredTopDocs> topDocsResponses = broadcastQuery(command);
       DistributedIterator it = new DistributedIterator(sort, fetchSize, this.resultSize,
                topDocsResponses, cache);
 
@@ -89,26 +96,23 @@ public QueryIterator iterator(int fetchSize) throws SearchException {
    @Override
    public QueryIterator lazyIterator(int fetchSize) {
       UUID lazyItId = UUID.randomUUID();
+      ClusteredQueryCommand command = ClusteredQueryCommand.createLazyIterator(hSearchQuery, cache,
+               lazyItId);
 
-      ClusteredQueryCommand command = ClusteredQueryCommand.createLazyIterator(
-               hSearchQuery, cache, lazyItId);
-
-      HashMap<UUID, ClusteredTopDocs> topDocsResponses = treatIteratorResponses(command);
+      HashMap<UUID, ClusteredTopDocs> topDocsResponses = broadcastQuery(command);
       DistributedLazyIterator it = new DistributedLazyIterator(sort, fetchSize, this.resultSize,
                lazyItId, topDocsResponses, asyncExecutor, cache);
 
       return it;
    }
 
-   private HashMap<UUID, ClusteredTopDocs> treatIteratorResponses(ClusteredQueryCommand command) {
+   private HashMap<UUID, ClusteredTopDocs> broadcastQuery(ClusteredQueryCommand command) {
       ClusteredQueryInvoker invoker = new ClusteredQueryInvoker(cache, asyncExecutor);
 
-      HashMap<UUID, ClusteredTopDocs> topDocsResponses = null;
+      HashMap<UUID, ClusteredTopDocs> topDocsResponses = new HashMap<UUID, ClusteredTopDocs>();
       int resultSize = 0;
       List<QueryResponse> responses = invoker.broadcast(command);
 
-      topDocsResponses = new HashMap<UUID, ClusteredTopDocs>();
-
       for (Object response : responses) {
          QueryResponse queryResponse = (QueryResponse) response;
          ClusteredTopDocs topDocs = new ClusteredTopDocs(queryResponse.getTopDocs(),",2011-09-07T11:43:18Z,464
"@@ -71,12 +71,20 @@ private ClusteredQueryCommand(ClusteredQueryCommandType type, String cacheName)
    }
 
    public static ClusteredQueryCommand createLazyIterator(HSQuery query, Cache cache, UUID id) {
-      ClusteredQueryCommand clQuery = new ClusteredQueryCommand(ClusteredQueryCommandType.CREATE_LAZY_ITERATOR, cache.getName());
+      ClusteredQueryCommand clQuery = new ClusteredQueryCommand(
+               ClusteredQueryCommandType.CREATE_LAZY_ITERATOR, cache.getName());
       clQuery.query = query;
       clQuery.lazyQueryId = id;
       return clQuery;
    }
 
+   public static ClusteredQueryCommand getResultSize(HSQuery query, Cache cache) {
+      ClusteredQueryCommand clQuery = new ClusteredQueryCommand(
+               ClusteredQueryCommandType.GET_RESULT_SIZE, cache.getName());
+      clQuery.query = query;
+      return clQuery;
+   }
+
    public static ClusteredQueryCommand createEagerIterator(HSQuery query, Cache cache) {
       ClusteredQueryCommand clQuery = new ClusteredQueryCommand(
                ClusteredQueryCommandType.CREATE_EAGER_ITERATOR, cache.getName());
@@ -121,7 +129,8 @@ public Object perform(InvocationContext context) throws Throwable {
    }
 
    public QueryResponse perform(Cache cache) {
-      ClusteredQueryCommandWorker worker = commandType.getCommand(cache, query, lazyQueryId, docIndex);
+      ClusteredQueryCommandWorker worker = commandType.getCommand(cache, query, lazyQueryId,
+               docIndex);
       return worker.perform();
    }
 ",2011-09-07T11:43:18Z,388
"@@ -27,6 +27,7 @@
 import org.infinispan.Cache;
 import org.infinispan.query.clustered.commandworkers.CQCreateEagerQuery;
 import org.infinispan.query.clustered.commandworkers.CQCreateLazyQuery;
+import org.infinispan.query.clustered.commandworkers.CQGetResultSize;
 import org.infinispan.query.clustered.commandworkers.CQKillLazyIterator;
 import org.infinispan.query.clustered.commandworkers.CQLazyFetcher;
 import org.infinispan.query.clustered.commandworkers.ClusteredQueryCommandWorker;
@@ -47,11 +48,11 @@ public ClusteredQueryCommandWorker getNewInstance() {
       }
    },
    CREATE_EAGER_ITERATOR() {
-	      @Override
-	      public ClusteredQueryCommandWorker getNewInstance() {
-	         return new CQCreateEagerQuery();
-	      }
-	   },
+      @Override
+      public ClusteredQueryCommandWorker getNewInstance() {
+         return new CQCreateEagerQuery();
+      }
+   },
    DESTROY_LAZY_ITERATOR() {
       @Override
       public ClusteredQueryCommandWorker getNewInstance() {
@@ -63,6 +64,12 @@ public ClusteredQueryCommandWorker getNewInstance() {
       public ClusteredQueryCommandWorker getNewInstance() {
          return new CQLazyFetcher();
       }
+   },
+   GET_RESULT_SIZE() {
+      @Override
+      public ClusteredQueryCommandWorker getNewInstance() {
+         return new CQGetResultSize();
+      }
    };
 
    protected abstract ClusteredQueryCommandWorker getNewInstance();",2011-09-07T11:43:18Z,388
"@@ -41,7 +41,7 @@
 import org.infinispan.remoting.transport.Address;
 
 /**
- * Invoke a CusteredQueryCommand on the cluster, including on own node. 
+ * Invoke a CusteredQueryCommand on the cluster, including on own node.
  * 
  * @author Israel Lacerra <israeldl@gmail.com>
  * @author Sanne Grinovero <sanne@infinispan.org> (C) 2011 Red Hat Inc.
@@ -65,46 +65,53 @@ public class ClusteredQueryInvoker {
       this.myAddress = localCacheInstance.getAdvancedCache().getRpcManager().getAddress();
    }
 
+   /**
+    * Retrieves the value (using doc index) in a remote query instance
+    * 
+    * @param doc
+    *           Doc index of the value on remote query
+    * @param address
+    *           Address of the node who has the value
+    * @param queryId
+    *           Id of the query
+    * @return The value of index doc of the query with queryId on node at address
+    */
    public Object getValue(int doc, Address address, UUID queryId) {
       ClusteredQueryCommand clusteredQuery = ClusteredQueryCommand.retrieveKeyFromLazyQuery(
                localCacheInstance, queryId, doc);
 
       if (address.equals(myAddress)) {
          Future<QueryResponse> localResponse = localInvoke(clusteredQuery);
          try {
-            return localResponse.get();
+            return localResponse.get().getFetchedValue();
          } catch (InterruptedException e) {
-            //FIXME
-            e.printStackTrace();
-            return null;
+            throw new SearchException(""interrupted while searching locally"", e);
          } catch (ExecutionException e) {
-            //FIXME
-            e.printStackTrace();
-            return null;
+            throw new SearchException(""Exception while searching locally"", e);
          }
       } else {
-
          List<Address> addresss = new ArrayList<Address>(1);
          addresss.add(address);
 
-         try {
-            Map<Address, Response> responses = rpcManager.invokeRemotely(addresss, clusteredQuery,
-                     ResponseMode.SYNCHRONOUS, 10000);
-            List<QueryResponse> objects = cast(responses);
-            return objects.get(0);
-         } catch (Exception e) {
-            // FIXME
-            e.printStackTrace();
-            return null;
-         }
+         Map<Address, Response> responses = rpcManager.invokeRemotely(addresss, clusteredQuery,
+                  ResponseMode.SYNCHRONOUS, 10000);
+         List<QueryResponse> objects = cast(responses);
+         return objects.get(0).getFetchedValue();
       }
    }
 
+   /**
+    * Broadcast this ClusteredQueryCommand to all cluster nodes. The command will be also invoked on
+    * local node.
+    * 
+    * @param clusteredQuery
+    * @return A list with all responses
+    */
    public List<QueryResponse> broadcast(ClusteredQueryCommand clusteredQuery) {
       // invoke on own node
       Future<QueryResponse> localResponse = localInvoke(clusteredQuery);
       Map<Address, Response> responses = rpcManager.invokeRemotely(null, clusteredQuery,
-            ResponseMode.SYNCHRONOUS, 10000);
+               ResponseMode.SYNCHRONOUS, 10000);
 
       List<QueryResponse> objects = cast(responses);
       final QueryResponse localReturnValue;
@@ -120,7 +127,8 @@ public List<QueryResponse> broadcast(ClusteredQueryCommand clusteredQuery) {
    }
 
    private Future<QueryResponse> localInvoke(ClusteredQueryCommand clusteredQuery) {
-      ClusteredQueryCallable clusteredQueryCallable = new ClusteredQueryCallable(clusteredQuery, localCacheInstance);
+      ClusteredQueryCallable clusteredQueryCallable = new ClusteredQueryCallable(clusteredQuery,
+               localCacheInstance);
       return asyncExecutor.submit(clusteredQueryCallable);
    }
 
@@ -132,15 +140,15 @@ private List<QueryResponse> cast(Map<Address, Response> responses) {
             QueryResponse response = (QueryResponse) ((SuccessfulResponse) resp).getResponseValue();
             objects.add(response);
          } else {
-            //TODO
+            throw new SearchException(""Unexpected response: "" + resp);
          }
       }
 
       return objects;
    }
 
    /**
-    * Created to call a ClusteredQueryCommand on own node. 
+    * Created to call a ClusteredQueryCommand on own node.
     * 
     * @author Israel Lacerra <israeldl@gmail.com>
     * @since 5.1",2011-09-07T11:43:18Z,465
"@@ -30,10 +30,15 @@
 import org.infinispan.query.clustered.commandworkers.QueryExtractorUtil;
 
 /**
- * Each node in the cluster has a QueryBox instance. The QueryBox keep the active lazy iterators on
- * the cluster, so it can return values for the queries in a ""lazy"" way.
+ * Each node in the cluster has a QueryBox instance. The QueryBox keep the active lazy iterators
+ * (actually it keeps the DocumentExtractor of the searches) on the cluster, so it can return values
+ * for the queries in a ""lazy"" way.
  * 
- * EVICTION: Currently the QueryBox keeps the last BOX_LIMIT used... probably there is a better way.
+ * When a DistributedLazyIterator is created, every nodes creates a DocumentExtractor and register
+ * it in your own QueryBox. So, the LazyIterator can fetch the values in a lazy way.
+ * 
+ * EVICTION: Currently the QueryBox keeps the last BOX_LIMIT DocumentExtractor used... probably
+ * there is a better way.
  * 
  * @author Israel Lacerra <israeldl@gmail.com>
  * @since 5.1
@@ -52,11 +57,21 @@ public class QueryBox {
    // this id will be sent with the responses to rpcs
    private final UUID myId = UUID.randomUUID();
 
-   private AdvancedCache<Object,QueryResponse> cache;
+   // the local cache instance
+   private AdvancedCache cache;
 
    public org.infinispan.util.logging.Log log;
 
-   public QueryResponse getValue(UUID queryUuid, int docIndex) {
+   /**
+    * Get the ""docIndex"" value on the correct DocumentExtractor
+    * 
+    * @param queryUuid
+    *           The queryId, so we can get the correct DocumentExtractor
+    * @param docIndex
+    *           value index in the DocumentExtractor
+    * @return
+    */
+   public Object getValue(UUID queryUuid, int docIndex) {
       touch(queryUuid);
 
       DocumentExtractor extractor = queries.get(queryUuid);
@@ -76,13 +91,27 @@ private void touch(UUID id) {
       }
    }
 
+   /**
+    * Kill the query (DocumentExtractor)
+    * 
+    * @param id
+    *           The id of the query
+    */
    public void kill(UUID id) {
       DocumentExtractor extractor = queries.remove(id);
       ageOrderedQueries.remove(id);
       if (extractor != null)
          extractor.close();
    }
 
+   /**
+    * Register a query (DocumentExtractor), so we can lazily load the results.
+    * 
+    * @param id
+    *           The id of the query
+    * @param extractor
+    *           The query
+    */
    public synchronized void put(UUID id, DocumentExtractor extractor) {
       synchronized (ageOrderedQueries) {
          if (ageOrderedQueries.size() >= BOX_LIMIT) {
@@ -94,6 +123,11 @@ public synchronized void put(UUID id, DocumentExtractor extractor) {
       queries.put(id, extractor);
    }
 
+   /**
+    * Id of this QueryBox
+    * 
+    * @return
+    */
    public UUID getMyId() {
       return myId;
    }",2011-09-07T11:43:18Z,466
"@@ -39,18 +39,28 @@ public class QueryResponse implements Serializable {
 
    private static final long serialVersionUID = -2113889511877165954L;
 
-   private final UUID nodeUUID;
+   private UUID nodeUUID;
 
    private TopDocs topDocs;
 
    private Address address;
 
    private Integer resultSize;
-   
+
+   private Object fetchedValue;
+
    public TopDocs getTopDocs() {
       return topDocs;
    }
 
+   public QueryResponse(Object value) {
+      fetchedValue = value;
+   }
+
+   public QueryResponse(int resultSize) {
+      this.resultSize = resultSize;
+   }
+
    public QueryResponse(TopDocs topDocs, UUID nodeUUid, int resultSize) {
       this.nodeUUID = nodeUUid;
       this.topDocs = topDocs;
@@ -73,4 +83,8 @@ public Address getAddress() {
       return address;
    }
 
+   public Object getFetchedValue() {
+      return fetchedValue;
+   }
+
 }
\ No newline at end of file",2011-09-07T11:43:18Z,467
"@@ -30,8 +30,8 @@
 /**
  * CQCreateLazyQuery.
  * 
- * Creates a lazy iterator of a distributed query.
- * 
+ * Creates a DocumentExtractor and register it on the node QueryBox.
+ *  
  * @author Israel Lacerra <israeldl@gmail.com>
  * @since 5.1
  */
@@ -44,9 +44,12 @@ public QueryResponse perform() {
       int resultSize = query.queryResultSize();
 
       QueryBox box = getQueryBox();
+      
+      // registering...
       box.put(lazyQueryId, extractor);
+      
+      // returning the QueryResponse 
       TopDocs topDocs = extractor.getTopDocs();
-
       QueryResponse queryResponse = new QueryResponse(topDocs, box.getMyId(), resultSize);
       queryResponse.setAddress(cache.getAdvancedCache().getRpcManager().getAddress());
       return queryResponse;",2011-09-07T11:43:18Z,468
"@@ -0,0 +1,47 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2011, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.query.clustered.commandworkers;
+
+import org.hibernate.search.engine.spi.SearchFactoryImplementor;
+import org.infinispan.query.clustered.QueryResponse;
+
+/**
+ * CQGetResultSize.
+ * 
+ * Get the result size of this query on current node
+ * 
+ * @author Israel Lacerra <israeldl@gmail.com>
+ * @since 5.1
+ */
+public class CQGetResultSize extends ClusteredQueryCommandWorker {
+
+   @Override
+   public QueryResponse perform() {
+      query.afterDeserialise((SearchFactoryImplementor) getSearchFactory());
+      query.queryDocumentExtractor();
+      int resultSize = query.queryResultSize();
+
+      QueryResponse queryResponse = new QueryResponse(resultSize);
+      return queryResponse;
+   }
+
+}",2011-09-07T11:43:18Z,469
"@@ -37,7 +37,8 @@ public class CQLazyFetcher extends ClusteredQueryCommandWorker {
    @Override
    public QueryResponse perform() {
       QueryBox box = getQueryBox();
-      return box.getValue(lazyQueryId, docIndex);
+      Object value = box.getValue(lazyQueryId, docIndex);
+      return new QueryResponse(value);
    }
 
 }",2011-09-07T11:43:18Z,470
"@@ -180,6 +180,11 @@ public void testList() throws ParseException {
          previousAge = person.getAge();
       }
    }
+   
+   public void testGetResultSizeList() throws ParseException {
+      populateCache();
+      assert cacheQuery.getResultSize() == 4 : cacheQuery.getResultSize();
+   }
 
    private void populateCache() throws ParseException {
       prepareTestData();",2011-09-07T11:43:18Z,344
"@@ -0,0 +1,85 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.query.blackbox;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeMethod;
+import org.testng.annotations.Test;
+import java.io.File;
+
+/**
+ * Run the basic set of operations with filesystem-based index storage in replicated mode
+ * with transactional caches.
+ *
+ * The default FSDirectory implementation for non Windows systems should be NIOFSDirectory.
+ * SimpleFSDirectory implementation will be used on Windows.
+ *
+ * @author Martin Gencur
+ */
+@Test(groups = ""functional"", testName = ""query.blackbox.ClusteredCacheFSDirectoryTest"")
+public class ClusteredCacheFSDirectoryTest extends ClusteredCacheTest {
+
+   private String TMP_DIR;
+
+   @Override
+   protected void createCacheManagers() throws Exception {
+      addClusterEnabledCacheManager(buildCacheConfig(""index1""));
+      addClusterEnabledCacheManager(buildCacheConfig(""index2""));
+      waitForClusterToForm();
+      cache1 = cache(0);
+      cache2 = cache(1);
+   }
+
+   private ConfigurationBuilder buildCacheConfig(String indexName) {
+      ConfigurationBuilder cb = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, true);
+      cb.indexing()
+            .enable()
+            .indexLocalOnly(false) //index also changes originated on other nodes, the index is not shared
+            .addProperty(""default.directory_provider"", ""filesystem"")
+            .addProperty(""default.indexBase"", TMP_DIR + File.separator + indexName)
+            .addProperty(""lucene_version"", ""LUCENE_CURRENT"");
+      return cb;
+   }
+
+   @BeforeMethod
+   protected void setUpTempDir() {
+      TMP_DIR = TestingUtil.tmpDirectory(this);
+      new File(TMP_DIR).mkdirs();
+   }
+
+   @Override
+   @AfterMethod(alwaysRun = true)
+   protected void clearContent() throws Throwable {
+      try {
+         //first stop cache managers, then clear the index
+         super.clearContent();
+      } finally {
+         //delete the index otherwise it will mess up the index for next tests
+         TestingUtil.recursiveFileRemove(TMP_DIR);
+      }
+   }
+}",2013-04-23T12:45:35Z,471
"@@ -222,10 +222,10 @@ public void testRemoved() throws Exception {
 
       cache1.remove(key3);
 
-      queryParser = createQueryParser(""blurb"");
-      luceneQuery = queryParser.parse(""eats"");
-      cacheQuery = Search.getSearchManager(cache2).getQuery(luceneQuery);
       found = cacheQuery.list();
+      assert found.size() == 1;
+      assert found.contains(person2);
+      assert !found.contains(person3) : ""This should not contain object person3 anymore"";
    }
 
    public void testGetResultSize() throws Exception {",2013-04-23T12:45:35Z,472
"@@ -0,0 +1,75 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.query.blackbox;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeMethod;
+import org.testng.annotations.Test;
+import java.io.File;
+
+/**
+ * Run the basic set of operations with filesystem-based index storage.
+ * The default FSDirectory implementation for non Windows systems should be NIOFSDirectory.
+ * SimpleFSDirectory implementation will be used on Windows.
+ *
+ * @author Martin Gencur
+ */
+@Test(groups = ""functional"", testName = ""query.blackbox.LocalCacheFSDirectoryTest"")
+public class LocalCacheFSDirectoryTest extends LocalCacheTest {
+
+   private String TMP_DIR;
+
+   @Override
+   protected EmbeddedCacheManager createCacheManager() throws Exception {
+      ConfigurationBuilder cfg = getDefaultStandaloneCacheConfig(true);
+      cfg.indexing().enable()
+         .indexLocalOnly(false) //not meaningful
+         .addProperty(""default.directory_provider"", ""filesystem"")
+         .addProperty(""default.indexBase"", TMP_DIR + File.separator + ""index"")
+         .addProperty(""default.lucene_version"", ""LUCENE_CURRENT"");
+      return TestCacheManagerFactory.createCacheManager(cfg);
+   }
+
+   @BeforeMethod
+   protected void setUpTempDir() {
+      TMP_DIR = TestingUtil.tmpDirectory(this);
+      new File(TMP_DIR).mkdirs();
+   }
+
+   @Override
+   @AfterMethod(alwaysRun = true)
+   protected void destroyAfterMethod() {
+      try {
+         //first stop cache managers, then clear the index
+         super.destroyAfterMethod();
+      } finally {
+         //delete the index otherwise it will mess up the index for next tests
+         TestingUtil.recursiveFileRemove(TMP_DIR);
+      }
+   }
+}",2013-04-23T12:45:35Z,473
"@@ -93,9 +93,9 @@ public interface CacheQuery extends Iterable<Object> {
    FacetManager getFacetManager();
 
    /**
-    * Gets the integer number of results.
+    * Gets the total number of results matching the query, ignoring pagination (firstResult, maxResult).
     *
-    * @return integer number of results.
+    * @return total number of results.
     */
    int getResultSize();
 ",2013-03-04T17:20:26Z,474
"@@ -48,7 +48,7 @@ public LazyIterator(HSQuery hSearchQuery, QueryResultLoader resultLoader, int fe
       super(resultLoader, fetchSize);
       this.extractor = hSearchQuery.queryDocumentExtractor(); //triggers actual Lucene search
       this.index = extractor.getFirstIndex();
-      this.max = hSearchQuery.queryResultSize() - 1;
+      this.max = extractor.getMaxIndex();
    }
 
    @Override",2013-03-04T17:20:26Z,475
"@@ -397,16 +397,8 @@ public void testLazyIteratorWithOffset() throws ParseException {
       Query luceneQuery = queryParser.parse(""Eats"");
       CacheQuery cacheQuery = Search.getSearchManager(cache).getQuery(luceneQuery).firstResult(1);
 
-      ResultIterator found = cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.LAZY));
-
-      int count = 0;
-      //noinspection UnusedDeclaration
-      while(found.hasNext()) {
-          count++;
-          found.next();
-      }
-
-      assert (count == 2);
+      ResultIterator iterator = cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.LAZY));
+      Assert.assertEquals(2, countElements(iterator));
    }
 
    @Test(expectedExceptions = IllegalArgumentException.class)
@@ -461,16 +453,8 @@ public void testSearchKeyTransformer() throws ParseException {
 
       CacheQuery cacheQuery = manager.getQuery(luceneQuery);
 
-
-      ResultIterator found = cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.LAZY));
-
-      int counter = 0;
-      while(found.hasNext()) {
-         found.next();
-         counter++;
-      }
-
-      AssertJUnit.assertEquals(3, counter);
+      ResultIterator iterator = cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.LAZY));
+      Assert.assertEquals(3, countElements(iterator));
    }
 
    @Test(expectedExceptions = IllegalArgumentException.class)
@@ -507,6 +491,31 @@ public void testGetResultSize() throws ParseException {
       assert cacheQuery.getResultSize() == 1;
    }
 
+   public void testMaxResults() throws ParseException {
+      loadTestingData();
+
+      queryParser = createQueryParser(""blurb"");
+      Query luceneQuery = queryParser.parse(""eats"");
+
+      CacheQuery cacheQuery = Search.getSearchManager(cache).getQuery(luceneQuery)
+            .maxResults(1);
+
+      Assert.assertEquals(3, cacheQuery.getResultSize());   // NOTE: getResultSize() ignores pagination (maxResults, firstResult)
+      Assert.assertEquals(1, cacheQuery.list().size());
+      Assert.assertEquals(1, countElements(cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.EAGER))));
+      Assert.assertEquals(1, countElements(cacheQuery.iterator(new FetchOptions().fetchMode(FetchOptions.FetchMode.LAZY))));
+      Assert.assertEquals(1, countElements(cacheQuery.iterator()));
+   }
+
+   private int countElements(ResultIterator iterator) {
+      int count = 0;
+      while (iterator.hasNext()) {
+         iterator.next();
+         count++;
+      }
+      return count;
+   }
+
    public void testClear() {
       loadTestingData();
 ",2013-03-04T17:20:26Z,476
"@@ -51,6 +51,7 @@ public void setUp() throws Exception {
       super.setUp();
 
       extractor = mock(DocumentExtractor.class);
+      when(extractor.getMaxIndex()).thenReturn(entityInfos.size() - 1);
       when(extractor.extract(anyInt())).thenAnswer(new Answer<EntityInfo>() {
          @Override
          public EntityInfo answer(InvocationOnMock invocation) throws Throwable {
@@ -61,7 +62,6 @@ public EntityInfo answer(InvocationOnMock invocation) throws Throwable {
 
       HSQuery hsQuery = mock(HSQuery.class);
       when(hsQuery.queryDocumentExtractor()).thenReturn(extractor);
-      when(hsQuery.queryResultSize()).thenReturn(entityInfos.size());
 
       iterator = new LazyIterator(hsQuery, new EntityLoader(cache, new KeyTransformationHandler()), getFetchSize());
    }",2013-03-04T17:20:26Z,477
"@@ -125,15 +125,23 @@ protected final Object handleNonTxWriteCommand(InvocationContext ctx, DataWriteC
          Object returnValue = invokeNextInterceptor(ctx, command);
          Address primaryOwner = cdl.getPrimaryOwner(command.getKey());
          if (primaryOwner.equals(rpcManager.getAddress())) {
+            if (command.isConditional() && !command.isSuccessful()) {
+               log.tracef(""Skipping the replication of the conditional command as it did not succeed on primary owner (%s)."", command);
+               return returnValue;
+            }
             rpcManager.invokeRemotely(recipientGenerator.generateRecipients(), command, rpcManager.getDefaultRpcOptions(isSync));
          }
          return returnValue;
       } else {
          Address primaryOwner = cdl.getPrimaryOwner(command.getKey());
          if (primaryOwner.equals(rpcManager.getAddress())) {
+            Object result = invokeNextInterceptor(ctx, command);
+            if (command.isConditional() && !command.isSuccessful()) {
+               log.tracef(""Skipping the replication of the conditional command as it did not succeed on primary owner (%s)."", command);
+               return result;
+            }
             List<Address> recipients = recipientGenerator.generateRecipients();
             log.tracef(""I'm the primary owner, sending the command to all (%s) the recipients in order to be applied."", recipients);
-            Object result = invokeNextInterceptor(ctx, command);
             // check if a single owner has been configured and the target for the key is the local address
             boolean isSingleOwnerAndLocal = cacheConfiguration.clustering().hash().numOwners() == 1
                   && recipients != null
@@ -146,11 +154,10 @@ protected final Object handleNonTxWriteCommand(InvocationContext ctx, DataWriteC
          } else {
             log.tracef(""I'm not the primary owner, so sending the command to the primary owner(%s) in order to be forwarded"", primaryOwner);
             Object localResult = invokeNextInterceptor(ctx, command);
+            boolean isSyncForwarding = isSync || isNeedReliableReturnValues(command);
             Map<Address, Response> addressResponseMap = rpcManager.invokeRemotely(Collections.singletonList(primaryOwner), command,
-                  rpcManager.getDefaultRpcOptions(isSync));
-            //the remote node always returns the correct result, but if we're async, then our best option is the local
-            //node. That might be incorrect though.
-            if (!isSync) return localResult;
+                  rpcManager.getDefaultRpcOptions(isSyncForwarding));
+            if (!isSyncForwarding) return localResult;
 
             return getResponseFromPrimaryOwner(primaryOwner, addressResponseMap);
          }",2013-05-30T08:24:59Z,478
"@@ -23,22 +23,11 @@
 
 package org.infinispan.distribution;
 
-import org.infinispan.test.ReplListener;
 import org.testng.annotations.Test;
 
 @Test(groups = ""functional"", testName = ""distribution.AsyncAPINonTxAsyncDistTest"")
 public class AsyncAPINonTxAsyncDistTest extends AsyncAPINonTxSyncDistTest {
 
-   private ReplListener rl;
-   private ReplListener rlNoTx;
-
-   @Override
-   protected void createCacheManagers() throws Throwable {
-      super.createCacheManagers();
-      rl = new ReplListener(cache(1), true);
-      rlNoTx = new ReplListener(cache(1, ""noTx""), true);
-   }
-
    @Override
    protected boolean sync() {
       return false;",2013-05-30T08:24:59Z,479
"@@ -57,10 +57,4 @@ public boolean isSatisfied() throws Exception {
          assert Util.safeEquals((real = c2.getAdvancedCache().withFlags(SKIP_REMOTE_LOOKUP).get(k)), v) : ""Error on cache 2.  Expected "" + v + "" and got "" + real;
       }
    }
-
-   @Test(enabled = false, description = ""Disabled due to https://issues.jboss.org/browse/ISPN-3133"")
-   @Override
-   public void testAsyncMethods() throws Exception {
-      super.testAsyncMethods();
-   }
 }",2013-05-30T08:24:59Z,480
"@@ -23,15 +23,18 @@
 
 package org.infinispan.replication;
 
+import org.infinispan.AdvancedCache;
 import org.infinispan.Cache;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.remoting.transport.Address;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.data.Key;
 import org.infinispan.util.Util;
 import org.testng.annotations.Test;
 
 import java.util.Collections;
+import java.util.concurrent.ExecutionException;
 import java.util.concurrent.Future;
 
 @Test(groups=""functional"", testName = ""replication.AsyncAPINonTxSyncReplTest"")
@@ -66,7 +69,6 @@ public void testAsyncMethods() throws Exception {
       final String v_null = ""v_nonexistent"";
       final Key key = new Key(""k"", true);
 
-      // put
       log.trace(""Before put"");
       Future<String> f = c1.putAsync(key, v);
       assert f != null;
@@ -77,7 +79,7 @@ public void testAsyncMethods() throws Exception {
       log.info(""*** Finished allowing serialization on key, checking future if cancelled"");
       assert !f.isCancelled();
       log.info(""*** Future not cancelled, checking future.get()"");
-      assert f.get() == null;
+      assertFutureValue(f, null);
       assert f.isDone();
       assertOnAllCaches(key, v, c1, c2);
 
@@ -88,7 +90,7 @@ public void testAsyncMethods() throws Exception {
       assert c2.get(key).equals(v);
       key.allowSerialization();
       assert !f.isCancelled();
-      assert f.get().equals(v);
+      assertFutureValue(f, v);
       assert f.isDone();
       assertOnAllCaches(key, v2, c1, c2);
 
@@ -107,8 +109,10 @@ public void testAsyncMethods() throws Exception {
       f = c1.putIfAbsentAsync(key, v4);
       assert f != null;
       assert c2.get(key).equals(v3);
+      if (!isLockOwner(c1, key))
+         key.allowSerialization();
       assert !f.isCancelled();
-      assert f.get().equals(v3);
+      assertFutureValue(f, v3);
       assert f.isDone();
       assertOnAllCaches(key, v3, c1, c2);
 
@@ -119,7 +123,7 @@ public void testAsyncMethods() throws Exception {
       assert c2.get(key).equals(v3);
       key.allowSerialization();
       assert !f.isCancelled();
-      assert f.get().equals(v3);
+      assertFutureValue(f, v3);
       assert f.isDone();
       assertOnAllCaches(key, null, c1, c2);
 
@@ -129,34 +133,38 @@ public void testAsyncMethods() throws Exception {
       assert !f.isDone();
       key.allowSerialization();
       assert !f.isCancelled();
-      assert f.get() == null;
+      assertFutureValue(f, null);
       assert f.isDone();
       assertOnAllCaches(key, v4, c1, c2);
 
-      log.trace(""Before removeAsync"");
+      log.trace(""Before conditional removeAsync"");
       Future<Boolean> f3 = c1.removeAsync(key, v_null);
       assert f3 != null;
       assert !f3.isCancelled();
-      assert f3.get().equals(false);
+      if (!isLockOwner(c1, key))
+         key.allowSerialization();
+      assertFutureValue(f3, Boolean.FALSE);
       assert f3.isDone();
       assertOnAllCaches(key, v4, c1, c2);
 
-      log.trace(""Before removeAsync2"");
+      log.trace(""Before conditional removeAsync2"");
       f3 = c1.removeAsync(key, v4);
       assert f3 != null;
       assert !f3.isDone();
       assert c2.get(key).equals(v4);
       key.allowSerialization();
       assert !f3.isCancelled();
-      assert f3.get().equals(true);
+      assertFutureValue(f3, true);
       assert f3.isDone();
       assertOnAllCaches(key, null, c1, c2);
 
       log.trace(""Before replaceAsync"");
       f = c1.replaceAsync(key, v5);
       assert f != null;
       assert !f.isCancelled();
-      assert f.get() == null;
+      if (!isLockOwner(c1, key))
+         key.allowSerialization();
+      assertFutureValue(f, null);
       assert f.isDone();
       assertOnAllCaches(key, null, c1, c2);
 
@@ -180,15 +188,17 @@ public boolean isSatisfied() throws Exception {
       assert c2.get(key).equals(v);
       key.allowSerialization();
       assert !f.isCancelled();
-      assert f.get().equals(v);
+      assertFutureValue(f, v);
       assert f.isDone();
       assertOnAllCaches(key, v5, c1, c2);
 
       log.trace(""Before replaceAsync3"");
       f3 = c1.replaceAsync(key, v_null, v6);
       assert f3 != null;
       assert !f3.isCancelled();
-      assert f3.get().equals(false);
+      if (!isLockOwner(c1, key))
+         key.allowSerialization();
+      assertFutureValue(f3, false);
       assert f3.isDone();
       assertOnAllCaches(key, v5, c1, c2);
 
@@ -199,11 +209,14 @@ public boolean isSatisfied() throws Exception {
       assert c2.get(key).equals(v5);
       key.allowSerialization();
       assert !f3.isCancelled();
-      assert f3.get().equals(true);
+      assertFutureValue(f3, true);
       assert f3.isDone();
       assertOnAllCaches(key, v6, c1, c2);
    }
 
+   protected void assertFutureValue(Future f, Object value) throws ExecutionException, InterruptedException {
+      assert Util.safeEquals(f.get(), value);
+   }
 
    protected void assertOnAllCaches(final Key k, final String v, final Cache c1, final Cache c2) {
       if (sync()) {
@@ -223,4 +236,12 @@ public boolean isSatisfied() throws Exception {
    protected void resetListeners() {
    }
 
+   private boolean isLockOwner(Cache cache, Object key) {
+      AdvancedCache advancedCache = cache.getAdvancedCache();
+      Address primaryLocation = advancedCache.getDistributionManager().getPrimaryLocation(key);
+      Address localAddress = advancedCache.getRpcManager().getAddress();
+      boolean isOwner = primaryLocation.equals(localAddress);
+      log.tracef(""Is %s lock owner? %s"", localAddress, isOwner);
+      return isOwner;
+   }
 }",2013-05-30T08:24:59Z,481
"@@ -164,11 +164,11 @@ public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) thr
       return visitRemoveCommand(ctx, command);
    }
 
-   protected void commitContextEntries(InvocationContext ctx) {
+   protected void commitContextEntries(final InvocationContext ctx) {
       Set<Map.Entry<Object, CacheEntry>> entries = ctx.getLookedUpEntries().entrySet();
       Iterator<Map.Entry<Object, CacheEntry>> it = entries.iterator();
-      Log log = getLog();
-      boolean trace = log.isTraceEnabled();
+      final Log log = getLog();
+      final boolean trace = log.isTraceEnabled();
       if (trace) log.tracef(""Number of entries in context: %s"", entries.size());
       while (it.hasNext()) {
          Map.Entry<Object, CacheEntry> e = it.next();
@@ -177,7 +177,12 @@ protected void commitContextEntries(InvocationContext ctx) {
             commitContextEntry(entry, ctx, ctx.hasFlag(Flag.SKIP_OWNERSHIP_CHECK));
             if (trace) log.tracef(""Committed entry %s"", entry);
          } else {
-            if (trace) log.tracef(""Entry for key %s is null or not changed(%s), not calling commitUpdate"", e.getKey(), entry);
+            if (trace) {
+               if (entry==null)
+                  log.tracef(""Entry for key %s is null : not calling commitUpdate"", e.getKey());
+               else
+                  log.tracef(""Entry for key %s is not changed(%s): not calling commitUpdate"", e.getKey(), entry);
+            }
          }
       }
    }",2012-01-05T22:45:29Z,399
"@@ -22,10 +22,6 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.context.InvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
@@ -95,24 +91,6 @@ public interface DistributionManager {
     */
    Set<Address> locateAll(Collection<Object> keys); //todo [anistor] this has to take an additional parameter that specifies if the lookup is for read or write
 
-   /**
-    * Transforms a cache entry so it is marked for L1 rather than the primary cache data structure.  This should be done
-    * if it is deemed that the entry is targeted for L1 storage rather than storage in the primary data container.
-    *
-    * @param entry entry to transform
-    */
-   void transformForL1(CacheEntry entry);
-
-   /**
-    * Retrieves a cache entry from a remote source.  Would typically involve an RPC call using a {@link org.infinispan.commands.remote.ClusteredGetCommand}
-    * and some form of quorum of responses if the responses returned are inconsistent - often the case if there is a
-    * rehash in progress, involving nodes that the key maps to.
-    *
-    * @param key key to look up
-    * @return an internal cache entry, or null if it cannot be located
-    */
-   InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception;
-
    /**
     * Retrieves the consistent hash instance currently in use, an instance of the configured ConsistentHash
     * class (which defaults to {@link org.infinispan.distribution.ch.DefaultConsistentHash}.",2013-03-07T23:03:04Z,60
"@@ -22,31 +22,16 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.commands.CommandsFactory;
-import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.commands.remote.ClusteredGetCommand;
-import org.infinispan.configuration.cache.Configuration;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalCacheValue;
-import org.infinispan.context.InvocationContext;
-import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.jmx.annotations.Parameter;
 import org.infinispan.statetransfer.StateTransferManager;
-import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
-import org.infinispan.remoting.responses.Response;
-import org.infinispan.remoting.responses.SuccessfulResponse;
-import org.infinispan.remoting.rpc.ResponseFilter;
-import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
@@ -70,9 +55,7 @@ public class DistributionManagerImpl implements DistributionManager {
    private static final boolean trace = log.isTraceEnabled();
 
    // Injected components
-   private Configuration configuration;
    private RpcManager rpcManager;
-   private CommandsFactory cf;
    private StateTransferManager stateTransferManager;
 
    /**
@@ -82,11 +65,8 @@ public DistributionManagerImpl() {
    }
 
    @Inject
-   public void init(Configuration configuration, RpcManager rpcManager, CommandsFactory cf,
-                    StateTransferManager stateTransferManager) {
-      this.configuration = configuration;
+   public void init(RpcManager rpcManager, StateTransferManager stateTransferManager) {
       this.rpcManager = rpcManager;
-      this.cf = cf;
       this.stateTransferManager = stateTransferManager;
    }
 
@@ -147,39 +127,6 @@ public Set<Address> locateAll(Collection<Object> keys) {
       return getConsistentHash().locateAllOwners(keys);
    }
 
-   @Override
-   public void transformForL1(CacheEntry entry) {
-      if (entry.getLifespan() < 0 || entry.getLifespan() > configuration.clustering().l1().lifespan())
-         entry.setLifespan(configuration.clustering().l1().lifespan());
-   }
-
-   @Override
-   public InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception {
-      GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
-      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
-
-      List<Address> targets = new ArrayList<Address>(getReadConsistentHash().locateOwners(key));
-      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
-      targets.retainAll(rpcManager.getTransport().getMembers());
-      ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, getAddress());
-      Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
-                                                                   configuration.clustering().sync().replTimeout(), true, filter);
-
-      if (!responses.isEmpty()) {
-         for (Response r : responses.values()) {
-            if (r instanceof SuccessfulResponse) {
-               InternalCacheValue cacheValue = (InternalCacheValue) ((SuccessfulResponse) r).getResponseValue();
-               return cacheValue.toInternalCacheEntry(key);
-            }
-         }
-      }
-
-      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
-      // Otherwise our get command might be processed by the old owners after they have invalidated their data
-      // and we'd return a null even though the key exists on
-      return null;
-   }
-
    @Override
    public ConsistentHash getConsistentHash() {
       return getWriteConsistentHash();",2013-03-07T23:03:04Z,60
"@@ -0,0 +1,120 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.interceptors;
+
+import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.FlagAffectedCommand;
+import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.factories.annotations.Inject;
+import org.infinispan.factories.annotations.Start;
+import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.statetransfer.StateTransferManager;
+import org.infinispan.util.concurrent.locks.LockManager;
+
+/**
+ * Base class for replication and distribution interceptors.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+public abstract class ClusteringInterceptor extends BaseRpcInterceptor {
+
+   protected CommandsFactory cf;
+   protected EntryFactory entryFactory;
+   protected LockManager lockManager;
+   protected DataContainer dataContainer;
+   protected StateTransferManager stateTransferManager;
+   protected boolean needReliableReturnValues;
+
+   @Inject
+   public void injectDependencies(CommandsFactory cf, EntryFactory entryFactory,
+                                  LockManager lockManager, DataContainer dataContainer,
+                                  StateTransferManager stateTransferManager) {
+      this.cf = cf;
+      this.entryFactory = entryFactory;
+      this.lockManager = lockManager;
+      this.dataContainer = dataContainer;
+      this.stateTransferManager = stateTransferManager;
+   }
+
+   @Start
+   public void configure() {
+      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
+   }
+
+   protected boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
+      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+   }
+
+   protected boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
+      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
+            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
+         return false;
+      }
+      boolean shouldFetchFromRemote = false;
+      CacheEntry entry = ctx.lookupEntry(command.getKey());
+      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
+         Object key = command.getKey();
+         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
+         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
+         if (!shouldFetchFromRemote && getLog().isTraceEnabled()) {
+            getLog().tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s) or is in L1. Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
+         }
+      }
+      return shouldFetchFromRemote;
+   }
+
+   /**
+    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
+    * <pre>
+    * - node A (owner, tx originator) does a successful replace
+    * - the actual value changes
+    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
+    *   B (check is performed at commit time).
+    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
+    * </pre>
+    */
+   protected boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return ctx.isOriginLocal() && command.isSuccessful();
+   }
+
+   /**
+    * Retrieves a cache entry from a remote source.  Would typically involve an RPC call using a {@link org.infinispan.commands.remote.ClusteredGetCommand}
+    * and some form of quorum of responses if the responses returned are inconsistent - often the case if there is a
+    * rehash in progress, involving nodes that the key maps to.
+    *
+    * @param key key to look up
+    * @return an internal cache entry, or null if it cannot be located
+    */
+   protected abstract InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception;
+}",2013-03-07T23:03:04Z,482
"@@ -22,7 +22,6 @@
  */
 package org.infinispan.interceptors;
 
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.AbstractDataCommand;
@@ -35,30 +34,21 @@
 import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configurations;
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.EntryFactory;
-import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.InternalCacheValue;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.ch.ConsistentHash;
-import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
-import org.infinispan.interceptors.base.BaseRpcInterceptor;
 import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
 import org.infinispan.remoting.responses.Response;
 import org.infinispan.remoting.responses.SuccessfulResponse;
 import org.infinispan.remoting.rpc.ResponseFilter;
 import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.jgroups.SuspectException;
-import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.xa.GlobalTransaction;
-import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -71,16 +61,8 @@
  * @author Bela Ban
  * @since 4.0
  */
-public class ReplicationInterceptor extends BaseRpcInterceptor {
+public class ReplicationInterceptor extends ClusteringInterceptor {
 
-   private CommandsFactory cf;
-
-   private EntryFactory entryFactory;
-   private LockManager lockManager;
-   private DataContainer dataContainer;
-   private StateTransferManager stateTransferManager;
-
-   private boolean needReliableReturnValues;
    private boolean isPessimisticCache;
 
    private static final Log log = LogFactory.getLog(ReplicationInterceptor.class);
@@ -91,19 +73,9 @@ protected Log getLog() {
       return log;
    }
 
-   @Inject
-   public void init(CommandsFactory cf, EntryFactory entryFactory, DataContainer dataContainer, LockManager lockManager, StateTransferManager stateTransferManager) {
-      this.cf = cf;
-      this.entryFactory = entryFactory;
-      this.dataContainer = dataContainer;
-      this.lockManager = lockManager;
-      this.stateTransferManager = stateTransferManager;
-   }
-
    @Start
    public void start() {
       isPessimisticCache = cacheConfiguration.transaction().lockingMode() == LockingMode.PESSIMISTIC;
-      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
    }
 
    @Override
@@ -180,44 +152,6 @@ public Object visitLockControlCommand(TxInvocationContext ctx, LockControlComman
       return retVal;
    }
 
-   private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] clarify usage of this flag in REPL mode
-            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
-         return false;
-      }
-      boolean shouldFetchFromRemote = false;
-      CacheEntry entry = ctx.lookupEntry(command.getKey());
-      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
-         Object key = command.getKey();
-         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
-         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
-         if (!shouldFetchFromRemote) {
-            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s). Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
-         }
-      }
-      return shouldFetchFromRemote;
-   }
-
-   private boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
-      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
-   }
-
-   /**
-    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
-    * <pre>
-    * - node A (owner, tx originator) does a successful replace
-    * - the actual value changes
-    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
-    *   B (check is performed at commit time).
-    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
-    * </pre>
-    */
-   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
-      return ctx.isOriginLocal() && command.isSuccessful();
-   }
-
    /**
     * This method retrieves an entry from a remote cache.
     * <p/>
@@ -242,7 +176,7 @@ private Object remoteGet(InvocationContext ctx, Object key, FlagAffectedCommand
          acquireRemoteLock = isWrite && isPessimisticCache && !txContext.getAffectedKeys().contains(key);
       }
       // attempt a remote lookup
-      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command.getFlags());
+      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
 
       if (acquireRemoteLock) {
          ((TxInvocationContext) ctx).addAffectedKey(key);
@@ -265,9 +199,9 @@ protected Address getPrimaryOwner() {
       return stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0);
    }
 
-   private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, Set<Flag> flags) {
+   protected InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) {
       GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
-      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, flags, acquireRemoteLock, gtx);
+      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
 
       List<Address> targets = Collections.singletonList(getPrimaryOwner());
       ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
@@ -289,7 +223,7 @@ private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContex
    private Object localGet(InvocationContext ctx, Object key, boolean isWrite, FlagAffectedCommand command) throws Throwable {
       InternalCacheEntry ice = dataContainer.get(key);
       if (ice != null) {
-         if (!ctx.replaceValue(key, ice.getValue()))  {
+         if (!ctx.replaceValue(key, ice.getValue())) {
             if (isWrite)
                lockAndWrap(ctx, key, ice, command);
             else",2013-03-07T23:03:04Z,103
"@@ -22,34 +22,32 @@
  */
 package org.infinispan.interceptors.distribution;
 
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.write.PutMapCommand;
 import org.infinispan.commands.write.RemoveCommand;
 import org.infinispan.commands.write.ReplaceCommand;
 import org.infinispan.commands.write.WriteCommand;
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.EntryFactory;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.container.entries.InternalCacheValue;
 import org.infinispan.context.InvocationContext;
-import org.infinispan.distribution.DataLocality;
+import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.DistributionManager;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
-import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.interceptors.ClusteringInterceptor;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
+import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.responses.SuccessfulResponse;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
-import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 
 /**
  * Base class for distribution of entries across a cluster.
@@ -60,14 +58,11 @@
  * @author Dan Berindei <dan@infinispan.org>
  * @since 4.0
  */
-public abstract class BaseDistributionInterceptor extends BaseRpcInterceptor {
+public abstract class BaseDistributionInterceptor extends ClusteringInterceptor {
+
    protected DistributionManager dm;
-   protected CommandsFactory cf;
-   protected DataContainer dataContainer;
-   protected EntryFactory entryFactory;
-   protected LockManager lockManager;
+
    protected ClusteringDependentLogic cdl;
-   private boolean needReliableReturnValues;
 
    private static final Log log = LogFactory.getLog(BaseDistributionInterceptor.class);
 
@@ -77,42 +72,36 @@ protected Log getLog() {
    }
 
    @Inject
-   public void injectDependencies(DistributionManager distributionManager,
-                                  CommandsFactory cf, DataContainer dataContainer, EntryFactory entryFactory,
-                                  LockManager lockManager, ClusteringDependentLogic cdl) {
+   public void injectDependencies(DistributionManager distributionManager, ClusteringDependentLogic cdl) {
       this.dm = distributionManager;
-      this.cf = cf;
-      this.dataContainer = dataContainer;
-      this.entryFactory = entryFactory;
-      this.lockManager = lockManager;
       this.cdl = cdl;
    }
 
-   @Start
-   public void configure() {
-      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
-   }
-
-   protected boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      boolean shouldFetchFromRemote = false;
-      final CacheEntry entry;
-      if (!command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            && !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES)
-            && ((entry = ctx.lookupEntry(command.getKey())) == null || entry.isNull() || entry.isLockPlaceholder())) {
-         Object key = command.getKey();
-         DataLocality locality = dm.getReadConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key) ? DataLocality.LOCAL : DataLocality.NOT_LOCAL;
-         shouldFetchFromRemote = ctx.isOriginLocal() && !locality.isLocal() && !dataContainer.containsKey(key);
-         if (!shouldFetchFromRemote) {
-            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s), or is in L1.  Owners are %s"", key, rpcManager.getAddress(), dm.locate(key));
+   @Override
+   protected InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception {
+      GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
+      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
+
+      List<Address> targets = new ArrayList<Address>(stateTransferManager.getCacheTopology().getReadConsistentHash().locateOwners(key));
+      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
+      targets.retainAll(rpcManager.getTransport().getMembers());
+      ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
+      Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
+            cacheConfiguration.clustering().sync().replTimeout(), true, filter);
+
+      if (!responses.isEmpty()) {
+         for (Response r : responses.values()) {
+            if (r instanceof SuccessfulResponse) {
+               InternalCacheValue cacheValue = (InternalCacheValue) ((SuccessfulResponse) r).getResponseValue();
+               return cacheValue.toInternalCacheEntry(key);
+            }
          }
       }
-      return shouldFetchFromRemote;
-   }
 
-   protected boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
-      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
+      // Otherwise our get command might be processed by the old owners after they have invalidated their data
+      // and we'd return a null even though the key exists on
+      return null;
    }
 
    @Override
@@ -157,9 +146,9 @@ interface RecipientGenerator extends KeyGenerator {
    }
 
    class SingleKeyRecipientGenerator implements RecipientGenerator {
-      final Object key;
-      final Set<Object> keys;
-      List<Address> recipients = null;
+      private final Object key;
+      private final Set<Object> keys;
+      private List<Address> recipients = null;
 
       SingleKeyRecipientGenerator(Object key) {
          this.key = key;
@@ -180,8 +169,8 @@ public Collection<Object> getKeys() {
 
    class MultipleKeysRecipientGenerator implements RecipientGenerator {
 
-      final Collection<Object> keys;
-      List<Address> recipients = null;
+      private final Collection<Object> keys;
+      private List<Address> recipients = null;
 
       MultipleKeysRecipientGenerator(Collection<Object> keys) {
          this.keys = keys;",2013-03-07T23:03:04Z,478
"@@ -140,7 +140,7 @@ private Object remoteGetBeforeWrite(InvocationContext ctx, Object key, FlagAffec
          if (trace) log.tracef(""Doing a remote get for key %s"", key);
 
          // attempt a remote lookup
-         InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, false, command);
+         InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, false, command);
          if (ice != null) {
             if (!ctx.replaceValue(key, ice.getValue())) {
                entryFactory.wrapEntryForPut(ctx, key, ice, false, command);
@@ -190,7 +190,7 @@ protected void handleRemoteWrite(InvocationContext ctx, WriteCommand command, Re
 
    private Object remoteGet(InvocationContext ctx, Object key, GetKeyValueCommand command) throws Throwable {
       if (trace) log.tracef(""Doing a remote get for key %s"", key);
-      InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, false, command);
+      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, false, command);
       command.setRemotelyFetchedValue(ice);
       if (ice != null) {
          return ice.getValue();",2013-03-07T23:03:04Z,483
"@@ -117,8 +117,9 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
     * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
     * </pre>
     */
-   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
-      return ctx.isOriginLocal() && command.isSuccessful() && cacheConfiguration.transaction().lockingMode() == LockingMode.OPTIMISTIC && !useClusteredWriteSkewCheck;
+   protected boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return super.ignorePreviousValueOnBackup(command, ctx)
+          && cacheConfiguration.transaction().lockingMode() == LockingMode.OPTIMISTIC && !useClusteredWriteSkewCheck;
    }
 
    @Start
@@ -176,7 +177,6 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
       }
    }
 
-
    private void lockAndWrap(InvocationContext ctx, Object key, InternalCacheEntry ice, FlagAffectedCommand command) throws InterruptedException {
       boolean skipLocking = hasSkipLocking(command);
       long lockTimeout = getLockAcquisitionTimeout(command, skipLocking);
@@ -341,7 +341,7 @@ private Object remoteGetAndStoreInL1(InvocationContext ctx, Object key, boolean
             acquireRemoteLock = isWrite && isPessimisticCache && !txContext.getAffectedKeys().contains(key);
          }
          // attempt a remote lookup
-         InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
+         InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
 
          if (acquireRemoteLock) {
             ((TxInvocationContext) ctx).addAffectedKey(key);",2013-03-07T23:03:04Z,484
"@@ -324,7 +324,9 @@ public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipO
             boolean isForeignOwned = !skipOwnershipCheck && !localNodeIsOwner(entry.getKey());
             if (isForeignOwned && !entry.isRemoved()) {
                if (configuration.clustering().l1().enabled()) {
-                  dm.transformForL1(entry);
+                  // transform for L1
+                  if (entry.getLifespan() < 0 || entry.getLifespan() > configuration.clustering().l1().lifespan())
+                     entry.setLifespan(configuration.clustering().l1().lifespan());
                } else {
                   doCommit = false;
                }",2013-03-07T23:03:04Z,172
"@@ -45,8 +45,6 @@
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.concurrent.locks.LockManager;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
 import org.testng.annotations.Test;
@@ -67,8 +65,6 @@
 @Test(groups = ""functional"", testName = ""interceptors.ReplicationInterceptorTest"")
 public class ReplicationInterceptorTest {
 
-   private static final Log log = LogFactory.getLog(ReplicationInterceptorTest.class);
-
    public void testRemoteGetForGetKeyValueCommand() throws Throwable {
       ConfigurationBuilder cb = new ConfigurationBuilder();
       cb.clustering().cacheMode(CacheMode.REPL_SYNC);
@@ -114,7 +110,7 @@ public CacheTopology answer(InvocationOnMock invocation) {
             return cacheTopology;
          }
       });
-      replInterceptor.init(commandsFactory, entryFactory, dataContainer, lockManager, stateTransferManager);
+      replInterceptor.injectDependencies(commandsFactory, entryFactory, lockManager, dataContainer, stateTransferManager);
       RpcManager rpcManager = mock(RpcManager.class);
       Transport transport = mock(Transport.class);
       when(rpcManager.getAddress()).thenReturn(B);",2013-03-07T23:03:04Z,103
"@@ -238,8 +238,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
       TestingUtil.waitForRehashToComplete(cache(0), cache(2));
 
       // at this point state transfer is fully done
-      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.keySet());
-      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.keySet());
+      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.entrySet());
+      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.entrySet());
 
       if (op == Operation.CLEAR || op == Operation.REMOVE) {
          // caches should be empty. check that no keys were revived by an inconsistent state transfer
@@ -262,7 +262,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
             assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
 
             // check values were not overwritten with old values carried by state transfer
-            assertEquals(""after_st_"" + i, cache(0).get(i));
+            String expected = ""after_st_"" + i;
+            assertEquals(expected, cache(0).get(i));
             assertEquals(""after_st_"" + i, cache(2).get(i));
          }
       } else { // PUT_IF_ABSENT
@@ -278,8 +279,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
             }
             assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
 
-            assertEquals(""before_st_"" + i, cache(0).get(i));
-            assertEquals(""before_st_"" + i, cache(2).get(i));
+            String expected = ""before_st_"" + i;
+            assertEquals(expected, cache(0).get(i));
+            assertEquals(expected, cache(2).get(i));
          }
       }
    }",2013-03-07T23:03:04Z,485
"@@ -0,0 +1,99 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.atomic;
+
+import org.infinispan.marshall.AbstractExternalizer;
+import org.infinispan.marshall.Ids;
+
+import java.io.IOException;
+import java.io.ObjectInput;
+import java.io.ObjectOutput;
+import java.util.Collections;
+import java.util.Set;
+
+/**
+ * DeltaCompositeKey is the key guarding access to a specific entry in DeltaAware
+ */
+public final class DeltaCompositeKey {
+
+   private final Object deltaAwareValueKey;
+   private final Object entryKey;
+
+   public DeltaCompositeKey(Object deltaAwareValueKey, Object entryKey) {
+      if (deltaAwareValueKey == null || entryKey == null)
+         throw new IllegalArgumentException(""Keys cannot be null"");
+
+      this.deltaAwareValueKey = deltaAwareValueKey;
+      this.entryKey = entryKey;
+   }
+
+   public final Object getDeltaAwareValueKey() {
+      return deltaAwareValueKey;
+   }
+
+   @Override
+   public int hashCode() {
+      return 31 * deltaAwareValueKey.hashCode() + entryKey.hashCode();
+   }
+
+   @Override
+   public boolean equals(Object obj) {
+      if (this == obj) {
+         return true;
+      }
+      if (!(obj instanceof DeltaCompositeKey)) {
+         return false;
+      }
+      DeltaCompositeKey other = (DeltaCompositeKey) obj;
+      return deltaAwareValueKey.equals(other.deltaAwareValueKey) && entryKey.equals(other.entryKey);
+   }
+
+   @Override
+   public String toString() {
+      return ""DeltaCompositeKey[deltaAwareValueKey="" + deltaAwareValueKey + "", entryKey="" + entryKey + ']';
+   }
+
+   public static class DeltaCompositeKeyExternalizer extends AbstractExternalizer<DeltaCompositeKey> {
+
+      @Override
+      public void writeObject(ObjectOutput output, DeltaCompositeKey dck) throws IOException {
+         output.writeObject(dck.deltaAwareValueKey);
+         output.writeObject(dck.entryKey);
+      }
+
+      @Override
+      @SuppressWarnings(""unchecked"")
+      public DeltaCompositeKey readObject(ObjectInput unmarshaller) throws IOException, ClassNotFoundException {
+         Object deltaAwareValueKey = unmarshaller.readObject();
+         Object entryKey = unmarshaller.readObject();
+         return new DeltaCompositeKey(deltaAwareValueKey, entryKey);
+      }
+
+      @Override
+      public Integer getId() {
+         return Ids.DELTA_COMPOSITE_KEY;
+      }
+
+      @Override
+      public Set<Class<? extends DeltaCompositeKey>> getTypeClasses() {
+         return Collections.<Class<? extends DeltaCompositeKey>>singleton(DeltaCompositeKey.class);
+      }
+   }
+}",2013-06-07T13:29:12Z,486
"@@ -22,18 +22,14 @@
  */
 package org.infinispan.commands.write;
 
-import java.io.IOException;
-import java.io.ObjectInput;
-import java.io.ObjectOutput;
 import java.util.*;
 
 import org.infinispan.atomic.Delta;
+import org.infinispan.atomic.DeltaCompositeKey;
 import org.infinispan.commands.Visitor;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.lifecycle.ComponentStatus;
-import org.infinispan.marshall.AbstractExternalizer;
-import org.infinispan.marshall.Ids;
 
 
 /**
@@ -166,69 +162,4 @@ public boolean isConditional() {
       return false;
    }
 
-   /**
-    * DeltaCompositeKey is the key guarding access to a specific entry in DeltaAware
-    */
-   private static final class DeltaCompositeKey {
-
-      private final Object deltaAwareValueKey;
-      private final Object entryKey;
-
-      public DeltaCompositeKey(Object deltaAwareValueKey, Object entryKey) {
-         if (deltaAwareValueKey == null || entryKey == null)
-            throw new IllegalArgumentException(""Keys cannot be null"");
-
-         this.deltaAwareValueKey = deltaAwareValueKey;
-         this.entryKey = entryKey;
-      }
-
-      @Override
-      public int hashCode() {
-         return 31 * deltaAwareValueKey.hashCode() + entryKey.hashCode();
-      }
-
-      @Override
-      public boolean equals(Object obj) {
-         if (this == obj) {
-            return true;
-         }
-         if (!(obj instanceof DeltaCompositeKey)) {
-            return false;
-         }
-         DeltaCompositeKey other = (DeltaCompositeKey) obj;
-         return deltaAwareValueKey.equals(other.deltaAwareValueKey) && entryKey.equals(other.entryKey);
-      }
-
-      @Override
-      public String toString() {
-         return ""DeltaCompositeKey[deltaAwareValueKey="" + deltaAwareValueKey + "", entryKey="" + entryKey + ']';
-      }
-   }
-
-   public static class DeltaCompositeKeyExternalizer extends AbstractExternalizer<DeltaCompositeKey> {
-
-      @Override
-      public void writeObject(ObjectOutput output, DeltaCompositeKey dck) throws IOException {
-         output.writeObject(dck.deltaAwareValueKey);
-         output.writeObject(dck.entryKey);
-      }
-
-      @Override
-      @SuppressWarnings(""unchecked"")
-      public DeltaCompositeKey readObject(ObjectInput unmarshaller) throws IOException, ClassNotFoundException {
-         Object deltaAwareValueKey = unmarshaller.readObject();
-         Object entryKey = unmarshaller.readObject();
-         return new DeltaCompositeKey(deltaAwareValueKey, entryKey);
-      }
-
-      @Override
-      public Integer getId() {
-         return Ids.DELTA_COMPOSITE_KEY;
-      }
-
-      @Override
-      public Set<Class<? extends DeltaCompositeKey>> getTypeClasses() {
-         return Collections.<Class<? extends DeltaCompositeKey>>singleton(DeltaCompositeKey.class);
-      }
-   }
 }",2013-06-07T13:29:12Z,59
"@@ -19,6 +19,7 @@
 
 package org.infinispan.interceptors.distribution;
 
+import org.infinispan.atomic.DeltaCompositeKey;
 import org.infinispan.metadata.Metadata;
 import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.commands.control.LockControlCommand;
@@ -48,10 +49,10 @@
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
 import java.util.concurrent.Future;
-import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 
 /**
@@ -202,7 +203,16 @@ protected void lockAndWrap(InvocationContext ctx, Object key, InternalCacheEntry
    @Override
    public Object visitLockControlCommand(TxInvocationContext ctx, LockControlCommand command) throws Throwable {
       if (ctx.isOriginLocal()) {
-         final Collection<Address> affectedNodes = cdl.getOwners(command.getKeys());
+         //In Pessimistic mode, the delta composite keys were sent to the wrong owner and never locked.
+         ArrayList<Object> keyToCheckOwners = new ArrayList<Object>(command.getKeys().size());
+         for (Object key : command.getKeys()) {
+            if (key instanceof DeltaCompositeKey) {
+               keyToCheckOwners.add(((DeltaCompositeKey) key).getDeltaAwareValueKey());
+            } else {
+               keyToCheckOwners.add(key);
+            }
+         }
+         final Collection<Address> affectedNodes = cdl.getOwners(keyToCheckOwners);
          ((LocalTxInvocationContext) ctx).remoteLocksAcquired(affectedNodes == null ? dm.getConsistentHash().getMembers() : affectedNodes);
          log.tracef(""Registered remote locks acquired %s"", affectedNodes);
          rpcManager.invokeRemotely(affectedNodes, command, rpcManager.getDefaultRpcOptions(true, false));",2013-06-07T13:29:12Z,484
"@@ -23,6 +23,7 @@
 
 package org.infinispan.interceptors.locking;
 
+import org.infinispan.atomic.DeltaCompositeKey;
 import org.infinispan.commands.read.GetKeyValueCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
@@ -127,9 +128,13 @@ protected final Object invokeNextAndCommitIf1Pc(TxInvocationContext ctx, Prepare
     * the originator leaving the cluster (if recovery is disabled).
     */
    protected final void lockAndRegisterBackupLock(TxInvocationContext ctx, Object key, long lockTimeout, boolean skipLocking) throws InterruptedException {
-      if (cdl.localNodeIsPrimaryOwner(key)) {
+      //with DeltaCompositeKey, the locks should be acquired in the owner of the delta aware key.
+      Object keyToCheck = key instanceof DeltaCompositeKey ?
+            ((DeltaCompositeKey) key).getDeltaAwareValueKey() :
+            key;
+      if (cdl.localNodeIsPrimaryOwner(keyToCheck)) {
          lockKeyAndCheckOwnership(ctx, key, lockTimeout, skipLocking);
-      } else if (cdl.localNodeIsOwner(key)) {
+      } else if (cdl.localNodeIsOwner(keyToCheck)) {
          ctx.getCacheTransaction().addBackupLockForKey(key);
       }
    }",2013-06-07T13:29:12Z,131
"@@ -24,14 +24,14 @@
 package org.infinispan.marshall.jboss;
 
 import org.infinispan.CacheException;
+import org.infinispan.atomic.DeltaCompositeKey;
 import org.infinispan.metadata.EmbeddedMetadata;
 import org.infinispan.atomic.AtomicHashMap;
 import org.infinispan.atomic.AtomicHashMapDelta;
 import org.infinispan.atomic.ClearOperation;
 import org.infinispan.atomic.PutOperation;
 import org.infinispan.atomic.RemoveOperation;
 import org.infinispan.commands.RemoteCommandsFactory;
-import org.infinispan.commands.write.ApplyDeltaCommand;
 import org.infinispan.commons.hash.MurmurHash2;
 import org.infinispan.commons.hash.MurmurHash2Compat;
 import org.infinispan.commons.hash.MurmurHash3;
@@ -279,7 +279,7 @@ private void loadInternalMarshallables() {
       addInternalExternalizer(new MetadataTransientCacheValue.Externalizer());
       addInternalExternalizer(new MetadataTransientMortalCacheValue.Externalizer());
 
-      addInternalExternalizer(new ApplyDeltaCommand.DeltaCompositeKeyExternalizer());
+      addInternalExternalizer(new DeltaCompositeKey.DeltaCompositeKeyExternalizer());
       addInternalExternalizer(new AtomicHashMap.Externalizer());
       addInternalExternalizer(new Bucket.Externalizer(gcr));
       addInternalExternalizer(new AtomicHashMapDelta.Externalizer());",2013-06-07T13:29:12Z,174
"@@ -0,0 +1,263 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.atomic;
+
+import org.infinispan.commands.tx.PrepareCommand;
+import org.infinispan.commands.write.ApplyDeltaCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.distribution.DistributionTestHelper;
+import org.infinispan.distribution.MagicKey;
+import org.infinispan.interceptors.TxInterceptor;
+import org.infinispan.interceptors.base.BaseCustomInterceptor;
+import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.tx.dld.ControlledRpcManager;
+import org.infinispan.util.concurrent.locks.LockManager;
+import org.testng.Assert;
+import org.testng.annotations.Test;
+
+import javax.transaction.Transaction;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.Set;
+import java.util.concurrent.Callable;
+import java.util.concurrent.Future;
+
+/**
+ * @author Pedro Ruivo
+ * @since 5.3
+ */
+@Test(groups = ""functional"")
+public abstract class BaseAtomicMapLockingTest extends MultipleCacheManagersTest {
+
+   private static final int NUM_NODES = 3;
+   private static final String VALUE = ""value"";
+   private static final Object[] EMPTY_ARRAY = new Object[0];
+   private final boolean pessimistic;
+   private final CollectCompositeKeysInterceptor[] collectors = new CollectCompositeKeysInterceptor[NUM_NODES];
+   private final ControlledRpcManager[] rpcManagers = new ControlledRpcManager[NUM_NODES];
+   private Object ahmKey;
+   private Object fgahmKey;
+
+   protected BaseAtomicMapLockingTest(boolean pessimistic) {
+      this.pessimistic = pessimistic;
+   }
+
+   public final void testAtomicHasMapLockingOnLockOwner() throws Exception {
+      testAtomicHashMap(true);
+   }
+
+   public final void testAtomicHasMapLockingOnNonLockOwner() throws Exception {
+      testAtomicHashMap(false);
+   }
+
+   public final void testFineGrainedAtomicHashMapLockingOnLockOwner() throws Exception {
+      testFineGrainedAtomicHashMap(true);
+   }
+
+   public final void testFineGrainedAtomicHashMapLockingOnNonLockOwner() throws Exception {
+      testFineGrainedAtomicHashMap(false);
+   }
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      for (int i = 0; i < NUM_NODES; ++i) {
+         collectors[i] = new CollectCompositeKeysInterceptor();
+         ConfigurationBuilder builder = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+         builder.transaction().lockingMode(pessimistic ? LockingMode.PESSIMISTIC : LockingMode.OPTIMISTIC);
+         builder.customInterceptors().addInterceptor().interceptor(collectors[i])
+               .before(TxInterceptor.class);
+         builder.clustering().hash().numOwners(2);
+         addClusterEnabledCacheManager(builder);
+      }
+      waitForClusterToForm();
+      for (int i = 0; i < NUM_NODES; ++i) {
+         RpcManager rpcManager = TestingUtil.extractComponent(cache(i), RpcManager.class);
+         rpcManagers[i] = new ControlledRpcManager(rpcManager);
+         TestingUtil.replaceComponent(cache(i), RpcManager.class, rpcManagers[i], true);
+      }
+      ahmKey = new MagicKey(""AtomicHashMap"", cache(0));
+      fgahmKey = new MagicKey(""FineGrainedAtomicHashMap"", cache(0));
+   }
+
+   protected final void testAtomicHashMap(boolean executeOnLockOwner) throws Exception {
+      resetBeforeMethod();
+      final int txExecutor = executeOnLockOwner ? 0 : 1;
+      AtomicMap<Object, Object> map = AtomicMapLookup.getAtomicMap(cache(txExecutor), ahmKey);
+
+      tm(txExecutor).begin();
+      map.put(""key1"", VALUE);
+      map.put(""key2"", VALUE);
+      map.put(""key3"", VALUE);
+      final Transaction tx1 = tm(txExecutor).suspend();
+
+      if (pessimistic) {
+         rpcManagers[txExecutor].blockBefore(PrepareCommand.class);
+      } else {
+         rpcManagers[txExecutor].blockAfter(PrepareCommand.class);
+      }
+
+      Future<Boolean> txOutcome = fork(new Callable<Boolean>() {
+         @Override
+         public Boolean call() throws Exception {
+            try {
+               tm(txExecutor).resume(tx1);
+               tm(txExecutor).commit();
+               return Boolean.TRUE;
+            } catch (Exception e) {
+               return Boolean.FALSE;
+            }
+         }
+      });
+
+      try {
+         rpcManagers[txExecutor].waitForCommandToBlock();
+         assertKeysLocked(0, ahmKey);
+         assertKeysLocked(1, EMPTY_ARRAY);
+         assertKeysLocked(2, EMPTY_ARRAY);
+
+         rpcManagers[txExecutor].stopBlocking();
+         Assert.assertTrue(txOutcome.get());
+      } finally {
+         rpcManagers[txExecutor].stopBlocking();
+      }
+   }
+
+   protected final void testFineGrainedAtomicHashMap(boolean executeOnLockOwner) throws Exception {
+      resetBeforeMethod();
+      final int txExecutor = executeOnLockOwner ? 0 : 1;
+      FineGrainedAtomicMap<Object, Object> map = AtomicMapLookup.getFineGrainedAtomicMap(cache(txExecutor), fgahmKey);
+
+      boolean hasLocalKeys = false;
+      boolean hasRemoteKeys = false;
+      int keyIndex = 0;
+
+      tm(txExecutor).begin();
+      while (!hasLocalKeys || !hasRemoteKeys) {
+         map.put(""key"" + keyIndex++, VALUE);
+         //has composite keys mapped to the lock owner?
+         hasLocalKeys = hasKeyMappedTo(true, collectors[txExecutor].getCompositeKeys());
+         //has composite keys mapped to the non lock owner?
+         hasRemoteKeys = hasKeyMappedTo(false, collectors[txExecutor].getCompositeKeys());
+         //the locks are independent on where the composite keys are mapped to.
+      }
+      final Transaction tx1 = tm(txExecutor).suspend();
+
+      Assert.assertEquals(collectors[txExecutor].getCompositeKeys().size(), keyIndex,
+                          ""Wrong number of composite keys collected!"");
+      log.infof(""%s composite keys collected."", collectors[txExecutor].getCompositeKeys().size());
+
+      if (pessimistic) {
+         rpcManagers[txExecutor].blockBefore(PrepareCommand.class);
+      } else {
+         rpcManagers[txExecutor].blockAfter(PrepareCommand.class);
+      }
+
+      Future<Boolean> txOutcome = fork(new Callable<Boolean>() {
+         @Override
+         public Boolean call() throws Exception {
+            try {
+               tm(txExecutor).resume(tx1);
+               tm(txExecutor).commit();
+               return Boolean.TRUE;
+            } catch (Exception e) {
+               return Boolean.FALSE;
+            }
+         }
+      });
+
+      try {
+         rpcManagers[txExecutor].waitForCommandToBlock();
+         assertKeysLocked(0, collectors[txExecutor].getCompositeKeys().toArray());
+         assertKeysLocked(1, EMPTY_ARRAY);
+         assertKeysLocked(2, EMPTY_ARRAY);
+
+         rpcManagers[txExecutor].stopBlocking();
+         Assert.assertTrue(txOutcome.get());
+      } finally {
+         rpcManagers[txExecutor].stopBlocking();
+      }
+   }
+
+   protected void assertKeysLocked(int index, Object... keys) {
+      LockManager lockManager = lockManager(index);
+      Assert.assertNotNull(keys);
+      for (Object key : keys) {
+         Assert.assertTrue(lockManager.isLocked(key), key + "" is not locked in cache("" + index + "")."");
+      }
+   }
+
+   protected boolean hasKeyMappedTo(boolean toLockOwner, Collection<Object> keys) {
+      for (Object key : keys) {
+         boolean onLockOwner = DistributionTestHelper.isFirstOwner(cache(0), key);
+         if ((toLockOwner && onLockOwner) || (!toLockOwner && !onLockOwner)) {
+            return true;
+         }
+      }
+      return false;
+   }
+
+   private void resetBeforeMethod() {
+      for (int i = 0; i < NUM_NODES; ++i) {
+         if (collectors[i] != null) {
+            collectors[i].reset();
+         }
+         if (rpcManagers[i] != null) {
+            rpcManagers[i].stopBlocking();
+            rpcManagers[i].stopFailing();
+         }
+      }
+   }
+
+   private static class CollectCompositeKeysInterceptor extends BaseCustomInterceptor {
+
+      private final Set<Object> compositeKeys;
+
+      public CollectCompositeKeysInterceptor() {
+         compositeKeys = new HashSet<Object>();
+      }
+
+      @Override
+      public Object visitApplyDeltaCommand(InvocationContext ctx, ApplyDeltaCommand command) throws Throwable {
+         synchronized (compositeKeys) {
+            compositeKeys.addAll(Arrays.asList(command.getCompositeKeys()));
+         }
+         return invokeNextInterceptor(ctx, command);
+      }
+
+      public final void reset() {
+         synchronized (compositeKeys) {
+            compositeKeys.clear();
+         }
+      }
+
+      public final Collection<Object> getCompositeKeys() {
+         synchronized (compositeKeys) {
+            return new ArrayList<Object>(compositeKeys);
+         }
+      }
+   }
+}",2013-06-07T13:29:12Z,487
"@@ -0,0 +1,34 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.atomic;
+
+import org.testng.annotations.Test;
+
+/**
+ * @author Pedro Ruivo
+ * @since 5.3
+ */
+@Test(groups = ""functional"", testName = ""atomic.OptimisticTxAtomicLocking"")
+public class OptimisticTxAtomicLocking extends BaseAtomicMapLockingTest {
+
+   public OptimisticTxAtomicLocking() {
+      super(false);
+   }
+}",2013-06-07T13:29:12Z,488
"@@ -0,0 +1,34 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.atomic;
+
+import org.testng.annotations.Test;
+
+/**
+ * @author Pedro Ruivo
+ * @since 5.3
+ */
+@Test(groups = ""functional"", testName = ""atomic.PessimisticTxAtomicLocking"")
+public class PessimisticTxAtomicLocking extends BaseAtomicMapLockingTest {
+
+   public PessimisticTxAtomicLocking() {
+      super(true);
+   }
+}",2013-06-07T13:29:12Z,489
"@@ -69,20 +69,24 @@ public ControlledRpcManager(RpcManager realOne) {
 
    public void failFor(Class... filter) {
       this.failFilter = new HashSet<Class>(Arrays.asList(filter));
+      blockingLatch.open();
    }
 
    public void stopFailing() {
       this.failFilter = Collections.emptySet();
+      blockingLatch.open();
    }
 
    public void blockBefore(Class... filter) {
       this.blockBeforeFilter = new HashSet<Class>(Arrays.asList(filter));
       replicationLatch.close();
+      blockingLatch.close();
    }
 
    public void blockAfter(Class... filter) {
       this.blockAfterFilter = new HashSet<Class>(Arrays.asList(filter));
       replicationLatch.close();
+      blockingLatch.close();
    }
 
    public void stopBlocking() {
@@ -110,6 +114,7 @@ protected void waitForReplicationLatch(ReplicableCommand rpcCommand, Set<Class>
       }
 
       try {
+         blockingLatch.open();
          log.debugf(""Replication trigger called, waiting for latch to open."");
          replicationLatch.await();
          log.trace(""Replication latch opened, continuing."");",2013-06-07T13:29:12Z,490
"@@ -77,6 +77,7 @@ public class ClusterTopologyManagerImpl implements ClusterTopologyManager {
    private volatile boolean isShuttingDown;
    private volatile int viewId = -1;
    private final Object viewUpdateLock = new Object();
+   private final Object viewHandlingLock = new Object();
 
 
    private final ConcurrentMap<String, ClusterCacheStatus> cacheStatusMap = ConcurrentMapFactory.makeConcurrentMap();
@@ -216,46 +217,49 @@ public void handleRebalanceCompleted(String cacheName, Address node, int topolog
       }
    }
 
-   protected void handleNewView(List<Address> newMembers, boolean mergeView, int newViewId) {
-      // check to ensure this is not an older view
-      if (newViewId <= viewId) {
-         log.tracef(""Ignoring old cluster view notification: %s"", newViewId);
-         return;
-      }
-
-      log.tracef(""Received new cluster view: %s"", newViewId);
-      boolean becameCoordinator = !isCoordinator && transport.isCoordinator();
-      isCoordinator = transport.isCoordinator();
+   protected void handleNewView(List<Address> ignored, boolean mergeView, int newViewId) {
+      synchronized (viewHandlingLock) {
+         // check to ensure this is not an older view
+         if (newViewId <= viewId) {
+            log.tracef(""Ignoring old cluster view notification: %s"", newViewId);
+            return;
+         }
 
-      if ((isCoordinator && mergeView) || becameCoordinator) {
-         try {
-            Map<String, List<CacheTopology>> clusterCacheMap = recoverClusterStatus();
+         boolean becameCoordinator = !isCoordinator && transport.isCoordinator();
+         isCoordinator = transport.isCoordinator();
+         log.tracef(""Received new cluster view: %s, isCoordinator = %s, becameCoordinator = %s"", newViewId,
+               isCoordinator, becameCoordinator);
 
-            for (Map.Entry<String, List<CacheTopology>> e : clusterCacheMap.entrySet()) {
-               String cacheName = e.getKey();
-               List<CacheTopology> topologyList = e.getValue();
-               updateCacheStatusAfterMerge(cacheName, newMembers, topologyList);
+         if ((isCoordinator && mergeView) || becameCoordinator) {
+            try {
+               Map<String, List<CacheTopology>> clusterCacheMap = recoverClusterStatus(newViewId);
+
+               for (Map.Entry<String, List<CacheTopology>> e : clusterCacheMap.entrySet()) {
+                  String cacheName = e.getKey();
+                  List<CacheTopology> topologyList = e.getValue();
+                  updateCacheStatusAfterMerge(cacheName, transport.getMembers(), topologyList);
+               }
+            } catch (InterruptedException e) {
+               log.tracef(""Cluster state recovery interrupted because the coordinator is shutting down"");
+               // the CTMI has already stopped, no need to update the view id or notify waiters
+               return;
+            } catch (Exception e) {
+               // TODO Retry?
+               log.failedToRecoverClusterState(e);
+            }
+         } else if (isCoordinator) {
+            try {
+               updateClusterMembers(transport.getMembers());
+            } catch (Exception e) {
+               log.errorUpdatingMembersList(e);
             }
-         } catch (InterruptedException e) {
-            log.tracef(""Cluster state recovery interrupted because the coordinator is shutting down"");
-            // the CTMI has already stopped, no need to update the view id or notify waiters
-            return;
-         } catch (Exception e) {
-            // TODO Retry?
-            log.failedToRecoverClusterState(e);
-         }
-      } else if (isCoordinator) {
-         try {
-            updateClusterMembers(newMembers);
-         } catch (Exception e) {
-            log.errorUpdatingMembersList(e);
          }
-      }
 
-      synchronized (viewUpdateLock) {
          // update the view id last, so join requests from other nodes wait until we recovered existing members' info
-         viewId = newViewId;
-         viewUpdateLock.notifyAll();
+         synchronized (viewUpdateLock) {
+            viewId = newViewId;
+            viewUpdateLock.notifyAll();
+         }
       }
    }
 
@@ -298,9 +302,10 @@ public void updateCacheStatusAfterMerge(String cacheName, List<Address> clusterM
          }
 
          // We have added each node to the cache status when we received its status response
+         // Prune those that have left the cluster.
+         cacheStatus.updateClusterMembers(clusterMembers);
          List<Address> members = cacheStatus.getMembers();
          // Filter out any nodes that aren't members of the cluster any more
-         cacheStatus.updateClusterMembers(clusterMembers);
          if (currentCHUnion != null) {
             currentCHUnion = chFactory.updateMembers(currentCHUnion, members);
          }
@@ -407,10 +412,10 @@ private void endRebalance(String cacheName, ClusterCacheStatus cacheStatus) {
       }
    }
 
-   private HashMap<String, List<CacheTopology>> recoverClusterStatus() throws Exception {
+   private HashMap<String, List<CacheTopology>> recoverClusterStatus(int newViewId) throws Exception {
       log.debugf(""Recovering running caches in the cluster"");
       ReplicableCommand command = new CacheTopologyControlCommand(null,
-            CacheTopologyControlCommand.Type.GET_STATUS, transport.getAddress(), viewId);
+            CacheTopologyControlCommand.Type.GET_STATUS, transport.getAddress(), newViewId);
       Map<Address, Object> statusResponses = executeOnClusterSync(command, getGlobalTimeout(), false, false);
 
       HashMap<String, List<CacheTopology>> clusterCacheMap = new HashMap<String, List<CacheTopology>>();
@@ -590,13 +595,18 @@ private int getGlobalTimeout() {
       return (int) globalConfiguration.transport().distributedSyncTimeout();
    }
 
-   // need to recover existing caches asynchronously (in case we just became the coordinator)
-   @Listener(sync = false)
+   @Listener(sync = true)
    public class ClusterViewListener {
+      @SuppressWarnings(""unused"")
       @Merged
       @ViewChanged
       public void handleViewChange(final ViewChangedEvent e) {
-         handleNewView(e.getNewMembers(), e.isMergeView(), e.getViewId());
+         // need to recover existing caches asynchronously (in case we just became the coordinator)
+         asyncTransportExecutor.submit(new Runnable() {
+            public void run() {
+               handleNewView(e.getNewMembers(), e.isMergeView(), e.getViewId());
+            }
+         });
       }
    }
 }
\ No newline at end of file",2013-04-09T16:32:35Z,124
"@@ -24,16 +24,11 @@
 
 import java.util.ArrayList;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.List;
-import java.util.Map;
 import java.util.concurrent.Callable;
 import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
-import java.util.concurrent.locks.Condition;
-import java.util.concurrent.locks.Lock;
-import java.util.concurrent.locks.ReentrantLock;
 
 import org.infinispan.Cache;
 import org.infinispan.configuration.cache.CacheMode;
@@ -42,6 +37,7 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CheckPoint;
 import org.infinispan.test.fwk.CleanupAfterMethod;
 import org.infinispan.test.fwk.TransportFlags;
 import org.infinispan.topology.CacheTopology;
@@ -266,19 +262,20 @@ public void testClusterRecoveryWithRebalance() throws Exception {
             LocalTopologyManager.class);
       final CheckPoint checkpoint = new CheckPoint();
       LocalTopologyManager spyLocalTopologyManager = spy(localTopologyManager);
+      TestingUtil.replaceComponent(mergeCoordManager, LocalTopologyManager.class, spyLocalTopologyManager, true);
       doAnswer(new Answer<Object>() {
          @Override
          public Object answer(InvocationOnMock invocation) throws Throwable {
             int viewId = (Integer) invocation.getArguments()[2];
-            checkpoint.trigger(""rebalance"" + viewId);
+            checkpoint.trigger(""rebalance_"" + viewId);
             log.debugf(""Blocking the REBALANCE_START command on the merge coordinator"");
             checkpoint.awaitStrict(""merge"", 10, TimeUnit.SECONDS);
             return invocation.callRealMethod();
          }
       }).when(spyLocalTopologyManager).handleRebalance(eq(CACHE_NAME), any(CacheTopology.class), anyInt());
-      TestingUtil.replaceComponent(mergeCoordManager, LocalTopologyManager.class, spyLocalTopologyManager, true);
 
-      final EmbeddedCacheManager cm4 = addClusterEnabledCacheManager(defaultConfig, new TransportFlags().withFD(true).withMerge(true));
+      final EmbeddedCacheManager cm4 = addClusterEnabledCacheManager(defaultConfig,
+            new TransportFlags().withFD(true).withMerge(true));
       Future<Cache<Object,Object>> cacheFuture = fork(new Callable<Cache<Object, Object>>() {
          @Override
          public Cache<Object, Object> call() throws Exception {
@@ -287,7 +284,7 @@ public Cache<Object, Object> call() throws Exception {
       });
 
       log.debugf(""Waiting for the REBALANCE_START command to reach the merge coordinator"");
-      checkpoint.awaitStrict(""rebalance"" + (viewIdAfterSplit + 1), 10, TimeUnit.SECONDS);
+      checkpoint.awaitStrict(""rebalance_"" + (viewIdAfterSplit + 1), 10, TimeUnit.SECONDS);
 
       // merge the partitions
       log.debugf(""Merging the cluster partitions"");
@@ -313,83 +310,46 @@ public Cache<Object, Object> call() throws Exception {
 
       // Check that another node can join
       ConfigurationBuilder defaultConfig = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, false);
-      EmbeddedCacheManager cm5 = addClusterEnabledCacheManager(defaultConfig, new TransportFlags().withFD(true).withMerge(true));
+      EmbeddedCacheManager cm5 = addClusterEnabledCacheManager(defaultConfig,
+            new TransportFlags().withFD(true).withMerge(true));
       Cache<Object, Object> c5 = cm5.getCache(CACHE_NAME);
       TestingUtil.blockUntilViewsReceived(30000, true, c1, c2, c3, c4, c5);
       TestingUtil.waitForRehashToComplete(c1, c2, c3, c4, c5);
    }
 
-}
-
-class CheckPoint {
-   private final Lock lock = new ReentrantLock();
-   private final Condition unblockCondition = lock.newCondition();
-   private final Map<String, Integer> events = new HashMap<String, Integer>();
-
-   public void awaitStrict(String event, long timeout, TimeUnit unit)
-         throws InterruptedException, TimeoutException {
-      awaitStrict(event, 1, timeout, unit);
-   }
-
-   public boolean await(String event, long timeout, TimeUnit unit) throws InterruptedException {
-      return await(event, 1, timeout, unit);
-   }
-
-   public void awaitStrict(String event, int count, long timeout, TimeUnit unit)
-         throws InterruptedException, TimeoutException {
-      if (!await(event, count, timeout, unit)) {
-         throw new TimeoutException(""Timed out waiting for event "" + event);
-      }
-   }
-
-   public boolean await(String event, int count, long timeout, TimeUnit unit) throws InterruptedException {
-      lock.lock();
-      try {
-         long waitNanos = unit.toNanos(timeout);
-         while (waitNanos > 0) {
-            Integer currentCount = events.get(event);
-            if (currentCount != null && currentCount >= count) {
-               events.put(event, currentCount - count);
-               break;
-            }
-            waitNanos = unblockCondition.awaitNanos(waitNanos);
-         }
-
-         if (waitNanos <= 0) {
-            // let the triggering thread know that we timed out
-            events.put(event, -1);
-            return false;
+   public void testAbruptLeaveAfterGetStatus() throws TimeoutException, InterruptedException {
+      // Block the GET_STATUS command on node 2
+      final LocalTopologyManager localTopologyManager = TestingUtil.extractGlobalComponent(manager(1),
+            LocalTopologyManager.class);
+      final CheckPoint checkpoint = new CheckPoint();
+      LocalTopologyManager spyLocalTopologyManager = spy(localTopologyManager);
+      TestingUtil.replaceComponent(manager(1), LocalTopologyManager.class, spyLocalTopologyManager, true);
+      doAnswer(new Answer<Object>() {
+         @Override
+         public Object answer(InvocationOnMock invocation) throws Throwable {
+            int viewId = (Integer) invocation.getArguments()[0];
+            checkpoint.trigger(""GET_STATUS_"" + viewId);
+            log.debugf(""Blocking the GET_STATUS command on the merge coordinator"");
+            checkpoint.awaitStrict(""3 left"", 10, TimeUnit.SECONDS);
+            return invocation.callRealMethod();
          }
+      }).when(spyLocalTopologyManager).handleStatusRequest(anyInt());
 
-         return true;
-      } finally {
-         lock.unlock();
-      }
-   }
-
-   public void trigger(String event) {
-      trigger(event, 1);
-   }
-
-   public void triggerForever(String event) {
-      trigger(event, Integer.MAX_VALUE);
-   }
+      // Node 1 (the coordinator) dies. Node 2 becomes coordinator and tries to call GET_STATUS
+      log.debugf(""Killing coordinator"");
+      manager(0).stop();
+      TestingUtil.blockUntilViewsReceived(30000, false, manager(1), manager(2));
 
-   public void trigger(String event, int count) {
-      lock.lock();
-      try {
-         Integer currentCount = events.get(event);
-         if (currentCount == null) {
-            currentCount = 0;
-         } else if (currentCount < 0) {
-            throw new IllegalStateException(""Thread already timed out waiting for event "" + event);
-         }
+      // Wait for the GET_STATUS command and stop node 3 abruptly
+      int viewId = manager(1).getTransport().getViewId();
+      checkpoint.awaitStrict(""GET_STATUS_"" + viewId, 10, TimeUnit.SECONDS);
+      d3.setDiscardAll(true);
+      manager(2).stop();
+      TestingUtil.blockUntilViewsReceived(30000, false, manager(1));
+      checkpoint.trigger(""3 left"");
 
-         // If triggerForever is called more than once, it will cause an overflow and the waiters will fail.
-         events.put(event, currentCount + count);
-         unblockCondition.signalAll();
-      } finally {
-         lock.unlock();
-      }
+      // Wait for node 2 to install a view with only itself and unblock the GET_STATUS command
+      TestingUtil.waitForRehashToComplete(c2);
    }
 }
+",2013-04-09T16:32:35Z,491
"@@ -0,0 +1,120 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.test.fwk;
+
+import java.util.HashMap;
+import java.util.Map;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.TimeoutException;
+import java.util.concurrent.locks.Condition;
+import java.util.concurrent.locks.Lock;
+import java.util.concurrent.locks.ReentrantLock;
+
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.jboss.logging.Logger;
+
+/**
+ * Behaves more or less like a map of {@link java.util.concurrent.Semaphore}s.
+ *
+ * One thread will wait for an event via {@code await(...)} or {@code awaitStrict(...)}, and one or more
+ * other threads will trigger the event via {@code trigger(...)} or {@code triggerForever(...)}.
+ *
+ * @author Dan Berindei
+ * @since 5.3
+ */
+public class CheckPoint {
+   private static final Log log = LogFactory.getLog(CheckPoint.class);
+   public static final int INFINITE = 999999999;
+   private final Lock lock = new ReentrantLock();
+   private final Condition unblockCondition = lock.newCondition();
+   private final Map<String, Integer> events = new HashMap<String, Integer>();
+
+   public void awaitStrict(String event, long timeout, TimeUnit unit)
+         throws InterruptedException, TimeoutException {
+      awaitStrict(event, 1, timeout, unit);
+   }
+
+   public boolean await(String event, long timeout, TimeUnit unit) throws InterruptedException {
+      return await(event, 1, timeout, unit);
+   }
+
+   public void awaitStrict(String event, int count, long timeout, TimeUnit unit)
+         throws InterruptedException, TimeoutException {
+      if (!await(event, count, timeout, unit)) {
+         throw new TimeoutException(""Timed out waiting for event "" + event);
+      }
+   }
+
+   public boolean await(String event, int count, long timeout, TimeUnit unit) throws InterruptedException {
+      log.tracef(""Waiting for event %s * %d"", event, count);
+      lock.lock();
+      try {
+         long waitNanos = unit.toNanos(timeout);
+         while (waitNanos > 0) {
+            Integer currentCount = events.get(event);
+            if (currentCount != null && currentCount >= count) {
+               events.put(event, currentCount - count);
+               break;
+            }
+            waitNanos = unblockCondition.awaitNanos(waitNanos);
+         }
+
+         if (waitNanos <= 0) {
+            log.tracef(""Timed out waiting for event %s * %d"", event, count);
+            // let the triggering thread know that we timed out
+            events.put(event, -1);
+            return false;
+         }
+
+         return true;
+      } finally {
+         lock.unlock();
+      }
+   }
+
+   public void trigger(String event) {
+      trigger(event, 1);
+   }
+
+   public void triggerForever(String event) {
+      trigger(event, INFINITE);
+   }
+
+   public void trigger(String event, int count) {
+      lock.lock();
+      try {
+         Integer currentCount = events.get(event);
+         if (currentCount == null) {
+            currentCount = 0;
+         } else if (currentCount < 0) {
+            throw new IllegalStateException(""Thread already timed out waiting for event "" + event);
+         }
+
+         // If triggerForever is called more than once, it will cause an overflow and the waiters will fail.
+         int newCount = count != INFINITE ? currentCount + count : INFINITE;
+         log.tracef(""Triggering event %s * %d, new count is %d"", event, count, newCount);
+         events.put(event, newCount);
+         unblockCondition.signalAll();
+      } finally {
+         lock.unlock();
+      }
+   }
+}",2013-04-09T16:32:35Z,492
"@@ -22,10 +22,6 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.context.InvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
@@ -95,24 +91,6 @@ public interface DistributionManager {
     */
    Set<Address> locateAll(Collection<Object> keys); //todo [anistor] this has to take an additional parameter that specifies if the lookup is for read or write
 
-   /**
-    * Transforms a cache entry so it is marked for L1 rather than the primary cache data structure.  This should be done
-    * if it is deemed that the entry is targeted for L1 storage rather than storage in the primary data container.
-    *
-    * @param entry entry to transform
-    */
-   void transformForL1(CacheEntry entry);
-
-   /**
-    * Retrieves a cache entry from a remote source.  Would typically involve an RPC call using a {@link org.infinispan.commands.remote.ClusteredGetCommand}
-    * and some form of quorum of responses if the responses returned are inconsistent - often the case if there is a
-    * rehash in progress, involving nodes that the key maps to.
-    *
-    * @param key key to look up
-    * @return an internal cache entry, or null if it cannot be located
-    */
-   InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception;
-
    /**
     * Retrieves the consistent hash instance currently in use, an instance of the configured ConsistentHash
     * class (which defaults to {@link org.infinispan.distribution.ch.DefaultConsistentHash}.",2013-03-07T23:03:04Z,60
"@@ -22,31 +22,16 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.commands.CommandsFactory;
-import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.commands.remote.ClusteredGetCommand;
-import org.infinispan.configuration.cache.Configuration;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalCacheValue;
-import org.infinispan.context.InvocationContext;
-import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.jmx.annotations.Parameter;
 import org.infinispan.statetransfer.StateTransferManager;
-import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
-import org.infinispan.remoting.responses.Response;
-import org.infinispan.remoting.responses.SuccessfulResponse;
-import org.infinispan.remoting.rpc.ResponseFilter;
-import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
@@ -70,9 +55,7 @@ public class DistributionManagerImpl implements DistributionManager {
    private static final boolean trace = log.isTraceEnabled();
 
    // Injected components
-   private Configuration configuration;
    private RpcManager rpcManager;
-   private CommandsFactory cf;
    private StateTransferManager stateTransferManager;
 
    /**
@@ -82,11 +65,8 @@ public DistributionManagerImpl() {
    }
 
    @Inject
-   public void init(Configuration configuration, RpcManager rpcManager, CommandsFactory cf,
-                    StateTransferManager stateTransferManager) {
-      this.configuration = configuration;
+   public void init(RpcManager rpcManager, StateTransferManager stateTransferManager) {
       this.rpcManager = rpcManager;
-      this.cf = cf;
       this.stateTransferManager = stateTransferManager;
    }
 
@@ -147,39 +127,6 @@ public Set<Address> locateAll(Collection<Object> keys) {
       return getConsistentHash().locateAllOwners(keys);
    }
 
-   @Override
-   public void transformForL1(CacheEntry entry) {
-      if (entry.getLifespan() < 0 || entry.getLifespan() > configuration.clustering().l1().lifespan())
-         entry.setLifespan(configuration.clustering().l1().lifespan());
-   }
-
-   @Override
-   public InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception {
-      GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
-      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
-
-      List<Address> targets = new ArrayList<Address>(getReadConsistentHash().locateOwners(key));
-      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
-      targets.retainAll(rpcManager.getTransport().getMembers());
-      ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, getAddress());
-      Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
-                                                                   configuration.clustering().sync().replTimeout(), true, filter);
-
-      if (!responses.isEmpty()) {
-         for (Response r : responses.values()) {
-            if (r instanceof SuccessfulResponse) {
-               InternalCacheValue cacheValue = (InternalCacheValue) ((SuccessfulResponse) r).getResponseValue();
-               return cacheValue.toInternalCacheEntry(key);
-            }
-         }
-      }
-
-      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
-      // Otherwise our get command might be processed by the old owners after they have invalidated their data
-      // and we'd return a null even though the key exists on
-      return null;
-   }
-
    @Override
    public ConsistentHash getConsistentHash() {
       return getWriteConsistentHash();",2013-03-07T23:03:04Z,60
"@@ -0,0 +1,120 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.interceptors;
+
+import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.FlagAffectedCommand;
+import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.factories.annotations.Inject;
+import org.infinispan.factories.annotations.Start;
+import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.statetransfer.StateTransferManager;
+import org.infinispan.util.concurrent.locks.LockManager;
+
+/**
+ * Base class for replication and distribution interceptors.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+public abstract class ClusteringInterceptor extends BaseRpcInterceptor {
+
+   protected CommandsFactory cf;
+   protected EntryFactory entryFactory;
+   protected LockManager lockManager;
+   protected DataContainer dataContainer;
+   protected StateTransferManager stateTransferManager;
+   protected boolean needReliableReturnValues;
+
+   @Inject
+   public void injectDependencies(CommandsFactory cf, EntryFactory entryFactory,
+                                  LockManager lockManager, DataContainer dataContainer,
+                                  StateTransferManager stateTransferManager) {
+      this.cf = cf;
+      this.entryFactory = entryFactory;
+      this.lockManager = lockManager;
+      this.dataContainer = dataContainer;
+      this.stateTransferManager = stateTransferManager;
+   }
+
+   @Start
+   public void configure() {
+      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
+   }
+
+   protected boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
+      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+   }
+
+   protected boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
+      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
+            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
+         return false;
+      }
+      boolean shouldFetchFromRemote = false;
+      CacheEntry entry = ctx.lookupEntry(command.getKey());
+      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
+         Object key = command.getKey();
+         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
+         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
+         if (!shouldFetchFromRemote && getLog().isTraceEnabled()) {
+            getLog().tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s) or is in L1. Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
+         }
+      }
+      return shouldFetchFromRemote;
+   }
+
+   /**
+    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
+    * <pre>
+    * - node A (owner, tx originator) does a successful replace
+    * - the actual value changes
+    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
+    *   B (check is performed at commit time).
+    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
+    * </pre>
+    */
+   protected boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return ctx.isOriginLocal() && command.isSuccessful();
+   }
+
+   /**
+    * Retrieves a cache entry from a remote source.  Would typically involve an RPC call using a {@link org.infinispan.commands.remote.ClusteredGetCommand}
+    * and some form of quorum of responses if the responses returned are inconsistent - often the case if there is a
+    * rehash in progress, involving nodes that the key maps to.
+    *
+    * @param key key to look up
+    * @return an internal cache entry, or null if it cannot be located
+    */
+   protected abstract InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception;
+}",2013-03-07T23:03:04Z,482
"@@ -22,7 +22,6 @@
  */
 package org.infinispan.interceptors;
 
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.AbstractDataCommand;
@@ -35,30 +34,21 @@
 import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configurations;
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.EntryFactory;
-import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.InternalCacheValue;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.ch.ConsistentHash;
-import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
-import org.infinispan.interceptors.base.BaseRpcInterceptor;
 import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
 import org.infinispan.remoting.responses.Response;
 import org.infinispan.remoting.responses.SuccessfulResponse;
 import org.infinispan.remoting.rpc.ResponseFilter;
 import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.jgroups.SuspectException;
-import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.xa.GlobalTransaction;
-import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -71,16 +61,8 @@
  * @author Bela Ban
  * @since 4.0
  */
-public class ReplicationInterceptor extends BaseRpcInterceptor {
+public class ReplicationInterceptor extends ClusteringInterceptor {
 
-   private CommandsFactory cf;
-
-   private EntryFactory entryFactory;
-   private LockManager lockManager;
-   private DataContainer dataContainer;
-   private StateTransferManager stateTransferManager;
-
-   private boolean needReliableReturnValues;
    private boolean isPessimisticCache;
 
    private static final Log log = LogFactory.getLog(ReplicationInterceptor.class);
@@ -91,19 +73,9 @@ protected Log getLog() {
       return log;
    }
 
-   @Inject
-   public void init(CommandsFactory cf, EntryFactory entryFactory, DataContainer dataContainer, LockManager lockManager, StateTransferManager stateTransferManager) {
-      this.cf = cf;
-      this.entryFactory = entryFactory;
-      this.dataContainer = dataContainer;
-      this.lockManager = lockManager;
-      this.stateTransferManager = stateTransferManager;
-   }
-
    @Start
    public void start() {
       isPessimisticCache = cacheConfiguration.transaction().lockingMode() == LockingMode.PESSIMISTIC;
-      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
    }
 
    @Override
@@ -180,44 +152,6 @@ public Object visitLockControlCommand(TxInvocationContext ctx, LockControlComman
       return retVal;
    }
 
-   private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] clarify usage of this flag in REPL mode
-            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
-         return false;
-      }
-      boolean shouldFetchFromRemote = false;
-      CacheEntry entry = ctx.lookupEntry(command.getKey());
-      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
-         Object key = command.getKey();
-         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
-         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
-         if (!shouldFetchFromRemote) {
-            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s). Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
-         }
-      }
-      return shouldFetchFromRemote;
-   }
-
-   private boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
-      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
-   }
-
-   /**
-    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
-    * <pre>
-    * - node A (owner, tx originator) does a successful replace
-    * - the actual value changes
-    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
-    *   B (check is performed at commit time).
-    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
-    * </pre>
-    */
-   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
-      return ctx.isOriginLocal() && command.isSuccessful();
-   }
-
    /**
     * This method retrieves an entry from a remote cache.
     * <p/>
@@ -242,7 +176,7 @@ private Object remoteGet(InvocationContext ctx, Object key, FlagAffectedCommand
          acquireRemoteLock = isWrite && isPessimisticCache && !txContext.getAffectedKeys().contains(key);
       }
       // attempt a remote lookup
-      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command.getFlags());
+      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
 
       if (acquireRemoteLock) {
          ((TxInvocationContext) ctx).addAffectedKey(key);
@@ -265,9 +199,9 @@ protected Address getPrimaryOwner() {
       return stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0);
    }
 
-   private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, Set<Flag> flags) {
+   protected InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) {
       GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
-      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, flags, acquireRemoteLock, gtx);
+      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
 
       List<Address> targets = Collections.singletonList(getPrimaryOwner());
       ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
@@ -289,7 +223,7 @@ private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContex
    private Object localGet(InvocationContext ctx, Object key, boolean isWrite, FlagAffectedCommand command) throws Throwable {
       InternalCacheEntry ice = dataContainer.get(key);
       if (ice != null) {
-         if (!ctx.replaceValue(key, ice.getValue()))  {
+         if (!ctx.replaceValue(key, ice.getValue())) {
             if (isWrite)
                lockAndWrap(ctx, key, ice, command);
             else",2013-03-07T23:03:04Z,103
"@@ -22,34 +22,32 @@
  */
 package org.infinispan.interceptors.distribution;
 
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.write.PutMapCommand;
 import org.infinispan.commands.write.RemoveCommand;
 import org.infinispan.commands.write.ReplaceCommand;
 import org.infinispan.commands.write.WriteCommand;
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.EntryFactory;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.container.entries.InternalCacheValue;
 import org.infinispan.context.InvocationContext;
-import org.infinispan.distribution.DataLocality;
+import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.DistributionManager;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
-import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.interceptors.ClusteringInterceptor;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
+import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.responses.SuccessfulResponse;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
-import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 
 /**
  * Base class for distribution of entries across a cluster.
@@ -60,14 +58,11 @@
  * @author Dan Berindei <dan@infinispan.org>
  * @since 4.0
  */
-public abstract class BaseDistributionInterceptor extends BaseRpcInterceptor {
+public abstract class BaseDistributionInterceptor extends ClusteringInterceptor {
+
    protected DistributionManager dm;
-   protected CommandsFactory cf;
-   protected DataContainer dataContainer;
-   protected EntryFactory entryFactory;
-   protected LockManager lockManager;
+
    protected ClusteringDependentLogic cdl;
-   private boolean needReliableReturnValues;
 
    private static final Log log = LogFactory.getLog(BaseDistributionInterceptor.class);
 
@@ -77,42 +72,36 @@ protected Log getLog() {
    }
 
    @Inject
-   public void injectDependencies(DistributionManager distributionManager,
-                                  CommandsFactory cf, DataContainer dataContainer, EntryFactory entryFactory,
-                                  LockManager lockManager, ClusteringDependentLogic cdl) {
+   public void injectDependencies(DistributionManager distributionManager, ClusteringDependentLogic cdl) {
       this.dm = distributionManager;
-      this.cf = cf;
-      this.dataContainer = dataContainer;
-      this.entryFactory = entryFactory;
-      this.lockManager = lockManager;
       this.cdl = cdl;
    }
 
-   @Start
-   public void configure() {
-      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
-   }
-
-   protected boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      boolean shouldFetchFromRemote = false;
-      final CacheEntry entry;
-      if (!command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            && !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES)
-            && ((entry = ctx.lookupEntry(command.getKey())) == null || entry.isNull() || entry.isLockPlaceholder())) {
-         Object key = command.getKey();
-         DataLocality locality = dm.getReadConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key) ? DataLocality.LOCAL : DataLocality.NOT_LOCAL;
-         shouldFetchFromRemote = ctx.isOriginLocal() && !locality.isLocal() && !dataContainer.containsKey(key);
-         if (!shouldFetchFromRemote) {
-            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s), or is in L1.  Owners are %s"", key, rpcManager.getAddress(), dm.locate(key));
+   @Override
+   protected InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception {
+      GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
+      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
+
+      List<Address> targets = new ArrayList<Address>(stateTransferManager.getCacheTopology().getReadConsistentHash().locateOwners(key));
+      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
+      targets.retainAll(rpcManager.getTransport().getMembers());
+      ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
+      Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
+            cacheConfiguration.clustering().sync().replTimeout(), true, filter);
+
+      if (!responses.isEmpty()) {
+         for (Response r : responses.values()) {
+            if (r instanceof SuccessfulResponse) {
+               InternalCacheValue cacheValue = (InternalCacheValue) ((SuccessfulResponse) r).getResponseValue();
+               return cacheValue.toInternalCacheEntry(key);
+            }
          }
       }
-      return shouldFetchFromRemote;
-   }
 
-   protected boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
-      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
+      // Otherwise our get command might be processed by the old owners after they have invalidated their data
+      // and we'd return a null even though the key exists on
+      return null;
    }
 
    @Override
@@ -157,9 +146,9 @@ interface RecipientGenerator extends KeyGenerator {
    }
 
    class SingleKeyRecipientGenerator implements RecipientGenerator {
-      final Object key;
-      final Set<Object> keys;
-      List<Address> recipients = null;
+      private final Object key;
+      private final Set<Object> keys;
+      private List<Address> recipients = null;
 
       SingleKeyRecipientGenerator(Object key) {
          this.key = key;
@@ -180,8 +169,8 @@ public Collection<Object> getKeys() {
 
    class MultipleKeysRecipientGenerator implements RecipientGenerator {
 
-      final Collection<Object> keys;
-      List<Address> recipients = null;
+      private final Collection<Object> keys;
+      private List<Address> recipients = null;
 
       MultipleKeysRecipientGenerator(Collection<Object> keys) {
          this.keys = keys;",2013-03-07T23:03:04Z,478
"@@ -140,7 +140,7 @@ private Object remoteGetBeforeWrite(InvocationContext ctx, Object key, FlagAffec
          if (trace) log.tracef(""Doing a remote get for key %s"", key);
 
          // attempt a remote lookup
-         InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, false, command);
+         InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, false, command);
          if (ice != null) {
             if (!ctx.replaceValue(key, ice.getValue())) {
                entryFactory.wrapEntryForPut(ctx, key, ice, false, command);
@@ -190,7 +190,7 @@ protected void handleRemoteWrite(InvocationContext ctx, WriteCommand command, Re
 
    private Object remoteGet(InvocationContext ctx, Object key, GetKeyValueCommand command) throws Throwable {
       if (trace) log.tracef(""Doing a remote get for key %s"", key);
-      InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, false, command);
+      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, false, command);
       command.setRemotelyFetchedValue(ice);
       if (ice != null) {
          return ice.getValue();",2013-03-07T23:03:04Z,483
"@@ -117,8 +117,9 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
     * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
     * </pre>
     */
-   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
-      return ctx.isOriginLocal() && command.isSuccessful() && cacheConfiguration.transaction().lockingMode() == LockingMode.OPTIMISTIC && !useClusteredWriteSkewCheck;
+   protected boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return super.ignorePreviousValueOnBackup(command, ctx)
+          && cacheConfiguration.transaction().lockingMode() == LockingMode.OPTIMISTIC && !useClusteredWriteSkewCheck;
    }
 
    @Start
@@ -176,7 +177,6 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
       }
    }
 
-
    private void lockAndWrap(InvocationContext ctx, Object key, InternalCacheEntry ice, FlagAffectedCommand command) throws InterruptedException {
       boolean skipLocking = hasSkipLocking(command);
       long lockTimeout = getLockAcquisitionTimeout(command, skipLocking);
@@ -341,7 +341,7 @@ private Object remoteGetAndStoreInL1(InvocationContext ctx, Object key, boolean
             acquireRemoteLock = isWrite && isPessimisticCache && !txContext.getAffectedKeys().contains(key);
          }
          // attempt a remote lookup
-         InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
+         InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
 
          if (acquireRemoteLock) {
             ((TxInvocationContext) ctx).addAffectedKey(key);",2013-03-07T23:03:04Z,484
"@@ -324,7 +324,9 @@ public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipO
             boolean isForeignOwned = !skipOwnershipCheck && !localNodeIsOwner(entry.getKey());
             if (isForeignOwned && !entry.isRemoved()) {
                if (configuration.clustering().l1().enabled()) {
-                  dm.transformForL1(entry);
+                  // transform for L1
+                  if (entry.getLifespan() < 0 || entry.getLifespan() > configuration.clustering().l1().lifespan())
+                     entry.setLifespan(configuration.clustering().l1().lifespan());
                } else {
                   doCommit = false;
                }",2013-03-07T23:03:04Z,172
"@@ -45,8 +45,6 @@
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.concurrent.locks.LockManager;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
 import org.testng.annotations.Test;
@@ -67,8 +65,6 @@
 @Test(groups = ""functional"", testName = ""interceptors.ReplicationInterceptorTest"")
 public class ReplicationInterceptorTest {
 
-   private static final Log log = LogFactory.getLog(ReplicationInterceptorTest.class);
-
    public void testRemoteGetForGetKeyValueCommand() throws Throwable {
       ConfigurationBuilder cb = new ConfigurationBuilder();
       cb.clustering().cacheMode(CacheMode.REPL_SYNC);
@@ -114,7 +110,7 @@ public CacheTopology answer(InvocationOnMock invocation) {
             return cacheTopology;
          }
       });
-      replInterceptor.init(commandsFactory, entryFactory, dataContainer, lockManager, stateTransferManager);
+      replInterceptor.injectDependencies(commandsFactory, entryFactory, lockManager, dataContainer, stateTransferManager);
       RpcManager rpcManager = mock(RpcManager.class);
       Transport transport = mock(Transport.class);
       when(rpcManager.getAddress()).thenReturn(B);",2013-03-07T23:03:04Z,103
"@@ -238,8 +238,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
       TestingUtil.waitForRehashToComplete(cache(0), cache(2));
 
       // at this point state transfer is fully done
-      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.keySet());
-      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.keySet());
+      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.entrySet());
+      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.entrySet());
 
       if (op == Operation.CLEAR || op == Operation.REMOVE) {
          // caches should be empty. check that no keys were revived by an inconsistent state transfer
@@ -262,7 +262,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
             assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
 
             // check values were not overwritten with old values carried by state transfer
-            assertEquals(""after_st_"" + i, cache(0).get(i));
+            String expected = ""after_st_"" + i;
+            assertEquals(expected, cache(0).get(i));
             assertEquals(""after_st_"" + i, cache(2).get(i));
          }
       } else { // PUT_IF_ABSENT
@@ -278,8 +279,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
             }
             assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
 
-            assertEquals(""before_st_"" + i, cache(0).get(i));
-            assertEquals(""before_st_"" + i, cache(2).get(i));
+            String expected = ""before_st_"" + i;
+            assertEquals(expected, cache(0).get(i));
+            assertEquals(expected, cache(2).get(i));
          }
       }
    }",2013-03-07T23:03:04Z,485
"@@ -168,7 +168,7 @@ public boolean isSuccessful() {
 
    @Override
    public boolean isConditional() {
-      return true;
+      return !ignorePreviousValue;
    }
 
    public long getLifespanMillis() {",2013-03-07T23:03:03Z,493
"@@ -81,8 +81,12 @@ public <T> T construct(Class<T> componentType) {
       Class<?> componentImpl;
       if (componentType.equals(ClusteringDependentLogic.class)) {
          CacheMode cacheMode = configuration.clustering().cacheMode();
-         if (cacheMode.isReplicated() || !cacheMode.isClustered() || cacheMode.isInvalidation()) {
-            return componentType.cast(new ClusteringDependentLogic.AllNodesLogic());
+         if (!cacheMode.isClustered()) {
+            return componentType.cast(new ClusteringDependentLogic.LocalLogic());
+         } else if (cacheMode.isInvalidation()) {
+            return componentType.cast(new ClusteringDependentLogic.InvalidationLogic());
+         } else if (cacheMode.isReplicated()) {
+            return componentType.cast(new ClusteringDependentLogic.ReplicationLogic());
          } else {
             return componentType.cast(new ClusteringDependentLogic.DistributionLogic());
          }",2013-03-07T23:03:03Z,494
"@@ -23,28 +23,28 @@
 package org.infinispan.interceptors;
 
 import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.read.GetCacheEntryCommand;
 import org.infinispan.commands.read.GetKeyValueCommand;
 import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.tx.RollbackCommand;
-import org.infinispan.commands.write.ClearCommand;
-import org.infinispan.commands.write.PutKeyValueCommand;
-import org.infinispan.commands.write.PutMapCommand;
-import org.infinispan.commands.write.RemoveCommand;
-import org.infinispan.commands.write.ReplaceCommand;
-import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configurations;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.InternalCacheValue;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
+import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.interceptors.base.BaseRpcInterceptor;
@@ -58,13 +58,11 @@
 import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.TimeoutException;
 
 /**
@@ -75,10 +73,14 @@
  */
 public class ReplicationInterceptor extends BaseRpcInterceptor {
 
-   protected CommandsFactory cf;
+   private CommandsFactory cf;
 
+   private EntryFactory entryFactory;
+   private LockManager lockManager;
+   private DataContainer dataContainer;
    private StateTransferManager stateTransferManager;
 
+   private boolean needReliableReturnValues;
    private boolean isPessimisticCache;
 
    private static final Log log = LogFactory.getLog(ReplicationInterceptor.class);
@@ -90,14 +92,18 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(CommandsFactory cf, StateTransferManager stateTransferManager) {
+   public void init(CommandsFactory cf, EntryFactory entryFactory, DataContainer dataContainer, LockManager lockManager, StateTransferManager stateTransferManager) {
       this.cf = cf;
+      this.entryFactory = entryFactory;
+      this.dataContainer = dataContainer;
+      this.lockManager = lockManager;
       this.stateTransferManager = stateTransferManager;
    }
 
    @Start
    public void start() {
       isPessimisticCache = cacheConfiguration.transaction().lockingMode() == LockingMode.PESSIMISTIC;
+      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
    }
 
    @Override
@@ -149,7 +155,10 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
          // the entry is mapped to the local node.
          if (returnValue == null && ctx.isOriginLocal()) {
             if (needsRemoteGet(ctx, command)) {
-               returnValue = remoteGet(ctx, command, false);
+               returnValue = remoteGet(ctx, command.getKey(), command, false);
+            }
+            if (returnValue == null) {
+               returnValue = localGet(ctx, command.getKey(), false, command);
             }
          }
          return returnValue;
@@ -172,15 +181,43 @@ public Object visitLockControlCommand(TxInvocationContext ctx, LockControlComman
    }
 
    private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      Object key = command.getKey();
-      final CacheEntry entry;
-      return !command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            && !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] do we need this? it should normally be used only in distributed mode, never in replicated mode
-            && !stateTransferManager.getCacheTopology().getReadConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key)
-            && ((entry = ctx.lookupEntry(key)) == null || entry.isNull() || entry.isLockPlaceholder());
+      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
+            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] clarify usage of this flag in REPL mode
+            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
+         return false;
+      }
+      boolean shouldFetchFromRemote = false;
+      CacheEntry entry = ctx.lookupEntry(command.getKey());
+      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
+         Object key = command.getKey();
+         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
+         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
+         if (!shouldFetchFromRemote) {
+            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s). Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
+         }
+      }
+      return shouldFetchFromRemote;
+   }
+
+   private boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
+      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+   }
+
+   /**
+    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
+    * <pre>
+    * - node A (owner, tx originator) does a successful replace
+    * - the actual value changes
+    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
+    *   B (check is performed at commit time).
+    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
+    * </pre>
+    */
+   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return ctx.isOriginLocal() && command.isSuccessful();
    }
 
-   //todo [anistor] need to revise these methods
    /**
     * This method retrieves an entry from a remote cache.
     * <p/>
@@ -190,12 +227,12 @@ private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand comman
     *
     *
     * @param ctx invocation context
+    * @param key
     * @param command
     * @return value of a remote get, or null
     * @throws Throwable if there are problems
     */
-   private Object remoteGet(InvocationContext ctx, AbstractDataCommand command, boolean isWrite) throws Throwable {
-      Object key = command.getKey();
+   private Object remoteGet(InvocationContext ctx, Object key, FlagAffectedCommand command, boolean isWrite) throws Throwable {
       if (trace) {
          log.tracef(""Key %s is not yet available on %s, so we may need to look elsewhere"", key, rpcManager.getAddress());
       }
@@ -211,16 +248,28 @@ private Object remoteGet(InvocationContext ctx, AbstractDataCommand command, boo
          ((TxInvocationContext) ctx).addAffectedKey(key);
       }
 
-      return ice != null ? ice.getValue() : null;
+      if (ice != null) {
+         if (!ctx.replaceValue(key, ice.getValue()))  {
+            if (isWrite) {
+               lockAndWrap(ctx, key, ice, command);
+            } else {
+               ctx.putLookedUpEntry(key, ice);
+            }
+         }
+         return ice.getValue();
+      }
+      return null;
+   }
+
+   protected Address getPrimaryOwner() {
+      return stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0);
    }
 
    private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, Set<Flag> flags) {
       GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
       ClusteredGetCommand get = cf.buildClusteredGetCommand(key, flags, acquireRemoteLock, gtx);
 
-      List<Address> targets = new ArrayList<Address>(stateTransferManager.getCacheTopology().getReadConsistentHash().locateOwners(key));
-      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
-      targets.retainAll(rpcManager.getTransport().getMembers());
+      List<Address> targets = Collections.singletonList(getPrimaryOwner());
       ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
       Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
             cacheConfiguration.clustering().sync().replTimeout(), true, filter);
@@ -237,36 +286,77 @@ private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContex
       return null;
    }
 
+   private Object localGet(InvocationContext ctx, Object key, boolean isWrite, FlagAffectedCommand command) throws Throwable {
+      InternalCacheEntry ice = dataContainer.get(key);
+      if (ice != null) {
+         if (!ctx.replaceValue(key, ice.getValue()))  {
+            if (isWrite)
+               lockAndWrap(ctx, key, ice, command);
+            else
+               ctx.putLookedUpEntry(key, ice);
+         }
+         return command instanceof GetCacheEntryCommand ? ice : ice.getValue();
+      }
+      return null;
+   }
+
+   private void lockAndWrap(InvocationContext ctx, Object key, InternalCacheEntry ice, FlagAffectedCommand command) throws InterruptedException {
+      if (isPessimisticCache && rpcManager.getAddress().equals(getPrimaryOwner())) {
+         boolean skipLocking = hasSkipLocking(command);
+         long lockTimeout = getLockAcquisitionTimeout(command, skipLocking);
+         lockManager.acquireLock(ctx, key, lockTimeout, skipLocking);
+      }
+      entryFactory.wrapEntryForPut(ctx, key, ice, false, command);
+   }
+
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      return handleCrudMethod(ctx, command, !ctx.isOriginLocal());
    }
 
    @Override
    public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      return handleCrudMethod(ctx, command, true);
    }
 
    @Override
    public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      try {
+         return handleCrudMethod(ctx, command, !ctx.isOriginLocal());
+      } finally {
+         if (ignorePreviousValueOnBackup(command, ctx)) {
+            // the command that will execute remotely must ignore previous values
+            command.setIgnorePreviousValue(true);
+         }
+      }
    }
 
    @Override
    public Object visitClearCommand(InvocationContext ctx, ClearCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      return handleCrudMethod(ctx, command, true);
    }
 
    @Override
    public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      try {
+         return handleCrudMethod(ctx, command, !ctx.isOriginLocal());
+      } finally {
+         if (ignorePreviousValueOnBackup(command, ctx)) {
+            // the command that will execute remotely must ignore previous values
+            command.setIgnorePreviousValue(true);
+         }
+      }
    }
 
    /**
     * If we are within one transaction we won't do any replication as replication would only be performed at commit
     * time. If the operation didn't originate locally we won't do any replication either.
     */
-   private Object handleCrudMethod(final InvocationContext ctx, final WriteCommand command) throws Throwable {
+   private Object handleCrudMethod(InvocationContext ctx, WriteCommand command, boolean skipRemoteGet) throws Throwable {
+      if (!skipRemoteGet) {
+         remoteGetBeforeWrite(ctx, command);
+      }
+
       // FIRST pass this call up the chain.  Only if it succeeds (no exceptions) locally do we attempt to replicate.
       final Object returnValue = invokeNextInterceptor(ctx, command);
       if (!isLocalModeForced(command) && command.isSuccessful() && ctx.isOriginLocal() && !ctx.isInTxScope()) {
@@ -275,4 +365,18 @@ private Object handleCrudMethod(final InvocationContext ctx, final WriteCommand
       return returnValue;
    }
 
+   private void remoteGetBeforeWrite(InvocationContext ctx, WriteCommand command) throws Throwable {
+      if (command instanceof AbstractDataCommand && (isNeedReliableReturnValues(command) || command.isConditional())) {
+         AbstractDataCommand singleKeyCommand = (AbstractDataCommand) command;
+
+         Object returnValue = null;
+         // get it remotely if we do not have it yet
+         if (needsRemoteGet(ctx, singleKeyCommand)) {
+            returnValue = remoteGet(ctx, singleKeyCommand.getKey(), singleKeyCommand, true);
+         }
+         if (returnValue == null) {
+            localGet(ctx, singleKeyCommand.getKey(), true, command);
+         }
+      }
+   }
 }",2013-03-07T23:03:03Z,103
"@@ -54,10 +54,11 @@ protected void broadcastPrepare(TxInvocationContext context, PrepareCommand comm
       // is then stored in the transactional context to be used during the commit phase.
       // However if the current node is already the coordinator, then we fall back to ""normal"" ReplicationInterceptor
       // logic for this step.
-      if (!rpcManager.getTransport().isCoordinator()) {
+      Address primaryOwner = getPrimaryOwner();
+      if (!primaryOwner.equals(rpcManager.getAddress())) {
          setVersionsSeenOnPrepareCommand((VersionedPrepareCommand) command, context);
          Map<Address, Response> resps = rpcManager.invokeRemotely(null, command, true, true);
-         Response r = resps.get(rpcManager.getTransport().getCoordinator());  // We only really care about the coordinator's response.
+         Response r = resps.get(primaryOwner);  // We only really care about the coordinator's response.
          readVersionsFromResponse(r, context.getCacheTransaction());
       } else {
          super.broadcastPrepare(context, command);",2013-03-07T23:03:03Z,495
"@@ -76,7 +76,7 @@ protected Log getLog() {
    }
 
    @Inject
-   private void injectConfiguration(Configuration configuration) {
+   public void injectConfiguration(Configuration configuration) {
       this.cacheConfiguration = configuration;
    }
 ",2013-03-07T23:03:03Z,496
"@@ -40,16 +40,14 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.statetransfer.StateTransferLock;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.transaction.xa.CacheTransaction;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
 
 import java.util.Collection;
 
 import static org.infinispan.transaction.WriteSkewHelper.performWriteSkewCheckAndReturnNewVersions;
 
-// todo [anistor] need to review this for NBST
 /**
  * Abstractization for logic related to different clustering modes: replicated or distributed. This implements the <a
  * href=""http://en.wikipedia.org/wiki/Bridge_pattern"">Bridge</a> pattern as described by the GoF: this plays the role of
@@ -61,8 +59,6 @@
 @Scope(Scopes.NAMED_CACHE)
 public interface ClusteringDependentLogic {
 
-   Log log = LogFactory.getLog(ClusteringDependentLogic.class);
-
    boolean localNodeIsOwner(Object key);
 
    boolean localNodeIsPrimaryOwner(Object key);
@@ -77,10 +73,18 @@ public interface ClusteringDependentLogic {
    
    Address getAddress();
 
-   public static abstract class AbstractClusteringDependentLogic implements  ClusteringDependentLogic {
+   public static abstract class AbstractClusteringDependentLogic implements ClusteringDependentLogic {
+
+      protected DataContainer dataContainer;
 
       protected CacheNotifier notifier;
 
+      @Inject
+      public void init(DataContainer dataContainer, CacheNotifier notifier) {
+         this.dataContainer = dataContainer;
+         this.notifier = notifier;
+      }
+
       protected void notifyCommitEntry(boolean created, boolean removed,
             boolean evicted, CacheEntry entry, InvocationContext ctx) {
          // Eviction has no notion of pre/post event since 4.2.0.ALPHA4.
@@ -109,13 +113,61 @@ protected void notifyCommitEntry(boolean created, boolean removed,
    }
 
    /**
-    * This logic is used when a changing a key affects all the nodes in the cluster, e.g. int the replicated,
-    * invalidated and local cache modes.
+    * This logic is used in local mode caches.
     */
-   public static final class AllNodesLogic extends AbstractClusteringDependentLogic {
+   public static class LocalLogic extends AbstractClusteringDependentLogic {
+
+      @Override
+      public boolean localNodeIsOwner(Object key) {
+         return true;
+      }
+
+      @Override
+      public boolean localNodeIsPrimaryOwner(Object key) {
+         return true;
+      }
+
+      @Override
+      public Address getPrimaryOwner(Object key) {
+         throw new IllegalStateException(""Cannot invoke this method for local caches"");
+      }
+
+      @Override
+      public Collection<Address> getOwners(Collection<Object> keys) {
+         return null;
+      }
+
+      @Override
+      public Address getAddress() {
+         return null;
+      }
+
+      @Override
+      public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipOwnershipCheck, InvocationContext ctx) {
+         // Cache flags before they're reset
+         // TODO: Can the reset be done after notification instead?
+         boolean created = entry.isCreated();
+         boolean removed = entry.isRemoved();
+         boolean evicted = entry.isEvicted();
 
-      private DataContainer dataContainer;
+         entry.commit(dataContainer, newVersion);
+
+         // Notify after events if necessary
+         notifyCommitEntry(created, removed, evicted, entry, ctx);
+      }
+
+      @Override
+      public EntryVersionsMap createNewVersionsAndCheckForWriteSkews(VersionGenerator versionGenerator, TxInvocationContext context, VersionedPrepareCommand prepareCommand) {
+         throw new IllegalStateException(""Cannot invoke this method for local caches"");
+      }
+   }
 
+   /**
+    * This logic is used in invalidation mode caches.
+    */
+   public static class InvalidationLogic extends AbstractClusteringDependentLogic {
+
+      private StateTransferManager stateTransferManager;
       private RpcManager rpcManager;
 
       private static final WriteSkewHelper.KeySpecificLogic keySpecificLogic = new WriteSkewHelper.KeySpecificLogic() {
@@ -126,27 +178,24 @@ public boolean performCheckOnKey(Object key) {
       };
 
       @Inject
-      public void init(DataContainer dc, RpcManager rpcManager, CacheNotifier notifier) {
-         this.dataContainer = dc;
+      public void init(RpcManager rpcManager, StateTransferManager stateTransferManager) {
          this.rpcManager = rpcManager;
-         this.notifier = notifier;
+         this.stateTransferManager = stateTransferManager;
       }
 
       @Override
       public boolean localNodeIsOwner(Object key) {
-         return true;
+         return stateTransferManager.getCacheTopology().getWriteConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key);
       }
 
       @Override
       public boolean localNodeIsPrimaryOwner(Object key) {
-         return rpcManager == null || rpcManager.getTransport().isCoordinator();
+         return stateTransferManager.getCacheTopology().getWriteConsistentHash().locatePrimaryOwner(key).equals(rpcManager.getAddress());
       }
 
       @Override
       public Address getPrimaryOwner(Object key) {
-         if (rpcManager == null)
-            throw new IllegalStateException(""Cannot invoke this method for local caches"");
-         return rpcManager.getTransport().getCoordinator();
+         return stateTransferManager.getCacheTopology().getWriteConsistentHash().locatePrimaryOwner(key);
       }
 
       @Override
@@ -165,7 +214,7 @@ public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipO
 
       @Override
       public Collection<Address> getOwners(Collection<Object> keys) {
-         return null;
+         return null;    //todo [anistor] should I actually return this based on current CH?
       }
       
       @Override
@@ -176,7 +225,7 @@ public Address getAddress() {
       @Override
       public EntryVersionsMap createNewVersionsAndCheckForWriteSkews(VersionGenerator versionGenerator, TxInvocationContext context, VersionedPrepareCommand prepareCommand) {
          // In REPL mode, this happens if we are the coordinator.
-         if (rpcManager.getTransport().isCoordinator()) {
+         if (stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0).equals(rpcManager.getAddress())) {
             // Perform a write skew check on each entry.
             EntryVersionsMap uv = performWriteSkewCheckAndReturnNewVersions(prepareCommand, dataContainer,
                                                                             versionGenerator, context,
@@ -194,10 +243,35 @@ public EntryVersionsMap createNewVersionsAndCheckForWriteSkews(VersionGenerator
       }
    }
 
-   public static final class DistributionLogic extends AbstractClusteringDependentLogic {
+   /**
+    * This logic is used in replicated mode caches.
+    */
+   public static class ReplicationLogic extends InvalidationLogic {
+
+      private StateTransferLock stateTransferLock;
+
+      @Inject
+      public void init(StateTransferLock stateTransferLock) {
+         this.stateTransferLock = stateTransferLock;
+      }
+
+      @Override
+      public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipOwnershipCheck, InvocationContext ctx) {
+         stateTransferLock.acquireSharedTopologyLock();
+         try {
+            super.commitEntry(entry, newVersion, skipOwnershipCheck, ctx);
+         } finally {
+            stateTransferLock.releaseSharedTopologyLock();
+         }
+      }
+   }
+
+   /**
+    * This logic is used in distributed mode caches.
+    */
+   public static class DistributionLogic extends AbstractClusteringDependentLogic {
 
       private DistributionManager dm;
-      private DataContainer dataContainer;
       private Configuration configuration;
       private RpcManager rpcManager;
       private StateTransferLock stateTransferLock;
@@ -210,14 +284,12 @@ public boolean performCheckOnKey(Object key) {
       };
 
       @Inject
-      public void init(DistributionManager dm, DataContainer dataContainer, Configuration configuration,
-                       RpcManager rpcManager, StateTransferLock stateTransferLock, CacheNotifier notifier) {
+      public void init(DistributionManager dm, Configuration configuration,
+                       RpcManager rpcManager, StateTransferLock stateTransferLock) {
          this.dm = dm;
-         this.dataContainer = dataContainer;
          this.configuration = configuration;
          this.rpcManager = rpcManager;
          this.stateTransferLock = stateTransferLock;
-         this.notifier = notifier;
       }
 
       @Override",2013-03-07T23:03:03Z,172
"@@ -22,17 +22,12 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.affinity.KeyAffinityService;
-import org.infinispan.affinity.KeyAffinityServiceFactory;
-import org.infinispan.affinity.RndKeyGenerator;
 import org.infinispan.config.Configuration;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
 import javax.transaction.Transaction;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
 
 /**
  * @author Mircea.Markus@jboss.com",2013-03-07T23:03:03Z,497
"@@ -0,0 +1,152 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.interceptors;
+
+import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.read.GetKeyValueCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.Configuration;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
+import org.infinispan.container.entries.ImmortalCacheValue;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.distribution.TestAddress;
+import org.infinispan.distribution.ch.ReplicatedConsistentHash;
+import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.responses.SuccessfulResponse;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
+import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.Transport;
+import org.infinispan.statetransfer.StateTransferManager;
+import org.infinispan.topology.CacheTopology;
+import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.util.concurrent.locks.LockManager;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.mockito.invocation.InvocationOnMock;
+import org.mockito.stubbing.Answer;
+import org.testng.annotations.Test;
+
+import java.util.*;
+
+import static org.junit.Assert.assertEquals;
+import static org.mockito.Matchers.*;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+/**
+ * Tests ReplicationInterceptor.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""interceptors.ReplicationInterceptorTest"")
+public class ReplicationInterceptorTest {
+
+   private static final Log log = LogFactory.getLog(ReplicationInterceptorTest.class);
+
+   public void testRemoteGetForGetKeyValueCommand() throws Throwable {
+      ConfigurationBuilder cb = new ConfigurationBuilder();
+      cb.clustering().cacheMode(CacheMode.REPL_SYNC);
+
+      GlobalConfigurationBuilder gcb = GlobalConfigurationBuilder.defaultClusteredBuilder();
+      Configuration configuration = cb.build();
+
+      ReplicationInterceptor replInterceptor = new ReplicationInterceptor();
+      CommandInterceptor nextInterceptor = mock(CommandInterceptor.class);
+      when(nextInterceptor.visitGetKeyValueCommand(any(InvocationContext.class), any(GetKeyValueCommand.class))).thenReturn(null);
+      replInterceptor.setNext(nextInterceptor);
+
+      CommandsFactory commandsFactory = mock(CommandsFactory.class);
+      when(commandsFactory.buildClusteredGetCommand(any(Object.class), any(Set.class), anyBoolean(), any(GlobalTransaction.class))).thenAnswer(new Answer<ClusteredGetCommand>() {
+         @Override
+         public ClusteredGetCommand answer(InvocationOnMock invocation) {
+            Object key = invocation.getArguments()[0];
+            Set<Flag> flags = (Set<Flag>) invocation.getArguments()[1];
+            boolean acquireRemoteLock = (Boolean) invocation.getArguments()[2];
+            GlobalTransaction gtx = (GlobalTransaction) invocation.getArguments()[3];
+            return new ClusteredGetCommand(key, ""cache1"", flags, acquireRemoteLock, gtx);
+         }
+      });
+
+      EntryFactory entryFactory = mock(EntryFactory.class);
+      DataContainer dataContainer = mock(DataContainer.class);
+      LockManager lockManager = mock(LockManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
+
+      TestAddress A = new TestAddress(0, ""A"");
+      TestAddress B = new TestAddress(1, ""B"");
+      List<Address> members1 = new ArrayList<Address>();
+      List<Address> members2 = new ArrayList<Address>();
+      members1.add(A);
+      members2.add(A);
+      members2.add(B);
+      ReplicatedConsistentHash readCh = new ReplicatedConsistentHash(members1);
+      ReplicatedConsistentHash writeCh = new ReplicatedConsistentHash(members2);
+      final CacheTopology cacheTopology = new CacheTopology(1, readCh, writeCh);
+      when(stateTransferManager.getCacheTopology()).thenAnswer(new Answer<CacheTopology>() {
+         @Override
+         public CacheTopology answer(InvocationOnMock invocation) {
+            return cacheTopology;
+         }
+      });
+      replInterceptor.init(commandsFactory, entryFactory, dataContainer, lockManager, stateTransferManager);
+      RpcManager rpcManager = mock(RpcManager.class);
+      Transport transport = mock(Transport.class);
+      when(rpcManager.getAddress()).thenReturn(B);
+      when(rpcManager.getTransport()).thenReturn(transport);
+      when(transport.getMembers()).thenReturn(members2);
+      replInterceptor.inject(rpcManager);
+      replInterceptor.injectConfiguration(configuration);
+
+      when(rpcManager.invokeRemotely(any(Collection.class), any(ClusteredGetCommand.class), any(ResponseMode.class),
+            anyLong(), anyBoolean(), any(ResponseFilter.class))).thenAnswer(new Answer<Map<Address, Response>>() {
+         @Override
+         public Map<Address, Response> answer(InvocationOnMock invocation) {
+            Collection<Address> recipients = (Collection<Address>) invocation.getArguments()[0];
+            ClusteredGetCommand clusteredGetCommand = (ClusteredGetCommand) invocation.getArguments()[1];
+            if (clusteredGetCommand.getKey().equals(""theKey"")) {
+               Map<Address, Response> results = new HashMap<Address, Response>();
+               for (Address recipient : recipients) {
+                  results.put(recipient, SuccessfulResponse.create(new ImmortalCacheValue(""theValue"")));
+               }
+               return results;
+            }
+            return Collections.emptyMap();
+         }
+      });
+
+      InvocationContext ctx = mock(InvocationContext.class);
+      when(ctx.isOriginLocal()).thenReturn(true);
+      when(ctx.isInTxScope()).thenReturn(false);
+
+      GetKeyValueCommand getKeyValueCommand = new GetKeyValueCommand(""theKey"", null);
+
+      Object retVal = replInterceptor.visitGetKeyValueCommand(ctx, getKeyValueCommand);
+      assertEquals(""theValue"", retVal);
+   }
+}",2013-03-07T23:03:03Z,103
"@@ -39,7 +39,7 @@
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
-@Test(groups = ""functional"", testName = ""replication.BaseReplicatedAPITest"")
+@Test(groups = ""functional"")
 public abstract class BaseReplicatedAPITest extends MultipleCacheManagersTest {
 
    protected boolean isSync;
@@ -150,7 +150,7 @@ public void testRemoveIfPresent() {
       waitForRpc(cache2);
 
       assert cache1.get(""key"") == null;
-      assert cache2.get(""key"").equals(""value2"");
+      assert cache2.get(""key"") == null;
    }
 
    public void testClear() {
@@ -214,8 +214,9 @@ public void testReplaceWithOldVal() {
       cache1.replace(""key"", ""valueN"", ""value1"");
       waitForRpc(cache2);
 
-      assert cache1.get(""key"").equals(""value1"");
-      assert cache2.get(""key"").equals(""value2"");
+      // the replace executed identically on both of them
+      assertEquals(""value1"", cache1.get(""key""));
+      assertEquals(""value1"", cache2.get(""key""));
    }
 
    public void testLocalOnlyClear() {",2013-03-07T23:03:03Z,282
"@@ -120,7 +120,6 @@ public void testPutIfAbsent() throws Exception {
       testStateTransferConsistency(Operation.PUT_IF_ABSENT);
    }
 
-   @Test(enabled = false)  // disabled due to ISPN-2647
    public void testReplace() throws Exception {
       testStateTransferConsistency(Operation.REPLACE);
    }
@@ -222,9 +221,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
       TestingUtil.waitForRehashToComplete(cache(0), cache(1), cache(2));
 
       // at this point state transfer is fully done
-      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.keySet());
-      log.infof(""Data container of NodeB has %d keys: %s"", dc1.size(), dc1.keySet());
-      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.keySet());
+      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.entrySet());
+      log.infof(""Data container of NodeB has %d keys: %s"", dc1.size(), dc1.entrySet());
+      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.entrySet());
 
       if (op == Operation.CLEAR || op == Operation.REMOVE) {
          // caches should be empty. check that no keys were revived by an inconsistent state transfer
@@ -253,9 +252,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
    }
 
    private void assertValue(int cacheIndex, int key, String expectedValue) {
-      InternalCacheEntry object = cache(cacheIndex).getAdvancedCache().getDataContainer().get(key);
-      assertNotNull(object);
-      assertEquals(expectedValue, object.getValue());
-      assertEquals(expectedValue, cache(cacheIndex).get(key));
+      InternalCacheEntry ice = cache(cacheIndex).getAdvancedCache().getDataContainer().get(key);
+      assertNotNull(""Found null on cache "" + cacheIndex,  ice);
+      assertEquals(""Did not find the expected value on cache "" + cacheIndex, expectedValue, ice.getValue());
+      assertEquals(""Did not find the expected value on cache "" + cacheIndex, expectedValue, cache(cacheIndex).get(key));
    }
 }",2013-03-07T23:03:03Z,498
"@@ -0,0 +1,40 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplNonTxOperationsDuringStateTransferTest"")
+@CleanupAfterMethod
+public class ReplNonTxOperationsDuringStateTransferTest extends BaseOperationsDuringStateTransferTest {
+
+   public ReplNonTxOperationsDuringStateTransferTest() {
+      super(CacheMode.REPL_SYNC, false, false, false);
+   }
+}",2013-03-07T23:03:03Z,499
"@@ -0,0 +1,40 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplOptimisticTxOperationsDuringStateTransferTest"")
+@CleanupAfterMethod
+public class ReplOptimisticTxOperationsDuringStateTransferTest extends BaseOperationsDuringStateTransferTest {
+
+   public ReplOptimisticTxOperationsDuringStateTransferTest() {
+      super(CacheMode.REPL_SYNC, true, true, false);
+   }
+}",2013-03-07T23:03:03Z,500
"@@ -0,0 +1,57 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplPessimisticOperationsDuringStateTransferTest"",
+      enabled = false, description = ""Disabled due to https://issues.jboss.org/browse/ISPN-2847"")
+@CleanupAfterMethod
+public class ReplPessimisticOperationsDuringStateTransferTest extends BaseOperationsDuringStateTransferTest {
+
+   public ReplPessimisticOperationsDuringStateTransferTest() {
+      super(CacheMode.REPL_SYNC, true, false, false);
+   }
+
+   @Test(enabled = false)
+   public void testPut() throws Exception {
+   }
+
+   @Test(enabled = false)
+   public void testReplace() throws Exception {
+   }
+
+   @Test(enabled = false)
+   public void testGet() throws Exception {
+   }
+
+   @Test(enabled = false)
+   public void testRemove() throws Exception {
+   }
+}",2013-03-07T23:03:03Z,501
"@@ -68,10 +68,10 @@ public void setUp() {
       txTable.addLocalTransactionMapping(localTx);      
 
       configuration = new ConfigurationBuilder().build();
-      TransactionCoordinator txCoordinator = new TransactionCoordinator();
+      txCoordinator = new TransactionCoordinator();
       txCoordinator.init(null, null, null, null, configuration);
       xaAdapter = new TransactionXaAdapter(localTx, txTable, null, txCoordinator, null, null,
-                                           new ClusteringDependentLogic.AllNodesLogic(), configuration, """");
+                                           new ClusteringDependentLogic.InvalidationLogic(), configuration, """");
    }
 
    public void testPrepareOnNonexistentXid() {",2013-03-07T23:03:03Z,94
"@@ -26,6 +26,7 @@
 import org.infinispan.CacheException;
 import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.configuration.global.GlobalConfiguration;
@@ -35,6 +36,7 @@
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.jmx.annotations.ManagedOperation;
+import org.infinispan.newstatetransfer.StateTransferManager;
 import org.infinispan.remoting.ReplicationQueue;
 import org.infinispan.remoting.RpcException;
 import org.infinispan.remoting.responses.IgnoreExtraResponsesValidityFilter;
@@ -95,13 +97,15 @@ public class RpcManagerImpl implements RpcManager {
    private ExecutorService asyncExecutor;
    private CommandsFactory cf;
    private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
 
    @Inject
    public void injectDependencies(Transport t, Cache cache, Configuration cfg,
             ReplicationQueue replicationQueue, CommandsFactory cf,
             @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService e,
-            LocalTopologyManager localTopologyManager, GlobalConfiguration globalCfg) {
+            LocalTopologyManager localTopologyManager, StateTransferManager stateTransferManager,
+            GlobalConfiguration globalCfg) {
       this.t = t;
       this.configuration = cfg;
       this.cacheName = cache.getName();
@@ -110,6 +114,7 @@ public void injectDependencies(Transport t, Cache cache, Configuration cfg,
       this.asyncExecutor = e;
       this.cf = cf;
       this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
    }
 
    @Start(priority = 9)
@@ -165,6 +170,9 @@ public final Map<Address, Response> invokeRemotely(Collection<Address> recipient
                   responseFilter = new IgnoreExtraResponsesValidityFilter(cacheMembers, getAddress());
                }
             }
+            if (rpcCommand instanceof TopologyAffectedCommand) {
+               ((TopologyAffectedCommand)rpcCommand).setTopologyId(stateTransferManager.getTopologyId());
+            }
             Map<Address, Response> result = t.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue, responseFilter);
             if (statisticsEnabled) replicationCount.incrementAndGet();
             return result;",2012-08-31T21:04:20Z,105
"@@ -22,10 +22,6 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.context.InvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
@@ -95,24 +91,6 @@ public interface DistributionManager {
     */
    Set<Address> locateAll(Collection<Object> keys); //todo [anistor] this has to take an additional parameter that specifies if the lookup is for read or write
 
-   /**
-    * Transforms a cache entry so it is marked for L1 rather than the primary cache data structure.  This should be done
-    * if it is deemed that the entry is targeted for L1 storage rather than storage in the primary data container.
-    *
-    * @param entry entry to transform
-    */
-   void transformForL1(CacheEntry entry);
-
-   /**
-    * Retrieves a cache entry from a remote source.  Would typically involve an RPC call using a {@link org.infinispan.commands.remote.ClusteredGetCommand}
-    * and some form of quorum of responses if the responses returned are inconsistent - often the case if there is a
-    * rehash in progress, involving nodes that the key maps to.
-    *
-    * @param key key to look up
-    * @return an internal cache entry, or null if it cannot be located
-    */
-   InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception;
-
    /**
     * Retrieves the consistent hash instance currently in use, an instance of the configured ConsistentHash
     * class (which defaults to {@link org.infinispan.distribution.ch.DefaultConsistentHash}.",2013-03-07T23:03:04Z,60
"@@ -22,31 +22,16 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.commands.CommandsFactory;
-import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.commands.remote.ClusteredGetCommand;
-import org.infinispan.configuration.cache.Configuration;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalCacheValue;
-import org.infinispan.context.InvocationContext;
-import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.jmx.annotations.Parameter;
 import org.infinispan.statetransfer.StateTransferManager;
-import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
-import org.infinispan.remoting.responses.Response;
-import org.infinispan.remoting.responses.SuccessfulResponse;
-import org.infinispan.remoting.rpc.ResponseFilter;
-import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
@@ -70,9 +55,7 @@ public class DistributionManagerImpl implements DistributionManager {
    private static final boolean trace = log.isTraceEnabled();
 
    // Injected components
-   private Configuration configuration;
    private RpcManager rpcManager;
-   private CommandsFactory cf;
    private StateTransferManager stateTransferManager;
 
    /**
@@ -82,11 +65,8 @@ public DistributionManagerImpl() {
    }
 
    @Inject
-   public void init(Configuration configuration, RpcManager rpcManager, CommandsFactory cf,
-                    StateTransferManager stateTransferManager) {
-      this.configuration = configuration;
+   public void init(RpcManager rpcManager, StateTransferManager stateTransferManager) {
       this.rpcManager = rpcManager;
-      this.cf = cf;
       this.stateTransferManager = stateTransferManager;
    }
 
@@ -147,39 +127,6 @@ public Set<Address> locateAll(Collection<Object> keys) {
       return getConsistentHash().locateAllOwners(keys);
    }
 
-   @Override
-   public void transformForL1(CacheEntry entry) {
-      if (entry.getLifespan() < 0 || entry.getLifespan() > configuration.clustering().l1().lifespan())
-         entry.setLifespan(configuration.clustering().l1().lifespan());
-   }
-
-   @Override
-   public InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception {
-      GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
-      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
-
-      List<Address> targets = new ArrayList<Address>(getReadConsistentHash().locateOwners(key));
-      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
-      targets.retainAll(rpcManager.getTransport().getMembers());
-      ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, getAddress());
-      Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
-                                                                   configuration.clustering().sync().replTimeout(), true, filter);
-
-      if (!responses.isEmpty()) {
-         for (Response r : responses.values()) {
-            if (r instanceof SuccessfulResponse) {
-               InternalCacheValue cacheValue = (InternalCacheValue) ((SuccessfulResponse) r).getResponseValue();
-               return cacheValue.toInternalCacheEntry(key);
-            }
-         }
-      }
-
-      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
-      // Otherwise our get command might be processed by the old owners after they have invalidated their data
-      // and we'd return a null even though the key exists on
-      return null;
-   }
-
    @Override
    public ConsistentHash getConsistentHash() {
       return getWriteConsistentHash();",2013-03-07T23:03:04Z,60
"@@ -0,0 +1,120 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.interceptors;
+
+import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.FlagAffectedCommand;
+import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.factories.annotations.Inject;
+import org.infinispan.factories.annotations.Start;
+import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.statetransfer.StateTransferManager;
+import org.infinispan.util.concurrent.locks.LockManager;
+
+/**
+ * Base class for replication and distribution interceptors.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+public abstract class ClusteringInterceptor extends BaseRpcInterceptor {
+
+   protected CommandsFactory cf;
+   protected EntryFactory entryFactory;
+   protected LockManager lockManager;
+   protected DataContainer dataContainer;
+   protected StateTransferManager stateTransferManager;
+   protected boolean needReliableReturnValues;
+
+   @Inject
+   public void injectDependencies(CommandsFactory cf, EntryFactory entryFactory,
+                                  LockManager lockManager, DataContainer dataContainer,
+                                  StateTransferManager stateTransferManager) {
+      this.cf = cf;
+      this.entryFactory = entryFactory;
+      this.lockManager = lockManager;
+      this.dataContainer = dataContainer;
+      this.stateTransferManager = stateTransferManager;
+   }
+
+   @Start
+   public void configure() {
+      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
+   }
+
+   protected boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
+      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+   }
+
+   protected boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
+      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
+            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
+         return false;
+      }
+      boolean shouldFetchFromRemote = false;
+      CacheEntry entry = ctx.lookupEntry(command.getKey());
+      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
+         Object key = command.getKey();
+         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
+         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
+         if (!shouldFetchFromRemote && getLog().isTraceEnabled()) {
+            getLog().tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s) or is in L1. Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
+         }
+      }
+      return shouldFetchFromRemote;
+   }
+
+   /**
+    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
+    * <pre>
+    * - node A (owner, tx originator) does a successful replace
+    * - the actual value changes
+    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
+    *   B (check is performed at commit time).
+    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
+    * </pre>
+    */
+   protected boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return ctx.isOriginLocal() && command.isSuccessful();
+   }
+
+   /**
+    * Retrieves a cache entry from a remote source.  Would typically involve an RPC call using a {@link org.infinispan.commands.remote.ClusteredGetCommand}
+    * and some form of quorum of responses if the responses returned are inconsistent - often the case if there is a
+    * rehash in progress, involving nodes that the key maps to.
+    *
+    * @param key key to look up
+    * @return an internal cache entry, or null if it cannot be located
+    */
+   protected abstract InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception;
+}",2013-03-07T23:03:04Z,482
"@@ -22,7 +22,6 @@
  */
 package org.infinispan.interceptors;
 
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.AbstractDataCommand;
@@ -35,30 +34,21 @@
 import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configurations;
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.EntryFactory;
-import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.InternalCacheValue;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.ch.ConsistentHash;
-import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
-import org.infinispan.interceptors.base.BaseRpcInterceptor;
 import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
 import org.infinispan.remoting.responses.Response;
 import org.infinispan.remoting.responses.SuccessfulResponse;
 import org.infinispan.remoting.rpc.ResponseFilter;
 import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.jgroups.SuspectException;
-import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.xa.GlobalTransaction;
-import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -71,16 +61,8 @@
  * @author Bela Ban
  * @since 4.0
  */
-public class ReplicationInterceptor extends BaseRpcInterceptor {
+public class ReplicationInterceptor extends ClusteringInterceptor {
 
-   private CommandsFactory cf;
-
-   private EntryFactory entryFactory;
-   private LockManager lockManager;
-   private DataContainer dataContainer;
-   private StateTransferManager stateTransferManager;
-
-   private boolean needReliableReturnValues;
    private boolean isPessimisticCache;
 
    private static final Log log = LogFactory.getLog(ReplicationInterceptor.class);
@@ -91,19 +73,9 @@ protected Log getLog() {
       return log;
    }
 
-   @Inject
-   public void init(CommandsFactory cf, EntryFactory entryFactory, DataContainer dataContainer, LockManager lockManager, StateTransferManager stateTransferManager) {
-      this.cf = cf;
-      this.entryFactory = entryFactory;
-      this.dataContainer = dataContainer;
-      this.lockManager = lockManager;
-      this.stateTransferManager = stateTransferManager;
-   }
-
    @Start
    public void start() {
       isPessimisticCache = cacheConfiguration.transaction().lockingMode() == LockingMode.PESSIMISTIC;
-      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
    }
 
    @Override
@@ -180,44 +152,6 @@ public Object visitLockControlCommand(TxInvocationContext ctx, LockControlComman
       return retVal;
    }
 
-   private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] clarify usage of this flag in REPL mode
-            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
-         return false;
-      }
-      boolean shouldFetchFromRemote = false;
-      CacheEntry entry = ctx.lookupEntry(command.getKey());
-      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
-         Object key = command.getKey();
-         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
-         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
-         if (!shouldFetchFromRemote) {
-            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s). Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
-         }
-      }
-      return shouldFetchFromRemote;
-   }
-
-   private boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
-      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
-   }
-
-   /**
-    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
-    * <pre>
-    * - node A (owner, tx originator) does a successful replace
-    * - the actual value changes
-    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
-    *   B (check is performed at commit time).
-    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
-    * </pre>
-    */
-   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
-      return ctx.isOriginLocal() && command.isSuccessful();
-   }
-
    /**
     * This method retrieves an entry from a remote cache.
     * <p/>
@@ -242,7 +176,7 @@ private Object remoteGet(InvocationContext ctx, Object key, FlagAffectedCommand
          acquireRemoteLock = isWrite && isPessimisticCache && !txContext.getAffectedKeys().contains(key);
       }
       // attempt a remote lookup
-      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command.getFlags());
+      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
 
       if (acquireRemoteLock) {
          ((TxInvocationContext) ctx).addAffectedKey(key);
@@ -265,9 +199,9 @@ protected Address getPrimaryOwner() {
       return stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0);
    }
 
-   private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, Set<Flag> flags) {
+   protected InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) {
       GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
-      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, flags, acquireRemoteLock, gtx);
+      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
 
       List<Address> targets = Collections.singletonList(getPrimaryOwner());
       ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
@@ -289,7 +223,7 @@ private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContex
    private Object localGet(InvocationContext ctx, Object key, boolean isWrite, FlagAffectedCommand command) throws Throwable {
       InternalCacheEntry ice = dataContainer.get(key);
       if (ice != null) {
-         if (!ctx.replaceValue(key, ice.getValue()))  {
+         if (!ctx.replaceValue(key, ice.getValue())) {
             if (isWrite)
                lockAndWrap(ctx, key, ice, command);
             else",2013-03-07T23:03:04Z,103
"@@ -22,34 +22,32 @@
  */
 package org.infinispan.interceptors.distribution;
 
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.write.PutMapCommand;
 import org.infinispan.commands.write.RemoveCommand;
 import org.infinispan.commands.write.ReplaceCommand;
 import org.infinispan.commands.write.WriteCommand;
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.EntryFactory;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.container.entries.InternalCacheValue;
 import org.infinispan.context.InvocationContext;
-import org.infinispan.distribution.DataLocality;
+import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.DistributionManager;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
-import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.interceptors.ClusteringInterceptor;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
+import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.responses.SuccessfulResponse;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
-import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 
 /**
  * Base class for distribution of entries across a cluster.
@@ -60,14 +58,11 @@
  * @author Dan Berindei <dan@infinispan.org>
  * @since 4.0
  */
-public abstract class BaseDistributionInterceptor extends BaseRpcInterceptor {
+public abstract class BaseDistributionInterceptor extends ClusteringInterceptor {
+
    protected DistributionManager dm;
-   protected CommandsFactory cf;
-   protected DataContainer dataContainer;
-   protected EntryFactory entryFactory;
-   protected LockManager lockManager;
+
    protected ClusteringDependentLogic cdl;
-   private boolean needReliableReturnValues;
 
    private static final Log log = LogFactory.getLog(BaseDistributionInterceptor.class);
 
@@ -77,42 +72,36 @@ protected Log getLog() {
    }
 
    @Inject
-   public void injectDependencies(DistributionManager distributionManager,
-                                  CommandsFactory cf, DataContainer dataContainer, EntryFactory entryFactory,
-                                  LockManager lockManager, ClusteringDependentLogic cdl) {
+   public void injectDependencies(DistributionManager distributionManager, ClusteringDependentLogic cdl) {
       this.dm = distributionManager;
-      this.cf = cf;
-      this.dataContainer = dataContainer;
-      this.entryFactory = entryFactory;
-      this.lockManager = lockManager;
       this.cdl = cdl;
    }
 
-   @Start
-   public void configure() {
-      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
-   }
-
-   protected boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      boolean shouldFetchFromRemote = false;
-      final CacheEntry entry;
-      if (!command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            && !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES)
-            && ((entry = ctx.lookupEntry(command.getKey())) == null || entry.isNull() || entry.isLockPlaceholder())) {
-         Object key = command.getKey();
-         DataLocality locality = dm.getReadConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key) ? DataLocality.LOCAL : DataLocality.NOT_LOCAL;
-         shouldFetchFromRemote = ctx.isOriginLocal() && !locality.isLocal() && !dataContainer.containsKey(key);
-         if (!shouldFetchFromRemote) {
-            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s), or is in L1.  Owners are %s"", key, rpcManager.getAddress(), dm.locate(key));
+   @Override
+   protected InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception {
+      GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
+      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
+
+      List<Address> targets = new ArrayList<Address>(stateTransferManager.getCacheTopology().getReadConsistentHash().locateOwners(key));
+      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
+      targets.retainAll(rpcManager.getTransport().getMembers());
+      ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
+      Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
+            cacheConfiguration.clustering().sync().replTimeout(), true, filter);
+
+      if (!responses.isEmpty()) {
+         for (Response r : responses.values()) {
+            if (r instanceof SuccessfulResponse) {
+               InternalCacheValue cacheValue = (InternalCacheValue) ((SuccessfulResponse) r).getResponseValue();
+               return cacheValue.toInternalCacheEntry(key);
+            }
          }
       }
-      return shouldFetchFromRemote;
-   }
 
-   protected boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
-      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
+      // Otherwise our get command might be processed by the old owners after they have invalidated their data
+      // and we'd return a null even though the key exists on
+      return null;
    }
 
    @Override
@@ -157,9 +146,9 @@ interface RecipientGenerator extends KeyGenerator {
    }
 
    class SingleKeyRecipientGenerator implements RecipientGenerator {
-      final Object key;
-      final Set<Object> keys;
-      List<Address> recipients = null;
+      private final Object key;
+      private final Set<Object> keys;
+      private List<Address> recipients = null;
 
       SingleKeyRecipientGenerator(Object key) {
          this.key = key;
@@ -180,8 +169,8 @@ public Collection<Object> getKeys() {
 
    class MultipleKeysRecipientGenerator implements RecipientGenerator {
 
-      final Collection<Object> keys;
-      List<Address> recipients = null;
+      private final Collection<Object> keys;
+      private List<Address> recipients = null;
 
       MultipleKeysRecipientGenerator(Collection<Object> keys) {
          this.keys = keys;",2013-03-07T23:03:04Z,478
"@@ -140,7 +140,7 @@ private Object remoteGetBeforeWrite(InvocationContext ctx, Object key, FlagAffec
          if (trace) log.tracef(""Doing a remote get for key %s"", key);
 
          // attempt a remote lookup
-         InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, false, command);
+         InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, false, command);
          if (ice != null) {
             if (!ctx.replaceValue(key, ice.getValue())) {
                entryFactory.wrapEntryForPut(ctx, key, ice, false, command);
@@ -190,7 +190,7 @@ protected void handleRemoteWrite(InvocationContext ctx, WriteCommand command, Re
 
    private Object remoteGet(InvocationContext ctx, Object key, GetKeyValueCommand command) throws Throwable {
       if (trace) log.tracef(""Doing a remote get for key %s"", key);
-      InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, false, command);
+      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, false, command);
       command.setRemotelyFetchedValue(ice);
       if (ice != null) {
          return ice.getValue();",2013-03-07T23:03:04Z,483
"@@ -117,8 +117,9 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
     * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
     * </pre>
     */
-   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
-      return ctx.isOriginLocal() && command.isSuccessful() && cacheConfiguration.transaction().lockingMode() == LockingMode.OPTIMISTIC && !useClusteredWriteSkewCheck;
+   protected boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return super.ignorePreviousValueOnBackup(command, ctx)
+          && cacheConfiguration.transaction().lockingMode() == LockingMode.OPTIMISTIC && !useClusteredWriteSkewCheck;
    }
 
    @Start
@@ -176,7 +177,6 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
       }
    }
 
-
    private void lockAndWrap(InvocationContext ctx, Object key, InternalCacheEntry ice, FlagAffectedCommand command) throws InterruptedException {
       boolean skipLocking = hasSkipLocking(command);
       long lockTimeout = getLockAcquisitionTimeout(command, skipLocking);
@@ -341,7 +341,7 @@ private Object remoteGetAndStoreInL1(InvocationContext ctx, Object key, boolean
             acquireRemoteLock = isWrite && isPessimisticCache && !txContext.getAffectedKeys().contains(key);
          }
          // attempt a remote lookup
-         InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
+         InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
 
          if (acquireRemoteLock) {
             ((TxInvocationContext) ctx).addAffectedKey(key);",2013-03-07T23:03:04Z,484
"@@ -324,7 +324,9 @@ public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipO
             boolean isForeignOwned = !skipOwnershipCheck && !localNodeIsOwner(entry.getKey());
             if (isForeignOwned && !entry.isRemoved()) {
                if (configuration.clustering().l1().enabled()) {
-                  dm.transformForL1(entry);
+                  // transform for L1
+                  if (entry.getLifespan() < 0 || entry.getLifespan() > configuration.clustering().l1().lifespan())
+                     entry.setLifespan(configuration.clustering().l1().lifespan());
                } else {
                   doCommit = false;
                }",2013-03-07T23:03:04Z,172
"@@ -45,8 +45,6 @@
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.concurrent.locks.LockManager;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
 import org.testng.annotations.Test;
@@ -67,8 +65,6 @@
 @Test(groups = ""functional"", testName = ""interceptors.ReplicationInterceptorTest"")
 public class ReplicationInterceptorTest {
 
-   private static final Log log = LogFactory.getLog(ReplicationInterceptorTest.class);
-
    public void testRemoteGetForGetKeyValueCommand() throws Throwable {
       ConfigurationBuilder cb = new ConfigurationBuilder();
       cb.clustering().cacheMode(CacheMode.REPL_SYNC);
@@ -114,7 +110,7 @@ public CacheTopology answer(InvocationOnMock invocation) {
             return cacheTopology;
          }
       });
-      replInterceptor.init(commandsFactory, entryFactory, dataContainer, lockManager, stateTransferManager);
+      replInterceptor.injectDependencies(commandsFactory, entryFactory, lockManager, dataContainer, stateTransferManager);
       RpcManager rpcManager = mock(RpcManager.class);
       Transport transport = mock(Transport.class);
       when(rpcManager.getAddress()).thenReturn(B);",2013-03-07T23:03:04Z,103
"@@ -238,8 +238,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
       TestingUtil.waitForRehashToComplete(cache(0), cache(2));
 
       // at this point state transfer is fully done
-      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.keySet());
-      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.keySet());
+      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.entrySet());
+      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.entrySet());
 
       if (op == Operation.CLEAR || op == Operation.REMOVE) {
          // caches should be empty. check that no keys were revived by an inconsistent state transfer
@@ -262,7 +262,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
             assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
 
             // check values were not overwritten with old values carried by state transfer
-            assertEquals(""after_st_"" + i, cache(0).get(i));
+            String expected = ""after_st_"" + i;
+            assertEquals(expected, cache(0).get(i));
             assertEquals(""after_st_"" + i, cache(2).get(i));
          }
       } else { // PUT_IF_ABSENT
@@ -278,8 +279,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
             }
             assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
 
-            assertEquals(""before_st_"" + i, cache(0).get(i));
-            assertEquals(""before_st_"" + i, cache(2).get(i));
+            String expected = ""before_st_"" + i;
+            assertEquals(expected, cache(0).get(i));
+            assertEquals(expected, cache(2).get(i));
          }
       }
    }",2013-03-07T23:03:04Z,485
"@@ -168,7 +168,7 @@ public boolean isSuccessful() {
 
    @Override
    public boolean isConditional() {
-      return true;
+      return !ignorePreviousValue;
    }
 
    public long getLifespanMillis() {",2013-03-07T23:03:03Z,493
"@@ -81,8 +81,12 @@ public <T> T construct(Class<T> componentType) {
       Class<?> componentImpl;
       if (componentType.equals(ClusteringDependentLogic.class)) {
          CacheMode cacheMode = configuration.clustering().cacheMode();
-         if (cacheMode.isReplicated() || !cacheMode.isClustered() || cacheMode.isInvalidation()) {
-            return componentType.cast(new ClusteringDependentLogic.AllNodesLogic());
+         if (!cacheMode.isClustered()) {
+            return componentType.cast(new ClusteringDependentLogic.LocalLogic());
+         } else if (cacheMode.isInvalidation()) {
+            return componentType.cast(new ClusteringDependentLogic.InvalidationLogic());
+         } else if (cacheMode.isReplicated()) {
+            return componentType.cast(new ClusteringDependentLogic.ReplicationLogic());
          } else {
             return componentType.cast(new ClusteringDependentLogic.DistributionLogic());
          }",2013-03-07T23:03:03Z,494
"@@ -23,28 +23,28 @@
 package org.infinispan.interceptors;
 
 import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.read.GetCacheEntryCommand;
 import org.infinispan.commands.read.GetKeyValueCommand;
 import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.tx.RollbackCommand;
-import org.infinispan.commands.write.ClearCommand;
-import org.infinispan.commands.write.PutKeyValueCommand;
-import org.infinispan.commands.write.PutMapCommand;
-import org.infinispan.commands.write.RemoveCommand;
-import org.infinispan.commands.write.ReplaceCommand;
-import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configurations;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.InternalCacheValue;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
+import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.interceptors.base.BaseRpcInterceptor;
@@ -58,13 +58,11 @@
 import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.TimeoutException;
 
 /**
@@ -75,10 +73,14 @@
  */
 public class ReplicationInterceptor extends BaseRpcInterceptor {
 
-   protected CommandsFactory cf;
+   private CommandsFactory cf;
 
+   private EntryFactory entryFactory;
+   private LockManager lockManager;
+   private DataContainer dataContainer;
    private StateTransferManager stateTransferManager;
 
+   private boolean needReliableReturnValues;
    private boolean isPessimisticCache;
 
    private static final Log log = LogFactory.getLog(ReplicationInterceptor.class);
@@ -90,14 +92,18 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(CommandsFactory cf, StateTransferManager stateTransferManager) {
+   public void init(CommandsFactory cf, EntryFactory entryFactory, DataContainer dataContainer, LockManager lockManager, StateTransferManager stateTransferManager) {
       this.cf = cf;
+      this.entryFactory = entryFactory;
+      this.dataContainer = dataContainer;
+      this.lockManager = lockManager;
       this.stateTransferManager = stateTransferManager;
    }
 
    @Start
    public void start() {
       isPessimisticCache = cacheConfiguration.transaction().lockingMode() == LockingMode.PESSIMISTIC;
+      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
    }
 
    @Override
@@ -149,7 +155,10 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
          // the entry is mapped to the local node.
          if (returnValue == null && ctx.isOriginLocal()) {
             if (needsRemoteGet(ctx, command)) {
-               returnValue = remoteGet(ctx, command, false);
+               returnValue = remoteGet(ctx, command.getKey(), command, false);
+            }
+            if (returnValue == null) {
+               returnValue = localGet(ctx, command.getKey(), false, command);
             }
          }
          return returnValue;
@@ -172,15 +181,43 @@ public Object visitLockControlCommand(TxInvocationContext ctx, LockControlComman
    }
 
    private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      Object key = command.getKey();
-      final CacheEntry entry;
-      return !command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            && !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] do we need this? it should normally be used only in distributed mode, never in replicated mode
-            && !stateTransferManager.getCacheTopology().getReadConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key)
-            && ((entry = ctx.lookupEntry(key)) == null || entry.isNull() || entry.isLockPlaceholder());
+      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
+            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] clarify usage of this flag in REPL mode
+            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
+         return false;
+      }
+      boolean shouldFetchFromRemote = false;
+      CacheEntry entry = ctx.lookupEntry(command.getKey());
+      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
+         Object key = command.getKey();
+         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
+         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
+         if (!shouldFetchFromRemote) {
+            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s). Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
+         }
+      }
+      return shouldFetchFromRemote;
+   }
+
+   private boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
+      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+   }
+
+   /**
+    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
+    * <pre>
+    * - node A (owner, tx originator) does a successful replace
+    * - the actual value changes
+    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
+    *   B (check is performed at commit time).
+    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
+    * </pre>
+    */
+   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return ctx.isOriginLocal() && command.isSuccessful();
    }
 
-   //todo [anistor] need to revise these methods
    /**
     * This method retrieves an entry from a remote cache.
     * <p/>
@@ -190,12 +227,12 @@ private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand comman
     *
     *
     * @param ctx invocation context
+    * @param key
     * @param command
     * @return value of a remote get, or null
     * @throws Throwable if there are problems
     */
-   private Object remoteGet(InvocationContext ctx, AbstractDataCommand command, boolean isWrite) throws Throwable {
-      Object key = command.getKey();
+   private Object remoteGet(InvocationContext ctx, Object key, FlagAffectedCommand command, boolean isWrite) throws Throwable {
       if (trace) {
          log.tracef(""Key %s is not yet available on %s, so we may need to look elsewhere"", key, rpcManager.getAddress());
       }
@@ -211,16 +248,28 @@ private Object remoteGet(InvocationContext ctx, AbstractDataCommand command, boo
          ((TxInvocationContext) ctx).addAffectedKey(key);
       }
 
-      return ice != null ? ice.getValue() : null;
+      if (ice != null) {
+         if (!ctx.replaceValue(key, ice.getValue()))  {
+            if (isWrite) {
+               lockAndWrap(ctx, key, ice, command);
+            } else {
+               ctx.putLookedUpEntry(key, ice);
+            }
+         }
+         return ice.getValue();
+      }
+      return null;
+   }
+
+   protected Address getPrimaryOwner() {
+      return stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0);
    }
 
    private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, Set<Flag> flags) {
       GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
       ClusteredGetCommand get = cf.buildClusteredGetCommand(key, flags, acquireRemoteLock, gtx);
 
-      List<Address> targets = new ArrayList<Address>(stateTransferManager.getCacheTopology().getReadConsistentHash().locateOwners(key));
-      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
-      targets.retainAll(rpcManager.getTransport().getMembers());
+      List<Address> targets = Collections.singletonList(getPrimaryOwner());
       ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
       Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
             cacheConfiguration.clustering().sync().replTimeout(), true, filter);
@@ -237,36 +286,77 @@ private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContex
       return null;
    }
 
+   private Object localGet(InvocationContext ctx, Object key, boolean isWrite, FlagAffectedCommand command) throws Throwable {
+      InternalCacheEntry ice = dataContainer.get(key);
+      if (ice != null) {
+         if (!ctx.replaceValue(key, ice.getValue()))  {
+            if (isWrite)
+               lockAndWrap(ctx, key, ice, command);
+            else
+               ctx.putLookedUpEntry(key, ice);
+         }
+         return command instanceof GetCacheEntryCommand ? ice : ice.getValue();
+      }
+      return null;
+   }
+
+   private void lockAndWrap(InvocationContext ctx, Object key, InternalCacheEntry ice, FlagAffectedCommand command) throws InterruptedException {
+      if (isPessimisticCache && rpcManager.getAddress().equals(getPrimaryOwner())) {
+         boolean skipLocking = hasSkipLocking(command);
+         long lockTimeout = getLockAcquisitionTimeout(command, skipLocking);
+         lockManager.acquireLock(ctx, key, lockTimeout, skipLocking);
+      }
+      entryFactory.wrapEntryForPut(ctx, key, ice, false, command);
+   }
+
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      return handleCrudMethod(ctx, command, !ctx.isOriginLocal());
    }
 
    @Override
    public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      return handleCrudMethod(ctx, command, true);
    }
 
    @Override
    public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      try {
+         return handleCrudMethod(ctx, command, !ctx.isOriginLocal());
+      } finally {
+         if (ignorePreviousValueOnBackup(command, ctx)) {
+            // the command that will execute remotely must ignore previous values
+            command.setIgnorePreviousValue(true);
+         }
+      }
    }
 
    @Override
    public Object visitClearCommand(InvocationContext ctx, ClearCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      return handleCrudMethod(ctx, command, true);
    }
 
    @Override
    public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      try {
+         return handleCrudMethod(ctx, command, !ctx.isOriginLocal());
+      } finally {
+         if (ignorePreviousValueOnBackup(command, ctx)) {
+            // the command that will execute remotely must ignore previous values
+            command.setIgnorePreviousValue(true);
+         }
+      }
    }
 
    /**
     * If we are within one transaction we won't do any replication as replication would only be performed at commit
     * time. If the operation didn't originate locally we won't do any replication either.
     */
-   private Object handleCrudMethod(final InvocationContext ctx, final WriteCommand command) throws Throwable {
+   private Object handleCrudMethod(InvocationContext ctx, WriteCommand command, boolean skipRemoteGet) throws Throwable {
+      if (!skipRemoteGet) {
+         remoteGetBeforeWrite(ctx, command);
+      }
+
       // FIRST pass this call up the chain.  Only if it succeeds (no exceptions) locally do we attempt to replicate.
       final Object returnValue = invokeNextInterceptor(ctx, command);
       if (!isLocalModeForced(command) && command.isSuccessful() && ctx.isOriginLocal() && !ctx.isInTxScope()) {
@@ -275,4 +365,18 @@ private Object handleCrudMethod(final InvocationContext ctx, final WriteCommand
       return returnValue;
    }
 
+   private void remoteGetBeforeWrite(InvocationContext ctx, WriteCommand command) throws Throwable {
+      if (command instanceof AbstractDataCommand && (isNeedReliableReturnValues(command) || command.isConditional())) {
+         AbstractDataCommand singleKeyCommand = (AbstractDataCommand) command;
+
+         Object returnValue = null;
+         // get it remotely if we do not have it yet
+         if (needsRemoteGet(ctx, singleKeyCommand)) {
+            returnValue = remoteGet(ctx, singleKeyCommand.getKey(), singleKeyCommand, true);
+         }
+         if (returnValue == null) {
+            localGet(ctx, singleKeyCommand.getKey(), true, command);
+         }
+      }
+   }
 }",2013-03-07T23:03:03Z,103
"@@ -54,10 +54,11 @@ protected void broadcastPrepare(TxInvocationContext context, PrepareCommand comm
       // is then stored in the transactional context to be used during the commit phase.
       // However if the current node is already the coordinator, then we fall back to ""normal"" ReplicationInterceptor
       // logic for this step.
-      if (!rpcManager.getTransport().isCoordinator()) {
+      Address primaryOwner = getPrimaryOwner();
+      if (!primaryOwner.equals(rpcManager.getAddress())) {
          setVersionsSeenOnPrepareCommand((VersionedPrepareCommand) command, context);
          Map<Address, Response> resps = rpcManager.invokeRemotely(null, command, true, true);
-         Response r = resps.get(rpcManager.getTransport().getCoordinator());  // We only really care about the coordinator's response.
+         Response r = resps.get(primaryOwner);  // We only really care about the coordinator's response.
          readVersionsFromResponse(r, context.getCacheTransaction());
       } else {
          super.broadcastPrepare(context, command);",2013-03-07T23:03:03Z,495
"@@ -76,7 +76,7 @@ protected Log getLog() {
    }
 
    @Inject
-   private void injectConfiguration(Configuration configuration) {
+   public void injectConfiguration(Configuration configuration) {
       this.cacheConfiguration = configuration;
    }
 ",2013-03-07T23:03:03Z,496
"@@ -40,16 +40,14 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.statetransfer.StateTransferLock;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.transaction.xa.CacheTransaction;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
 
 import java.util.Collection;
 
 import static org.infinispan.transaction.WriteSkewHelper.performWriteSkewCheckAndReturnNewVersions;
 
-// todo [anistor] need to review this for NBST
 /**
  * Abstractization for logic related to different clustering modes: replicated or distributed. This implements the <a
  * href=""http://en.wikipedia.org/wiki/Bridge_pattern"">Bridge</a> pattern as described by the GoF: this plays the role of
@@ -61,8 +59,6 @@
 @Scope(Scopes.NAMED_CACHE)
 public interface ClusteringDependentLogic {
 
-   Log log = LogFactory.getLog(ClusteringDependentLogic.class);
-
    boolean localNodeIsOwner(Object key);
 
    boolean localNodeIsPrimaryOwner(Object key);
@@ -77,10 +73,18 @@ public interface ClusteringDependentLogic {
    
    Address getAddress();
 
-   public static abstract class AbstractClusteringDependentLogic implements  ClusteringDependentLogic {
+   public static abstract class AbstractClusteringDependentLogic implements ClusteringDependentLogic {
+
+      protected DataContainer dataContainer;
 
       protected CacheNotifier notifier;
 
+      @Inject
+      public void init(DataContainer dataContainer, CacheNotifier notifier) {
+         this.dataContainer = dataContainer;
+         this.notifier = notifier;
+      }
+
       protected void notifyCommitEntry(boolean created, boolean removed,
             boolean evicted, CacheEntry entry, InvocationContext ctx) {
          // Eviction has no notion of pre/post event since 4.2.0.ALPHA4.
@@ -109,13 +113,61 @@ protected void notifyCommitEntry(boolean created, boolean removed,
    }
 
    /**
-    * This logic is used when a changing a key affects all the nodes in the cluster, e.g. int the replicated,
-    * invalidated and local cache modes.
+    * This logic is used in local mode caches.
     */
-   public static final class AllNodesLogic extends AbstractClusteringDependentLogic {
+   public static class LocalLogic extends AbstractClusteringDependentLogic {
+
+      @Override
+      public boolean localNodeIsOwner(Object key) {
+         return true;
+      }
+
+      @Override
+      public boolean localNodeIsPrimaryOwner(Object key) {
+         return true;
+      }
+
+      @Override
+      public Address getPrimaryOwner(Object key) {
+         throw new IllegalStateException(""Cannot invoke this method for local caches"");
+      }
+
+      @Override
+      public Collection<Address> getOwners(Collection<Object> keys) {
+         return null;
+      }
+
+      @Override
+      public Address getAddress() {
+         return null;
+      }
+
+      @Override
+      public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipOwnershipCheck, InvocationContext ctx) {
+         // Cache flags before they're reset
+         // TODO: Can the reset be done after notification instead?
+         boolean created = entry.isCreated();
+         boolean removed = entry.isRemoved();
+         boolean evicted = entry.isEvicted();
 
-      private DataContainer dataContainer;
+         entry.commit(dataContainer, newVersion);
+
+         // Notify after events if necessary
+         notifyCommitEntry(created, removed, evicted, entry, ctx);
+      }
+
+      @Override
+      public EntryVersionsMap createNewVersionsAndCheckForWriteSkews(VersionGenerator versionGenerator, TxInvocationContext context, VersionedPrepareCommand prepareCommand) {
+         throw new IllegalStateException(""Cannot invoke this method for local caches"");
+      }
+   }
 
+   /**
+    * This logic is used in invalidation mode caches.
+    */
+   public static class InvalidationLogic extends AbstractClusteringDependentLogic {
+
+      private StateTransferManager stateTransferManager;
       private RpcManager rpcManager;
 
       private static final WriteSkewHelper.KeySpecificLogic keySpecificLogic = new WriteSkewHelper.KeySpecificLogic() {
@@ -126,27 +178,24 @@ public boolean performCheckOnKey(Object key) {
       };
 
       @Inject
-      public void init(DataContainer dc, RpcManager rpcManager, CacheNotifier notifier) {
-         this.dataContainer = dc;
+      public void init(RpcManager rpcManager, StateTransferManager stateTransferManager) {
          this.rpcManager = rpcManager;
-         this.notifier = notifier;
+         this.stateTransferManager = stateTransferManager;
       }
 
       @Override
       public boolean localNodeIsOwner(Object key) {
-         return true;
+         return stateTransferManager.getCacheTopology().getWriteConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key);
       }
 
       @Override
       public boolean localNodeIsPrimaryOwner(Object key) {
-         return rpcManager == null || rpcManager.getTransport().isCoordinator();
+         return stateTransferManager.getCacheTopology().getWriteConsistentHash().locatePrimaryOwner(key).equals(rpcManager.getAddress());
       }
 
       @Override
       public Address getPrimaryOwner(Object key) {
-         if (rpcManager == null)
-            throw new IllegalStateException(""Cannot invoke this method for local caches"");
-         return rpcManager.getTransport().getCoordinator();
+         return stateTransferManager.getCacheTopology().getWriteConsistentHash().locatePrimaryOwner(key);
       }
 
       @Override
@@ -165,7 +214,7 @@ public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipO
 
       @Override
       public Collection<Address> getOwners(Collection<Object> keys) {
-         return null;
+         return null;    //todo [anistor] should I actually return this based on current CH?
       }
       
       @Override
@@ -176,7 +225,7 @@ public Address getAddress() {
       @Override
       public EntryVersionsMap createNewVersionsAndCheckForWriteSkews(VersionGenerator versionGenerator, TxInvocationContext context, VersionedPrepareCommand prepareCommand) {
          // In REPL mode, this happens if we are the coordinator.
-         if (rpcManager.getTransport().isCoordinator()) {
+         if (stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0).equals(rpcManager.getAddress())) {
             // Perform a write skew check on each entry.
             EntryVersionsMap uv = performWriteSkewCheckAndReturnNewVersions(prepareCommand, dataContainer,
                                                                             versionGenerator, context,
@@ -194,10 +243,35 @@ public EntryVersionsMap createNewVersionsAndCheckForWriteSkews(VersionGenerator
       }
    }
 
-   public static final class DistributionLogic extends AbstractClusteringDependentLogic {
+   /**
+    * This logic is used in replicated mode caches.
+    */
+   public static class ReplicationLogic extends InvalidationLogic {
+
+      private StateTransferLock stateTransferLock;
+
+      @Inject
+      public void init(StateTransferLock stateTransferLock) {
+         this.stateTransferLock = stateTransferLock;
+      }
+
+      @Override
+      public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipOwnershipCheck, InvocationContext ctx) {
+         stateTransferLock.acquireSharedTopologyLock();
+         try {
+            super.commitEntry(entry, newVersion, skipOwnershipCheck, ctx);
+         } finally {
+            stateTransferLock.releaseSharedTopologyLock();
+         }
+      }
+   }
+
+   /**
+    * This logic is used in distributed mode caches.
+    */
+   public static class DistributionLogic extends AbstractClusteringDependentLogic {
 
       private DistributionManager dm;
-      private DataContainer dataContainer;
       private Configuration configuration;
       private RpcManager rpcManager;
       private StateTransferLock stateTransferLock;
@@ -210,14 +284,12 @@ public boolean performCheckOnKey(Object key) {
       };
 
       @Inject
-      public void init(DistributionManager dm, DataContainer dataContainer, Configuration configuration,
-                       RpcManager rpcManager, StateTransferLock stateTransferLock, CacheNotifier notifier) {
+      public void init(DistributionManager dm, Configuration configuration,
+                       RpcManager rpcManager, StateTransferLock stateTransferLock) {
          this.dm = dm;
-         this.dataContainer = dataContainer;
          this.configuration = configuration;
          this.rpcManager = rpcManager;
          this.stateTransferLock = stateTransferLock;
-         this.notifier = notifier;
       }
 
       @Override",2013-03-07T23:03:03Z,172
"@@ -22,17 +22,12 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.affinity.KeyAffinityService;
-import org.infinispan.affinity.KeyAffinityServiceFactory;
-import org.infinispan.affinity.RndKeyGenerator;
 import org.infinispan.config.Configuration;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
 import javax.transaction.Transaction;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
 
 /**
  * @author Mircea.Markus@jboss.com",2013-03-07T23:03:03Z,497
"@@ -0,0 +1,152 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.interceptors;
+
+import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.read.GetKeyValueCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.Configuration;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
+import org.infinispan.container.entries.ImmortalCacheValue;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.distribution.TestAddress;
+import org.infinispan.distribution.ch.ReplicatedConsistentHash;
+import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.responses.SuccessfulResponse;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
+import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.Transport;
+import org.infinispan.statetransfer.StateTransferManager;
+import org.infinispan.topology.CacheTopology;
+import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.util.concurrent.locks.LockManager;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.mockito.invocation.InvocationOnMock;
+import org.mockito.stubbing.Answer;
+import org.testng.annotations.Test;
+
+import java.util.*;
+
+import static org.junit.Assert.assertEquals;
+import static org.mockito.Matchers.*;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+/**
+ * Tests ReplicationInterceptor.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""interceptors.ReplicationInterceptorTest"")
+public class ReplicationInterceptorTest {
+
+   private static final Log log = LogFactory.getLog(ReplicationInterceptorTest.class);
+
+   public void testRemoteGetForGetKeyValueCommand() throws Throwable {
+      ConfigurationBuilder cb = new ConfigurationBuilder();
+      cb.clustering().cacheMode(CacheMode.REPL_SYNC);
+
+      GlobalConfigurationBuilder gcb = GlobalConfigurationBuilder.defaultClusteredBuilder();
+      Configuration configuration = cb.build();
+
+      ReplicationInterceptor replInterceptor = new ReplicationInterceptor();
+      CommandInterceptor nextInterceptor = mock(CommandInterceptor.class);
+      when(nextInterceptor.visitGetKeyValueCommand(any(InvocationContext.class), any(GetKeyValueCommand.class))).thenReturn(null);
+      replInterceptor.setNext(nextInterceptor);
+
+      CommandsFactory commandsFactory = mock(CommandsFactory.class);
+      when(commandsFactory.buildClusteredGetCommand(any(Object.class), any(Set.class), anyBoolean(), any(GlobalTransaction.class))).thenAnswer(new Answer<ClusteredGetCommand>() {
+         @Override
+         public ClusteredGetCommand answer(InvocationOnMock invocation) {
+            Object key = invocation.getArguments()[0];
+            Set<Flag> flags = (Set<Flag>) invocation.getArguments()[1];
+            boolean acquireRemoteLock = (Boolean) invocation.getArguments()[2];
+            GlobalTransaction gtx = (GlobalTransaction) invocation.getArguments()[3];
+            return new ClusteredGetCommand(key, ""cache1"", flags, acquireRemoteLock, gtx);
+         }
+      });
+
+      EntryFactory entryFactory = mock(EntryFactory.class);
+      DataContainer dataContainer = mock(DataContainer.class);
+      LockManager lockManager = mock(LockManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
+
+      TestAddress A = new TestAddress(0, ""A"");
+      TestAddress B = new TestAddress(1, ""B"");
+      List<Address> members1 = new ArrayList<Address>();
+      List<Address> members2 = new ArrayList<Address>();
+      members1.add(A);
+      members2.add(A);
+      members2.add(B);
+      ReplicatedConsistentHash readCh = new ReplicatedConsistentHash(members1);
+      ReplicatedConsistentHash writeCh = new ReplicatedConsistentHash(members2);
+      final CacheTopology cacheTopology = new CacheTopology(1, readCh, writeCh);
+      when(stateTransferManager.getCacheTopology()).thenAnswer(new Answer<CacheTopology>() {
+         @Override
+         public CacheTopology answer(InvocationOnMock invocation) {
+            return cacheTopology;
+         }
+      });
+      replInterceptor.init(commandsFactory, entryFactory, dataContainer, lockManager, stateTransferManager);
+      RpcManager rpcManager = mock(RpcManager.class);
+      Transport transport = mock(Transport.class);
+      when(rpcManager.getAddress()).thenReturn(B);
+      when(rpcManager.getTransport()).thenReturn(transport);
+      when(transport.getMembers()).thenReturn(members2);
+      replInterceptor.inject(rpcManager);
+      replInterceptor.injectConfiguration(configuration);
+
+      when(rpcManager.invokeRemotely(any(Collection.class), any(ClusteredGetCommand.class), any(ResponseMode.class),
+            anyLong(), anyBoolean(), any(ResponseFilter.class))).thenAnswer(new Answer<Map<Address, Response>>() {
+         @Override
+         public Map<Address, Response> answer(InvocationOnMock invocation) {
+            Collection<Address> recipients = (Collection<Address>) invocation.getArguments()[0];
+            ClusteredGetCommand clusteredGetCommand = (ClusteredGetCommand) invocation.getArguments()[1];
+            if (clusteredGetCommand.getKey().equals(""theKey"")) {
+               Map<Address, Response> results = new HashMap<Address, Response>();
+               for (Address recipient : recipients) {
+                  results.put(recipient, SuccessfulResponse.create(new ImmortalCacheValue(""theValue"")));
+               }
+               return results;
+            }
+            return Collections.emptyMap();
+         }
+      });
+
+      InvocationContext ctx = mock(InvocationContext.class);
+      when(ctx.isOriginLocal()).thenReturn(true);
+      when(ctx.isInTxScope()).thenReturn(false);
+
+      GetKeyValueCommand getKeyValueCommand = new GetKeyValueCommand(""theKey"", null);
+
+      Object retVal = replInterceptor.visitGetKeyValueCommand(ctx, getKeyValueCommand);
+      assertEquals(""theValue"", retVal);
+   }
+}",2013-03-07T23:03:03Z,103
"@@ -39,7 +39,7 @@
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
-@Test(groups = ""functional"", testName = ""replication.BaseReplicatedAPITest"")
+@Test(groups = ""functional"")
 public abstract class BaseReplicatedAPITest extends MultipleCacheManagersTest {
 
    protected boolean isSync;
@@ -150,7 +150,7 @@ public void testRemoveIfPresent() {
       waitForRpc(cache2);
 
       assert cache1.get(""key"") == null;
-      assert cache2.get(""key"").equals(""value2"");
+      assert cache2.get(""key"") == null;
    }
 
    public void testClear() {
@@ -214,8 +214,9 @@ public void testReplaceWithOldVal() {
       cache1.replace(""key"", ""valueN"", ""value1"");
       waitForRpc(cache2);
 
-      assert cache1.get(""key"").equals(""value1"");
-      assert cache2.get(""key"").equals(""value2"");
+      // the replace executed identically on both of them
+      assertEquals(""value1"", cache1.get(""key""));
+      assertEquals(""value1"", cache2.get(""key""));
    }
 
    public void testLocalOnlyClear() {",2013-03-07T23:03:03Z,282
"@@ -120,7 +120,6 @@ public void testPutIfAbsent() throws Exception {
       testStateTransferConsistency(Operation.PUT_IF_ABSENT);
    }
 
-   @Test(enabled = false)  // disabled due to ISPN-2647
    public void testReplace() throws Exception {
       testStateTransferConsistency(Operation.REPLACE);
    }
@@ -222,9 +221,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
       TestingUtil.waitForRehashToComplete(cache(0), cache(1), cache(2));
 
       // at this point state transfer is fully done
-      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.keySet());
-      log.infof(""Data container of NodeB has %d keys: %s"", dc1.size(), dc1.keySet());
-      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.keySet());
+      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.entrySet());
+      log.infof(""Data container of NodeB has %d keys: %s"", dc1.size(), dc1.entrySet());
+      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.entrySet());
 
       if (op == Operation.CLEAR || op == Operation.REMOVE) {
          // caches should be empty. check that no keys were revived by an inconsistent state transfer
@@ -253,9 +252,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
    }
 
    private void assertValue(int cacheIndex, int key, String expectedValue) {
-      InternalCacheEntry object = cache(cacheIndex).getAdvancedCache().getDataContainer().get(key);
-      assertNotNull(object);
-      assertEquals(expectedValue, object.getValue());
-      assertEquals(expectedValue, cache(cacheIndex).get(key));
+      InternalCacheEntry ice = cache(cacheIndex).getAdvancedCache().getDataContainer().get(key);
+      assertNotNull(""Found null on cache "" + cacheIndex,  ice);
+      assertEquals(""Did not find the expected value on cache "" + cacheIndex, expectedValue, ice.getValue());
+      assertEquals(""Did not find the expected value on cache "" + cacheIndex, expectedValue, cache(cacheIndex).get(key));
    }
 }",2013-03-07T23:03:03Z,498
"@@ -0,0 +1,40 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplNonTxOperationsDuringStateTransferTest"")
+@CleanupAfterMethod
+public class ReplNonTxOperationsDuringStateTransferTest extends BaseOperationsDuringStateTransferTest {
+
+   public ReplNonTxOperationsDuringStateTransferTest() {
+      super(CacheMode.REPL_SYNC, false, false, false);
+   }
+}",2013-03-07T23:03:03Z,499
"@@ -0,0 +1,40 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplOptimisticTxOperationsDuringStateTransferTest"")
+@CleanupAfterMethod
+public class ReplOptimisticTxOperationsDuringStateTransferTest extends BaseOperationsDuringStateTransferTest {
+
+   public ReplOptimisticTxOperationsDuringStateTransferTest() {
+      super(CacheMode.REPL_SYNC, true, true, false);
+   }
+}",2013-03-07T23:03:03Z,500
"@@ -0,0 +1,57 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplPessimisticOperationsDuringStateTransferTest"",
+      enabled = false, description = ""Disabled due to https://issues.jboss.org/browse/ISPN-2847"")
+@CleanupAfterMethod
+public class ReplPessimisticOperationsDuringStateTransferTest extends BaseOperationsDuringStateTransferTest {
+
+   public ReplPessimisticOperationsDuringStateTransferTest() {
+      super(CacheMode.REPL_SYNC, true, false, false);
+   }
+
+   @Test(enabled = false)
+   public void testPut() throws Exception {
+   }
+
+   @Test(enabled = false)
+   public void testReplace() throws Exception {
+   }
+
+   @Test(enabled = false)
+   public void testGet() throws Exception {
+   }
+
+   @Test(enabled = false)
+   public void testRemove() throws Exception {
+   }
+}",2013-03-07T23:03:03Z,501
"@@ -68,10 +68,10 @@ public void setUp() {
       txTable.addLocalTransactionMapping(localTx);      
 
       configuration = new ConfigurationBuilder().build();
-      TransactionCoordinator txCoordinator = new TransactionCoordinator();
+      txCoordinator = new TransactionCoordinator();
       txCoordinator.init(null, null, null, null, configuration);
       xaAdapter = new TransactionXaAdapter(localTx, txTable, null, txCoordinator, null, null,
-                                           new ClusteringDependentLogic.AllNodesLogic(), configuration, """");
+                                           new ClusteringDependentLogic.InvalidationLogic(), configuration, """");
    }
 
    public void testPrepareOnNonexistentXid() {",2013-03-07T23:03:03Z,94
"@@ -26,6 +26,7 @@
 import org.infinispan.CacheException;
 import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.configuration.global.GlobalConfiguration;
@@ -35,6 +36,7 @@
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.jmx.annotations.ManagedOperation;
+import org.infinispan.newstatetransfer.StateTransferManager;
 import org.infinispan.remoting.ReplicationQueue;
 import org.infinispan.remoting.RpcException;
 import org.infinispan.remoting.responses.IgnoreExtraResponsesValidityFilter;
@@ -95,13 +97,15 @@ public class RpcManagerImpl implements RpcManager {
    private ExecutorService asyncExecutor;
    private CommandsFactory cf;
    private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
 
    @Inject
    public void injectDependencies(Transport t, Cache cache, Configuration cfg,
             ReplicationQueue replicationQueue, CommandsFactory cf,
             @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService e,
-            LocalTopologyManager localTopologyManager, GlobalConfiguration globalCfg) {
+            LocalTopologyManager localTopologyManager, StateTransferManager stateTransferManager,
+            GlobalConfiguration globalCfg) {
       this.t = t;
       this.configuration = cfg;
       this.cacheName = cache.getName();
@@ -110,6 +114,7 @@ public void injectDependencies(Transport t, Cache cache, Configuration cfg,
       this.asyncExecutor = e;
       this.cf = cf;
       this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
    }
 
    @Start(priority = 9)
@@ -165,6 +170,9 @@ public final Map<Address, Response> invokeRemotely(Collection<Address> recipient
                   responseFilter = new IgnoreExtraResponsesValidityFilter(cacheMembers, getAddress());
                }
             }
+            if (rpcCommand instanceof TopologyAffectedCommand) {
+               ((TopologyAffectedCommand)rpcCommand).setTopologyId(stateTransferManager.getTopologyId());
+            }
             Map<Address, Response> result = t.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue, responseFilter);
             if (statisticsEnabled) replicationCount.incrementAndGet();
             return result;",2012-08-31T21:04:20Z,105
"@@ -22,10 +22,6 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.context.InvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
@@ -95,24 +91,6 @@ public interface DistributionManager {
     */
    Set<Address> locateAll(Collection<Object> keys); //todo [anistor] this has to take an additional parameter that specifies if the lookup is for read or write
 
-   /**
-    * Transforms a cache entry so it is marked for L1 rather than the primary cache data structure.  This should be done
-    * if it is deemed that the entry is targeted for L1 storage rather than storage in the primary data container.
-    *
-    * @param entry entry to transform
-    */
-   void transformForL1(CacheEntry entry);
-
-   /**
-    * Retrieves a cache entry from a remote source.  Would typically involve an RPC call using a {@link org.infinispan.commands.remote.ClusteredGetCommand}
-    * and some form of quorum of responses if the responses returned are inconsistent - often the case if there is a
-    * rehash in progress, involving nodes that the key maps to.
-    *
-    * @param key key to look up
-    * @return an internal cache entry, or null if it cannot be located
-    */
-   InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception;
-
    /**
     * Retrieves the consistent hash instance currently in use, an instance of the configured ConsistentHash
     * class (which defaults to {@link org.infinispan.distribution.ch.DefaultConsistentHash}.",2013-03-07T23:03:04Z,60
"@@ -22,31 +22,16 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.commands.CommandsFactory;
-import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.commands.remote.ClusteredGetCommand;
-import org.infinispan.configuration.cache.Configuration;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalCacheValue;
-import org.infinispan.context.InvocationContext;
-import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.jmx.annotations.Parameter;
 import org.infinispan.statetransfer.StateTransferManager;
-import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
-import org.infinispan.remoting.responses.Response;
-import org.infinispan.remoting.responses.SuccessfulResponse;
-import org.infinispan.remoting.rpc.ResponseFilter;
-import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
@@ -70,9 +55,7 @@ public class DistributionManagerImpl implements DistributionManager {
    private static final boolean trace = log.isTraceEnabled();
 
    // Injected components
-   private Configuration configuration;
    private RpcManager rpcManager;
-   private CommandsFactory cf;
    private StateTransferManager stateTransferManager;
 
    /**
@@ -82,11 +65,8 @@ public DistributionManagerImpl() {
    }
 
    @Inject
-   public void init(Configuration configuration, RpcManager rpcManager, CommandsFactory cf,
-                    StateTransferManager stateTransferManager) {
-      this.configuration = configuration;
+   public void init(RpcManager rpcManager, StateTransferManager stateTransferManager) {
       this.rpcManager = rpcManager;
-      this.cf = cf;
       this.stateTransferManager = stateTransferManager;
    }
 
@@ -147,39 +127,6 @@ public Set<Address> locateAll(Collection<Object> keys) {
       return getConsistentHash().locateAllOwners(keys);
    }
 
-   @Override
-   public void transformForL1(CacheEntry entry) {
-      if (entry.getLifespan() < 0 || entry.getLifespan() > configuration.clustering().l1().lifespan())
-         entry.setLifespan(configuration.clustering().l1().lifespan());
-   }
-
-   @Override
-   public InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception {
-      GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
-      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
-
-      List<Address> targets = new ArrayList<Address>(getReadConsistentHash().locateOwners(key));
-      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
-      targets.retainAll(rpcManager.getTransport().getMembers());
-      ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, getAddress());
-      Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
-                                                                   configuration.clustering().sync().replTimeout(), true, filter);
-
-      if (!responses.isEmpty()) {
-         for (Response r : responses.values()) {
-            if (r instanceof SuccessfulResponse) {
-               InternalCacheValue cacheValue = (InternalCacheValue) ((SuccessfulResponse) r).getResponseValue();
-               return cacheValue.toInternalCacheEntry(key);
-            }
-         }
-      }
-
-      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
-      // Otherwise our get command might be processed by the old owners after they have invalidated their data
-      // and we'd return a null even though the key exists on
-      return null;
-   }
-
    @Override
    public ConsistentHash getConsistentHash() {
       return getWriteConsistentHash();",2013-03-07T23:03:04Z,60
"@@ -0,0 +1,120 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.interceptors;
+
+import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.FlagAffectedCommand;
+import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.factories.annotations.Inject;
+import org.infinispan.factories.annotations.Start;
+import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.statetransfer.StateTransferManager;
+import org.infinispan.util.concurrent.locks.LockManager;
+
+/**
+ * Base class for replication and distribution interceptors.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+public abstract class ClusteringInterceptor extends BaseRpcInterceptor {
+
+   protected CommandsFactory cf;
+   protected EntryFactory entryFactory;
+   protected LockManager lockManager;
+   protected DataContainer dataContainer;
+   protected StateTransferManager stateTransferManager;
+   protected boolean needReliableReturnValues;
+
+   @Inject
+   public void injectDependencies(CommandsFactory cf, EntryFactory entryFactory,
+                                  LockManager lockManager, DataContainer dataContainer,
+                                  StateTransferManager stateTransferManager) {
+      this.cf = cf;
+      this.entryFactory = entryFactory;
+      this.lockManager = lockManager;
+      this.dataContainer = dataContainer;
+      this.stateTransferManager = stateTransferManager;
+   }
+
+   @Start
+   public void configure() {
+      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
+   }
+
+   protected boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
+      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+   }
+
+   protected boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
+      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
+            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
+         return false;
+      }
+      boolean shouldFetchFromRemote = false;
+      CacheEntry entry = ctx.lookupEntry(command.getKey());
+      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
+         Object key = command.getKey();
+         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
+         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
+         if (!shouldFetchFromRemote && getLog().isTraceEnabled()) {
+            getLog().tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s) or is in L1. Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
+         }
+      }
+      return shouldFetchFromRemote;
+   }
+
+   /**
+    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
+    * <pre>
+    * - node A (owner, tx originator) does a successful replace
+    * - the actual value changes
+    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
+    *   B (check is performed at commit time).
+    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
+    * </pre>
+    */
+   protected boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return ctx.isOriginLocal() && command.isSuccessful();
+   }
+
+   /**
+    * Retrieves a cache entry from a remote source.  Would typically involve an RPC call using a {@link org.infinispan.commands.remote.ClusteredGetCommand}
+    * and some form of quorum of responses if the responses returned are inconsistent - often the case if there is a
+    * rehash in progress, involving nodes that the key maps to.
+    *
+    * @param key key to look up
+    * @return an internal cache entry, or null if it cannot be located
+    */
+   protected abstract InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception;
+}",2013-03-07T23:03:04Z,482
"@@ -22,7 +22,6 @@
  */
 package org.infinispan.interceptors;
 
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.AbstractDataCommand;
@@ -35,30 +34,21 @@
 import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configurations;
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.EntryFactory;
-import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.InternalCacheValue;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.ch.ConsistentHash;
-import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
-import org.infinispan.interceptors.base.BaseRpcInterceptor;
 import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
 import org.infinispan.remoting.responses.Response;
 import org.infinispan.remoting.responses.SuccessfulResponse;
 import org.infinispan.remoting.rpc.ResponseFilter;
 import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.jgroups.SuspectException;
-import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.xa.GlobalTransaction;
-import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -71,16 +61,8 @@
  * @author Bela Ban
  * @since 4.0
  */
-public class ReplicationInterceptor extends BaseRpcInterceptor {
+public class ReplicationInterceptor extends ClusteringInterceptor {
 
-   private CommandsFactory cf;
-
-   private EntryFactory entryFactory;
-   private LockManager lockManager;
-   private DataContainer dataContainer;
-   private StateTransferManager stateTransferManager;
-
-   private boolean needReliableReturnValues;
    private boolean isPessimisticCache;
 
    private static final Log log = LogFactory.getLog(ReplicationInterceptor.class);
@@ -91,19 +73,9 @@ protected Log getLog() {
       return log;
    }
 
-   @Inject
-   public void init(CommandsFactory cf, EntryFactory entryFactory, DataContainer dataContainer, LockManager lockManager, StateTransferManager stateTransferManager) {
-      this.cf = cf;
-      this.entryFactory = entryFactory;
-      this.dataContainer = dataContainer;
-      this.lockManager = lockManager;
-      this.stateTransferManager = stateTransferManager;
-   }
-
    @Start
    public void start() {
       isPessimisticCache = cacheConfiguration.transaction().lockingMode() == LockingMode.PESSIMISTIC;
-      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
    }
 
    @Override
@@ -180,44 +152,6 @@ public Object visitLockControlCommand(TxInvocationContext ctx, LockControlComman
       return retVal;
    }
 
-   private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] clarify usage of this flag in REPL mode
-            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
-         return false;
-      }
-      boolean shouldFetchFromRemote = false;
-      CacheEntry entry = ctx.lookupEntry(command.getKey());
-      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
-         Object key = command.getKey();
-         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
-         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
-         if (!shouldFetchFromRemote) {
-            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s). Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
-         }
-      }
-      return shouldFetchFromRemote;
-   }
-
-   private boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
-      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
-   }
-
-   /**
-    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
-    * <pre>
-    * - node A (owner, tx originator) does a successful replace
-    * - the actual value changes
-    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
-    *   B (check is performed at commit time).
-    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
-    * </pre>
-    */
-   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
-      return ctx.isOriginLocal() && command.isSuccessful();
-   }
-
    /**
     * This method retrieves an entry from a remote cache.
     * <p/>
@@ -242,7 +176,7 @@ private Object remoteGet(InvocationContext ctx, Object key, FlagAffectedCommand
          acquireRemoteLock = isWrite && isPessimisticCache && !txContext.getAffectedKeys().contains(key);
       }
       // attempt a remote lookup
-      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command.getFlags());
+      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
 
       if (acquireRemoteLock) {
          ((TxInvocationContext) ctx).addAffectedKey(key);
@@ -265,9 +199,9 @@ protected Address getPrimaryOwner() {
       return stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0);
    }
 
-   private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, Set<Flag> flags) {
+   protected InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) {
       GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
-      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, flags, acquireRemoteLock, gtx);
+      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
 
       List<Address> targets = Collections.singletonList(getPrimaryOwner());
       ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
@@ -289,7 +223,7 @@ private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContex
    private Object localGet(InvocationContext ctx, Object key, boolean isWrite, FlagAffectedCommand command) throws Throwable {
       InternalCacheEntry ice = dataContainer.get(key);
       if (ice != null) {
-         if (!ctx.replaceValue(key, ice.getValue()))  {
+         if (!ctx.replaceValue(key, ice.getValue())) {
             if (isWrite)
                lockAndWrap(ctx, key, ice, command);
             else",2013-03-07T23:03:04Z,103
"@@ -22,34 +22,32 @@
  */
 package org.infinispan.interceptors.distribution;
 
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.write.PutMapCommand;
 import org.infinispan.commands.write.RemoveCommand;
 import org.infinispan.commands.write.ReplaceCommand;
 import org.infinispan.commands.write.WriteCommand;
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.EntryFactory;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.container.entries.InternalCacheValue;
 import org.infinispan.context.InvocationContext;
-import org.infinispan.distribution.DataLocality;
+import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.DistributionManager;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
-import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.interceptors.ClusteringInterceptor;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
+import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.responses.SuccessfulResponse;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
-import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 
 /**
  * Base class for distribution of entries across a cluster.
@@ -60,14 +58,11 @@
  * @author Dan Berindei <dan@infinispan.org>
  * @since 4.0
  */
-public abstract class BaseDistributionInterceptor extends BaseRpcInterceptor {
+public abstract class BaseDistributionInterceptor extends ClusteringInterceptor {
+
    protected DistributionManager dm;
-   protected CommandsFactory cf;
-   protected DataContainer dataContainer;
-   protected EntryFactory entryFactory;
-   protected LockManager lockManager;
+
    protected ClusteringDependentLogic cdl;
-   private boolean needReliableReturnValues;
 
    private static final Log log = LogFactory.getLog(BaseDistributionInterceptor.class);
 
@@ -77,42 +72,36 @@ protected Log getLog() {
    }
 
    @Inject
-   public void injectDependencies(DistributionManager distributionManager,
-                                  CommandsFactory cf, DataContainer dataContainer, EntryFactory entryFactory,
-                                  LockManager lockManager, ClusteringDependentLogic cdl) {
+   public void injectDependencies(DistributionManager distributionManager, ClusteringDependentLogic cdl) {
       this.dm = distributionManager;
-      this.cf = cf;
-      this.dataContainer = dataContainer;
-      this.entryFactory = entryFactory;
-      this.lockManager = lockManager;
       this.cdl = cdl;
    }
 
-   @Start
-   public void configure() {
-      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
-   }
-
-   protected boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      boolean shouldFetchFromRemote = false;
-      final CacheEntry entry;
-      if (!command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            && !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES)
-            && ((entry = ctx.lookupEntry(command.getKey())) == null || entry.isNull() || entry.isLockPlaceholder())) {
-         Object key = command.getKey();
-         DataLocality locality = dm.getReadConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key) ? DataLocality.LOCAL : DataLocality.NOT_LOCAL;
-         shouldFetchFromRemote = ctx.isOriginLocal() && !locality.isLocal() && !dataContainer.containsKey(key);
-         if (!shouldFetchFromRemote) {
-            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s), or is in L1.  Owners are %s"", key, rpcManager.getAddress(), dm.locate(key));
+   @Override
+   protected InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception {
+      GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
+      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
+
+      List<Address> targets = new ArrayList<Address>(stateTransferManager.getCacheTopology().getReadConsistentHash().locateOwners(key));
+      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
+      targets.retainAll(rpcManager.getTransport().getMembers());
+      ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
+      Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
+            cacheConfiguration.clustering().sync().replTimeout(), true, filter);
+
+      if (!responses.isEmpty()) {
+         for (Response r : responses.values()) {
+            if (r instanceof SuccessfulResponse) {
+               InternalCacheValue cacheValue = (InternalCacheValue) ((SuccessfulResponse) r).getResponseValue();
+               return cacheValue.toInternalCacheEntry(key);
+            }
          }
       }
-      return shouldFetchFromRemote;
-   }
 
-   protected boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
-      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
+      // Otherwise our get command might be processed by the old owners after they have invalidated their data
+      // and we'd return a null even though the key exists on
+      return null;
    }
 
    @Override
@@ -157,9 +146,9 @@ interface RecipientGenerator extends KeyGenerator {
    }
 
    class SingleKeyRecipientGenerator implements RecipientGenerator {
-      final Object key;
-      final Set<Object> keys;
-      List<Address> recipients = null;
+      private final Object key;
+      private final Set<Object> keys;
+      private List<Address> recipients = null;
 
       SingleKeyRecipientGenerator(Object key) {
          this.key = key;
@@ -180,8 +169,8 @@ public Collection<Object> getKeys() {
 
    class MultipleKeysRecipientGenerator implements RecipientGenerator {
 
-      final Collection<Object> keys;
-      List<Address> recipients = null;
+      private final Collection<Object> keys;
+      private List<Address> recipients = null;
 
       MultipleKeysRecipientGenerator(Collection<Object> keys) {
          this.keys = keys;",2013-03-07T23:03:04Z,478
"@@ -140,7 +140,7 @@ private Object remoteGetBeforeWrite(InvocationContext ctx, Object key, FlagAffec
          if (trace) log.tracef(""Doing a remote get for key %s"", key);
 
          // attempt a remote lookup
-         InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, false, command);
+         InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, false, command);
          if (ice != null) {
             if (!ctx.replaceValue(key, ice.getValue())) {
                entryFactory.wrapEntryForPut(ctx, key, ice, false, command);
@@ -190,7 +190,7 @@ protected void handleRemoteWrite(InvocationContext ctx, WriteCommand command, Re
 
    private Object remoteGet(InvocationContext ctx, Object key, GetKeyValueCommand command) throws Throwable {
       if (trace) log.tracef(""Doing a remote get for key %s"", key);
-      InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, false, command);
+      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, false, command);
       command.setRemotelyFetchedValue(ice);
       if (ice != null) {
          return ice.getValue();",2013-03-07T23:03:04Z,483
"@@ -117,8 +117,9 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
     * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
     * </pre>
     */
-   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
-      return ctx.isOriginLocal() && command.isSuccessful() && cacheConfiguration.transaction().lockingMode() == LockingMode.OPTIMISTIC && !useClusteredWriteSkewCheck;
+   protected boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return super.ignorePreviousValueOnBackup(command, ctx)
+          && cacheConfiguration.transaction().lockingMode() == LockingMode.OPTIMISTIC && !useClusteredWriteSkewCheck;
    }
 
    @Start
@@ -176,7 +177,6 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
       }
    }
 
-
    private void lockAndWrap(InvocationContext ctx, Object key, InternalCacheEntry ice, FlagAffectedCommand command) throws InterruptedException {
       boolean skipLocking = hasSkipLocking(command);
       long lockTimeout = getLockAcquisitionTimeout(command, skipLocking);
@@ -341,7 +341,7 @@ private Object remoteGetAndStoreInL1(InvocationContext ctx, Object key, boolean
             acquireRemoteLock = isWrite && isPessimisticCache && !txContext.getAffectedKeys().contains(key);
          }
          // attempt a remote lookup
-         InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
+         InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
 
          if (acquireRemoteLock) {
             ((TxInvocationContext) ctx).addAffectedKey(key);",2013-03-07T23:03:04Z,484
"@@ -324,7 +324,9 @@ public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipO
             boolean isForeignOwned = !skipOwnershipCheck && !localNodeIsOwner(entry.getKey());
             if (isForeignOwned && !entry.isRemoved()) {
                if (configuration.clustering().l1().enabled()) {
-                  dm.transformForL1(entry);
+                  // transform for L1
+                  if (entry.getLifespan() < 0 || entry.getLifespan() > configuration.clustering().l1().lifespan())
+                     entry.setLifespan(configuration.clustering().l1().lifespan());
                } else {
                   doCommit = false;
                }",2013-03-07T23:03:04Z,172
"@@ -45,8 +45,6 @@
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.concurrent.locks.LockManager;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
 import org.testng.annotations.Test;
@@ -67,8 +65,6 @@
 @Test(groups = ""functional"", testName = ""interceptors.ReplicationInterceptorTest"")
 public class ReplicationInterceptorTest {
 
-   private static final Log log = LogFactory.getLog(ReplicationInterceptorTest.class);
-
    public void testRemoteGetForGetKeyValueCommand() throws Throwable {
       ConfigurationBuilder cb = new ConfigurationBuilder();
       cb.clustering().cacheMode(CacheMode.REPL_SYNC);
@@ -114,7 +110,7 @@ public CacheTopology answer(InvocationOnMock invocation) {
             return cacheTopology;
          }
       });
-      replInterceptor.init(commandsFactory, entryFactory, dataContainer, lockManager, stateTransferManager);
+      replInterceptor.injectDependencies(commandsFactory, entryFactory, lockManager, dataContainer, stateTransferManager);
       RpcManager rpcManager = mock(RpcManager.class);
       Transport transport = mock(Transport.class);
       when(rpcManager.getAddress()).thenReturn(B);",2013-03-07T23:03:04Z,103
"@@ -238,8 +238,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
       TestingUtil.waitForRehashToComplete(cache(0), cache(2));
 
       // at this point state transfer is fully done
-      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.keySet());
-      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.keySet());
+      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.entrySet());
+      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.entrySet());
 
       if (op == Operation.CLEAR || op == Operation.REMOVE) {
          // caches should be empty. check that no keys were revived by an inconsistent state transfer
@@ -262,7 +262,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
             assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
 
             // check values were not overwritten with old values carried by state transfer
-            assertEquals(""after_st_"" + i, cache(0).get(i));
+            String expected = ""after_st_"" + i;
+            assertEquals(expected, cache(0).get(i));
             assertEquals(""after_st_"" + i, cache(2).get(i));
          }
       } else { // PUT_IF_ABSENT
@@ -278,8 +279,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
             }
             assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
 
-            assertEquals(""before_st_"" + i, cache(0).get(i));
-            assertEquals(""before_st_"" + i, cache(2).get(i));
+            String expected = ""before_st_"" + i;
+            assertEquals(expected, cache(0).get(i));
+            assertEquals(expected, cache(2).get(i));
          }
       }
    }",2013-03-07T23:03:04Z,485
"@@ -168,7 +168,7 @@ public boolean isSuccessful() {
 
    @Override
    public boolean isConditional() {
-      return true;
+      return !ignorePreviousValue;
    }
 
    public long getLifespanMillis() {",2013-03-07T23:03:03Z,493
"@@ -81,8 +81,12 @@ public <T> T construct(Class<T> componentType) {
       Class<?> componentImpl;
       if (componentType.equals(ClusteringDependentLogic.class)) {
          CacheMode cacheMode = configuration.clustering().cacheMode();
-         if (cacheMode.isReplicated() || !cacheMode.isClustered() || cacheMode.isInvalidation()) {
-            return componentType.cast(new ClusteringDependentLogic.AllNodesLogic());
+         if (!cacheMode.isClustered()) {
+            return componentType.cast(new ClusteringDependentLogic.LocalLogic());
+         } else if (cacheMode.isInvalidation()) {
+            return componentType.cast(new ClusteringDependentLogic.InvalidationLogic());
+         } else if (cacheMode.isReplicated()) {
+            return componentType.cast(new ClusteringDependentLogic.ReplicationLogic());
          } else {
             return componentType.cast(new ClusteringDependentLogic.DistributionLogic());
          }",2013-03-07T23:03:03Z,494
"@@ -23,28 +23,28 @@
 package org.infinispan.interceptors;
 
 import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.read.GetCacheEntryCommand;
 import org.infinispan.commands.read.GetKeyValueCommand;
 import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.tx.RollbackCommand;
-import org.infinispan.commands.write.ClearCommand;
-import org.infinispan.commands.write.PutKeyValueCommand;
-import org.infinispan.commands.write.PutMapCommand;
-import org.infinispan.commands.write.RemoveCommand;
-import org.infinispan.commands.write.ReplaceCommand;
-import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configurations;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.InternalCacheValue;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
+import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.interceptors.base.BaseRpcInterceptor;
@@ -58,13 +58,11 @@
 import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.TimeoutException;
 
 /**
@@ -75,10 +73,14 @@
  */
 public class ReplicationInterceptor extends BaseRpcInterceptor {
 
-   protected CommandsFactory cf;
+   private CommandsFactory cf;
 
+   private EntryFactory entryFactory;
+   private LockManager lockManager;
+   private DataContainer dataContainer;
    private StateTransferManager stateTransferManager;
 
+   private boolean needReliableReturnValues;
    private boolean isPessimisticCache;
 
    private static final Log log = LogFactory.getLog(ReplicationInterceptor.class);
@@ -90,14 +92,18 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(CommandsFactory cf, StateTransferManager stateTransferManager) {
+   public void init(CommandsFactory cf, EntryFactory entryFactory, DataContainer dataContainer, LockManager lockManager, StateTransferManager stateTransferManager) {
       this.cf = cf;
+      this.entryFactory = entryFactory;
+      this.dataContainer = dataContainer;
+      this.lockManager = lockManager;
       this.stateTransferManager = stateTransferManager;
    }
 
    @Start
    public void start() {
       isPessimisticCache = cacheConfiguration.transaction().lockingMode() == LockingMode.PESSIMISTIC;
+      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
    }
 
    @Override
@@ -149,7 +155,10 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
          // the entry is mapped to the local node.
          if (returnValue == null && ctx.isOriginLocal()) {
             if (needsRemoteGet(ctx, command)) {
-               returnValue = remoteGet(ctx, command, false);
+               returnValue = remoteGet(ctx, command.getKey(), command, false);
+            }
+            if (returnValue == null) {
+               returnValue = localGet(ctx, command.getKey(), false, command);
             }
          }
          return returnValue;
@@ -172,15 +181,43 @@ public Object visitLockControlCommand(TxInvocationContext ctx, LockControlComman
    }
 
    private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      Object key = command.getKey();
-      final CacheEntry entry;
-      return !command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            && !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] do we need this? it should normally be used only in distributed mode, never in replicated mode
-            && !stateTransferManager.getCacheTopology().getReadConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key)
-            && ((entry = ctx.lookupEntry(key)) == null || entry.isNull() || entry.isLockPlaceholder());
+      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
+            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] clarify usage of this flag in REPL mode
+            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
+         return false;
+      }
+      boolean shouldFetchFromRemote = false;
+      CacheEntry entry = ctx.lookupEntry(command.getKey());
+      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
+         Object key = command.getKey();
+         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
+         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
+         if (!shouldFetchFromRemote) {
+            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s). Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
+         }
+      }
+      return shouldFetchFromRemote;
+   }
+
+   private boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
+      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+   }
+
+   /**
+    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
+    * <pre>
+    * - node A (owner, tx originator) does a successful replace
+    * - the actual value changes
+    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
+    *   B (check is performed at commit time).
+    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
+    * </pre>
+    */
+   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return ctx.isOriginLocal() && command.isSuccessful();
    }
 
-   //todo [anistor] need to revise these methods
    /**
     * This method retrieves an entry from a remote cache.
     * <p/>
@@ -190,12 +227,12 @@ private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand comman
     *
     *
     * @param ctx invocation context
+    * @param key
     * @param command
     * @return value of a remote get, or null
     * @throws Throwable if there are problems
     */
-   private Object remoteGet(InvocationContext ctx, AbstractDataCommand command, boolean isWrite) throws Throwable {
-      Object key = command.getKey();
+   private Object remoteGet(InvocationContext ctx, Object key, FlagAffectedCommand command, boolean isWrite) throws Throwable {
       if (trace) {
          log.tracef(""Key %s is not yet available on %s, so we may need to look elsewhere"", key, rpcManager.getAddress());
       }
@@ -211,16 +248,28 @@ private Object remoteGet(InvocationContext ctx, AbstractDataCommand command, boo
          ((TxInvocationContext) ctx).addAffectedKey(key);
       }
 
-      return ice != null ? ice.getValue() : null;
+      if (ice != null) {
+         if (!ctx.replaceValue(key, ice.getValue()))  {
+            if (isWrite) {
+               lockAndWrap(ctx, key, ice, command);
+            } else {
+               ctx.putLookedUpEntry(key, ice);
+            }
+         }
+         return ice.getValue();
+      }
+      return null;
+   }
+
+   protected Address getPrimaryOwner() {
+      return stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0);
    }
 
    private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, Set<Flag> flags) {
       GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
       ClusteredGetCommand get = cf.buildClusteredGetCommand(key, flags, acquireRemoteLock, gtx);
 
-      List<Address> targets = new ArrayList<Address>(stateTransferManager.getCacheTopology().getReadConsistentHash().locateOwners(key));
-      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
-      targets.retainAll(rpcManager.getTransport().getMembers());
+      List<Address> targets = Collections.singletonList(getPrimaryOwner());
       ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
       Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
             cacheConfiguration.clustering().sync().replTimeout(), true, filter);
@@ -237,36 +286,77 @@ private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContex
       return null;
    }
 
+   private Object localGet(InvocationContext ctx, Object key, boolean isWrite, FlagAffectedCommand command) throws Throwable {
+      InternalCacheEntry ice = dataContainer.get(key);
+      if (ice != null) {
+         if (!ctx.replaceValue(key, ice.getValue()))  {
+            if (isWrite)
+               lockAndWrap(ctx, key, ice, command);
+            else
+               ctx.putLookedUpEntry(key, ice);
+         }
+         return command instanceof GetCacheEntryCommand ? ice : ice.getValue();
+      }
+      return null;
+   }
+
+   private void lockAndWrap(InvocationContext ctx, Object key, InternalCacheEntry ice, FlagAffectedCommand command) throws InterruptedException {
+      if (isPessimisticCache && rpcManager.getAddress().equals(getPrimaryOwner())) {
+         boolean skipLocking = hasSkipLocking(command);
+         long lockTimeout = getLockAcquisitionTimeout(command, skipLocking);
+         lockManager.acquireLock(ctx, key, lockTimeout, skipLocking);
+      }
+      entryFactory.wrapEntryForPut(ctx, key, ice, false, command);
+   }
+
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      return handleCrudMethod(ctx, command, !ctx.isOriginLocal());
    }
 
    @Override
    public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      return handleCrudMethod(ctx, command, true);
    }
 
    @Override
    public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      try {
+         return handleCrudMethod(ctx, command, !ctx.isOriginLocal());
+      } finally {
+         if (ignorePreviousValueOnBackup(command, ctx)) {
+            // the command that will execute remotely must ignore previous values
+            command.setIgnorePreviousValue(true);
+         }
+      }
    }
 
    @Override
    public Object visitClearCommand(InvocationContext ctx, ClearCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      return handleCrudMethod(ctx, command, true);
    }
 
    @Override
    public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
-      return handleCrudMethod(ctx, command);
+      try {
+         return handleCrudMethod(ctx, command, !ctx.isOriginLocal());
+      } finally {
+         if (ignorePreviousValueOnBackup(command, ctx)) {
+            // the command that will execute remotely must ignore previous values
+            command.setIgnorePreviousValue(true);
+         }
+      }
    }
 
    /**
     * If we are within one transaction we won't do any replication as replication would only be performed at commit
     * time. If the operation didn't originate locally we won't do any replication either.
     */
-   private Object handleCrudMethod(final InvocationContext ctx, final WriteCommand command) throws Throwable {
+   private Object handleCrudMethod(InvocationContext ctx, WriteCommand command, boolean skipRemoteGet) throws Throwable {
+      if (!skipRemoteGet) {
+         remoteGetBeforeWrite(ctx, command);
+      }
+
       // FIRST pass this call up the chain.  Only if it succeeds (no exceptions) locally do we attempt to replicate.
       final Object returnValue = invokeNextInterceptor(ctx, command);
       if (!isLocalModeForced(command) && command.isSuccessful() && ctx.isOriginLocal() && !ctx.isInTxScope()) {
@@ -275,4 +365,18 @@ private Object handleCrudMethod(final InvocationContext ctx, final WriteCommand
       return returnValue;
    }
 
+   private void remoteGetBeforeWrite(InvocationContext ctx, WriteCommand command) throws Throwable {
+      if (command instanceof AbstractDataCommand && (isNeedReliableReturnValues(command) || command.isConditional())) {
+         AbstractDataCommand singleKeyCommand = (AbstractDataCommand) command;
+
+         Object returnValue = null;
+         // get it remotely if we do not have it yet
+         if (needsRemoteGet(ctx, singleKeyCommand)) {
+            returnValue = remoteGet(ctx, singleKeyCommand.getKey(), singleKeyCommand, true);
+         }
+         if (returnValue == null) {
+            localGet(ctx, singleKeyCommand.getKey(), true, command);
+         }
+      }
+   }
 }",2013-03-07T23:03:03Z,103
"@@ -54,10 +54,11 @@ protected void broadcastPrepare(TxInvocationContext context, PrepareCommand comm
       // is then stored in the transactional context to be used during the commit phase.
       // However if the current node is already the coordinator, then we fall back to ""normal"" ReplicationInterceptor
       // logic for this step.
-      if (!rpcManager.getTransport().isCoordinator()) {
+      Address primaryOwner = getPrimaryOwner();
+      if (!primaryOwner.equals(rpcManager.getAddress())) {
          setVersionsSeenOnPrepareCommand((VersionedPrepareCommand) command, context);
          Map<Address, Response> resps = rpcManager.invokeRemotely(null, command, true, true);
-         Response r = resps.get(rpcManager.getTransport().getCoordinator());  // We only really care about the coordinator's response.
+         Response r = resps.get(primaryOwner);  // We only really care about the coordinator's response.
          readVersionsFromResponse(r, context.getCacheTransaction());
       } else {
          super.broadcastPrepare(context, command);",2013-03-07T23:03:03Z,495
"@@ -76,7 +76,7 @@ protected Log getLog() {
    }
 
    @Inject
-   private void injectConfiguration(Configuration configuration) {
+   public void injectConfiguration(Configuration configuration) {
       this.cacheConfiguration = configuration;
    }
 ",2013-03-07T23:03:03Z,496
"@@ -40,16 +40,14 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.statetransfer.StateTransferLock;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.transaction.xa.CacheTransaction;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
 
 import java.util.Collection;
 
 import static org.infinispan.transaction.WriteSkewHelper.performWriteSkewCheckAndReturnNewVersions;
 
-// todo [anistor] need to review this for NBST
 /**
  * Abstractization for logic related to different clustering modes: replicated or distributed. This implements the <a
  * href=""http://en.wikipedia.org/wiki/Bridge_pattern"">Bridge</a> pattern as described by the GoF: this plays the role of
@@ -61,8 +59,6 @@
 @Scope(Scopes.NAMED_CACHE)
 public interface ClusteringDependentLogic {
 
-   Log log = LogFactory.getLog(ClusteringDependentLogic.class);
-
    boolean localNodeIsOwner(Object key);
 
    boolean localNodeIsPrimaryOwner(Object key);
@@ -77,10 +73,18 @@ public interface ClusteringDependentLogic {
    
    Address getAddress();
 
-   public static abstract class AbstractClusteringDependentLogic implements  ClusteringDependentLogic {
+   public static abstract class AbstractClusteringDependentLogic implements ClusteringDependentLogic {
+
+      protected DataContainer dataContainer;
 
       protected CacheNotifier notifier;
 
+      @Inject
+      public void init(DataContainer dataContainer, CacheNotifier notifier) {
+         this.dataContainer = dataContainer;
+         this.notifier = notifier;
+      }
+
       protected void notifyCommitEntry(boolean created, boolean removed,
             boolean evicted, CacheEntry entry, InvocationContext ctx) {
          // Eviction has no notion of pre/post event since 4.2.0.ALPHA4.
@@ -109,13 +113,61 @@ protected void notifyCommitEntry(boolean created, boolean removed,
    }
 
    /**
-    * This logic is used when a changing a key affects all the nodes in the cluster, e.g. int the replicated,
-    * invalidated and local cache modes.
+    * This logic is used in local mode caches.
     */
-   public static final class AllNodesLogic extends AbstractClusteringDependentLogic {
+   public static class LocalLogic extends AbstractClusteringDependentLogic {
+
+      @Override
+      public boolean localNodeIsOwner(Object key) {
+         return true;
+      }
+
+      @Override
+      public boolean localNodeIsPrimaryOwner(Object key) {
+         return true;
+      }
+
+      @Override
+      public Address getPrimaryOwner(Object key) {
+         throw new IllegalStateException(""Cannot invoke this method for local caches"");
+      }
+
+      @Override
+      public Collection<Address> getOwners(Collection<Object> keys) {
+         return null;
+      }
+
+      @Override
+      public Address getAddress() {
+         return null;
+      }
+
+      @Override
+      public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipOwnershipCheck, InvocationContext ctx) {
+         // Cache flags before they're reset
+         // TODO: Can the reset be done after notification instead?
+         boolean created = entry.isCreated();
+         boolean removed = entry.isRemoved();
+         boolean evicted = entry.isEvicted();
 
-      private DataContainer dataContainer;
+         entry.commit(dataContainer, newVersion);
+
+         // Notify after events if necessary
+         notifyCommitEntry(created, removed, evicted, entry, ctx);
+      }
+
+      @Override
+      public EntryVersionsMap createNewVersionsAndCheckForWriteSkews(VersionGenerator versionGenerator, TxInvocationContext context, VersionedPrepareCommand prepareCommand) {
+         throw new IllegalStateException(""Cannot invoke this method for local caches"");
+      }
+   }
 
+   /**
+    * This logic is used in invalidation mode caches.
+    */
+   public static class InvalidationLogic extends AbstractClusteringDependentLogic {
+
+      private StateTransferManager stateTransferManager;
       private RpcManager rpcManager;
 
       private static final WriteSkewHelper.KeySpecificLogic keySpecificLogic = new WriteSkewHelper.KeySpecificLogic() {
@@ -126,27 +178,24 @@ public boolean performCheckOnKey(Object key) {
       };
 
       @Inject
-      public void init(DataContainer dc, RpcManager rpcManager, CacheNotifier notifier) {
-         this.dataContainer = dc;
+      public void init(RpcManager rpcManager, StateTransferManager stateTransferManager) {
          this.rpcManager = rpcManager;
-         this.notifier = notifier;
+         this.stateTransferManager = stateTransferManager;
       }
 
       @Override
       public boolean localNodeIsOwner(Object key) {
-         return true;
+         return stateTransferManager.getCacheTopology().getWriteConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key);
       }
 
       @Override
       public boolean localNodeIsPrimaryOwner(Object key) {
-         return rpcManager == null || rpcManager.getTransport().isCoordinator();
+         return stateTransferManager.getCacheTopology().getWriteConsistentHash().locatePrimaryOwner(key).equals(rpcManager.getAddress());
       }
 
       @Override
       public Address getPrimaryOwner(Object key) {
-         if (rpcManager == null)
-            throw new IllegalStateException(""Cannot invoke this method for local caches"");
-         return rpcManager.getTransport().getCoordinator();
+         return stateTransferManager.getCacheTopology().getWriteConsistentHash().locatePrimaryOwner(key);
       }
 
       @Override
@@ -165,7 +214,7 @@ public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipO
 
       @Override
       public Collection<Address> getOwners(Collection<Object> keys) {
-         return null;
+         return null;    //todo [anistor] should I actually return this based on current CH?
       }
       
       @Override
@@ -176,7 +225,7 @@ public Address getAddress() {
       @Override
       public EntryVersionsMap createNewVersionsAndCheckForWriteSkews(VersionGenerator versionGenerator, TxInvocationContext context, VersionedPrepareCommand prepareCommand) {
          // In REPL mode, this happens if we are the coordinator.
-         if (rpcManager.getTransport().isCoordinator()) {
+         if (stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0).equals(rpcManager.getAddress())) {
             // Perform a write skew check on each entry.
             EntryVersionsMap uv = performWriteSkewCheckAndReturnNewVersions(prepareCommand, dataContainer,
                                                                             versionGenerator, context,
@@ -194,10 +243,35 @@ public EntryVersionsMap createNewVersionsAndCheckForWriteSkews(VersionGenerator
       }
    }
 
-   public static final class DistributionLogic extends AbstractClusteringDependentLogic {
+   /**
+    * This logic is used in replicated mode caches.
+    */
+   public static class ReplicationLogic extends InvalidationLogic {
+
+      private StateTransferLock stateTransferLock;
+
+      @Inject
+      public void init(StateTransferLock stateTransferLock) {
+         this.stateTransferLock = stateTransferLock;
+      }
+
+      @Override
+      public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipOwnershipCheck, InvocationContext ctx) {
+         stateTransferLock.acquireSharedTopologyLock();
+         try {
+            super.commitEntry(entry, newVersion, skipOwnershipCheck, ctx);
+         } finally {
+            stateTransferLock.releaseSharedTopologyLock();
+         }
+      }
+   }
+
+   /**
+    * This logic is used in distributed mode caches.
+    */
+   public static class DistributionLogic extends AbstractClusteringDependentLogic {
 
       private DistributionManager dm;
-      private DataContainer dataContainer;
       private Configuration configuration;
       private RpcManager rpcManager;
       private StateTransferLock stateTransferLock;
@@ -210,14 +284,12 @@ public boolean performCheckOnKey(Object key) {
       };
 
       @Inject
-      public void init(DistributionManager dm, DataContainer dataContainer, Configuration configuration,
-                       RpcManager rpcManager, StateTransferLock stateTransferLock, CacheNotifier notifier) {
+      public void init(DistributionManager dm, Configuration configuration,
+                       RpcManager rpcManager, StateTransferLock stateTransferLock) {
          this.dm = dm;
-         this.dataContainer = dataContainer;
          this.configuration = configuration;
          this.rpcManager = rpcManager;
          this.stateTransferLock = stateTransferLock;
-         this.notifier = notifier;
       }
 
       @Override",2013-03-07T23:03:03Z,172
"@@ -22,17 +22,12 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.affinity.KeyAffinityService;
-import org.infinispan.affinity.KeyAffinityServiceFactory;
-import org.infinispan.affinity.RndKeyGenerator;
 import org.infinispan.config.Configuration;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
 import javax.transaction.Transaction;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
 
 /**
  * @author Mircea.Markus@jboss.com",2013-03-07T23:03:03Z,497
"@@ -0,0 +1,152 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.interceptors;
+
+import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.read.GetKeyValueCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.Configuration;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
+import org.infinispan.container.entries.ImmortalCacheValue;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.distribution.TestAddress;
+import org.infinispan.distribution.ch.ReplicatedConsistentHash;
+import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.responses.SuccessfulResponse;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
+import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.Transport;
+import org.infinispan.statetransfer.StateTransferManager;
+import org.infinispan.topology.CacheTopology;
+import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.util.concurrent.locks.LockManager;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.mockito.invocation.InvocationOnMock;
+import org.mockito.stubbing.Answer;
+import org.testng.annotations.Test;
+
+import java.util.*;
+
+import static org.junit.Assert.assertEquals;
+import static org.mockito.Matchers.*;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+
+/**
+ * Tests ReplicationInterceptor.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""interceptors.ReplicationInterceptorTest"")
+public class ReplicationInterceptorTest {
+
+   private static final Log log = LogFactory.getLog(ReplicationInterceptorTest.class);
+
+   public void testRemoteGetForGetKeyValueCommand() throws Throwable {
+      ConfigurationBuilder cb = new ConfigurationBuilder();
+      cb.clustering().cacheMode(CacheMode.REPL_SYNC);
+
+      GlobalConfigurationBuilder gcb = GlobalConfigurationBuilder.defaultClusteredBuilder();
+      Configuration configuration = cb.build();
+
+      ReplicationInterceptor replInterceptor = new ReplicationInterceptor();
+      CommandInterceptor nextInterceptor = mock(CommandInterceptor.class);
+      when(nextInterceptor.visitGetKeyValueCommand(any(InvocationContext.class), any(GetKeyValueCommand.class))).thenReturn(null);
+      replInterceptor.setNext(nextInterceptor);
+
+      CommandsFactory commandsFactory = mock(CommandsFactory.class);
+      when(commandsFactory.buildClusteredGetCommand(any(Object.class), any(Set.class), anyBoolean(), any(GlobalTransaction.class))).thenAnswer(new Answer<ClusteredGetCommand>() {
+         @Override
+         public ClusteredGetCommand answer(InvocationOnMock invocation) {
+            Object key = invocation.getArguments()[0];
+            Set<Flag> flags = (Set<Flag>) invocation.getArguments()[1];
+            boolean acquireRemoteLock = (Boolean) invocation.getArguments()[2];
+            GlobalTransaction gtx = (GlobalTransaction) invocation.getArguments()[3];
+            return new ClusteredGetCommand(key, ""cache1"", flags, acquireRemoteLock, gtx);
+         }
+      });
+
+      EntryFactory entryFactory = mock(EntryFactory.class);
+      DataContainer dataContainer = mock(DataContainer.class);
+      LockManager lockManager = mock(LockManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
+
+      TestAddress A = new TestAddress(0, ""A"");
+      TestAddress B = new TestAddress(1, ""B"");
+      List<Address> members1 = new ArrayList<Address>();
+      List<Address> members2 = new ArrayList<Address>();
+      members1.add(A);
+      members2.add(A);
+      members2.add(B);
+      ReplicatedConsistentHash readCh = new ReplicatedConsistentHash(members1);
+      ReplicatedConsistentHash writeCh = new ReplicatedConsistentHash(members2);
+      final CacheTopology cacheTopology = new CacheTopology(1, readCh, writeCh);
+      when(stateTransferManager.getCacheTopology()).thenAnswer(new Answer<CacheTopology>() {
+         @Override
+         public CacheTopology answer(InvocationOnMock invocation) {
+            return cacheTopology;
+         }
+      });
+      replInterceptor.init(commandsFactory, entryFactory, dataContainer, lockManager, stateTransferManager);
+      RpcManager rpcManager = mock(RpcManager.class);
+      Transport transport = mock(Transport.class);
+      when(rpcManager.getAddress()).thenReturn(B);
+      when(rpcManager.getTransport()).thenReturn(transport);
+      when(transport.getMembers()).thenReturn(members2);
+      replInterceptor.inject(rpcManager);
+      replInterceptor.injectConfiguration(configuration);
+
+      when(rpcManager.invokeRemotely(any(Collection.class), any(ClusteredGetCommand.class), any(ResponseMode.class),
+            anyLong(), anyBoolean(), any(ResponseFilter.class))).thenAnswer(new Answer<Map<Address, Response>>() {
+         @Override
+         public Map<Address, Response> answer(InvocationOnMock invocation) {
+            Collection<Address> recipients = (Collection<Address>) invocation.getArguments()[0];
+            ClusteredGetCommand clusteredGetCommand = (ClusteredGetCommand) invocation.getArguments()[1];
+            if (clusteredGetCommand.getKey().equals(""theKey"")) {
+               Map<Address, Response> results = new HashMap<Address, Response>();
+               for (Address recipient : recipients) {
+                  results.put(recipient, SuccessfulResponse.create(new ImmortalCacheValue(""theValue"")));
+               }
+               return results;
+            }
+            return Collections.emptyMap();
+         }
+      });
+
+      InvocationContext ctx = mock(InvocationContext.class);
+      when(ctx.isOriginLocal()).thenReturn(true);
+      when(ctx.isInTxScope()).thenReturn(false);
+
+      GetKeyValueCommand getKeyValueCommand = new GetKeyValueCommand(""theKey"", null);
+
+      Object retVal = replInterceptor.visitGetKeyValueCommand(ctx, getKeyValueCommand);
+      assertEquals(""theValue"", retVal);
+   }
+}",2013-03-07T23:03:03Z,103
"@@ -39,7 +39,7 @@
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
-@Test(groups = ""functional"", testName = ""replication.BaseReplicatedAPITest"")
+@Test(groups = ""functional"")
 public abstract class BaseReplicatedAPITest extends MultipleCacheManagersTest {
 
    protected boolean isSync;
@@ -150,7 +150,7 @@ public void testRemoveIfPresent() {
       waitForRpc(cache2);
 
       assert cache1.get(""key"") == null;
-      assert cache2.get(""key"").equals(""value2"");
+      assert cache2.get(""key"") == null;
    }
 
    public void testClear() {
@@ -214,8 +214,9 @@ public void testReplaceWithOldVal() {
       cache1.replace(""key"", ""valueN"", ""value1"");
       waitForRpc(cache2);
 
-      assert cache1.get(""key"").equals(""value1"");
-      assert cache2.get(""key"").equals(""value2"");
+      // the replace executed identically on both of them
+      assertEquals(""value1"", cache1.get(""key""));
+      assertEquals(""value1"", cache2.get(""key""));
    }
 
    public void testLocalOnlyClear() {",2013-03-07T23:03:03Z,282
"@@ -120,7 +120,6 @@ public void testPutIfAbsent() throws Exception {
       testStateTransferConsistency(Operation.PUT_IF_ABSENT);
    }
 
-   @Test(enabled = false)  // disabled due to ISPN-2647
    public void testReplace() throws Exception {
       testStateTransferConsistency(Operation.REPLACE);
    }
@@ -222,9 +221,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
       TestingUtil.waitForRehashToComplete(cache(0), cache(1), cache(2));
 
       // at this point state transfer is fully done
-      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.keySet());
-      log.infof(""Data container of NodeB has %d keys: %s"", dc1.size(), dc1.keySet());
-      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.keySet());
+      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.entrySet());
+      log.infof(""Data container of NodeB has %d keys: %s"", dc1.size(), dc1.entrySet());
+      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.entrySet());
 
       if (op == Operation.CLEAR || op == Operation.REMOVE) {
          // caches should be empty. check that no keys were revived by an inconsistent state transfer
@@ -253,9 +252,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
    }
 
    private void assertValue(int cacheIndex, int key, String expectedValue) {
-      InternalCacheEntry object = cache(cacheIndex).getAdvancedCache().getDataContainer().get(key);
-      assertNotNull(object);
-      assertEquals(expectedValue, object.getValue());
-      assertEquals(expectedValue, cache(cacheIndex).get(key));
+      InternalCacheEntry ice = cache(cacheIndex).getAdvancedCache().getDataContainer().get(key);
+      assertNotNull(""Found null on cache "" + cacheIndex,  ice);
+      assertEquals(""Did not find the expected value on cache "" + cacheIndex, expectedValue, ice.getValue());
+      assertEquals(""Did not find the expected value on cache "" + cacheIndex, expectedValue, cache(cacheIndex).get(key));
    }
 }",2013-03-07T23:03:03Z,498
"@@ -0,0 +1,40 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplNonTxOperationsDuringStateTransferTest"")
+@CleanupAfterMethod
+public class ReplNonTxOperationsDuringStateTransferTest extends BaseOperationsDuringStateTransferTest {
+
+   public ReplNonTxOperationsDuringStateTransferTest() {
+      super(CacheMode.REPL_SYNC, false, false, false);
+   }
+}",2013-03-07T23:03:03Z,499
"@@ -0,0 +1,40 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplOptimisticTxOperationsDuringStateTransferTest"")
+@CleanupAfterMethod
+public class ReplOptimisticTxOperationsDuringStateTransferTest extends BaseOperationsDuringStateTransferTest {
+
+   public ReplOptimisticTxOperationsDuringStateTransferTest() {
+      super(CacheMode.REPL_SYNC, true, true, false);
+   }
+}",2013-03-07T23:03:03Z,500
"@@ -0,0 +1,57 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplPessimisticOperationsDuringStateTransferTest"",
+      enabled = false, description = ""Disabled due to https://issues.jboss.org/browse/ISPN-2847"")
+@CleanupAfterMethod
+public class ReplPessimisticOperationsDuringStateTransferTest extends BaseOperationsDuringStateTransferTest {
+
+   public ReplPessimisticOperationsDuringStateTransferTest() {
+      super(CacheMode.REPL_SYNC, true, false, false);
+   }
+
+   @Test(enabled = false)
+   public void testPut() throws Exception {
+   }
+
+   @Test(enabled = false)
+   public void testReplace() throws Exception {
+   }
+
+   @Test(enabled = false)
+   public void testGet() throws Exception {
+   }
+
+   @Test(enabled = false)
+   public void testRemove() throws Exception {
+   }
+}",2013-03-07T23:03:03Z,501
"@@ -68,10 +68,10 @@ public void setUp() {
       txTable.addLocalTransactionMapping(localTx);      
 
       configuration = new ConfigurationBuilder().build();
-      TransactionCoordinator txCoordinator = new TransactionCoordinator();
+      txCoordinator = new TransactionCoordinator();
       txCoordinator.init(null, null, null, null, configuration);
       xaAdapter = new TransactionXaAdapter(localTx, txTable, null, txCoordinator, null, null,
-                                           new ClusteringDependentLogic.AllNodesLogic(), configuration, """");
+                                           new ClusteringDependentLogic.InvalidationLogic(), configuration, """");
    }
 
    public void testPrepareOnNonexistentXid() {",2013-03-07T23:03:03Z,94
"@@ -26,6 +26,7 @@
 import org.infinispan.CacheException;
 import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.configuration.global.GlobalConfiguration;
@@ -35,6 +36,7 @@
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.jmx.annotations.ManagedOperation;
+import org.infinispan.newstatetransfer.StateTransferManager;
 import org.infinispan.remoting.ReplicationQueue;
 import org.infinispan.remoting.RpcException;
 import org.infinispan.remoting.responses.IgnoreExtraResponsesValidityFilter;
@@ -95,13 +97,15 @@ public class RpcManagerImpl implements RpcManager {
    private ExecutorService asyncExecutor;
    private CommandsFactory cf;
    private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
 
    @Inject
    public void injectDependencies(Transport t, Cache cache, Configuration cfg,
             ReplicationQueue replicationQueue, CommandsFactory cf,
             @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService e,
-            LocalTopologyManager localTopologyManager, GlobalConfiguration globalCfg) {
+            LocalTopologyManager localTopologyManager, StateTransferManager stateTransferManager,
+            GlobalConfiguration globalCfg) {
       this.t = t;
       this.configuration = cfg;
       this.cacheName = cache.getName();
@@ -110,6 +114,7 @@ public void injectDependencies(Transport t, Cache cache, Configuration cfg,
       this.asyncExecutor = e;
       this.cf = cf;
       this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
    }
 
    @Start(priority = 9)
@@ -165,6 +170,9 @@ public final Map<Address, Response> invokeRemotely(Collection<Address> recipient
                   responseFilter = new IgnoreExtraResponsesValidityFilter(cacheMembers, getAddress());
                }
             }
+            if (rpcCommand instanceof TopologyAffectedCommand) {
+               ((TopologyAffectedCommand)rpcCommand).setTopologyId(stateTransferManager.getTopologyId());
+            }
             Map<Address, Response> result = t.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue, responseFilter);
             if (statisticsEnabled) replicationCount.incrementAndGet();
             return result;",2012-08-31T21:04:20Z,105
"@@ -22,10 +22,6 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.context.InvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
@@ -95,24 +91,6 @@ public interface DistributionManager {
     */
    Set<Address> locateAll(Collection<Object> keys); //todo [anistor] this has to take an additional parameter that specifies if the lookup is for read or write
 
-   /**
-    * Transforms a cache entry so it is marked for L1 rather than the primary cache data structure.  This should be done
-    * if it is deemed that the entry is targeted for L1 storage rather than storage in the primary data container.
-    *
-    * @param entry entry to transform
-    */
-   void transformForL1(CacheEntry entry);
-
-   /**
-    * Retrieves a cache entry from a remote source.  Would typically involve an RPC call using a {@link org.infinispan.commands.remote.ClusteredGetCommand}
-    * and some form of quorum of responses if the responses returned are inconsistent - often the case if there is a
-    * rehash in progress, involving nodes that the key maps to.
-    *
-    * @param key key to look up
-    * @return an internal cache entry, or null if it cannot be located
-    */
-   InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception;
-
    /**
     * Retrieves the consistent hash instance currently in use, an instance of the configured ConsistentHash
     * class (which defaults to {@link org.infinispan.distribution.ch.DefaultConsistentHash}.",2013-03-07T23:03:04Z,60
"@@ -22,31 +22,16 @@
  */
 package org.infinispan.distribution;
 
-import org.infinispan.commands.CommandsFactory;
-import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.commands.remote.ClusteredGetCommand;
-import org.infinispan.configuration.cache.Configuration;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalCacheValue;
-import org.infinispan.context.InvocationContext;
-import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.jmx.annotations.Parameter;
 import org.infinispan.statetransfer.StateTransferManager;
-import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
-import org.infinispan.remoting.responses.Response;
-import org.infinispan.remoting.responses.SuccessfulResponse;
-import org.infinispan.remoting.rpc.ResponseFilter;
-import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
@@ -70,9 +55,7 @@ public class DistributionManagerImpl implements DistributionManager {
    private static final boolean trace = log.isTraceEnabled();
 
    // Injected components
-   private Configuration configuration;
    private RpcManager rpcManager;
-   private CommandsFactory cf;
    private StateTransferManager stateTransferManager;
 
    /**
@@ -82,11 +65,8 @@ public DistributionManagerImpl() {
    }
 
    @Inject
-   public void init(Configuration configuration, RpcManager rpcManager, CommandsFactory cf,
-                    StateTransferManager stateTransferManager) {
-      this.configuration = configuration;
+   public void init(RpcManager rpcManager, StateTransferManager stateTransferManager) {
       this.rpcManager = rpcManager;
-      this.cf = cf;
       this.stateTransferManager = stateTransferManager;
    }
 
@@ -147,39 +127,6 @@ public Set<Address> locateAll(Collection<Object> keys) {
       return getConsistentHash().locateAllOwners(keys);
    }
 
-   @Override
-   public void transformForL1(CacheEntry entry) {
-      if (entry.getLifespan() < 0 || entry.getLifespan() > configuration.clustering().l1().lifespan())
-         entry.setLifespan(configuration.clustering().l1().lifespan());
-   }
-
-   @Override
-   public InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception {
-      GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
-      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
-
-      List<Address> targets = new ArrayList<Address>(getReadConsistentHash().locateOwners(key));
-      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
-      targets.retainAll(rpcManager.getTransport().getMembers());
-      ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, getAddress());
-      Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
-                                                                   configuration.clustering().sync().replTimeout(), true, filter);
-
-      if (!responses.isEmpty()) {
-         for (Response r : responses.values()) {
-            if (r instanceof SuccessfulResponse) {
-               InternalCacheValue cacheValue = (InternalCacheValue) ((SuccessfulResponse) r).getResponseValue();
-               return cacheValue.toInternalCacheEntry(key);
-            }
-         }
-      }
-
-      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
-      // Otherwise our get command might be processed by the old owners after they have invalidated their data
-      // and we'd return a null even though the key exists on
-      return null;
-   }
-
    @Override
    public ConsistentHash getConsistentHash() {
       return getWriteConsistentHash();",2013-03-07T23:03:04Z,60
"@@ -0,0 +1,120 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.interceptors;
+
+import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.FlagAffectedCommand;
+import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.EntryFactory;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.factories.annotations.Inject;
+import org.infinispan.factories.annotations.Start;
+import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.statetransfer.StateTransferManager;
+import org.infinispan.util.concurrent.locks.LockManager;
+
+/**
+ * Base class for replication and distribution interceptors.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+public abstract class ClusteringInterceptor extends BaseRpcInterceptor {
+
+   protected CommandsFactory cf;
+   protected EntryFactory entryFactory;
+   protected LockManager lockManager;
+   protected DataContainer dataContainer;
+   protected StateTransferManager stateTransferManager;
+   protected boolean needReliableReturnValues;
+
+   @Inject
+   public void injectDependencies(CommandsFactory cf, EntryFactory entryFactory,
+                                  LockManager lockManager, DataContainer dataContainer,
+                                  StateTransferManager stateTransferManager) {
+      this.cf = cf;
+      this.entryFactory = entryFactory;
+      this.lockManager = lockManager;
+      this.dataContainer = dataContainer;
+      this.stateTransferManager = stateTransferManager;
+   }
+
+   @Start
+   public void configure() {
+      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
+   }
+
+   protected boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
+      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+   }
+
+   protected boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
+      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
+            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
+         return false;
+      }
+      boolean shouldFetchFromRemote = false;
+      CacheEntry entry = ctx.lookupEntry(command.getKey());
+      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
+         Object key = command.getKey();
+         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
+         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
+         if (!shouldFetchFromRemote && getLog().isTraceEnabled()) {
+            getLog().tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s) or is in L1. Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
+         }
+      }
+      return shouldFetchFromRemote;
+   }
+
+   /**
+    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
+    * <pre>
+    * - node A (owner, tx originator) does a successful replace
+    * - the actual value changes
+    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
+    *   B (check is performed at commit time).
+    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
+    * </pre>
+    */
+   protected boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return ctx.isOriginLocal() && command.isSuccessful();
+   }
+
+   /**
+    * Retrieves a cache entry from a remote source.  Would typically involve an RPC call using a {@link org.infinispan.commands.remote.ClusteredGetCommand}
+    * and some form of quorum of responses if the responses returned are inconsistent - often the case if there is a
+    * rehash in progress, involving nodes that the key maps to.
+    *
+    * @param key key to look up
+    * @return an internal cache entry, or null if it cannot be located
+    */
+   protected abstract InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception;
+}",2013-03-07T23:03:04Z,482
"@@ -22,7 +22,6 @@
  */
 package org.infinispan.interceptors;
 
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.AbstractDataCommand;
@@ -35,30 +34,21 @@
 import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configurations;
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.EntryFactory;
-import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.InternalCacheValue;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.ch.ConsistentHash;
-import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
-import org.infinispan.interceptors.base.BaseRpcInterceptor;
 import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
 import org.infinispan.remoting.responses.Response;
 import org.infinispan.remoting.responses.SuccessfulResponse;
 import org.infinispan.remoting.rpc.ResponseFilter;
 import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.jgroups.SuspectException;
-import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.xa.GlobalTransaction;
-import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -71,16 +61,8 @@
  * @author Bela Ban
  * @since 4.0
  */
-public class ReplicationInterceptor extends BaseRpcInterceptor {
+public class ReplicationInterceptor extends ClusteringInterceptor {
 
-   private CommandsFactory cf;
-
-   private EntryFactory entryFactory;
-   private LockManager lockManager;
-   private DataContainer dataContainer;
-   private StateTransferManager stateTransferManager;
-
-   private boolean needReliableReturnValues;
    private boolean isPessimisticCache;
 
    private static final Log log = LogFactory.getLog(ReplicationInterceptor.class);
@@ -91,19 +73,9 @@ protected Log getLog() {
       return log;
    }
 
-   @Inject
-   public void init(CommandsFactory cf, EntryFactory entryFactory, DataContainer dataContainer, LockManager lockManager, StateTransferManager stateTransferManager) {
-      this.cf = cf;
-      this.entryFactory = entryFactory;
-      this.dataContainer = dataContainer;
-      this.lockManager = lockManager;
-      this.stateTransferManager = stateTransferManager;
-   }
-
    @Start
    public void start() {
       isPessimisticCache = cacheConfiguration.transaction().lockingMode() == LockingMode.PESSIMISTIC;
-      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
    }
 
    @Override
@@ -180,44 +152,6 @@ public Object visitLockControlCommand(TxInvocationContext ctx, LockControlComman
       return retVal;
    }
 
-   private boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            || command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)   //todo [anistor] clarify usage of this flag in REPL mode
-            || command.hasFlag(Flag.IGNORE_RETURN_VALUES)) {
-         return false;
-      }
-      boolean shouldFetchFromRemote = false;
-      CacheEntry entry = ctx.lookupEntry(command.getKey());
-      if (entry == null || entry.isNull() || entry.isLockPlaceholder()) {
-         Object key = command.getKey();
-         ConsistentHash ch = stateTransferManager.getCacheTopology().getReadConsistentHash();
-         shouldFetchFromRemote = ctx.isOriginLocal() && !ch.isKeyLocalToNode(rpcManager.getAddress(), key) && !dataContainer.containsKey(key);
-         if (!shouldFetchFromRemote) {
-            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s). Owners are %s"", key, rpcManager.getAddress(), ch.locateOwners(key));
-         }
-      }
-      return shouldFetchFromRemote;
-   }
-
-   private boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
-      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
-   }
-
-   /**
-    * For conditional operations (replace, remove, put if absent) Used only for optimistic transactional caches, to solve the following situation:
-    * <pre>
-    * - node A (owner, tx originator) does a successful replace
-    * - the actual value changes
-    * - tx commits. The value is applied on A (the check was performed at operation time) but is not applied on
-    *   B (check is performed at commit time).
-    * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
-    * </pre>
-    */
-   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
-      return ctx.isOriginLocal() && command.isSuccessful();
-   }
-
    /**
     * This method retrieves an entry from a remote cache.
     * <p/>
@@ -242,7 +176,7 @@ private Object remoteGet(InvocationContext ctx, Object key, FlagAffectedCommand
          acquireRemoteLock = isWrite && isPessimisticCache && !txContext.getAffectedKeys().contains(key);
       }
       // attempt a remote lookup
-      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command.getFlags());
+      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
 
       if (acquireRemoteLock) {
          ((TxInvocationContext) ctx).addAffectedKey(key);
@@ -265,9 +199,9 @@ protected Address getPrimaryOwner() {
       return stateTransferManager.getCacheTopology().getReadConsistentHash().getMembers().get(0);
    }
 
-   private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, Set<Flag> flags) {
+   protected InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) {
       GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
-      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, flags, acquireRemoteLock, gtx);
+      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
 
       List<Address> targets = Collections.singletonList(getPrimaryOwner());
       ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
@@ -289,7 +223,7 @@ private InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContex
    private Object localGet(InvocationContext ctx, Object key, boolean isWrite, FlagAffectedCommand command) throws Throwable {
       InternalCacheEntry ice = dataContainer.get(key);
       if (ice != null) {
-         if (!ctx.replaceValue(key, ice.getValue()))  {
+         if (!ctx.replaceValue(key, ice.getValue())) {
             if (isWrite)
                lockAndWrap(ctx, key, ice, command);
             else",2013-03-07T23:03:04Z,103
"@@ -22,34 +22,32 @@
  */
 package org.infinispan.interceptors.distribution;
 
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.FlagAffectedCommand;
-import org.infinispan.commands.read.AbstractDataCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.write.PutMapCommand;
 import org.infinispan.commands.write.RemoveCommand;
 import org.infinispan.commands.write.ReplaceCommand;
 import org.infinispan.commands.write.WriteCommand;
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.EntryFactory;
-import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.container.entries.InternalCacheValue;
 import org.infinispan.context.InvocationContext;
-import org.infinispan.distribution.DataLocality;
+import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.DistributionManager;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
-import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.interceptors.ClusteringInterceptor;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
+import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.responses.SuccessfulResponse;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
-import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 
 /**
  * Base class for distribution of entries across a cluster.
@@ -60,14 +58,11 @@
  * @author Dan Berindei <dan@infinispan.org>
  * @since 4.0
  */
-public abstract class BaseDistributionInterceptor extends BaseRpcInterceptor {
+public abstract class BaseDistributionInterceptor extends ClusteringInterceptor {
+
    protected DistributionManager dm;
-   protected CommandsFactory cf;
-   protected DataContainer dataContainer;
-   protected EntryFactory entryFactory;
-   protected LockManager lockManager;
+
    protected ClusteringDependentLogic cdl;
-   private boolean needReliableReturnValues;
 
    private static final Log log = LogFactory.getLog(BaseDistributionInterceptor.class);
 
@@ -77,42 +72,36 @@ protected Log getLog() {
    }
 
    @Inject
-   public void injectDependencies(DistributionManager distributionManager,
-                                  CommandsFactory cf, DataContainer dataContainer, EntryFactory entryFactory,
-                                  LockManager lockManager, ClusteringDependentLogic cdl) {
+   public void injectDependencies(DistributionManager distributionManager, ClusteringDependentLogic cdl) {
       this.dm = distributionManager;
-      this.cf = cf;
-      this.dataContainer = dataContainer;
-      this.entryFactory = entryFactory;
-      this.lockManager = lockManager;
       this.cdl = cdl;
    }
 
-   @Start
-   public void configure() {
-      needReliableReturnValues = !cacheConfiguration.unsafe().unreliableReturnValues();
-   }
-
-   protected boolean needsRemoteGet(InvocationContext ctx, AbstractDataCommand command) {
-      boolean shouldFetchFromRemote = false;
-      final CacheEntry entry;
-      if (!command.hasFlag(Flag.CACHE_MODE_LOCAL)
-            && !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES)
-            && ((entry = ctx.lookupEntry(command.getKey())) == null || entry.isNull() || entry.isLockPlaceholder())) {
-         Object key = command.getKey();
-         DataLocality locality = dm.getReadConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key) ? DataLocality.LOCAL : DataLocality.NOT_LOCAL;
-         shouldFetchFromRemote = ctx.isOriginLocal() && !locality.isLocal() && !dataContainer.containsKey(key);
-         if (!shouldFetchFromRemote) {
-            log.tracef(""Not doing a remote get for key %s since entry is mapped to current node (%s), or is in L1.  Owners are %s"", key, rpcManager.getAddress(), dm.locate(key));
+   @Override
+   protected InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext ctx, boolean acquireRemoteLock, FlagAffectedCommand command) throws Exception {
+      GlobalTransaction gtx = acquireRemoteLock ? ((TxInvocationContext)ctx).getGlobalTransaction() : null;
+      ClusteredGetCommand get = cf.buildClusteredGetCommand(key, command.getFlags(), acquireRemoteLock, gtx);
+
+      List<Address> targets = new ArrayList<Address>(stateTransferManager.getCacheTopology().getReadConsistentHash().locateOwners(key));
+      // if any of the recipients has left the cluster since the command was issued, just don't wait for its response
+      targets.retainAll(rpcManager.getTransport().getMembers());
+      ResponseFilter filter = new ClusteredGetResponseValidityFilter(targets, rpcManager.getAddress());
+      Map<Address, Response> responses = rpcManager.invokeRemotely(targets, get, ResponseMode.WAIT_FOR_VALID_RESPONSE,
+            cacheConfiguration.clustering().sync().replTimeout(), true, filter);
+
+      if (!responses.isEmpty()) {
+         for (Response r : responses.values()) {
+            if (r instanceof SuccessfulResponse) {
+               InternalCacheValue cacheValue = (InternalCacheValue) ((SuccessfulResponse) r).getResponseValue();
+               return cacheValue.toInternalCacheEntry(key);
+            }
          }
       }
-      return shouldFetchFromRemote;
-   }
 
-   protected boolean isNeedReliableReturnValues(FlagAffectedCommand command) {
-      return !command.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
-            && !command.hasFlag(Flag.IGNORE_RETURN_VALUES) && needReliableReturnValues;
+      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
+      // Otherwise our get command might be processed by the old owners after they have invalidated their data
+      // and we'd return a null even though the key exists on
+      return null;
    }
 
    @Override
@@ -157,9 +146,9 @@ interface RecipientGenerator extends KeyGenerator {
    }
 
    class SingleKeyRecipientGenerator implements RecipientGenerator {
-      final Object key;
-      final Set<Object> keys;
-      List<Address> recipients = null;
+      private final Object key;
+      private final Set<Object> keys;
+      private List<Address> recipients = null;
 
       SingleKeyRecipientGenerator(Object key) {
          this.key = key;
@@ -180,8 +169,8 @@ public Collection<Object> getKeys() {
 
    class MultipleKeysRecipientGenerator implements RecipientGenerator {
 
-      final Collection<Object> keys;
-      List<Address> recipients = null;
+      private final Collection<Object> keys;
+      private List<Address> recipients = null;
 
       MultipleKeysRecipientGenerator(Collection<Object> keys) {
          this.keys = keys;",2013-03-07T23:03:04Z,478
"@@ -140,7 +140,7 @@ private Object remoteGetBeforeWrite(InvocationContext ctx, Object key, FlagAffec
          if (trace) log.tracef(""Doing a remote get for key %s"", key);
 
          // attempt a remote lookup
-         InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, false, command);
+         InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, false, command);
          if (ice != null) {
             if (!ctx.replaceValue(key, ice.getValue())) {
                entryFactory.wrapEntryForPut(ctx, key, ice, false, command);
@@ -190,7 +190,7 @@ protected void handleRemoteWrite(InvocationContext ctx, WriteCommand command, Re
 
    private Object remoteGet(InvocationContext ctx, Object key, GetKeyValueCommand command) throws Throwable {
       if (trace) log.tracef(""Doing a remote get for key %s"", key);
-      InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, false, command);
+      InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, false, command);
       command.setRemotelyFetchedValue(ice);
       if (ice != null) {
          return ice.getValue();",2013-03-07T23:03:04Z,483
"@@ -117,8 +117,9 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
     * In such situations (optimistic caches) the remote conditional command should not re-check the old value.
     * </pre>
     */
-   private boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
-      return ctx.isOriginLocal() && command.isSuccessful() && cacheConfiguration.transaction().lockingMode() == LockingMode.OPTIMISTIC && !useClusteredWriteSkewCheck;
+   protected boolean ignorePreviousValueOnBackup(WriteCommand command, InvocationContext ctx) {
+      return super.ignorePreviousValueOnBackup(command, ctx)
+          && cacheConfiguration.transaction().lockingMode() == LockingMode.OPTIMISTIC && !useClusteredWriteSkewCheck;
    }
 
    @Start
@@ -176,7 +177,6 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
       }
    }
 
-
    private void lockAndWrap(InvocationContext ctx, Object key, InternalCacheEntry ice, FlagAffectedCommand command) throws InterruptedException {
       boolean skipLocking = hasSkipLocking(command);
       long lockTimeout = getLockAcquisitionTimeout(command, skipLocking);
@@ -341,7 +341,7 @@ private Object remoteGetAndStoreInL1(InvocationContext ctx, Object key, boolean
             acquireRemoteLock = isWrite && isPessimisticCache && !txContext.getAffectedKeys().contains(key);
          }
          // attempt a remote lookup
-         InternalCacheEntry ice = dm.retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
+         InternalCacheEntry ice = retrieveFromRemoteSource(key, ctx, acquireRemoteLock, command);
 
          if (acquireRemoteLock) {
             ((TxInvocationContext) ctx).addAffectedKey(key);",2013-03-07T23:03:04Z,484
"@@ -324,7 +324,9 @@ public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipO
             boolean isForeignOwned = !skipOwnershipCheck && !localNodeIsOwner(entry.getKey());
             if (isForeignOwned && !entry.isRemoved()) {
                if (configuration.clustering().l1().enabled()) {
-                  dm.transformForL1(entry);
+                  // transform for L1
+                  if (entry.getLifespan() < 0 || entry.getLifespan() > configuration.clustering().l1().lifespan())
+                     entry.setLifespan(configuration.clustering().l1().lifespan());
                } else {
                   doCommit = false;
                }",2013-03-07T23:03:04Z,172
"@@ -45,8 +45,6 @@
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.concurrent.locks.LockManager;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
 import org.mockito.invocation.InvocationOnMock;
 import org.mockito.stubbing.Answer;
 import org.testng.annotations.Test;
@@ -67,8 +65,6 @@
 @Test(groups = ""functional"", testName = ""interceptors.ReplicationInterceptorTest"")
 public class ReplicationInterceptorTest {
 
-   private static final Log log = LogFactory.getLog(ReplicationInterceptorTest.class);
-
    public void testRemoteGetForGetKeyValueCommand() throws Throwable {
       ConfigurationBuilder cb = new ConfigurationBuilder();
       cb.clustering().cacheMode(CacheMode.REPL_SYNC);
@@ -114,7 +110,7 @@ public CacheTopology answer(InvocationOnMock invocation) {
             return cacheTopology;
          }
       });
-      replInterceptor.init(commandsFactory, entryFactory, dataContainer, lockManager, stateTransferManager);
+      replInterceptor.injectDependencies(commandsFactory, entryFactory, lockManager, dataContainer, stateTransferManager);
       RpcManager rpcManager = mock(RpcManager.class);
       Transport transport = mock(Transport.class);
       when(rpcManager.getAddress()).thenReturn(B);",2013-03-07T23:03:04Z,103
"@@ -238,8 +238,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
       TestingUtil.waitForRehashToComplete(cache(0), cache(2));
 
       // at this point state transfer is fully done
-      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.keySet());
-      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.keySet());
+      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.entrySet());
+      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.entrySet());
 
       if (op == Operation.CLEAR || op == Operation.REMOVE) {
          // caches should be empty. check that no keys were revived by an inconsistent state transfer
@@ -262,7 +262,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
             assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
 
             // check values were not overwritten with old values carried by state transfer
-            assertEquals(""after_st_"" + i, cache(0).get(i));
+            String expected = ""after_st_"" + i;
+            assertEquals(expected, cache(0).get(i));
             assertEquals(""after_st_"" + i, cache(2).get(i));
          }
       } else { // PUT_IF_ABSENT
@@ -278,8 +279,9 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) thro
             }
             assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
 
-            assertEquals(""before_st_"" + i, cache(0).get(i));
-            assertEquals(""before_st_"" + i, cache(2).get(i));
+            String expected = ""before_st_"" + i;
+            assertEquals(expected, cache(0).get(i));
+            assertEquals(expected, cache(2).get(i));
          }
       }
    }",2013-03-07T23:03:04Z,485
"@@ -0,0 +1,355 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2009 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.lucene;
+
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.util.Set;
+
+import org.apache.lucene.store.Directory;
+import org.apache.lucene.store.IndexInput;
+import org.apache.lucene.store.IndexOutput;
+import org.apache.lucene.store.LockFactory;
+import org.infinispan.AdvancedCache;
+import org.infinispan.Cache;
+import org.infinispan.context.Flag;
+import org.infinispan.lucene.impl.FileListOperations;
+import org.infinispan.lucene.impl.IndexInputContext;
+import org.infinispan.lucene.impl.InfinispanIndexInputV3;
+import org.infinispan.lucene.impl.InfinispanIndexOutput;
+import org.infinispan.lucene.impl.SingleChunkIndexInput;
+import org.infinispan.lucene.locking.BaseLockFactory;
+import org.infinispan.lucene.readlocks.DistributedSegmentReadLocker;
+import org.infinispan.lucene.readlocks.SegmentReadLocker;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+/**
+ * An implementation of Lucene's {@link org.apache.lucene.store.Directory} which uses Infinispan to store Lucene indexes.
+ * As the RAMDirectory the data is stored in memory, but provides some additional flexibility:
+ * <p><b>Passivation, LRU or LIRS</b> Bigger indexes can be configured to passivate cleverly selected chunks of data to a cache store.
+ * This can be a local filesystem, a network filesystem, a database or custom cloud stores like S3. See Infinispan's core documentation for a full list of available implementations, or {@link org.infinispan.loaders.CacheStore} to implement more.</p>
+ * <p><b>Non-volatile memory</b> The contents of the index can be stored in it's entirety in such a store, so that on shutdown or crash of the system data is not lost.
+ * A copy of the index will be copied to the store in sync or async depending on configuration; In case you enable
+ * Infinispan's clustering even in case of async the segments are always duplicated synchronously to other nodes, so you can
+ * benefit from good reliability even while choosing the asynchronous mode to write the index to the slowest store implementations.</p>
+ * <p><b>Real-time change propagation</b> All changes done on a node are propagated at low latency to other nodes of the cluster; this was designed especially for
+ * interactive usage of Lucene, so that after an IndexWriter commits on one node new IndexReaders opened on any node of the cluster
+ * will be able to deliver updated search results.</p>
+ * <p><b>Distributed heap</b> Infinispan acts as a shared heap for the purpose of total memory consumption, so you can avoid hitting the slower disks even
+ * if the total size of the index can't fit in the memory of a single node: network is faster than disks, especially if the index
+ * is bigger than the memory available to cache it.</p>
+ * <p><b>Distributed locking</b>
+ * As default Lucene Directory implementations a global lock needs to protect the index from having more than an IndexWriter open; in case of a
+ * replicated or distributed index you need to enable a cluster-wide {@link org.apache.lucene.store.LockFactory}.
+ * This implementation uses by default {@link org.infinispan.lucene.locking.BaseLockFactory}; in case you want to apply changes during a JTA transaction
+ * see also {@link org.infinispan.lucene.locking.TransactionalLockFactory}.
+ * </p>
+ * <p><b>Combined store patterns</b> It's possible to combine different stores and passivation policies, so that each nodes shares the index changes
+ * quickly to other nodes, offloads less frequently used data to a per-node local filesystem, and the cluster also coordinates to keeps a safe copy on a shared store.</p>
+ * 
+ * @deprecated This class will be removed. Use {@link org.infinispan.lucene.directory.DirectoryBuilder} to create Directory instead.
+ * 
+ * @since 4.0
+ * @author Sanne Grinovero
+ * @author Lukasz Moren
+ * @see org.apache.lucene.store.Directory
+ * @see org.apache.lucene.store.LockFactory
+ * @see org.infinispan.lucene.locking.BaseLockFactory
+ * @see org.infinispan.lucene.locking.TransactionalLockFactory
+ */
+@SuppressWarnings(""unchecked"")
+@Deprecated
+public class InfinispanDirectory extends Directory {
+   
+   /**
+    * Used as default chunk size, can be overriden at construction time.
+    * Each Lucene index segment is splitted into parts with default size defined here
+    */
+   public final static int DEFAULT_BUFFER_SIZE = 16 * 1024;
+
+   private static final Log log = LogFactory.getLog(InfinispanDirectory.class);
+
+   private final AdvancedCache<FileCacheKey, FileMetadata> metadataCache;
+   private final AdvancedCache<ChunkCacheKey, Object> chunksCache;
+
+   // indexName is required when one common cache is used
+   private final String indexName;
+
+   // chunk size used in this directory, static field not used as we want to have different chunk
+   // size per dir
+   private final int chunkSize;
+
+   private final FileListOperations fileOps;
+   private final SegmentReadLocker readLocks;
+
+   /**
+    * @param metadataCache the cache to be used for all smaller metadata: prefer replication over distribution, avoid eviction
+    * @param chunksCache the cache to use for the space consuming segments: prefer distribution, enable eviction if needed
+    * @param indexName the unique index name, useful to store multiple indexes in the same caches
+    * @param lf the LockFactory to be used by IndexWriters. @see org.infinispan.lucene.locking
+    * @param chunkSize segments are fragmented in chunkSize bytes; larger values are more efficient for searching but less for distribution and network replication
+    * @param readLocker @see org.infinispan.lucene.readlocks for some implementations; you might be able to provide more efficient implementations by controlling the IndexReader's lifecycle.
+    */
+   public InfinispanDirectory(Cache<?, ?> metadataCache, Cache<?, ?> chunksCache, String indexName, LockFactory lf, int chunkSize, SegmentReadLocker readLocker) {
+      checkNotNull(metadataCache, ""metadataCache"");
+      checkNotNull(chunksCache, ""chunksCache"");
+      checkNotNull(indexName, ""indexName"");
+      checkNotNull(lf, ""LockFactory"");
+      checkNotNull(readLocker, ""SegmentReadLocker"");
+      if (chunkSize <= 0)
+         throw new IllegalArgumentException(""chunkSize must be a positive integer"");
+      this.metadataCache = (AdvancedCache<FileCacheKey, FileMetadata>) metadataCache.getAdvancedCache();
+      this.chunksCache = (AdvancedCache<ChunkCacheKey, Object>) chunksCache.getAdvancedCache();
+      this.indexName = indexName;
+      this.lockFactory = lf;
+      this.lockFactory.setLockPrefix(this.getLockID());
+      this.chunkSize = chunkSize;
+      this.fileOps = new FileListOperations(this.metadataCache, indexName);
+      this.readLocks = readLocker;
+   }
+
+   public InfinispanDirectory(Cache<?, ?> cache, String indexName, int chunkSize, SegmentReadLocker readLocker) {
+      this(cache, cache, indexName, makeDefaultLockFactory(cache, indexName), chunkSize, readLocker);
+   }
+
+   /**
+    * This constructor assumes that three different caches are being used with specialized configurations for each
+    * cache usage
+    * @param metadataCache contains the metadata of stored elements
+    * @param chunksCache cache containing the bulk of the index; this is the larger part of data
+    * @param distLocksCache cache to store locks; should be replicated and not using a persistent CacheStore
+    * @param indexName identifies the index; you can store different indexes in the same set of caches using different identifiers
+    * @param chunkSize the maximum size in bytes for each chunk of data: larger sizes offer better search performance
+    * but might be problematic to handle during network replication or storage
+    */
+   public InfinispanDirectory(Cache<?, ?> metadataCache, Cache<?, ?> chunksCache, Cache<?, ?> distLocksCache, String indexName, int chunkSize) {
+      this(metadataCache, chunksCache, indexName, makeDefaultLockFactory(distLocksCache, indexName),
+               chunkSize, makeDefaultSegmentReadLocker(metadataCache, chunksCache, distLocksCache, indexName));
+   }
+
+   /**
+    * @param cache the cache to use to store the index
+    * @param indexName identifies the index; you can store different indexes in the same set of caches using different identifiers
+    */
+   public InfinispanDirectory(Cache<?, ?> cache, String indexName) {
+      this(cache, cache, cache, indexName, DEFAULT_BUFFER_SIZE);
+   }
+
+   public InfinispanDirectory(Cache<?, ?> cache) {
+      this(cache, cache, cache, """", DEFAULT_BUFFER_SIZE);
+   }
+
+   /**
+    * {@inheritDoc}
+    */
+   public String[] list() {
+      ensureOpen();
+      Set<String> filesList = fileOps.getFileList();
+      String[] array = filesList.toArray(new String[0]);
+      return array;
+   }
+
+   /**
+    * {@inheritDoc}
+    */
+   @Override
+   public boolean fileExists(String name) {
+      ensureOpen();
+      return fileOps.getFileList().contains(name);
+   }
+
+   /**
+    * {@inheritDoc}
+    */
+   @Override
+   public long fileModified(String name) {
+      ensureOpen();
+      FileMetadata fileMetadata = fileOps.getFileMetadata(name);
+      if (fileMetadata == null) {
+         return 0L;
+      }
+      else {
+         return fileMetadata.getLastModified();
+      }
+   }
+
+   /**
+    * {@inheritDoc}
+    */
+   @Override
+   public void touchFile(String fileName) {
+      ensureOpen();
+      FileMetadata file = fileOps.getFileMetadata(fileName);
+      if (file == null) {
+         return;
+      }
+      else {
+         FileCacheKey key = new FileCacheKey(indexName, fileName);
+         file.touch();
+         metadataCache.put(key, file);
+      }
+   }
+
+   /**
+    * {@inheritDoc}
+    */
+   @Override
+   public void deleteFile(String name) {
+      ensureOpen();
+      fileOps.deleteFileName(name);
+      readLocks.deleteOrReleaseReadLock(name);
+      if (log.isDebugEnabled()) {
+         log.debugf(""Removed file: %s from index: %s"", name, indexName);
+      }
+   }
+
+   /**
+    * {@inheritDoc}
+    */
+   public void renameFile(String from, String to) {
+      ensureOpen();
+
+      final FileCacheKey fromKey = new FileCacheKey(indexName, from);
+      final FileMetadata metadata = (FileMetadata) metadataCache.get(fromKey);
+      final int bufferSize = metadata.getBufferSize();
+      // preparation: copy all chunks to new keys
+      int i = -1;
+      Object ob;
+      do {
+         ChunkCacheKey fromChunkKey = new ChunkCacheKey(indexName, from, ++i, bufferSize);
+         ob = chunksCache.get(fromChunkKey);
+         if (ob == null) {
+            break;
+         }
+         ChunkCacheKey toChunkKey = new ChunkCacheKey(indexName, to, i, bufferSize);
+         chunksCache.withFlags(Flag.IGNORE_RETURN_VALUES).put(toChunkKey, ob);
+      } while (true);
+
+      // rename metadata first
+
+      metadataCache.put(new FileCacheKey(indexName, to), metadata);
+      fileOps.removeAndAdd(from, to);
+      
+      // now trigger deletion of old file chunks:
+      readLocks.deleteOrReleaseReadLock(from);
+      if (log.isTraceEnabled()) {
+         log.tracef(""Renamed file from: %s to: %s in index %s"", from, to, indexName);
+      }
+   }
+
+   /**
+    * {@inheritDoc}
+    */
+   @Override
+   public long fileLength(String name) {
+      ensureOpen();
+      FileMetadata fileMetadata = fileOps.getFileMetadata(name);
+      if (fileMetadata == null) {
+         return 0L;//as in FSDirectory (RAMDirectory throws an exception instead)
+      }
+      else {
+         return fileMetadata.getSize();
+      }
+   }
+
+   /**
+    * {@inheritDoc}
+    */
+   @Override
+   public IndexOutput createOutput(String name) {
+      final FileCacheKey key = new FileCacheKey(indexName, name);
+      // creating new file, metadata is added on flush() or close() of IndexOutPut
+      return new InfinispanIndexOutput(metadataCache, chunksCache, key, chunkSize, fileOps);
+   }
+
+   /**
+    * {@inheritDoc}
+    */
+   @Override
+   public IndexInput openInput(String name) throws IOException {
+      final FileCacheKey fileKey = new FileCacheKey(indexName, name);
+      FileMetadata fileMetadata = (FileMetadata) metadataCache.get(fileKey);
+      if (fileMetadata == null) {
+         throw new FileNotFoundException(""Error loading metadata for index file: "" + fileKey);
+      }
+      else if (fileMetadata.getSize() <= fileMetadata.getBufferSize()) {
+         //files smaller than chunkSize don't need a readLock
+         IndexInputContext iic = new IndexInputContext(chunksCache, fileKey, fileMetadata, null);
+         return new SingleChunkIndexInput(iic);
+      }
+      else {
+         boolean locked = readLocks.acquireReadLock(name);
+         if (!locked) {
+            // safest reaction is to tell this file doesn't exist anymore.
+            throw new FileNotFoundException(""Error loading metadata for index file: "" + fileKey);
+         }
+         IndexInputContext iic = new IndexInputContext(chunksCache, fileKey, fileMetadata, readLocks);
+         return new InfinispanIndexInputV3(iic);
+      }
+   }
+
+   /**
+    * {@inheritDoc}
+    */
+   @Override
+   public void close() {
+      isOpen = false;
+   }
+
+   @Override
+   public String toString() {
+      return ""InfinispanDirectory{indexName=\'"" + indexName + ""\'}"";
+   }
+
+   /** new name for list() in Lucene 3.0 **/
+   @Override
+   public String[] listAll() {
+      return list();
+   }
+
+   /**
+    * @return The value of indexName, same constant as provided to the constructor.
+    */
+   public String getIndexName() {
+       return indexName;
+   }
+   
+   private static LockFactory makeDefaultLockFactory(Cache<?, ?> cache, String indexName) {
+      checkNotNull(cache, ""cache"");
+      checkNotNull(indexName, ""indexName"");
+      return new BaseLockFactory(cache, indexName);
+   }
+   
+   private static SegmentReadLocker makeDefaultSegmentReadLocker(Cache<?, ?> metadataCache, Cache<?, ?> chunksCache, Cache<?, ?> distLocksCache, String indexName) {
+      checkNotNull(distLocksCache, ""distLocksCache"");
+      checkNotNull(indexName, ""indexName"");
+      return new DistributedSegmentReadLocker((Cache<Object, Integer>) distLocksCache, chunksCache, metadataCache, indexName);
+   }
+   
+   private static void checkNotNull(Object v, String objectname) {
+      if (v == null)
+         throw new IllegalArgumentException(objectname + "" must not be null"");
+   }
+   
+}",2013-02-05T17:57:25Z,446
"@@ -17,19 +17,13 @@
  * MA  02110-1301, USA.
  */
 
-
-/**
- * @author Sanne Grinovero
- * @since 5.2
- */
 package org.infinispan.lucene.cachestore;
 
 import org.apache.lucene.store.Directory;
 import org.infinispan.lucene.impl.LuceneVersionDetector;
 import org.infinispan.lucene.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-
 /**
  * @since 5.2
  * @author Sanne Grinovero",2013-02-05T17:57:25Z,502
"@@ -26,14 +26,47 @@
 import org.apache.lucene.store.LockFactory;
 import org.infinispan.lucene.readlocks.SegmentReadLocker;
 
+/**
+ * Building context to set construction parameters of Infinispan Directory instances
+ *
+ * @since 5.2
+ * @author Sanne Grinovero
+ */
 public interface BuildContext {
 
-    Directory create();
+   /**
+    * Creates a Directory instance
+    * @see org.apache.lucene.store.Directory
+    * @return the new Directory
+    */
+   Directory create();
 
-    BuildContext chunkSize(int bytes);
+   /**
+    * Sets the chunkSize option for the Directory being created.
+    * 
+    * @param bytes segments are fragmented in chunkSize bytes; larger values are more efficient for searching but less for
+    *        distribution and network replication
+    * @return the same building context to eventually create the Directory instance
+    */
+   BuildContext chunkSize(int bytes);
 
-    BuildContext overrideSegmentReadLocker(SegmentReadLocker srl);
+   /**
+    * Overrides the default SegmentReadLocker. In some cases you might be able to provide more efficient implementations than
+    * the default one by controlling the IndexReader's lifecycle
+    * 
+    * @see org.infinispan.lucene.readlocks
+    * @param srl the new read locking strategy for fragmented segments
+    * @return the same building context to eventually create the Directory instance
+    */
+   BuildContext overrideSegmentReadLocker(SegmentReadLocker srl);
 
-    BuildContext overrideWriteLocker(LockFactory cache);
+   /**
+    * Overrides the IndexWriter LockFactory
+    * 
+    * @see org.infinispan.lucene.locking
+    * @param lf the LockFactory to be used by IndexWriters.
+    * @return the same building context to eventually create the Directory instance
+    */
+   BuildContext overrideWriteLocker(LockFactory lf);
 
 }",2013-02-05T17:57:25Z,503
"@@ -1,6 +1,6 @@
 /*
  * JBoss, Home of Professional Open Source
- * Copyright 2009 Red Hat Inc. and/or its affiliates and other
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
  * contributors as indicated by the @author tags. All rights reserved.
  * See the copyright.txt in the distribution for a full listing of
  * individual contributors.
@@ -37,12 +37,12 @@ private DirectoryBuilder() {
     }
 
     /**
-     * @param metadataCache the cache to be used for all smaller metadata: prefer replication over distribution, avoid eviction
-     * @param chunksCache the cache to use for the space consuming segments: prefer distribution, enable eviction if needed
-     * @param indexName the unique index name, useful to store multiple indexes in the same caches
-     * @param lf the LockFactory to be used by IndexWriters. @see org.infinispan.lucene.locking
-     * @param chunkSize segments are fragmented in chunkSize bytes; larger values are more efficient for searching but less for distribution and network replication
-     * @param readLocker @see org.infinispan.lucene.readlocks for some implementations; you might be able to provide more efficient implementations by controlling the IndexReader's lifecycle.
+     * Starting point to create a Directory instance.
+     * 
+     * @param metadataCache contains the metadata of stored elements
+     * @param chunksCache cache containing the bulk of the index; this is the larger part of data
+     * @param distLocksCache cache to store locks; should be replicated and not using a persistent CacheStore
+     * @param indexName identifies the index; you can store different indexes in the same set of caches using different identifiers
      */
     public static BuildContext newDirectoryInstance(Cache<?, ?> metadataCache, Cache<?, ?> chunksCache, Cache<?, ?> distLocksCache, String indexName) {
         return new DirectoryBuilderImpl(metadataCache, chunksCache, distLocksCache, indexName);",2013-02-05T17:57:25Z,504
"@@ -119,18 +119,18 @@ public BuildContext overrideWriteLocker(LockFactory lockFactory) {
       return this;
    }
 
-   static SegmentReadLocker makeDefaultSegmentReadLocker(Cache<?, ?> metadataCache, Cache<?, ?> chunksCache, Cache<?, ?> distLocksCache, String indexName) {
+   private static SegmentReadLocker makeDefaultSegmentReadLocker(Cache<?, ?> metadataCache, Cache<?, ?> chunksCache, Cache<?, ?> distLocksCache, String indexName) {
       checkNotNull(distLocksCache, ""distLocksCache"");
       checkNotNull(indexName, ""indexName"");
       return new DistributedSegmentReadLocker((Cache<Object, Integer>) distLocksCache, chunksCache, metadataCache, indexName);
    }
 
-   static void checkNotNull(Object v, String objectname) {
+   private static void checkNotNull(Object v, String objectname) {
       if (v == null)
          throw new IllegalArgumentException(objectname + "" must not be null"");
    }
 
-   static LockFactory makeDefaultLockFactory(Cache<?, ?> cache, String indexName) {
+   private static LockFactory makeDefaultLockFactory(Cache<?, ?> cache, String indexName) {
       checkNotNull(cache, ""cache"");
       checkNotNull(indexName, ""indexName"");
       return new BaseLockFactory(cache, indexName);",2013-02-05T17:57:25Z,505
"@@ -22,6 +22,12 @@
  */
 package org.infinispan.lucene.impl;
 
+/**
+ * Some additional methods we add to our Directory implementations,
+ * mostly for reporting and testing reasons.
+ * 
+ * @author Sanne Grinovero <sanne@hibernate.org> (C) 2013 Red Hat Inc.
+ */
 public interface DirectoryExtensions {
 
    public String getIndexName();",2013-02-05T17:57:25Z,506
"@@ -25,7 +25,6 @@
 
 import java.io.FileNotFoundException;
 import java.io.IOException;
-import java.util.Collection;
 import java.util.Set;
 
 import org.apache.lucene.store.IndexOutput;
@@ -88,7 +87,7 @@ boolean fileExists(final String name) {
      * Used by Lucene v3.x only
      */
     long fileModified(final String name) {
-       FileMetadata fileMetadata = fileOps.getFileMetadata(name);
+       final FileMetadata fileMetadata = fileOps.getFileMetadata(name);
        if (fileMetadata == null) {
           return 0L;
        }
@@ -101,12 +100,12 @@ long fileModified(final String name) {
      * Used by Lucene v3.x only
      */
     void touchFile(final String fileName) {
-       FileMetadata file = fileOps.getFileMetadata(fileName);
+       final FileMetadata file = fileOps.getFileMetadata(fileName);
        if (file == null) {
           return;
        }
        else {
-          FileCacheKey key = new FileCacheKey(indexName, fileName);
+          final FileCacheKey key = new FileCacheKey(indexName, fileName);
           file.touch();
           metadataCache.put(key, file);
        }
@@ -128,12 +127,12 @@ void renameFile(final String from, final String to) {
        int i = -1;
        Object ob;
        do {
-          ChunkCacheKey fromChunkKey = new ChunkCacheKey(indexName, from, ++i, bufferSize);
+          final ChunkCacheKey fromChunkKey = new ChunkCacheKey(indexName, from, ++i, bufferSize);
           ob = chunksCache.get(fromChunkKey);
           if (ob == null) {
              break;
           }
-          ChunkCacheKey toChunkKey = new ChunkCacheKey(indexName, to, i, bufferSize);
+          final ChunkCacheKey toChunkKey = new ChunkCacheKey(indexName, to, i, bufferSize);
           chunksCache.withFlags(Flag.IGNORE_RETURN_VALUES).put(toChunkKey, ob);
        } while (true);
 
@@ -150,7 +149,7 @@ void renameFile(final String from, final String to) {
     }
 
     long fileLength(final String name) {
-       FileMetadata fileMetadata = fileOps.getFileMetadata(name);
+       final FileMetadata fileMetadata = fileOps.getFileMetadata(name);
        if (fileMetadata == null) {
           return 0L; //as in FSDirectory (RAMDirectory throws an exception instead)
        }
@@ -167,7 +166,7 @@ IndexOutput createOutput(final String name) {
 
     IndexInputContext openInput(final String name) throws IOException {
        final FileCacheKey fileKey = new FileCacheKey(indexName, name);
-       FileMetadata fileMetadata = (FileMetadata) metadataCache.get(fileKey);
+       final FileMetadata fileMetadata = (FileMetadata) metadataCache.get(fileKey);
        if (fileMetadata == null) {
           throw new FileNotFoundException(""Error loading metadata for index file: "" + fileKey);
        }
@@ -192,13 +191,6 @@ public String getIndexName() {
         return indexName;
     }
 
-    /**
-     * Used by Lucene v4.x only
-     */
-    void sync(final Collection<String> names) throws IOException {
-       //This implementation is always in sync with the storage, so NOOP is fine
-    }
-
     @Override
     public String toString() {
        return ""DirectoryImplementor{indexName=\'"" + indexName + ""\'}"";",2013-02-05T17:57:25Z,507
"@@ -41,7 +41,7 @@
  * @since 4.1
  */
 @SuppressWarnings(""unchecked"")
-final class FileListOperations {
+public final class FileListOperations {
 
    private static final Log log = LogFactory.getLog(InfinispanIndexOutput.class);
    private static final boolean trace = log.isTraceEnabled();
@@ -51,7 +51,7 @@ final class FileListOperations {
    private final String indexName;
    private final AdvancedCache<FileListCacheKey, Set<String>> cacheNoRetrieve;
 
-   FileListOperations(AdvancedCache<?, ?> cache, String indexName){
+   public FileListOperations(AdvancedCache<?, ?> cache, String indexName){
       this.cache = (AdvancedCache<FileListCacheKey, Object>) cache.withFlags(Flag.SKIP_INDEXING);
       this.cacheNoRetrieve = (AdvancedCache<FileListCacheKey, Set<String>>)
             cache.withFlags(Flag.IGNORE_RETURN_VALUES, Flag.SKIP_INDEXING);
@@ -62,7 +62,7 @@ final class FileListOperations {
    /**
     * @return the current list of files being part of the index 
     */
-   Set<String> getFileList() {
+   public Set<String> getFileList() {
       Set<String> fileList = (Set<String>) cache.get(fileListCacheKey);
       if (fileList == null) {
          fileList = new ConcurrentHashSet<String>();
@@ -80,7 +80,7 @@ Set<String> getFileList() {
     * Deleted a file from the list of files actively part of the index
     * @param fileName
     */
-   void deleteFileName(String fileName) {
+   public void deleteFileName(String fileName) {
       Set<String> fileList = getFileList();
       boolean done = fileList.remove(fileName);
       if (done) {
@@ -108,7 +108,7 @@ void addFileName(String fileName) {
     * @param fileName
     * @return the FileMetadata associated with the fileName, or null if the file wasn't found.
     */
-   FileMetadata getFileMetadata(String fileName) {
+   public FileMetadata getFileMetadata(String fileName) {
       FileCacheKey key = new FileCacheKey(indexName, fileName);
       FileMetadata metadata = (FileMetadata) cache.get(key);
       return metadata;
@@ -119,7 +119,7 @@ FileMetadata getFileMetadata(String fileName) {
     * @param toRemove
     * @param toAdd
     */
-   void removeAndAdd(String toRemove, String toAdd) {
+   public void removeAndAdd(String toRemove, String toAdd) {
       Set<String> fileList = getFileList();
       boolean doneAdd = fileList.add(toAdd);
       boolean doneRemove = fileList.remove(toRemove);",2013-02-05T17:57:25Z,508
"@@ -29,14 +29,14 @@
 import org.infinispan.lucene.FileMetadata;
 import org.infinispan.lucene.readlocks.SegmentReadLocker;
 
-final class IndexInputContext {
+public final class IndexInputContext {
 
    final AdvancedCache<ChunkCacheKey, Object> chunksCache;
    final FileCacheKey fileKey;
    final FileMetadata fileMetadata;
    final SegmentReadLocker readLocks;
 
-   IndexInputContext(AdvancedCache<ChunkCacheKey, Object> chunksCache, FileCacheKey fileKey, FileMetadata fileMetadata,
+   public IndexInputContext(AdvancedCache<ChunkCacheKey, Object> chunksCache, FileCacheKey fileKey, FileMetadata fileMetadata,
          SegmentReadLocker readLocks) {
             this.chunksCache = chunksCache;
             this.fileKey = fileKey;",2013-02-05T17:57:25Z,509
"@@ -41,7 +41,6 @@
  * @see org.apache.lucene.store.Directory
  * @see org.apache.lucene.store.IndexInput
  */
-@SuppressWarnings(""unchecked"")
 abstract class InfinispanIndexInput extends IndexInput {
 
    private static final Log log = LogFactory.getLog(InfinispanIndexInput.class);",2013-02-05T17:57:25Z,451
"@@ -25,6 +25,11 @@
 import org.infinispan.lucene.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+
+/**
+ * @since 5.2
+ * @author Sanne Grinovero
+ */
 public class LuceneVersionDetector {
 
    public static final int VERSION = detectVersion();",2013-02-05T17:57:25Z,510
"@@ -57,7 +57,7 @@ public class ActivationManagerImpl implements ActivationManager {
    private Configuration cfg;
    private boolean enabled;
 
-   @ManagedAttribute(description = ""Enables or disables the gathering of statistics by this component"", writable = true)
+   @ManagedAttribute(description = ""Enables or disables the gathering of statistics by this component"", displayName = ""Statistics enabled"", writable = true)
    private boolean statisticsEnabled = false;
 
    @Inject",2013-02-27T16:53:58Z,511
"@@ -353,20 +353,21 @@ public long getReplicationFailures() {
       return replicationFailures.get();
    }
 
-   @ManagedAttribute(description = ""Statistics enabled"", dataType = DataType.TRAIT, writable = true)
+   @ManagedAttribute(description = ""Statistics enabled"", displayName = ""Statistics enabled"", dataType = DataType.TRAIT, writable = true)
    public boolean isStatisticsEnabled() {
       return statisticsEnabled;
    }
 
    /**
     * @deprecated We already have an attribute, we shouldn't have an operation for the same thing.
     */
+   @Deprecated
    @ManagedOperation(displayName = ""Enable/disable statistics. Deprecated, use the statisticsEnabled attribute instead."")
    public void setStatisticsEnabled(@Parameter(name = ""enabled"", description = ""Whether statistics should be enabled or disabled (true/false)"") boolean statisticsEnabled) {
       this.statisticsEnabled = statisticsEnabled;
    }
 
-   @ManagedAttribute(description = ""Successful replications as a ratio of total replications"")
+   @ManagedAttribute(description = ""Successful replications as a ratio of total replications"", displayName = ""Successful replications ratio"")
    public String getSuccessRatio() {
       if (replicationCount.get() == 0 || !statisticsEnabled) {
          return ""N/A"";",2013-02-27T16:53:58Z,105
"@@ -56,7 +56,7 @@ public void init(RecoveryManager recoveryManager) {
       this.recoveryManager = recoveryManager;
    }
 
-   @ManagedOperation(description = ""Shows all the prepared transactions for which the originating node crashed"")
+   @ManagedOperation(description = ""Shows all the prepared transactions for which the originating node crashed"", displayName=""Show in doubt transactions"")
    public String showInDoubtTransactions() {
       Set<RecoveryManager.InDoubtTxInfo> info = getRecoveryInfoFromCluster();
       if (log.isTraceEnabled()) {
@@ -82,35 +82,35 @@ public String showInDoubtTransactions() {
       return result.toString();
    }
 
-   @ManagedOperation(description = ""Forces the commit of an in-doubt transaction"")
+   @ManagedOperation(description = ""Forces the commit of an in-doubt transaction"", displayName=""Force commit by internal id"")
    public String forceCommit(@Parameter(name = ""internalId"", description = ""The internal identifier of the transaction"") long internalId) {
       if (log.isTraceEnabled())
          log.tracef(""Forces the commit of an in-doubt transaction: %s"", internalId);
       return completeBasedOnInternalId(internalId, true);
    }
 
-   @ManagedOperation(description = ""Forces the commit of an in-doubt transaction"", name=""forceCommitByXid"")
+   @ManagedOperation(description = ""Forces the commit of an in-doubt transaction"", displayName=""Force commit by Xid"", name=""forceCommitByXid"")
    public String forceCommit(
          @Parameter(name = ""formatId"", description = ""The formatId of the transaction"") int formatId,
          @Parameter(name = ""globalTxId"", description = ""The globalTxId of the transaction"") byte[] globalTxId,
          @Parameter(name = ""branchQualifier"", description = ""The branchQualifier of the transaction"") byte[] branchQualifier) {
       return completeBasedOnXid(formatId, globalTxId, branchQualifier, true);
    }
 
-   @ManagedOperation(description = ""Forces the rollback of an in-doubt transaction"")
+   @ManagedOperation(description = ""Forces the rollback of an in-doubt transaction"", displayName=""Force rollback by internal id"")
    public String forceRollback(@Parameter(name = ""internalId"", description = ""The internal identifier of the transaction"") long internalId) {
       return completeBasedOnInternalId(internalId, false);
    }
 
-   @ManagedOperation(description = ""Forces the rollback of an in-doubt transaction"", name=""forceRollbackByXid"")
+   @ManagedOperation(description = ""Forces the rollback of an in-doubt transaction"", displayName=""Force rollback by Xid"", name=""forceRollbackByXid"")
    public String forceRollback(
          @Parameter(name = ""formatId"", description = ""The formatId of the transaction"") int formatId,
          @Parameter(name = ""globalTxId"", description = ""The globalTxId of the transaction"") byte[] globalTxId,
          @Parameter(name = ""branchQualifier"", description = ""The branchQualifier of the transaction"") byte[] branchQualifier) {
       return completeBasedOnXid(formatId, globalTxId, branchQualifier, false);
    }
 
-   @ManagedOperation(description = ""Removes recovery info for the given transaction."", name=""forgetByXid"")
+   @ManagedOperation(description = ""Removes recovery info for the given transaction."", displayName=""Remove recovery info by Xid"", name=""forgetByXid"")
    public String forget(
          @Parameter(name = ""formatId"", description = ""The formatId of the transaction"") int formatId,
          @Parameter(name = ""globalTxId"", description = ""The globalTxId of the transaction"") byte[] globalTxId,
@@ -119,7 +119,7 @@ public String forget(
       return ""Recovery info removed."";
    }
 
-   @ManagedOperation(description = ""Removes recovery info for the given transaction."")
+   @ManagedOperation(description = ""Removes recovery info for the given transaction."", displayName=""Remove recovery info by internal id"")
    public String forget(@Parameter(name = ""internalId"", description = ""The internal identifier of the transaction"") long internalId) {
       recoveryManager.removeRecoveryInformationFromCluster(null, internalId, true);
       return ""Recovery info removed."";",2013-02-27T16:53:58Z,512
"@@ -26,6 +26,7 @@
 import org.apache.commons.logging.LogFactory;
 import org.mc4j.ems.connection.EmsConnection;
 import org.mc4j.ems.connection.bean.EmsBean;
+import org.mc4j.ems.connection.bean.EmsBeanName;
 import org.mc4j.ems.connection.bean.attribute.EmsAttribute;
 import org.mc4j.ems.connection.bean.operation.EmsOperation;
 import org.rhq.core.domain.configuration.Configuration;
@@ -219,16 +220,19 @@ private EmsBean queryBean(String componentName) {
       if (log.isTraceEnabled()) log.trace(""Pattern to query is "" + pattern);
       ObjectNameQueryUtility queryUtility = new ObjectNameQueryUtility(pattern);
       List<EmsBean> beans = conn.queryBeans(queryUtility.getTranslatedQuery());
-      if (beans.size() > 1) {
-         // If more than one are returned, most likely is due to duplicate domains which is not the general case
-         if(log.isWarnEnabled()) {
-            log.warn(String.format(""More than one bean returned from applying %s pattern: %s"", pattern, beans));
+      for (EmsBean bean : beans) {
+         if (isCacheComponent(bean)) {
+            return bean;
+         } else {
+            log.warn(String.format(""MBeanServer returned spurious object %s"", bean.getBeanName().getCanonicalName()));
          }
       }
-      EmsBean bean = beans.size() > 0 ? beans.get(0) : null;
-      if (bean == null) {
-         if (log.isTraceEnabled()) log.trace(""No mbean found with name "" + pattern);
-      }
-      return bean;
+      if (log.isTraceEnabled()) log.trace(""No mbean found with name "" + pattern);
+      return null;
+   }
+
+   protected static boolean isCacheComponent(EmsBean bean) {
+      EmsBeanName beanName = bean.getBeanName();
+      return ""Cache"".equals(beanName.getKeyProperty(""type"")) && ""Cache"".equals(beanName.getKeyProperty(""component""));
    }
 }",2013-02-27T16:53:58Z,513
"@@ -63,25 +63,30 @@ public Set<DiscoveredResourceDetails> discoverResources(ResourceDiscoveryContext
       if (trace) log.trace(""Querying ""+queryUtility.getTranslatedQuery()+"" returned beans: "" + beans);
 
       for (EmsBean bean : beans) {
-         /* A discovered resource must have a unique key, that must
-          * stay the same when the resource is discovered the next
-          * time */
-         String name = bean.getAttribute(""CacheName"").getValue().toString();
-         String mbeanCacheName = bean.getBeanName().getKeyProperty(""name"");
-         if (trace) log.trace(""Resource name is ""+name+"" and resource key ""+ mbeanCacheName);
-         DiscoveredResourceDetails detail = new DiscoveredResourceDetails(
-               ctx.getResourceType(), // Resource Type
-               mbeanCacheName, // Resource Key
-               name, // Resource name
-               null, // Version
-               ""One cache within Infinispan"", // ResourceDescription
-               ctx.getDefaultPluginConfiguration(), // Plugin Config
-               null // ProcessInfo
-         );
+         // Filter out spurious beans
+         if (CacheComponent.isCacheComponent(bean)) {
+            /* A discovered resource must have a unique key, that must
+             * stay the same when the resource is discovered the next
+             * time */
+            String name = bean.getAttribute(""CacheName"").getValue().toString();
+            String mbeanCacheName = bean.getBeanName().getKeyProperty(""name"");
+            if (trace) log.trace(""Resource name is ""+name+"" and resource key ""+ mbeanCacheName);
+            DiscoveredResourceDetails detail = new DiscoveredResourceDetails(
+                  ctx.getResourceType(), // Resource Type
+                  mbeanCacheName, // Resource Key
+                  name, // Resource name
+                  null, // Version
+                  ""One cache within Infinispan"", // ResourceDescription
+                  ctx.getDefaultPluginConfiguration(), // Plugin Config
+                  null // ProcessInfo
+            );
 
-         // Add to return values
-         discoveredResources.add(detail);
-         log.info(""Discovered new ...  "" + bean.getBeanName().getCanonicalName());
+            // Add to return values
+            discoveredResources.add(detail);
+            log.info(""Discovered new ...  "" + bean.getBeanName().getCanonicalName());
+         } else {
+            log.warn(String.format(""MBeanServer returned spurious object %s"", bean.getBeanName().getCanonicalName()));
+         }
       }
       return discoveredResources;
    }",2013-02-27T16:53:58Z,514
"@@ -33,6 +33,7 @@
 import org.apache.commons.logging.LogFactory;
 import org.mc4j.ems.connection.EmsConnection;
 import org.mc4j.ems.connection.bean.EmsBean;
+import org.mc4j.ems.connection.bean.EmsBeanName;
 import org.mc4j.ems.connection.bean.attribute.EmsAttribute;
 import org.rhq.core.domain.measurement.AvailabilityType;
 import org.rhq.core.domain.measurement.DataType;
@@ -134,12 +135,18 @@ private EmsBean queryCacheManagerBean(EmsConnection conn) {
       if (log.isTraceEnabled()) log.trace(""Pattern to query is "" + pattern);
       ObjectNameQueryUtility queryUtility = new ObjectNameQueryUtility(pattern);
       List<EmsBean> beans = conn.queryBeans(queryUtility.getTranslatedQuery());
-      if (beans.size() > 1) {
-         // If more than one are returned, most likely is due to duplicate domains which is not the general case
-         if(log.isWarnEnabled()) {
-            log.warn(String.format(""More than one bean returned from applying %s pattern: %s"", pattern, beans));
+      for(EmsBean bean : beans) {
+         if (isCacheManagerComponent(bean)) {
+            return bean;
+         } else {
+            log.warn(String.format(""MBeanServer returned spurious object %s"", bean.getBeanName().getCanonicalName()));
          }
       }
-      return beans.get(0);
+      throw new IllegalStateException(""MBeanServer unexpectedly did not return any CacheManager components"");
+   }
+
+   protected static boolean isCacheManagerComponent(EmsBean bean) {
+      EmsBeanName beanName = bean.getBeanName();
+      return ""CacheManager"".equals(beanName.getKeyProperty(""type"")) && ""CacheManager"".equals(beanName.getKeyProperty(""component""));
    }
 }",2013-02-27T16:53:58Z,515
"@@ -79,24 +79,29 @@ private Set<DiscoveredResourceDetails> createDiscoveredResource(ResourceDiscover
 
          Set<DiscoveredResourceDetails> discoveredResources = new HashSet<DiscoveredResourceDetails>();
          for (EmsBean bean : beans) {
-            String managerName = bean.getBeanName().getCanonicalName();
-            String resourceName = bean.getAttribute(""Name"").getValue().toString();
-            String version = bean.getAttribute(""Version"").getValue().toString();
-            /* A discovered resource must have a unique key, that must stay the same when the resource is discovered the next time */
-            if (trace) log.trace(""Add resource with version '""+version+""' and type "" + ctx.getResourceType());
-            DiscoveredResourceDetails detail = new DiscoveredResourceDetails(
-                  ctx.getResourceType(), // Resource type
-                  resourceName, // Resource key
-                  resourceName, // Resource name
-                  version, // Resource version
-                  ""A cache manager within Infinispan"", // Description
-                  pluginConfiguration, // Plugin config
-                  null // Process info from a process scan
-            );
-            if(log.isInfoEnabled()) {
-               log.info(String.format(""Discovered Infinispan instance with key %s and name %s"", resourceName, managerName));
+            // Filter out spurious beans
+            if (CacheManagerComponent.isCacheManagerComponent(bean)) {
+               String managerName = bean.getBeanName().getCanonicalName();
+               String resourceName = bean.getAttribute(""Name"").getValue().toString();
+               String version = bean.getAttribute(""Version"").getValue().toString();
+               /* A discovered resource must have a unique key, that must stay the same when the resource is discovered the next time */
+               if (trace) log.trace(""Add resource with version '""+version+""' and type "" + ctx.getResourceType());
+               DiscoveredResourceDetails detail = new DiscoveredResourceDetails(
+                     ctx.getResourceType(), // Resource type
+                     resourceName, // Resource key
+                     resourceName, // Resource name
+                     version, // Resource version
+                     ""A cache manager within Infinispan"", // Description
+                     pluginConfiguration, // Plugin config
+                     null // Process info from a process scan
+               );
+               if(log.isInfoEnabled()) {
+                  log.info(String.format(""Discovered Infinispan instance with key %s and name %s"", resourceName, managerName));
+               }
+               discoveredResources.add(detail);
+            } else {
+               log.warn(String.format(""MBeanServer returned spurious object %s"", bean.getBeanName().getCanonicalName()));
             }
-            discoveredResources.add(detail);
          }
          return discoveredResources;
       } else {",2013-02-27T16:53:58Z,516
"@@ -149,7 +149,11 @@ private static void populateMetricsAndOperations(List<Class<?>> classes, Element
             if (managedAttr != null) {
                String property = prefix + getPropertyFromBeanConvention(ctMethod);
 
-               String displayName = withNamePrefix ? ""["" + mbean.objectName() + ""] "" + managedAttr.displayName() : managedAttr.displayName();
+               String attrDisplayName = managedAttr.displayName();
+               if (attrDisplayName.length() == 0) {
+                  throw new RuntimeException(""Missing displayName on: "" + property);
+               }
+               String displayName = withNamePrefix ? ""["" + mbean.objectName() + ""] "" + attrDisplayName : attrDisplayName;
                validateDisplayName(displayName);
 
                Element metric = doc.createElement(""metric"");
@@ -175,7 +179,11 @@ private static void populateMetricsAndOperations(List<Class<?>> classes, Element
                }
                uniqueOperations.add(name);
 
-               String displayName = withNamePrefix ? ""["" + mbean.objectName() + ""] "" + managedOp.displayName() : managedOp.displayName();
+               String opDisplayName = managedOp.displayName();
+               if (opDisplayName.length() == 0) {
+                  throw new RuntimeException(""Missing displayName on: "" + name);
+               }
+               String displayName = withNamePrefix ? ""["" + mbean.objectName() + ""] "" + opDisplayName : opDisplayName;
                validateDisplayName(displayName);
 
                Element operation = doc.createElement(""operation"");",2013-02-27T16:53:58Z,517
"@@ -57,7 +57,7 @@ public class ActivationManagerImpl implements ActivationManager {
    private Configuration cfg;
    private boolean enabled;
 
-   @ManagedAttribute(description = ""Enables or disables the gathering of statistics by this component"", writable = true)
+   @ManagedAttribute(description = ""Enables or disables the gathering of statistics by this component"", displayName = ""Statistics enabled"", writable = true)
    private boolean statisticsEnabled = false;
 
    @Inject",2013-02-27T16:53:58Z,511
"@@ -353,20 +353,21 @@ public long getReplicationFailures() {
       return replicationFailures.get();
    }
 
-   @ManagedAttribute(description = ""Statistics enabled"", dataType = DataType.TRAIT, writable = true)
+   @ManagedAttribute(description = ""Statistics enabled"", displayName = ""Statistics enabled"", dataType = DataType.TRAIT, writable = true)
    public boolean isStatisticsEnabled() {
       return statisticsEnabled;
    }
 
    /**
     * @deprecated We already have an attribute, we shouldn't have an operation for the same thing.
     */
+   @Deprecated
    @ManagedOperation(displayName = ""Enable/disable statistics. Deprecated, use the statisticsEnabled attribute instead."")
    public void setStatisticsEnabled(@Parameter(name = ""enabled"", description = ""Whether statistics should be enabled or disabled (true/false)"") boolean statisticsEnabled) {
       this.statisticsEnabled = statisticsEnabled;
    }
 
-   @ManagedAttribute(description = ""Successful replications as a ratio of total replications"")
+   @ManagedAttribute(description = ""Successful replications as a ratio of total replications"", displayName = ""Successful replications ratio"")
    public String getSuccessRatio() {
       if (replicationCount.get() == 0 || !statisticsEnabled) {
          return ""N/A"";",2013-02-27T16:53:58Z,105
"@@ -56,7 +56,7 @@ public void init(RecoveryManager recoveryManager) {
       this.recoveryManager = recoveryManager;
    }
 
-   @ManagedOperation(description = ""Shows all the prepared transactions for which the originating node crashed"")
+   @ManagedOperation(description = ""Shows all the prepared transactions for which the originating node crashed"", displayName=""Show in doubt transactions"")
    public String showInDoubtTransactions() {
       Set<RecoveryManager.InDoubtTxInfo> info = getRecoveryInfoFromCluster();
       if (log.isTraceEnabled()) {
@@ -82,35 +82,35 @@ public String showInDoubtTransactions() {
       return result.toString();
    }
 
-   @ManagedOperation(description = ""Forces the commit of an in-doubt transaction"")
+   @ManagedOperation(description = ""Forces the commit of an in-doubt transaction"", displayName=""Force commit by internal id"")
    public String forceCommit(@Parameter(name = ""internalId"", description = ""The internal identifier of the transaction"") long internalId) {
       if (log.isTraceEnabled())
          log.tracef(""Forces the commit of an in-doubt transaction: %s"", internalId);
       return completeBasedOnInternalId(internalId, true);
    }
 
-   @ManagedOperation(description = ""Forces the commit of an in-doubt transaction"", name=""forceCommitByXid"")
+   @ManagedOperation(description = ""Forces the commit of an in-doubt transaction"", displayName=""Force commit by Xid"", name=""forceCommitByXid"")
    public String forceCommit(
          @Parameter(name = ""formatId"", description = ""The formatId of the transaction"") int formatId,
          @Parameter(name = ""globalTxId"", description = ""The globalTxId of the transaction"") byte[] globalTxId,
          @Parameter(name = ""branchQualifier"", description = ""The branchQualifier of the transaction"") byte[] branchQualifier) {
       return completeBasedOnXid(formatId, globalTxId, branchQualifier, true);
    }
 
-   @ManagedOperation(description = ""Forces the rollback of an in-doubt transaction"")
+   @ManagedOperation(description = ""Forces the rollback of an in-doubt transaction"", displayName=""Force rollback by internal id"")
    public String forceRollback(@Parameter(name = ""internalId"", description = ""The internal identifier of the transaction"") long internalId) {
       return completeBasedOnInternalId(internalId, false);
    }
 
-   @ManagedOperation(description = ""Forces the rollback of an in-doubt transaction"", name=""forceRollbackByXid"")
+   @ManagedOperation(description = ""Forces the rollback of an in-doubt transaction"", displayName=""Force rollback by Xid"", name=""forceRollbackByXid"")
    public String forceRollback(
          @Parameter(name = ""formatId"", description = ""The formatId of the transaction"") int formatId,
          @Parameter(name = ""globalTxId"", description = ""The globalTxId of the transaction"") byte[] globalTxId,
          @Parameter(name = ""branchQualifier"", description = ""The branchQualifier of the transaction"") byte[] branchQualifier) {
       return completeBasedOnXid(formatId, globalTxId, branchQualifier, false);
    }
 
-   @ManagedOperation(description = ""Removes recovery info for the given transaction."", name=""forgetByXid"")
+   @ManagedOperation(description = ""Removes recovery info for the given transaction."", displayName=""Remove recovery info by Xid"", name=""forgetByXid"")
    public String forget(
          @Parameter(name = ""formatId"", description = ""The formatId of the transaction"") int formatId,
          @Parameter(name = ""globalTxId"", description = ""The globalTxId of the transaction"") byte[] globalTxId,
@@ -119,7 +119,7 @@ public String forget(
       return ""Recovery info removed."";
    }
 
-   @ManagedOperation(description = ""Removes recovery info for the given transaction."")
+   @ManagedOperation(description = ""Removes recovery info for the given transaction."", displayName=""Remove recovery info by internal id"")
    public String forget(@Parameter(name = ""internalId"", description = ""The internal identifier of the transaction"") long internalId) {
       recoveryManager.removeRecoveryInformationFromCluster(null, internalId, true);
       return ""Recovery info removed."";",2013-02-27T16:53:58Z,512
"@@ -26,6 +26,7 @@
 import org.apache.commons.logging.LogFactory;
 import org.mc4j.ems.connection.EmsConnection;
 import org.mc4j.ems.connection.bean.EmsBean;
+import org.mc4j.ems.connection.bean.EmsBeanName;
 import org.mc4j.ems.connection.bean.attribute.EmsAttribute;
 import org.mc4j.ems.connection.bean.operation.EmsOperation;
 import org.rhq.core.domain.configuration.Configuration;
@@ -219,16 +220,19 @@ private EmsBean queryBean(String componentName) {
       if (log.isTraceEnabled()) log.trace(""Pattern to query is "" + pattern);
       ObjectNameQueryUtility queryUtility = new ObjectNameQueryUtility(pattern);
       List<EmsBean> beans = conn.queryBeans(queryUtility.getTranslatedQuery());
-      if (beans.size() > 1) {
-         // If more than one are returned, most likely is due to duplicate domains which is not the general case
-         if(log.isWarnEnabled()) {
-            log.warn(String.format(""More than one bean returned from applying %s pattern: %s"", pattern, beans));
+      for (EmsBean bean : beans) {
+         if (isCacheComponent(bean)) {
+            return bean;
+         } else {
+            log.warn(String.format(""MBeanServer returned spurious object %s"", bean.getBeanName().getCanonicalName()));
          }
       }
-      EmsBean bean = beans.size() > 0 ? beans.get(0) : null;
-      if (bean == null) {
-         if (log.isTraceEnabled()) log.trace(""No mbean found with name "" + pattern);
-      }
-      return bean;
+      if (log.isTraceEnabled()) log.trace(""No mbean found with name "" + pattern);
+      return null;
+   }
+
+   protected static boolean isCacheComponent(EmsBean bean) {
+      EmsBeanName beanName = bean.getBeanName();
+      return ""Cache"".equals(beanName.getKeyProperty(""type"")) && ""Cache"".equals(beanName.getKeyProperty(""component""));
    }
 }",2013-02-27T16:53:58Z,513
"@@ -63,25 +63,30 @@ public Set<DiscoveredResourceDetails> discoverResources(ResourceDiscoveryContext
       if (trace) log.trace(""Querying ""+queryUtility.getTranslatedQuery()+"" returned beans: "" + beans);
 
       for (EmsBean bean : beans) {
-         /* A discovered resource must have a unique key, that must
-          * stay the same when the resource is discovered the next
-          * time */
-         String name = bean.getAttribute(""CacheName"").getValue().toString();
-         String mbeanCacheName = bean.getBeanName().getKeyProperty(""name"");
-         if (trace) log.trace(""Resource name is ""+name+"" and resource key ""+ mbeanCacheName);
-         DiscoveredResourceDetails detail = new DiscoveredResourceDetails(
-               ctx.getResourceType(), // Resource Type
-               mbeanCacheName, // Resource Key
-               name, // Resource name
-               null, // Version
-               ""One cache within Infinispan"", // ResourceDescription
-               ctx.getDefaultPluginConfiguration(), // Plugin Config
-               null // ProcessInfo
-         );
+         // Filter out spurious beans
+         if (CacheComponent.isCacheComponent(bean)) {
+            /* A discovered resource must have a unique key, that must
+             * stay the same when the resource is discovered the next
+             * time */
+            String name = bean.getAttribute(""CacheName"").getValue().toString();
+            String mbeanCacheName = bean.getBeanName().getKeyProperty(""name"");
+            if (trace) log.trace(""Resource name is ""+name+"" and resource key ""+ mbeanCacheName);
+            DiscoveredResourceDetails detail = new DiscoveredResourceDetails(
+                  ctx.getResourceType(), // Resource Type
+                  mbeanCacheName, // Resource Key
+                  name, // Resource name
+                  null, // Version
+                  ""One cache within Infinispan"", // ResourceDescription
+                  ctx.getDefaultPluginConfiguration(), // Plugin Config
+                  null // ProcessInfo
+            );
 
-         // Add to return values
-         discoveredResources.add(detail);
-         log.info(""Discovered new ...  "" + bean.getBeanName().getCanonicalName());
+            // Add to return values
+            discoveredResources.add(detail);
+            log.info(""Discovered new ...  "" + bean.getBeanName().getCanonicalName());
+         } else {
+            log.warn(String.format(""MBeanServer returned spurious object %s"", bean.getBeanName().getCanonicalName()));
+         }
       }
       return discoveredResources;
    }",2013-02-27T16:53:58Z,514
"@@ -33,6 +33,7 @@
 import org.apache.commons.logging.LogFactory;
 import org.mc4j.ems.connection.EmsConnection;
 import org.mc4j.ems.connection.bean.EmsBean;
+import org.mc4j.ems.connection.bean.EmsBeanName;
 import org.mc4j.ems.connection.bean.attribute.EmsAttribute;
 import org.rhq.core.domain.measurement.AvailabilityType;
 import org.rhq.core.domain.measurement.DataType;
@@ -134,12 +135,18 @@ private EmsBean queryCacheManagerBean(EmsConnection conn) {
       if (log.isTraceEnabled()) log.trace(""Pattern to query is "" + pattern);
       ObjectNameQueryUtility queryUtility = new ObjectNameQueryUtility(pattern);
       List<EmsBean> beans = conn.queryBeans(queryUtility.getTranslatedQuery());
-      if (beans.size() > 1) {
-         // If more than one are returned, most likely is due to duplicate domains which is not the general case
-         if(log.isWarnEnabled()) {
-            log.warn(String.format(""More than one bean returned from applying %s pattern: %s"", pattern, beans));
+      for(EmsBean bean : beans) {
+         if (isCacheManagerComponent(bean)) {
+            return bean;
+         } else {
+            log.warn(String.format(""MBeanServer returned spurious object %s"", bean.getBeanName().getCanonicalName()));
          }
       }
-      return beans.get(0);
+      throw new IllegalStateException(""MBeanServer unexpectedly did not return any CacheManager components"");
+   }
+
+   protected static boolean isCacheManagerComponent(EmsBean bean) {
+      EmsBeanName beanName = bean.getBeanName();
+      return ""CacheManager"".equals(beanName.getKeyProperty(""type"")) && ""CacheManager"".equals(beanName.getKeyProperty(""component""));
    }
 }",2013-02-27T16:53:58Z,515
"@@ -79,24 +79,29 @@ private Set<DiscoveredResourceDetails> createDiscoveredResource(ResourceDiscover
 
          Set<DiscoveredResourceDetails> discoveredResources = new HashSet<DiscoveredResourceDetails>();
          for (EmsBean bean : beans) {
-            String managerName = bean.getBeanName().getCanonicalName();
-            String resourceName = bean.getAttribute(""Name"").getValue().toString();
-            String version = bean.getAttribute(""Version"").getValue().toString();
-            /* A discovered resource must have a unique key, that must stay the same when the resource is discovered the next time */
-            if (trace) log.trace(""Add resource with version '""+version+""' and type "" + ctx.getResourceType());
-            DiscoveredResourceDetails detail = new DiscoveredResourceDetails(
-                  ctx.getResourceType(), // Resource type
-                  resourceName, // Resource key
-                  resourceName, // Resource name
-                  version, // Resource version
-                  ""A cache manager within Infinispan"", // Description
-                  pluginConfiguration, // Plugin config
-                  null // Process info from a process scan
-            );
-            if(log.isInfoEnabled()) {
-               log.info(String.format(""Discovered Infinispan instance with key %s and name %s"", resourceName, managerName));
+            // Filter out spurious beans
+            if (CacheManagerComponent.isCacheManagerComponent(bean)) {
+               String managerName = bean.getBeanName().getCanonicalName();
+               String resourceName = bean.getAttribute(""Name"").getValue().toString();
+               String version = bean.getAttribute(""Version"").getValue().toString();
+               /* A discovered resource must have a unique key, that must stay the same when the resource is discovered the next time */
+               if (trace) log.trace(""Add resource with version '""+version+""' and type "" + ctx.getResourceType());
+               DiscoveredResourceDetails detail = new DiscoveredResourceDetails(
+                     ctx.getResourceType(), // Resource type
+                     resourceName, // Resource key
+                     resourceName, // Resource name
+                     version, // Resource version
+                     ""A cache manager within Infinispan"", // Description
+                     pluginConfiguration, // Plugin config
+                     null // Process info from a process scan
+               );
+               if(log.isInfoEnabled()) {
+                  log.info(String.format(""Discovered Infinispan instance with key %s and name %s"", resourceName, managerName));
+               }
+               discoveredResources.add(detail);
+            } else {
+               log.warn(String.format(""MBeanServer returned spurious object %s"", bean.getBeanName().getCanonicalName()));
             }
-            discoveredResources.add(detail);
          }
          return discoveredResources;
       } else {",2013-02-27T16:53:58Z,516
"@@ -149,7 +149,11 @@ private static void populateMetricsAndOperations(List<Class<?>> classes, Element
             if (managedAttr != null) {
                String property = prefix + getPropertyFromBeanConvention(ctMethod);
 
-               String displayName = withNamePrefix ? ""["" + mbean.objectName() + ""] "" + managedAttr.displayName() : managedAttr.displayName();
+               String attrDisplayName = managedAttr.displayName();
+               if (attrDisplayName.length() == 0) {
+                  throw new RuntimeException(""Missing displayName on: "" + property);
+               }
+               String displayName = withNamePrefix ? ""["" + mbean.objectName() + ""] "" + attrDisplayName : attrDisplayName;
                validateDisplayName(displayName);
 
                Element metric = doc.createElement(""metric"");
@@ -175,7 +179,11 @@ private static void populateMetricsAndOperations(List<Class<?>> classes, Element
                }
                uniqueOperations.add(name);
 
-               String displayName = withNamePrefix ? ""["" + mbean.objectName() + ""] "" + managedOp.displayName() : managedOp.displayName();
+               String opDisplayName = managedOp.displayName();
+               if (opDisplayName.length() == 0) {
+                  throw new RuntimeException(""Missing displayName on: "" + name);
+               }
+               String displayName = withNamePrefix ? ""["" + mbean.objectName() + ""] "" + opDisplayName : opDisplayName;
                validateDisplayName(displayName);
 
                Element operation = doc.createElement(""operation"");",2013-02-27T16:53:58Z,517
"@@ -18,13 +18,22 @@
  */
 package org.infinispan.cli.commands.server;
 
+import java.util.Arrays;
+import java.util.List;
+
 public class Locate extends AbstractServerCommand {
+   private final static List<String> OPTIONS = Arrays.asList(""--codec="");
 
    @Override
    public String getName() {
       return ""locate"";
    }
 
+   @Override
+   public List<String> getOptions() {
+      return OPTIONS;
+   }
+
    @Override
    public int nesting() {
       return 0;",2013-02-20T15:53:25Z,518
"@@ -1,5 +1,5 @@
 .SH SYNOPSIS
-.B locate [
+.B locate [--encoding=codec] [
 .I cache.
 .B ]
 .I key
@@ -13,4 +13,7 @@ works for distributed caches
 command
 .IP key
 the key of the entry for which to show the address
-.SH OUTPUT
+.I --codec=codec
+option has been specified then the key will be encoded using the specified codec, otherwise the default session codec will be used. See the
+.B encoding
+command for more information",2013-02-20T15:53:25Z,519
"@@ -178,7 +178,7 @@ infoStatement returns [InfoStatement stmt]
    ;
 
 locateStatement returns [LocateStatement stmt]
-   : LOCATE key = keyIdentifier (EOL | ';')! { $stmt = new LocateStatement($key.key); }
+   : LOCATE opts = statementOptions key = keyIdentifier (EOL | ';')! { $stmt = new LocateStatement($opts.options, $key.key); }
    ;
 
 pingStatement returns [PingStatement stmt]",2013-02-20T15:53:25Z,520
"@@ -21,6 +21,7 @@
 import java.util.List;
 
 import org.infinispan.Cache;
+import org.infinispan.cli.interpreter.codec.Codec;
 import org.infinispan.cli.interpreter.logging.Log;
 import org.infinispan.cli.interpreter.result.Result;
 import org.infinispan.cli.interpreter.result.StatementException;
@@ -39,18 +40,39 @@
 public class LocateStatement implements Statement {
    private static final Log log = LogFactory.getLog(LocateStatement.class, Log.class);
 
+   private enum Options {
+      CODEC
+   };
+
    final KeyData keyData;
+   final private List<Option> options;
 
-   public LocateStatement(final KeyData key) {
+   public LocateStatement(List<Option> options, KeyData key) {
+      this.options = options;
       this.keyData = key;
    }
 
    @Override
    public Result execute(Session session) throws StatementException {
       Cache<Object, Object> cache = session.getCache(keyData.getCacheName());
+      Codec codec = session.getCodec();
+      if (options.size() > 0) {
+         for (Option option : options) {
+            switch (option.toEnum(Options.class)) {
+            case CODEC: {
+               if (option.getParameter() == null) {
+                  throw log.missingOptionParameter(option.getName());
+               } else {
+                  codec = session.getCodec(option.getParameter());
+               }
+            }
+            }
+         }
+      }
       DistributionManager distributionManager = cache.getAdvancedCache().getDistributionManager();
       if(distributionManager!=null) {
-         List<Address> addresses = distributionManager.locate(keyData.getKey());
+         Object key = keyData.getKey();
+         List<Address> addresses = distributionManager.locate(codec.encodeKey(key));
          return new StringResult(addresses.toString());
       } else {
          throw log.cacheNotDistributed();",2013-02-20T15:53:25Z,521
"@@ -39,6 +39,7 @@
 import org.infinispan.util.logging.LogFactory;
 
 import java.util.Collections;
+import java.util.EnumSet;
 import java.util.Set;
 
 /**
@@ -94,7 +95,11 @@ public void initialize(InvocationContextContainer icc, CommandsFactory commandsF
     */
    public InternalCacheValue perform(InvocationContext context) throws Throwable {
       if (distributionManager != null && distributionManager.isAffectedByRehash(key)) return null;
-      GetKeyValueCommand command = commandsFactory.buildGetKeyValueCommand(key, flags);
+      // make sure the get command doesn't perform a remote call
+      // as our caller is already calling the ClusteredGetCommand on all the relevant nodes
+      Set<Flag> commandFlags = EnumSet.of(Flag.SKIP_REMOTE_LOOKUP);
+      if (this.flags != null) commandFlags.addAll(this.flags);
+      GetKeyValueCommand command = commandsFactory.buildGetKeyValueCommand(key, commandFlags);
       command.setReturnCacheEntry(true);
       InvocationContext invocationContext = icc.createRemoteInvocationContextForCommand(command, getOrigin());
       CacheEntry cacheEntry = (CacheEntry) invoker.invoke(invocationContext, command);",2011-06-01T17:19:32Z,522
"@@ -256,6 +256,9 @@ private void waitForJoinToStart() {
       try {
          joinStartedLatch.await();
       } catch (InterruptedException e) {
+         // TODO We're setting the interrupted flag so the caller can still check if the thread was interrupted, but it would be better to throw InterruptedException instead
+         // The only problem is that would require a lot of method signature changes
+         Thread.currentThread().interrupt();
          throw new IllegalStateException(""Thread interrupted"", e);
       }
    }
@@ -352,7 +355,7 @@ private Map<Object, InternalCacheValue> applyStateMap(ConsistentHash consistentH
                }
             }
          } else {
-            log.warnf(""Received a key that doesn't map to this node: %s, mapped to %s"", e.getKey(), consistentHash.locate(e.getKey(), configuration.getNumOwners()));
+            log.keyDoesNotMapToLocalNode(e.getKey(), consistentHash.locate(e.getKey(), configuration.getNumOwners()));
          }
       }
       return retry;",2011-06-01T17:19:32Z,60
"@@ -95,35 +95,36 @@ protected void performRehash() throws Exception {
          log.debugf(""Commencing rehash on node: %s. Before start, distributionManager.joinComplete = %s"", getMyAddress(), distributionManager.isJoinComplete());
       ConsistentHash chOld, chNew;
       try {
-         // 1.  Get the old CH
-         chOld = distributionManager.getConsistentHash();
-
-         // 2. Create the new CH:
-         List<Address> newMembers = rpcManager.getTransport().getMembers();
-         chNew = createConsistentHash(configuration, newMembers);
-         notifier.notifyTopologyChanged(chOld, chNew, true);
-         distributionManager.setConsistentHash(chNew);
-         notifier.notifyTopologyChanged(chOld, chNew, false);
-
-         if (log.isTraceEnabled()) {
-            log.tracef(""Rebalancing\nchOld = %s\nchNew = %s"", chOld, chNew);
-         }
-
-         if (configuration.isRehashEnabled()) {
-            // Cache sets for notification
-            Collection<Address> oldCacheSet = Immutables.immutableCollectionWrap(chOld.getCaches());
-            Collection<Address> newCacheSet = Immutables.immutableCollectionWrap(chNew.getCaches());
+         // Don't need to log anything, all transactions will be blocked
+         //distributionManager.getTransactionLogger().enable();
+         distributionManager.getTransactionLogger().blockNewTransactions();
+
+         boolean needToUnblockTransactions = true;
+         try {
+            // 1.  Get the old CH
+            chOld = distributionManager.getConsistentHash();
+
+            // 2. Create the new CH:
+            List<Address> newMembers = rpcManager.getTransport().getMembers();
+            chNew = createConsistentHash(configuration, newMembers);
+            notifier.notifyTopologyChanged(chOld, chNew, true);
+            distributionManager.setConsistentHash(chNew);
+            notifier.notifyTopologyChanged(chOld, chNew, false);
+
+            if (log.isTraceEnabled()) {
+               log.tracef(""Rebalancing\nchOld = %s\nchNew = %s"", chOld, chNew);
+            }
 
-            // notify listeners that a rehash is about to start
-            notifier.notifyDataRehashed(oldCacheSet, newCacheSet, newViewId, true);
+            if (configuration.isRehashEnabled()) {
+               // Cache sets for notification
+               Collection<Address> oldCacheSet = Immutables.immutableCollectionWrap(chOld.getCaches());
+               Collection<Address> newCacheSet = Immutables.immutableCollectionWrap(chNew.getCaches());
 
-            List<Object> removedKeys = new ArrayList<Object>();
-            NotifyingNotifiableFuture<Object> stateTransferFuture = new AggregatingNotifyingFutureImpl(null, newMembers.size());
+               // notify listeners that a rehash is about to start
+               notifier.notifyDataRehashed(oldCacheSet, newCacheSet, newViewId, true);
 
-            try {
-               // Don't need to log anything, all transactions will be blocked
-               //distributionManager.getTransactionLogger().enable();
-               distributionManager.getTransactionLogger().blockNewTransactions();
+               List<Object> removedKeys = new ArrayList<Object>();
+               NotifyingNotifiableFuture<Object> stateTransferFuture = new AggregatingNotifyingFutureImpl(null, newMembers.size());
 
                int numOwners = configuration.getNumOwners();
 
@@ -157,37 +158,46 @@ protected void performRehash() throws Exception {
                   rpcManager.invokeRemotelyInFuture(Collections.singleton(target), cmd,
                                                     false, stateTransferFuture, configuration.getRehashRpcTimeout());
                }
-            } finally {
+
+               // TODO Allow APPLY_STATE RehashControlCommand to skip transaction blocking, so we can unblock new transactions
+               // only after we have invalidated the keys removed from this cache
+               // For transactions TransactionTable should have already rolled back the transactions touching those keys,
+               // but it still might be a problem for non-transactional writes.
+               needToUnblockTransactions = false;
                distributionManager.getTransactionLogger().unblockNewTransactions();
-            }
 
-            // wait to see if all servers received the new state
-            // TODO should we retry the state transfer operation if it failed on some of the nodes?
-            try {
-               stateTransferFuture.get();
-            } catch (ExecutionException e) {
-               log.error(""Error transferring state to node after rehash:"", e);
-            }
+               // wait to see if all servers received the new state
+               // TODO should we retry the state transfer operation if it failed on some of the nodes?
+               try {
+                  stateTransferFuture.get();
+               } catch (ExecutionException e) {
+                  log.errorTransferringState(e);
+               }
 
-            // Notify listeners of completion of rehashing
-            notifier.notifyDataRehashed(oldCacheSet, newCacheSet, newViewId, false);
+               // Notify listeners of completion of rehashing
+               notifier.notifyDataRehashed(oldCacheSet, newCacheSet, newViewId, false);
 
-            // now we can invalidate the keys
-            try {
-               InvalidateCommand invalidateCmd = cf.buildInvalidateFromL1Command(true, removedKeys);
-               InvocationContext ctx = icc.createNonTxInvocationContext();
-               invalidateCmd.perform(ctx);
-            } catch (Throwable t) {
-               log.error(""Error invalidating from L1"", t);
-            }
+               // now we can invalidate the keys
+               try {
+                  InvalidateCommand invalidateCmd = cf.buildInvalidateFromL1Command(true, removedKeys);
+                  InvocationContext ctx = icc.createNonTxInvocationContext();
+                  invalidateCmd.perform(ctx);
+               } catch (Throwable t) {
+                  log.failedToInvalidateKeys(t);
+               }
 
-            if (trace) {
-               if (removedKeys.size() > 0)
-                  log.tracef(""removed %d keys"", removedKeys.size());
-               log.tracef(""data container has now %d keys"", dataContainer.size());
+               if (trace) {
+                  if (removedKeys.size() > 0)
+                     log.tracef(""removed %d keys"", removedKeys.size());
+                  log.tracef(""data container has now %d keys"", dataContainer.size());
+               }
+            } else {
+               if (trace) log.trace(""Rehash not enabled, so not pushing state"");
+            }
+         } finally {
+            if (needToUnblockTransactions) {
+               distributionManager.getTransactionLogger().unblockNewTransactions();
             }
-         } else {
-            if (trace) log.trace(""Rehash not enabled, so not pushing state"");
          }
 
          // now we can inform the coordinator that we have finished our push
@@ -200,11 +210,8 @@ protected void performRehash() throws Exception {
             // doesn't matter when the coordinator receives the command, the transport will ensure that it eventually gets there
             rpcManager.invokeRemotely(Collections.singleton(t.getCoordinator()), cmd, false);
          }
-      } catch (Exception e) {
-         log.error(""failure in rebalancing"", e);
-         throw new CacheException(""Unexpected exception"", e);
       } finally {
-         log.debugf(""%s completed join rehash in %s!"", self, Util.prettyPrintTime(System.currentTimeMillis() - start));
+         log.debugf(""Node %s completed join rehash in %s!"", self, Util.prettyPrintTime(System.currentTimeMillis() - start));
       }
    }
 
@@ -250,7 +257,7 @@ protected void rebalance(Object key, InternalCacheEntry value, int numOwners, Co
             try {
                value = cacheStore.load(key);
             } catch (CacheLoaderException e) {
-               log.warnf(""failed loading value for key %s from cache store"", key);
+               log.failedLoadingValueFromCacheStore(key);
             }
          }
 ",2011-06-01T17:19:32Z,266
"@@ -73,7 +73,7 @@ public Void call() throws Exception {
       }
       catch (Throwable th) {
          // there is no one else to handle the exception below us
-         log.error(""Error during rehash"", th);
+         log.errorDuringRehash(th);
       }
       return null;
    }",2011-06-01T17:19:32Z,523
"@@ -49,7 +49,7 @@ public interface RemoteTransactionLogger {
     *
     * @return list of drained commands
     */
-   List<WriteCommand> drainAndLock(Address lockFor);
+   List<WriteCommand> drainAndLock() throws InterruptedException;
 
    /**
     * Tests whether the drain() method can be called without a lock.  This is usually true if there is a lot of stuff to
@@ -71,5 +71,5 @@ public interface RemoteTransactionLogger {
    /**
     * Unlocks and disables the transaction logger.  Should <i>only</i> be called after {@link #drainAndLock()}.
     */
-   void unlockAndDisable(Address lockedFor);
+   void unlockAndDisable();
 }",2011-06-01T17:19:32Z,524
"@@ -27,16 +27,19 @@
 import org.infinispan.commands.tx.RollbackCommand;
 import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.context.impl.TxInvocationContext;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.transaction.xa.GlobalTransaction;
 
 /**
  * Typically adding a command, the following pattern would be used:
  * <p/>
  * <code>
  *
- * if (txLogger.logIfNeeded(cmd)) {
- *     // do NOT proceed with executing this command!
- * } else {
- *     // proceed with executing this command as per normal!
+ * txLogger.beforeCommand();
+ * try {
+ *    // execute this command!
+ * } finally {
+ *    txLogger.afterCommand(cmd);
  * }
  *
  * </code>
@@ -58,6 +61,7 @@
  * </code>
  *
  * @author Manik Surtani
+ * @author Dan Berindei <dberinde@redhat.com>
  * @since 4.0
  */
 public interface TransactionLogger extends RemoteTransactionLogger {
@@ -67,30 +71,29 @@ public interface TransactionLogger extends RemoteTransactionLogger {
    void enable();
 
    /**
-    * If logging is enabled, will log the command and return true.  Otherwise, will just return false.
+    * Logs a write command (if needed).
     *
     * @param command command to log
-    * @return true if logged, false otherwise
     */
-   boolean logIfNeeded(WriteCommand command);
+   void afterCommand(WriteCommand command) throws InterruptedException;
 
    /**
     * Logs a PrepareCommand if needed.
     * @param command PrepoareCommand to log
     */
-   void logIfNeeded(PrepareCommand command);
+   void afterCommand(PrepareCommand command) throws InterruptedException;
 
    /**
     * Logs a CommitCommand if needed.
     * @param command CommitCommand to log
     */
-   void logIfNeeded(CommitCommand command, TxInvocationContext context);
+   void afterCommand(CommitCommand command, TxInvocationContext context) throws InterruptedException;
 
    /**
     * Logs a RollbackCommand if needed.
     * @param command RollbackCommand to log
     */
-   void logIfNeeded(RollbackCommand command);
+   void afterCommand(RollbackCommand command) throws InterruptedException;
 
    /**
     * Checks whether transaction logging is enabled
@@ -99,20 +102,34 @@ public interface TransactionLogger extends RemoteTransactionLogger {
    boolean isEnabled();
 
    /**
-    * A mechanism for commit commands to register modifications instead of a prepare.  Used for when transaction logging
-    * was disabled during prepare, but was enabled before commit.
-    * @param commit commit command
-    * @param context context from which to extract modification list
+    * Notify the transaction logger before a write command, potentially blocking.
     */
-   void logModificationsIfNeeded(CommitCommand commit, TxInvocationContext context);
+   void beforeCommand(WriteCommand command) throws InterruptedException;
 
    /**
-    * Causes new transactions to block when testing isEnabled().
+    * Notify the transaction logger before a prepare command, potentially blocking.
     */
-   void blockNewTransactions();
+   void beforeCommand(PrepareCommand command) throws InterruptedException;
 
    /**
-    * Unblocks anything blocking on isEnabled().
+    * Notify the transaction logger before a commit command, potentially blocking.
+    * If transaction logging was not enabled during the prepare command, use the
+    * context to extract the list of modifications.
     */
-   void unblockNewTransactions();
+   void beforeCommand(CommitCommand command, TxInvocationContext context) throws InterruptedException;
+
+   /**
+    * Notify the transaction logger before a rollback command, potentially blocking.
+    */
+   void beforeCommand(RollbackCommand command) throws InterruptedException;
+
+   /**
+    * Causes new transactions to block when calling <code>beforeCommand()</code>.
+    */
+   void blockNewTransactions() throws InterruptedException;
+
+   /**
+    * Unblocks anything blocking on <code>beforeCommand()</code>.
+    */
+   void unblockNewTransactions() throws InterruptedException;
 }",2011-06-01T17:19:32Z,525
"@@ -42,6 +42,9 @@
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.atomic.AtomicReference;
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
 
 import static java.util.Arrays.asList;
 
@@ -51,15 +54,10 @@
  * Transaction logs can then be replayed after the state transferred during a rehash has been written.
  *
  * @author Manik Surtani
+ * @author Dan Berindei <dberinde@redhat.com>
  * @since 4.0
  */
 public class TransactionLoggerImpl implements TransactionLogger {
-   volatile boolean enabled;
-   volatile Address writeLockOwner = null;
-   final ReclosableLatch modsLatch = new ReclosableLatch();
-
-   final BlockingQueue<WriteCommand> commandQueue = new LinkedBlockingQueue<WriteCommand>();
-   final Map<GlobalTransaction, PrepareCommand> uncommittedPrepares = new ConcurrentHashMap<GlobalTransaction, PrepareCommand>();
    private static final Log log = LogFactory.getLog(TransactionLoggerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
@@ -68,8 +66,19 @@ public class TransactionLoggerImpl implements TransactionLogger {
    // If we see the queue growing this many times, lock.
    private static final int GROWTH_COUNT_THRESHOLD = 3;
    private int previousSize, growthCount;
-   private final ReclosableLatch txBlockGate = new ReclosableLatch(true);
 
+   private volatile boolean loggingEnabled;
+   // This lock is used to block new transactions during rehash
+   // Write commands must acquire the read lock for the duration of the command
+   // We acquire the write lock to block new transactions
+   // That means we wait for pending write commands to finish, and we might have to wait a lot if
+   // a command is deadlocked
+   // TODO Find a way to interrupt all transactions waiting for answers from remote nodes, instead
+   // of waiting for all of them to finish
+   private ReentrantReadWriteLock txLock = new ReentrantReadWriteLock();
+
+   final BlockingQueue<WriteCommand> commandQueue = new LinkedBlockingQueue<WriteCommand>();
+   final Map<GlobalTransaction, PrepareCommand> uncommittedPrepares = new ConcurrentHashMap<GlobalTransaction, PrepareCommand>();
 
    private final CommandsFactory cf;
 
@@ -78,8 +87,7 @@ public TransactionLoggerImpl(CommandsFactory cf) {
    }
 
    public void enable() {
-      modsLatch.open();
-      enabled = true;
+      loggingEnabled = true;
    }
 
    public List<WriteCommand> drain() {
@@ -88,128 +96,95 @@ public List<WriteCommand> drain() {
       return list;
    }
 
-   public List<WriteCommand> drainAndLock(Address lockedFor) {
-      if (writeLockOwner != null) throw new IllegalStateException(""This cannot happen - write lock already owned by "" + writeLockOwner);
-
-      modsLatch.close();
-      if (writeLockOwner != null) throw new IllegalStateException(""This cannot happen - write lock already owned by "" + writeLockOwner);
-      writeLockOwner = lockedFor;
+   public List<WriteCommand> drainAndLock() throws InterruptedException {
+      blockNewTransactions();
       return drain();
    }
 
-   public void unlockAndDisable(Address lockedFor) {
-      boolean unlock = true;
-      try {
-         if (!lockedFor.equals(writeLockOwner)) {
-            unlock = false;
-            throw new IllegalMonitorStateException(""Compare-and-set for owner "" + lockedFor + "" failed - was "" + writeLockOwner);
-         }
+   public void unlockAndDisable() {
+      loggingEnabled = false;
+      uncommittedPrepares.clear();
+      unblockNewTransactions();
+   }
 
-         enabled = false;
-         uncommittedPrepares.clear();
-         writeLockOwner = null;
-      } catch (IllegalMonitorStateException imse) {
-         log.unableToStopTransactionLogging(imse);
-      } finally {
-         if (unlock) modsLatch.open();
+   public void afterCommand(WriteCommand command) throws InterruptedException {
+      txLock.readLock().unlock();
+      if (loggingEnabled && command.isSuccessful()) {
+         commandQueue.put(command);
       }
    }
 
-   public boolean logIfNeeded(WriteCommand command) {
-      if (isEnabled()) {
-         waitForModsLatch();
-         if (enabled) {
-            try {
-               commandQueue.put(command);
-            } catch (InterruptedException e) {
-               Thread.currentThread().interrupt();
-            }
-            return true;
-         }
+   public void afterCommand(PrepareCommand command) throws InterruptedException {
+      txLock.readLock().unlock();
+      if (loggingEnabled) {
+         if (command.isOnePhaseCommit())
+            logModificationsInTransaction(command);
+         else
+            uncommittedPrepares.put(command.getGlobalTransaction(), command);
       }
-      return false;
    }
 
-   public void logIfNeeded(PrepareCommand command) {
-      if (isEnabled()) {
-         waitForModsLatch();
-         if (enabled) {
-            if (command.isOnePhaseCommit())
-               logModificationsInTransaction(command);
-            else
-               uncommittedPrepares.put(command.getGlobalTransaction(), command);
-         }
+   public void afterCommand(CommitCommand command, TxInvocationContext context) throws InterruptedException {
+      txLock.readLock().unlock();
+      if (loggingEnabled) {
+         PrepareCommand pc = uncommittedPrepares.remove(command.getGlobalTransaction());
+         if (pc == null)
+            logModifications(context.getModifications());
+         else
+            logModificationsInTransaction(pc);
+      }
+   }
+
+   public void afterCommand(RollbackCommand command) {
+      txLock.readLock().unlock();
+      if (loggingEnabled) {
+         if (loggingEnabled) uncommittedPrepares.remove(command.getGlobalTransaction());
       }
    }
 
-   private void logModificationsInTransaction(PrepareCommand command) {
+   private void logModificationsInTransaction(PrepareCommand command) throws InterruptedException {
       logModifications(asList(command.getModifications()));
    }
 
-   private void logModifications(Collection<WriteCommand> mods) {
+   private void logModifications(Collection<WriteCommand> mods) throws InterruptedException {
       for (WriteCommand wc : mods) {
-         try {
-            commandQueue.put(wc);
-         } catch (InterruptedException ie) {
-            Thread.currentThread().interrupt();
-         }
+         commandQueue.put(wc);
       }
    }
 
-   public void logModificationsIfNeeded(CommitCommand commit, TxInvocationContext context) {
-      if (isEnabled()) {
-         waitForModsLatch();
-         if (enabled) {
-            GlobalTransaction gtx;
-            if (!uncommittedPrepares.containsKey(gtx = commit.getGlobalTransaction()))
-               uncommittedPrepares.put(gtx, cf.buildPrepareCommand(gtx, context.getModifications(), false));
-         }
-      }
+   public void beforeCommand(WriteCommand command) throws InterruptedException {
+      txLock.readLock().lock();
    }
 
-   public void logIfNeeded(CommitCommand command, TxInvocationContext context) {
-      if (isEnabled()) {
-         waitForModsLatch();
-         if (enabled) {
-            PrepareCommand pc = uncommittedPrepares.remove(command.getGlobalTransaction());
-            if (pc == null)
-               logModifications(context.getModifications());
-            else
-               logModificationsInTransaction(pc);
-         }
-      }
+   public void beforeCommand(PrepareCommand command) throws InterruptedException {
+      txLock.readLock().lock();
    }
 
-   public void logIfNeeded(RollbackCommand command) {
-      if (isEnabled()) {
-         waitForModsLatch();
-         if (enabled) uncommittedPrepares.remove(command.getGlobalTransaction());
+   public void beforeCommand(CommitCommand command, TxInvocationContext context) throws InterruptedException {
+      txLock.readLock().lock();
+
+      // if the prepare command wasn't logged, do it here instead
+      if (loggingEnabled) {
+         GlobalTransaction gtx;
+         if (!uncommittedPrepares.containsKey(gtx = context.getGlobalTransaction()))
+            uncommittedPrepares.put(gtx, cf.buildPrepareCommand(gtx, context.getModifications(), false));
       }
    }
 
-   private void waitForModsLatch() {
-      try {
-         modsLatch.await();
-      } catch (InterruptedException i) {
-         Thread.currentThread().interrupt();
-      }
+   public void beforeCommand(RollbackCommand command) throws InterruptedException {
+      txLock.readLock().lock();
    }
 
    private int size() {
-      return enabled ? 0 : commandQueue.size();
+      return loggingEnabled ? commandQueue.size() : 0;
    }
 
    public boolean isEnabled() {
-      try {
-         txBlockGate.await();
-      } catch (InterruptedException e) {
-         Thread.currentThread().interrupt();
-      }
-      return enabled;
+      return loggingEnabled;
    }
 
    public boolean shouldDrainWithoutLock() {
-      if (enabled) {
+      if (loggingEnabled) {
          int sz = size();
          boolean shouldLock = (previousSize > 0 && growthCount > GROWTH_COUNT_THRESHOLD) || sz < DRAIN_LOCK_THRESHOLD;
          if (!shouldLock) {
@@ -228,12 +203,15 @@ public Collection<PrepareCommand> getPendingPrepares() {
       return commands;
    }
 
-   public void blockNewTransactions() {
-      txBlockGate.close();
+   public void blockNewTransactions() throws InterruptedException {
+      if (trace) log.debug(""Blocking new transactions"");
+      // we just want to ensure that all the modifications that passed through the tx gate have ended
+      txLock.writeLock().lockInterruptibly();
    }
 
    public void unblockNewTransactions() {
-      txBlockGate.open();
+      if (trace) log.debug(""Unblocking new transactions"");
+      txLock.writeLock().unlock();
    }
 
 ",2011-06-01T17:19:32Z,526
"@@ -598,12 +598,12 @@ public void start() {
             destroy(); // this will take us back to TERMINATED
 
          if (state.needToInitializeBeforeStart()) {
-            state = ComponentStatus.INITIALIZING;
             rewire();
          } else
             return;
       }
 
+      state = ComponentStatus.INITIALIZING;
       try {
          internalStart();
       }",2011-06-01T17:19:32Z,23
"@@ -77,58 +77,82 @@ protected VisitableCommand getCommandToReplay(VisitableCommand command) {
 
    @Override
    public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand cmd) throws Throwable {
-      dm.getTransactionLogger().logIfNeeded(cmd);
-      return super.visitPrepareCommand(ctx, cmd);
+      dm.getTransactionLogger().beforeCommand(cmd);
+      try {
+         return super.visitPrepareCommand(ctx, cmd);
+      } finally {
+         dm.getTransactionLogger().afterCommand(cmd);
+      }
    }
 
    @Override
    public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand cmd) throws Throwable {
-      Object rv = super.visitRollbackCommand(ctx, cmd);
-      dm.getTransactionLogger().logIfNeeded(cmd);
-      return rv;
+      dm.getTransactionLogger().beforeCommand(cmd);
+      try {
+         return super.visitRollbackCommand(ctx, cmd);
+      } finally {
+         dm.getTransactionLogger().afterCommand(cmd);
+      }
    }
 
    @Override
    public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand cmd) throws Throwable {
-      dm.getTransactionLogger().logModificationsIfNeeded(cmd, ctx);
-      Object rv = super.visitCommitCommand(ctx, cmd);
-      dm.getTransactionLogger().logIfNeeded(cmd, ctx);
-      return rv;
+      dm.getTransactionLogger().beforeCommand(cmd, ctx);
+      try {
+         return super.visitCommitCommand(ctx, cmd);
+      } finally {
+         dm.getTransactionLogger().afterCommand(cmd, ctx);
+      }
    }
 
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
-      Object o = super.visitPutKeyValueCommand(ctx, command);
-      if (!ctx.isInTxScope() && command.isSuccessful()) dm.getTransactionLogger().logIfNeeded(command);
-      return o;
+      if (!ctx.isInTxScope()) dm.getTransactionLogger().beforeCommand(command);
+      try {
+         return super.visitPutKeyValueCommand(ctx, command);
+      } finally {
+         if (!ctx.isInTxScope()) dm.getTransactionLogger().afterCommand(command);
+      }
    }
 
    @Override
    public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
-      Object o = super.visitRemoveCommand(ctx, command);
-      if (!ctx.isInTxScope() && command.isSuccessful()) dm.getTransactionLogger().logIfNeeded(command);
-      return o;
+      if (!ctx.isInTxScope()) dm.getTransactionLogger().beforeCommand(command);
+      try {
+         return super.visitRemoveCommand(ctx, command);
+      } finally {
+         if (!ctx.isInTxScope()) dm.getTransactionLogger().afterCommand(command);
+      }
    }
 
    @Override
    public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
-      Object o = super.visitReplaceCommand(ctx, command);
-      if (!ctx.isInTxScope() && command.isSuccessful()) dm.getTransactionLogger().logIfNeeded(command);
-      return o;
+      if (!ctx.isInTxScope()) dm.getTransactionLogger().beforeCommand(command);
+      try {
+         return super.visitReplaceCommand(ctx, command);
+      } finally {
+         if (!ctx.isInTxScope()) dm.getTransactionLogger().afterCommand(command);
+      }
    }
 
    @Override
    public Object visitClearCommand(InvocationContext ctx, ClearCommand command) throws Throwable {
-      Object o = super.visitClearCommand(ctx, command);
-      if (!ctx.isInTxScope() && command.isSuccessful()) dm.getTransactionLogger().logIfNeeded(command);
-      return o;
+      if (!ctx.isInTxScope()) dm.getTransactionLogger().beforeCommand(command);
+      try {
+         return super.visitClearCommand(ctx, command);
+      } finally {
+         if (!ctx.isInTxScope()) dm.getTransactionLogger().afterCommand(command);
+      }
    }
 
    @Override
    public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
-      Object o = super.visitPutMapCommand(ctx, command);
-      if (!ctx.isInTxScope() && command.isSuccessful()) dm.getTransactionLogger().logIfNeeded(command);
-      return o;
+      if (!ctx.isInTxScope()) dm.getTransactionLogger().beforeCommand(command);
+      try {
+         return super.visitPutMapCommand(ctx, command);
+      } finally {
+         if (!ctx.isInTxScope()) dm.getTransactionLogger().afterCommand(command);
+      }
    }
 
 ",2011-06-01T17:19:32Z,527
"@@ -48,15 +48,15 @@ public static List<Address> getMembersLeft(List<Address> oldList, List<Address>
       return new ArrayList<Address>(tmp);
    }
 
-   public static Address getMemberJoined(List<Address> oldList, List<Address> newList) {
-      Set<Address> tmp = new HashSet<Address>(newList);
-      tmp.removeAll(oldList);
-      return tmp.isEmpty() ? null : tmp.iterator().next();
+   public static Set<Address> getMembersJoined(Set<Address> oldSet, Set<Address> newSet) {
+      Set<Address> result = new HashSet<Address>(newSet);
+      result.removeAll(oldSet);
+      return result;
    }
 
-   public static Address getMemberLeft(List<Address> oldList, List<Address> newList) {
-      Set<Address> tmp = new HashSet<Address>(oldList);
-      tmp.removeAll(newList);
-      return tmp.isEmpty() ? null : tmp.iterator().next();
-   }   
+   public static Set<Address> getMembersLeft(Set<Address> oldSet, Set<Address> newSet) {
+      Set<Address> result = new HashSet<Address>(oldSet);
+      result.removeAll(newSet);
+      return result;
+   }
 }",2011-06-01T17:19:32Z,528
"@@ -534,11 +534,12 @@ public void viewAccepted(View newView) {
       // Now that we have a view, figure out if we are the coordinator
       coordinator = (members != null && !members.isEmpty() && members.get(0).equals(getAddress()));
 
-      // now notify listeners - *after* updating the coordinator. - JBCACHE-662
-      if (needNotification && n != null) n.emitNotification(oldMembers, newView);
-
       // Wake up any threads that are waiting to know about who the coordinator is
+      // do it before the notifications, so if a listener throws an exception we can still start
       channelConnectedLatch.countDown();
+
+      // now notify listeners - *after* updating the coordinator. - JBCACHE-662
+      if (needNotification && n != null) n.emitNotification(oldMembers, newView);
    }
 
    public void suspect(org.jgroups.Address suspected_mbr) {",2011-06-01T17:19:32Z,214
"@@ -73,8 +73,8 @@ public void addModification(WriteCommand mod) {
       modifications.add(mod);
    }
 
-   public boolean hasRemoteLocksAcquired(List<Address> leavers) {
-      if (log.isTraceEnabled()) {
+   public boolean hasRemoteLocksAcquired(Collection<Address> leavers) {
+      if (trace) {
          log.tracef(""My remote locks: %s, leavers are: %s"", remoteLockedNodes, leavers);
       }
       return (remoteLockedNodes != null) && !Collections.disjoint(remoteLockedNodes, leavers);",2011-06-01T17:19:32Z,454
"@@ -37,6 +37,8 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
+import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
+import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
 import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
 import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.MembershipArithmetic;
@@ -50,16 +52,8 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.Transaction;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.RejectedExecutionException;
-import java.util.concurrent.TimeUnit;
+import java.util.*;
+import java.util.concurrent.*;
 
 import static java.util.Collections.emptySet;
 
@@ -111,10 +105,12 @@ public void initialize(RpcManager rpcManager, Configuration configuration,
    private void start() {
       lockBreakingService = Executors.newFixedThreadPool(1);
       cm.addListener(listener);
+      notifier.addListener(listener);
    }
 
    @Stop
    private void stop() {
+      notifier.removeListener(listener);
       cm.removeListener(listener);
       lockBreakingService.shutdownNow();
       if (trace) log.tracef(""Wait for on-going transactions to finish for %d seconds."", TimeUnit.MILLISECONDS.toSeconds(configuration.getCacheStopTimeout()));
@@ -176,22 +172,6 @@ public void failureCompletingTransaction(Transaction tx) {
       removeLocalTransaction(localTransactions.get(tx));
    }
 
-   public void memberJoined(ConsistentHash chNew, Address newMember) {
-      if (configuration.isEagerLockingSingleNodeInUse()) {
-         for (LocalTransaction localTx : localTransactions.values()) {
-            for (Object k : localTx.getAffectedKeys()) {
-               Address newMainOwner = chNew.locate(k, 1).get(0);
-               if (newMember.equals(newMainOwner)) {
-                  localTx.markForRollback(true);
-                  if (log.isTraceEnabled()) log.tracef(""Marked local transaction for rollback, as the main data "" +
-                                                            ""owner has changed %s"", localTx);
-                  break;
-               }
-            }
-         }
-      }
-   }
-
    /**
     * Returns true if the given transaction is already registered with the transaction table.
     * @param tx if null false is returned
@@ -202,23 +182,69 @@ public boolean containsLocalTx(Transaction tx) {
 
    @Listener
    public class StaleTransactionCleanup {
+      /**
+       * Roll back remote transactions originating on nodes that have left the cluster.
+       */
       @ViewChanged
       public void onViewChange(ViewChangedEvent vce) {
-         final List<Address> leavers = MembershipArithmetic.getMembersLeft(vce.getOldMembers(), vce.getNewMembers());
+         final List<Address> leavers = MembershipArithmetic.getMembersLeft(vce.getOldMembers(),
+                                                                           vce.getNewMembers());
          if (!leavers.isEmpty()) {
-            if (trace) log.tracef(""Saw %s leavers - kicking off a lock breaking task"", leavers.size());
+            if (trace) log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
             cleanTxForWhichTheOwnerLeft(leavers);
+         }
+      }
+
+      /**
+       * Roll back local transactions that have acquired lock that are no longer valid,
+       * either because the main data owner left the cluster or because a node joined
+       * the cluster and is the new data owner.
+       * This method will only ever be called in distributed mode.
+       */
+      @TopologyChanged
+      public void onTopologyChange(TopologyChangedEvent tce) {
+         // do all the work AFTER the consistent hash has changed
+         if (tce.isPre())
+            return;
+
+         final ConsistentHash chNew = tce.getConsistentHashAtEnd();
+         final Set<Address> oldMembers = tce.getConsistentHashAtStart().getCaches();
+         final Set<Address> newMembers = tce.getConsistentHashAtEnd().getCaches();
+
+         final Set<Address> leavers = MembershipArithmetic.getMembersLeft(oldMembers, newMembers);
+         if (!leavers.isEmpty()) {
+            // roll back local transactions if they had acquired locks on one of the leavers
             if (configuration.isEagerLockingSingleNodeInUse()) {
                for (LocalTransaction localTx : localTransactions.values()) {
                   if (localTx.hasRemoteLocksAcquired(leavers)) {
                      localTx.markForRollback(true);
+                     if (trace) log.tracef(""Marked local transaction for rollback, as it had acquired "" +
+                                                 ""locks on a node that has left the cluster: %s"", localTx);
+                  }
+               }
+            }
+         }
+
+         final Set<Address> joiners = MembershipArithmetic.getMembersJoined(oldMembers, newMembers);
+         if (!joiners.isEmpty()) {
+            // roll back local transactions if their main data owner has changed
+            if (configuration.isEagerLockingSingleNodeInUse()) {
+               for (LocalTransaction localTx : localTransactions.values()) {
+                  for (Object k : localTx.getAffectedKeys()) {
+                     Address newMainOwner = chNew.locate(k, 1).get(0);
+                     if (joiners.contains(newMainOwner)) {
+                        localTx.markForRollback(true);
+                        if (trace) log.tracef(""Marked local transaction for rollback, as the main data "" +
+                                                   ""owner has changed %s"", localTx);
+                        break;
+                     }
                   }
                }
             }
          }
       }
 
-      private void cleanTxForWhichTheOwnerLeft(final List<Address> leavers) {
+      private void cleanTxForWhichTheOwnerLeft(final Collection<Address> leavers) {
          try {
             lockBreakingService.submit(new Runnable() {
                public void run() {
@@ -236,7 +262,7 @@ public void run() {
       }
    }
 
-   protected void updateStateOnNodesLeaving(List<Address> leavers) {
+   protected void updateStateOnNodesLeaving(Collection<Address> leavers) {
       Set<GlobalTransaction> toKill = new HashSet<GlobalTransaction>();
       for (GlobalTransaction gt : remoteTransactions.keySet()) {
          if (leavers.contains(gt.getAddress())) toKill.add(gt);",2011-06-01T17:19:32Z,127
"@@ -30,6 +30,7 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.Status;
+import java.util.Collection;
 import java.util.List;
 
 /**
@@ -76,7 +77,7 @@ public boolean isOrphan() {
     * {@link #isOrphan()}.
     * @param leavers the nodes that left the cluster
     */
-   public void computeOrphan(List<Address> leavers) {
+   public void computeOrphan(Collection<Address> leavers) {
       if (leavers.contains(getGlobalTransaction().getAddress())) {
          if (log.isTraceEnabled()) log.tracef(""This transaction's originator has left the cluster: %s"", getGlobalTransaction());
          isOrphan = true;",2011-06-01T17:19:32Z,529
"@@ -35,6 +35,7 @@
 
 import javax.transaction.Transaction;
 import javax.transaction.xa.Xid;
+import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
 import java.util.LinkedList;
@@ -74,7 +75,7 @@ public void localTransactionPrepared(LocalTransaction localTransaction) {
    }
 
    @Override
-   protected void updateStateOnNodesLeaving(List<Address> leavers) {
+   protected void updateStateOnNodesLeaving(Collection<Address> leavers) {
       Iterator<Map.Entry<GlobalTransaction,RemoteTransaction>> it = remoteTransactions.entrySet().iterator();
       while (it.hasNext()) {
          RecoveryAwareRemoteTransaction recTx = (RecoveryAwareRemoteTransaction) it.next().getValue();",2011-06-01T17:19:32Z,530
"@@ -196,7 +196,7 @@ public interface Log extends BasicLogger {
 
    @LogMessage(level = WARN)
    @Message(value = ""Unable to stop transaction logging!"", id = 24)
-   void unableToStopTransactionLogging(IllegalMonitorStateException imse);
+   void unableToStopTransactionLogging(@Cause IllegalMonitorStateException imse);
 
    @LogMessage(level = INFO)
    @Message(value = ""wakeUpInterval is <= 0, not starting eviction thread"", id = 25)
@@ -595,7 +595,7 @@ void preparedTxAlreadyExists(RecoveryAwareTransaction previous,
 
    @LogMessage(level = WARN)
    @Message(value = ""Invocation of %s threw an exception %s. Exception is ignored."", id = 120)
-   void ignoringException(String name, Throwable t);
+   void ignoringException(String name, @Cause Throwable t);
 
    @LogMessage(level = ERROR)
    @Message(value = ""Unable to set value!"", id = 121)
@@ -670,7 +670,7 @@ void preparedTxAlreadyExists(RecoveryAwareTransaction previous,
 
    @LogMessage(level = INFO)
    @Message(value = ""Could not register object with name: %s (%s)"", id = 138)
-   void couldNotRegisterObjectName(ObjectName objectName, InstanceAlreadyExistsException e);
+   void couldNotRegisterObjectName(ObjectName objectName, @Cause InstanceAlreadyExistsException e);
 
    @LogMessage(level = WARN)
    @Message(value = ""Infinispan configuration schema could not be resolved locally nor fetched from URL. Local path=%s, schema path=%s, schema URL=%s"", id = 139)
@@ -689,4 +689,24 @@ void preparedTxAlreadyExists(RecoveryAwareTransaction previous,
          "" to cache stop timeout (%d ms), so instead using %d ms for async store stop wait"", id = 142)
    void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
       long cacheStopTimeout, long asyncStopTimeout);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Received a key that doesn't map to this node: %s, mapped to %s"", id = 143)
+   void keyDoesNotMapToLocalNode(Object key, Collection<Address> nodes);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed loading value for key %s from cache store"", id = 144)
+   void failedLoadingValueFromCacheStore(Object key);
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""Error during rehash"", id = 145)
+   void errorDuringRehash(@Cause Throwable th);
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""Error transferring state to node after rehash"", id = 146)
+   void errorTransferringState(@Cause Exception e);
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""Error invalidating keys from L1 after rehash"", id = 147)
+   void failedToInvalidateKeys(@Cause Throwable t);
 }",2011-06-01T17:19:32Z,45
"@@ -59,18 +59,19 @@ public void tearDown() {
    public void testListenerRemoval() {
       cache.put(""x"", ""y"");
       AtomicInteger i = new AtomicInteger(0);
-      assert cache.getListeners().isEmpty();
+      // TransactionTable has already added a listener
+      assert 1 == cache.getListeners().size();
       CacheListener l = new CacheListener(i);
       cache.addListener(l);
-      assert 1 == cache.getListeners().size();
-      assert cache.getListeners().iterator().next() == l;
+      assert 2 == cache.getListeners().size();
+      assert cache.getListeners().contains(l);
       assert 0 == i.get();
       cache.get(""x"");
       assert 1 == i.get();
 
       // remove the replListener
       cache.removeListener(l);
-      assert cache.getListeners().isEmpty();
+      assert 1 == cache.getListeners().size();
       i.set(0);
       assert 0 == i.get();
       cache.get(""x"");",2011-06-01T17:19:32Z,531
"@@ -223,6 +223,11 @@ public static EmbeddedCacheManager createCacheManager(Configuration defaultCache
       amendMarshaller(globalConfiguration);
       minimizeThreads(globalConfiguration);
       if (transactional) amendJTA(defaultCacheConfig);
+
+      // we stop caches during transactions all the time
+      // so wait at most 1 second for ongoing transactions when stopping
+      defaultCacheConfig.fluent().cacheStopTimeout(1000);
+
       return newDefaultCacheManager(true, globalConfiguration, defaultCacheConfig, false);
    }
 ",2011-06-01T17:19:32Z,130
"@@ -27,6 +27,7 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
+import org.infinispan.util.concurrent.TimeoutException;
 import org.testng.annotations.Test;
 
 import javax.transaction.NotSupportedException;
@@ -84,8 +85,8 @@ private void assertLocked(Cache<String, String> c, String key) throws SystemExce
       try {
          c.put(key, ""dummy""); // should time out
          assert false : ""Should have been locked!"";
-      } catch (Exception e) {
-
+      } catch (TimeoutException e) {
+         // ignoring timeout exception
       } finally {
          tm.rollback();
       }
@@ -96,7 +97,7 @@ private void assertNotLocked(Cache<String, String> c, String key) throws SystemE
       tm.begin();
       try {
          c.put(key, ""dummy""); // should time out
-      } catch (Exception e) {
+      } catch (TimeoutException e) {
          assert false : ""Should not have been locked!"";
       } finally {
          tm.rollback();",2011-06-01T17:19:32Z,532
"@@ -0,0 +1,40 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.remoting;
+
+import org.infinispan.CacheException;
+
+/**
+ * Represents an application-level exception originating in a remote node.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public class RemoteException extends CacheException {
+
+   public RemoteException(String msg, Throwable cause) {
+      super(msg, cause);
+   }
+
+}",2013-02-12T14:49:18Z,533
"@@ -46,6 +46,7 @@ public abstract class AbstractTransport implements Transport {
    protected GlobalConfiguration configuration;
 
    @Inject
+   @SuppressWarnings(""unused"")
    public void setConfiguration(GlobalConfiguration globalConfiguration) {
       this.configuration = globalConfiguration;
    }
@@ -63,13 +64,15 @@ public final boolean checkResponse(Object responseObject, Address sender) throws
       if (responseObject instanceof Response) {
          Response response = (Response) responseObject;
          if (response instanceof ExceptionResponse) {
-            Exception e = ((ExceptionResponse) response).getException();
+            ExceptionResponse exceptionResponse = (ExceptionResponse) response;
+            Exception e = exceptionResponse.getException();
             if (!(e instanceof RpcException)) {
                // if we have any application-level exceptions make sure we throw them!!
                if (shouldThrowException(e)) {
-                  throw e;
+                  throw log.remoteException(sender, e);
                } else {
-                  if (log.isDebugEnabled()) log.debug(""Received exception from sender"" + sender, e);
+                  if (log.isDebugEnabled())
+                     log.debug(""Received exception from "" + sender, e);
                }
             }
          }",2013-02-12T14:49:18Z,534
"@@ -28,6 +28,7 @@
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.bucket.Bucket;
 import org.infinispan.loaders.decorators.SingletonStore;
+import org.infinispan.remoting.RemoteException;
 import org.infinispan.remoting.responses.Response;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.LocalTransaction;
@@ -840,5 +841,9 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @LogMessage(level = INFO)
    @Message(value = ""%d entries migrated to cache %s in %s"", id = 216)
    void entriesMigrated(long count, String name, String prettyTime);
+
+   @Message(value = ""Received exception from %s, see cause for remote stack trace"", id = 217)
+   RemoteException remoteException(Address sender, @Cause Exception e);
+
 }
 ",2013-02-12T14:49:18Z,45
"@@ -81,9 +81,10 @@ public void testInvokeAndExceptionWhileUnmarshalling() throws Exception {
          dispatcher2.setRequestMarshaller(mockMarshaller);
          cache1.put(key, value);
          assert false : ""Should have thrown an exception"";
-      } catch(CacheException ce) {
+      } catch (RemoteException ce) {
          assert !(ce.getCause() instanceof ClassCastException) : ""No way a ClassCastException must be sent back to user!"";
-         assert ce.getCause() instanceof EOFException;
+         assert ce.getCause() instanceof CacheException;
+         assert ce.getCause().getCause() instanceof EOFException;
       } finally {
          dispatcher1.setMarshaller(originalMarshaller1);
          dispatcher2.setMarshaller(originalMarshaller);
@@ -120,7 +121,11 @@ private void induceInterceptorMalfunctioning(FailureType failureType) throws Thr
       try {
          cache1.put(failureType, 1);
       } catch (CacheException e) {
-         throw e.getCause();
+         Throwable cause = e.getCause();
+         if (cause.getCause() == null)
+            throw cause;
+         else
+            throw cause.getCause();
       } finally {
          cache2.getAdvancedCache().removeInterceptor(ErrorInducingInterceptor.class);
       }
@@ -133,11 +138,12 @@ private void induceListenerMalfunctioning(boolean throwError, FailureType failur
       cache2.addListener(listener);
       try {
          cache1.put(failureType, 1);
-      } catch (CacheException e) {
-         if (throwError && e.getCause() instanceof InvocationTargetException)
-            throw e.getCause().getCause();
+      } catch (RemoteException e) {
+         Throwable cause = e.getCause(); // get the exception behind the remote one
+         if (throwError && cause.getCause() instanceof InvocationTargetException)
+            throw cause.getCause().getCause();
          else
-            throw e.getCause();
+            throw cause.getCause();
       } finally {
          cache2.removeListener(listener);
       }",2013-02-12T14:49:18Z,264
"@@ -25,6 +25,7 @@
 import org.infinispan.Cache;
 import org.infinispan.config.Configuration;
 import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.remoting.RemoteException;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.transaction.LockingMode;
@@ -90,6 +91,9 @@ private void assertLocked(Cache<String, String> c, String key) throws SystemExce
          assert false : ""Should have been locked!"";
       } catch (TimeoutException e) {
          // ignoring timeout exception
+      } catch (RemoteException e) {
+         assert e.getCause() instanceof TimeoutException;
+         // ignoring timeout exception
       } finally {
          tm.rollback();
       }",2013-02-12T14:49:18Z,532
"@@ -27,6 +27,7 @@
 
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.remoting.RemoteException;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
 import org.infinispan.util.concurrent.TimeoutException;
@@ -95,10 +96,14 @@ private void test(int firstTxIndex, int secondTxIndex) throws Exception {
       tm(secondTxIndex).begin();
       try {
          cache(secondTxIndex).put(k, ""v2"");
-         assert false : ""Timeout exception expected"";
+         assert false : ""Exception expected"";
       } catch (TimeoutException e) {
          //expected
          tm(secondTxIndex).suspend();
+      } catch (RemoteException e) {
+         assert e.getCause() instanceof TimeoutException;
+         //expected
+         tm(secondTxIndex).suspend();
       }
 
       tm(firstTxIndex).resume(tx1);",2013-02-12T14:49:18Z,535
"@@ -0,0 +1,85 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ JBoss, Home of Professional Open Source
+  ~ Copyright 2009 Red Hat Inc. and/or its affiliates and other
+  ~ contributors as indicated by the @author tags. All rights reserved.
+  ~ See the copyright.txt in the distribution for a full listing of
+  ~ individual contributors.
+  ~
+  ~ This is free software; you can redistribute it and/or modify it
+  ~ under the terms of the GNU Lesser General Public License as
+  ~ published by the Free Software Foundation; either version 2.1 of
+  ~ the License, or (at your option) any later version.
+  ~
+  ~ This software is distributed in the hope that it will be useful,
+  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
+  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+  ~ Lesser General Public License for more details.
+  ~
+  ~ You should have received a copy of the GNU Lesser General Public
+  ~ License along with this software; if not, write to the Free
+  ~ Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+  ~ 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+  -->
+<!DOCTYPE log4j:configuration SYSTEM ""log4j.dtd"">
+
+<!--
+   For more configuration infromation and examples see the Apache Log4j website: http://logging.apache.org/log4j/
+ -->
+<log4j:configuration xmlns:log4j=""http://jakarta.apache.org/log4j/"" debug=""false"">
+
+   <!-- A time/date based rolling appender -->
+   <appender name=""FILE"" class=""org.infinispan.util.logging.log4j.CompressedFileAppender"">
+      <param name=""File"" value=""trace-infinispan.log.gz""/>
+      <param name=""Append"" value=""false""/>
+
+      <param name=""Threshold"" value=""TRACE""/>
+
+      <layout class=""org.apache.log4j.PatternLayout"">
+         <!-- The default pattern: Date Priority (Thread) [Category] Message\n -->
+         <param name=""ConversionPattern"" value=""%d %-5p (%t) [%c] %m%n""/>
+
+         <!-- The full pattern: Date MS Priority [Category] (Thread:NDC) Message\n
+        <param name=""ConversionPattern"" value=""%d %-5r %-5p [%c] (%t:%x) %m%n""/>
+         -->
+      </layout>
+   </appender>
+
+   <appender name=""CONSOLE"" class=""org.apache.log4j.ConsoleAppender"">
+      <param name=""Threshold"" value=""WARN""/>
+      <param name=""Target"" value=""System.out""/>
+
+      <layout class=""org.apache.log4j.PatternLayout"">
+         <!-- The default pattern: Date Priority [Category] Message\n -->
+         <param name=""ConversionPattern"" value=""%d %-5p [%c{1}] (%t) %m%n""/>
+      </layout>
+   </appender>
+
+
+   <!-- ================ -->
+   <!-- Limit categories -->
+   <!-- ================ -->
+
+   <category name=""org.infinispan"">
+      <priority value=""TRACE""/>
+   </category>
+
+   <category name=""com.mchange"">
+      <priority value=""WARN""/>
+   </category>
+
+   <category name=""org.jgroups"">
+      <priority value=""INFO""/>
+   </category>
+
+   <!-- ======================= -->
+   <!-- Setup the Root category -->
+   <!-- ======================= -->
+
+   <root>
+      <priority value=""INFO""/>
+      <appender-ref ref=""CONSOLE""/>
+      <appender-ref ref=""FILE""/>
+   </root>
+
+</log4j:configuration>",2011-11-28T12:29:18Z,536
"@@ -98,6 +98,7 @@
       <jboss.releases.repo.url>https://repository.jboss.org/nexus/service/local/staging/deploy/maven2/</jboss.releases.repo.url>
       <jboss.snapshots.repo.url>https://repository.jboss.org/nexus/content/repositories/snapshots/</jboss.snapshots.repo.url>
       <packaging>jar</packaging>
+      <infinispan.log4j.configuration>log4j.xml</infinispan.log4j.configuration>
 
       <!-- Versions for dependencies -->
       <version.apacheds.jdbm>1.5.7</version.apacheds.jdbm>
@@ -463,14 +464,14 @@
                      <name>java.net.preferIPv4Stack</name>
                      <value>true</value>
                   </property>
-                  <property>
-                     <name>infinispan.test.marshaller.class</name>
-                     <value>${infinispan.test.marshaller.class}</value>
-                  </property>
                   <property>
                      <name>infinispan.suppress_cache_creation_warning</name>
                      <value>true</value>
                   </property>
+                  <property>
+                     <name>log4j.configuration</name>
+                     <value>${infinispan.log4j.configuration}</value>
+                  </property>
                </systemProperties>
                <trimStackTrace>false</trimStackTrace>
                <properties>
@@ -859,5 +860,15 @@
             <infinispan.test.jgroups.protocol>tcp</infinispan.test.jgroups.protocol>
          </properties>
       </profile>
+      <profile>
+         <id>traceTests</id>
+         <activation>
+            <activeByDefault>false</activeByDefault>
+         </activation>
+         <properties>
+            <infinispan.log4j.configuration>log4j-trace.xml</infinispan.log4j.configuration>
+            <infinispan.test.jgroups.protocol>tcp</infinispan.test.jgroups.protocol>
+         </properties>
+      </profile>
    </profiles>
 </project>",2011-11-28T12:29:18Z,152
"@@ -186,24 +186,25 @@ public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) thr
    private Object handleTxCommand(TxInvocationContext ctx, TransactionBoundaryCommand command) throws Throwable {
       // For local commands we may not have a GlobalTransaction yet
       Address address = ctx.isOriginLocal() ? ctx.getOrigin() : ctx.getGlobalTransaction().getAddress();
-      return handleTopologyAffectedCommand(ctx, command, address);
+      return handleTopologyAffectedCommand(ctx, command, address, true);
    }
 
    private Object handleWriteCommand(InvocationContext ctx, WriteCommand command) throws Throwable {
-      return handleTopologyAffectedCommand(ctx, command, ctx.getOrigin());
+      // ISPN-2473 - forward non-transactional commands asynchronously
+      return handleTopologyAffectedCommand(ctx, command, ctx.getOrigin(), false);
    }
 
    @Override
    protected Object handleDefault(InvocationContext ctx, VisitableCommand command) throws Throwable {
       if (command instanceof TopologyAffectedCommand) {
-         return handleTopologyAffectedCommand(ctx, command, ctx.getOrigin());
+         return handleTopologyAffectedCommand(ctx, command, ctx.getOrigin(), true);
       } else {
          return invokeNextInterceptor(ctx, command);
       }
    }
 
    private Object handleTopologyAffectedCommand(InvocationContext ctx, VisitableCommand command,
-                                                Address origin) throws Throwable {
+                                                Address origin, boolean sync) throws Throwable {
       log.tracef(""handleTopologyAffectedCommand for command %s"", command);
 
       if (isLocalOnly(ctx, command)) {
@@ -221,7 +222,7 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, VisitableCom
       }
 
       if (isNonTransactionalWrite || isTransactionalAndNotRolledBack) {
-         stateTransferManager.forwardCommandIfNeeded(((TopologyAffectedCommand)command), getAffectedKeys(ctx, command), origin, true);
+         stateTransferManager.forwardCommandIfNeeded(((TopologyAffectedCommand)command), getAffectedKeys(ctx, command), origin, sync);
       }
 
       return localResult;",2013-01-04T14:44:38Z,115
"@@ -62,6 +62,8 @@ protected void createCacheManagers() throws Throwable {
       CacheContainer first = TestCacheManagerFactory.createCacheManager(GlobalConfiguration.getClusteredDefault(), cfg);
       CacheContainer second = TestCacheManagerFactory.createCacheManager(GlobalConfiguration.getClusteredDefault(), cfg);
       registerCacheManager(first, second);
+      // wait for the coordinator to install the balanced CH, otherwise StateTransferInterceptor will duplicate the command (via forwarding)
+      waitForClusterToForm();
    }
 
    public void testConcurrentFlush(Method m) throws Exception {
@@ -77,7 +79,7 @@ public void testConcurrentFlush(Method m) throws Exception {
       final String v = ""v-"" + m.getName();
       cache1.put(k, v);
       // Wait for periodic repl queue task to try repl the single modification
-      secondPutLatch.await();
+      secondPutLatch.await(10, TimeUnit.SECONDS);
       // Put something random so that after remove call, the element number exceeds
       cache1.put(""k-blah"",""v-blah"");
       cache1.remove(k);",2013-01-04T14:44:38Z,537
"@@ -0,0 +1,280 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.statetransfer;
+
+import java.util.concurrent.BrokenBarrierException;
+import java.util.concurrent.Callable;
+import java.util.concurrent.Future;
+import java.util.concurrent.SynchronousQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.TimeoutException;
+import java.util.concurrent.atomic.AtomicInteger;
+
+import org.infinispan.Cache;
+import org.infinispan.commands.tx.PrepareCommand;
+import org.infinispan.commands.write.PutKeyValueCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.context.impl.TxInvocationContext;
+import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.topology.CacheTopology;
+import org.infinispan.transaction.LocalTransaction;
+import org.testng.annotations.Test;
+
+import static org.infinispan.test.TestingUtil.extractComponent;
+import static org.infinispan.test.TestingUtil.findInterceptor;
+import static org.infinispan.test.TestingUtil.waitForRehashToComplete;
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNotNull;
+import static org.testng.Assert.assertTrue;
+
+/**
+ * Test that command forwarding works during/after state transfer.
+ *
+ * @author Dan Berindei
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplCommandForwardingTest"")
+@CleanupAfterMethod
+public class ReplCommandForwardingTest extends MultipleCacheManagersTest {
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      // do nothing, each test will create its own cache managers
+   }
+
+   private ConfigurationBuilder buildConfig(boolean transactional) {
+      ConfigurationBuilder configurationBuilder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, transactional);
+      configurationBuilder.clustering().sync().replTimeout(10000);
+      configurationBuilder.clustering().stateTransfer().fetchInMemoryState(true);
+      configurationBuilder.customInterceptors().addInterceptor().after(StateTransferInterceptor.class).interceptor(new DelayInterceptor());
+      return configurationBuilder;
+   }
+
+   public void testForwardToJoinerNonTransactional() throws Exception {
+      EmbeddedCacheManager cm1 = addClusterEnabledCacheManager(buildConfig(false));
+      final Cache<Object, Object> c1 = cm1.getCache();
+      DelayInterceptor di1 = findInterceptor(c1, DelayInterceptor.class);
+
+      EmbeddedCacheManager cm2 = addClusterEnabledCacheManager(buildConfig(false));
+      Cache<Object, Object> c2 = cm2.getCache();
+      DelayInterceptor di2 = findInterceptor(c2, DelayInterceptor.class);
+      waitForStateTransfer(2, c1, c2);
+
+      Future<Object> f = fork(new Callable<Object>() {
+         @Override
+         public Object call() throws Exception {
+            log.tracef(""Initiating a put command on %s"", c1);
+            // The put command is replicated to cache c2, and it blocks in the DelayInterceptor.
+            c1.put(""k"", ""v"");
+            return null;
+         }
+      });
+
+      // c3 joins, topology id changes
+      EmbeddedCacheManager cm3 = addClusterEnabledCacheManager(buildConfig(false));
+      Cache<Object, Object> c3 = cm3.getCache();
+      DelayInterceptor di3 = findInterceptor(c3, DelayInterceptor.class);
+      waitForStateTransfer(4, c1, c2, c3);
+
+      // Unblock the replicated command on c2.
+      // StateTransferInterceptor will forward the command to c3.
+      // The DelayInterceptor on c3 will then block, waiting for an unblock() call.
+      log.tracef(""Forwarding the command from %s"", c2);
+      di2.unblock();
+
+      // Wait to ensure that the c3 receives the forwarded commands in the ""right"" order
+      Thread.sleep(1000);
+
+      // Unblock the command on the originator (c1), while forwarding is still in progress.
+      // StateTransferInterceptor will forward the command to c2 and c3.
+      di1.unblock();
+
+      // Unblock the command forwarded from c1 on c2 (c2 won't forward the command again).
+      // Don't unblock the command on c3, because we'd actually unblock the command forwarded from c2.
+      di2.unblock();
+
+      // c4 joins, topology id changes
+      EmbeddedCacheManager cm4 = addClusterEnabledCacheManager(buildConfig(false));
+      Cache<Object, Object> c4 = cm4.getCache();
+      DelayInterceptor di4 = findInterceptor(c4, DelayInterceptor.class);
+      waitForStateTransfer(6, c1, c2, c3, c4);
+
+      // Allow command forwarded from c2 to proceed on c3.
+      // StateTransferInterceptor will then forward the command to c1 and c4.
+      log.tracef(""Forwarding the command from %s"", c3);
+      di3.unblock();
+
+      // Check that c1 and c4 receive the forwarded command (no extra forwarding).
+      di1.unblock();
+      di4.unblock();
+
+      // Allow the DelayInterceptor on c3 to proceed again (for the command forwarded from c1).
+      // StateTransferInterceptor will then forward the command to c2 and c4.
+      log.tracef(""Forwarding the command from %s for a second time"", c3);
+      di3.unblock();
+
+      // Check that c2 and c4 receive the forwarded command (no extra forwarding).
+      di2.unblock();
+      di4.unblock();
+
+      log.tracef(""Waiting for the put command to finish on %s"", c1);
+      f.get(10, TimeUnit.SECONDS);
+      log.tracef(""Put command finished on %s"", c1);
+
+      // 1 direct invocation + 1 forwarded by c3
+      assertEquals(di1.getCounter(), 2);
+      // 1 from replication + 1 forwarded by c1 + 1 re-forwarded by c3
+      assertEquals(di2.getCounter(), 3);
+      // 1 forwarded by c2 + 1 forwarded by c1
+      assertEquals(di3.getCounter(), 2);
+      // 1 forwarded by c3 + 1 re-forwarded by c3
+      assertEquals(di4.getCounter(), 2);
+   }
+
+   public void testForwardToJoinerTransactional() throws Exception {
+      EmbeddedCacheManager cm1 = addClusterEnabledCacheManager(buildConfig(true));
+      final Cache<Object, Object> c1 = cm1.getCache();
+      DelayInterceptor di1 = findInterceptor(c1, DelayInterceptor.class);
+
+      EmbeddedCacheManager cm2 = addClusterEnabledCacheManager(buildConfig(true));
+      Cache c2 = cm2.getCache();
+      DelayInterceptor di2 = findInterceptor(c2, DelayInterceptor.class);
+      waitForStateTransfer(2, c1, c2);
+
+      Future<Object> f = fork(new Callable<Object>() {
+         @Override
+         public Object call() throws Exception {
+            log.tracef(""Initiating a transaction on %s"", c1);
+            // The prepare command is replicated to cache c2, and it blocks in the DelayInterceptor.
+            c1.put(""k"", ""v"");
+            return null;
+         }
+      });
+
+      // c3 joins, topology id changes
+      EmbeddedCacheManager cm3 = addClusterEnabledCacheManager(buildConfig(true));
+      Cache c3 = cm3.getCache();
+      DelayInterceptor di3 = findInterceptor(c3, DelayInterceptor.class);
+      waitForStateTransfer(4, c1, c2, c3);
+
+      // Unblock the replicated command on c2.
+      // StateTransferInterceptor will forward the command to c3.
+      // The DelayInterceptor on c3 will then block, waiting for an unblock() call.
+      log.tracef(""Forwarding the prepare command from %s"", c2);
+      di2.unblock();
+
+      // c4 joins, topology id changes
+      EmbeddedCacheManager cm4 = addClusterEnabledCacheManager(buildConfig(true));
+      Cache c4 = cm4.getCache();
+      DelayInterceptor di4 = findInterceptor(c4, DelayInterceptor.class);
+      waitForStateTransfer(6, c1, c2, c3, c4);
+
+      // Unblock the forwarded command on c3.
+      // StateTransferInterceptor will then forward the command to c2 and c4.
+      log.tracef(""Forwarding the prepare command from %s"", c3);
+      di3.unblock();
+
+      // Check that the c2 and c4 received the forwarded command.
+      di2.unblock();
+      di4.unblock();
+
+      // Allow the command to proceed on the originator (c1).
+      // StateTransferInterceptor will forward the command to c2, c3, and c4.
+      log.tracef(""Forwarding the prepare command from %s"", c1);
+      di1.unblock();
+
+      // Check that c2, c3, and c4 received the forwarded command.
+      di2.unblock();
+      di3.unblock();
+      di4.unblock();
+
+      log.tracef(""Waiting for the transaction to finish on %s"", c1);
+      f.get(10, TimeUnit.SECONDS);
+      log.tracef(""Transaction finished on %s"", c1);
+
+      assertEquals(di1.getCounter(), 1);
+      // 1 from replication + 1 re-forwarded by C + 1 forwarded by A
+      assertEquals(di2.getCounter(), 3);
+      // 1 forwarded by B + 1 forwarded by A
+      assertEquals(di3.getCounter(), 2);
+      // 1 re-1forwarded by C + 1 forwarded by A
+      assertEquals(di4.getCounter(), 2);
+   }
+
+   private void waitForStateTransfer(int expectedTopologyId, Cache... caches) {
+      waitForRehashToComplete(caches);
+      for (Cache c : caches) {
+         CacheTopology cacheTopology = extractComponent(c, StateTransferManager.class).getCacheTopology();
+         assertEquals(cacheTopology.getTopologyId(), expectedTopologyId,
+               String.format(""Wrong topology on cache %s, expected %d and got %s"",
+                     c, expectedTopologyId, cacheTopology));
+      }
+   }
+
+   private class DelayInterceptor extends CommandInterceptor {
+      private final AtomicInteger counter = new AtomicInteger(0);
+      private final SynchronousQueue<Object> barrier = new SynchronousQueue<Object>(true);
+
+      public int getCounter() {
+         return counter.get();
+      }
+
+      public void unblock() throws InterruptedException, TimeoutException, BrokenBarrierException {
+         boolean offerResult = barrier.offer(""bla"", 5, TimeUnit.SECONDS);
+         assertTrue(offerResult);
+      }
+
+      @Override
+      public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
+         Object result = super.visitPutKeyValueCommand(ctx, command);
+
+         if (!ctx.isInTxScope() && !command.hasFlag(Flag.PUT_FOR_STATE_TRANSFER)) {
+            log.tracef(""Delaying command %s"", command);
+            counter.incrementAndGet();
+            Object pollResult = barrier.poll(3, TimeUnit.SECONDS);
+            assertNotNull(pollResult, ""Timed out waiting for unblock() call"");
+         }
+         return result;
+      }
+
+      @Override
+      public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand command) throws Throwable {
+         Object result = super.visitPrepareCommand(ctx, command);
+         if (!ctx.isOriginLocal() || !((LocalTransaction)ctx.getCacheTransaction()).isFromStateTransfer()) {
+            log.tracef(""Delaying command %s"", command);
+            counter.incrementAndGet();
+            Object pollResult = barrier.poll(3, TimeUnit.SECONDS);
+            assertNotNull(pollResult, ""Timed out waiting for unblock() call"");
+         }
+         return result;
+      }
+
+      @Override
+      public String toString() {
+         return ""DelayInterceptor{counter="" + counter + ""}"";
+      }
+   }
+}",2013-01-04T14:44:38Z,538
"@@ -106,7 +106,9 @@ public Object perform(InvocationContext ignored) throws Throwable {
       RemoteTransaction remoteTransaction = txTable.getOrCreateRemoteTransaction(globalTx, modifications);
       //set the list of modifications anyway, as the transaction might have already been created by a previous
       //LockControlCommand with null modifications.
-      remoteTransaction.setModifications(getModifications());
+      if (hasModifications()) {
+         remoteTransaction.setModifications(Arrays.asList(modifications));
+      }
 
       // 2. then set it on the invocation context
       RemoteTxInvocationContext ctx = icc.createRemoteTxInvocationContext(remoteTransaction, getOrigin());",2013-01-30T11:04:59Z,539
"@@ -41,7 +41,7 @@
 public interface TxInvocationContext extends InvocationContext {
 
    /**
-    * Were there any modifications performed within the tx's scope?
+    * Checks if there are modifications performed within the tx's scope. Any modifications having Flag.CACHE_MODE_LOCAL are ignored.
     */
    boolean hasModifications();
 
@@ -57,7 +57,8 @@ public interface TxInvocationContext extends InvocationContext {
    GlobalTransaction getGlobalTransaction();
 
    /**
-    * Returns all the modifications performed in the scope of the current transaction.
+    * Returns the modifications performed in the scope of the current transaction. Any modifications having Flag.CACHE_MODE_LOCAL are ignored.
+    * The returned list can be null.
     */
    List<WriteCommand> getModifications();
 ",2013-01-30T11:04:59Z,540
"@@ -149,7 +149,7 @@ public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command)
    }
 
    protected void commitCommand(TxInvocationContext ctx) throws Throwable {
-      if (ctx.hasModifications()) {
+      if (!ctx.getCacheTransaction().getAllModifications().isEmpty()) {
          // this is a commit call.
          GlobalTransaction tx = ctx.getGlobalTransaction();
          if (getLog().isTraceEnabled()) getLog().tracef(""Calling loader.commit() for transaction %s"", tx);
@@ -187,7 +187,7 @@ protected void commitCommand(TxInvocationContext ctx) throws Throwable {
    public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand command) throws Throwable {
       if (!skip(ctx)) {
          if (getLog().isTraceEnabled()) getLog().trace(""Transactional so don't put stuff in the cache store yet."");
-         if (ctx.hasModifications()) {
+         if (!ctx.getCacheTransaction().getAllModifications().isEmpty()) {
             GlobalTransaction tx = ctx.getGlobalTransaction();
             // this is a rollback method
             if (preparingTxs.containsKey(tx)) {
@@ -282,15 +282,19 @@ protected final void prepareCacheLoader(TxInvocationContext ctx, GlobalTransacti
       if (transactionContext == null) {
          throw new Exception(""transactionContext for transaction "" + gtx + "" not found in transaction table"");
       }
-      List<WriteCommand> modifications = transactionContext.getModifications();
 
-      if (!transactionContext.hasModifications()) {
+      List<WriteCommand> modifications = transactionContext.getCacheTransaction().getAllModifications();
+      if (modifications.isEmpty()) {
          if (getLog().isTraceEnabled()) getLog().trace(""Transaction has not logged any modifications!"");
          return;
       }
       if (getLog().isTraceEnabled()) getLog().tracef(""Cache loader modification list: %s"", modifications);
       StoreModificationsBuilder modsBuilder = new StoreModificationsBuilder(getStatisticsEnabled(), modifications.size());
-      for (WriteCommand cacheCommand : modifications) cacheCommand.acceptVisitor(ctx, modsBuilder);
+      for (WriteCommand cacheCommand : modifications) {
+         if (!skip(ctx, cacheCommand)) {
+            cacheCommand.acceptVisitor(ctx, modsBuilder);
+         }
+      }
       int numMods = modsBuilder.modifications.size();
       if (getLog().isTraceEnabled()) getLog().tracef(""Converted method calls to cache loader modifications.  List size: %s"", numMods);
 
@@ -326,23 +330,19 @@ public StoreModificationsBuilder(boolean generateStatistics, int numMods) {
          this.generateStatistics = generateStatistics;
          affectedKeys = new HashSet<Object>(numMods);
          modifications = new ArrayList<Modification>(numMods);
-
       }
 
       @Override
-      @SuppressWarnings(""unchecked"")
       public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
          return visitSingleStore(ctx, command.getKey());
       }
 
       @Override
-      @SuppressWarnings(""unchecked"")
       public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
          return visitSingleStore(ctx, command.getKey());
       }
 
       @Override
-      @SuppressWarnings(""unchecked"")
       public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
          Map<Object, Object> map = command.getMap();
          for (Object key : map.keySet())
@@ -351,7 +351,6 @@ public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) t
       }
 
       @Override
-      @SuppressWarnings(""unchecked"")
       public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
          Object key = command.getKey();
          if (!skipKey(key)) {
@@ -362,7 +361,6 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
       }
 
       @Override
-      @SuppressWarnings(""unchecked"")
       public Object visitClearCommand(InvocationContext ctx, ClearCommand command) throws Throwable {
          modifications.add(new Clear());
          return null;
@@ -392,7 +390,6 @@ public void resetStatistics() {
          displayName = ""Number of cache stores"",
          measurementType = MeasurementType.TRENDSUP
    )
-
    public long getCacheLoaderStores() {
       return cacheStores.get();
    }",2013-01-30T11:04:59Z,145
"@@ -28,7 +28,6 @@
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
 
-import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.GetKeyValueCommand;
@@ -242,11 +241,9 @@ private void enlistIfNeeded(InvocationContext ctx) throws SystemException {
 
    private Object enlistWriteAndInvokeNext(InvocationContext ctx, WriteCommand command) throws Throwable {
       LocalTransaction localTransaction = null;
-      boolean shouldAddMod = false;
       if (shouldEnlist(ctx)) {
          localTransaction = enlist((TxInvocationContext) ctx);
          LocalTxInvocationContext localTxContext = (LocalTxInvocationContext) ctx;
-         if (localModeNotForced(command)) shouldAddMod = true;
          localTxContext.setLocalTransaction(localTransaction);
       }
       Object rv;
@@ -260,7 +257,7 @@ private Object enlistWriteAndInvokeNext(InvocationContext ctx, WriteCommand comm
          }
          throw throwable;
       }
-      if (command.isSuccessful() && shouldAddMod) localTransaction.addModification(command);
+      if (command.isSuccessful() && localTransaction != null) localTransaction.addModification(command);
       return rv;
    }
 
@@ -285,14 +282,6 @@ private static boolean shouldEnlist(InvocationContext ctx) {
       return ctx.isInTxScope() && ctx.isOriginLocal();
    }
 
-   private boolean localModeNotForced(FlagAffectedCommand command) {
-      if (command.hasFlag(Flag.CACHE_MODE_LOCAL)) {
-         if (getLog().isTraceEnabled()) getLog().debug(""LOCAL mode forced on invocation.  Suppressing clustered events."");
-         return false;
-      }
-      return true;
-   }
-
    @ManagedOperation(
          description = ""Resets statistics gathered by this component"",
          displayName = ""Reset Statistics""",2013-01-30T11:04:59Z,87
"@@ -233,6 +233,7 @@ private CacheTopology getCacheTopology(int requestTopologyId, Address destinatio
    private void collectTransactionsToTransfer(List<TransactionInfo> transactionsToTransfer,
                                               Collection<? extends CacheTransaction> transactions,
                                               Set<Integer> segments, ConsistentHash readCh) {
+      // no need to filter out state transfer generated transactions because there should not be any such transactions running for any of the requested segments
       for (CacheTransaction tx : transactions) {
          // transfer only locked keys that belong to requested segments
          Set<Object> filteredLockedKeys = new HashSet<Object>();
@@ -255,7 +256,7 @@ private void collectTransactionsToTransfer(List<TransactionInfo> transactionsToT
          if (!filteredLockedKeys.isEmpty()) {
             List<WriteCommand> txModifications = tx.getModifications();
             WriteCommand[] modifications = null;
-            if (txModifications != null) {
+            if (!txModifications.isEmpty()) {
                modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
             }
             transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), tx.getTopologyId(), modifications, filteredLockedKeys));",2013-01-30T11:04:59Z,55
"@@ -23,7 +23,6 @@
 
 package org.infinispan.transaction;
 
-import java.util.Arrays;
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.Collections;
@@ -37,6 +36,7 @@
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.versioning.EntryVersion;
 import org.infinispan.container.versioning.EntryVersionsMap;
+import org.infinispan.context.Flag;
 import org.infinispan.transaction.xa.CacheTransaction;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.InfinispanCollections;
@@ -59,6 +59,7 @@ public abstract class AbstractCacheTransaction implements CacheTransaction {
    private static final boolean trace = log.isTraceEnabled();
    private static final int INITIAL_LOCK_CAPACITY = 4;
 
+   protected volatile boolean hasLocalOnlyModifications;
    protected volatile List<WriteCommand> modifications;
    protected HashMap<Object, CacheEntry> lookedUpEntries;
 
@@ -107,18 +108,43 @@ public GlobalTransaction getGlobalTransaction() {
    }
 
    @Override
-   public List<WriteCommand> getModifications() {
-      return modifications;
+   public final List<WriteCommand> getModifications() {
+      if (hasLocalOnlyModifications) {
+         List<WriteCommand> mods = new ArrayList<WriteCommand>();
+         for (WriteCommand cmd : modifications) {
+            if (!cmd.hasFlag(Flag.CACHE_MODE_LOCAL)) {
+               mods.add(cmd);
+            }
+         }
+         return mods;
+      } else {
+         return getAllModifications();
+      }
    }
 
-   public void setModifications(WriteCommand[] modifications) {
+   @Override
+   public final List<WriteCommand> getAllModifications() {
+      return modifications == null ? InfinispanCollections.<WriteCommand>emptyList() : modifications;
+   }
+
+   public final void setModifications(List<WriteCommand> modifications) {
+      if (modifications == null) {
+         throw new IllegalArgumentException(""modification list cannot be null"");
+      }
+      List<WriteCommand> mods = new ArrayList<WriteCommand>();
+      for (WriteCommand cmd : modifications) {
+         if (cmd.hasFlag(Flag.CACHE_MODE_LOCAL)) {
+            hasLocalOnlyModifications = true;
+         }
+         mods.add(cmd);
+      }
       // we need to synchronize this collection to be able to get a valid copy from another thread during state transfer
-      this.modifications = Collections.synchronizedList(new ArrayList<WriteCommand>(Arrays.asList(modifications)));
+      this.modifications = Collections.synchronizedList(mods);
    }
 
-   public boolean hasModification(Class modificationClass) {
+   public final boolean hasModification(Class<?> modificationClass) {
       if (modifications != null) {
-         for (WriteCommand mod : modifications) {
+         for (WriteCommand mod : getModifications()) {
             if (modificationClass.isAssignableFrom(mod.getClass())) {
                return true;
             }",2013-01-30T11:04:59Z,541
"@@ -95,9 +95,9 @@ private void removeTransactionInfoRemotely(LocalTransaction localTransaction, Gl
    }
 
    private boolean mayHaveRemoteLocks(LocalTransaction lt) {
-      return (lt.getRemoteLocksAcquired() != null && !lt.getRemoteLocksAcquired().isEmpty()) ||
-            (lt.getModifications() != null && !lt.getModifications().isEmpty()) ||
-            (isPessimisticLocking && lt.getTopologyId() != rpcManager.getTopologyId());
+      return lt.getRemoteLocksAcquired() != null && !lt.getRemoteLocksAcquired().isEmpty() ||
+            !lt.getModifications().isEmpty() ||
+            isPessimisticLocking && lt.getTopologyId() != rpcManager.getTopologyId();
    }
 
    /**",2013-01-30T11:04:59Z,542
"@@ -27,6 +27,7 @@
 import org.infinispan.commands.write.ClearCommand;
 import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.context.Flag;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.InfinispanCollections;
@@ -39,7 +40,6 @@
 import java.util.HashMap;
 import java.util.HashSet;
 import java.util.LinkedList;
-import java.util.List;
 import java.util.Map;
 import java.util.Set;
 
@@ -71,12 +71,15 @@ public LocalTransaction(Transaction transaction, GlobalTransaction tx, boolean i
       this.implicitTransaction = implicitTransaction;
    }
 
-   public void addModification(WriteCommand mod) {
+   public final void addModification(WriteCommand mod) {
       if (trace) log.tracef(""Adding modification %s. Mod list is %s"", mod, modifications);
       if (modifications == null) {
          // we need to synchronize this collection to be able to get a valid snapshot from another thread during state transfer
          modifications = Collections.synchronizedList(new LinkedList<WriteCommand>());
       }
+      if (mod.hasFlag(Flag.CACHE_MODE_LOCAL)) {
+         hasLocalOnlyModifications = true;
+      }
       modifications.add(mod);
    }
 
@@ -165,10 +168,6 @@ public String toString() {
             ""} "" + super.toString();
    }
 
-   public void setModifications(List<WriteCommand> modifications) {
-      this.modifications = modifications;
-   }
-
    @Override
    public void addReadKey(Object key) {
       if (readKeys == null) readKeys = new HashSet<Object>(2);",2013-01-30T11:04:59Z,454
"@@ -32,7 +32,6 @@
 
 import java.util.ArrayList;
 import java.util.Arrays;
-import java.util.Collections;
 import java.util.HashMap;
 import java.util.LinkedList;
 import java.util.Map;",2013-01-30T11:04:59Z,543
"@@ -45,11 +45,24 @@ public interface CacheTransaction {
    GlobalTransaction getGlobalTransaction();
 
    /**
-    * Returns the modifications visible within the current transaction.
+    * Returns the modifications visible within the current transaction. Any modifications using Flag#CACHE_MODE_LOCAL are excluded.
+    * The returned list is never null.
     */
    List<WriteCommand> getModifications();
 
-   boolean hasModification(Class modificationClass);
+   /**
+    * Returns all the modifications visible within the current transaction, including those using Flag#CACHE_MODE_LOCAL.
+    * The returned list is never null.
+    */
+   List<WriteCommand> getAllModifications();
+
+   /**
+    * Checks if a modification of the given class (or subclass) is present in this transaction. Any modifications using Flag#CACHE_MODE_LOCAL are ignored.
+    *
+    * @param modificationClass the modification type to look for
+    * @return true if found, false otherwise
+    */
+   boolean hasModification(Class<?> modificationClass);
 
    CacheEntry lookupEntry(Object key);
 ",2013-01-30T11:04:59Z,544
"@@ -0,0 +1,109 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.eviction.EvictionStrategy;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.transaction.TransactionMode;
+import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
+import org.infinispan.util.concurrent.IsolationLevel;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.testng.annotations.Test;
+
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Short test to reproduce the scenario form MODE-1754 (https://issues.jboss.org/browse/MODE-1754).
+ * <p/>
+ * This test passes on 5.1.x but fails on 5.2 so we need to investigate further.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplStateTransferCacheLoaderTest"")
+@CleanupAfterMethod
+public class ReplStateTransferCacheLoaderTest extends MultipleCacheManagersTest {
+
+   private static final Log log = LogFactory.getLog(ReplStateTransferCacheLoaderTest.class);
+
+   private ConfigurationBuilder builder;
+
+   @Override
+   protected void createCacheManagers() {
+      TestingUtil.recursiveFileRemove(""./target/tmp"");
+
+      // reproduce the MODE-1754 config as closely as possible
+      builder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, true, true);
+      builder.transaction().transactionMode(TransactionMode.TRANSACTIONAL).lockingMode(LockingMode.PESSIMISTIC)
+            .transactionManagerLookup(new DummyTransactionManagerLookup())
+            .eviction().maxEntries(1000).strategy(EvictionStrategy.LIRS)
+            .locking().lockAcquisitionTimeout(20000)
+            .concurrencyLevel(5000) // lowering this to 50 makes the test pass also on 5.2 but it's just a temporary workaround
+            .useLockStriping(false).writeSkewCheck(false).isolationLevel(IsolationLevel.READ_COMMITTED)
+            .dataContainer().storeAsBinary()
+            .clustering().sync().replTimeout(20000)
+            .stateTransfer().timeout(240000).fetchInMemoryState(false).chunkSize(0)
+            .loaders().passivation(false).shared(false).preload(false).addFileCacheStore().location(""./target/tmp/store_0"")
+            .fetchPersistentState(true)
+            .purgerThreads(3)
+            .purgeSynchronously(true)
+            .ignoreModifications(false)
+            .purgeOnStartup(false);
+
+      createCluster(builder, 1);
+      waitForClusterToForm();
+   }
+
+   public void testStateTransfer() throws Exception {
+      final int numKeys = 300;
+      for (int i = 0; i < numKeys; i++) {
+         cache(0).put(i, i);
+      }
+      log.info(""Finished putting keys"");
+
+      for (int i = 0; i < numKeys; i++) {
+         assertEquals(i, cache(0).get(i));
+      }
+
+      log.info(""Adding a new node .."");
+      builder.loaders().clearCacheLoaders().addFileCacheStore().location(""./target/tmp/store_1"")   // make sure this node writes in a different location
+            .fetchPersistentState(true)
+            .purgerThreads(3)
+            .purgeSynchronously(true)
+            .ignoreModifications(false)
+            .purgeOnStartup(false);
+
+      addClusterEnabledCacheManager(builder);
+      log.info(""Added a new node"");
+
+      for (int i = 0; i < numKeys; i++) {
+         assertEquals(i, cache(1).get(i));   // some keys are lost in 5.2
+      }
+   }
+}",2013-01-30T11:04:59Z,545
"@@ -491,6 +491,15 @@ public void purge(File f) throws IOException {
          // cos any cached file channel write won't change the file's exists
          // status. So, clear the file rather than delete it.
          FileChannel channel = streams.get(f.getPath());
+         if (channel == null) {
+            channel = createChannel(f);
+            String path = f.getPath();
+            FileChannel existingChannel = streams.putIfAbsent(path, channel);
+            if (existingChannel != null) {
+               Util.close(channel);
+               channel = existingChannel;
+            }
+         }
          channel.truncate(0);
          // Apart from truncating, it's necessary to reset the position!
          channel.position(0);",2011-06-27T13:03:20Z,178
"@@ -125,6 +125,9 @@ public void testLoadAndStoreImmortal() throws CacheLoaderException {
       assert cs.load(""k"").getMaxIdle() == -1;
       assert !cs.load(""k"").isExpired();
       assert cs.containsKey(""k"");
+
+      boolean removed = cs.remove(""k2"");
+      assert !removed;
    }
 
    public void testLoadAndStoreWithLifespan() throws Exception {",2011-06-27T13:03:20Z,84
"@@ -122,6 +122,22 @@ public void testBucketRemoval() throws Exception {
       checkBucketExists(b);
    }
 
+   public void testCacheStoreRebootable() throws Exception {
+      String key = ""testCacheStoreRebootable"";
+      InternalCacheEntry se = InternalEntryFactory.create(key, ""initialValue"");
+      fcs.store(se);
+      Bucket b = fcs.loadBucketContainingKey(key);
+
+      //stop and restart it:
+      fcs.stop();
+      fcs.start();
+
+      InternalCacheEntry entry = b.getEntry(key);
+      entry.setValue(""updatedValue"");
+      fcs.updateBucket(b);
+      ""updatedValue"".equals(fcs.load(key).getValue());
+   }
+
    protected void checkBucketExists(Bucket b) {
       File file = new File(fcs.root, b.getBucketIdAsString());
       assert file.exists();",2011-06-27T13:03:20Z,546
"@@ -79,6 +79,7 @@
 import org.infinispan.statetransfer.StateChunk;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.xa.DldGlobalTransaction;
@@ -128,6 +129,7 @@ public class CommandsFactoryImpl implements CommandsFactory {
    private LockManager lockManager;
    private InternalEntryFactory entryFactory;
    private MapReduceManager mapReduceManager;
+   private StateTransferManager stateTransferManager;
 
    private Map<Byte, ModuleCommandInitializer> moduleCommandInitializers;
 
@@ -137,7 +139,7 @@ public void setupDependencies(DataContainer container, CacheNotifier notifier, C
                                  InvocationContextContainer icc, TransactionTable txTable, Configuration configuration,
                                  @ComponentName(KnownComponentNames.MODULE_COMMAND_INITIALIZERS) Map<Byte, ModuleCommandInitializer> moduleCommandInitializers,
                                  RecoveryManager recoveryManager, StateProvider stateProvider, StateConsumer stateConsumer,
-                                 LockManager lockManager, InternalEntryFactory entryFactory, MapReduceManager mapReduceManager) {
+                                 LockManager lockManager, InternalEntryFactory entryFactory, MapReduceManager mapReduceManager, StateTransferManager stm) {
       this.dataContainer = container;
       this.notifier = notifier;
       this.cache = cache;
@@ -153,6 +155,7 @@ public void setupDependencies(DataContainer container, CacheNotifier notifier, C
       this.lockManager = lockManager;
       this.entryFactory = entryFactory;
       this.mapReduceManager = mapReduceManager;
+      this.stateTransferManager = stm;
    }
 
    @Start(priority = 1)
@@ -402,7 +405,7 @@ public void initializeReplicableCommand(ReplicableCommand c, boolean isRemote) {
             break;
          case TxCompletionNotificationCommand.COMMAND_ID:
             TxCompletionNotificationCommand ftx = (TxCompletionNotificationCommand) c;
-            ftx.init(txTable, lockManager, recoveryManager);
+            ftx.init(txTable, lockManager, recoveryManager, stateTransferManager);
             break;
          case MapCombineCommand.COMMAND_ID:
             MapCombineCommand mrc = (MapCombineCommand)c;",2012-10-12T16:37:21Z,111
"@@ -36,7 +36,7 @@
  * @author Sanne Grinovero <sanne@hibernate.org> (C) 2011 Red Hat Inc.
  * @since 5.0
  */
-public interface FlagAffectedCommand extends TopologyAffectedCommand {
+public interface FlagAffectedCommand extends VisitableCommand, TopologyAffectedCommand {
    
    /**
     * @return the Flags which where set in the context - only valid to invoke after {@link #setFlags(Set)}",2012-10-12T16:37:21Z,112
"@@ -28,7 +28,7 @@
  * @author anistor@redhat.com
  * @since 5.2
  */
-public interface TopologyAffectedCommand extends VisitableCommand {
+public interface TopologyAffectedCommand extends ReplicableCommand {
 
    int getTopologyId();
 ",2012-10-12T16:37:21Z,113
"@@ -22,7 +22,9 @@
  */
 package org.infinispan.commands.remote.recovery;
 
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.context.InvocationContext;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.xa.GlobalTransaction;
@@ -32,14 +34,15 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.xa.Xid;
+import java.util.Set;
 
 /**
  * Command for removing recovery related information from the cluster.
  *
  * @author Mircea.Markus@jboss.com
  * @since 5.0
  */
-public class TxCompletionNotificationCommand extends RecoveryCommand {
+public class TxCompletionNotificationCommand  extends RecoveryCommand implements TopologyAffectedCommand {
 
    private static Log log = LogFactory.getLog(TxCompletionNotificationCommand.class);
 
@@ -50,6 +53,8 @@ public class TxCompletionNotificationCommand extends RecoveryCommand {
    private GlobalTransaction gtx;
    private TransactionTable txTable;
    private LockManager lockManager;
+   private StateTransferManager stateTransferManager;
+   private int topologyId;
 
    private TxCompletionNotificationCommand() {
       super(null); // For command id uniqueness test
@@ -61,10 +66,11 @@ public TxCompletionNotificationCommand(Xid xid, GlobalTransaction gtx, String ca
       this.gtx = gtx;
    }
 
-   public void init(TransactionTable tt, LockManager lockManager, RecoveryManager rm) {
+   public void init(TransactionTable tt, LockManager lockManager, RecoveryManager rm, StateTransferManager stm) {
       super.init(rm);
       this.txTable = tt;
       this.lockManager = lockManager;
+      this.stateTransferManager = stm;
    }
 
 
@@ -77,6 +83,21 @@ public TxCompletionNotificationCommand(String cacheName) {
       super(cacheName);
    }
 
+   @Override
+   public int getTopologyId() {
+      return topologyId;
+   }
+
+   @Override
+   public void setTopologyId(int topologyId) {
+      this.topologyId = topologyId;
+   }
+
+   @Override
+   public boolean isReturnValueExpected() {
+      return false;
+   }
+
    @Override
    public Object perform(InvocationContext ctx) throws Throwable {
       log.tracef(""Processing completed transaction %s"", gtx);
@@ -92,10 +113,21 @@ public Object perform(InvocationContext ctx) throws Throwable {
          remoteTx = txTable.removeRemoteTransaction(gtx);
       }
       if (remoteTx == null) return null;
+      forwardCommandRemotely(remoteTx);
+
       lockManager.unlock(remoteTx.getLockedKeys(), remoteTx.getGlobalTransaction());
       return null;
    }
 
+   /**
+    * This only happens during state transfer.
+    */
+   private void forwardCommandRemotely(RemoteTransaction remoteTx) {
+      Set<Object> affectedKeys = remoteTx.getAffectedKeys();
+      log.tracef(""Invoking forward of TxCompletionNotification for transaction %s. Affected keys: %w"", gtx, affectedKeys);
+      stateTransferManager.forwardCommandIfNeeded(this, affectedKeys, false);
+   }
+
    @Override
    public byte getCommandId() {
       return COMMAND_ID;
@@ -124,6 +156,7 @@ public String toString() {
       return getClass().getSimpleName() +
             ""{ xid="" + xid +
             "", internalId="" + internalId +
+            "", topologyId="" + topologyId +
             "", gtx="" + gtx +
             "", cacheName="" + cacheName + ""} "";
    }",2012-10-12T16:37:21Z,114
"@@ -34,20 +34,18 @@
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.remoting.transport.Address;
-import org.infinispan.topology.CacheTopology;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.*;
+import java.util.Collections;
+import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
 /**
@@ -60,20 +58,16 @@ public class StateTransferInterceptor extends CommandInterceptor {   //todo [ani
 
    private static final Log log = LogFactory.getLog(StateTransferInterceptor.class);
 
-   private final AffectedKeysVisitor affectedKeysVisitor = new AffectedKeysVisitor();
-
    private StateTransferLock stateTransferLock;
 
    private StateTransferManager stateTransferManager;
 
-   private RpcManager rpcManager;
-
    private CommandsFactory commandFactory;
 
-   private long rpcTimeout;
-
    private boolean useVersioning;
 
+   private final AffectedKeysVisitor affectedKeysVisitor = new AffectedKeysVisitor();
+
    @Override
    protected Log getLog() {
       return log;
@@ -83,14 +77,9 @@ protected Log getLog() {
    public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
-      this.rpcManager = rpcManager;
       this.commandFactory = commandFactory;
       this.stateTransferManager = stateTransferManager;
 
-      // no need to retry for asynchronous caches
-      rpcTimeout = configuration.clustering().cacheMode().isSynchronous()
-            ? configuration.clustering().sync().replTimeout() : 0;
-
       useVersioning = configuration.transaction().transactionMode().isTransactional() && configuration.locking().writeSkewCheck() &&
             configuration.transaction().lockingMode() == LockingMode.OPTIMISTIC && configuration.versioning().enabled();
    }
@@ -205,25 +194,32 @@ private Object handleWriteCommand(InvocationContext ctx, WriteCommand command) t
    @Override
    protected Object handleDefault(InvocationContext ctx, VisitableCommand command) throws Throwable {
       if (command instanceof TopologyAffectedCommand) {
-         return handleTopologyAffectedCommand(ctx, (TopologyAffectedCommand) command, ctx.isOriginLocal());
+         return handleTopologyAffectedCommand(ctx, command, ctx.isOriginLocal());
       } else {
          return invokeNextInterceptor(ctx, command);
       }
    }
 
-   private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffectedCommand command,
-                                                boolean originLocal) throws Throwable {
-      boolean cacheModeLocal = false;
-      if (command instanceof FlagAffectedCommand) {
-         cacheModeLocal = ((FlagAffectedCommand)command).hasFlag(Flag.CACHE_MODE_LOCAL);
-      }
-      log.tracef(""handleTopologyAffectedCommand for command %s, originLocal=%s, cacheModeLocal=%s"", command, originLocal
-            , cacheModeLocal);
-      if (originLocal || cacheModeLocal) {
+   private Object handleTopologyAffectedCommand(InvocationContext ctx, VisitableCommand command, boolean originLocal) throws Throwable {
+
+      log.tracef(""handleTopologyAffectedCommand for command %s, originLocal=%s, cacheModeLocal=%s"", command, originLocal);
+
+      if (isLocal(command, originLocal)) {
          return invokeNextInterceptor(ctx, command);
       }
+      updateTopologyIdAndWaitForTransactionData((TopologyAffectedCommand) command);
+
+      // TODO we may need to skip local invocation for read/write/tx commands if the command is too old and none of its keys are local
+      Object localResult = invokeNextInterceptor(ctx, command);
+
+      if (command instanceof TransactionBoundaryCommand || (command instanceof WriteCommand && !ctx.isInTxScope())) {
+         stateTransferManager.forwardCommandIfNeeded(((TopologyAffectedCommand)command), getAffectedKeys(ctx, command), true);
+      }
 
+      return localResult;
+   }
 
+   private void updateTopologyIdAndWaitForTransactionData(TopologyAffectedCommand command) throws InterruptedException {
       // set the topology id if it was not set before (ie. this is local command)
       // TODO Make tx commands extend FlagAffectedCommand so we can use CACHE_MODE_LOCAL in StaleTransactionCleanupService
       if (command.getTopologyId() == -1) {
@@ -233,34 +229,16 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       // remote/forwarded command
       int cmdTopologyId = command.getTopologyId();
       stateTransferLock.waitForTransactionData(cmdTopologyId);
+   }
 
-      // TODO we may need to skip local invocation for read/write/tx commands if the command is too old and none of its keys are local
-      Object localResult = invokeNextInterceptor(ctx, command);
+   private boolean isLocal(VisitableCommand command, boolean originLocal) {
+      if (originLocal) return true;
 
-      // forward commands with older topology ids to their new targets
-      // but we need to make sure we have the latest topology
-      CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
-      int localTopologyId = cacheTopology.getTopologyId();
-      // if it's a tx/lock/write command, forward it to the new owners
-      log.tracef(""CommandTopologyId=%s, localTopologyId=%s"", cmdTopologyId, localTopologyId);
-
-      if (cmdTopologyId < localTopologyId) {
-         if (command instanceof TransactionBoundaryCommand  || (command instanceof WriteCommand && !ctx.isInTxScope())) {
-            ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
-            Set<Object> affectedKeys = getAffectedKeys(ctx, command);
-            Set<Address> newTargets = writeCh.locateAllOwners(affectedKeys);
-            newTargets.remove(rpcManager.getAddress());
-            if (!newTargets.isEmpty()) {
-               // Update the topology id to prevent cycles
-               command.setTopologyId(localTopologyId);
-               log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
-               // TODO find a way to forward the command async if it was received async
-               rpcManager.invokeRemotely(newTargets, command, true, false);
-            }
-         }
+      boolean cacheModeLocal = false;
+      if (command instanceof FlagAffectedCommand) {
+         cacheModeLocal = ((FlagAffectedCommand)command).hasFlag(Flag.CACHE_MODE_LOCAL);
       }
-
-      return localResult;
+      return cacheModeLocal;
    }
 
    @SuppressWarnings(""unchecked"")",2012-10-12T16:37:21Z,115
"@@ -23,14 +23,16 @@
 
 package org.infinispan.statetransfer;
 
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.topology.CacheTopology;
 import org.rhq.helpers.pluginAnnotations.agent.DataType;
 import org.rhq.helpers.pluginAnnotations.agent.Metric;
 
-//todo [anistor] remove this class and move the remaining functionality to StateConsumer
+import java.util.Set;
+
 /**
  * A component that manages the state transfer when the topology of the cluster changes.
  *
@@ -72,4 +74,11 @@ public interface StateTransferManager {
     * @return {@code true} if the local node was the first to start this cache in the cluster.
     */
    boolean isLocalNodeFirst();
+
+   /**
+    * If there is an state transfer happening at the moment, this method forwards the supplied
+    * command to the nodes that are new owners of the data, in order to assure consistency.
+    */
+   void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
+
 }",2012-10-12T16:37:21Z,116
"@@ -23,11 +23,13 @@
 
 package org.infinispan.statetransfer;
 
+import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.Cache;
 import org.infinispan.CacheException;
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.configuration.global.GlobalConfiguration;
@@ -40,6 +42,7 @@
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
 import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheJoinInfo;
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.topology.CacheTopologyHandler;
@@ -242,4 +245,27 @@ public boolean isLocalNodeFirst() {
       return cacheTopology.getMembers().get(0).equals(rpcManager.getAddress());
    }
 
+   @Override
+   public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync) {
+      int cmdTopologyId = command.getTopologyId();
+      // forward commands with older topology ids to their new targets
+      // but we need to make sure we have the latest topology
+      CacheTopology cacheTopology = getCacheTopology();
+      int localTopologyId = cacheTopology.getTopologyId();
+      // if it's a tx/lock/write command, forward it to the new owners
+      log.tracef(""CommandTopologyId=%s, localTopologyId=%s"", cmdTopologyId, localTopologyId);
+
+      if (cmdTopologyId < localTopologyId) {
+         ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
+         Set<Address> newTargets = writeCh.locateAllOwners(affectedKeys);
+         newTargets.remove(rpcManager.getAddress());
+         if (!newTargets.isEmpty()) {
+            // Update the topology id to prevent cycles
+            command.setTopologyId(localTopologyId);
+            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
+            // TODO find a way to forward the command async if it was received async
+            rpcManager.invokeRemotely(newTargets, command, sync, false);
+         }
+      }
+   }
 }
\ No newline at end of file",2012-10-12T16:37:21Z,117
"@@ -52,7 +52,6 @@
 import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.ConfigurationBuilder;
-import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.versioning.EntryVersion;
 import org.infinispan.context.Flag;
 import org.infinispan.distexec.mapreduce.Mapper;
@@ -67,16 +66,12 @@
 import org.infinispan.test.TestingUtil;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
-import org.infinispan.transaction.tm.DummyTransaction;
-import org.infinispan.transaction.tm.DummyTransactionManager;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.concurrent.ReclosableLatch;
 import org.testng.annotations.Test;
 
-import javax.transaction.HeuristicMixedException;
 import javax.transaction.xa.Xid;
 import java.util.Collection;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -104,11 +99,18 @@ protected void createCacheManagers() throws Throwable {
       waitForClusterToForm();
    }
 
-   public void testLockReleasedCorrectly() throws Throwable {
+   public void testBelatedCommit() throws Throwable {
+      testLockReleasedCorrectly(CommitCommand.class);
+   }
+
+   public void testBelatedTxCompletionNotificationCommand() throws Throwable {
+      testLockReleasedCorrectly(TxCompletionNotificationCommand.class);
+   }
 
+   private void testLockReleasedCorrectly(Class<? extends  ReplicableCommand> toBlock ) throws Throwable {
 
       ComponentRegistry componentRegistry = advancedCache(1).getComponentRegistry();
-      final ControlledCommandFactory ccf = new ControlledCommandFactory(componentRegistry.getCommandsFactory());
+      final ControlledCommandFactory ccf = new ControlledCommandFactory(componentRegistry.getCommandsFactory(), toBlock);
       TestingUtil.replaceField(ccf, ""commandsFactory"", componentRegistry, ComponentRegistry.class);
 
       //hack: re-add the component registry to the GlobalComponentRegistry's ""namedComponents"" (CHM) in order to correctly publish it for
@@ -137,7 +139,7 @@ public Object call() throws Exception {
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            return ccf.receivedCommits.get() == 1;
+            return ccf.receivedCommands.get() == 1;
          }
       });
 
@@ -153,17 +155,12 @@ public boolean isSatisfied() throws Exception {
       }
 
       log.tracef(""Number of migrated keys is %s"", migratedKeys.size());
-      System.out.println(""Number of migrated tx is "" + migratedKeys.size());
       if (migratedKeys.size() == 0) return;
 
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            int remoteTxCount = TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount();
-            int localTxCount = TestingUtil.getTransactionTable(cache(2)).getLocalTxCount();
-            log.trace(""remoteTxCount = "" + remoteTxCount);
-            log.trace(""localTxCount = "" + localTxCount);
-            return remoteTxCount == 1;
+            return TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount() == 1;
          }
       });
 
@@ -173,7 +170,8 @@ public boolean isSatisfied() throws Exception {
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            return TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount() == 0;
+            int remoteTxCount = TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount();
+            return remoteTxCount == 0;
          }
       });
 
@@ -189,6 +187,12 @@ public boolean isSatisfied() throws Exception {
          assertNotLocked(key);
          assertEquals(key, cache(0).get(key));
       }
+
+      for (Object k : migratedKeys) {
+         assertFalse(advancedCache(0).getDataContainer().containsKey(k));
+         assertFalse(advancedCache(1).getDataContainer().containsKey(k));
+         assertTrue(advancedCache(2).getDataContainer().containsKey(k));
+      }
    }
 
    private boolean keyMapsToNode(Object key, int nodeIndex) {
@@ -203,10 +207,12 @@ private Address owner(Object key) {
    public class ControlledCommandFactory implements CommandsFactory {
       final CommandsFactory actual;
       final ReclosableLatch gate = new ReclosableLatch(true);
-      final AtomicInteger receivedCommits = new AtomicInteger(0);
+      final AtomicInteger receivedCommands = new AtomicInteger(0);
+      final Class<? extends  ReplicableCommand> toBlock;
 
-      public ControlledCommandFactory(CommandsFactory actual) {
+      public ControlledCommandFactory(CommandsFactory actual, Class<? extends  ReplicableCommand> toBlock) {
          this.actual = actual;
+         this.toBlock = toBlock;
       }
 
       @Override
@@ -316,11 +322,11 @@ public RollbackCommand buildRollbackCommand(GlobalTransaction gtx) {
 
       @Override
       public void initializeReplicableCommand(ReplicableCommand command, boolean isRemote) {
-         if (isRemote && command instanceof CommitCommand) {
-            receivedCommits.incrementAndGet();
+         if (isRemote && command.getClass().isAssignableFrom(toBlock)) {
+            receivedCommands.incrementAndGet();
             try {
                gate.await();
-               log.tracef(""gate is opened, processing the commit:  %s"", command);
+               log.tracef(""gate is opened, processing the lock cleanup:  %s"", command);
             } catch (InterruptedException e) {
                throw new RuntimeException(e);
             }",2012-10-12T16:37:21Z,118
"@@ -0,0 +1,188 @@
+/*
+ * JBoss, Home of Professional Open Source
+ *  Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ *  contributors as indicated by the @author tags. All rights reserved
+ *  See the copyright.txt in the distribution for a full listing of
+ *  individual contributors.
+ *
+ *  This is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU Lesser General Public License as
+ *  published by the Free Software Foundation; either version 2.1 of
+ *  the License, or (at your option) any later version.
+ *
+ *  This software is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ *  Lesser General Public License for more details.
+ *
+ *  You should have received a copy of the GNU Lesser General Public
+ *  License along with this software; if not, write to the Free
+ *  Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ *  02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.statetransfer;
+
+import java.util.Collection;
+import java.util.Map;
+import java.util.concurrent.Callable;
+
+import org.infinispan.Cache;
+import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.JGroupsTransport;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.test.fwk.TransportFlags;
+import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
+import org.infinispan.util.InfinispanCollections;
+import org.jgroups.protocols.DISCARD;
+import org.testng.annotations.Test;
+
+import static org.junit.Assert.assertEquals;
+
+/**
+ * tests scenario for ISPN-2574
+ *
+ * - create nodes A, B - start node C - starts state transfer from B to C
+ * - abruptly kill B before it is able to send StateResponse to C
+ * - C resends the request to A
+ * - finally cluster A, C is formed where all entries are properly backed up on both nodes
+ *
+ * @author Michal Linhard
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.StateTransferRestartTest"")
+@CleanupAfterMethod
+public class StateTransferRestartTest extends MultipleCacheManagersTest {
+
+   private ConfigurationBuilder cfgBuilder;
+   private GlobalConfigurationBuilder gcfgBuilder;
+
+   private class MockTransport extends JGroupsTransport {
+      volatile Callable<Void> callOnStateResponseCommand;
+
+      @Override
+      public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout,
+                                                   boolean usePriorityQueue, ResponseFilter responseFilter) throws Exception {
+         if (callOnStateResponseCommand != null && rpcCommand.getClass() == StateResponseCommand.class) {
+            log.trace(""Ignoring StateResponseCommand"");
+            try {
+               callOnStateResponseCommand.call();
+            } catch (Exception e) {
+               log.error(""Error in callOnStateResponseCommand"", e);
+            }
+            return InfinispanCollections.emptyMap();
+         }
+         return super.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue, responseFilter);
+      }
+   }
+
+   private MockTransport mockTransport = new MockTransport();
+
+   private void waitForStateTransfer(Cache... caches) throws InterruptedException {
+      StateTransferManager[] stm = new StateTransferManager[caches.length];
+      for (int i = 0; i < stm.length; i++) {
+         stm[i] = TestingUtil.extractComponent(caches[i], StateTransferManager.class);
+      }
+      while (true) {
+         boolean inProgress = false;
+         for (StateTransferManager aStm : stm) {
+            if (aStm.isStateTransferInProgress()) {
+               inProgress = true;
+               break;
+            }
+         }
+         if (!inProgress) {
+            break;
+         }
+         wait(100);
+      }
+   }
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      cfgBuilder = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+      cfgBuilder.transaction().transactionManagerLookup(new DummyTransactionManagerLookup());
+      cfgBuilder.clustering().hash().numOwners(2);
+      cfgBuilder.clustering().stateTransfer().fetchInMemoryState(true);
+      cfgBuilder.clustering().stateTransfer().timeout(10000);
+
+      gcfgBuilder = new GlobalConfigurationBuilder();
+      gcfgBuilder.transport().transport(mockTransport);
+   }
+
+   public void testStateTransferRestart() throws Throwable {
+      addClusterEnabledCacheManager(cfgBuilder, new TransportFlags().withFD(true));
+      addClusterEnabledCacheManager(gcfgBuilder, cfgBuilder, new TransportFlags().withFD(true));
+      log.info(""waiting for cluster { c0, c1 }"");
+      waitForClusterToForm();
+
+      log.info(""putting in data"");
+      final Cache<Object, Object> c0 = cache(0);
+      final Cache<Object, Object> c1 = cache(1);
+      for (int k = 0; k < 1000; k++) {
+         c0.put(k, k);
+      }
+      waitForStateTransfer(c0, c1);
+
+      assertEquals(1000, c0.entrySet().size());
+      assertEquals(1000, c1.entrySet().size());
+
+      mockTransport.callOnStateResponseCommand = new Callable<Void>() {
+         @Override
+         public Void call() throws Exception {
+            fork(new Callable<Void>() {
+               @Override
+               public Void call() throws Exception {
+                  log.info(""KILLING the c1 cache"");
+                  try {
+                     DISCARD d3 = TestingUtil.getDiscardForCache(c1);
+                     d3.setDiscardAll(true);
+                     d3.setExcludeItself(true);
+                     TestingUtil.killCacheManagers(manager(c1));
+                  } catch (Exception e) {
+                     log.info(""there was some exception while killing cache"");
+                  }
+                  return null;
+               }
+            });
+            try {
+               // sleep and wait to be killed
+               Thread.sleep(20000);
+            } catch (InterruptedException e) {
+               log.info(""Interrupted as expected."");
+               Thread.currentThread().interrupt();
+            }
+            return null;
+         }
+      };
+
+      log.info(""adding cache c2"");
+      addClusterEnabledCacheManager(cfgBuilder, new TransportFlags().withFD(true));
+      log.info(""get c2"");
+      final Cache<Object, Object> c2 = cache(2);
+
+      log.info(""waiting for cluster { c0, c2 }"");
+      TestingUtil.blockUntilViewsChanged(10000, 2, c0, c2);
+
+      log.infof(""c0 entrySet size before : %d"", c0.entrySet().size());
+      log.infof(""c2 entrySet size before : %d"", c2.entrySet().size());
+
+      eventually(new Condition() {
+         @Override
+         public boolean isSatisfied() throws Exception {
+            return c0.entrySet().size() == 1000 && c2.entrySet().size() == 1000;
+         }
+      });
+
+      log.info(""Ending the test"");
+   }
+}",2013-01-23T11:38:31Z,119
"@@ -66,7 +66,9 @@ public class InboundTransferTask {
 
    private final long timeout;
 
-   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout) {
+   private final String cacheName;
+
+   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""segments must not be null or empty"");
       }
@@ -81,6 +83,7 @@ public InboundTransferTask(Set<Integer> segments, Address source, int topologyId
       this.rpcManager = rpcManager;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public Set<Integer> getSegments() {
@@ -93,7 +96,7 @@ public Address getSource() {
 
    public boolean requestTransactions() {
       if (trace) {
-         log.tracef(""Requesting transactions for segments %s"", segments);
+         log.tracef(""Requesting transactions for segments %s of cache %s from node %s"", segments, cacheName, source);
       }
       // get transactions and locks
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.GET_TRANSACTIONS, rpcManager.getAddress(), topologyId, segments);
@@ -109,6 +112,10 @@ public boolean requestTransactions() {
    }
 
    public boolean requestSegments() {
+      if (trace) {
+         log.tracef(""Requesting segments %s of cache %s from node %s"", segments, cacheName, source);
+      }
+
       // start transfer of cache entries
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.START_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
       Map<Address, Response> responses = rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
@@ -139,24 +146,21 @@ public void cancel() {
       if (!isCancelled) {
          isCancelled = true;
 
-         Set<Integer> cancelledSegments = new HashSet<Integer>(segments);
-         segments.clear();
-         finishedSegments.clear();
-
-         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, cancelledSegments);
+         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
          rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
 
          stateConsumer.onTaskCompletion(this);
       }
    }
 
    public void onStateReceived(int segmentId, boolean isLastChunk) {
-      if (!isCancelled && segments.contains(segmentId)) {
-         if (isLastChunk) {
-            finishedSegments.add(segmentId);
-            if (finishedSegments.containsAll(segments)) {
-               stateConsumer.onTaskCompletion(this);
+      if (!isCancelled && isLastChunk && segments.contains(segmentId)) {
+         finishedSegments.add(segmentId);
+         if (finishedSegments.containsAll(segments)) {
+            if (trace) {
+               log.tracef(""Finished receiving state for segments %s of cache %s"", segments, cacheName);
             }
+            stateConsumer.onTaskCompletion(this);
          }
       }
    }
@@ -166,11 +170,14 @@ public String toString() {
       HashSet<Integer> unfinishedSegments = new HashSet<Integer>(segments);
       unfinishedSegments.removeAll(finishedSegments);
       return ""InboundTransferTask{"" +
-            ""unfinishedSegments="" + unfinishedSegments +
+            ""segments="" + segments +
+            "", finishedSegments="" + finishedSegments +
+            "", unfinishedSegments="" + unfinishedSegments +
             "", source="" + source +
             "", isCancelled="" + isCancelled +
             "", topologyId="" + topologyId +
             "", timeout="" + timeout +
+            "", cacheName="" + cacheName +
             '}';
    }
 }",2012-11-07T14:07:34Z,120
"@@ -24,20 +24,19 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.commands.CommandsFactory;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheLoaderManager;
 import org.infinispan.loaders.CacheStore;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.SuspectException;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
-import org.infinispan.util.concurrent.AggregatingNotifyingFutureBuilder;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -70,8 +69,6 @@ public class OutboundTransferTask implements Runnable {
 
    private final int stateTransferChunkSize;
 
-   private final Configuration configuration;
-
    private final ConsistentHash readCh;
 
    private final DataContainer dataContainer;
@@ -84,27 +81,24 @@ public class OutboundTransferTask implements Runnable {
 
    private final long timeout;
 
+   private final String cacheName;
+
    private final Map<Integer, List<InternalCacheEntry>> entriesBySegment = ConcurrentMapFactory.makeConcurrentMap();
 
    /**
     * The total number of entries from all segments accumulated in entriesBySegment.
     */
    private int accumulatedEntries;
 
-   /**
-    * This is used with RpcManager.invokeRemotelyInFuture() to be able to cancel message sending if the task needs to be canceled.
-    */
-   private final NotifyingNotifiableFuture<Object> sendFuture = new AggregatingNotifyingFutureBuilder(null);
-
    /**
     * The Future obtained from submitting this task to an executor service. This is used for cancellation.
     */
    private FutureTask runnableFuture;
 
    public OutboundTransferTask(Address destination, Set<Integer> segments, int stateTransferChunkSize,
                                int topologyId, ConsistentHash readCh, StateProviderImpl stateProvider, DataContainer dataContainer,
-                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager, Configuration configuration,
-                               CommandsFactory commandsFactory, long timeout) {
+                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager,
+                               CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""Segments must not be null or empty"");
       }
@@ -123,9 +117,9 @@ public OutboundTransferTask(Address destination, Set<Integer> segments, int stat
       this.dataContainer = dataContainer;
       this.cacheLoaderManager = cacheLoaderManager;
       this.rpcManager = rpcManager;
-      this.configuration = configuration;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public void execute(ExecutorService executorService) {
@@ -154,7 +148,7 @@ public void run() {
       try {
          // send data container entries
          for (InternalCacheEntry ice : dataContainer) {
-            Object key = ice.getKey();
+            Object key = ice.getKey();  //todo [anistor] should we check for expired entries?
             int segmentId = readCh.getSegment(key);
             if (segments.contains(segmentId)) {
                sendEntry(ice, segmentId);
@@ -198,7 +192,7 @@ public void run() {
          }
       }
       if (trace) {
-         log.tracef(""Outbound transfer of segments %s to %s is complete"", segments, destination);
+         log.tracef(""Outbound transfer of segments %s of cache %s to node %s is complete"", segments, cacheName, destination);
       }
    }
 
@@ -217,7 +211,6 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
       // send if we have a full chunk
       if (accumulatedEntries >= stateTransferChunkSize) {
          sendEntries(false);
-         entriesBySegment.clear();
          accumulatedEntries = 0;
       }
 
@@ -232,32 +225,42 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
 
    private void sendEntries(boolean isLast) {
       List<StateChunk> chunks = new ArrayList<StateChunk>();
+      for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
+         List<InternalCacheEntry> entries = e.getValue();
+         if (!entries.isEmpty()) {
+            chunks.add(new StateChunk(e.getKey(), new ArrayList<InternalCacheEntry>(entries), isLast));
+            entries.clear();
+         }
+      }
+
       if (isLast) {
          for (int segmentId : segments) {
             List<InternalCacheEntry> entries = entriesBySegment.get(segmentId);
             if (entries == null) {
-               entries = InfinispanCollections.emptyList();
-            }
-            chunks.add(new StateChunk(segmentId, entries, isLast));
-         }
-      } else {
-         for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
-            List<InternalCacheEntry> entries = e.getValue();
-            if (!entries.isEmpty()) {
-               chunks.add(new StateChunk(e.getKey(), entries, isLast));
+               chunks.add(new StateChunk(segmentId, InfinispanCollections.<InternalCacheEntry>emptyList(), true));
             }
          }
       }
 
-      if (!chunks.isEmpty() || isLast) {
+      if (!chunks.isEmpty()) {
          if (trace) {
-            log.tracef(""Sending %d cache entries from segments %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), destination);
+            if (isLast) {
+               log.tracef(""Sending last chunk containing %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, segments, cacheName, destination);
+            } else {
+               log.tracef(""Sending %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), cacheName, destination);
+            }
          }
 
-         //todo [anistor] send back the received topologyId or my local one?
          StateResponseCommand cmd = commandsFactory.buildStateResponseCommand(rpcManager.getAddress(), topologyId, chunks);
-         // send synchronously, in FIFO mode. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
-         rpcManager.invokeRemotelyInFuture(Collections.singleton(destination), cmd, false, sendFuture, timeout);
+         // send synchronously, in order. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
+         try {
+            rpcManager.invokeRemotely(Collections.singleton(destination), cmd, ResponseMode.SYNCHRONOUS, timeout, false, null);
+         } catch (SuspectException e) {
+            log.errorf(e, ""Node %s left cache %s: %s"", destination, cacheName, e.getMessage());
+            cancel();
+         } catch (Exception e) {
+            log.errorf(e, ""Failed to send entries to node %s : %s"", destination, e.getMessage());
+         }
       }
    }
 
@@ -268,7 +271,7 @@ private void sendEntries(boolean isLast) {
     */
    public void cancelSegments(Set<Integer> cancelledSegments) {
       if (trace) {
-         log.tracef(""Cancelling outbound transfer of segments %s to %s"", cancelledSegments, destination);
+         log.tracef(""Cancelling outbound transfer of segments %s of cache %s to node %s"", cancelledSegments, cacheName, destination);
       }
       if (segments.removeAll(cancelledSegments)) {
          entriesBySegment.keySet().removeAll(cancelledSegments);  // here we do not update accumulatedEntries but this inaccuracy does not cause any harm
@@ -284,11 +287,22 @@ public void cancelSegments(Set<Integer> cancelledSegments) {
    public void cancel() {
       if (runnableFuture != null && !runnableFuture.isCancelled()) {
          runnableFuture.cancel(true);
-         sendFuture.cancel(true);
       }
    }
 
    public boolean isCancelled() {
       return runnableFuture != null && runnableFuture.isCancelled();
    }
+
+   @Override
+   public String toString() {
+      return ""OutboundTransferTask{"" +
+            ""topologyId="" + topologyId +
+            "", destination="" + destination +
+            "", segments="" + segments +
+            "", stateTransferChunkSize="" + stateTransferChunkSize +
+            "", timeout="" + timeout +
+            "", cacheName='"" + cacheName + '\'' +
+            '}';
+   }
 }",2012-11-07T14:07:34Z,121
"@@ -45,7 +45,6 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -62,7 +61,7 @@
 import static org.infinispan.context.Flag.*;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateConsumer} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -72,7 +71,7 @@ public class StateConsumerImpl implements StateConsumer {
    private static final Log log = LogFactory.getLog(StateConsumerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
-   private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
    private Configuration configuration;
    private RpcManager rpcManager;
@@ -119,7 +118,7 @@ public StateConsumerImpl() {
 
    @Inject
    public void init(Cache cache,
-                    LocalTopologyManager localTopologyManager,
+                    StateTransferManager stateTransferManager,
                     InterceptorChain interceptorChain,
                     InvocationContextContainer icc,
                     Configuration configuration,
@@ -130,7 +129,7 @@ public void init(Cache cache,
                     TransactionTable transactionTable,
                     StateTransferLock stateTransferLock) {
       this.cacheName = cache.getName();
-      this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
       this.interceptorChain = interceptorChain;
       this.icc = icc;
       this.configuration = configuration;
@@ -171,26 +170,30 @@ public boolean isStateTransferInProgressForKey(Object key) {
 
    @Override
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
-      if (trace) log.tracef(""Received new CH: %s"", cacheTopology.getWriteConsistentHash());
+      if (trace) log.tracef(""Received new CH %s for cache %s"", cacheTopology.getWriteConsistentHash(), cacheName);
 
       activeTopologyUpdates.incrementAndGet();
       if (isRebalance) {
          rebalanceInProgress.set(true);
       }
-      ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
+      final ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
       // Ensures writes to the data container use the right consistent hash
       // No need for a try/finally block, since it's just an assignment
       stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
       stateTransferLock.releaseExclusiveTopologyLock();
-      stateTransferLock.topologyInstalled(cacheTopology.getTopologyId());
+      stateTransferLock.notifyTopologyInstalled(cacheTopology.getTopologyId());
 
       try {
          Set<Integer> addedSegments;
          if (previousCh == null) {
             // we start fresh, without any data, so we need to pull everything we own according to writeCh
 
             addedSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
+
+            if (trace) {
+               log.tracef(""On cache %s we have: added segments: %s"", cacheName, addedSegments);
+            }
          } else {
             Set<Integer> previousSegments = getOwnedSegments(previousCh);
             Set<Integer> newSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
@@ -199,16 +202,16 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             Set<Integer> removedSegments = new HashSet<Integer>(previousSegments);
             removedSegments.removeAll(newSegments);
 
-            // remove inbound transfers and any data for segments we no longer own
+            addedSegments = new HashSet<Integer>(newSegments);
+            addedSegments.removeAll(previousSegments);
+
             if (trace) {
-               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                     removedSegments, newSegments, previousSegments);
+               log.tracef(""On cache %s we have: removed segments: %s; new segments: %s; old segments: %s; added segments: %s"",
+                     cacheName, removedSegments, newSegments, previousSegments, addedSegments);
             }
-            discardSegments(removedSegments);
 
-            Set<Integer> currentSegments = getOwnedSegments(cacheTopology.getReadConsistentHash());
-            addedSegments = new HashSet<Integer>(newSegments);
-            addedSegments.removeAll(currentSegments);
+            // remove inbound transfers and any data for segments we no longer own
+            discardSegments(removedSegments);
 
             // check if any of the existing transfers should be restarted from a different source because the initial source is no longer a member
             Set<Address> members = new HashSet<Address>(cacheTopology.getReadConsistentHash().getMembers());
@@ -230,24 +233,30 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
                      }
                   }
                }
+
+               // exclude those that are already in progress from a valid source
+               addedSegments.removeAll(transfersBySegment.keySet());
             }
          }
 
-         if (addedSegments != null && !addedSegments.isEmpty()) {
+         if (!addedSegments.isEmpty()) {
             addTransfers(addedSegments);  // add transfers for new or restarted segments
          }
       } finally {
-         stateTransferLock.transactionDataReceived(cacheTopology.getTopologyId());
+         stateTransferLock.notifyTransactionDataReceived(cacheTopology.getTopologyId());
 
-         if (activeTopologyUpdates.decrementAndGet() == 0 && !isStateTransferInProgress()) {
+         if (activeTopologyUpdates.decrementAndGet() == 0) {
             notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
          }
       }
    }
 
    private void notifyEndOfTopologyUpdate(int topologyId) {
-      if (rebalanceInProgress.compareAndSet(true, false)) {
-         localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+      if (!isStateTransferInProgress()) {
+         if (rebalanceInProgress.compareAndSet(true, false)) {
+            log.debugf(""Finished receiving of segments for cache %s for topology %d."", cacheName, topologyId);
+            stateTransferManager.notifyEndOfTopologyUpdate(topologyId);
+         }
       }
    }
 
@@ -262,43 +271,42 @@ public void applyState(Address sender, int topologyId, int segmentId, Collection
       //todo [anistor] this check should be based on topologyId
       if (!cacheTopology.getWriteConsistentHash().getSegmentsForOwner(rpcManager.getAddress()).contains(segmentId)) {
          if (trace) {
-            log.warnf(""Discarding received cache entries for segment %d because they do not belong to this node."", segmentId);
+            log.warnf(""Discarding received cache entries for segment %d of cache %s because they do not belong to this node."", segmentId, cacheName);
          }
          return;
       }
 
-      if (cacheEntries != null) {
-         doApplyState(sender, segmentId, cacheEntries);
-      }
-
       // notify the inbound task that a chunk of cache entries was received
       InboundTransferTask inboundTransfer;
       synchronized (this) {
          inboundTransfer = transfersBySegment.get(segmentId);
       }
       if (inboundTransfer != null) {
+         if (cacheEntries != null) {
+            doApplyState(sender, segmentId, cacheEntries);
+         }
+
          inboundTransfer.onStateReceived(segmentId, isLastChunk);
-      } else {
-         log.debugf(""Received unsolicited state for segment %d from node %s"", segmentId, sender);
-         return;
-      }
 
-      if (trace) {
-         log.tracef(""After applying the received state the data container has %d keys"", dataContainer.size());
-         synchronized (this) {
-            log.tracef(""Segments not received yet: %s"", transfersBySource);
+         if (trace) {
+            log.tracef(""After applying the received state the data container of cache %s has %d keys"", cacheName, dataContainer.size());
+            synchronized (this) {
+               log.tracef(""Segments not received yet for cache %s: %s"", cacheName, transfersBySource);
+            }
          }
+      } else {
+         log.warnf(""Received unsolicited state from node %s for segment %d of cache %s"", sender, segmentId, cacheName);
       }
    }
 
    private void doApplyState(Address sender, int segmentId, Collection<InternalCacheEntry> cacheEntries) {
-      log.debugf(""Applying new state for segment %d from %s: received %d cache entries"", segmentId, sender, cacheEntries.size());
+      log.debugf(""Applying new state for segment %d of cache %s from node %s: received %d cache entries"", segmentId, cacheName, sender, cacheEntries.size());
       if (trace) {
          List<Object> keys = new ArrayList<Object>(cacheEntries.size());
          for (InternalCacheEntry e : cacheEntries) {
             keys.add(e.getKey());
          }
-         log.tracef(""Received keys: %s"", keys);
+         log.tracef(""Received keys %s for segment %d of cache %s from node %s"", keys, segmentId, cacheName, sender);
       }
 
       // CACHE_MODE_LOCAL avoids handling by StateTransferInterceptor and any potential locks in StateTransferLock
@@ -316,10 +324,11 @@ private void doApplyState(Address sender, int segmentId, Collection<InternalCach
             log.problemApplyingStateForKey(ex.getMessage(), e.getKey());
          }
       }
+      log.debugf(""Finished applying state for segment %d of cache %s"", segmentId, cacheName);
    }
 
    public void applyTransactions(Address sender, int topologyId, Collection<TransactionInfo> transactions) {
-      log.debugf(""Applying %d transactions transferred from %s"", transactions.size(), sender);
+      log.debugf(""Applying %d transactions for cache %s transferred from node %s"", transactions.size(), cacheName, sender);
       if (configuration.transaction().transactionMode().isTransactional()) {
          for (TransactionInfo transactionInfo : transactions) {
             CacheTransaction tx = transactionTable.getLocalTransaction(transactionInfo.getGlobalTransaction());
@@ -374,30 +383,31 @@ public CacheTopology getCacheTopology() {
    }
 
    private void addTransfers(Set<Integer> segments) {
-      log.debugf(""Adding state transfer for segments: %s"", segments);
+      log.debugf(""Adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
 
       Set<Integer> segmentsToProcess = new HashSet<Integer>(segments);
-      Set<Address> blacklistedSources = new HashSet<Address>();
+      Set<Address> faultysources = new HashSet<Address>();
 
       // ignore all segments for which there are no other owners to pull data from.
       // these segments are considered empty (or lost) and do not require a state transfer
       for (Iterator<Integer> it = segmentsToProcess.iterator(); it.hasNext(); ) {
          Integer segmentId = it.next();
-         Address source = pickSourceOwner(segmentId, blacklistedSources);
+         Address source = pickSourceOwner(segmentId, faultysources);
          if (source == null) {
             it.remove();
          }
       }
 
-      synchronized (this) {
-         // already active transfers do not need to be added again
-         segmentsToProcess.removeAll(transfersBySegment.keySet());
-      }
-
       while (!segmentsToProcess.isEmpty()) {
          Map<Address, Set<Integer>> segmentsBySource = new HashMap<Address, Set<Integer>>();
          for (int segmentId : segmentsToProcess) {
-            Address source = pickSourceOwner(segmentId, blacklistedSources);
+            synchronized (this) {
+               // already active transfers do not need to be added again
+               if (transfersBySegment.containsKey(segmentId)) {
+                  continue;
+               }
+            }
+            Address source = pickSourceOwner(segmentId, faultysources);
             if (source != null) {
                Set<Integer> segmentsFromSource = segmentsBySource.get(source);
                if (segmentsFromSource == null) {
@@ -411,8 +421,14 @@ private void addTransfers(Set<Integer> segments) {
          Set<Integer> failedSegments = new HashSet<Integer>();
          for (Address source : segmentsBySource.keySet()) {
             Set<Integer> segmentsFromSource = segmentsBySource.get(source);
-            InboundTransferTask inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout);
+            InboundTransferTask inboundTransfer;
             synchronized (this) {
+               segmentsFromSource.removeAll(transfersBySegment.keySet());  // already in progress segments are excluded
+               if (segmentsFromSource.isEmpty()) {
+                  continue;
+               }
+
+               inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout, cacheName);
                for (int segmentId : segmentsFromSource) {
                   transfersBySegment.put(segmentId, inboundTransfer);
                }
@@ -427,9 +443,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the transactions fails we need to retry from another source
             if (configuration.transaction().transactionMode().isTransactional()) {
                if (!inboundTransfer.requestTransactions()) {
-                  log.errorf(""Failed to retrieve transactions for segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRetrieveTransactionsForSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                   continue;
                }
@@ -438,9 +454,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the segments fails we need to retry from another source
             if (fetchEnabled) {
                if (!inboundTransfer.requestSegments()) {
-                  log.errorf(""Failed to request segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRequestSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                }
             } else {
@@ -450,21 +466,22 @@ private void addTransfers(Set<Integer> segments) {
 
          segmentsToProcess = failedSegments;
       }
+      log.debugf(""Finished adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
    }
 
-   private Address pickSourceOwner(int segmentId, Set<Address> blacklistedSources) {
+   private Address pickSourceOwner(int segmentId, Set<Address> faultySources) {
       List<Address> owners = cacheTopology.getReadConsistentHash().locateOwnersForSegment(segmentId);
       if (owners.size() == 1 && owners.get(0).equals(rpcManager.getAddress())) {
          return null;
       }
 
       for (int i = owners.size() - 1; i >= 0; i--) {   // iterate backwards because we prefer to fetch from newer nodes
          Address o = owners.get(i);
-         if (!o.equals(rpcManager.getAddress()) && !blacklistedSources.contains(o)) {
+         if (!o.equals(rpcManager.getAddress()) && !faultySources.contains(o)) {
             return o;
          }
       }
-      log.errorf(""No live owners found for segment %d. Current owners are:  %s. Blacklisted owners: %s"", segmentId, owners, blacklistedSources);
+      log.noLiveOwnersFoundForSegment(segmentId, cacheName, owners, faultySources);
       return null;
    }
 
@@ -478,9 +495,9 @@ private void discardSegments(Set<Integer> segments) {
          List<Integer> segmentsToCancel = new ArrayList<Integer>(segments);
          while (!segmentsToCancel.isEmpty()) {
             int segmentId = segmentsToCancel.remove(0);
-            log.debugf(""Removing state transfer for segment %d"", segmentId);
             InboundTransferTask inboundTransfer = transfersBySegment.remove(segmentId);
             if (inboundTransfer != null) { // we need to check the transfer was not already completed
+               log.debugf(""Cancelling inbound state transfer for segment %d of cache %s"", segmentId, cacheName);
                Set<Integer> cancelledSegments = new HashSet<Integer>(segmentsToCancel);
                cancelledSegments.retainAll(inboundTransfer.getSegments());
                segmentsToCancel.removeAll(cancelledSegments);
@@ -489,6 +506,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      // gather all keys from data container that belong to the segments that are being removed
       Set<Object> keysToRemove = new HashSet<Object>();
       for (InternalCacheEntry ice : dataContainer) {
          Object key = ice.getKey();
@@ -497,7 +515,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
-      // we also remove keys from the cache store
+      // gather all keys from cache store that belong to the segments that are being removed
       CacheStore cacheStore = getCacheStore();
       if (cacheStore != null) {
          //todo [anistor] extend CacheStore interface to be able to specify a filter when loading keys (ie. keys should belong to desired segments)
@@ -514,13 +532,14 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      log.debugf(""Removing state for segments %s of cache %s"", segments, cacheName);
       if (!keysToRemove.isEmpty()) {
          try {
             InvalidateCommand invalidateCmd = commandsFactory.buildInvalidateFromL1Command(true, EnumSet.of(CACHE_MODE_LOCAL, SKIP_LOCKING), keysToRemove);
             InvocationContext ctx = icc.createNonTxInvocationContext();
             interceptorChain.invoke(ctx, invalidateCmd);
 
-            log.debugf(""Invalidated %d keys, data container now has %d keys"", keysToRemove.size(), dataContainer.size());
+            log.debugf(""Invalidated %d keys, data container of cache %s now has %d keys"", keysToRemove.size(), cacheName, dataContainer.size());
             if (trace) log.tracef(""Invalidated keys: %s"", keysToRemove);
          } catch (CacheException e) {
             log.failedToInvalidateKeys(e);
@@ -553,18 +572,17 @@ private void removeTransfer(InboundTransferTask inboundTransfer) {
                if (transfers.isEmpty()) {
                   transfersBySource.remove(inboundTransfer.getSource());
                }
-               for (int segmentId : inboundTransfer.getSegments()) {
-                  transfersBySegment.remove(segmentId);
-               }
+               transfersBySegment.keySet().removeAll(inboundTransfer.getSegments());
             }
          }
       }
    }
 
    void onTaskCompletion(InboundTransferTask inboundTransfer) {
+      log.tracef(""Completion of inbound transfer task: %s "", inboundTransfer);
       removeTransfer(inboundTransfer);
 
-      if (activeTopologyUpdates.get() == 0 && !isStateTransferInProgress()) {
+      if (activeTopologyUpdates.get() == 0) {
          notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
       }
    }",2012-11-07T14:07:34Z,54
"@@ -52,7 +52,7 @@
 import static org.infinispan.factories.KnownComponentNames.ASYNC_TRANSPORT_EXECUTOR;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateProvider} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -90,7 +90,7 @@ public StateProviderImpl() {
 
    @Inject
    public void init(Cache cache,
-                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //todo [anistor] use a separate ExecutorService
+                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //TODO Use a dedicated ExecutorService
                     Configuration configuration,
                     RpcManager rpcManager,
                     CommandsFactory commandsFactory,
@@ -184,7 +184,7 @@ public void stop() {
 
    public List<TransactionInfo> getTransactionsForSegments(Address destination, int requestTopologyId, Set<Integer> segments) throws InterruptedException {
       if (trace) {
-         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, requestTopologyId);
+         log.tracef(""Received request for transactions from node %s for segments %s of cache %s with topology id %d"", destination, segments, cacheName, requestTopologyId);
       }
 
       if (readCh == null) {
@@ -262,8 +262,8 @@ public void startOutboundTransfer(Address destination, int requestTopologyId, Se
       }
 
       // the destination node must already have an InboundTransferTask waiting for these segments
-      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, requestTopologyId,
-            readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
+      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId,
+            readCh, this, dataContainer, cacheLoaderManager, rpcManager, commandsFactory, timeout, cacheName);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);
    }
@@ -294,7 +294,7 @@ public void cancelOutboundTransfer(Address destination, int topologyId, Set<Inte
             // get an array copy of the collection to avoid ConcurrentModificationException if the entire task gets cancelled and removeTransfer(transferTask) is called
             OutboundTransferTask[] tasks = transferTasks.toArray(new OutboundTransferTask[transferTasks.size()]);
             for (OutboundTransferTask transferTask : tasks) {
-               transferTask.cancelSegments(segments); //this can potentially result in a removeTransfer(transferTask)
+               transferTask.cancelSegments(segments); //this can potentially result in a call to removeTransfer(transferTask)
             }
          }
       }",2012-11-07T14:07:34Z,55
"@@ -36,16 +36,13 @@
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
-import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
 import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
@@ -75,7 +72,7 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
+   public void init(StateTransferLock stateTransferLock, Configuration configuration,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
       this.commandFactory = commandFactory;",2012-11-07T14:07:34Z,115
"@@ -58,13 +58,13 @@ public interface StateTransferLock {
    void releaseSharedTopologyLock();
 
    // transaction data latch
-   void transactionDataReceived(int topologyId);
+   void notifyTransactionDataReceived(int topologyId);
 
    void waitForTransactionData(int expectedTopologyId) throws InterruptedException;
 
    // topology installation latch
    // TODO move this to Cluster/LocalTopologyManagerImpl and don't start requesting state until every node has the jgroups view with the local node
-   void topologyInstalled(int topologyId);
+   void notifyTopologyInstalled(int topologyId);
 
    void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-11-07T14:07:34Z,122
"@@ -23,12 +23,12 @@
 
 package org.infinispan.statetransfer;
 
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+
 /**
  * {@code StateTransferLock} implementation.
  *
@@ -38,6 +38,7 @@
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
+   private static final boolean trace = log.isTraceEnabled();
 
    private final ReadWriteLock ownershipLock = new ReentrantReadWriteLock();
 
@@ -68,8 +69,15 @@ public void releaseSharedTopologyLock() {
    }
 
    @Override
-   public void transactionDataReceived(int topologyId) {
-      this.transactionDataTopologyId = topologyId;
+   public void notifyTransactionDataReceived(int topologyId) {
+      if (topologyId < transactionDataTopologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + transactionDataTopologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling transaction data received for topology %d"", topologyId);
+      }
+      transactionDataTopologyId = topologyId;
       synchronized (transactionDataLock) {
          transactionDataLock.notifyAll();
       }
@@ -80,19 +88,32 @@ public void waitForTransactionData(int expectedTopologyId) throws InterruptedExc
       if (transactionDataTopologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
-            transactionDataTopologyId);
+      if (trace) {
+         log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
+               transactionDataTopologyId);
+      }
       synchronized (transactionDataLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (transactionDataTopologyId < expectedTopologyId) {
             transactionDataLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Received transaction data for topology %d, expected topology was %d"", transactionDataTopologyId,
+               expectedTopologyId);
+      }
    }
 
    @Override
-   public void topologyInstalled(int topologyId) {
+   public void notifyTopologyInstalled(int topologyId) {
+      if (topologyId < this.topologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + this.topologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling topology %d is installed"", topologyId);
+      }
       this.topologyId = topologyId;
       synchronized (topologyLock) {
          topologyLock.notifyAll();
@@ -104,14 +125,18 @@ public void waitForTopology(int expectedTopologyId) throws InterruptedException
       if (topologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId,
-            topologyId);
+      if (trace) {
+         log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId, topologyId);
+      }
       synchronized (topologyLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (topologyId < expectedTopologyId) {
             topologyLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Topology %d is now installed, expected topology was %d"", topologyId, expectedTopologyId);
+      }
    }
 }",2012-11-07T14:07:34Z,123
"@@ -81,4 +81,5 @@ public interface StateTransferManager {
     */
    void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
 
+   void notifyEndOfTopologyUpdate(int topologyId);
 }",2012-11-07T14:07:34Z,116
"@@ -70,7 +70,7 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private GroupManager groupManager;   // optional
    private LocalTopologyManager localTopologyManager;
 
-   private CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
+   private final CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
 
    public StateTransferManagerImpl() {
    }
@@ -170,13 +170,18 @@ private CacheTopology addGrouping(CacheTopology cacheTopology) {
 
    private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalance) {
       if (trace) {
-         log.tracef(""Installing new cache topology %s"", newCacheTopology);
+         log.tracef(""Installing new cache topology %s on cache %s"", newCacheTopology, cacheName);
       }
 
       // handle grouping
       newCacheTopology = addGrouping(newCacheTopology);
 
       CacheTopology oldCacheTopology = stateConsumer.getCacheTopology();
+
+      if (oldCacheTopology != null && oldCacheTopology.getTopologyId() > newCacheTopology.getTopologyId()) {
+         throw new IllegalStateException(""Old topology is higher: old="" + oldCacheTopology + "", new="" + newCacheTopology);
+      }
+
       ConsistentHash oldCH = oldCacheTopology != null ? oldCacheTopology.getWriteConsistentHash() : null;
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
@@ -188,15 +193,17 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
 
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
-      if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
+      boolean isJoined = stateConsumer.getCacheTopology().getReadConsistentHash().getMembers().contains(rpcManager.getAddress());
+      if (initialStateTransferComplete.getCount() > 0 && isJoined) {
          initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
    }
 
    @Start(priority = 1000)
    @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
-      if (trace) log.tracef(""Waiting for initial state transfer to finish"");
+      if (trace) log.tracef(""Waiting for initial state transfer to finish for cache %s on %s"", cacheName, rpcManager.getAddress());
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);
       if (!success) {
          throw new CacheException(String.format(""Initial state transfer timed out for cache %s on %s"",
@@ -210,6 +217,7 @@ public void stop() {
       if (trace) {
          log.tracef(""Shutting down StateTransferManager of cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
+      initialStateTransferComplete.countDown();
       localTopologyManager.leave(cacheName);
    }
 
@@ -268,4 +276,14 @@ public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object>
          }
       }
    }
+
+   @Override
+   public void notifyEndOfTopologyUpdate(int topologyId) {
+      if (initialStateTransferComplete.getCount() > 0
+            && stateConsumer.getCacheTopology().getWriteConsistentHash().getMembers().contains(rpcManager.getAddress())) {
+         initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
+      }
+      localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+   }
 }
\ No newline at end of file",2012-11-07T14:07:34Z,117
"@@ -126,13 +126,17 @@ public void triggerRebalance(final String cacheName) throws Exception {
       asyncTransportExecutor.submit(new Callable<Object>() {
          @Override
          public Object call() throws Exception {
-            startRebalance(cacheName);
-            return null;
+            try {
+               startRebalance(cacheName);
+               return null;
+            } catch (Throwable t) {
+               log.errorf(t, ""Failed to start rebalance: %s"", t.getMessage());
+               throw new Exception(t);
+            }
          }
       });
    }
 
-
    @Override
    public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo joinInfo, int viewId) throws Exception {
       waitForView(viewId);
@@ -594,6 +598,7 @@ public Object call() throws Exception {
             try {
                return command.perform(null);
             } catch (Throwable t) {
+               log.errorf(t, ""Failed to execute ReplicableCommand %s on cluster async: %s"", command, t.getMessage());
                throw new Exception(t);
             }
          }",2012-11-07T14:07:34Z,124
"@@ -280,6 +280,7 @@ public Object call() throws Exception {
                try {
                   return command.perform(null);
                } catch (Throwable t) {
+                  log.errorf(t, ""Failed to execute ReplicableCommand %s on coordinator async: %s"", command, t.getMessage());
                   throw new Exception(t);
                }
             }
@@ -298,8 +299,6 @@ class LocalCacheStatus {
    private final CacheTopologyHandler handler;
    private volatile CacheTopology topology;
 
-   private boolean joined;
-
    public LocalCacheStatus(CacheJoinInfo joinInfo, CacheTopologyHandler handler) {
       this.joinInfo = joinInfo;
       this.handler = handler;
@@ -320,12 +319,4 @@ public CacheTopology getTopology() {
    public void setTopology(CacheTopology topology) {
       this.topology = topology;
    }
-
-   public boolean isJoined() {
-      return joined;
-   }
-
-   public void setJoined(boolean joined) {
-      this.joined = joined;
-   }
 }",2012-11-07T14:07:34Z,125
"@@ -53,15 +53,14 @@ public class StaleTransactionCleanupService {
 
    private static Log log = LogFactory.getLog(StaleTransactionCleanupService.class);
 
+   private ScheduledExecutorService executorService;
 
    private TransactionTable transactionTable;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
-   private ScheduledExecutorService executorService;
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * because the main data owner left. Also unlocks keys for which the lock owner has changed as a result of a topology change.
@@ -71,15 +70,19 @@ public StaleTransactionCleanupService(TransactionTable transactionTable) {
    @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // Roll back remote transactions originating on nodes that have left the cluster.
-      if (tce.isPre()) {
-         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
-         if (consistentHashAtStart != null) {
-            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
-            if (!leavers.isEmpty()) {
-               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-               cleanTxForWhichTheOwnerLeft(leavers);
+      try {
+         if (tce.isPre()) {
+            ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+            if (consistentHashAtStart != null) {
+               List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+               if (!leavers.isEmpty()) {
+                  log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+                  cleanTxForWhichTheOwnerLeft(leavers);
+               }
             }
          }
+      } catch (Exception e) {
+         log.error(""Failed to process topology update"", e);
       }
    }
 
@@ -120,7 +123,6 @@ public void run() {
             transactionTable.cleanupCompletedTransactions();
          }
       }, interval, interval, TimeUnit.MILLISECONDS);
-
    }
 
    public void stop() {",2012-11-07T14:07:34Z,126
"@@ -523,25 +523,29 @@ public boolean isTransactionCompleted(GlobalTransaction gtx) {
    }
 
    public void cleanupCompletedTransactions() {
-      log.debugf(""About to cleanup completed transaction. Initial size is %s"", completedTransactions.size());
-      //this iterator is weekly consistent and will never throw ConcurrentModificationException
-      Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
-      long timeout = configuration.transaction().completedTxTimeout();
-
-      int removedEntries = 0;
-      long beginning = System.nanoTime();
-      while (iterator.hasNext()) {
-         Map.Entry<GlobalTransaction, Long> e = iterator.next();
-         long ageNanos = System.nanoTime() - e.getValue();
-         if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
-            iterator.remove();
-            removedEntries++;
+      try {
+         log.debugf(""About to cleanup completed transaction. Initial size is %d"", completedTransactions.size());
+         //this iterator is weekly consistent and will never throw ConcurrentModificationException
+         Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
+         long timeout = configuration.transaction().completedTxTimeout();
+
+         int removedEntries = 0;
+         long beginning = System.nanoTime();
+         while (iterator.hasNext()) {
+            Map.Entry<GlobalTransaction, Long> e = iterator.next();
+            long ageNanos = System.nanoTime() - e.getValue();
+            if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
+               iterator.remove();
+               removedEntries++;
+            }
          }
-      }
-      long duration = System.nanoTime() - beginning;
+         long duration = System.nanoTime() - beginning;
 
-      log.debugf(""Finished cleaning up completed transactions. %s transactions were removed, total duration was %s millis, "" +
-                      ""current number of completed transactions is %"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
-                 completedTransactions.size());
+         log.debugf(""Finished cleaning up completed transactions. %d transactions were removed, total duration was %d millis, "" +
+                         ""current number of completed transactions is %d"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
+                    completedTransactions.size());
+      } catch (Exception e) {
+         log.errorf(e, ""Failed to cleanup completed transactions: %s"", e.getMessage());
+      }
    }
 }",2012-11-07T14:07:34Z,127
"@@ -24,9 +24,7 @@
 
 import org.infinispan.CacheException;
 import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.commands.tx.PrepareCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.bucket.Bucket;
 import org.infinispan.loaders.decorators.SingletonStore;
@@ -60,7 +58,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.UUID;
-import java.util.concurrent.ExecutionException;
 
 import static org.jboss.logging.Logger.Level.*;
 
@@ -131,26 +128,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Can not select %s random members for %s"", id = 8)
    void cannotSelectRandomMembers(int numNeeded, List<Address> members);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Detected a view change. Member list changed from %s to %s"", id = 9)
-   void viewChangeDetected(List<Address> oldMembers, List<Address> newMembers);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a JOIN event! Wait for notification from new joiner %s"", id = 10)
-   void joinEvent(Address joiner);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a LEAVE event! Node %s has just left"", id = 11)
-   void leaveEvent(Address leaver);
-
-   @LogMessage(level = FATAL)
-   @Message(value = ""Unable to process leaver!!"", id = 12)
-   void unableToProcessLeaver(@Cause Exception e);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""I %s am participating in rehash, state providers %s, state receivers %s"", id = 13)
-   void participatingInRehash(Address address, List<Address> stateProviders, List<Address> receiversOfLeaverState);
-
    @LogMessage(level = INFO)
    @Message(value = ""DistributionManager not yet joined the cluster. Cannot do anything about other concurrent joiners."", id = 14)
    void distributionManagerNotJoined();
@@ -163,10 +140,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Problem %s encountered when applying state for key %s!"", id = 16)
    void problemApplyingStateForKey(String msg, Object key);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""View change interrupted; not rehashing!"", id = 17)
-   void viewChangeInterrupted();
-
    @LogMessage(level = WARN)
    @Message(value = ""Unable to apply prepare %s"", id = 18)
    void unableToApplyPrepare(PrepareCommand pc, @Cause Throwable t);
@@ -175,26 +148,10 @@ public interface Log extends BasicLogger {
    @Message(value = ""Couldn't acquire shared lock"", id = 19)
    void couldNotAcquireSharedLock();
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Caught exception replaying %s"", id = 20)
-   void exceptionWhenReplaying(WriteCommand cmd, @Cause Exception e);
-
    @LogMessage(level = WARN)
    @Message(value = ""Expected just one response; got %s"", id = 21)
    void expectedJustOneResponse(Map<Address, Response> lr);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Completed leave rehash on node %s in %s - leavers now are %s"", id = 22)
-   void completedLeaveRehash(Address self, String duration, List<Address> leavers);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error pushing tx log"", id = 23)
-   void errorPushingTxLog(@Cause ExecutionException e);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Unable to stop transaction logging!"", id = 24)
-   void unableToStopTransactionLogging(@Cause IllegalMonitorStateException imse);
-
    @LogMessage(level = INFO)
    @Message(value = ""wakeUpInterval is <= 0, not starting expired purge thread"", id = 25)
    void notStartingEvictionThread();
@@ -211,7 +168,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unable to passivate entry under %s"", id = 28)
    void unableToPassivateEntry(Object key, @Cause Exception e);
 
-
    @LogMessage(level = INFO)
    @Message(value = ""Passivating all entries to disk"", id = 29)
    void passivatingAllEntries();
@@ -296,14 +252,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Interrupted or timeout while waiting for AsyncStore worker threads to push all state to the decorated store"", id = 48)
    void interruptedWaitingAsyncStorePush(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing clear in async store"", id = 49)
-   void errorClearinAsyncStore(@Cause CacheLoaderException e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing purging expired from async store"", id = 50)
-   void errorPurgingAsyncStore(@Cause CacheLoaderException e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Unexpected error"", id = 51)
    void unexpectedErrorInAsyncProcessor(@Cause Throwable t);
@@ -376,14 +324,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Cache named %s does not exist on this cache manager!"", id = 68)
    void namedCacheDoesNotExist(String cacheName);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Cache named [%s] exists but isn't in a state to handle remote invocations"", id = 69)
-   void cacheCanNotHandleInvocations(String cacheName);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Quietly ignoring clustered get call %s since unable to acquire processing lock, even after %s"", id = 70)
-   void ignoreClusterGetCall(CacheRpcCommand cmd, String time);
-
    @LogMessage(level = WARN)
    @Message(value = ""Caught exception when handling command %s"", id = 71)
    void exceptionHandlingCommand(ReplicableCommand cmd, @Cause Throwable t);
@@ -396,18 +336,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unexpected error while replicating"", id = 73)
    void unexpectedErrorReplicating(@Cause Throwable t);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Trying to fetch state from %s"", id = 74)
-   void tryingToFetchState(Address member);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Could not find available peer for state, backing off and retrying"", id = 75)
-   void couldNotFindPeerForState();
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Successfully retrieved and applied state from %s"", id = 76)
-   void successfullyAppliedState(Address member);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Message or message buffer is null or empty."", id = 77)
    void msgOrMsgBufferEmpty();
@@ -461,15 +389,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""getCoordinator(): Interrupted while waiting for members to be set"", id = 89)
    void interruptedWaitingForCoordinator(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Unable to retrieve state from member %s"", id = 90)
-   void unableToRetrieveState(Address member, @Cause Exception e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Channel does not contain STREAMING_STATE_TRANSFER. "" +
-         ""Cannot support state transfers!"", id = 91)
-   void streamingStateTransferNotPresent();
-
    @LogMessage(level = WARN)
    @Message(value = ""Channel not set up properly!"", id = 92)
    void channelNotSetUp();
@@ -482,10 +401,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Received new cluster view: %s"", id = 94)
    void receivedClusterView(View newView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Caught while requesting or applying state"", id = 96)
-   void errorRequestingOrApplyingState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error while processing a prepare in a single-phase transaction"", id = 97)
    void errorProcessing1pcPrepareCommand(@Cause Throwable e);
@@ -688,14 +603,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Failed loading value for key %s from cache store"", id = 144)
    void failedLoadingValueFromCacheStore(Object key, @Cause Exception e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error during rehash"", id = 145)
-   void errorDuringRehash(@Cause Throwable th);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error transferring state to node after rehash"", id = 146)
-   void errorTransferringState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error invalidating keys from L1 after rehash"", id = 147)
    void failedToInvalidateKeys(@Cause Exception e);
@@ -729,14 +636,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Unable to unlock keys %2$s for transaction %1$s after they were rebalanced off node %3$s"", id = 154)
    void unableToUnlockRebalancedKeys(GlobalTransaction gtx, List<Object> keys, Address self, @Cause Throwable t);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm pushing data for view %d, received confirmations %s. Cancelling state transfer"", id = 157)
-   void stateTransferTimeoutWaitingForPushConfirmations(int viewId, Map<Address, Integer> pushConfirmations);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm joining for view %d, joined %s. Cancelling state transfer"", id = 158)
-   void stateTransferTimeoutWaitingForJoinConfirmations(int viewId, Map<Address, Integer> joinConfirmations);
-
    @LogMessage(level = WARN)
    @Message(value = ""Unblocking transactions failed"", id = 159)
    void errorUnblockingTransactions(@Cause Exception e);
@@ -761,26 +660,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Rolling back to cache view %d, but last committed view is %d"", id = 164)
    void cacheViewRollbackIdMismatch(int committedViewId, int committedView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error triggering a view installation for cache %s"", id = 165)
-   void errorTriggeringViewInstallation(@Cause RuntimeException e, String cacheName);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""View installation failed for cache %s"", id = 166)
-   void viewInstallationFailure(@Cause Throwable e, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Rejecting state pushed by node %s for view %d, there is no state transfer in progress (we are at view %d)"", id = 167)
-   void remoteStateRejected(Address sender, int viewId, int installedViewId);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error rolling back to cache view %1$d for cache %2$s"", id = 168)
-   void cacheViewRollbackFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error committing cache view %1$d for cache %2$s"", id = 169)
-   void cacheViewCommitFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
    @LogMessage(level = INFO)
    @Message(value = ""Strict peer-to-peer is enabled but the JGroups channel was started externally - this is very likely to result in RPC timeout errors on startup"", id = 171)
    void warnStrictPeerToPeerWithInjectedChannel();
@@ -926,5 +805,16 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @LogMessage(level = WARN)
    @Message(value = ""Could not interrupt as no thread found for command uuid %s"", id=207)
    void couldNotInterruptThread(UUID id);
-   
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""No live owners found for segment %d of cache %s. Current owners are:  %s. Faulty owners: %s"", id=208)
+   void noLiveOwnersFoundForSegment(int segmentId, String cacheName, Collection<Address> owners, Collection<Address> faultySources);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to retrieve transactions for segments %s of cache %s from node %s (node will not be retried)"", id=209)
+   void failedToRetrieveTransactionsForSegments(Collection<Integer> segments, String cacheName, Address source);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to request segments %s of cache %s from node %s (node will not be retried)"", id=210)
+   void failedToRequestSegments(Collection<Integer> segments, String cacheName, Address source);
 }",2012-11-07T14:07:34Z,45
"@@ -263,7 +263,7 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm, boolean deprecated) {
 
       assert gc.asyncTransportExecutor().factory() instanceof DefaultExecutorFactory;
       // Should be 25, but it's overriden by the test cache manager factory
-      assertEquals(""4"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
+      assertEquals(""6"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
       assert gc.asyncTransportExecutor().properties().getProperty(""threadNamePrefix"").equals(""AsyncSerializationThread"");
 
       assert gc.evictionScheduledExecutor().factory() instanceof DefaultScheduledExecutorFactory;",2012-11-07T14:07:34Z,128
"@@ -50,7 +50,6 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -126,7 +125,7 @@ public void test1() throws Exception {
       when(cache.getName()).thenReturn(""testCache"");
 
       StateProvider stateProvider = mock(StateProvider.class);
-      LocalTopologyManager localTopologyManager = mock(LocalTopologyManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
       CacheNotifier cacheNotifier = mock(CacheNotifier.class);
       ExecutorService mockExecutorService = mock(ExecutorService.class);
       RpcManager rpcManager = mock(RpcManager.class);
@@ -183,7 +182,7 @@ public Map<Address, Response> answer(InvocationOnMock invocation) {
 
       // create state provider
       StateConsumerImpl stateConsumer = new StateConsumerImpl();
-      stateConsumer.init(cache, localTopologyManager, interceptorChain, icc, configuration, rpcManager,
+      stateConsumer.init(cache, stateTransferManager, interceptorChain, icc, configuration, rpcManager,
             commandsFactory, cacheLoaderManager, dataContainer, transactionTable, stateTransferLock);
       stateConsumer.start();
 ",2012-11-07T14:07:34Z,56
"@@ -40,6 +40,7 @@
 
 /**
  * Test if state transfer happens properly on a cache with pessimistic transactions.
+ * See https://issues.jboss.org/browse/ISPN-2408.
  *
  * @since 5.2
  */",2012-11-07T14:07:34Z,129
"@@ -75,6 +75,8 @@
  */
 public class TestCacheManagerFactory {
 
+   private static final int MAX_ASYNC_EXEC_THREADS = 6;
+
    public static final String MARSHALLER = LegacyKeySupportSystemProperties.getProperty(""infinispan.test.marshaller.class"", ""infinispan.marshaller.class"");
    private static final Log log = LogFactory.getLog(TestCacheManagerFactory.class);
 
@@ -523,12 +525,12 @@ private static void checkTestName(String fullTestName) {
 
    public static void minimizeThreads(GlobalConfiguration gc) {
       Properties p = new Properties();
-      p.setProperty(""maxThreads"", ""4"");
+      p.setProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
       gc.setAsyncTransportExecutorProperties(p);
    }
 
    public static void minimizeThreads(GlobalConfigurationBuilder builder) {
-      builder.asyncTransportExecutor().addProperty(""maxThreads"", ""4"");
+      builder.asyncTransportExecutor().addProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
    }
 
    public static void amendMarshaller(GlobalConfiguration configuration) {",2012-11-07T14:07:34Z,130
"@@ -35,7 +35,6 @@
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.TransactionTable;
@@ -58,14 +57,9 @@ public abstract class AbstractTxLockingInterceptor extends AbstractLockingInterc
    public void setDependencies(TransactionTable txTable, RpcManager rpcManager) {
       this.txTable = txTable;
       this.rpcManager = rpcManager;
-   }
-
-   @Start
-   private void setClustered() {
       clustered = rpcManager != null;
    }
 
-
    @Override
    public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand command) throws Throwable {
       try {
@@ -169,10 +163,12 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
       TxInvocationContext txContext = (TxInvocationContext) ctx;
       int transactionViewId = -1;
+      boolean useStrictComparison = true;
       if (clustered) {
          transactionViewId = txContext.getCacheTransaction().getViewId();
          if (transactionViewId != TransactionTable.CACHE_STOPPED_VIEW_ID) {
-            checkForPendingLocks = transactionViewId > txTable.getMinViewId();
+            useStrictComparison = txTable.useStrictTopologyIdComparison();
+            checkForPendingLocks = isFromOlderTopology(txTable.getMinViewId(), transactionViewId, useStrictComparison);
          }
       }
 
@@ -183,15 +179,15 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
 
          // Check local transactions first
          for (CacheTransaction ct: txTable.getLocalTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
          }
 
          // ... then remote ones
          for (CacheTransaction ct: txTable.getRemoteTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
@@ -211,6 +207,19 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
    }
 
+   /**
+    * Checks if first topology id is smaller than the second. The comparison can be strict or non-strict,
+    * depending on the isStrictComparison flag.
+    *
+    * @param tx1TopologyId topology id of first transaction
+    * @param tx2TopologyId topology id of second transaction
+    * @param useStrictComparison a flag indicating if comparison must be strict
+    * @return if the first transaction was started in an older topology than the second transaction
+    */
+   private boolean isFromOlderTopology(int tx1TopologyId, int tx2TopologyId, boolean useStrictComparison) {
+      return useStrictComparison ? tx1TopologyId < tx2TopologyId : tx1TopologyId <= tx2TopologyId;
+   }
+
    private TimeoutException newTimeoutException(Object key, TxInvocationContext txContext) {
       return new TimeoutException(""Could not acquire lock on "" + key + "" on behalf of transaction "" +
                                        txContext.getGlobalTransaction() + "". Lock is being held by "" + lockManager.getOwner(key));",2012-09-21T12:26:43Z,131
"@@ -109,9 +109,7 @@ public interface CacheNotifier extends Listenable {
     */
    void notifyTransactionRegistered(GlobalTransaction globalTransaction, InvocationContext ctx);
 
-   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre);
-
-   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre);
-
+   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre);
 
+   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre);
 }
\ No newline at end of file",2012-09-21T12:26:43Z,132
"@@ -334,24 +334,25 @@ public void notifyTransactionRegistered(GlobalTransaction globalTransaction, Inv
    }
 
    @Override
-   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre) {
+   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre) {
       if (!dataRehashedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, DATA_REHASHED);
          e.setPre(pre);
          e.setMembersAtStart(oldView);
          e.setMembersAtEnd(newView);
-         e.setNewViewId(newViewId);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : dataRehashedListeners) listener.invoke(e);
       }
    }
 
    @Override
-   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre) {
+   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre) {
       if (!topologyChangedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, TOPOLOGY_CHANGED);
          e.setPre(pre);
          e.setConsistentHashAtStart(oldConsistentHash);
          e.setConsistentHashAtEnd(newConsistentHash);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : topologyChangedListeners) listener.invoke(e);
       }
    }",2012-09-21T12:26:43Z,133
"@@ -43,7 +43,7 @@ public interface DataRehashedEvent<K, V> extends Event<K, V> {
    Collection<Address> getMembersAtEnd();
 
    /**
-    * @return Retrieves the new view id after rehashing was triggered.
+    * @return Retrieves the new topology id after rehashing was triggered.
     */
-   long getNewViewId();
+   int getNewTopologyId();
 }",2012-09-21T12:26:43Z,134
"@@ -53,7 +53,7 @@ public class EventImpl<K, V> implements CacheEntryActivatedEvent, CacheEntryCrea
    private V value;
    private Collection<Address> membersAtStart, membersAtEnd;
    private ConsistentHash consistentHashAtStart, consistentHashAtEnd;
-   private long newViewId;
+   private int newTopologyId;
    private Map<Object, Object> entries;
 
    public EventImpl() {
@@ -150,8 +150,8 @@ public void setConsistentHashAtEnd(ConsistentHash consistentHashAtEnd) {
       this.consistentHashAtEnd = consistentHashAtEnd;
    }
 
-   public void setNewViewId(long newViewId) {
-      this.newViewId = newViewId;
+   public void setNewTopologyId(int newTopologyId) {
+      this.newTopologyId = newTopologyId;
    }
 
    @Override
@@ -189,7 +189,7 @@ public boolean equals(Object o) {
       if (!Util.safeEquals(consistentHashAtEnd, event.consistentHashAtEnd)) return false;
       if (!Util.safeEquals(membersAtStart, event.membersAtStart)) return false;
       if (!Util.safeEquals(membersAtEnd, event.membersAtEnd)) return false;
-      if (newViewId != event.newViewId) return false;
+      if (newTopologyId != event.newTopologyId) return false;
 
       return true;
    }
@@ -208,7 +208,7 @@ public int hashCode() {
       result = 31 * result + (membersAtEnd != null ? membersAtEnd.hashCode() : 0);
       result = 31 * result + (consistentHashAtStart != null ? consistentHashAtStart.hashCode() : 0);
       result = 31 * result + (consistentHashAtEnd != null ? consistentHashAtEnd.hashCode() : 0);
-      result = 31 * result + ((int) newViewId);
+      result = 31 * result + ((int) newTopologyId);
       return result;
    }
 
@@ -236,8 +236,8 @@ public Collection<Address> getMembersAtEnd() {
    }
 
    @Override
-   public long getNewViewId() {
-      return newViewId;
+   public int getNewTopologyId() {
+      return newTopologyId;
    }
 
    @Override",2012-09-21T12:26:43Z,135
"@@ -40,5 +40,7 @@ public interface TopologyChangedEvent<K, V> extends Event<K, V> {
     */
    ConsistentHash getConsistentHashAtEnd();
 
+   int getNewTopologyId();
+
    //todo [anistor] add topologyId, prevReadCH, prevWriteCH, newReadCH2, newWriteCH
 }",2012-09-21T12:26:43Z,136
"@@ -95,7 +95,7 @@ public class StateConsumerImpl implements StateConsumer {
    private AtomicInteger activeTopologyUpdates = new AtomicInteger(0);
 
    /**
-    * Indicates if currently executing topology update is a rabalance.
+    * Indicates if the currently executing topology update is a rebalance.
     */
    private AtomicBoolean rebalanceInProgress = new AtomicBoolean(false);
 
@@ -197,8 +197,10 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             removedSegments.removeAll(newSegments);
 
             // remove inbound transfers and any data for segments we no longer own
-            log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                  removedSegments, newSegments, previousSegments);
+            if (trace) {
+               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
+                     removedSegments, newSegments, previousSegments);
+            }
             discardSegments(removedSegments);
 
             if (fetchEnabled) {",2012-09-21T12:26:43Z,54
"@@ -80,7 +80,7 @@ public class StateProviderImpl implements StateProvider {
    private volatile ConsistentHash readCh;
 
    /**
-    * A map that keeps track of current outbound state transfers by source address. There could be multiple transfers
+    * A map that keeps track of current outbound state transfers by destination address. There could be multiple transfers
     * flowing to the same destination (but for different segments) so the values are lists.
     */
    private final Map<Address, List<OutboundTransferTask>> transfersByDestination = new HashMap<Address, List<OutboundTransferTask>>();
@@ -124,6 +124,7 @@ public boolean isStateTransferInProgress() {
    }
 
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // do all the work AFTER the consistent hash has changed
       if (tce.isPre())
@@ -236,12 +237,14 @@ private void collectTransactionsToTransfer(List<TransactionInfo> transactionsToT
                lockedKeys.add(key);
             }
          }
-         List<WriteCommand> txModifications = tx.getModifications();
-         WriteCommand[] modifications = null;
-         if (txModifications != null) {
-            modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+         if (!lockedKeys.isEmpty()) {
+            List<WriteCommand> txModifications = tx.getModifications();
+            WriteCommand[] modifications = null;
+            if (txModifications != null) {
+               modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+            }
+            transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), tx.getViewId(), modifications, lockedKeys));
          }
-         transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), modifications, lockedKeys));
       }
    }
 ",2012-09-21T12:26:43Z,55
"@@ -48,10 +48,9 @@
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 
+//todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
 /**
  * // TODO: Document this
  *
@@ -317,8 +316,8 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       } finally {
          stateTransferLock.commandsSharedUnlock();
 
-         log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
          if (newTargets != null && !newTargets.isEmpty()) {
+            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
             rpcManager.invokeRemotely(newTargets, command, true);
          }
       }",2012-09-21T12:26:43Z,115
"@@ -178,19 +178,20 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
       // TODO Improve notification to contain both CHs
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, true);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), true);
 
       stateConsumer.onTopologyUpdate(newCacheTopology, isRebalance);
       stateProvider.onTopologyUpdate(newCacheTopology, isRebalance);
 
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, false);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
       if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
          initialStateTransferComplete.countDown();
       }
    }
 
    @Start(priority = 1000)
+   @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
       if (trace) log.tracef(""Waiting for initial state transfer to finish"");
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);",2012-09-21T12:26:43Z,117
"@@ -50,8 +50,11 @@ public class TransactionInfo {
 
    private final Set<Object> lockedKeys;
 
-   public TransactionInfo(GlobalTransaction globalTransaction, WriteCommand[] modifications, Set<Object> lockedKeys) {
+   private final int topologyId;
+
+   public TransactionInfo(GlobalTransaction globalTransaction, int topologyId, WriteCommand[] modifications, Set<Object> lockedKeys) {
       this.globalTransaction = globalTransaction;
+      this.topologyId = topologyId;
       this.modifications = modifications;
       this.lockedKeys = lockedKeys;
    }
@@ -68,10 +71,15 @@ public Set<Object> getLockedKeys() {
       return lockedKeys;
    }
 
+   public int getTopologyId() {
+      return topologyId;
+   }
+
    @Override
    public String toString() {
       return ""TransactionInfo{"" +
             ""globalTransaction="" + globalTransaction +
+            "", topologyId="" + topologyId +
             "", modifications="" + Arrays.asList(modifications) +
             "", lockedKeys="" + lockedKeys +
             '}';
@@ -92,6 +100,7 @@ public Set<Class<? extends TransactionInfo>> getTypeClasses() {
       @Override
       public void writeObject(ObjectOutput output, TransactionInfo object) throws IOException {
          output.writeObject(object.globalTransaction);
+         output.writeInt(object.topologyId);
          output.writeObject(object.modifications);
          output.writeObject(object.lockedKeys);
       }
@@ -100,9 +109,10 @@ public void writeObject(ObjectOutput output, TransactionInfo object) throws IOEx
       @SuppressWarnings(""unchecked"")
       public TransactionInfo readObject(ObjectInput input) throws IOException, ClassNotFoundException {
          GlobalTransaction globalTransaction = (GlobalTransaction) input.readObject();
+         int topologyId = input.readInt();
          WriteCommand[] modifications = (WriteCommand[]) input.readObject();
          Set<Object> lockedKeys = (Set<Object>) input.readObject();
-         return new TransactionInfo(globalTransaction, modifications, lockedKeys);
+         return new TransactionInfo(globalTransaction, topologyId, modifications, lockedKeys);
       }
    }
 }",2012-09-21T12:26:43Z,137
"@@ -31,8 +31,6 @@
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
 import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.MembershipArithmetic;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
@@ -67,37 +65,41 @@ public class StaleTransactionCleanupService {
    private TransactionTable transactionTable;
    private InterceptorChain invoker;
    private String cacheName;
+   private boolean isDistributed;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
    private ExecutorService lockBreakingService; // a thread pool with max. 1 thread
 
-   /**
-    * Roll back remote transactions originating on nodes that have left the cluster.
-    */
-   @ViewChanged
-   public void onViewChange(ViewChangedEvent vce) {
-      final List<Address> leavers = MembershipArithmetic.getMembersLeft(vce.getOldMembers(),
-                                                                        vce.getNewMembers());
-      if (!leavers.isEmpty()) {
-         log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-         cleanTxForWhichTheOwnerLeft(leavers);
-      }
-   }
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * either because the main data owner left the cluster or because a node joined
     * the cluster and is the new data owner.
     * This method will only ever be called in distributed mode.
     */
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
-      // do all the work AFTER the consistent hash has changed
-      if (tce.isPre())
+      // Roll back remote transactions originating on nodes that have left the cluster.
+      if (tce.isPre()) {
+         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+         if (consistentHashAtStart != null) {
+            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+            if (!leavers.isEmpty()) {
+               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+               cleanTxForWhichTheOwnerLeft(leavers);
+            }
+         }
+         return;
+      }
+
+      if (!isDistributed) {
          return;
+      }
+
+      // do all the work AFTER the consistent hash has changed
 
       Address self = transactionTable.rpcManager.getAddress();
       ConsistentHash chOld = tce.getConsistentHashAtStart();
@@ -173,7 +175,7 @@ public void run() {
       }
    }
 
-   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain) {
+   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain, boolean isDistributed) {
       this.invoker = interceptorChain;
       ThreadFactory tf = new ThreadFactory() {
          @Override
@@ -185,8 +187,9 @@ public Thread newThread(Runnable r) {
          }
       };
       this.cacheName = cacheName;
+      this.isDistributed = isDistributed;
       lockBreakingService = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingDeque<Runnable>(), tf,
-                                                   new ThreadPoolExecutor.CallerRunsPolicy());
+                                                   new ThreadPoolExecutor.DiscardOldestPolicy());
    }
 
    public void stop() {",2012-09-21T12:26:43Z,126
"@@ -38,11 +38,10 @@
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.interceptors.InterceptorChain;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
-import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
+import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.synchronization.SyncLocalTransaction;
@@ -57,9 +56,7 @@
 
 import javax.transaction.Transaction;
 import javax.transaction.TransactionSynchronizationRegistry;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.locks.Lock;
@@ -76,7 +73,7 @@
  * @author Galder Zamarreño
  * @since 4.0
  */
-@Listener(sync = false)
+@Listener
 public class TransactionTable {
 
    public static final int CACHE_STOPPED_VIEW_ID = -1;
@@ -95,25 +92,23 @@ public class TransactionTable {
    protected CommandsFactory commandsFactory;
    private InterceptorChain invoker;
    private CacheNotifier notifier;
-   private EmbeddedCacheManager cm;
    private TransactionSynchronizationRegistry transactionSynchronizationRegistry;
    protected ClusteringDependentLogic clusteringLogic;
    protected boolean clustered = false;
    private Lock minViewRecalculationLock;
 
    /**
-    * minTxViewId is the minimum view ID across all ongoing local and remote transactions. It doesn't update on
-    * transaction creation, but only on removal. That's because it is not possible for a newly created transaction to
-    * have an bigger view ID than the current one.
+    * minTxViewId is the minimum view ID across all ongoing local and remote transactions.
     */
    private volatile int minTxViewId = CACHE_STOPPED_VIEW_ID;
    private volatile int currentViewId = CACHE_STOPPED_VIEW_ID;
+   private volatile boolean useStrictTopologyIdComparison = true;
    private String cacheName;
 
    @Inject
    public void initialize(RpcManager rpcManager, Configuration configuration,
                           InvocationContextContainer icc, InterceptorChain invoker, CacheNotifier notifier,
-                          TransactionFactory gtf, EmbeddedCacheManager cm, TransactionCoordinator txCoordinator,
+                          TransactionFactory gtf, TransactionCoordinator txCoordinator,
                           TransactionSynchronizationRegistry transactionSynchronizationRegistry,
                           CommandsFactory commandsFactory, ClusteringDependentLogic clusteringDependentLogic, Cache cache) {
       this.rpcManager = rpcManager;
@@ -122,7 +117,6 @@ public void initialize(RpcManager rpcManager, Configuration configuration,
       this.invoker = invoker;
       this.notifier = notifier;
       this.txFactory = gtf;
-      this.cm = cm;
       this.txCoordinator = txCoordinator;
       this.transactionSynchronizationRegistry = transactionSynchronizationRegistry;
       this.commandsFactory = commandsFactory;
@@ -139,24 +133,20 @@ private void start() {
          minViewRecalculationLock = new ReentrantLock();
          // Only initialize this if we are clustered.
          remoteTransactions = ConcurrentMapFactory.makeConcurrentMap(concurrencyLevel, 0.75f, concurrencyLevel);
-         cleanupService.start(cacheName, rpcManager, invoker);
-         cm.addListener(cleanupService);
-         cm.addListener(this);
+         cleanupService.start(cacheName, rpcManager, invoker, configuration.clustering().cacheMode().isDistributed());
          notifier.addListener(cleanupService);
-         minTxViewId = rpcManager.getTransport().getViewId();
-         currentViewId = minTxViewId;
-         log.debugf(""Min view id set to %s"", minTxViewId);
+         notifier.addListener(this);
          clustered = true;
       }
    }
 
    @Stop
+   @SuppressWarnings(""unused"")
    private void stop() {
       if (clustered) {
          notifier.removeListener(cleanupService);
-         cm.removeListener(cleanupService);
          cleanupService.stop();
-         cm.removeListener(this);
+         notifier.removeListener(this);
          currentViewId = CACHE_STOPPED_VIEW_ID; // indicate that the cache has stopped
       }
       shutDownGracefully();
@@ -223,6 +213,17 @@ public int getMinViewId() {
       return minTxViewId;
    }
 
+   /**
+    * Indicates if topology id comparisons should be strict if one wants to compare topology ids in oder to tell
+    * if a transaction was started in an older topology than a second transaction. This flag is true most of the time
+    * except when the current topology did not increase its id (it's not caused by a rebalance).
+    *
+    * @return true if strict topology id comparisons should be used, false otherwise
+    */
+   public boolean useStrictTopologyIdComparison() {
+      return useStrictTopologyIdComparison;
+   }
+
    protected void updateStateOnNodesLeaving(Collection<Address> leavers) {
       Set<GlobalTransaction> toKill = new HashSet<GlobalTransaction>();
       for (GlobalTransaction gt : remoteTransactions.keySet()) {
@@ -263,14 +264,24 @@ public void remoteTransactionRollback(GlobalTransaction gtx) {
    }
 
    /**
-    * Creates and register a {@link RemoteTransaction} with no modifications. Returns the created transaction.
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
     *
     * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
     *                               made.
     */
    public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications) {
-      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, currentViewId)
-            : txFactory.newRemoteTransaction(modifications, globalTx, currentViewId);
+      return createRemoteTransaction(globalTx, modifications, currentViewId);
+   }
+
+   /**
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
+    *
+    * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
+    *                               made.
+    */
+   public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications, int topologyId) {
+      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, topologyId)
+            : txFactory.newRemoteTransaction(modifications, globalTx, topologyId);
       registerRemoteTransaction(globalTx, remoteTransaction);
       return remoteTransaction;
    }
@@ -283,6 +294,10 @@ private void registerRemoteTransaction(GlobalTransaction gtx, RemoteTransaction
       }
 
       log.tracef(""Created and registered remote transaction %s"", rtx);
+      if (rtx.getViewId() < minTxViewId) {
+         log.tracef(""Changing minimum view ID from %d to %d"", minTxViewId, rtx.getViewId());
+         minTxViewId = rtx.getViewId();
+      }
    }
 
    /**
@@ -293,6 +308,9 @@ public LocalTransaction getOrCreateLocalTransaction(Transaction transaction, TxI
       LocalTransaction current = localTransactions.get(transaction);
       if (current == null) {
          Address localAddress = rpcManager != null ? rpcManager.getTransport().getAddress() : null;
+         if (rpcManager != null && currentViewId < 0) {
+            throw new IllegalStateException(""Cannot create transactions if topology id is not known yet!"");
+         }
          GlobalTransaction tx = txFactory.newGlobalTransaction(localAddress, false);
          current = txFactory.newLocalTransaction(transaction, tx, ctx.isImplicitTransaction(), currentViewId);
          log.tracef(""Created a new local transaction: %s"", current);
@@ -310,10 +328,6 @@ public boolean removeLocalTransaction(LocalTransaction localTransaction) {
       return localTransaction != null && (removeLocalTransactionInternal(localTransaction.getTransaction()) != null);
    }
 
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      return removeLocalTransactionInternal(tx);
-   }
-
    protected final LocalTransaction removeLocalTransactionInternal(Transaction tx) {
       LocalTransaction removed;
       removed = localTransactions.remove(tx);
@@ -357,8 +371,8 @@ public int getLocalTxCount() {
 
    /**
     * Looks up a LocalTransaction given a GlobalTransaction.
-    * @param txId
-    * @return
+    * @param txId the global transaction identifier
+    * @return the LocalTransaction or null if not found
     */
    public LocalTransaction getLocalTransaction(GlobalTransaction txId) {
       for (LocalTransaction localTx : localTransactions.values()) { //todo [anistor] optimize lookup!
@@ -402,17 +416,21 @@ protected final void recalculateMinViewIdIfNeeded(CacheTransaction removedTransa
       }
    }
 
-   @ViewChanged
-   public void recalculateMinViewIdOnTopologyChange(ViewChangedEvent vce) {
-      // don't do anything if this cache is not clustered - view changes are global
+   @TopologyChanged
+   @SuppressWarnings(""unused"")
+   public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
+      // don't do anything if this cache is not clustered
       if (clustered) {
-         log.debugf(""View changed, recalculating minViewId"");
-         currentViewId = vce.getViewId();
-         calculateMinViewId(-1);
+         if (tce.isPre()) {
+            useStrictTopologyIdComparison = tce.getNewTopologyId() != currentViewId;
+            currentViewId = tce.getNewTopologyId();
+         } else {
+            log.debugf(""Topology changed, recalculating minViewId"");
+            calculateMinViewId(-1);
+         }
       }
    }
 
-
    /**
     * This method calculates the minimum view ID known by the current node.  This method is only used in a clustered
     * cache, and only invoked when either a view change is detected, or a transaction whose view ID is not the same as
@@ -442,7 +460,7 @@ private void calculateMinViewId(int idOfRemovedTransaction) {
                int viewId = ct.getViewId();
                if (viewId < minViewIdFound) minViewIdFound = viewId;
             }
-            if (minViewIdFound > minTxViewId) {
+            if (minViewIdFound != minTxViewId) {
                log.tracef(""Changing minimum view ID from %s to %s"", minTxViewId, minViewIdFound);
                minTxViewId = minViewIdFound;
             } else {",2012-09-21T12:26:43Z,127
"@@ -80,13 +80,6 @@ private void removeXidTxMapping(LocalXaTransaction localTx) {
       xid2LocalTx.remove(xid);
    }
 
-   @Override
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      final LocalTransaction remove = removeLocalTransactionInternal(tx);
-      if (remove != null) removeXidTxMapping((LocalXaTransaction) remove);
-      return remove;
-   }
-
    public LocalXaTransaction getLocalTransaction(Xid xid) {
       return this.xid2LocalTx.get(xid);
    }",2012-09-21T12:26:43Z,138
"@@ -22,10 +22,8 @@
  */
 package org.infinispan.util.concurrent.locks;
 
-import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.jmx.annotations.MBean;",2012-09-21T12:26:43Z,139
"@@ -93,15 +93,16 @@ public boolean isSatisfied() throws Exception {
          public void run() {
             try {
                log.trace(""This thread runs a different tx"");
-               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).resume(suspend);
+               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).commit();
             } catch (Exception e) {
                e.printStackTrace();
             }
          }
       }, false);
 
+      // this 'ensures' transaction called 'suspend' has the chance to start the prepare phase and is waiting to acquire the locks on k held by first transaction before it gets resumed
       Thread.sleep(1000);
 
       log.trace(""Before completing the transaction!"");",2012-09-21T12:26:43Z,140
"@@ -21,7 +21,7 @@
 /**
  * @since 5.1
  */
-@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"", enabled = false) //todo [anistor] temporarily disabled for NBST
+@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"")
 @CleanupAfterMethod
 public class MainOwnerChangesLockTest extends MultipleCacheManagersTest {
 ",2012-09-21T12:26:43Z,141
"@@ -24,6 +24,7 @@
 package org.infinispan.lock.singlelock;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.CleanupAfterMethod;
@@ -33,8 +34,7 @@
 import org.infinispan.transaction.tm.DummyTransaction;
 import org.testng.annotations.Test;
 
-import javax.transaction.Status;
-
+import static org.testng.Assert.assertTrue;
 import static org.testng.Assert.assertEquals;
 
 
@@ -60,21 +60,22 @@ protected void createCacheManagers() throws Throwable {
       waitForClusterToForm();
    }
 
-   @Test(enabled = false, description = ""See ISPN-2113"")
    public void testMinViewId1() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
+
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);
 
       //add a new cache and check that min view is updated
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId2);
       assertEquals(tt1.getMinViewId(), viewId2);
@@ -88,8 +89,8 @@ public void testMinViewId2() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
 
       tm(1).begin();
       cache(1).put(getKeyForCache(0),""v"");
@@ -109,8 +110,8 @@ public boolean isSatisfied() throws Exception {
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);",2012-09-21T12:26:43Z,142
"@@ -36,7 +36,6 @@
 import javax.transaction.InvalidTransactionException;
 import javax.transaction.NotSupportedException;
 import javax.transaction.RollbackException;
-import javax.transaction.Status;
 import javax.transaction.SystemException;
 
 import static org.testng.Assert.assertEquals;
@@ -45,7 +44,7 @@
  * @author Mircea Markus
  * @since 5.1
  */
-@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"", enabled = false, description = ""See ISPN-2113"")
+@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"")
 @CleanupAfterMethod
 public class LockOwnerCrashPessimisticTest extends AbstractLockOwnerCrashTest {
 ",2012-09-21T12:26:43Z,143
"@@ -159,9 +159,8 @@
       <version.netty>3.2.6.Final</version.netty>
       <version.org.jboss.naming>5.0.6.CR1</version.org.jboss.naming>
       <version.resteasy>2.2.1.GA</version.resteasy>
-      <version.rhq.pluginAnnotations>3.0.4</version.rhq.pluginAnnotations>
-      <version.rhq.plugingen>3.0.4</version.rhq.plugingen>
-      <version.rhq>3.0.0</version.rhq>
+      <version.rhq.helpers>3.0.4</version.rhq.helpers>
+      <version.rhq>4.2.0</version.rhq>
       <version.scala>2.9.1</version.scala>
       <version.slf4j>1.6.1</version.slf4j>
       <version.solder>3.1.0.Final</version.solder>
@@ -575,7 +574,12 @@
          <dependency>
             <groupId>org.rhq.helpers</groupId>
             <artifactId>rhq-pluginAnnotations</artifactId>
-            <version>${version.rhq}</version>
+            <version>${version.rhq.helpers}</version>
+         </dependency>
+         <dependency>
+            <groupId>org.rhq.helpers</groupId>
+            <artifactId>rhq-pluginGen</artifactId>
+            <version>${version.rhq.helpers}</version>
          </dependency>
          <dependency>
             <groupId>org.scala-lang</groupId>",2012-02-27T09:15:52Z,152
"@@ -52,6 +52,12 @@
          <groupId>org.rhq</groupId>
          <artifactId>rhq-core-domain</artifactId>
          <scope>provided</scope>
+         <exclusions>
+            <exclusion>
+               <groupId>hibernate</groupId>
+               <artifactId>hibernate3</artifactId>
+            </exclusion>
+         </exclusions>
       </dependency>
       <dependency>
          <groupId>org.rhq</groupId>
@@ -78,21 +84,18 @@
       </dependency>
 
       <dependency>
-         <groupId>${project.groupId}</groupId>
-         <artifactId>infinispan-core</artifactId>
-      </dependency>
-      
-      <dependency>
-         <groupId>${project.groupId}</groupId>
-         <artifactId>infinispan-tools</artifactId>
+         <groupId>commons-logging</groupId>
+         <artifactId>commons-logging</artifactId>
+         <scope>provided</scope>
       </dependency>
 
       <dependency>
-         <groupId>${project.groupId}</groupId>
-         <artifactId>infinispan-server-core</artifactId>
-         <scope>provided</scope>
+            <groupId>org.jboss.logging</groupId>
+            <artifactId>jboss-logging</artifactId>
+            <scope>provided</scope>
       </dependency>
 
+      <!-- Crazy dependencies to solve the usual compiler bug with unavailable annotations -->
       <dependency>
          <groupId>javax.persistence</groupId>
          <artifactId>persistence-api</artifactId>
@@ -112,6 +115,19 @@
          <version>${version.hibernate.annotations}</version>
          <scope>provided</scope>
       </dependency>
+      
+      <!-- Dependencies for plugin descriptor generation -->
+      <dependency>
+         <groupId>${project.groupId}</groupId>
+         <artifactId>infinispan-core</artifactId>
+         <scope>provided</scope>
+      </dependency>
+      
+      <dependency>
+         <groupId>${project.groupId}</groupId>
+         <artifactId>infinispan-server-core</artifactId>
+         <scope>provided</scope>
+      </dependency>
 
       <dependency>
          <groupId>${project.groupId}</groupId>
@@ -154,7 +170,7 @@
             </executions>
          </plugin>
          
-         <plugin>
+         <!-- <plugin>
              <artifactId>maven-dependency-plugin</artifactId>
              <executions>
                  <execution>
@@ -165,7 +181,7 @@
                      </goals>
                      <configuration>
                          <artifactItems>
-                             <!-- TODO include other needed external jars that should go into your jar file -->
+                             TODO include other needed external jars that should go into your jar file
                              <artifactItem>
                                  <groupId>org.infinispan</groupId>
                                  <artifactId>infinispan-core</artifactId>
@@ -181,7 +197,7 @@
                      </configuration>
                  </execution>
              </executions>
-         </plugin>
+         </plugin> -->
  
          <plugin>
             <groupId>org.apache.maven.plugins</groupId>",2012-02-27T09:15:52Z,547
"@@ -22,9 +22,8 @@
  */
 package org.infinispan.rhq;
 
-import org.infinispan.lifecycle.ComponentStatus;
-import org.infinispan.rhq.logging.Log;
-import org.infinispan.util.logging.LogFactory;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.mc4j.ems.connection.EmsConnection;
 import org.mc4j.ems.connection.bean.EmsBean;
 import org.mc4j.ems.connection.bean.attribute.EmsAttribute;
@@ -55,7 +54,7 @@
  * @author Galder Zamarreño
  */
 public class CacheComponent extends MBeanResourceComponent<CacheManagerComponent> {
-   private static final Log log = LogFactory.getLog(CacheComponent.class, Log.class);
+   private static final Log log = LogFactory.getLog(CacheComponent.class);
 
    private ResourceContext<CacheManagerComponent> context;
    private String cacheManagerName;
@@ -66,18 +65,19 @@ public class CacheComponent extends MBeanResourceComponent<CacheManagerComponent
     *
     * @see org.rhq.core.pluginapi.inventory.ResourceComponent#getAvailability()
     */
+   @Override
    public AvailabilityType getAvailability() {
       boolean trace = log.isTraceEnabled();
       EmsConnection conn = getConnection();
       try {
          conn.refresh();
          EmsBean bean = queryCacheBean();
-         if (bean != null && bean.getAttribute(""CacheStatus"").getValue().equals(ComponentStatus.RUNNING.toString())) {
+         if (bean != null && bean.getAttribute(""CacheStatus"").getValue().equals(""RUNNING"")) {
             bean.refreshAttributes();
-            if (trace) log.tracef(""Cache %s within %s cache manager is running and attributes could be refreshed, so it's up."", cacheName, cacheManagerName);
+            if (trace) log.trace(""Cache ""+cacheName+"" within ""+cacheManagerName+"" cache manager is running and attributes could be refreshed, so it's up."");
             return AvailabilityType.UP;
          }
-         if (trace) log.tracef(""Cache status for %s within %s cache manager is anything other than running, so it's down."", cacheName, cacheManagerName);
+         if (trace) log.trace(""Cache status for ""+cacheName+"" within ""+cacheManagerName+"" cache manager is anything other than running, so it's down."");
          return AvailabilityType.DOWN;
       } catch (Exception e) {
          if (trace) log.trace(""There was an exception checking availability, so cache status is down."", e);
@@ -88,19 +88,21 @@ public AvailabilityType getAvailability() {
    /**
     * Start the resource connection
     */
+   @Override
    public void start(ResourceContext<CacheManagerComponent> context) {
       this.context = context;
       this.cacheManagerName = context.getParentResourceComponent().context.getResourceKey();
       this.cacheName = context.getResourceKey();
       if (log.isTraceEnabled())
-         log.tracef(""Start cache component for cache manager %s with cache key %s"", cacheManagerName, cacheName);
+         log.trace(""Start cache component for cache manager ""+cacheManagerName+"" with cache key ""+cacheName);
    }
 
    /**
     * Tear down the rescource connection
     *
     * @see org.rhq.core.pluginapi.inventory.ResourceComponent#stop()
     */
+   @Override
    public void stop() {
    }
 
@@ -110,44 +112,49 @@ public void stop() {
     * @see org.rhq.core.pluginapi.measurement.MeasurementFacet#getValues(org.rhq.core.domain.measurement.MeasurementReport,
     *      java.util.Set)
     */
+   @Override
    public void getValues(MeasurementReport report, Set<MeasurementScheduleRequest> metrics) {
       boolean trace = log.isTraceEnabled();
       if (trace) log.trace(""Get values metrics"");
       for (MeasurementScheduleRequest req : metrics) {
-         if (trace) log.tracef(""Inspect metric %s"", req);
+         if (trace) log.trace(""Inspect metric "" + req);
          String metric = req.getName();
          try {
             EmsBean bean = queryComponentBean(metric);
             if (bean != null) {
-               if (trace) log.tracef(""Retrieved mbean with name %s"", bean.getBeanName());
+               if (trace) log.trace(""Retrieved mbean with name ""+ bean.getBeanName());
                bean.refreshAttributes();
                String attName = metric.substring(metric.indexOf(""."") + 1);
                EmsAttribute att = bean.getAttribute(attName);
                // Attribute values are of various data types
                if (att != null) {
                   Object o = att.getValue();
-                  Class attrType = att.getTypeClass();
+                  Class<?> attrType = att.getTypeClass();
                   DataType type = req.getDataType();
                   if (type == DataType.MEASUREMENT) {
                      if (o != null) {
                         MeasurementDataNumeric res = constructNumericMeasure(attrType, o, req);
                         if (res != null) report.addData(res);
                      } else {
-                        if (log.isDebugEnabled()) log.debugf(""Metric (%s) has null value, do not add to report"", req.getName());
+                        if (log.isDebugEnabled()) log.debug(""Metric (""+req.getName()+"") has null value, do not add to report"");
                      }
                   } else if (type == DataType.TRAIT) {
                      String value = (String) o;
-                     if (trace) log.tracef(""Metric (%s) is trait with value %s"", req.getName(), value);
+                     if (trace) log.trace(""Metric (""+req.getName()+"") is trait with value "" + value);
                      MeasurementDataTrait res = new MeasurementDataTrait(req, value);
                      report.addData(res);
                   }
                } else {
-                  log.attributeNotFound(attName);
+                  if(log.isWarnEnabled()) {
+                     log.warn(""Attribute ""+attName+"" not found"");
+                  }
                }
             }
          }
          catch (Exception e) {
-            log.getValuesFailed(metric, e);
+            if(log.isWarnEnabled()) {
+               log.warn(""getValues failed for ""+metric, e);
+            }
          }
       }
    }
@@ -160,13 +167,14 @@ public void getValues(MeasurementReport report, Set<MeasurementScheduleRequest>
     * @return OperationResult object if successful
     * @throws Exception       If operation was not successful
     */
+   @Override
    public OperationResult invokeOperation(String fullOpName, Configuration parameters) throws Exception {
       boolean trace = log.isTraceEnabled();
       EmsBean bean = queryComponentBean(fullOpName);
       String opName = fullOpName.substring(fullOpName.indexOf(""."") + 1);
       EmsOperation ops = bean.getOperation(opName);
       Collection<PropertySimple> simples = parameters.getSimpleProperties().values();
-      if (trace) log.tracef(""Parameters, as simple properties, are %s"", simples);
+      if (trace) log.trace(""Parameters, as simple properties, are "" + simples);
       Object[] realParams = new Object[simples.size()];
       int i = 0;
       for (PropertySimple property : simples) {
@@ -176,9 +184,9 @@ public OperationResult invokeOperation(String fullOpName, Configuration paramete
 
       if (ops == null)
          throw new Exception(""Operation "" + fullOpName + "" can't be found"");
-      
+
       Object result = ops.invoke(realParams);
-      if (trace) log.tracef(""Returning operation result containing %s"", result.toString());
+      if (trace) log.trace(""Returning operation result containing "" + result.toString());
       return new OperationResult(result.toString());
    }
 
@@ -207,16 +215,18 @@ private EmsBean queryComponentBean(String name) {
    private EmsBean queryBean(String componentName) {
       EmsConnection conn = getConnection();
       String pattern = getSingleComponentPattern(cacheManagerName, cacheName, componentName);
-      if (log.isTraceEnabled()) log.tracef(""Pattern to query is %s"", pattern);
+      if (log.isTraceEnabled()) log.trace(""Pattern to query is "" + pattern);
       ObjectNameQueryUtility queryUtility = new ObjectNameQueryUtility(pattern);
       List<EmsBean> beans = conn.queryBeans(queryUtility.getTranslatedQuery());
       if (beans.size() > 1) {
          // If more than one are returned, most likely is due to duplicate domains which is not the general case
-         log.moreThanOneBeanReturned(pattern, beans);
+         if(log.isWarnEnabled()) {
+            log.warn(String.format(""More than one bean returned from applying %s pattern: %s"", pattern, beans));
+         }
       }
       EmsBean bean = beans.get(0);
       if (bean == null) {
-         if (log.isTraceEnabled()) log.tracef(""No mbean found with name %s"", pattern);
+         if (log.isTraceEnabled()) log.trace(""No mbean found with name "" + pattern);
       }
       return bean;
    }",2012-02-27T09:15:52Z,513
"@@ -22,8 +22,8 @@
  */
 package org.infinispan.rhq;
 
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.mc4j.ems.connection.EmsConnection;
 import org.mc4j.ems.connection.bean.EmsBean;
 import org.rhq.core.pluginapi.inventory.DiscoveredResourceDetails;
@@ -46,6 +46,7 @@ public class CacheDiscovery extends MBeanResourceDiscoveryComponent<CacheManager
    private static final Log log = LogFactory.getLog(CacheDiscovery.class);
 
    /** Run the discovery */
+   @Override
    public Set<DiscoveredResourceDetails> discoverResources(ResourceDiscoveryContext<CacheManagerComponent> ctx) {
       boolean trace = log.isTraceEnabled();
       if (trace) log.trace(""Discover resources with context"");
@@ -55,23 +56,23 @@ public Set<DiscoveredResourceDetails> discoverResources(ResourceDiscoveryContext
       if (trace) log.trace(""Connection to ems server established"");
 
       String pattern = getAllCachesPattern(ctx.getParentResourceContext().getResourceKey());
-      if (trace) log.tracef(""Pattern to query is %s"", pattern);
+      if (trace) log.trace(""Pattern to query is "" + pattern);
 
       ObjectNameQueryUtility queryUtility = new ObjectNameQueryUtility(pattern);
       List<EmsBean> beans = conn.queryBeans(queryUtility.getTranslatedQuery());
-      if (trace) log.tracef(""Querying [%s] returned beans: %s"", queryUtility.getTranslatedQuery(), beans);
+      if (trace) log.trace(""Querying ""+queryUtility.getTranslatedQuery()+"" returned beans: "" + beans);
 
       for (EmsBean bean : beans) {
          /* A discovered resource must have a unique key, that must
           * stay the same when the resource is discovered the next
           * time */
          String name = bean.getAttribute(""CacheName"").getValue().toString();
          String mbeanCacheName = bean.getBeanName().getKeyProperty(""name"");
-         if (trace) log.tracef(""Resource name is %s and resource key %s"", name, mbeanCacheName);
+         if (trace) log.trace(""Resource name is ""+name+"" and resource key ""+ mbeanCacheName);
          DiscoveredResourceDetails detail = new DiscoveredResourceDetails(
                ctx.getResourceType(), // Resource Type
                mbeanCacheName, // Resource Key
-               name, // Resource name 
+               name, // Resource name
                null, // Version
                ""One cache within Infinispan"", // ResourceDescription
                ctx.getDefaultPluginConfiguration(), // Plugin Config",2012-02-27T09:15:52Z,514
"@@ -22,8 +22,15 @@
  */
 package org.infinispan.rhq;
 
-import org.infinispan.rhq.logging.Log;
-import org.infinispan.util.logging.LogFactory;
+import static org.infinispan.rhq.RhqUtil.constructNumericMeasure;
+
+import java.util.List;
+import java.util.Set;
+
+import javax.management.ObjectName;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.mc4j.ems.connection.EmsConnection;
 import org.mc4j.ems.connection.bean.EmsBean;
 import org.mc4j.ems.connection.bean.attribute.EmsAttribute;
@@ -34,26 +41,18 @@
 import org.rhq.core.domain.measurement.MeasurementReport;
 import org.rhq.core.domain.measurement.MeasurementScheduleRequest;
 import org.rhq.core.pluginapi.inventory.ResourceContext;
-import org.rhq.plugins.jmx.JMXComponent;
 import org.rhq.plugins.jmx.MBeanResourceComponent;
 import org.rhq.plugins.jmx.ObjectNameQueryUtility;
 
-import javax.management.ObjectName;
-import java.util.List;
-import java.util.Set;
-
-import static org.infinispan.jmx.CacheManagerJmxRegistration.CACHE_MANAGER_JMX_GROUP;
-import static org.infinispan.rhq.RhqUtil.constructNumericMeasure;
-
 /**
  * The component class for the Infinispan manager
  *
  * @author Heiko W. Rupp
  * @author Galder Zamarreño
  */
-public class CacheManagerComponent extends MBeanResourceComponent<MBeanResourceComponent> {
-   private static final Log log = LogFactory.getLog(CacheManagerComponent.class, Log.class);
-   protected ResourceContext<JMXComponent> context;
+public class CacheManagerComponent extends MBeanResourceComponent<MBeanResourceComponent<?>> {
+   private static final Log log = LogFactory.getLog(CacheManagerComponent.class);
+   protected ResourceContext<MBeanResourceComponent<?>> context;
    private String cacheManagerPattern;
 
    /**
@@ -62,6 +61,7 @@ public class CacheManagerComponent extends MBeanResourceComponent<MBeanResourceC
     *
     * @see org.rhq.core.pluginapi.inventory.ResourceComponent#getAvailability()
     */
+   @Override
    public AvailabilityType getAvailability() {
       boolean trace = log.isTraceEnabled();
       EmsConnection conn = getEmsConnection();
@@ -70,7 +70,7 @@ public AvailabilityType getAvailability() {
          EmsBean bean = queryCacheManagerBean(conn);
          if (bean != null) {
             bean.refreshAttributes();
-            if (trace) log.tracef(""Cache manager %s could be found and attributes where refreshed, so it's up."", bean);
+            if (trace) log.trace(""Cache manager ""+bean+"" could be found and attributes where refreshed, so it's up."");
             return AvailabilityType.UP;
          }
          if (trace) log.trace(""Cache manager could not be found, so cache manager is down"");
@@ -84,11 +84,11 @@ public AvailabilityType getAvailability() {
    /**
     * Start the resource connection
     */
-   @SuppressWarnings(""unchecked"")
-   public void start(ResourceContext context) {
+   @Override
+   public void start(ResourceContext<MBeanResourceComponent<?>> context) {
       // TODO: Call super.start() ?
       this.context = context;
-      this.cacheManagerPattern = ""*:"" + CACHE_MANAGER_JMX_GROUP + "",name="" + ObjectName.quote(context.getResourceKey()) + "",*"";
+      this.cacheManagerPattern = ""*:"" + CacheManagerDiscovery.CACHE_MANAGER_JMX_GROUP + "",name="" + ObjectName.quote(context.getResourceKey()) + "",*"";
    }
 
    @Override
@@ -102,23 +102,26 @@ public EmsConnection getEmsConnection() {
     * @see org.rhq.core.pluginapi.measurement.MeasurementFacet#getValues(org.rhq.core.domain.measurement.MeasurementReport,
     *      java.util.Set)
     */
+   @Override
    public void getValues(MeasurementReport report, Set<MeasurementScheduleRequest> metrics) {
       boolean trace = log.isTraceEnabled();
-      if (trace) log.tracef(""Get values for these metrics: %s"", metrics);
+      if (trace) log.trace(""Get values for these metrics: "" + metrics);
       EmsConnection conn = getEmsConnection();
-      if (trace) log.tracef(""Connection to ems server established: %s"", conn);
+      if (trace) log.trace(""Connection to ems server established: "" + conn);
       EmsBean bean = queryCacheManagerBean(conn);
       bean.refreshAttributes();
-      if (trace) log.tracef(""Querying returned bean: %s"", bean);
+      if (trace) log.trace(""Querying returned bean: "" + bean);
       for (MeasurementScheduleRequest req : metrics) {
          DataType type = req.getDataType();
          if (type == DataType.MEASUREMENT) {
             EmsAttribute att = bean.getAttribute(req.getName());
-            MeasurementDataNumeric res = constructNumericMeasure(att.getTypeClass(), att.getValue(), req);
-            report.addData(res);
+            if (att != null) {
+               MeasurementDataNumeric res = constructNumericMeasure(att.getTypeClass(), att.getValue(), req);
+               report.addData(res);
+            }
          } else if (type == DataType.TRAIT) {
             String value = (String) bean.getAttribute(req.getName()).getValue();
-            if (trace) log.tracef(""Metric (%s) is trait with value %s"", req.getName(), value);
+            if (trace) log.trace(""Metric (""+req.getName()+"") is trait with value ""+ value);
             MeasurementDataTrait res = new MeasurementDataTrait(req, value);
             report.addData(res);
          }
@@ -127,12 +130,14 @@ public void getValues(MeasurementReport report, Set<MeasurementScheduleRequest>
 
    private EmsBean queryCacheManagerBean(EmsConnection conn) {
       String pattern = cacheManagerPattern;
-      if (log.isTraceEnabled()) log.tracef(""Pattern to query is %s"", pattern);
+      if (log.isTraceEnabled()) log.trace(""Pattern to query is "" + pattern);
       ObjectNameQueryUtility queryUtility = new ObjectNameQueryUtility(pattern);
       List<EmsBean> beans = conn.queryBeans(queryUtility.getTranslatedQuery());
       if (beans.size() > 1) {
          // If more than one are returned, most likely is due to duplicate domains which is not the general case
-         log.moreThanOneBeanReturned(pattern, beans);
+         if(log.isWarnEnabled()) {
+            log.warn(String.format(""More than one bean returned from applying %s pattern: %s"", pattern, beans));
+         }
       }
       return beans.get(0);
    }",2012-02-27T09:15:52Z,515
"@@ -22,82 +22,80 @@
  */
 package org.infinispan.rhq;
 
-import static org.infinispan.jmx.CacheManagerJmxRegistration.*;
-import org.infinispan.rhq.logging.Log;
-import org.infinispan.util.logging.LogFactory;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.mc4j.ems.connection.EmsConnection;
 import org.mc4j.ems.connection.bean.EmsBean;
 import org.rhq.core.domain.configuration.Configuration;
 import org.rhq.core.pluginapi.inventory.DiscoveredResourceDetails;
+import org.rhq.core.pluginapi.inventory.InvalidPluginConfigurationException;
+import org.rhq.core.pluginapi.inventory.ManualAddFacet;
 import org.rhq.core.pluginapi.inventory.ResourceDiscoveryContext;
 import org.rhq.plugins.jmx.JMXComponent;
 import org.rhq.plugins.jmx.MBeanResourceDiscoveryComponent;
 import org.rhq.plugins.jmx.ObjectNameQueryUtility;
 
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
 /**
  * Discovery class for Infinispan engines
  *
  * @author Heiko W. Rupp
  * @author Galder Zamarreño
  */
-public class CacheManagerDiscovery extends MBeanResourceDiscoveryComponent<JMXComponent> {
-   private static final Log log = LogFactory.getLog(CacheManagerDiscovery.class, Log.class);
+public class CacheManagerDiscovery extends MBeanResourceDiscoveryComponent<JMXComponent<?>> implements ManualAddFacet<JMXComponent<?>>{
+   private static final Log log = LogFactory.getLog(CacheManagerDiscovery.class);
+   public static final String CACHE_MANAGER_JMX_GROUP = ""type=CacheManager"";
 
    protected static final String CACHE_MANAGER_OBJECTS = ""*:"" + CACHE_MANAGER_JMX_GROUP + "",*"";
-   
+
    /**
     * Run the discovery
     */
-   public Set<DiscoveredResourceDetails> discoverResources(ResourceDiscoveryContext<JMXComponent> ctx) {
+   @Override
+   public Set<DiscoveredResourceDetails> discoverResources(ResourceDiscoveryContext<JMXComponent<?>> ctx) {
       boolean trace = log.isTraceEnabled();
-      if (trace) log.tracef(""Discover resources with context: %s"", ctx);
-      Set<DiscoveredResourceDetails> discoveredResources;
-      List<Configuration> manualCfgs = ctx.getPluginConfigurations();
-      if (!manualCfgs.isEmpty()) {
-         // TODO: Remove this?
-         discoveredResources = createDiscoveredResource(ctx, CACHE_MANAGER_OBJECTS);
-         if (trace) log.tracef(""Manually discovered resources are %s"", discoveredResources);
-      } else {
-         // Process auto discovered resource
-         discoveredResources = createDiscoveredResource(ctx, CACHE_MANAGER_OBJECTS);
-         if (trace) log.tracef(""Automatically discovered resources are %s"", discoveredResources);
-      }
+      if (trace) log.trace(""Discover resources with context "" + ctx);
+      // Process auto discovered resource
+      Set<DiscoveredResourceDetails> discoveredResources = createDiscoveredResource(ctx, null, CACHE_MANAGER_OBJECTS);
+      if (trace) log.trace(""Automatically discovered resources are "" + discoveredResources);
+
       return discoveredResources;
    }
 
-   private Set<DiscoveredResourceDetails> createDiscoveredResource(ResourceDiscoveryContext<JMXComponent> ctx, String objectName) {
+   private Set<DiscoveredResourceDetails> createDiscoveredResource(ResourceDiscoveryContext<JMXComponent<?>> ctx, Configuration pluginConfiguration, String objectName) {
       boolean trace = log.isTraceEnabled();
-      JMXComponent parentComponent = ctx.getParentResourceComponent();
+      JMXComponent<?> parentComponent = ctx.getParentResourceComponent();
       EmsConnection conn = parentComponent.getEmsConnection();
       if (conn != null) {
-         if (trace) log.tracef(""Connection to ems server established: %s"", conn);
+         if (trace) log.trace(""Connection to ems server established: "" + conn);
 
          // Run query for manager_object
          ObjectNameQueryUtility queryUtility = new ObjectNameQueryUtility(objectName);
          List<EmsBean> beans = conn.queryBeans(queryUtility.getTranslatedQuery());
-         if (trace) log.tracef(""Querying [%s] returned beans: %s"", queryUtility.getTranslatedQuery(), beans);
+         if (trace) log.trace(""Querying [""+queryUtility.getTranslatedQuery()+""] returned beans: "" + beans);
 
          Set<DiscoveredResourceDetails> discoveredResources = new HashSet<DiscoveredResourceDetails>();
          for (EmsBean bean : beans) {
             String managerName = bean.getBeanName().getCanonicalName();
             String resourceName = bean.getAttribute(""Name"").getValue().toString();
             String version = bean.getAttribute(""Version"").getValue().toString();
             /* A discovered resource must have a unique key, that must stay the same when the resource is discovered the next time */
-            if (trace) log.tracef(""Add resource with version '%s' and type %s"", version, ctx.getResourceType());
+            if (trace) log.trace(""Add resource with version '""+version+""' and type "" + ctx.getResourceType());
             DiscoveredResourceDetails detail = new DiscoveredResourceDetails(
                   ctx.getResourceType(), // Resource type
                   resourceName, // Resource key
                   resourceName, // Resource name
                   version, // Resource version
                   ""A cache manager within Infinispan"", // Description
-                  null, // Plugin config
+                  pluginConfiguration, // Plugin config
                   null // Process info from a process scan
             );
-            log.discoveredInfinispanInstance(resourceName, managerName);
+            if(log.isInfoEnabled()) {
+               log.info(String.format(""Discovered Infinispan instance with key %s and name %s"", resourceName, managerName));
+            }
             discoveredResources.add(detail);
          }
          return discoveredResources;
@@ -106,4 +104,16 @@ private Set<DiscoveredResourceDetails> createDiscoveredResource(ResourceDiscover
          return null;
       }
    }
+
+   @Override
+   public DiscoveredResourceDetails discoverResource(Configuration pluginConfiguration,
+         ResourceDiscoveryContext<JMXComponent<?>> ctx) throws InvalidPluginConfigurationException {
+      Set<DiscoveredResourceDetails> discoveredResources = createDiscoveredResource(ctx, pluginConfiguration, CACHE_MANAGER_OBJECTS);
+      if (log.isTraceEnabled()) log.trace(""Manually discovered resource: "" + discoveredResources);
+      if(discoveredResources.size()>0) {
+         return discoveredResources.iterator().next();
+      } else {
+         throw new InvalidPluginConfigurationException(""Expecting single resource, found ""+discoveredResources.size());
+      }
+   }
 }",2012-02-27T09:15:52Z,516
"@@ -1,8 +1,7 @@
 package org.infinispan.rhq;
 
-import org.infinispan.rhq.logging.Log;
-import org.infinispan.util.Util;
-import org.infinispan.util.logging.LogFactory;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
 import org.rhq.core.domain.measurement.MeasurementDataNumeric;
 import org.rhq.core.domain.measurement.MeasurementScheduleRequest;
 
@@ -14,13 +13,25 @@
  */
 public class RhqUtil {
 
-   private static final Log log = LogFactory.getLog(RhqUtil.class, Log.class);
+   private static final Log log = LogFactory.getLog(RhqUtil.class);
 
    public static MeasurementDataNumeric constructNumericMeasure(
-         Class attrType, Object o, MeasurementScheduleRequest req) {
+         Class<?> attrType, Object o, MeasurementScheduleRequest req) {
       if (log.isTraceEnabled())
-         log.tracef(""Metric (%s) is measurement with value %s"", req.getName(), o);
-      return new MeasurementDataNumeric(req, Util.constructDouble(attrType, o));
+         log.trace(""Metric (""+req.getName() +"") is measurement with value "" + o);
+      return new MeasurementDataNumeric(req, constructDouble(attrType, o));
    }
 
+   public static Double constructDouble(Class<?> type, Object o) {
+      if (type.equals(Long.class) || type.equals(long.class))
+         return Double.valueOf((Long) o);
+      else if (type.equals(Double.class) || type.equals(double.class))
+         return (Double) o;
+      else if (type.equals(Integer.class) || type.equals(int.class))
+         return Double.valueOf((Integer) o);
+      else if (type.equals(String.class))
+         return Double.valueOf((String) o);
+
+      throw new IllegalStateException(String.format(""Expected a value that can be converted into a double: type=%s, value=%s"", type, o));
+   }
 }",2012-02-27T09:15:52Z,548
"@@ -1,66 +0,0 @@
-/*
- * JBoss, Home of Professional Open Source.
- * Copyright 2000 - 2011, Red Hat Middleware LLC, and individual contributors
- * as indicated by the @author tags. See the copyright.txt file in the
- * distribution for a full listing of individual contributors.
- *
- * This is free software; you can redistribute it and/or modify it
- * under the terms of the GNU Lesser General Public License as
- * published by the Free Software Foundation; either version 2.1 of
- * the License, or (at your option) any later version.
- *
- * This software is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this software; if not, write to the Free
- * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
- * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
- */
-
-package org.infinispan.rhq.logging;
-
-import org.jboss.logging.Cause;
-import org.jboss.logging.LogMessage;
-import org.jboss.logging.Message;
-import org.jboss.logging.MessageLogger;
-import org.mc4j.ems.connection.bean.EmsBean;
-
-import java.util.List;
-
-import static org.jboss.logging.Logger.Level.*;
-
-/**
- * Log abstraction for the RHQ plugin. For this module, message ids
- * ranging from 16001 to 17000 inclusively have been reserved.
- *
- * @author Galder Zamarreño
- * @since 5.0
- */
-@MessageLogger(projectCode = ""ISPN"")
-public interface Log extends org.infinispan.util.logging.Log {
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Attribute %s not found"", id = 16001)
-   void attributeNotFound(String attributeName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""getValues failed for %s"", id = 16002)
-   void getValuesFailed(String metric, @Cause Exception e);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Unknown %s attribute type for %s"", id = 16003)
-   void unknownAttributeType(Class attrType, Object o);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""More than one bean returned from applying %s pattern: %s"", id = 16004)
-   void moreThanOneBeanReturned(String pattern, List<EmsBean> beans);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Discovered Infinispan instance with key %s and name %s"", id = 16005)
-   void discoveredInfinispanInstance(String resourceName, String managerName);
-
-
-}",2012-02-27T09:15:52Z,549
"@@ -60,13 +60,11 @@
       <dependency>
          <groupId>org.rhq.helpers</groupId>
          <artifactId>rhq-pluginGen</artifactId>
-         <version>${version.rhq.plugingen}</version>
       </dependency>
 
       <dependency>
          <groupId>javassist</groupId>
          <artifactId>javassist</artifactId>
-         <version>${version.javassist}</version>
       </dependency>
 
       <dependency>
@@ -78,7 +76,6 @@
       <dependency>
          <groupId>commons-logging</groupId>
          <artifactId>commons-logging</artifactId>
-         <version>${version.commons.logging}</version>
          <scope>test</scope>
       </dependency>
    </dependencies>
@@ -108,7 +105,6 @@
          <plugin>
             <groupId>org.apache.felix</groupId>
             <artifactId>maven-bundle-plugin</artifactId>
-            <version>${version.maven.bundle}</version>
             <configuration>
                <instructions>
                   <Export-Package>",2012-02-27T09:15:52Z,260
"@@ -62,15 +62,15 @@
 
 /**
  * RhqPluginDoclet.
- * 
+ *
  * @author Galder Zamarreño
  * @since 4.0
  */
 public class RhqPluginXmlGenerator {
    private static final Log log = LogFactory.getLog(RhqPluginXmlGenerator.class);
    private static ClassPool classPool;
    private static String cp;
-   
+
    public static void main(String[] args) throws Exception {
       cp = System.getProperty(""java.class.path"");
       start(null);
@@ -84,7 +84,7 @@ public static boolean validOptions(String options[][], DocErrorReporter reporter
 
       return true;
    }
-   
+
    public static boolean start(RootDoc rootDoc) throws Exception {
       List<Class<?>> mbeanIspnClasses = getMBeanClasses();
       List<Class<?>> globalClasses = new ArrayList<Class<?>>();
@@ -99,12 +99,12 @@ public static boolean start(RootDoc rootDoc) throws Exception {
             namedCacheClasses.add(clazz);
          }
       }
-      
+
       // Init the Javassist class pool.
       classPool = ClassPool.getDefault();
       classPool.insertClassPath(new ClassClassPath(RhqPluginXmlGenerator.class));
       PluginGen pg = new PluginGen();
-      
+
       Props root = new Props();
       root.setPluginName(""Infinispan"");
       root.setPluginDescription(""Supports management and monitoring of Infinispan"");
@@ -119,6 +119,8 @@ public static boolean start(RootDoc rootDoc) throws Exception {
       servers.add(new TypeKey(""JMX Server"", ""JMX""));
       servers.add(new TypeKey(""JBossAS Server"", ""JBossAS""));
       servers.add(new TypeKey(""JBossAS Server"", ""JBossAS5""));
+      servers.add(new TypeKey(""JBossAS7 Standalone Server"", ""jboss-as-7""));
+      servers.add(new TypeKey(""Profile"", ""jboss-as-7""));
       root.setRunsInsides(servers);
       populateMetricsAndOperations(globalClasses, root, false);
 
@@ -131,7 +133,7 @@ public static boolean start(RootDoc rootDoc) throws Exception {
       cache.setSingleton(false);
       cache.setCategory(ResourceCategory.SERVICE);
       populateMetricsAndOperations(namedCacheClasses, cache, true);
-      
+
       root.getChildren().add(cache);
 
       String metaInfDir = ""../../../src/main/resources/META-INF"";
@@ -141,7 +143,7 @@ public static boolean start(RootDoc rootDoc) throws Exception {
 
       pg.createFile(root, ""descriptor"", ""rhq-plugin.xml"", metaInfDir);
       copyFile(new File(metaInfDir + ""/rhq-plugin.xml""), new File(targetMetaInfDir + ""/rhq-plugin.xml""));
-      
+
       return true;
    }
 
@@ -157,7 +159,7 @@ private static void copyFile(File in, File out) throws IOException {
          if (outCh != null) outCh.close();
       }
    }
-   
+
    private static List<Class<?>> getMBeanClasses() throws IOException {
       try {
          return ClassFinder.withAnnotationDeclared(ClassFinder.infinispanClasses(cp), MBean.class);
@@ -167,7 +169,7 @@ private static List<Class<?>> getMBeanClasses() throws IOException {
          throw ioe;
       }
    }
-   
+
    private static void populateMetricsAndOperations(List<Class<?>> classes,
             Props props, boolean withNamePrefix) throws Exception {
       props.setHasOperations(true);
@@ -212,7 +214,7 @@ private static void populateMetricsAndOperations(List<Class<?>> classes,
                }
                props.getMetrics().add(metric);
             }
-            
+
             Operation rhqOperation = (Operation) ctMethod.getAnnotation(Operation.class);
             if (rhqOperation != null) {
                debug(""Operation annotation found "" + rhqOperation);
@@ -235,7 +237,7 @@ private static void populateMetricsAndOperations(List<Class<?>> classes,
                   debug(""Operation has no managed annotations, so take the description from the display name."");
                   operation.setDescription(rhqOperation.displayName());
                }
-               
+
                Object[][] paramAnnotations = ctMethod.getParameterAnnotations();
                int i = 0;
                for (Object[] paramAnnotationsInEach : paramAnnotations) {
@@ -296,7 +298,7 @@ private static void populateMetricsAndOperations(List<Class<?>> classes,
                props.getMetrics().add(metric);
             }
          }
-        
+
       }
    }
 ",2012-02-27T09:15:52Z,517
"@@ -22,14 +22,6 @@
  */
 package org.infinispan.jmx;
 
-import static org.infinispan.test.TestingUtil.getCacheObjectName;
-import static org.mockito.Matchers.any;
-import static org.mockito.Matchers.anyBoolean;
-import static org.mockito.Matchers.anyLong;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-import static org.testng.Assert.assertEquals;
-
 import java.io.Externalizable;
 import java.io.IOException;
 import java.io.ObjectInput;
@@ -38,15 +30,15 @@
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
-
 import javax.management.Attribute;
 import javax.management.MBeanServer;
 import javax.management.ObjectName;
 
 import org.infinispan.Cache;
 import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.config.Configuration;
-import org.infinispan.config.GlobalConfiguration;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.remoting.rpc.ResponseFilter;
 import org.infinispan.remoting.rpc.ResponseMode;
@@ -57,8 +49,18 @@
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.test.fwk.TransportFlags;
 import org.testng.annotations.Test;
 
+import static org.infinispan.test.TestingUtil.getCacheObjectName;
+import static org.mockito.Matchers.any;
+import static org.mockito.Matchers.anyBoolean;
+import static org.mockito.Matchers.anyLong;
+import static org.mockito.Mockito.mock;
+import static org.mockito.Mockito.when;
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNotEquals;
+
 /**
  * @author Mircea.Markus@jboss.com
  * @author Galder Zamarreño
@@ -71,27 +73,33 @@ public class RpcManagerMBeanTest extends MultipleCacheManagersTest {
 
    @Override
    protected void createCacheManagers() throws Throwable {
-      GlobalConfiguration globalConfiguration = GlobalConfiguration.getClusteredDefault();
-      globalConfiguration.setExposeGlobalJmxStatistics(true);
-      globalConfiguration.setAllowDuplicateDomains(true);
-      globalConfiguration.setJmxDomain(JMX_DOMAIN);
-      globalConfiguration.setMBeanServerLookup(PerThreadMBeanServerLookup.class.getName());
-      CacheContainer cacheManager1 = TestCacheManagerFactory.createCacheManagerEnforceJmxDomain(globalConfiguration);
+      ConfigurationBuilder defaultConfig = new ConfigurationBuilder();
+      GlobalConfigurationBuilder gcb1 = GlobalConfigurationBuilder.defaultClusteredBuilder();
+      gcb1.globalJmxStatistics()
+            .enable()
+            .allowDuplicateDomains(true)
+            .jmxDomain(JMX_DOMAIN)
+            .mBeanServerLookup(new PerThreadMBeanServerLookup());
+      CacheContainer cacheManager1 = TestCacheManagerFactory.createClusteredCacheManager(gcb1, defaultConfig,
+            new TransportFlags(), true);
       cacheManager1.start();
 
-      GlobalConfiguration globalConfiguration2 = GlobalConfiguration.getClusteredDefault();
-      globalConfiguration2.setExposeGlobalJmxStatistics(true);
-      globalConfiguration2.setMBeanServerLookup(PerThreadMBeanServerLookup.class.getName());
-      globalConfiguration2.setJmxDomain(JMX_DOMAIN);
-      globalConfiguration2.setAllowDuplicateDomains(true);
-      CacheContainer cacheManager2 = TestCacheManagerFactory.createCacheManagerEnforceJmxDomain(globalConfiguration2);
+      GlobalConfigurationBuilder gcb2 = GlobalConfigurationBuilder.defaultClusteredBuilder();
+      gcb2.globalJmxStatistics()
+            .enable()
+            .allowDuplicateDomains(true)
+            .jmxDomain(JMX_DOMAIN)
+            .mBeanServerLookup(new PerThreadMBeanServerLookup());
+      CacheContainer cacheManager2 = TestCacheManagerFactory.createClusteredCacheManager(gcb2, defaultConfig,
+            new TransportFlags(), true);
       cacheManager2.start();
 
       registerCacheManager(cacheManager1, cacheManager2);
 
-      Configuration config = getDefaultClusteredConfig(Configuration.CacheMode.REPL_SYNC);
-      config.setExposeJmxStatistics(true);
-      defineConfigurationOnAllManagers(cachename, config);
+      ConfigurationBuilder cb = new ConfigurationBuilder();
+      cb.clustering().cacheMode(CacheMode.REPL_SYNC).jmxStatistics().enable();
+      defineConfigurationOnAllManagers(cachename, cb);
+      waitForClusterToForm(cachename);
    }
 
    public void testEnableJmxStats() throws Exception {
@@ -105,31 +113,30 @@ public void testEnableJmxStats() throws Exception {
 
       Object statsEnabled = mBeanServer.getAttribute(rpcManager1, ""StatisticsEnabled"");
       assert statsEnabled != null;
-      assert statsEnabled.equals(Boolean.TRUE);
+      assertEquals(statsEnabled, Boolean.TRUE);
 
-      assert mBeanServer.getAttribute(rpcManager1, ""StatisticsEnabled"").equals(Boolean.TRUE);
-      assert mBeanServer.getAttribute(rpcManager2, ""StatisticsEnabled"").equals(Boolean.TRUE);
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""StatisticsEnabled""), Boolean.TRUE);
+      assertEquals(mBeanServer.getAttribute(rpcManager2, ""StatisticsEnabled""), Boolean.TRUE);
 
       // The initial state transfer uses cache commands, so it also increases the ReplicationCount value
       long initialReplicationCount1 = (Long) mBeanServer.getAttribute(rpcManager1, ""ReplicationCount"");
 
       cache1.put(""key"", ""value2"");
-      assert cache2.get(""key"").equals(""value2"");
-      assert mBeanServer.getAttribute(rpcManager1, ""ReplicationCount"").equals(initialReplicationCount1 + 1)
-            : ""Expected "" + (initialReplicationCount1 + 1) + "", was "" + mBeanServer.getAttribute(rpcManager1, ""ReplicationCount"");
-      assert mBeanServer.getAttribute(rpcManager1, ""ReplicationFailures"").equals((long) 0);
+      assertEquals(cache2.get(""key""), ""value2"");
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""ReplicationCount""), initialReplicationCount1 + 1);
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""ReplicationFailures""), (long) 0);
 
       // now reset statistics
       mBeanServer.invoke(rpcManager1, ""resetStatistics"", new Object[0], new String[0]);
-      assert mBeanServer.getAttribute(rpcManager1, ""ReplicationCount"").equals((long) 0);
-      assert mBeanServer.getAttribute(rpcManager1, ""ReplicationFailures"").equals((long) 0);
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""ReplicationCount""), (long) 0);
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""ReplicationFailures""), (long) 0);
 
       mBeanServer.setAttribute(rpcManager1, new Attribute(""StatisticsEnabled"", Boolean.FALSE));
 
       cache1.put(""key"", ""value"");
-      assert cache2.get(""key"").equals(""value"");
-      assert mBeanServer.getAttribute(rpcManager1, ""ReplicationCount"").equals((long) -1);
-      assert mBeanServer.getAttribute(rpcManager1, ""ReplicationCount"").equals((long) -1);
+      assertEquals(cache2.get(""key""), ""value"");
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""ReplicationCount""), (long) -1);
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""ReplicationCount""), (long) -1);
 
       // reset stats enabled parameter
       mBeanServer.setAttribute(rpcManager1, new Attribute(""StatisticsEnabled"", Boolean.TRUE));
@@ -143,18 +150,18 @@ public void testSuccessRatio() throws Exception {
       ObjectName rpcManager1 = getCacheObjectName(JMX_DOMAIN, cachename + ""(repl_sync)"", ""RpcManager"");
 
       // the previous test has reset the statistics
-      assert mBeanServer.getAttribute(rpcManager1, ""ReplicationCount"").equals((long) 0);
-      assert mBeanServer.getAttribute(rpcManager1, ""ReplicationFailures"").equals((long) 0);
-      assert mBeanServer.getAttribute(rpcManager1, ""SuccessRatio"").equals(""N/A"");
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""ReplicationCount""), (long) 0);
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""ReplicationFailures""), (long) 0);
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""SuccessRatio""), ""N/A"");
 
       cache1.put(""a1"", new SlowToSerialize(""b1"", 50));
       cache1.put(""a2"", new SlowToSerialize(""b2"", 50));
       cache1.put(""a3"", new SlowToSerialize(""b3"", 50));
       cache1.put(""a4"", new SlowToSerialize(""b4"", 50));
-      assert mBeanServer.getAttribute(rpcManager1, ""ReplicationCount"").equals((long) 4);
-      assert mBeanServer.getAttribute(rpcManager1, ""SuccessRatio"").equals(""100%"");
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""ReplicationCount""), (long) 4);
+      assertEquals(mBeanServer.getAttribute(rpcManager1, ""SuccessRatio""), ""100%"");
       Object avgReplTime = mBeanServer.getAttribute(rpcManager1, ""AverageReplicationTime"");
-      assert !avgReplTime.equals((long) 0) : ""Expected !0, was "" + avgReplTime;
+      assertNotEquals(avgReplTime, (long) 0);
 
       RpcManagerImpl rpcManager = (RpcManagerImpl) TestingUtil.extractComponent(cache1, RpcManager.class);
       Transport originalTransport = rpcManager.getTransport();",2012-11-19T08:40:38Z,550
"@@ -382,6 +382,7 @@ public void testCacheLoaders() {
       cacheCofig.setCacheLoaderManagerConfig(clmc);
 
       defineConfigurationOnAllManagers(""replSync2"", cacheCofig);
+      waitForClusterToForm(""replSync2"");
       cache1 = cache(0, ""replSync2"");
       cache2 = cache(1, ""replSync2"");
 ",2012-11-19T08:40:38Z,551
"@@ -48,6 +48,8 @@
 import java.util.IdentityHashMap;
 import java.util.List;
 
+import static org.testng.Assert.assertTrue;
+
 /**
  * Base class for tests that operates on clusters of caches. The way tests extending this class operates is:
  * <pre>
@@ -290,7 +292,7 @@ protected void waitForClusterToForm(String cacheName) {
       List<Cache<Object, Object>> caches = getCaches(cacheName);
       Cache<Object, Object> cache = caches.get(0);
       TestingUtil.blockUntilViewsReceived(10000, caches);
-      if (cache.getConfiguration().getCacheMode().isDistributed()) {
+      if (cache.getCacheConfiguration().clustering().cacheMode().isClustered()) {
          TestingUtil.waitForRehashToComplete(caches);
       }
    }",2012-11-19T08:40:38Z,387
"@@ -261,9 +261,16 @@ public static EmbeddedCacheManager createClusteredCacheManager(ConfigurationBuil
    }
 
    public static EmbeddedCacheManager createClusteredCacheManager(GlobalConfigurationBuilder gcb, ConfigurationBuilder defaultCacheConfig, TransportFlags flags) {
+      return createClusteredCacheManager(gcb, defaultCacheConfig, flags, false);
+   }
+
+   public static EmbeddedCacheManager createClusteredCacheManager(GlobalConfigurationBuilder gcb,
+                                                                  ConfigurationBuilder defaultCacheConfig,
+                                                                  TransportFlags flags,
+                                                                  boolean keepJmxDomainName) {
       amendGlobalConfiguration(gcb, flags);
       amendJTA(defaultCacheConfig);
-      return newDefaultCacheManager(true, gcb, defaultCacheConfig, false);
+      return newDefaultCacheManager(true, gcb, defaultCacheConfig, keepJmxDomainName);
    }
 
    public static void amendGlobalConfiguration(GlobalConfigurationBuilder gcb, TransportFlags flags) {",2012-11-19T08:40:38Z,130
"@@ -29,6 +29,8 @@
 import org.infinispan.factories.annotations.DefaultFactoryFor;
 import org.infinispan.interceptors.*;
 import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.loaders.CacheLoaderConfig;
+import org.infinispan.loaders.CacheStoreConfig;
 import org.infinispan.util.Util;
 
 import java.util.List;
@@ -71,6 +73,11 @@ public InterceptorChain buildInterceptorChain() throws IllegalAccessException, I
       // add the interceptor chain to the registry first, since some interceptors may ask for it.
       componentRegistry.registerComponent(interceptorChain, InterceptorChain.class);
 
+      // add marshallable check interceptor for situations where we want to figure out before marshalling
+      if (configuration.isUseLazyDeserialization() || configuration.isUseAsyncMarshalling()
+            || configuration.isUseReplQueue() || hasAsyncStore())
+         interceptorChain.appendIntereceptor(createInterceptor(IsMarshallableInterceptor.class));
+
       // NOW add the ICI if we are using batching!
       if (invocationBatching)
          interceptorChain.appendIntereceptor(createInterceptor(InvocationContextInterceptor.class));
@@ -157,7 +164,6 @@ private CommandInterceptor getOrCreateCustomInterceptor(CustomInterceptorConfig
    }
 
    private void buildCustomInterceptors(InterceptorChain interceptorChain, List<CustomInterceptorConfig> customInterceptors) {
-
       for (CustomInterceptorConfig config : customInterceptors) {
          if (interceptorChain.containsInterceptorType(getCustomInterceptorType(config))) continue;
          if (config.isFirst())
@@ -186,6 +192,18 @@ else if (config.getBefore() != null) {
       
    }
 
+   private boolean hasAsyncStore() {
+      List<CacheLoaderConfig> loaderConfigs = configuration.getCacheLoaderManagerConfig().getCacheLoaderConfigs();
+      for (CacheLoaderConfig loaderConfig : loaderConfigs) {
+         if (loaderConfig instanceof CacheStoreConfig) {
+            CacheStoreConfig storeConfig = (CacheStoreConfig) loaderConfig;
+            if (storeConfig.getAsyncStoreConfig().isEnabled())
+               return true;
+         }
+      }
+      return false;
+   }
+
    @Override
    public <T> T construct(Class<T> componentType) {
       try {",2011-03-05T09:51:08Z,328
"@@ -0,0 +1,153 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2000 - 2011, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.interceptors;
+
+import org.infinispan.commands.control.LockControlCommand;
+import org.infinispan.commands.read.GetKeyValueCommand;
+import org.infinispan.commands.write.PutKeyValueCommand;
+import org.infinispan.commands.write.PutMapCommand;
+import org.infinispan.commands.write.RemoveCommand;
+import org.infinispan.commands.write.ReplaceCommand;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.context.impl.TxInvocationContext;
+import org.infinispan.distribution.DistributionManager;
+import org.infinispan.factories.annotations.Inject;
+import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.marshall.NotSerializableException;
+import org.infinispan.marshall.StreamingMarshaller;
+
+import java.util.Map;
+
+/**
+ * Interceptor to verify whether parameters passed into cache are marshallables
+ * or not. This is handy in situations where we want to find out before
+ * marshalling whether the type of object is marshallable. Such situations
+ * include lazy deserialization, or when marshalling happens in a separate
+ * thread and marshalling failures might be swallowed. </p>
+ *
+ * This interceptor offers the possibility to discover these issues way before
+ * the code has moved onto a different thread where it's harder to communicate
+ * with the original request thread.
+ *
+ * @author Galder Zamarreño
+ * @since 4.2
+ */
+public class IsMarshallableInterceptor extends CommandInterceptor {
+
+   private StreamingMarshaller marshaller;
+   private DistributionManager distManager;
+
+   @Inject
+   protected void injectMarshaller(StreamingMarshaller marshaller, DistributionManager distManager) {
+      this.marshaller = marshaller;
+      this.distManager = distManager;
+   }
+
+   @Override
+   public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand command) throws Throwable {
+      Object key = command.getKey();
+      if (isLazyDeserialization() || getMightGoRemote(ctx, key))
+         checkMarshallable(key);
+      return super.visitGetKeyValueCommand(ctx, command);
+   }
+
+   @Override
+   public Object visitLockControlCommand(TxInvocationContext ctx, LockControlCommand command) throws Throwable {
+      if (isLazyDeserialization() || isClusterInvocation(ctx))
+         checkMarshallable(command.getKeys());
+      return super.visitLockControlCommand(ctx, command);
+   }
+
+   @Override
+   public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
+      if (isLazyDeserialization() || isClusterInvocation(ctx) || isStoreInvocation(ctx))
+         checkMarshallable(command.getKey(), command.getValue());
+      return super.visitPutKeyValueCommand(ctx, command);
+   }
+
+   @Override
+   public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
+      if (isLazyDeserialization() || isClusterInvocation(ctx) || isStoreInvocation(ctx))
+         checkMarshallable(command.getMap());
+      return super.visitPutMapCommand(ctx, command);
+   }
+
+   @Override
+   public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
+      if (isLazyDeserialization() || isClusterInvocation(ctx) || isStoreInvocation(ctx))
+         checkMarshallable(command.getKey());
+      return super.visitRemoveCommand(ctx, command);
+   }
+
+   @Override
+   public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
+      if (isLazyDeserialization() || isClusterInvocation(ctx) || isStoreInvocation(ctx))
+         checkMarshallable(command.getKey(), command.getNewValue());
+      return super.visitReplaceCommand(ctx, command);
+   }
+
+   private boolean isClusterInvocation(InvocationContext ctx) {
+      // If the cache is local, the interceptor should only be enabled in case
+      // of lazy deserialization or when an async store is in place. So, if
+      // any cache store is configured, check whether it'll be skipped
+      return ctx.isOriginLocal()
+            && configuration.getCacheMode().isClustered()
+            && !ctx.hasFlag(Flag.CACHE_MODE_LOCAL);
+   }
+
+   private boolean isStoreInvocation(InvocationContext ctx) {
+      // If the cache is local, the interceptor should only be enabled in case
+      // of lazy deserialization or when an async store is in place. So, if
+      // any cache store is configured, check whether it'll be skipped
+      return !configuration.getCacheMode().isClustered()
+            && configuration.getCacheLoaderManagerConfig().getFirstCacheLoaderConfig() != null
+            && !ctx.hasFlag(Flag.SKIP_CACHE_STORE);
+   }
+
+   private boolean isLazyDeserialization() {
+      return configuration.isUseLazyDeserialization();
+   }
+
+   private boolean getMightGoRemote(InvocationContext ctx, Object key) {
+      return ctx.isOriginLocal()
+            && configuration.getCacheMode().isDistributed()
+            && !ctx.hasFlag(Flag.SKIP_REMOTE_LOOKUP)
+            && !distManager.getLocality(key).isLocal();
+   }
+
+   private void checkMarshallable(Object... objs) throws NotSerializableException {
+      for (Object o : objs) {
+         if (!marshaller.isMarshallable(o))
+            throw new NotSerializableException(String.format(
+               ""Object of type %s expected to be marshallable"", o.getClass()
+            ));
+      }
+   }
+
+   private void checkMarshallable(Map<Object, Object> objs) throws NotSerializableException {
+      for (Map.Entry entry : objs.entrySet())
+         checkMarshallable(entry.getKey(), entry.getValue());
+   }
+
+}",2011-03-05T09:51:08Z,443
"@@ -60,11 +60,7 @@ public class MarshalledValue {
    public MarshalledValue(Object instance, boolean equalityPreferenceForInstance, StreamingMarshaller marshaller) throws NotSerializableException {
       if (instance == null) throw new NullPointerException(""Null values cannot be wrapped as MarshalledValues!"");
 
-      if (marshaller.isMarshallable(instance))
-         this.instance = instance;
-      else
-         throw new NotSerializableException(""Marshalled values can only wrap Objects that can be serialized or marshalled!  Instance of "" 
-               + instance.getClass() + "" won't serialize or marshall."");
+      this.instance = instance;
       this.equalityPreferenceForInstance = equalityPreferenceForInstance;
       this.marshaller = marshaller;
    }",2011-03-05T09:51:08Z,78
"@@ -38,6 +38,10 @@ public NotSerializableException(String message, Throwable cause) {
       super(message, cause);
    }
 
+   public NotSerializableException(String message) {
+      super(message);
+   }
+
    @Override
    public void setStackTrace(StackTraceElement[] stackTrace) {
       // nothing",2011-03-05T09:51:08Z,552
"@@ -19,6 +19,7 @@
  * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
  * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
  */
+
 package org.infinispan.marshall.jboss;
 
 import org.infinispan.CacheException;
@@ -234,7 +235,7 @@ public Object readObject(Unmarshaller input) throws IOException, ClassNotFoundEx
       return adapter.readObject(input);
    }
 
-   boolean isMarshallable(Object o) {
+   boolean isMarshallableCandidate(Object o) {
       return writers.containsKey(o.getClass());
    }
 ",2011-03-05T09:51:08Z,174
"@@ -4,6 +4,7 @@
 import org.infinispan.io.ByteBuffer;
 import org.infinispan.io.ExposedByteArrayOutputStream;
 import org.infinispan.marshall.AbstractMarshaller;
+import org.infinispan.util.ConcurrentWeakKeyHashMap;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.jboss.marshalling.ContextClassResolver;
@@ -24,6 +25,8 @@
 import java.io.Serializable;
 import java.lang.reflect.Method;
 import java.net.URL;
+import java.util.WeakHashMap;
+import java.util.concurrent.ConcurrentMap;
 
 /**
  * A marshaller that makes use of <a href=""http://www.jboss.org/jbossmarshalling"">JBoss Marshalling</a> to serialize
@@ -40,6 +43,13 @@ public class GenericJBossMarshaller extends AbstractMarshaller {
    protected ClassLoader defaultCl = this.getClass().getClassLoader();
    protected MarshallingConfiguration configuration;
    protected MarshallerFactory factory;
+   /**
+    * Cache of classes that are considered to be marshallable. Since checking
+    * whether a type is marshallable requires attempting to marshalling them,
+    * a cache for the types that are known to be marshallable or not is
+    * advantageous.
+    */
+   private final ConcurrentMap<Class, Boolean> isMarshallableMap = new ConcurrentWeakKeyHashMap<Class, Boolean>();
 
    public GenericJBossMarshaller() {
       factory = Marshalling.getMarshallerFactory(""river"");
@@ -184,7 +194,33 @@ public void finishObjectInput(ObjectInput oi) {
 
    @Override
    public boolean isMarshallable(Object o) {
-      return (o instanceof Serializable);
+      Class clazz = o.getClass();
+      Object isClassMarshallable = isMarshallableMap.get(clazz);
+      if (isClassMarshallable != null) {
+         return (Boolean) isClassMarshallable;
+      } else {
+         if (isMarshallableCandidate(o)) {
+            boolean isMarshallable = true;
+            try {
+               objectToBuffer(o);
+            } catch (Exception e) {
+               isMarshallable = false;
+            } finally {
+               isMarshallableMap.putIfAbsent(clazz, isMarshallable);
+               return isMarshallable;
+            }
+         }
+         return false;
+      }
+   }
+
+   public void stop() {
+       // Clear class cache
+      isMarshallableMap.clear();
+   }
+
+   protected boolean isMarshallableCandidate(Object o) {
+      return o instanceof Serializable;
    }
 
    protected static class DebuggingExceptionListener implements ExceptionListener {",2011-03-05T09:51:08Z,553
"@@ -51,14 +51,15 @@ public void start(ClassLoader defaultCl, RemoteCommandsFactory cmdFactory, Strea
    }
 
    public void stop() {
+      super.stop();
       // Do not leak classloader when cache is stopped.
       defaultCl = null;
       if (externalizerTable != null) externalizerTable.stop();
    }
 
    @Override
-   public boolean isMarshallable(Object o) {
-      return super.isMarshallable(o) || externalizerTable.isMarshallable(o);
+   public boolean isMarshallableCandidate(Object o) {
+      return super.isMarshallableCandidate(o) || externalizerTable.isMarshallableCandidate(o);
    }
 
    protected ExternalizerTable createExternalizerTable(RemoteCommandsFactory f, StreamingMarshaller m, GlobalConfiguration g) {",2011-03-05T09:51:08Z,19
"@@ -22,15 +22,18 @@
  */
 package org.infinispan.eviction;
 
+import java.io.Externalizable;
+import java.io.IOException;
 import java.io.NotSerializableException;
+import java.io.ObjectInput;
+import java.io.ObjectOutput;
 
 import org.infinispan.commands.write.EvictCommand;
 import org.infinispan.config.Configuration;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.interceptors.MarshalledValueInterceptor;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.MarshalledValue;
-import org.infinispan.marshall.MarshalledValueTest;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.SingleCacheManagerTest;
 import org.infinispan.test.TestingUtil;
@@ -62,9 +65,9 @@ protected EmbeddedCacheManager createCacheManager() throws Exception {
    
    public void testEvictCustomKeyValue() {
       for (int i = 0; i<CACHE_SIZE*2;i++) {
-         MarshalledValueTest.Pojo p1 = new MarshalledValueTest.Pojo();
+         EvictionPojo p1 = new EvictionPojo();
          p1.i = (int)Util.random(2000);
-         MarshalledValueTest.Pojo p2 = new MarshalledValueTest.Pojo();
+         EvictionPojo p2 = new EvictionPojo();
          p2.i = 24;
          cache.put(p1, p2);         
       }   
@@ -85,9 +88,9 @@ public void testEvictCustomKeyValue() {
 
    public void testEvictPrimitiveKeyCustomValue() {
       for (int i = 0; i<CACHE_SIZE*2;i++) {
-         MarshalledValueTest.Pojo p1 = new MarshalledValueTest.Pojo();
+         EvictionPojo p1 = new EvictionPojo();
          p1.i = (int)Util.random(2000);
-         MarshalledValueTest.Pojo p2 = new MarshalledValueTest.Pojo();
+         EvictionPojo p2 = new EvictionPojo();
          p2.i = 24;
          cache.put(p1, p2);         
       }
@@ -127,4 +130,32 @@ public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) thr
       }
    }
 
+   class EvictionPojo implements Externalizable {
+      int i;
+
+      public boolean equals(Object o) {
+         if (this == o) return true;
+         if (o == null || getClass() != o.getClass()) return false;
+         EvictionPojo pojo = (EvictionPojo) o;
+         if (i != pojo.i) return false;
+         return true;
+      }
+
+      public int hashCode() {
+         int result;
+         result = i;
+         return result;
+      }
+
+      @Override
+      public void writeExternal(ObjectOutput out) throws IOException {
+         out.writeInt(i);
+      }
+
+      @Override
+      public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {
+         i = in.readInt();
+      }
+
+   }
 }",2011-03-05T09:51:08Z,554
"@@ -26,13 +26,17 @@
 import org.infinispan.eviction.MarshalledValuesEvictionTest.MockMarshalledValueInterceptor;
 import org.infinispan.interceptors.MarshalledValueInterceptor;
 import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.marshall.MarshalledValueTest;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.SingleCacheManagerTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
 import org.testng.annotations.Test;
 
+import java.io.Externalizable;
+import java.io.IOException;
+import java.io.ObjectInput;
+import java.io.ObjectOutput;
+
 @Test(groups = ""functional"", testName = ""eviction.MarshalledValuesManualEvictionTest"")
 public class MarshalledValuesManualEvictionTest extends SingleCacheManagerTest {
 
@@ -50,13 +54,13 @@ protected EmbeddedCacheManager createCacheManager() throws Exception {
    }
    
    public void testManualEvictCustomKeyValue() {
-      MarshalledValueTest.Pojo p1 = new MarshalledValueTest.Pojo();
+      ManualEvictionPojo p1 = new ManualEvictionPojo();
       p1.i = 64;
-      MarshalledValueTest.Pojo p2 = new MarshalledValueTest.Pojo();
+      ManualEvictionPojo p2 = new ManualEvictionPojo();
       p2.i = 24;
-      MarshalledValueTest.Pojo p3 = new MarshalledValueTest.Pojo();
+      ManualEvictionPojo p3 = new ManualEvictionPojo();
       p3.i = 97;
-      MarshalledValueTest.Pojo p4 = new MarshalledValueTest.Pojo();
+      ManualEvictionPojo p4 = new ManualEvictionPojo();
       p4.i = 35;
 
       cache.put(p1, p2);
@@ -68,9 +72,9 @@ public void testManualEvictCustomKeyValue() {
    }
    
    public void testEvictPrimitiveKeyCustomValue() {
-      MarshalledValueTest.Pojo p1 = new MarshalledValueTest.Pojo();
+      ManualEvictionPojo p1 = new ManualEvictionPojo();
       p1.i = 51;
-      MarshalledValueTest.Pojo p2 = new MarshalledValueTest.Pojo();
+      ManualEvictionPojo p2 = new ManualEvictionPojo();
       p2.i = 78;
 
       cache.put(""key-isoprene"", p1);
@@ -81,4 +85,32 @@ public void testEvictPrimitiveKeyCustomValue() {
       assert !interceptor.marshalledValueCreated;
    }
 
+   class ManualEvictionPojo implements Externalizable {
+      int i;
+
+      public boolean equals(Object o) {
+         if (this == o) return true;
+         if (o == null || getClass() != o.getClass()) return false;
+         ManualEvictionPojo pojo = (ManualEvictionPojo) o;
+         if (i != pojo.i) return false;
+         return true;
+      }
+
+      public int hashCode() {
+         int result;
+         result = i;
+         return result;
+      }
+
+      @Override
+      public void writeExternal(ObjectOutput out) throws IOException {
+         out.writeInt(i);
+      }
+
+      @Override
+      public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {
+         i = in.readInt();
+      }
+   }
+
 }",2011-03-05T09:51:08Z,555
"@@ -0,0 +1,88 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2000 - 2011, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.invalidation;
+
+import org.infinispan.AdvancedCache;
+import org.infinispan.config.Configuration;
+import org.infinispan.marshall.NotSerializableException;
+import org.infinispan.replication.ReplicationExceptionTest;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.testng.annotations.Test;
+
+import static org.testng.AssertJUnit.assertNotNull;
+
+/**
+ * Test to verify how the invalidation works under exceptional circumstances.
+ *
+ * @author Galder Zamarreño
+ * @since 4.2
+ */
+@Test(groups = ""functional"", testName = ""invalidation.InvalidationExceptionTest"")
+public class InvalidationExceptionTest extends MultipleCacheManagersTest {
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      Configuration invalidAsync = getDefaultClusteredConfig(Configuration.CacheMode.INVALIDATION_ASYNC,true);
+      createClusteredCaches(2, ""invalidAsync"", invalidAsync);
+
+      Configuration replQueue = getDefaultClusteredConfig(Configuration.CacheMode.INVALIDATION_ASYNC,true);
+      replQueue.setUseReplQueue(true);
+      defineConfigurationOnAllManagers(""invalidReplQueueCache"", replQueue);
+
+      Configuration asyncMarshall = getDefaultClusteredConfig(Configuration.CacheMode.INVALIDATION_ASYNC,true);
+      asyncMarshall.setUseAsyncMarshalling(true);
+      defineConfigurationOnAllManagers(""invalidAsyncMarshallCache"", asyncMarshall);
+   }
+
+   public void testNonSerializableAsyncInvalid() throws Exception {
+      doNonSerializableInvalidTest(""invalidAsync"");
+   }
+
+   public void testNonSerializableReplQueue() throws Exception {
+      doNonSerializableInvalidTest(""invalidReplQueueCache"");
+   }
+
+   public void testNonSerializableAsyncMarshalling() throws Exception {
+      doNonSerializableInvalidTest(""invalidAsyncMarshallCache"");
+   }
+
+   private void doNonSerializableInvalidTest(String cacheName) {
+      AdvancedCache cache1 = cache(0, cacheName).getAdvancedCache();
+      AdvancedCache cache2 = cache(1, cacheName).getAdvancedCache();
+      try {
+         cache1.put(new ReplicationExceptionTest.ContainerData(), ""test"");
+         // We should not come here.
+         assertNotNull(""NonSerializableData should not be null on cache2"", cache2.get(""test""));
+      } catch (RuntimeException runtime) {
+         Throwable t = runtime.getCause();
+         if (runtime instanceof NotSerializableException
+                  || t instanceof NotSerializableException
+                  || t.getCause() instanceof NotSerializableException) {
+            System.out.println(""received NotSerializableException - as expected"");
+         } else {
+            throw runtime;
+         }
+      }
+   }
+
+}",2011-03-05T09:51:08Z,556
"@@ -6,15 +6,20 @@
 import org.infinispan.interceptors.MarshalledValueInterceptor;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
 import org.testng.annotations.Test;
 
-import static org.infinispan.marshall.MarshalledValueTest.*;
+import java.io.Externalizable;
+import java.io.IOException;
+import java.io.ObjectInput;
+import java.io.ObjectOutput;
 
 /**
- * // TODO: Document this
+ * Tests that invalidation and lazy deserialization works as expected.
  *
- * @author Galder Zamarre�o
- * @since // TODO
+ * @author Galder Zamarreño
+ * @since 4.2
  */
 @Test(groups = ""functional"", testName = ""marshall.InvalidatedMarshalledValueTest"")
 public class InvalidatedMarshalledValueTest extends MultipleCacheManagersTest {
@@ -45,28 +50,44 @@ public void testModificationsOnSameCustomKey() {
       InvalidatedPojo key = new InvalidatedPojo();
       cache2.put(key, ""1"");
       cache1.put(key, ""2"");
-      assertSerializationCounts(3, 0);
+      // Each cache manager attempts to serialize the pojo once to check is
+      // marshallable, so add a couple of more times on previous 3. Note that
+      // this is only done once for the type.
+      assertSerializationCounts(5, 0);
       cache1.put(key, ""3"");
-      assertSerializationCounts(4, 0);
+      // +2 carried on here.
+      assertSerializationCounts(6, 0);
    }
 
-   public static class InvalidatedPojo extends Pojo {
-      static int serializationCount, deserializationCount;
+   public static class InvalidatedPojo implements Externalizable {
+      final Log log = LogFactory.getLog(InvalidatedPojo.class);
+
+      static int invalidSerializationCount, invalidDeserializationCount;
 
-      @Override
       public int updateSerializationCount() {
-         return ++serializationCount;
+         return ++invalidSerializationCount;
       }
 
-      @Override
       public int updateDeserializationCount() {
-         return ++deserializationCount;
+         return ++invalidDeserializationCount;
+      }
+
+      @Override
+      public void writeExternal(ObjectOutput out) throws IOException {
+         int serCount = updateSerializationCount();
+         log.trace(""invalidSerializationCount="" + serCount);
+      }
+
+      @Override
+      public void readExternal(ObjectInput in) throws IOException, ClassNotFoundException {
+         int deserCount = updateDeserializationCount();
+         log.trace(""invalidDeserializationCount="" + deserCount);
       }
    }
 
    private void assertSerializationCounts(int serializationCount, int deserializationCount) {
-      assert InvalidatedPojo.serializationCount == serializationCount : ""Serialization count: expected "" + serializationCount + "" but was "" + InvalidatedPojo.serializationCount;
-      assert InvalidatedPojo.deserializationCount == deserializationCount : ""Deserialization count: expected "" + deserializationCount + "" but was "" + InvalidatedPojo.deserializationCount;
+      assert InvalidatedPojo.invalidSerializationCount == serializationCount : ""Serialization count: expected "" + serializationCount + "" but was "" + InvalidatedPojo.invalidSerializationCount;
+      assert InvalidatedPojo.invalidDeserializationCount == deserializationCount : ""Deserialization count: expected "" + deserializationCount + "" but was "" + InvalidatedPojo.invalidDeserializationCount;
    }
 
 }",2011-03-05T09:51:08Z,557
"@@ -449,7 +449,8 @@ public void testCallbackValues() throws Exception {
          Pojo pojo = new Pojo();
          cache1.put(""key"", pojo);
          assert l.newValue instanceof Pojo : ""recieved "" + l.newValue.getClass().getName();
-         assertSerializationCounts(1, 0);
+         // +1 due to new marshallable checks
+         assertSerializationCounts(2, 0);
       } finally {
          cache1.removeListener(l);
       }
@@ -491,7 +492,7 @@ public void testModificationsOnSameCustomKey() {
       cache2.put(key, ""2"");
 
       // Deserialization only occurs when the cache2.put occurs, not during transport thread execution.
-      assertSerializationCounts(3, 1);
+      assertSerializationCounts(4, 1);
    }
 
    public void testReturnValueDeserialization() { 
@@ -530,7 +531,7 @@ public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand
 
    }
 
-   public static class Pojo implements Externalizable {
+   static class Pojo implements Externalizable {
       public int i;
       boolean b = true;
       static int serializationCount, deserializationCount;",2011-03-05T09:51:08Z,551
"@@ -34,29 +34,55 @@ protected void createCacheManagers() throws Throwable {
       Configuration configuration = getDefaultClusteredConfig(Configuration.CacheMode.REPL_SYNC,true);
       configuration.setIsolationLevel(IsolationLevel.REPEATABLE_READ);
       configuration.setLockAcquisitionTimeout(5000);
+      createClusteredCaches(2, ""syncReplCache"", configuration);
 
-      createClusteredCaches(2, ""replicatinExceptionTest"", configuration);
+      Configuration replAsync = getDefaultClusteredConfig(Configuration.CacheMode.REPL_ASYNC,true);
+      defineConfigurationOnAllManagers(""asyncReplCache"", replAsync);
+
+      Configuration replQueue = getDefaultClusteredConfig(Configuration.CacheMode.REPL_ASYNC,true);
+      replQueue.setUseReplQueue(true);
+      defineConfigurationOnAllManagers(""replQueueCache"", replQueue);
+
+      Configuration asyncMarshall = getDefaultClusteredConfig(Configuration.CacheMode.REPL_ASYNC,true);
+      asyncMarshall.setUseAsyncMarshalling(true);
+      defineConfigurationOnAllManagers(""asyncMarshallCache"", asyncMarshall);
    }
 
    private TransactionManager beginTransaction() throws SystemException, NotSupportedException {
-      AdvancedCache cache1 = cache(0, ""replicatinExceptionTest"").getAdvancedCache();
+      AdvancedCache cache1 = cache(0, ""syncReplCache"").getAdvancedCache();
 
       TransactionManager mgr = TestingUtil.getTransactionManager(cache1);
       mgr.begin();
       return mgr;
    }
 
    public void testNonSerializableRepl() throws Exception {
-      AdvancedCache cache1 = cache(0, ""replicatinExceptionTest"").getAdvancedCache();
-      AdvancedCache cache2 = cache(1, ""replicatinExceptionTest"").getAdvancedCache();
+      doNonSerializableReplTest(""syncReplCache"");
+   }
+
+   public void testNonSerializableAsyncRepl() throws Exception {
+      doNonSerializableReplTest(""asyncReplCache"");
+   }
+
+   public void testNonSerializableReplQueue() throws Exception {
+      doNonSerializableReplTest(""replQueueCache"");
+   }
+
+   public void testNonSerializableAsyncMarshalling() throws Exception {
+      doNonSerializableReplTest(""asyncMarshallCache"");
+   }
+
+   private void doNonSerializableReplTest(String cacheName) {
+      AdvancedCache cache1 = cache(0, cacheName).getAdvancedCache();
+      AdvancedCache cache2 = cache(1, cacheName).getAdvancedCache();
       try {
          cache1.put(""test"", new ContainerData());
-
          // We should not come here.
          assertNotNull(""NonSerializableData should not be null on cache2"", cache2.get(""test""));
       } catch (RuntimeException runtime) {
          Throwable t = runtime.getCause();
-         if (t instanceof NotSerializableException
+         if (runtime instanceof NotSerializableException
+                  || t instanceof NotSerializableException
                   || t.getCause() instanceof NotSerializableException) {
             System.out.println(""received NotSerializableException - as expected"");
          } else {
@@ -66,8 +92,8 @@ public void testNonSerializableRepl() throws Exception {
    }
 
    public void testNonSerializableReplWithTx() throws Exception {
-      AdvancedCache cache1 = cache(0, ""replicatinExceptionTest"").getAdvancedCache();
-      AdvancedCache cache2 = cache(1, ""replicatinExceptionTest"").getAdvancedCache();
+      AdvancedCache cache1 = cache(0, ""syncReplCache"").getAdvancedCache();
+      AdvancedCache cache2 = cache(1, ""syncReplCache"").getAdvancedCache();
       TransactionManager tm;
 
       try {
@@ -87,8 +113,8 @@ public void testNonSerializableReplWithTx() throws Exception {
 
    @Test(groups = ""functional"", expectedExceptions = { TimeoutException.class })
    public void testSyncReplTimeout() {
-      AdvancedCache cache1 = cache(0, ""replicatinExceptionTest"").getAdvancedCache();
-      AdvancedCache cache2 = cache(1, ""replicatinExceptionTest"").getAdvancedCache();
+      AdvancedCache cache1 = cache(0, ""syncReplCache"").getAdvancedCache();
+      AdvancedCache cache2 = cache(1, ""syncReplCache"").getAdvancedCache();
       cache2.addInterceptor(new CommandInterceptor() {
          @Override
          protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd)
@@ -108,8 +134,8 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd)
 
    @Test(groups = ""functional"", expectedExceptions = { TimeoutException.class })
    public void testLockAcquisitionTimeout() throws Exception {
-      AdvancedCache cache1 = cache(0, ""replicatinExceptionTest"").getAdvancedCache();
-      AdvancedCache cache2 = cache(1, ""replicatinExceptionTest"").getAdvancedCache();
+      AdvancedCache cache1 = cache(0, ""syncReplCache"").getAdvancedCache();
+      AdvancedCache cache2 = cache(1, ""syncReplCache"").getAdvancedCache();
       cache2.getConfiguration().setLockAcquisitionTimeout(1);
       TestingUtil.blockUntilViewsReceived(10000, cache1, cache2);
 
@@ -125,7 +151,7 @@ static class NonSerializabeData {
       int i;
    }
 
-   static class ContainerData implements Serializable {
+   public static class ContainerData implements Serializable {
       int i;
       NonSerializabeData non_serializable_data;
       private static final long serialVersionUID = -8322197791060897247L;",2011-03-05T09:51:08Z,558
"@@ -491,6 +491,15 @@ public void purge(File f) throws IOException {
          // cos any cached file channel write won't change the file's exists
          // status. So, clear the file rather than delete it.
          FileChannel channel = streams.get(f.getPath());
+         if (channel == null) {
+            channel = createChannel(f);
+            String path = f.getPath();
+            FileChannel existingChannel = streams.putIfAbsent(path, channel);
+            if (existingChannel != null) {
+               Util.close(channel);
+               channel = existingChannel;
+            }
+         }
          channel.truncate(0);
          // Apart from truncating, it's necessary to reset the position!
          channel.position(0);",2011-06-27T13:03:20Z,178
"@@ -125,6 +125,9 @@ public void testLoadAndStoreImmortal() throws CacheLoaderException {
       assert cs.load(""k"").getMaxIdle() == -1;
       assert !cs.load(""k"").isExpired();
       assert cs.containsKey(""k"");
+
+      boolean removed = cs.remove(""k2"");
+      assert !removed;
    }
 
    public void testLoadAndStoreWithLifespan() throws Exception {",2011-06-27T13:03:20Z,84
"@@ -122,6 +122,22 @@ public void testBucketRemoval() throws Exception {
       checkBucketExists(b);
    }
 
+   public void testCacheStoreRebootable() throws Exception {
+      String key = ""testCacheStoreRebootable"";
+      InternalCacheEntry se = InternalEntryFactory.create(key, ""initialValue"");
+      fcs.store(se);
+      Bucket b = fcs.loadBucketContainingKey(key);
+
+      //stop and restart it:
+      fcs.stop();
+      fcs.start();
+
+      InternalCacheEntry entry = b.getEntry(key);
+      entry.setValue(""updatedValue"");
+      fcs.updateBucket(b);
+      ""updatedValue"".equals(fcs.load(key).getValue());
+   }
+
    protected void checkBucketExists(Bucket b) {
       File file = new File(fcs.root, b.getBucketIdAsString());
       assert file.exists();",2011-06-27T13:03:20Z,546
"@@ -190,7 +190,8 @@ public void setNewValue(Object newValue) {
    @Override
    public String toString() {
       return ""ReplaceCommand{"" +
-            ""oldValue="" + oldValue +
+            ""key="" + key +
+            "", oldValue="" + oldValue +
             "", newValue="" + newValue +
             "", flags="" + flags +
             "", successful="" + successful +",2012-12-17T12:44:28Z,493
"@@ -170,6 +170,13 @@ public enum Flag {
     */
    PUT_FOR_EXTERNAL_READ,
 
+   /**
+    * Flags the invocation as a put operation done internally by the state transfer.
+    * This flag was created purely for internal Infinispan usage, and should not be
+    * used by clients calling into Infinispan.
+    */
+   PUT_FOR_STATE_TRANSFER,
+
    /**
     * If this flag is enabled, if a cache store is shared, then storage to the store is skipped.
     */",2012-12-17T12:44:28Z,442
"@@ -126,6 +126,10 @@ public void clearLookedUpEntries() {
       clearLockedKeys();
    }
 
+   public Object getKey() {
+      return key;
+   }
+
    public CacheEntry getCacheEntry() {
       return cacheEntry;
    }",2012-12-17T12:44:28Z,559
"@@ -47,6 +47,8 @@
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
+import org.infinispan.statetransfer.StateConsumer;
+import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -69,6 +71,7 @@ public class EntryWrappingInterceptor extends CommandInterceptor {
    protected final EntryWrappingVisitor entryWrappingVisitor = new EntryWrappingVisitor();
    private CommandsFactory commandFactory;
    private boolean isUsingLockDelegation;
+   private StateConsumer stateConsumer;       // optional
 
    private static final Log log = LogFactory.getLog(EntryWrappingInterceptor.class);
    private static final boolean trace = log.isTraceEnabled();
@@ -79,11 +82,12 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(EntryFactory entryFactory, DataContainer dataContainer, ClusteringDependentLogic cdl, CommandsFactory commandFactory) {
+   public void init(EntryFactory entryFactory, DataContainer dataContainer, ClusteringDependentLogic cdl, CommandsFactory commandFactory, StateConsumer stateConsumer) {
       this.entryFactory = entryFactory;
       this.dataContainer = dataContainer;
       this.cdl = cdl;
       this.commandFactory = commandFactory;
+      this.stateConsumer = stateConsumer;
    }
 
    @Start
@@ -92,7 +96,6 @@ public void start() {
             cacheConfiguration.locking().supportsConcurrentUpdates() && cacheConfiguration.clustering().cacheMode().isDistributed();
    }
 
-
    @Override
    public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand command) throws Throwable {
       if (!ctx.isOriginLocal() || command.isReplayEntryWrapping()) {
@@ -102,7 +105,7 @@ public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand comman
       }
       Object result = invokeNextInterceptor(ctx, command);
       if (command.isOnePhaseCommit()) {
-         commitContextEntries(ctx, false);
+         commitContextEntries(ctx, false, isFromStateTransfer(ctx));
       }
       return result;
    }
@@ -112,7 +115,7 @@ public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command)
       try {
          return invokeNextInterceptor(ctx, command);
       } finally {
-         commitContextEntries(ctx, false);
+         commitContextEntries(ctx, false, isFromStateTransfer(ctx));
       }
    }
 
@@ -124,7 +127,7 @@ public final Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCo
       } finally {
          //needed because entries might be added in L1
          if (!ctx.isInTxScope())
-            commitContextEntries(ctx, command.hasFlag(Flag.SKIP_OWNERSHIP_CHECK));
+            commitContextEntries(ctx, command.hasFlag(Flag.SKIP_OWNERSHIP_CHECK), false);
       }
    }
 
@@ -218,18 +221,40 @@ public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) thr
       return visitRemoveCommand(ctx, command);
    }
 
-   protected void commitContextEntries(final InvocationContext ctx, boolean skipOwnershipCheck) {
+   protected boolean isFromStateTransfer(InvocationContext ctx) {
+      if (ctx.isInTxScope() && ctx.isOriginLocal()) {
+         LocalTransaction localTx = (LocalTransaction) ((TxInvocationContext) ctx).getCacheTransaction();
+         if (localTx.isFromStateTransfer()) {
+            return true;
+         }
+      }
+      return false;
+   }
+
+   protected boolean isFromStateTransfer(FlagAffectedCommand command) {
+      return command.hasFlag(Flag.PUT_FOR_STATE_TRANSFER);
+   }
+
+   protected final void commitContextEntries(InvocationContext ctx, boolean skipOwnershipCheck, boolean isPutForStateTransfer) {
+      if (!isPutForStateTransfer && stateConsumer != null
+            && ctx instanceof TxInvocationContext
+            && ((TxInvocationContext) ctx).getCacheTransaction().hasModification(ClearCommand.class)) {
+         // If we are committing a ClearCommand now then no keys should be written by state transfer from
+         // now on until current rebalance ends.
+         stateConsumer.stopApplyingState();
+      }
+
       if (ctx instanceof SingleKeyNonTxInvocationContext) {
-         CacheEntry entry = ((SingleKeyNonTxInvocationContext) ctx).getCacheEntry();
-         commitEntryIfNeeded(ctx, skipOwnershipCheck, entry);
+         SingleKeyNonTxInvocationContext singleKeyCtx = (SingleKeyNonTxInvocationContext) ctx;
+         commitEntryIfNeeded(ctx, skipOwnershipCheck, singleKeyCtx.getKey(), singleKeyCtx.getCacheEntry(), isPutForStateTransfer);
       } else {
          Set<Map.Entry<Object, CacheEntry>> entries = ctx.getLookedUpEntries().entrySet();
          Iterator<Map.Entry<Object, CacheEntry>> it = entries.iterator();
          final Log log = getLog();
          while (it.hasNext()) {
             Map.Entry<Object, CacheEntry> e = it.next();
             CacheEntry entry = e.getValue();
-            if (!commitEntryIfNeeded(ctx, skipOwnershipCheck, entry)) {
+            if (!commitEntryIfNeeded(ctx, skipOwnershipCheck, e.getKey(), entry, isPutForStateTransfer)) {
                if (trace) {
                   if (entry == null)
                      log.tracef(""Entry for key %s is null : not calling commitUpdate"", e.getKey());
@@ -248,7 +273,7 @@ protected void commitContextEntry(CacheEntry entry, InvocationContext ctx, boole
    private Object invokeNextAndApplyChanges(InvocationContext ctx, FlagAffectedCommand command) throws Throwable {
       final Object result = invokeNextInterceptor(ctx, command);
       if (!ctx.isInTxScope())
-         commitContextEntries(ctx, command.hasFlag(Flag.SKIP_OWNERSHIP_CHECK));
+         commitContextEntries(ctx, command.hasFlag(Flag.SKIP_OWNERSHIP_CHECK), isFromStateTransfer(command));
       log.tracef(""The return value is %s"", result);
       return result;
    }
@@ -257,13 +282,18 @@ private final class EntryWrappingVisitor extends AbstractVisitor {
 
       @Override
       public Object visitClearCommand(InvocationContext ctx, ClearCommand command) throws Throwable {
-         boolean notWrapped = false;
+         boolean wrapped = false;
          for (Object key : dataContainer.keySet()) {
             entryFactory.wrapEntryForClear(ctx, key);
-            notWrapped = true;
+            wrapped = true;
          }
-         if (notWrapped)
+         if (wrapped)
             invokeNextInterceptor(ctx, command);
+         if (stateConsumer != null && !ctx.isInTxScope()) {
+            // If a non-tx ClearCommand was executed successfully we must stop recording updated keys and do not
+            // allow any further updates to be written by state transfer from now on until current rebalance ends.
+            stateConsumer.stopApplyingState();
+         }
          return null;
       }
 
@@ -321,10 +351,29 @@ public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command)
       }
    }
 
-   private boolean commitEntryIfNeeded(InvocationContext ctx, boolean skipOwnershipCheck, CacheEntry entry) {
-      if (entry != null && entry.isChanged()) {
+   private boolean commitEntryIfNeeded(InvocationContext ctx, boolean skipOwnershipCheck, Object key, CacheEntry entry, boolean isPutForStateTransfer) {
+      if (entry == null) {
+         if (key != null && !isPutForStateTransfer && stateConsumer != null) {
+            // this key is not yet stored locally
+            stateConsumer.addUpdatedKey(key);
+         }
+         return false;
+      }
+
+      if (isPutForStateTransfer && stateConsumer.isKeyUpdated(key)) {
+         // This is a state transfer put command on a key that was already modified by other user commands. We need to back off.
+         entry.rollback();
+         return false;
+      }
+
+      if (entry.isChanged()) {
          log.tracef(""About to commit entry %s"", entry);
          commitContextEntry(entry, ctx, skipOwnershipCheck);
+
+         if (!isPutForStateTransfer && stateConsumer != null) {
+            stateConsumer.addUpdatedKey(key);
+         }
+
          return true;
       }
       return false;",2012-12-17T12:44:28Z,399
"@@ -31,6 +31,7 @@
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
+import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -61,19 +62,18 @@ public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand comman
          for (WriteCommand c : command.getModifications()) c.acceptVisitor(ctx, entryWrappingVisitor);
       }
       EntryVersionsMap newVersionData= null;
-      if (ctx.isOriginLocal()) newVersionData = cdl.createNewVersionsAndCheckForWriteSkews(versionGenerator, ctx, (VersionedPrepareCommand) command);
+      if (ctx.isOriginLocal() && !((LocalTransaction)ctx.getCacheTransaction()).isFromStateTransfer()) newVersionData = cdl.createNewVersionsAndCheckForWriteSkews(versionGenerator, ctx, (VersionedPrepareCommand) command);
 
       Object retval = invokeNextInterceptor(ctx, command);
 
       if (!ctx.isOriginLocal()) newVersionData = cdl.createNewVersionsAndCheckForWriteSkews(versionGenerator, ctx, (VersionedPrepareCommand) command);
       if (command.isOnePhaseCommit()) ctx.getCacheTransaction().setUpdatedEntryVersions(((VersionedPrepareCommand) command).getVersionsSeen());
 
       if (newVersionData != null) retval = newVersionData;
-      if (command.isOnePhaseCommit()) commitContextEntries(ctx, false);
+      if (command.isOnePhaseCommit()) commitContextEntries(ctx, false, isFromStateTransfer(ctx));
       return retval;
    }
 
-
    @Override
    public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command) throws Throwable {
       try {
@@ -84,13 +84,13 @@ public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command)
       } finally {
          if (!ctx.isOriginLocal())
             ctx.getCacheTransaction().setUpdatedEntryVersions(((VersionedCommitCommand) command).getUpdatedVersions());
-         commitContextEntries(ctx, false);
+         commitContextEntries(ctx, false, isFromStateTransfer(ctx));
       }
    }
 
    @Override
    protected void commitContextEntry(CacheEntry entry, InvocationContext ctx, boolean skipOwnershipCheck) {
-      if (ctx.isInTxScope()) {
+      if (ctx.isInTxScope() && !isFromStateTransfer(ctx)) {
          EntryVersion version = ((TxInvocationContext) ctx).getCacheTransaction().getUpdatedEntryVersions().get(entry.getKey());
          cdl.commitEntry(entry, version, skipOwnershipCheck);
       } else {",2012-12-17T12:44:28Z,560
"@@ -25,6 +25,7 @@
 import org.infinispan.commands.write.PutKeyValueCommand;
 import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.remoting.responses.Response;
 import org.infinispan.remoting.responses.SuccessfulResponse;
@@ -64,7 +65,7 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
       SingleKeyRecipientGenerator skrg = new SingleKeyRecipientGenerator(command.getKey());
-      return handleWriteCommand(ctx, command, skrg, false, false);
+      return handleWriteCommand(ctx, command, skrg, command.hasFlag(Flag.PUT_FOR_STATE_TRANSFER), false);
    }
 
    /**",2012-12-17T12:44:28Z,483
"@@ -94,7 +94,7 @@ public void start() {
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
       SingleKeyRecipientGenerator skrg = new SingleKeyRecipientGenerator(command.getKey());
-      Object returnValue = handleWriteCommand(ctx, command, skrg, false, false);
+      Object returnValue = handleWriteCommand(ctx, command, skrg, command.hasFlag(Flag.PUT_FOR_STATE_TRANSFER), false);
       // If this was a remote put record that which sent it
       if (isL1CacheEnabled && !ctx.isOriginLocal() && !skrg.generateRecipients().contains(ctx.getOrigin()))
          l1Manager.addRequestor(command.getKey(), ctx.getOrigin());",2012-12-17T12:44:28Z,484
"@@ -35,7 +35,7 @@
 import static org.infinispan.transaction.WriteSkewHelper.setVersionsSeenOnPrepareCommand;
 
 /**
- * A version of the {@link BaseDistributionInterceptor} that adds logic to handling prepares when entries are versioned.
+ * A version of the {@link TxDistributionInterceptor} that adds logic to handling prepares when entries are versioned.
  *
  * @author Manik Surtani
  * @since 5.1",2012-12-17T12:44:28Z,561
"@@ -64,4 +64,25 @@ public interface StateConsumer {
     * This is executed when the cache is shutting down.
     */
    void stop();
+
+   /**
+    * Receive notification of updated keys right before they are committed in DataContainer.
+    *
+    * @param key the key that is being modified
+    */
+   void addUpdatedKey(Object key);
+
+   /**
+    * Checks if a given key was updated by user code during state transfer (and consequently it is untouchable by state transfer).
+    *
+    * @param key the key to check
+    * @return true if the key is known to be modified, false otherwise
+    */
+   boolean isKeyUpdated(Object key);
+
+   /**
+    * Stops applying incoming state. Also stops tracking updated keys. Should be called at the end of state transfer or
+    * when a ClearCommand is committed during state transfer.
+    */
+   void stopApplyingState();
 }",2012-12-17T12:44:28Z,56
"@@ -34,6 +34,7 @@
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
+import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
@@ -45,15 +46,19 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
+import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.xa.CacheTransaction;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
+import org.infinispan.util.concurrent.ConcurrentHashSet;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import javax.transaction.Transaction;
+import javax.transaction.TransactionManager;
 import java.util.*;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
@@ -75,6 +80,7 @@ public class StateConsumerImpl implements StateConsumer {
    private String cacheName;
    private Configuration configuration;
    private RpcManager rpcManager;
+   private TransactionManager transactionManager;   // optional
    private CommandsFactory commandsFactory;
    private TransactionTable transactionTable;       // optional
    private DataContainer dataContainer;
@@ -88,30 +94,68 @@ public class StateConsumerImpl implements StateConsumer {
 
    private volatile CacheTopology cacheTopology;
 
+   /**
+    * Keeps track of all keys updated by user code during state transfer. If this is null no keys are being recorded and
+    * state transfer is not allowed to update anything. This can be null if there is not state transfer in progress at
+    * the moment of there is one but a ClearCommand was encountered.
+    */
+   private volatile Set<Object> updatedKeys;
+
+   /**
+    * Stops applying incoming state. Also stops tracking updated keys. Should be called at the end of state transfer or
+    * when a ClearCommand is committed during state transfer.
+    */
+   public void stopApplyingState() {
+      updatedKeys = null;
+   }
+
+   /**
+    * Receive notification of updated keys right before they are committed in DataContainer.
+    *
+    * @param key the key that is being modified
+    */
+   public void addUpdatedKey(Object key) {
+      if (updatedKeys != null) {
+         if (cacheTopology.getWriteConsistentHash().isKeyLocalToNode(rpcManager.getAddress(), key)) {
+            updatedKeys.add(key);
+         }
+      }
+   }
+
+   /**
+    * Checks if a given key was updated by user code during state transfer (and consequently it is untouchable by state transfer).
+    *
+    * @param key the key to check
+    * @return true if the key is known to be modified, false otherwise
+    */
+   public boolean isKeyUpdated(Object key) {
+      return updatedKeys == null || updatedKeys.contains(key);
+   }
+
    /**
     * The number of topology updates that are being processed concurrently (in method onTopologyUpdate()).
     * This is needed to be able to detect completion.
     */
-   private AtomicInteger activeTopologyUpdates = new AtomicInteger(0);
+   private final AtomicInteger activeTopologyUpdates = new AtomicInteger(0);
 
    /**
     * Indicates if the currently executing topology update is a rebalance.
     */
-   private AtomicBoolean rebalanceInProgress = new AtomicBoolean(false);
+   private final AtomicBoolean rebalanceInProgress = new AtomicBoolean(false);
 
    /**
     * A map that keeps track of current inbound state transfers by source address. There could be multiple transfers
     * flowing in from the same source (but for different segments) so the values are lists. This works in tandem with
     * transfersBySegment so they always need to be kept in sync and updates to both of them need to be atomic.
     */
-   private Map<Address, List<InboundTransferTask>> transfersBySource = new HashMap<Address, List<InboundTransferTask>>();
+   private final Map<Address, List<InboundTransferTask>> transfersBySource = new HashMap<Address, List<InboundTransferTask>>();
 
    /**
     * A map that keeps track of current inbound state transfers by segment id. There is at most one transfers per segment.
     * This works in tandem with transfersBySource so they always need to be kept in sync and updates to both of them
     * need to be atomic.
     */
-   private Map<Integer, InboundTransferTask> transfersBySegment = new HashMap<Integer, InboundTransferTask>();
+   private final Map<Integer, InboundTransferTask> transfersBySegment = new HashMap<Integer, InboundTransferTask>();
 
    public StateConsumerImpl() {
    }
@@ -123,6 +167,7 @@ public void init(Cache cache,
                     InvocationContextContainer icc,
                     Configuration configuration,
                     RpcManager rpcManager,
+                    TransactionManager transactionManager,
                     CommandsFactory commandsFactory,
                     CacheLoaderManager cacheLoaderManager,
                     DataContainer dataContainer,
@@ -134,6 +179,7 @@ public void init(Cache cache,
       this.icc = icc;
       this.configuration = configuration;
       this.rpcManager = rpcManager;
+      this.transactionManager = transactionManager;
       this.commandsFactory = commandsFactory;
       this.cacheLoaderManager = cacheLoaderManager;
       this.dataContainer = dataContainer;
@@ -172,7 +218,7 @@ public boolean isStateTransferInProgressForKey(Object key) {
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
       if (trace) log.tracef(""Received new CH %s for cache %s"", cacheTopology.getWriteConsistentHash(), cacheName);
 
-      activeTopologyUpdates.incrementAndGet();
+      int numStartedTopologyUpdates = activeTopologyUpdates.incrementAndGet();
       if (isRebalance) {
          rebalanceInProgress.set(true);
       }
@@ -181,6 +227,9 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
       // No need for a try/finally block, since it's just an assignment
       stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
+      if (numStartedTopologyUpdates == 1) {
+         updatedKeys = new ConcurrentHashSet<Object>();
+      }
       stateTransferLock.releaseExclusiveTopologyLock();
       stateTransferLock.notifyTopologyInstalled(cacheTopology.getTopologyId());
 
@@ -260,6 +309,7 @@ private void notifyEndOfTopologyUpdate(int topologyId) {
       if (!isStateTransferInProgress()) {
          if (rebalanceInProgress.compareAndSet(true, false)) {
             log.debugf(""Finished receiving of segments for cache %s for topology %d."", cacheName, topologyId);
+            stopApplyingState();
             stateTransferManager.notifyEndOfTopologyUpdate(topologyId);
          }
       }
@@ -287,6 +337,10 @@ public void applyState(Address sender, int topologyId, int segmentId, Collection
          inboundTransfer = transfersBySegment.get(segmentId);
       }
       if (inboundTransfer != null) {
+         if (trace) {
+            log.tracef(""Before applying the received state the data container of cache %s has %d keys"", cacheName, dataContainer.size());
+         }
+
          if (cacheEntries != null) {
             doApplyState(sender, segmentId, cacheEntries);
          }
@@ -315,18 +369,48 @@ private void doApplyState(Address sender, int segmentId, Collection<InternalCach
       }
 
       // CACHE_MODE_LOCAL avoids handling by StateTransferInterceptor and any potential locks in StateTransferLock
-      //TODO This must be addressed again. SKIP_LOCKING is just a workaround for issue https://issues.jboss.org/browse/ISPN-2408
-      EnumSet<Flag> flags = EnumSet.of(CACHE_MODE_LOCAL, SKIP_LOCKING, IGNORE_RETURN_VALUES, SKIP_SHARED_CACHE_STORE, SKIP_OWNERSHIP_CHECK, SKIP_XSITE_BACKUP);
+      EnumSet<Flag> flags = EnumSet.of(PUT_FOR_STATE_TRANSFER, CACHE_MODE_LOCAL, IGNORE_RETURN_VALUES, SKIP_REMOTE_LOOKUP, SKIP_SHARED_CACHE_STORE, SKIP_OWNERSHIP_CHECK, SKIP_XSITE_BACKUP);
       for (InternalCacheEntry e : cacheEntries) {
-         InvocationContext ctx = icc.createRemoteInvocationContext(sender);
          try {
+            InvocationContext ctx;
+            if (transactionManager != null) {
+               // cache is transactional
+               transactionManager.begin();
+               Transaction transaction = transactionManager.getTransaction();
+               ctx = icc.createInvocationContext(transaction);
+               ((TxInvocationContext) ctx).setImplicitTransaction(true);
+            } else {
+               // non-tx cache
+               ctx = icc.createSingleKeyNonTxInvocationContext();
+            }
+
             PutKeyValueCommand put = useVersionedPut ?
                   commandsFactory.buildVersionedPutKeyValueCommand(e.getKey(), e.getValue(), e.getLifespan(), e.getMaxIdle(), e.getVersion(), flags)
                   : commandsFactory.buildPutKeyValueCommand(e.getKey(), e.getValue(), e.getLifespan(), e.getMaxIdle(), flags);
-            put.setPutIfAbsent(true); //todo [anistor] this still does not solve removal cases. we need tombstones for deleted keys. we need to keep a separate set of deleted keys an use it during apply state
-            interceptorChain.invoke(ctx, put);
+
+            boolean success = false;
+            try {
+               interceptorChain.invoke(ctx, put);
+               success = true;
+            } finally {
+               if (ctx.isInTxScope()) {
+                  if (success) {
+                     ((LocalTransaction)((TxInvocationContext)ctx).getCacheTransaction()).setFromStateTransfer(true);
+                     try {
+                        transactionManager.commit();
+                     } catch (Throwable ex) {
+                        log.errorf(ex, ""Could not commit transaction created by state transfer of key %s"", e.getKey());
+                        if (transactionManager.getTransaction() != null) {
+                           transactionManager.rollback();
+                        }
+                     }
+                  } else {
+                     transactionManager.rollback();
+                  }
+               }
+            }
          } catch (Exception ex) {
-            log.problemApplyingStateForKey(ex.getMessage(), e.getKey());
+            log.problemApplyingStateForKey(ex.getMessage(), e.getKey(), ex);
          }
       }
       log.debugf(""Finished applying state for segment %d of cache %s"", segmentId, cacheName);",2012-12-17T12:44:28Z,54
"@@ -63,6 +63,8 @@ public abstract class LocalTransaction extends AbstractCacheTransaction {
 
    private volatile boolean isFromRemoteSite;
 
+   private volatile boolean isFromStateTransfer;
+
    public LocalTransaction(Transaction transaction, GlobalTransaction tx, boolean implicitTransaction, int topologyId) {
       super(tx, topologyId);
       this.transaction = transaction;
@@ -159,6 +161,7 @@ public String toString() {
             "", lockedKeys="" + lockedKeys +
             "", backupKeyLocks="" + backupKeyLocks +
             "", topologyId="" + topologyId +
+            "", isFromStateTransfer="" + isFromStateTransfer +
             ""} "" + super.toString();
    }
 
@@ -177,6 +180,14 @@ public boolean keyRead(Object key) {
       return readKeys != null && readKeys.contains(key);
    }
 
+   public boolean isFromStateTransfer() {
+      return isFromStateTransfer;
+   }
+
+   public void setFromStateTransfer(boolean isFromStateTransfer) {
+      this.isFromStateTransfer = isFromStateTransfer;
+   }
+
    /**
     * When x-site replication is used, this returns when this operation
     * happens as a result of backing up data from a remote site.",2012-12-17T12:44:28Z,454
"@@ -138,7 +138,7 @@ public interface Log extends BasicLogger {
 
    @LogMessage(level = WARN)
    @Message(value = ""Problem %s encountered when applying state for key %s!"", id = 16)
-   void problemApplyingStateForKey(String msg, Object key);
+   void problemApplyingStateForKey(String msg, Object key, @Cause Throwable t);
 
    @LogMessage(level = WARN)
    @Message(value = ""Unable to apply prepare %s"", id = 18)",2012-12-17T12:44:28Z,45
"@@ -0,0 +1,262 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.commands.VisitableCommand;
+import org.infinispan.commands.write.PutKeyValueCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.cache.VersioningScheme;
+import org.infinispan.container.DataContainer;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.transaction.TransactionMode;
+import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
+import org.infinispan.util.concurrent.IsolationLevel;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.testng.annotations.Test;
+
+import java.util.HashMap;
+import java.util.Map;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.TimeoutException;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.assertNull;
+
+/**
+ * Base test class for ISPN-2362 and ISPN-2502 in distributed mode. Uses a cluster which initially has 3 nodes and
+ * the second node is killed in order to cause a state transfer and test consistency.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"")
+@CleanupAfterMethod
+public abstract class BaseDistStateTransferConsistencyTest extends MultipleCacheManagersTest {
+
+   private static final Log log = LogFactory.getLog(BaseDistStateTransferConsistencyTest.class);
+
+   private enum Operation {
+      REMOVE, CLEAR, PUT, PUT_MAP, REPLACE
+   }
+
+   private final boolean isOptimistic;
+
+   protected BaseDistStateTransferConsistencyTest(boolean isOptimistic) {
+      this.isOptimistic = isOptimistic;
+   }
+
+   @Override
+   protected void createCacheManagers() {
+      ConfigurationBuilder builder = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true, true);
+      builder.transaction().transactionMode(TransactionMode.TRANSACTIONAL)
+            .transactionManagerLookup(new DummyTransactionManagerLookup())
+            .syncCommitPhase(true).syncRollbackPhase(true);
+
+      if (isOptimistic) {
+         builder.transaction().lockingMode(LockingMode.OPTIMISTIC)
+               .locking().writeSkewCheck(true).isolationLevel(IsolationLevel.REPEATABLE_READ)
+               .versioning().enable().scheme(VersioningScheme.SIMPLE);
+      } else {
+         builder.transaction().lockingMode(LockingMode.PESSIMISTIC);
+      }
+
+      builder.clustering().hash().numSegments(10).numOwners(2).l1().disable().onRehash(false).locking().lockAcquisitionTimeout(1000l);
+      builder.clustering().stateTransfer().fetchInMemoryState(true).waitForInitialStateTransferToComplete(false);
+
+      createCluster(builder, 3);
+      waitForClusterToForm();
+   }
+
+   public void testRemove() throws Exception {
+      testStateTransferConsistency(Operation.REMOVE);
+   }
+
+   public void testClear() throws Exception {
+      testStateTransferConsistency(Operation.CLEAR);
+   }
+
+   public void testPut() throws Exception {
+      testStateTransferConsistency(Operation.PUT);
+   }
+
+   public void testPutMap() throws Exception {
+      testStateTransferConsistency(Operation.PUT_MAP);
+   }
+
+   @Test(enabled = false)  // disabled due to ISPN-2647
+   public void testReplace() throws Exception {
+      testStateTransferConsistency(Operation.REPLACE);
+   }
+
+   private void testStateTransferConsistency(Operation op) throws Exception {
+      final int num = 5;
+      log.infof(""Putting %d keys into cache .."", num);
+      for (int i = 0; i < num; i++) {
+         cache(0).put(i, ""before_st_"" + i);
+      }
+      log.info(""Finished putting keys"");
+
+      for (int i = 0; i < num; i++) {
+         assertEquals(""before_st_"" + i, cache(0).get(i));
+         assertEquals(""before_st_"" + i, cache(1).get(i));
+         assertEquals(""before_st_"" + i, cache(2).get(i));
+      }
+
+      final CountDownLatch applyStateProceedLatch = new CountDownLatch(1);
+      final CountDownLatch applyStateStartedLatch1 = new CountDownLatch(1);
+      advancedCache(0).addInterceptor(new CommandInterceptor() {
+         @Override
+         protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) throws Throwable {
+            // if this 'put' command is caused by state transfer we delay it to ensure other cache operations
+            // are performed first and create opportunity for inconsistencies
+            if (cmd instanceof PutKeyValueCommand && ((PutKeyValueCommand) cmd).hasFlag(Flag.PUT_FOR_STATE_TRANSFER)) {
+               // signal we encounter a state transfer PUT
+               applyStateStartedLatch1.countDown();
+               // wait until it is ok to apply state
+               if (!applyStateProceedLatch.await(15, TimeUnit.SECONDS)) {
+                  throw new TimeoutException();
+               }
+            }
+            return super.handleDefault(ctx, cmd);
+         }
+      }, 0);
+
+      final CountDownLatch applyStateStartedLatch2 = new CountDownLatch(1);
+      advancedCache(2).addInterceptor(new CommandInterceptor() {
+         @Override
+         protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) throws Throwable {
+            // if this 'put' command is caused by state transfer we delay it to ensure other cache operations
+            // are performed first and create opportunity for inconsistencies
+            if (cmd instanceof PutKeyValueCommand && ((PutKeyValueCommand) cmd).hasFlag(Flag.PUT_FOR_STATE_TRANSFER)) {
+               // signal we encounter a state transfer PUT
+               applyStateStartedLatch2.countDown();
+               // wait until it is ok to apply state
+               if (!applyStateProceedLatch.await(15, TimeUnit.SECONDS)) {
+                  throw new TimeoutException();
+               }
+            }
+            return super.handleDefault(ctx, cmd);
+         }
+      }, 0);
+
+      log.info(""Killing node 1 .."");
+      TestingUtil.killCacheManagers(manager(1));
+      log.info(""Node 1 killed"");
+
+      DataContainer dc0 = advancedCache(0).getDataContainer();
+      DataContainer dc2 = advancedCache(2).getDataContainer();
+
+      // wait for state transfer on nodes A and C to progress to the point where data segments are about to be applied
+      if (!applyStateStartedLatch1.await(15, TimeUnit.SECONDS)) {
+         throw new TimeoutException();
+      }
+      if (!applyStateStartedLatch2.await(15, TimeUnit.SECONDS)) {
+         throw new TimeoutException();
+      }
+
+      if (op == Operation.CLEAR) {
+         log.info(""Clearing cache .."");
+         cache(0).clear();
+         log.info(""Finished clearing cache"");
+
+         assertEquals(0, dc0.size());
+         assertEquals(0, dc2.size());
+      } else if (op == Operation.REMOVE) {
+         log.info(""Removing all keys one by one .."");
+         for (int i = 0; i < num; i++) {
+            cache(0).remove(i);
+         }
+         log.info(""Finished removing keys"");
+
+         assertEquals(0, dc0.size());
+         assertEquals(0, dc2.size());
+      } else if (op == Operation.PUT || op == Operation.PUT_MAP || op == Operation.REPLACE) {
+         log.info(""Updating all keys .."");
+         if (op == Operation.PUT) {
+            for (int i = 0; i < num; i++) {
+               cache(0).put(i, ""after_st_"" + i);
+            }
+         } else if (op == Operation.PUT_MAP) {
+            Map<Integer, String> toPut = new HashMap<Integer, String>();
+            for (int i = 0; i < num; i++) {
+               toPut.put(i, ""after_st_"" + i);
+            }
+            cache(0).putAll(toPut);
+         } else {
+            for (int i = 0; i < num; i++) {
+               String expectedOldValue = ""before_st_"" + i;
+               boolean replaced = cache(0).replace(i, expectedOldValue, ""after_st_"" + i);
+               assertTrue(replaced);
+            }
+         }
+         log.info(""Finished updating keys"");
+      }
+
+      // allow state transfer to apply state
+      applyStateProceedLatch.countDown();
+
+      // wait for apply state to end
+      TestingUtil.waitForRehashToComplete(cache(0), cache(2));
+
+      // at this point state transfer is fully done
+      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.keySet());
+      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.keySet());
+
+      if (op == Operation.CLEAR || op == Operation.REMOVE) {
+         // caches should be empty. check that no keys were revived by an inconsistent state transfer
+         for (int i = 0; i < num; i++) {
+            assertNull(dc0.get(i));
+            assertNull(dc2.get(i));
+         }
+      } else if (op == Operation.PUT || op == Operation.PUT_MAP || op == Operation.REPLACE) {
+         ConsistentHash ch = advancedCache(0).getComponentRegistry().getStateTransferManager().getCacheTopology().getReadConsistentHash();
+         // check that all values are the ones expected after state transfer
+         for (int i = 0; i < num; i++) {
+            // check values were not overwritten with old values carried by state transfer
+            assertEquals(""after_st_"" + i, cache(0).get(i));
+            assertEquals(""after_st_"" + i, cache(2).get(i));
+
+            // check number of owners
+            int owners = 0;
+            if (dc0.get(i) != null) {
+               owners++;
+            }
+            if (dc2.get(i) != null) {
+               owners++;
+            }
+            assertEquals(""Wrong number of owners"", ch.locateOwners(i).size(), owners);
+         }
+      }
+   }
+}",2012-12-17T12:44:28Z,485
"@@ -0,0 +1,246 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.commands.VisitableCommand;
+import org.infinispan.commands.write.PutKeyValueCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.cache.VersioningScheme;
+import org.infinispan.container.DataContainer;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.interceptors.InvocationContextInterceptor;
+import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.transaction.TransactionMode;
+import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
+import org.infinispan.util.concurrent.IsolationLevel;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.testng.annotations.Test;
+
+import java.util.HashMap;
+import java.util.Map;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.TimeoutException;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertNotNull;
+
+/**
+ * Base test class for issues ISPN-2362 and ISPN-2502 in replicated mode. Uses a cluster which initially has two nodes
+ * and then a third is added to test consistency of state transfer.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"")
+@CleanupAfterMethod
+public abstract class BaseReplStateTransferConsistencyTest extends MultipleCacheManagersTest {
+
+   private static final Log log = LogFactory.getLog(BaseReplStateTransferConsistencyTest.class);
+
+   private enum Operation {
+      REMOVE, CLEAR, PUT, PUT_MAP, REPLACE
+   }
+
+   private ConfigurationBuilder cacheConfigBuilder;
+
+   private final boolean isOptimistic;
+
+   protected BaseReplStateTransferConsistencyTest(boolean isOptimistic) {
+      this.isOptimistic = isOptimistic;
+   }
+
+   @Override
+   protected void createCacheManagers() {
+      cacheConfigBuilder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, true, true);
+      cacheConfigBuilder.transaction().transactionMode(TransactionMode.TRANSACTIONAL)
+            .transactionManagerLookup(new DummyTransactionManagerLookup())
+            .syncCommitPhase(true).syncRollbackPhase(true);
+
+      if (isOptimistic) {
+         cacheConfigBuilder.transaction().lockingMode(LockingMode.OPTIMISTIC)
+               .locking().writeSkewCheck(true).isolationLevel(IsolationLevel.REPEATABLE_READ)
+               .versioning().enable().scheme(VersioningScheme.SIMPLE);
+      } else {
+         cacheConfigBuilder.transaction().lockingMode(LockingMode.PESSIMISTIC);
+      }
+
+      cacheConfigBuilder.clustering().l1().disable().onRehash(false).locking().lockAcquisitionTimeout(1000l);
+      cacheConfigBuilder.clustering().hash().numSegments(10)
+            .stateTransfer().fetchInMemoryState(true).waitForInitialStateTransferToComplete(false);
+
+      createCluster(cacheConfigBuilder, 2);
+      waitForClusterToForm();
+   }
+
+   public void testRemove() throws Exception {
+      testStateTransferConsistency(Operation.REMOVE);
+   }
+
+   public void testClear() throws Exception {
+      testStateTransferConsistency(Operation.CLEAR);
+   }
+
+   public void testPut() throws Exception {
+      testStateTransferConsistency(Operation.PUT);
+   }
+
+   public void testPutMap() throws Exception {
+      testStateTransferConsistency(Operation.PUT_MAP);
+   }
+
+   @Test(enabled = false)  // disabled due to ISPN-2647
+   public void testReplace() throws Exception {
+      testStateTransferConsistency(Operation.REPLACE);
+   }
+
+   private void testStateTransferConsistency(Operation op) throws Exception {
+      final int num = 5;
+      log.infof(""Putting %d keys into cache .."", num);
+      for (int i = 0; i < num; i++) {
+         cache(0).put(i, ""before_st_"" + i);
+      }
+      log.info(""Finished putting keys"");
+
+      for (int i = 0; i < num; i++) {
+         String expected = ""before_st_"" + i;
+         assertValue(0, i, expected);
+         assertValue(1, i, expected);
+      }
+
+      final CountDownLatch applyStateProceedLatch = new CountDownLatch(1);
+      final CountDownLatch applyStateStartedLatch = new CountDownLatch(1);
+      cacheConfigBuilder.customInterceptors().addInterceptor().before(InvocationContextInterceptor.class).interceptor(new CommandInterceptor() {
+         @Override
+         protected Object handleDefault(InvocationContext ctx, VisitableCommand cmd) throws Throwable {
+            // if this 'put' command is caused by state transfer we delay it to ensure other cache operations
+            // are performed first and create opportunity for inconsistencies
+            if (cmd instanceof PutKeyValueCommand && ((PutKeyValueCommand) cmd).hasFlag(Flag.PUT_FOR_STATE_TRANSFER)) {
+               // signal we encounter a state transfer PUT
+               applyStateStartedLatch.countDown();
+               // wait until it is ok to apply state
+               if (!applyStateProceedLatch.await(15, TimeUnit.SECONDS)) {
+                  throw new TimeoutException();
+               }
+            }
+            return super.handleDefault(ctx, cmd);
+         }
+      });
+
+      log.info(""Adding a new node .."");
+      addClusterEnabledCacheManager(cacheConfigBuilder);
+      log.info(""Added a new node"");
+
+      DataContainer dc0 = advancedCache(0).getDataContainer();
+      DataContainer dc1 = advancedCache(1).getDataContainer();
+      DataContainer dc2 = advancedCache(2).getDataContainer();
+
+      // wait for state transfer on node C to progress to the point where data segments are about to be applied
+      if (!applyStateStartedLatch.await(15, TimeUnit.SECONDS)) {
+         throw new TimeoutException();
+      }
+
+      if (op == Operation.CLEAR) {
+         log.info(""Clearing cache .."");
+         cache(0).clear();
+         log.info(""Finished clearing cache"");
+
+         assertEquals(0, dc0.size());
+         assertEquals(0, dc1.size());
+      } else if (op == Operation.REMOVE) {
+         log.info(""Removing all keys one by one .."");
+         for (int i = 0; i < num; i++) {
+            cache(0).remove(i);
+         }
+         log.info(""Finished removing keys"");
+
+         assertEquals(0, dc0.size());
+         assertEquals(0, dc1.size());
+      } else if (op == Operation.PUT || op == Operation.PUT_MAP || op == Operation.REPLACE) {
+         log.info(""Updating all keys .."");
+         if (op == Operation.PUT) {
+            for (int i = 0; i < num; i++) {
+               cache(0).put(i, ""after_st_"" + i);
+            }
+         } else if (op == Operation.PUT_MAP) {
+            Map<Integer, String> toPut = new HashMap<Integer, String>();
+            for (int i = 0; i < num; i++) {
+               toPut.put(i, ""after_st_"" + i);
+            }
+            cache(0).putAll(toPut);
+         } else {
+            for (int i = 0; i < num; i++) {
+               String expectedOldValue = ""before_st_"" + i;
+               boolean replaced = cache(0).replace(i, expectedOldValue, ""after_st_"" + i);
+               assertTrue(replaced);
+            }
+         }
+         log.info(""Finished updating keys"");
+      }
+
+      // allow state transfer to apply state
+      applyStateProceedLatch.countDown();
+
+      // wait for apply state to end
+      TestingUtil.waitForRehashToComplete(cache(0), cache(1), cache(2));
+
+      // at this point state transfer is fully done
+      log.infof(""Data container of NodeA has %d keys: %s"", dc0.size(), dc0.keySet());
+      log.infof(""Data container of NodeB has %d keys: %s"", dc1.size(), dc1.keySet());
+      log.infof(""Data container of NodeC has %d keys: %s"", dc2.size(), dc2.keySet());
+
+      if (op == Operation.CLEAR || op == Operation.REMOVE) {
+         // caches should be empty. check that no keys were revived by an inconsistent state transfer
+         for (int i = 0; i < num; i++) {
+            assertNull(dc0.get(i));
+            assertNull(dc1.get(i));
+            assertNull(dc2.get(i));
+         }
+      } else if (op == Operation.PUT || op == Operation.PUT_MAP || op == Operation.REPLACE) {
+         // check that all values are the ones expected after state transfer and were not overwritten with old values carried by state transfer
+         for (int i = 0; i < num; i++) {
+            String expectedValue = ""after_st_"" + i;
+            assertValue(0, i, expectedValue);
+            assertValue(1, i, expectedValue);
+            assertValue(2, i, expectedValue);
+         }
+      }
+   }
+
+   private void assertValue(int cacheIndex, int key, String expectedValue) {
+      InternalCacheEntry object = cache(cacheIndex).getAdvancedCache().getDataContainer().get(key);
+      assertNotNull(object);
+      assertEquals(expectedValue, object.getValue());
+      assertEquals(expectedValue, cache(cacheIndex).get(key));
+   }
+}",2012-12-17T12:44:28Z,498
"@@ -0,0 +1,41 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * Test ISPN-2362 and ISPN-2502 on distributed, optimistic cluster, with write-skew check.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.DistStateTransferConsistencyOptimisticTest"")
+@CleanupAfterMethod
+public class DistStateTransferConsistencyOptimisticTest extends BaseDistStateTransferConsistencyTest {
+
+   public DistStateTransferConsistencyOptimisticTest() {
+      super(true);
+   }
+}",2012-12-17T12:44:28Z,562
"@@ -0,0 +1,41 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * Test for ISPN-2362 and ISPN-2502 on distributed, pessimistic cluster.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.DistStateTransferConsistencyPessimisticTest"")
+@CleanupAfterMethod
+public class DistStateTransferConsistencyPessimisticTest extends BaseDistStateTransferConsistencyTest {
+
+   public DistStateTransferConsistencyPessimisticTest() {
+      super(false);
+   }
+}
\ No newline at end of file",2012-12-17T12:44:28Z,563
"@@ -0,0 +1,41 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * Test ISPN-2362 and ISPN-2502 on replicated, optimistic cluster, with write-skew check.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplStateTransferConsistencyOptimisticTest"")
+@CleanupAfterMethod
+public class ReplStateTransferConsistencyOptimisticTest extends BaseReplStateTransferConsistencyTest {
+
+   protected ReplStateTransferConsistencyOptimisticTest() {
+      super(true);
+   }
+}",2012-12-17T12:44:28Z,564
"@@ -0,0 +1,41 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.statetransfer;
+
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.testng.annotations.Test;
+
+/**
+ * Test for ISPN-2362 and ISPN-2502 on replicated, pessimistic cluster.
+ *
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.ReplStateTransferConsistencyPessimisticTest"")
+@CleanupAfterMethod
+public class ReplStateTransferConsistencyPessimisticTest extends BaseReplStateTransferConsistencyTest {
+
+   protected ReplStateTransferConsistencyPessimisticTest() {
+      super(false);
+   }
+}
\ No newline at end of file",2012-12-17T12:44:28Z,565
"@@ -182,7 +182,7 @@ public Map<Address, Response> answer(InvocationOnMock invocation) {
 
       // create state provider
       StateConsumerImpl stateConsumer = new StateConsumerImpl();
-      stateConsumer.init(cache, stateTransferManager, interceptorChain, icc, configuration, rpcManager,
+      stateConsumer.init(cache, stateTransferManager, interceptorChain, icc, configuration, rpcManager, null,
             commandsFactory, cacheLoaderManager, dataContainer, transactionTable, stateTransferLock);
       stateConsumer.start();
 ",2012-12-17T12:44:28Z,56
"@@ -53,7 +53,8 @@ protected Log getLog() {
    }
 
    @Override
-   protected boolean shouldModifyIndexes(final FlagAffectedCommand command, final InvocationContext ctx) {
-      return ctx.isOriginLocal() && ! command.hasFlag(Flag.SKIP_INDEXING);
+   protected boolean shouldModifyIndexes(FlagAffectedCommand command, InvocationContext ctx) {
+      // will index only local updates that were not flagged with SKIP_INDEXING and are not caused internally by state transfer
+      return ctx.isOriginLocal() && !command.hasFlag(Flag.SKIP_INDEXING) && !command.hasFlag(Flag.PUT_FOR_STATE_TRANSFER);
    }
 }",2012-12-17T12:44:28Z,566
"@@ -23,6 +23,7 @@
 package org.infinispan.client.hotrod.impl.consistenthash;
 
 import java.net.SocketAddress;
+import java.util.Arrays;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.Random;
@@ -45,9 +46,12 @@
 public class ConsistentHashV1 implements ConsistentHash {
 
    private static final BasicLogger log = BasicLogFactory.getLog(ConsistentHashV1.class);
-   
+
    private final SortedMap<Integer, SocketAddress> positions = new TreeMap<Integer, SocketAddress>();
 
+   private volatile int[] hashes;
+   private volatile SocketAddress[] addresses;
+
    private int hashSpace;
 
    protected Hash hash = new MurmurHash2();
@@ -58,7 +62,7 @@ public class ConsistentHashV1 implements ConsistentHash {
 
    @Override
    public void init(Map<SocketAddress, Set<Integer>> servers2Hash, int numKeyOwners, int hashSpace) {
-      for (Map.Entry<SocketAddress, Set<Integer>> entry : servers2Hash.entrySet()){
+      for (Map.Entry<SocketAddress, Set<Integer>> entry : servers2Hash.entrySet()) {
          SocketAddress addr = entry.getKey();
          for (Integer hash : entry.getValue()) {
             SocketAddress prev = positions.put(hash, addr);
@@ -68,6 +72,14 @@ public void init(Map<SocketAddress, Set<Integer>> servers2Hash, int numKeyOwners
       }
 
       log.tracef(""Positions (%d entries) are: %s"", positions.size(), positions);
+
+      hashes = new int[servers2Hash.size()];
+      Iterator<Integer> it = positions.keySet().iterator();
+      for (int i = 0; i < hashes.length; i++) {
+         hashes[i] = it.next();
+      }
+      addresses = positions.values().toArray(new SocketAddress[servers2Hash.size()]);
+
       this.hashSpace = hashSpace;
       this.numKeyOwners = numKeyOwners;
    }
@@ -78,39 +90,34 @@ public SocketAddress getServer(byte[] key) {
       if (keyHashCode == Integer.MIN_VALUE) keyHashCode += 1;
       int hash = Math.abs(keyHashCode);
 
-      SortedMap<Integer, SocketAddress> candidates = positions.tailMap(hash % hashSpace);
-      if (log.isTraceEnabled()) {
-         log.tracef(""Found possible candidates: %s"", candidates);
-      }
-      int index = getIndex();
-      if (candidates.size() <= index) {
-         int newIndex = index - candidates.size();
-         SocketAddress socketAddress = getItemAtPosition(newIndex, positions);
-         if (log.isTraceEnabled()) {
-            log.tracef(""Over the wheel, returning member: %s"", socketAddress);
-         }
-         return socketAddress;
+      int normalisedHashForKey = hash % hashSpace;
+
+      int mainOwner = getHashIndex(normalisedHashForKey);
+      int randomOwner = getIndex();
+
+      int indexToReturn = (mainOwner + randomOwner) % hashes.length;
+
+      return addresses[indexToReturn];
+   }
+
+   private int getHashIndex(int normalisedHashForKey) {
+      int result = Arrays.binarySearch(hashes, normalisedHashForKey);
+      if (result > 0) {//the normalisedHashForKey has an exact match in the hashes array
+         return result;
       } else {
-         SocketAddress socketAddress = getItemAtPosition(index, candidates);
-         if (log.isTraceEnabled()) {
-            log.tracef(""Found candidate: %s"", socketAddress);
+         //see javadoc for Arrays.binarySearch, @return tag in particular
+         if (result == (-hashes.length - 1)) {
+            return 0;
+         } else {
+            return -result - 1;
          }
-         return socketAddress;
       }
    }
 
    private int getIndex() {
       return rnd.nextInt(Math.min(numKeyOwners, positions.size()));
    }
 
-   private SocketAddress getItemAtPosition(int position, SortedMap<Integer, SocketAddress> map) {
-      Iterator<Map.Entry<Integer,SocketAddress>> iterator = map.entrySet().iterator();
-      for (int i = 0; i < position; i++) {
-         iterator.next();
-      }
-      return iterator.next().getValue();
-   }
-
    public void setHash(Hash hash) {
       this.hash = hash;
    }
@@ -119,5 +126,4 @@ public void setHash(Hash hash) {
    public int getNormalizedHash(Object key) {
       return Util.getNormalizedHash(key, hash);
    }
-
 }",2012-05-25T13:07:50Z,410
"@@ -0,0 +1,99 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2010 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.client.hotrod;
+
+import org.infinispan.client.hotrod.impl.consistenthash.ConsistentHash;
+import org.infinispan.client.hotrod.impl.consistenthash.ConsistentHashV1;
+import org.infinispan.commons.hash.MurmurHash3;
+import org.testng.annotations.Test;
+
+import java.net.InetSocketAddress;
+import java.net.SocketAddress;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Random;
+import java.util.Set;
+import java.util.concurrent.TimeUnit;
+
+/**
+ * @author Mircea Markus <mircea.markus@jboss.com> (C) 2011 Red Hat Inc.
+ * @since 5.1
+ */
+@Test (groups = ""performance"", testName = ""client.hotrod.ConsistentHashPerformanceTest"", enabled = false)
+public class ConsistentHashPerformanceTest {
+
+
+   public static final int KEY_POOL_SIZE = 1000;
+   static List<byte[]> keys = new ArrayList<byte[]>(KEY_POOL_SIZE);
+
+   static {
+      Random rnd = new Random();
+      for (int i = 0; i < KEY_POOL_SIZE; i++) {
+         byte[] bytes = new byte[12];
+         rnd.nextBytes(bytes);
+         keys.add(bytes);
+      }
+   }
+
+   private void testConsistentHashSpeed(ConsistentHash ch) {
+
+      int loopSize = 1000000;
+      Random rnd = new Random();
+      long duration = 0;
+
+      for (int i = 0; i < loopSize; i++) {
+         int keyIndex = rnd.nextInt(KEY_POOL_SIZE);
+
+         long start = System.nanoTime();
+         SocketAddress server = ch.getServer(keys.get(keyIndex));
+         duration += System.nanoTime() - start;
+
+         //just make sure this code is not removed from JIT
+         if (server.hashCode() == loopSize) {
+            System.out.println("""");
+         }
+      }
+
+      System.out.printf(""It took %s millis for consistent hash %s to execute %s operations \n"" , TimeUnit.NANOSECONDS.toMillis(duration), ch.getClass().getSimpleName(), loopSize);
+   }
+
+   public void testVariousVersion1() {
+      ConsistentHashV1 dch2 = new ConsistentHashV1();
+      initConsistentHash(dch2);
+      testConsistentHashSpeed(dch2);
+   }
+
+   private void initConsistentHash(ConsistentHashV1 dch) {
+      int numAddresses = 1500;
+      LinkedHashMap<SocketAddress, Set<Integer>> map = new LinkedHashMap<SocketAddress, Set<Integer>>();
+      for (int i = 0; i < numAddresses; i++) {
+         map.put(new InetSocketAddress(i), Collections.singleton(i * 1000));
+      }
+
+
+      dch.init(map, 2, 10024);
+      dch.setHash(new MurmurHash3());
+   }
+}",2012-05-25T13:07:50Z,567
"@@ -63,6 +63,7 @@
       <module>server/rest</module>
       <module>client/hotrod-client</module>
       <module>rhq-plugin</module>
+      <module>upgrade-tools</module>
       <module>spring</module>
       <module>cli/cli-server</module>
       <module>cli/cli-client</module>",2012-10-02T06:13:46Z,568
"@@ -0,0 +1,42 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Copyright 2012 Red Hat, Inc. and/or its affiliates.
+  ~
+  ~ This is free software; you can redistribute it and/or modify it
+  ~ under the terms of the GNU Lesser General Public License as
+  ~ published by the Free Software Foundation; either version 2.1 of
+  ~ the License, or (at your option) any later version.
+  ~
+  ~ This software is distributed in the hope that it will be useful,
+  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
+  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  ~ Lesser General Public License for more details.
+  ~
+  ~ You should have received a copy of the GNU Lesser General Public
+  ~ License along with this library; if not, write to the Free Software
+  ~ Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+  ~ 02110-1301 USA
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+   <modelVersion>4.0.0</modelVersion>
+   <parent>
+      <groupId>org.infinispan</groupId>
+      <artifactId>infinispan-parent</artifactId>
+      <version>5.2.0-SNAPSHOT</version>
+      <relativePath>../parent/pom.xml</relativePath>
+   </parent>
+
+   <artifactId>upgrade-tools</artifactId>
+   <name>Infinispan Rolling Upgrade Tooling</name>
+
+   <dependencies>
+      <dependency>
+         <groupId>org.infinispan</groupId>
+         <artifactId>infinispan-client-hotrod</artifactId>
+         <version>5.2.0-SNAPSHOT</version>
+      </dependency>
+   </dependencies>
+</project>",2012-10-02T06:13:46Z,569
"@@ -0,0 +1,175 @@
+package org.infinispan.upgrade;
+
+import org.infinispan.client.hotrod.RemoteCacheManager;
+import org.infinispan.io.ByteBuffer;
+import org.infinispan.manager.CacheContainer;
+import org.infinispan.marshall.BufferSizePredictor;
+import org.infinispan.marshall.Marshaller;
+import org.infinispan.marshall.jboss.GenericJBossMarshaller;
+import org.infinispan.util.ByteArrayKey;
+import org.infinispan.util.FileLookup;
+import org.infinispan.util.FileLookupFactory;
+import org.infinispan.util.Util;
+
+import java.io.IOException;
+import java.io.UnsupportedEncodingException;
+import java.util.Properties;
+import java.util.Set;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.locks.LockSupport;
+
+/**
+ * // TODO: Document this
+ *
+ * @author Manik Surtani
+ * @since 5.1
+ */
+
+// TODO: make this accessible via JMX on the new cluster as well.  Not just via the command-line with a boat load of jars!
+public class RollingUpgradeSynchronizer {
+
+   private final Properties oldCluster;
+   private final Properties newCluster;
+   private final String cacheName;
+   private int threads;
+
+   public static void main(String[] args) throws UnsupportedEncodingException {
+      RollingUpgradeSynchronizer r = new RollingUpgradeSynchronizer(args);
+      r.start();
+   }
+
+   public RollingUpgradeSynchronizer(String[] args) {
+      if (args.length < 2)
+         helpAndExit();
+
+      String oldClusterCfg = args[0];
+      String newClusterCfg = args[1];
+
+      oldCluster = readProperties(oldClusterCfg);
+      newCluster = readProperties(newClusterCfg);
+
+      if (args.length >= 3)
+         cacheName = args[2];
+      else
+         cacheName = CacheContainer.DEFAULT_CACHE_NAME;
+
+      threads = Runtime.getRuntime().availableProcessors(); // default to the number of CPUs
+      if (args.length >= 4) {
+         try {
+            threads = Integer.parseInt(args[3]);
+         } catch (Exception e) {
+            System.out.printf(""  WARN: parameter %s should represent the nunber of threads to use, and be an integer. Using the default number of threads instead.%n"", args[3]);
+         }
+      }
+   }
+
+   private static void helpAndExit() {
+      System.out.println(""  Usage: RollingUpgradeSynchronizer <old cluster properties file> <new cluster properties file> <cache name> <num threads to use>"");
+      System.out.println();
+      System.out.println(""         The last two parameters are optional, defaulting to the default cache and number of processors, respectively."");
+      System.out.println();
+      System.exit(0);
+   }
+
+   private static Properties readProperties(String propsFile) {
+      try {
+         Properties p = new Properties();
+         FileLookup lookup = FileLookupFactory.newInstance();
+         p.load(lookup.lookupFile(propsFile, RollingUpgradeSynchronizer.class.getClassLoader()));
+         return p;
+      } catch (Exception e) {
+         System.out.printf(""  FATAL: Unable to load properties file %s!  Exiting!%n"", propsFile);
+         System.exit(-1);
+         return null;
+      }
+   }
+
+   private void start() {
+      long start = System.currentTimeMillis();
+      // TODO: Take in more parameters, e.g., port, etc., possibly via a config file.
+      // TODO: Should also take in a cache name, or even a set of cache names to migrate.
+      Marshaller m = new MigrationMarshaller();
+
+      RemoteCacheManager rcmOld = new RemoteCacheManager(m, oldCluster);
+      final RemoteCacheManager rcmNew = new RemoteCacheManager(m, newCluster);
+
+      Set<ByteArrayKey> keys = (Set<ByteArrayKey>) rcmOld.getCache(cacheName).get(""___MigrationManager_HotRod_KnownKeys___"");
+
+      System.out.printf("">> Retrieved %s keys stored in cache %s on the old cluster.%n"", keys.size(), cacheName);
+
+      ExecutorService es = Executors.newFixedThreadPool(threads);
+
+      final AtomicInteger count = new AtomicInteger(0);
+      for (final ByteArrayKey key: keys) {
+         es.submit(new Runnable() {
+            @Override
+            public void run() {
+               // the custom marshaller registered above will make sure this byte array is placed, verbatim, on the stream
+               rcmNew.getCache(cacheName).get(key.getData());
+               int i = count.get();
+               if (i % 100 == 0) System.out.printf("">>    Moved %s keys%n"", i);
+            }
+         });
+         count.getAndIncrement();
+      }
+
+      es.shutdown();
+      while (!es.isShutdown()) LockSupport.parkNanos(TimeUnit.NANOSECONDS.convert(100, TimeUnit.MILLISECONDS));
+      System.out.printf("">> Transferred %s entries in cache %s from the old cluster to the new, in %s%n"", keys.size(), cacheName, Util.prettyPrintTime(System.currentTimeMillis() - start));
+   }
+
+   private static class MigrationMarshaller implements Marshaller {
+
+      private final Marshaller delegate = new GenericJBossMarshaller();
+
+      @Override
+      public byte[] objectToByteBuffer(Object o, int i) throws IOException, InterruptedException {
+         if (o instanceof byte[])
+            return (byte[]) o;
+         else
+            return delegate.objectToByteBuffer(o, i);
+      }
+
+      @Override
+      public byte[] objectToByteBuffer(Object o) throws IOException, InterruptedException {
+         if (o instanceof byte[])
+            return (byte[]) o;
+         else
+            return delegate.objectToByteBuffer(o);
+      }
+
+      @Override
+      public Object objectFromByteBuffer(byte[] bytes) throws IOException, ClassNotFoundException {
+         return delegate.objectFromByteBuffer(bytes);
+      }
+
+      @Override
+      public Object objectFromByteBuffer(byte[] bytes, int i, int i1) throws IOException, ClassNotFoundException {
+         return delegate.objectFromByteBuffer(bytes, i, i1);
+      }
+
+      @Override
+      public ByteBuffer objectToBuffer(Object o) throws IOException, InterruptedException {
+         if (o instanceof byte[]) {
+            byte[] bytes = (byte[]) o;
+            return new ByteBuffer(bytes, 0, bytes.length);
+         } else {
+            return delegate.objectToBuffer(o);
+         }
+      }
+
+      @Override
+      public boolean isMarshallable(Object o) throws Exception {
+         return o instanceof byte[] || delegate.isMarshallable(o);
+      }
+
+      @Override
+      public BufferSizePredictor getBufferSizePredictor(Object o) {
+         return delegate.getBufferSizePredictor(o);
+      }
+   }
+}
+",2012-10-02T06:13:46Z,570
"@@ -38,7 +38,7 @@ public enum Attribute {
    DRIVER_CLASS(""driverClass""),
    DROP_ON_EXIT(""dropOnExit""),
    FETCH_SIZE(""fetchSize""),
-   KEY_TO_STRING_MAPPER(""keyToStringMapper""),
+   KEY_TO_STRING_MAPPER(""key2StringMapper""),
    NAME(""name""),
    PASSIVATION(""passivation""),
    PASSWORD(""password""),",2013-01-07T15:44:51Z,571
"@@ -86,7 +86,18 @@ private void parseStringKeyedJdbcStore(final XMLExtendedStreamReader reader,
          LoadersConfigurationBuilder loadersBuilder) throws XMLStreamException {
       JdbcStringBasedCacheStoreConfigurationBuilder builder = new JdbcStringBasedCacheStoreConfigurationBuilder(
             loadersBuilder);
-      parseCommonJdbcStoreAttributes(reader, builder);
+      for (int i = 0; i < reader.getAttributeCount(); i++) {
+         String value = replaceProperties(reader.getAttributeValue(i));
+         Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
+         switch (attribute) {
+         case KEY_TO_STRING_MAPPER:
+            builder.key2StringMapper(value);
+            break;
+         default:
+            Parser52.parseCommonStoreAttributes(reader, i, builder);
+            break;
+         }
+      }
       while (reader.hasNext() && (reader.nextTag() != XMLStreamConstants.END_ELEMENT)) {
          Element element = Element.forName(reader.getLocalName());
          switch (element) {
@@ -223,7 +234,18 @@ private void parseSimpleConnectionAttributes(XMLExtendedStreamReader reader,
    private void parseMixedKeyedJdbcStore(XMLExtendedStreamReader reader, LoadersConfigurationBuilder loadersBuilder)
          throws XMLStreamException {
       JdbcMixedCacheStoreConfigurationBuilder builder = new JdbcMixedCacheStoreConfigurationBuilder(loadersBuilder);
-      parseCommonJdbcStoreAttributes(reader, builder);
+      for (int i = 0; i < reader.getAttributeCount(); i++) {
+         String value = replaceProperties(reader.getAttributeValue(i));
+         Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
+         switch (attribute) {
+         case KEY_TO_STRING_MAPPER:
+            builder.key2StringMapper(value);
+            break;
+         default:
+            Parser52.parseCommonStoreAttributes(reader, i, builder);
+            break;
+         }
+      }
       while (reader.hasNext() && (reader.nextTag() != XMLStreamConstants.END_ELEMENT)) {
          Element element = Element.forName(reader.getLocalName());
          switch (element) {
@@ -244,7 +266,7 @@ private void parseMixedKeyedJdbcStore(XMLExtendedStreamReader reader, LoadersCon
       loadersBuilder.addStore(builder);
    }
 
-   private void parseTable(XMLExtendedStreamReader reader, TableManipulationConfigurationBuilder builder)
+   private void parseTable(XMLExtendedStreamReader reader, TableManipulationConfigurationBuilder<?, ?> builder)
          throws XMLStreamException {
       for (int i = 0; i < reader.getAttributeCount(); i++) {
          ParseUtils.requireNoNamespaceAttribute(reader, i);
@@ -279,7 +301,7 @@ private void parseTable(XMLExtendedStreamReader reader, TableManipulationConfigu
       parseTableElements(reader, builder);
    }
 
-   private void parseTableElements(XMLExtendedStreamReader reader, TableManipulationConfigurationBuilder builder)
+   private void parseTableElements(XMLExtendedStreamReader reader, TableManipulationConfigurationBuilder<?, ?> builder)
          throws XMLStreamException {
       while (reader.hasNext() && (reader.nextTag() != XMLStreamConstants.END_ELEMENT)) {
          Element element = Element.forName(reader.getLocalName());",2013-01-07T15:44:51Z,572
"@@ -34,7 +34,7 @@
             </xs:annotation>
           </xs:element>
         </xs:sequence>
-        <xs:attribute name=""keyToStringMapper"" type=""xs:string"">
+        <xs:attribute name=""key2StringMapper"" type=""xs:string"">
           <xs:annotation>
             <xs:documentation>
               The class name of a Key2StringMapper to use when mapping keys to strings to be used in the database tables
@@ -104,6 +104,13 @@
             </xs:annotation>
           </xs:element>
         </xs:sequence>
+        <xs:attribute name=""key2StringMapper"" type=""xs:string"">
+          <xs:annotation>
+            <xs:documentation>
+              The class name of a Key2StringMapper to use when mapping keys to strings to be used in the database tables
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
       </xs:extension>
     </xs:complexContent>
   </xs:complexType>
@@ -113,91 +120,85 @@
       <xs:extension base=""config:lockSupportStore"">
         <xs:sequence>
           <xs:choice minOccurs=""1"" maxOccurs=""1"">
-            <xs:element ref=""connectionPool"" />
-            <xs:element ref=""dataSource"" />
-            <xs:element ref=""singleConnection"" />
+            <xs:element name=""connectionPool"" type=""tns:connectionPool"" />
+            <xs:element name=""dataSource"" type=""tns:dataSource"" />
+            <xs:element name=""singleConnection"" type=""tns:singleConnection"" />
           </xs:choice>
         </xs:sequence>
       </xs:extension>
     </xs:complexContent>
   </xs:complexType>
   
   <xs:complexType name=""connectionPool"">
-    <xs:complexContent>
-      <xs:attribute name=""connectionUrl"" type=""xs:string"">
-          <xs:annotation>
-            <xs:documentation>
-              A JDBC driver-specific connection URL
-            </xs:documentation>
-          </xs:annotation>
-        </xs:attribute>
-        <xs:attribute name=""driverClass"" type=""xs:string"">
-          <xs:annotation>
-            <xs:documentation>
-              The class name of the driver used for connecting to the database.
-            </xs:documentation>
-          </xs:annotation>
-        </xs:attribute>
-        <xs:attribute name=""password"" type=""xs:string"">
-          <xs:annotation>
-            <xs:documentation>
-              The password to use when connecting via connectionUrl
-            </xs:documentation>
-          </xs:annotation>
-        </xs:attribute>
-        <xs:attribute name=""username"" type=""xs:string"">
-          <xs:annotation>
-            <xs:documentation>
-              The username to use when connecting via connectionUrl
-            </xs:documentation>
-          </xs:annotation>
-        </xs:attribute>
-    </xs:complexContent>
+    <xs:attribute name=""connectionUrl"" type=""xs:string"">
+        <xs:annotation>
+          <xs:documentation>
+            A JDBC driver-specific connection URL
+          </xs:documentation>
+        </xs:annotation>
+      </xs:attribute>
+      <xs:attribute name=""driverClass"" type=""xs:string"">
+        <xs:annotation>
+          <xs:documentation>
+            The class name of the driver used for connecting to the database.
+          </xs:documentation>
+        </xs:annotation>
+      </xs:attribute>
+      <xs:attribute name=""password"" type=""xs:string"">
+        <xs:annotation>
+          <xs:documentation>
+            The password to use when connecting via connectionUrl
+          </xs:documentation>
+        </xs:annotation>
+      </xs:attribute>
+      <xs:attribute name=""username"" type=""xs:string"">
+        <xs:annotation>
+          <xs:documentation>
+            The username to use when connecting via connectionUrl
+          </xs:documentation>
+        </xs:annotation>
+      </xs:attribute>
   </xs:complexType>
   
   <xs:complexType name=""dataSource"">
-    <xs:complexContent>
-      <xs:attribute name=""jndiUrl"" type=""xs:string"">
-          <xs:annotation>
-            <xs:documentation>
-              The address of a datasource to use when connecting
-            </xs:documentation>
-          </xs:annotation>
-        </xs:attribute>
-    </xs:complexContent>
+    <xs:attribute name=""jndiUrl"" type=""xs:string"">
+       <xs:annotation>
+         <xs:documentation>
+           The address of a datasource to use when connecting
+         </xs:documentation>
+       </xs:annotation>
+    </xs:attribute>
   </xs:complexType>
   
   <xs:complexType name=""singleConnection"">
-    <xs:complexContent>
-      <xs:attribute name=""connectionUrl"" type=""xs:string"">
-          <xs:annotation>
-            <xs:documentation>
-              A JDBC driver-specific connection URL
-            </xs:documentation>
-          </xs:annotation>
-        </xs:attribute>
-        <xs:attribute name=""driverClass"" type=""xs:string"">
-          <xs:annotation>
-            <xs:documentation>
-              The class name of the driver used for connecting to the database.
-            </xs:documentation>
-          </xs:annotation>
-        </xs:attribute>
-        <xs:attribute name=""password"" type=""xs:string"">
-          <xs:annotation>
-            <xs:documentation>
-              The password to use when connecting via connectionUrl
-            </xs:documentation>
-          </xs:annotation>
-        </xs:attribute>
-        <xs:attribute name=""username"" type=""xs:string"">
-          <xs:annotation>
-            <xs:documentation>
-              The username to use when connecting via connectionUrl
-            </xs:documentation>
-          </xs:annotation>
-        </xs:attribute>
-    </xs:complexContent>
+    <xs:attribute name=""connectionUrl"" type=""xs:string"">
+      <xs:annotation>
+        <xs:documentation>
+          A JDBC driver-specific connection URL
+        </xs:documentation>
+      </xs:annotation>
+      </xs:attribute>
+      <xs:attribute name=""driverClass"" type=""xs:string"">
+        <xs:annotation>
+          <xs:documentation>
+            The class name of the driver used for connecting to the database.
+          </xs:documentation>
+        </xs:annotation>
+      </xs:attribute>
+      <xs:attribute name=""password"" type=""xs:string"">
+        <xs:annotation>
+          <xs:documentation>
+            The password to use when connecting via connectionUrl
+          </xs:documentation>
+        </xs:annotation>
+      </xs:attribute>
+      <xs:attribute name=""username"" type=""xs:string"">
+        <xs:annotation>
+          <xs:documentation>
+            The username to use when connecting via connectionUrl
+          </xs:documentation>
+        </xs:annotation>
+     </xs:attribute>
   </xs:complexType>
 
   <xs:complexType name=""table"">",2013-01-07T15:44:51Z,573
"@@ -0,0 +1,25 @@
+/* 
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.jdbc.configuration;
+
+import org.infinispan.loaders.keymappers.DefaultTwoWayKey2StringMapper;
+
+public class DummyKey2StringMapper extends DefaultTwoWayKey2StringMapper {
+
+}",2013-01-07T15:44:51Z,574
"@@ -34,6 +34,7 @@
 import org.infinispan.test.fwk.TestCacheManagerFactory;
 import org.testng.annotations.AfterMethod;
 import org.testng.annotations.Test;
+import static org.testng.AssertJUnit.*;
 
 @Test(groups = ""unit"", testName = ""loaders.jdbc.configuration.XmlFileParsingTest"")
 public class XmlFileParsingTest extends AbstractInfinispanTest {
@@ -49,9 +50,9 @@ public void testStringKeyedJdbcStore() throws Exception {
       String config = INFINISPAN_START_TAG +
             ""   <default>\n"" +
             ""     <loaders>\n"" +
-            ""       <stringKeyedJdbcStore xmlns=\""urn:infinispan:config:jdbc:5.2\"" >\n"" +
+            ""       <stringKeyedJdbcStore xmlns=\""urn:infinispan:config:jdbc:5.2\"" key2StringMapper=\""org.infinispan.loaders.jdbc.configuration.DummyKey2StringMapper\"">\n"" +
             ""         <connectionPool connectionUrl=\""jdbc:h2:mem:infinispan;DB_CLOSE_DELAY=-1\"" username=\""dbuser\"" password=\""dbpass\"" />\n"" +
-            ""         <stringKeyedTable prefix=\""entry\"" fetchSize=\""34\"" batchSize=\""99\"">\n"" +
+            ""         <stringKeyedTable prefix=\""entry\"" fetchSize=\""34\"" batchSize=\""99\"" >\n"" +
             ""           <idColumn name=\""id\"" type=\""VARCHAR\"" />\n"" +
             ""           <dataColumn name=\""datum\"" type=\""BINARY\"" />\n"" +
             ""           <timestampColumn name=\""version\"" type=\""BIGINT\"" />\n"" +
@@ -63,11 +64,13 @@ public void testStringKeyedJdbcStore() throws Exception {
             TestingUtil.INFINISPAN_END_TAG;
 
       JdbcStringBasedCacheStoreConfiguration store = (JdbcStringBasedCacheStoreConfiguration) buildCacheManagerWithCacheStore(config);
-      assert store.table().batchSize() == 99;
-      assert store.table().fetchSize() == 34;
-      assert store.table().dataColumnType().equals(""BINARY"");
-      assert store.table().timestampColumnName().equals(""version"");
-      assert store.async().enabled();
+      assertEquals(99, store.table().batchSize());
+      assertEquals(34, store.table().fetchSize());
+      assertEquals(""BINARY"", store.table().dataColumnType());
+      assertEquals(""version"", store.table().timestampColumnName());
+      assertTrue(store.async().enabled());
+      assertEquals(""org.infinispan.loaders.jdbc.configuration.DummyKey2StringMapper"", store.key2StringMapper());
+
    }
 
    public void testBinaryKeyedJdbcStore() throws Exception {
@@ -88,21 +91,20 @@ public void testBinaryKeyedJdbcStore() throws Exception {
             TestingUtil.INFINISPAN_END_TAG;
 
       JdbcBinaryCacheStoreConfiguration store = (JdbcBinaryCacheStoreConfiguration) buildCacheManagerWithCacheStore(config);
-      assert store.ignoreModifications();
-      assert store.table().tableNamePrefix().equals(""bucket"");
-      assert store.table().batchSize() == 99;
-      assert store.table().fetchSize() == 34;
-      assert store.table().dataColumnType().equals(""BINARY"");
-      assert store.table().timestampColumnName().equals(""version"");
-      assert store.singletonStore().enabled();
-
+      assertTrue(store.ignoreModifications());
+      assertEquals(""bucket"", store.table().tableNamePrefix());
+      assertEquals(99, store.table().batchSize());
+      assertEquals(34, store.table().fetchSize());
+      assertEquals(""BINARY"", store.table().dataColumnType());
+      assertEquals(""version"", store.table().timestampColumnName());
+      assertTrue(store.singletonStore().enabled());
    }
 
    public void testMixedKeyedJdbcStore() throws Exception {
       String config = INFINISPAN_START_TAG +
             ""   <default>\n"" +
             ""     <loaders>\n"" +
-            ""       <mixedKeyedJdbcStore xmlns=\""urn:infinispan:config:jdbc:5.2\"" >\n"" +
+            ""       <mixedKeyedJdbcStore xmlns=\""urn:infinispan:config:jdbc:5.2\"" key2StringMapper=\""org.infinispan.loaders.jdbc.configuration.DummyKey2StringMapper\"">\n"" +
             ""         <dataSource jndiUrl=\""java:MyDataSource\"" />\n"" +
             ""         <stringKeyedTable prefix=\""entry\"" fetchSize=\""34\"" batchSize=\""99\"">\n"" +
             ""           <idColumn name=\""id\"" type=\""VARCHAR\"" />\n"" +
@@ -123,26 +125,27 @@ public void testMixedKeyedJdbcStore() throws Exception {
 
       JdbcMixedCacheStoreConfiguration store = (JdbcMixedCacheStoreConfiguration) buildCacheManagerWithCacheStore(config);
 
-      assert store.stringTable().tableNamePrefix().equals(""entry"");
-      assert store.stringTable().batchSize() == 99;
-      assert store.stringTable().fetchSize() == 34;
-      assert store.stringTable().dataColumnType().equals(""BINARY"");
-      assert store.stringTable().timestampColumnName().equals(""version"");
-
-      assert store.binaryTable().tableNamePrefix().equals(""bucket"");
-      assert store.binaryTable().batchSize() == 79;
-      assert store.binaryTable().fetchSize() == 44;
-      assert store.binaryTable().dataColumnType().equals(""BINARY"");
-      assert store.binaryTable().timestampColumnName().equals(""version"");
-
-      assert store.async().enabled();
-      assert store.singletonStore().enabled();
+      assertEquals(""entry"", store.stringTable().tableNamePrefix());
+      assertEquals(99, store.stringTable().batchSize());
+      assertEquals(34, store.stringTable().fetchSize());
+      assertEquals(""BINARY"", store.stringTable().dataColumnType());
+      assertEquals(""version"", store.stringTable().timestampColumnName());
+
+      assertEquals(""bucket"", store.binaryTable().tableNamePrefix());
+      assertEquals(79, store.binaryTable().batchSize());
+      assertEquals(44, store.binaryTable().fetchSize());
+      assertEquals(""BINARY"", store.binaryTable().dataColumnType());
+      assertEquals(""version"", store.binaryTable().timestampColumnName());
+
+      assertTrue(store.async().enabled());
+      assertTrue(store.singletonStore().enabled());
+      assertEquals(""org.infinispan.loaders.jdbc.configuration.DummyKey2StringMapper"", store.key2StringMapper());
    }
 
    private CacheLoaderConfiguration buildCacheManagerWithCacheStore(final String config) throws IOException {
       InputStream is = new ByteArrayInputStream(config.getBytes());
       cacheManager = TestCacheManagerFactory.fromStream(is);
-      assert cacheManager.getDefaultCacheConfiguration().loaders().cacheLoaders().size() == 1;
+      assertEquals(1, cacheManager.getDefaultCacheConfiguration().loaders().cacheLoaders().size());
       return cacheManager.getDefaultCacheConfiguration().loaders().cacheLoaders().get(0);
    }
 }
\ No newline at end of file",2013-01-07T15:44:51Z,409
"@@ -449,7 +449,13 @@ public void testModificationsOnSameCustomKey() {
       cache2.put(key, ""2"");
 
       // Deserialization only occurs when the cache2.put occurs, not during transport thread execution.
-      assertSerializationCounts(4, 1);
+      // Serialized 5 times:
+      //    twice when cache1 is stored, one to check if the type can be serialized, 2nd to replicate.
+      //    twice when cache1 is stored, one to check if the type can be serialized, 2nd to replicate.
+      //    the final time is when in the 1st node it compares the received
+      //    value and the one in the cache, whose comparison happens in
+      //    serialized mode since serializing is cheaper than deserializing.
+      assertSerializationCounts(5, 1);
    }
 
    public void testReturnValueDeserialization() { ",2013-01-08T16:54:46Z,551
"@@ -153,7 +153,7 @@
       <version.jclouds>1.4.1</version.jclouds>
       <version.jetty>6.1.25</version.jetty>
       <version.jgoodies.forms>1.0.5</version.jgoodies.forms>
-      <version.jgroups>3.2.5.Final</version.jgroups>
+      <version.jgroups>3.2.6.Final</version.jgroups>
       <version.jsap>2.1</version.jsap>
       <version.json>20090211</version.json>
       <version.jstl>1.2</version.jstl>",2013-01-17T22:26:27Z,152
"@@ -34,7 +34,7 @@
  *
  * @author Sanne Grinovero
  */
-@Test(groups = ""functional,unstable"", testName = ""query.distributed.MultiNodeDistributedTest"", description = ""See https://issues.jboss.org/browse/ISPN-4186"")
+@Test(groups = /*functional*/""unstable"", testName = ""query.distributed.MultiNodeDistributedTest"", description = ""Unstable, see https://issues.jboss.org/browse/ISPN-4186"")
 public class MultiNodeDistributedTest extends AbstractInfinispanTest {
 
    protected List<EmbeddedCacheManager> cacheManagers = new ArrayList<EmbeddedCacheManager>(4);",2014-04-16T13:49:15Z,8
"@@ -11,7 +11,7 @@
 /**
  * Tests verifying that Mass Indexer works properly on Topology Aware nodes.
  */
-@Test(groups = ""functional,unstable"", testName = ""query.distributed.TopologyAwareDistMassIndexingTest"", description = ""Unstable, see https://issues.jboss.org/browse/ISPN-4012"")
+@Test(groups = /*functional*/""unstable"", testName = ""query.distributed.TopologyAwareDistMassIndexingTest"", description = ""Unstable, see https://issues.jboss.org/browse/ISPN-4012"")
 public class TopologyAwareDistMassIndexingTest extends DistributedMassIndexingTest {
 
    @Override",2014-04-16T13:49:15Z,357
"@@ -16,7 +16,7 @@
  *
  * @author Anna Manukyan
  */
-@Test(groups = ""functional"", testName = ""query.distributed.MultiNodeDistributedTxTest"")
+@Test(groups = ""unstable"", description = ""ISPN-4165"", testName = ""query.distributed.MultiNodeDistributedTxTest"")
 public class MultiNodeDistributedTxTest extends MultiNodeDistributedTest {
 
    protected boolean transactionsEnabled() {",2014-03-26T18:32:46Z,358
"@@ -473,6 +473,12 @@
                 </exclusion>
             </exclusions>
          </dependency>
+         <dependency>
+            <groupId>org.hibernate</groupId>
+            <artifactId>hibernate-search-infinispan</artifactId>
+            <version>${version.hibernate.search}</version>
+            <optional>true</optional>
+         </dependency>
          <dependency>
             <groupId>org.hibernate</groupId>
             <artifactId>hibernate-search-engine</artifactId>",2012-08-29T15:49:30Z,152
"@@ -53,6 +53,16 @@
          <artifactId>hibernate-search-engine</artifactId>
       </dependency>
 
+      <dependency>
+         <groupId>org.hibernate</groupId>
+         <artifactId>hibernate-search-infinispan</artifactId>
+      </dependency>
+
+      <dependency>
+         <groupId>${project.groupId}</groupId>
+         <artifactId>infinispan-lucene-directory</artifactId>
+      </dependency>
+
       <dependency>
          <groupId>org.apache.lucene</groupId>
          <artifactId>lucene-core</artifactId>",2012-08-29T15:49:30Z,254
"@@ -28,6 +28,7 @@
 import org.infinispan.commands.module.ExtendedModuleCommandFactory;
 import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.query.clustered.ClusteredQueryCommand;
+import org.infinispan.query.indexmanager.IndexUpdateCommand;
 
 /**
 * Remote commands factory implementation
@@ -41,6 +42,7 @@ public class CommandFactory implements ExtendedModuleCommandFactory {
    public Map<Byte, Class<? extends ReplicableCommand>> getModuleCommands() {
       Map<Byte, Class<? extends ReplicableCommand>> map = new HashMap<Byte, Class<? extends ReplicableCommand>>(1);
       map.put(Byte.valueOf(ClusteredQueryCommand.COMMAND_ID), ClusteredQueryCommand.class);
+      map.put(Byte.valueOf(IndexUpdateCommand.COMMAND_ID), IndexUpdateCommand.class);
       return map;
    }
 
@@ -58,6 +60,9 @@ public CacheRpcCommand fromStream(byte commandId, Object[] args, String cacheNam
          case ClusteredQueryCommand.COMMAND_ID:
             c = new ClusteredQueryCommand(cacheName);
             break;
+         case IndexUpdateCommand.COMMAND_ID:
+            c = new IndexUpdateCommand(cacheName);
+            break;
          default:
             throw new IllegalArgumentException(""Not registered to handle command id "" + commandId);
       }",2012-08-29T15:49:30Z,359
"@@ -21,10 +21,14 @@
  */
 package org.infinispan.query;
 
+import org.hibernate.search.SearchFactory;
+import org.hibernate.search.engine.spi.SearchFactoryImplementor;
 import org.infinispan.Cache;
 import org.infinispan.commands.ReplicableCommand;
 import org.infinispan.commands.module.ModuleCommandInitializer;
+import org.infinispan.query.backend.QueryInterceptor;
 import org.infinispan.query.clustered.ClusteredQueryCommand;
+import org.infinispan.query.indexmanager.IndexUpdateCommand;
 
 /**
  * Initializes query module remote commands
@@ -35,16 +39,25 @@
 public class CommandInitializer implements ModuleCommandInitializer {
 
    private Cache<?, ?> cache;
+   private SearchFactoryImplementor searchFactoryImplementor;
+   private QueryInterceptor queryInterceptor;
    
    public void setCache(Cache<?, ?> cache){
       this.cache = cache;
+      SearchManager searchManager = Search.getSearchManager(cache);
+      SearchFactory searchFactory = searchManager.getSearchFactory();
+      searchFactoryImplementor = (SearchFactoryImplementor) searchFactory;
+      queryInterceptor = cache.getAdvancedCache().getComponentRegistry().getComponent(QueryInterceptor.class);
    }
    
    @Override
    public void initializeReplicableCommand(ReplicableCommand c, boolean isRemote) {
       if (c instanceof ClusteredQueryCommand){
           ((ClusteredQueryCommand) c).injectComponents(cache);
       }
+      else if (c instanceof IndexUpdateCommand) {
+         ((IndexUpdateCommand) c).injectComponents(searchFactoryImplementor, queryInterceptor);
+      }
    }
 
 }",2012-08-29T15:49:30Z,360
"@@ -29,4 +29,6 @@ public interface ModuleCommandIds {
 
    public static final byte CLUSTERED_QUERY = 101;
 
+   public static final byte UPDATE_INDEX = 102;
+
 }",2012-08-29T15:49:30Z,361
"@@ -0,0 +1,57 @@
+/* 
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.query.backend;
+
+import java.util.Properties;
+
+import org.hibernate.search.spi.BuildContext;
+import org.hibernate.search.spi.ServiceProvider;
+import org.infinispan.factories.ComponentRegistry;
+
+/**
+ * Simple wrapper to make the Cache ComponentRegistry available to the services managed by
+ * Hibernate Search
+ * 
+ * @author Sanne Grinovero
+ * @since 5.2
+ */
+public final class ComponentRegistryServiceProvider implements ServiceProvider<ComponentRegistry> {
+
+   private final ComponentRegistry cr;
+
+   public ComponentRegistryServiceProvider(ComponentRegistry cr) {
+      this.cr = cr;
+   }
+
+   @Override
+   public void start(Properties properties, BuildContext context) {
+      // no-op
+   }
+
+   @Override
+   public ComponentRegistry getService() {
+      return cr;
+   }
+
+   @Override
+   public void stop() {
+      // no-op
+   }
+
+}",2012-08-29T15:49:30Z,362
"@@ -256,13 +256,8 @@ private void enableClassesIncrementally(Class<?>[] classes, boolean locked) {
          return;
       }
       if (locked) {
-         Set<Class<?>> existingClasses = knownClasses.keySet();
-         int index = existingClasses.size();
-         Class<?>[] all = existingClasses.toArray(new Class[existingClasses.size()+toAdd.size()]);
-         for (Class<?> toAddClass : toAdd) {
-            all[index++] = toAddClass;
-         }
-         searchFactory.addClasses(all);
+         Class[] array = toAdd.toArray(new Class[toAdd.size()]);
+         searchFactory.addClasses(array);
          for (Class<?> type : toAdd) {
             if (searchFactory.getIndexBindingForEntity(type) != null) {
                knownClasses.put(type, Boolean.TRUE);
@@ -311,4 +306,9 @@ private String keyToString(Object key) {
    public KeyTransformationHandler getKeyTransformationHandler() {
       return keyTransformationHandler;
    }
+
+   public void enableClasses(Set<Class> knownIndexedTypes) {
+      Class[] classes = knownIndexedTypes.toArray(new Class[knownIndexedTypes.size()]);
+      enableClasses(classes);
+   }
 }",2012-08-29T15:49:30Z,363
"@@ -28,7 +28,10 @@
 import org.hibernate.search.cfg.spi.SearchConfiguration;
 import org.hibernate.search.cfg.spi.SearchConfigurationBase;
 import org.hibernate.search.impl.SearchMappingBuilder;
+import org.hibernate.search.infinispan.CacheManagerServiceProvider;
 import org.hibernate.search.spi.ServiceProvider;
+import org.infinispan.factories.ComponentRegistry;
+import org.infinispan.manager.EmbeddedCacheManager;
 
 import java.util.Collections;
 import java.util.HashMap;
@@ -49,8 +52,10 @@ public class SearchableCacheConfiguration extends SearchConfigurationBase implem
    private final Map<String, Class<?>> classes;
    private final Properties properties;
    private final SearchMapping searchMapping;
+   private final Map<Class<? extends ServiceProvider<?>>, Object> providedServices;
 
-   public SearchableCacheConfiguration(Class<?>[] classArray, Properties properties) {
+   public SearchableCacheConfiguration(Class<?>[] classArray, Properties properties, EmbeddedCacheManager uninitializedCacheManager, ComponentRegistry cr) {
+      this.providedServices = initializeProvidedServices(uninitializedCacheManager, cr);
       if (properties == null) {
          this.properties = new Properties();
       }
@@ -78,6 +83,14 @@ public SearchableCacheConfiguration(Class<?>[] classArray, Properties properties
       }
    }
 
+   private static Map<Class<? extends ServiceProvider<?>>, Object> initializeProvidedServices(EmbeddedCacheManager uninitializedCacheManager, ComponentRegistry cr) {
+      //Register the SelfLoopedCacheManagerServiceProvider to allow custom IndexManagers to access the CacheManager
+      HashMap map = new HashMap(2);
+      map.put(CacheManagerServiceProvider.class, uninitializedCacheManager);
+      map.put(ComponentRegistryServiceProvider.class, cr);
+      return Collections.unmodifiableMap(map);
+   }
+
    @Override
    public Iterator<Class<?>> getClassMappings() {
       return classes.values().iterator();
@@ -110,7 +123,7 @@ public SearchMapping getProgrammaticMapping() {
 
    @Override
    public Map<Class<? extends ServiceProvider<?>>, Object> getProvidedServices() {
-      return Collections.emptyMap();
+      return providedServices;
    }
 
    @Override",2012-08-29T15:49:30Z,364
"@@ -34,12 +34,14 @@
 import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.configuration.cache.InterceptorConfigurationBuilder;
 import org.infinispan.factories.ComponentRegistry;
+import org.infinispan.factories.GlobalComponentRegistry;
 import org.infinispan.interceptors.InterceptorChain;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.interceptors.locking.NonTransactionalLockingInterceptor;
 import org.infinispan.interceptors.locking.OptimisticLockingInterceptor;
 import org.infinispan.interceptors.locking.PessimisticLockingInterceptor;
 import org.infinispan.lifecycle.AbstractModuleLifecycle;
+import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.query.CommandInitializer;
 import org.infinispan.query.backend.LocalQueryInterceptor;
 import org.infinispan.query.backend.QueryInterceptor;
@@ -148,8 +150,10 @@ private SearchFactoryIntegrator getSearchFactory(Properties indexingProperties,
        SearchFactoryIntegrator searchFactory = cr.getComponent(SearchFactoryIntegrator.class);
        //defend against multiple initialization:
        if (searchFactory==null) {
+          GlobalComponentRegistry globalComponentRegistry = cr.getGlobalComponentRegistry();
+          EmbeddedCacheManager uninitializedCacheManager = globalComponentRegistry.getComponent(EmbeddedCacheManager.class);
           // Set up the search factory for Hibernate Search first.
-          SearchConfiguration config = new SearchableCacheConfiguration(new Class[0], indexingProperties);
+          SearchConfiguration config = new SearchableCacheConfiguration(new Class[0], indexingProperties, uninitializedCacheManager, cr);
           searchFactory = new SearchFactoryBuilder().configuration(config).buildSearchFactory();
           cr.registerComponent(searchFactory, SearchFactoryIntegrator.class);
        }",2012-08-29T15:49:30Z,353
"@@ -0,0 +1,117 @@
+/* 
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.query.indexmanager;
+
+import java.util.List;
+import java.util.Set;
+
+import org.hibernate.search.SearchException;
+import org.hibernate.search.backend.LuceneWork;
+import org.hibernate.search.engine.spi.SearchFactoryImplementor;
+import org.hibernate.search.indexes.spi.IndexManager;
+import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.commands.remote.BaseRpcCommand;
+import org.infinispan.context.InvocationContext;
+import org.infinispan.query.ModuleCommandIds;
+import org.infinispan.query.backend.QueryInterceptor;
+
+/**
+ * Custom RPC command containing an index update request for the
+ * Master IndexManager of a specific cache & index.
+ * 
+* @author Sanne Grinovero
+*/
+public class IndexUpdateCommand extends BaseRpcCommand implements ReplicableCommand {
+
+   public static final byte COMMAND_ID = ModuleCommandIds.UPDATE_INDEX;
+
+   private SearchFactoryImplementor searchFactory;
+
+   private byte[] serializedModel;
+
+   private String indexName;
+
+   private QueryInterceptor queryInterceptor;
+
+   /**
+    * Currently we need to ship this set as not all types
+    * might be known to the master node.
+    * TODO ISPN-2143
+    */
+   private Set<Class> knownIndexedTypes;
+
+   public IndexUpdateCommand(String cacheName) {
+      super(cacheName);
+   }
+
+   @Override
+   public Object perform(InvocationContext ctx) throws Throwable {
+      queryInterceptor.enableClasses(knownIndexedTypes);
+      IndexManager indexManager = searchFactory.getAllIndexesManager().getIndexManager(indexName);
+      if (indexManager == null) {
+         throw new SearchException(""Unknown index referenced"");
+      }
+      List<LuceneWork> luceneWorks = indexManager.getSerializer().toLuceneWorks(this.serializedModel);
+      indexManager.performOperations(luceneWorks, null);
+      return Boolean.TRUE; //Return value to be ignored
+   }
+
+   @Override
+   public byte getCommandId() {
+      return COMMAND_ID;
+   }
+
+   @Override
+   public Object[] getParameters() {
+      return new Object[]{ indexName, serializedModel, knownIndexedTypes };
+   }
+
+   @Override
+   public void setParameters(int commandId, Object[] parameters) {
+      this.indexName = (String) parameters[0];
+      this.serializedModel = (byte[]) parameters[1];
+      this.knownIndexedTypes = (Set<Class>) parameters[2];
+   }
+
+   @Override
+   public boolean isReturnValueExpected() {
+      return false;
+   }
+
+   /**
+    * This is invoked only on the receiving node, before {@link #perform(InvocationContext)}
+    */
+   public void injectComponents(SearchFactoryImplementor searchFactory, QueryInterceptor queryInterceptor) {
+      this.searchFactory = searchFactory;
+      this.queryInterceptor = queryInterceptor;
+   }
+
+   public void setSerializedWorkList(byte[] serializedModel) {
+      this.serializedModel = serializedModel;
+   }
+
+   public void setIndexName(String indexName) {
+      this.indexName = indexName;
+   }
+
+   public void setKnownIndexedTypes(Set<Class> knownIndexedTypes) {
+      this.knownIndexedTypes = knownIndexedTypes;
+   }
+
+}",2012-08-29T15:49:30Z,365
"@@ -0,0 +1,172 @@
+/* 
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.query.indexmanager;
+
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Properties;
+import java.util.Set;
+import java.util.concurrent.locks.Lock;
+
+import org.hibernate.search.backend.IndexingMonitor;
+import org.hibernate.search.backend.LuceneWork;
+import org.hibernate.search.backend.spi.BackendQueueProcessor;
+import org.hibernate.search.indexes.impl.DirectoryBasedIndexManager;
+import org.hibernate.search.infinispan.CacheManagerServiceProvider;
+import org.hibernate.search.spi.WorkerBuildContext;
+import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.distribution.DistributionManager;
+import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.factories.ComponentRegistry;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.query.backend.ComponentRegistryServiceProvider;
+import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.Transport;
+import org.infinispan.query.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+/**
+ * An Hibernate Search backend module tailored to delegate index writing to
+ * another node in the Infinispan cluster using custom remoting commands.
+ * 
+ * The master IndexWriter for each index is elected as a consistent hash
+ * on the index name. Index shards in Hibernate Search have different names,
+ * so this provides a primitive load balancing.
+ * 
+ * TODO Design a policy to deterministically try balance different shards of
+ * the same index on different nodes.
+ * 
+* @author Sanne Grinovero
+*/
+public class InfinispanCommandsBackend implements BackendQueueProcessor {
+
+   private static final Log log = LogFactory.getLog(InfinispanCommandsBackend.class, Log.class);
+
+   private EmbeddedCacheManager cacheManager;
+   private WorkerBuildContext context;
+   private String indexName;
+   private ConsistentHash hashService;
+   private RpcManager rpcManager;
+   private String cacheName;
+   private DirectoryBasedIndexManager indexManager;
+   private HashSet<Class> knownTypes = new HashSet<Class>(10);
+
+   @Override
+   public void initialize(Properties props, WorkerBuildContext context, DirectoryBasedIndexManager indexManager) {
+      this.context = context;
+      this.indexManager = indexManager;
+      this.cacheManager = context.requestService(CacheManagerServiceProvider.class);
+      final ComponentRegistry componentsRegistry = context.requestService(ComponentRegistryServiceProvider.class);
+      this.indexName = indexManager.getIndexName();
+      this.rpcManager = componentsRegistry.getComponent(RpcManager.class);
+      this.cacheName = componentsRegistry.getCacheName();
+      DistributionManager distributionManager = componentsRegistry.getComponent(DistributionManager.class);
+      if (distributionManager != null) {
+         hashService = distributionManager.getConsistentHash();
+      }
+      log.commandsBackendInitialized(indexName);
+   }
+
+   @Override
+   public void close() {
+      context.releaseService(CacheManagerServiceProvider.class);
+      context.releaseService(ComponentRegistryServiceProvider.class);
+      context = null;
+      cacheManager = null;
+   }
+
+   @Override
+   public void applyWork(List<LuceneWork> workList, IndexingMonitor monitor) {
+      IndexUpdateCommand command = new IndexUpdateCommand(cacheName);
+      //Use Search's custom Avro based serializer as it includes support for back/future compatibility
+      byte[] serializedModel = indexManager.getSerializer().toSerializedModel(workList);
+      command.setSerializedWorkList(serializedModel);
+      command.setKnownIndexedTypes(extractTypesUnique(workList));
+      command.setIndexName(this.indexName);
+      sendCommand(command, workList);
+   }
+
+   private Set<Class> extractTypesUnique(List<LuceneWork> workList) {
+      for (LuceneWork work : workList) {
+         Class<?> entityClass = work.getEntityClass();
+         if (entityClass != null) {
+            knownTypes.add(work.getEntityClass());
+         }
+      }
+      return knownTypes;
+   }
+
+   private void sendCommand(ReplicableCommand command, List<LuceneWork> workList) {
+      Address primaryNodeAddress = getPrimaryNodeAddress();
+      Collection<Address> recipients = Collections.singleton(primaryNodeAddress);
+      rpcManager.invokeRemotely(recipients, command, true);
+      log.workListRemotedTo(workList, primaryNodeAddress);
+   }
+
+   @Override
+   public void applyStreamWork(LuceneWork singleOperation, IndexingMonitor monitor) {
+      applyWork(Collections.singletonList(singleOperation), monitor);
+   }
+
+   @Override
+   public Lock getExclusiveWriteLock() {
+      throw new UnsupportedOperationException(""Not Implementable: nonsense on a distributed index."");
+   }
+
+   @Override
+   public void indexMappingChanged() {
+      //FIXME implement me? Not sure it's needed.
+   }
+
+   public boolean isMasterLocal() {
+      Transport transport = cacheManager.getTransport();
+      if (transport == null) {
+         return true;
+      }
+      else {
+         final Address primaryLocation = getPrimaryNodeAddress();
+         Address localAddress = transport.getAddress();
+         return localAddress.equals(primaryLocation);
+      }
+   }
+
+   /**
+    * Returns the primary node for this index, or null
+    * for non clustered configurations.
+    */
+   private Address getPrimaryNodeAddress() {
+      Transport transport = cacheManager.getTransport();
+      if (transport == null) {
+         return null;
+      }
+      if (hashService == null) { //If cache is configured as REPL
+         //TODO Make this decision making pluggable?
+         List<Address> members = transport.getMembers();
+         int elementIndex = (Math.abs(indexName.hashCode()) % members.size());
+         return members.get(elementIndex);
+      }
+      else { //If cache is configured as DIST
+         return hashService.primaryLocation(indexName);
+      }
+   }
+
+}",2012-08-29T15:49:30Z,366
"@@ -0,0 +1,67 @@
+/* 
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.query.indexmanager;
+
+import java.util.Properties;
+
+import org.hibernate.search.backend.BackendFactory;
+import org.hibernate.search.backend.spi.BackendQueueProcessor;
+import org.hibernate.search.indexes.impl.DirectoryBasedIndexManager;
+import org.hibernate.search.infinispan.impl.InfinispanDirectoryProvider;
+import org.hibernate.search.spi.WorkerBuildContext;
+import org.hibernate.search.store.DirectoryProvider;
+import org.infinispan.query.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+/**
+ * A custom IndexManager to store indexes in the grid itself.
+ * 
+ * @author Sanne Grinovero <sanne@hibernate.org> (C) 2012 Red Hat Inc.
+ */
+public class InfinispanIndexManager extends DirectoryBasedIndexManager {
+
+   private static final Log log = LogFactory.getLog(InfinispanIndexManager.class, Log.class);
+
+   private InfinispanCommandsBackend remoteMaster;
+
+   protected BackendQueueProcessor createBackend(String indexName, Properties cfg, WorkerBuildContext buildContext) {
+      BackendQueueProcessor localMaster = BackendFactory.createBackend(this, buildContext, cfg);
+      remoteMaster = new InfinispanCommandsBackend();
+      remoteMaster.initialize(cfg, buildContext, this);
+      //localMaster is already initialized by the BackendFactory
+      MasterSwitchDelegatingQueueProcessor joinedMaster = new MasterSwitchDelegatingQueueProcessor(localMaster, remoteMaster);
+      return joinedMaster;
+   }
+
+   protected DirectoryProvider createDirectoryProvider(String indexName, Properties cfg, WorkerBuildContext buildContext) {
+      //warn user we're overriding the configured DirectoryProvider - if anything different than Infinispan is selected.
+      String directoryOption = cfg.getProperty(""directory_provider"", null);
+      if (directoryOption != null && ! ""infinispan"".equals(directoryOption)) {
+         log.ignoreDirectoryProviderProperty(indexName, directoryOption);
+      }
+      InfinispanDirectoryProvider infinispanDP = new InfinispanDirectoryProvider();
+      infinispanDP.initialize(indexName, cfg, buildContext);
+      return infinispanDP;
+   }
+
+   public InfinispanCommandsBackend getRemoteMaster() {
+      return remoteMaster;
+   }
+
+}",2012-08-29T15:49:30Z,367
"@@ -0,0 +1,101 @@
+/* 
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.query.indexmanager;
+
+import java.util.List;
+import java.util.Properties;
+import java.util.concurrent.locks.Lock;
+
+import org.hibernate.search.backend.IndexingMonitor;
+import org.hibernate.search.backend.LuceneWork;
+import org.hibernate.search.backend.spi.BackendQueueProcessor;
+import org.hibernate.search.indexes.impl.DirectoryBasedIndexManager;
+import org.hibernate.search.spi.WorkerBuildContext;
+import org.infinispan.query.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+/**
+ * Switches between local indexing by delegating to a traditional BackendQueueProcessor
+ * or to the custom InfinispanCommandsBackend to delegate to remote nodes.
+ *
+ * @author Sanne Grinovero
+ */
+public class MasterSwitchDelegatingQueueProcessor implements BackendQueueProcessor {
+
+   private static final Log log = LogFactory.getLog(MasterSwitchDelegatingQueueProcessor.class, Log.class);
+
+   private final BackendQueueProcessor localMaster;
+   private final InfinispanCommandsBackend remoteMaster;
+
+   public MasterSwitchDelegatingQueueProcessor(BackendQueueProcessor localMaster, InfinispanCommandsBackend remoteMaster) {
+      this.localMaster = localMaster;
+      this.remoteMaster = remoteMaster;
+   }
+
+   @Override
+   public void initialize(Properties props, WorkerBuildContext context, DirectoryBasedIndexManager indexManager) {
+      localMaster.initialize(props, context, indexManager);
+      remoteMaster.initialize(props, context, indexManager);
+   }
+
+   @Override
+   public void close() {
+      remoteMaster.close();
+      localMaster.close();
+   }
+
+   @Override
+   public void applyWork(List<LuceneWork> workList, IndexingMonitor monitor) {
+      if (remoteMaster.isMasterLocal()) {
+         log.applyingChangeListLocally(workList);
+         localMaster.applyWork(workList, monitor);
+      }
+      else {
+         log.applyingChangeListRemotely(workList);
+         remoteMaster.applyWork(workList, monitor);
+      }
+   }
+
+   @Override
+   public void applyStreamWork(LuceneWork singleOperation, IndexingMonitor monitor) {
+      if (remoteMaster.isMasterLocal()) {
+         localMaster.applyStreamWork(singleOperation, monitor);
+      }
+      else {
+         remoteMaster.applyStreamWork(singleOperation, monitor);
+      }
+   }
+
+   @Override
+   public Lock getExclusiveWriteLock() {
+      //This is non-sense for the remote delegator, so we only acquire it on the local master queue.
+      //The lock is currently used only by org.hibernate.search.store.impl.FSMasterDirectoryProvider
+      //which should not be used with this backend anyway unless in very exotic architectures.
+      //TODO: even the FSMasterDirectoryProvider could be rewritten to not need such a lock.
+      return localMaster.getExclusiveWriteLock();
+   }
+
+   @Override
+   public void indexMappingChanged() {
+      //Needs to notify all backends, so they can all reconfigure themselves if needed.
+      remoteMaster.indexMappingChanged();
+      localMaster.indexMappingChanged();
+   }
+
+}",2012-08-29T15:49:30Z,368
"@@ -22,6 +22,10 @@
 
 package org.infinispan.query.logging;
 
+import java.util.List;
+
+import org.hibernate.search.backend.LuceneWork;
+import org.infinispan.remoting.transport.Address;
 import org.jboss.logging.Cause;
 import org.jboss.logging.LogMessage;
 import org.jboss.logging.Message;
@@ -34,6 +38,7 @@
  * ranging from 14001 to 15000 inclusively have been reserved.
  *
  * @author Galder Zamarreño
+ * @author Sanne Grinovero
  * @since 5.0
  */
 @MessageLogger(projectCode = ""ISPN"")
@@ -51,4 +56,25 @@ public interface Log extends org.infinispan.util.logging.Log {
    @Message(value = ""Registering Query interceptor"", id = 14003)
    void registeringQueryInterceptor();
 
+   @LogMessage(level = DEBUG)
+   @Message(value = ""Custom commands backend initialized backing index %s"", id = 14004)
+   void commandsBackendInitialized(String indexName);
+
+   @LogMessage(level = DEBUG)
+   @Message(value = ""Sent list of LuceneWork %s to node %s"", id = 14005)
+   void workListRemotedTo(Object workList, Address primaryNodeAddress);
+
+   @LogMessage(level = DEBUG)
+   @Message(value = ""Apply list of LuceneWork %s delegating to local indexing engine"", id = 14006)
+   void applyingChangeListLocally(List<LuceneWork> workList);
+
+   @LogMessage(level = DEBUG)
+   @Message(value = ""Going to ship list of LuceneWork %s to a remote master indexer"", id = 14007)
+   void applyingChangeListRemotely(List<LuceneWork> workList);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Index named '%1$s' is ignoring configuration option 'directory_provider' set '%2$s':"" +
+   		"" overriden to use the Infinispan Directory"", id = 14008)
+   void ignoreDirectoryProviderProperty(String indexName, String directoryOption);
+
 }",2012-08-29T15:49:30Z,369
"@@ -0,0 +1,140 @@
+/* 
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.query.distributed;
+
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+
+import javax.transaction.TransactionManager;
+
+import junit.framework.Assert;
+
+import org.apache.lucene.search.MatchAllDocsQuery;
+import org.hibernate.search.engine.spi.SearchFactoryImplementor;
+import org.infinispan.Cache;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.query.CacheQuery;
+import org.infinispan.query.Search;
+import org.infinispan.query.SearchManager;
+import org.infinispan.query.indexmanager.InfinispanCommandsBackend;
+import org.infinispan.query.indexmanager.InfinispanIndexManager;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.AbstractInfinispanTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.Test;
+
+/**
+ * Configures the Hibernate Search backend to use Infinispan custom commands as a backend
+ * transport, and a consistent hash for Master election for each index.
+ * The test changes the view several times while indexing and verifying index state.
+ * 
+ * @author Sanne Grinovero
+ */
+@Test(groups = ""functional"", testName = ""query.distributed.MultiNodeDistributedTest"")
+public class MultiNodeDistributedTest extends AbstractInfinispanTest {
+
+   private List<EmbeddedCacheManager> cacheManagers = new ArrayList<EmbeddedCacheManager>(4);
+   private List<Cache<String, Person>> caches = new ArrayList<Cache<String, Person>>(4);
+
+   protected EmbeddedCacheManager createCacheManager() throws IOException {
+      EmbeddedCacheManager cacheManager = TestCacheManagerFactory.fromXml(getConfigurationResourceName());
+      cacheManagers.add(cacheManager);
+      Cache<String, Person> cache = cacheManager.getCache();
+      caches.add(cache);
+      TestingUtil.waitForRehashToComplete(caches);
+      return cacheManager;
+   }
+
+   protected String getConfigurationResourceName() {
+      return ""dynamic-indexing-distribution.xml"";
+   }
+
+   private void storeOn(Cache<String, Person> cache, String key, Person person) throws Exception {
+      TransactionManager transactionManager = null;
+      transactionManager = cache.getAdvancedCache().getTransactionManager();
+      if (transactionsEnabled()) transactionManager.begin();
+      cache.put(key, person);
+      if (transactionsEnabled()) transactionManager.commit();
+   }
+
+   public void testIndexingWorkDistribution() throws Exception {
+      try {
+         createCacheManager();
+         createCacheManager();
+         assertIndexSize(0);
+         //depending on test run, the index master selection might pick either cache.
+         //We don't know which cache it picks, but we allow writing & searching on all.
+         storeOn(caches.get(0), ""k1"", new Person(""K. Firt"", ""Is not a character from the matrix"", 1));
+         assertIndexSize(1);
+         storeOn(caches.get(1), ""k2"", new Person(""K. Seycond"", ""Is a pilot"", 1));
+         assertIndexSize(2);
+         storeOn(caches.get(0), ""k3"", new Person(""K. Theerd"", ""Forgot the fundamental laws"", 1));
+         assertIndexSize(3);
+         storeOn(caches.get(1), ""k3"", new Person(""K. Overide"", ""Impersonating Mr. Theerd"", 1));
+         assertIndexSize(3);
+         createCacheManager();
+         storeOn(caches.get(2), ""k4"", new Person(""K. Forth"", ""Dynamic Topology!"", 1));
+         assertIndexSize(4);
+         createCacheManager();
+         assertIndexSize(4);
+         killMasterNode();
+         storeOn(caches.get(2), ""k5"", new Person(""K. Vife"", ""Failover!"", 1));
+         assertIndexSize(5);
+      }
+      finally {
+         TestingUtil.killCacheManagers(cacheManagers);
+      }
+   }
+
+   private void killMasterNode() {
+      for (Cache cache : caches) {
+         if (isMasterNode(cache)) {
+            TestingUtil.killCacheManagers(cache.getCacheManager());
+            caches.remove(cache);
+            cacheManagers.remove(cache.getCacheManager());
+            TestingUtil.waitForRehashToComplete(caches);
+            break;
+         }
+      }
+   }
+
+   private boolean isMasterNode(Cache cache) {
+      //Implicitly verifies the components are setup as configured by casting:
+      SearchManager searchManager = Search.getSearchManager(cache);
+      SearchFactoryImplementor searchFactory = (SearchFactoryImplementor) searchManager.getSearchFactory();
+      InfinispanIndexManager indexManager = (InfinispanIndexManager) searchFactory.getAllIndexesManager().getIndexManager(""person"");
+      InfinispanCommandsBackend commandsBackend = indexManager.getRemoteMaster();
+      return commandsBackend.isMasterLocal();
+   }
+
+   private void assertIndexSize(int expectedIndexSize) {
+      for (Cache cache : caches) {
+         SearchManager searchManager = Search.getSearchManager(cache);
+         CacheQuery query = searchManager.getQuery(new MatchAllDocsQuery(), Person.class);
+         Assert.assertEquals(expectedIndexSize, query.list().size());
+      }
+   }
+
+   private boolean transactionsEnabled() {
+      return false; //TODO extend this test using a Transactional configuration
+   }
+
+}",2012-08-29T15:49:30Z,8
"@@ -0,0 +1,37 @@
+/* 
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.query.distributed;
+
+import org.testng.annotations.Test;
+
+/**
+ * Similar to MultiNodeDistributedTest, but using a replicated configuration both for
+ * the indexed cache and for the storage of the index data.
+ * 
+ * @author Sanne Grinovero <sanne@hibernate.org> (C) 2012 Red Hat Inc.
+ */
+@Test(groups = ""functional"", testName = ""query.distributed.MultiNodeReplicatedTest"")
+public class MultiNodeReplicatedTest extends MultiNodeDistributedTest {
+
+   @Override
+   protected String getConfigurationResourceName() {
+      return ""dynamic-indexing-replication.xml"";
+   }
+
+}",2012-08-29T15:49:30Z,370
"@@ -0,0 +1,169 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ JBoss, Home of Professional Open Source
+  ~ Copyright 2012 Red Hat Inc. and/or its affiliates and other
+  ~ contributors as indicated by the @author tags. All rights reserved.
+  ~ See the copyright.txt in the distribution for a full listing of
+  ~ individual contributors.
+  ~
+  ~ This is free software; you can redistribute it and/or modify it
+  ~ under the terms of the GNU Lesser General Public License as
+  ~ published by the Free Software Foundation; either version 2.1 of
+  ~ the License, or (at your option) any later version.
+  ~
+  ~ This software is distributed in the hope that it will be useful,
+  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
+  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+  ~ Lesser General Public License for more details.
+  ~
+  ~ You should have received a copy of the GNU Lesser General Public
+  ~ License along with this software; if not, write to the Free
+  ~ Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+  ~ 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+  ~ 
+  ~ Author: Sanne Grinovero
+ -->
+<infinispan xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+    xsi:schemaLocation=""urn:infinispan:config:5.2 http://www.infinispan.org/schemas/infinispan-config-5.2.xsd""
+    xmlns=""urn:infinispan:config:5.2"">
+
+    <!-- *************************** -->
+    <!-- System-wide global settings -->
+    <!-- *************************** -->
+
+    <global>
+
+        <globalJmxStatistics
+            enabled=""true""
+            cacheManagerName=""QueryEnabledGrid-Dist""
+            allowDuplicateDomains=""true""
+            />
+
+        <!-- If the transport is omitted, there is no way to create distributed or clustered
+            caches. There is no added cost to defining a transport but not creating a cache that uses one,
+            since the transport is created and initialized lazily. -->
+        <transport
+            clusterName=""Infinispan-Query-Cluster""
+            >
+
+            <!-- Note that the JGroups transport uses sensible defaults if no configuration 
+                property is defined. See the JGroupsTransport javadocs for more flags -->
+        </transport>
+
+    </global>
+
+    <!-- *************************************** -->
+    <!--  Default Cache, with indexing enabled.  -->
+    <!-- *************************************** -->
+    <default>
+
+        <locking
+            lockAcquisitionTimeout=""20000""
+            writeSkewCheck=""false""
+            concurrencyLevel=""500""
+            useLockStriping=""false"" />
+
+        <!-- This element specifies that the cache is clustered. modes supported: distribution 
+            (d), replication (r) or invalidation (i). Don't use invalidation to store Lucene indexes (as 
+            with Hibernate Search DirectoryProvider). Replication is recommended for best performance of 
+            Lucene indexes, but make sure you have enough memory to store the index in your heap.
+            Also distribution scales much better than replication on high number of nodes in the cluster. -->
+        <clustering
+            mode=""distribution"">
+
+            <!-- Prefer loading all data at startup than later -->
+            <stateTransfer
+                timeout=""480000""
+                fetchInMemoryState=""true"" />
+
+            <!-- Network calls are synchronous by default -->
+            <sync
+                replTimeout=""20000"" />
+        </clustering>
+
+        <jmxStatistics
+            enabled=""true"" />
+
+        <eviction
+            maxEntries=""-1""
+            strategy=""NONE"" />
+
+        <expiration
+            maxIdle=""-1""
+            reaperEnabled=""false"" />
+
+        <indexing enabled=""true"" indexLocalOnly=""true"">
+            <properties>
+
+                <!-- Use our custom IndexManager; TODO autoinject by default? -->
+                <property name=""hibernate.search.default.indexmanager"" value=""org.infinispan.query.indexmanager.InfinispanIndexManager"" />
+
+                <!-- specify the managed index is to be shared across the nodes -->
+                <property name=""hibernate.search.default.directory_provider"" value=""infinispan"" />
+
+                <!-- Supporting exclusive index usage will require lock cleanup on crashed nodes to be implemented -->
+                <property name=""hibernate.search.default.exclusive_index_use"" value=""false"" />
+
+                <!-- Use latest Lucene version -->
+                <property name=""hibernate.search.lucene_version"" value=""LUCENE_36"" />
+            </properties>
+        </indexing>
+    </default>
+
+    
+    <!-- ******************************************************************************* -->
+    <!-- Individually configured ""named"" caches.                                         -->
+    <!--                                                                                 -->
+    <!-- While default configuration happens to be fine with similar settings across the -->
+    <!-- three caches, they should generally be different in a production environment.   -->
+    <!--                                                                                 -->
+    <!-- Current settings could easily lead to OutOfMemory exception as a CacheStore     -->
+    <!-- should be enabled, and maybe distribution is more suited for LuceneIndexesData. -->
+    <!-- ******************************************************************************* -->
+
+    <!-- *************************************** -->
+    <!--  Cache to store Lucene's file metadata  -->
+    <!-- *************************************** -->
+    <namedCache
+        name=""LuceneIndexesMetadata"">
+        <clustering
+            mode=""replication"">
+            <stateTransfer
+                fetchInMemoryState=""true"" />
+            <sync
+                replTimeout=""25000"" />
+        </clustering>
+        <indexing enabled=""false"" />
+    </namedCache>
+
+    <!-- **************************** -->
+    <!--  Cache to store Lucene data  -->
+    <!-- **************************** -->
+    <namedCache
+        name=""LuceneIndexesData"">
+        <clustering
+            mode=""distribution"">
+            <stateTransfer
+                fetchInMemoryState=""true"" />
+            <sync
+                replTimeout=""25000"" />
+        </clustering>
+        <indexing enabled=""false"" />
+    </namedCache>
+
+    <!-- ***************************** -->
+    <!--  Cache to store Lucene locks  -->
+    <!-- ***************************** -->
+    <namedCache
+        name=""LuceneIndexesLocking"">
+        <clustering
+            mode=""replication"">
+            <stateTransfer
+                fetchInMemoryState=""true"" />
+            <sync
+                replTimeout=""25000"" />
+        </clustering>
+        <indexing enabled=""false"" />
+    </namedCache>
+
+</infinispan>
\ No newline at end of file",2012-08-29T15:49:30Z,371
"@@ -0,0 +1,169 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ JBoss, Home of Professional Open Source
+  ~ Copyright 2012 Red Hat Inc. and/or its affiliates and other
+  ~ contributors as indicated by the @author tags. All rights reserved.
+  ~ See the copyright.txt in the distribution for a full listing of
+  ~ individual contributors.
+  ~
+  ~ This is free software; you can redistribute it and/or modify it
+  ~ under the terms of the GNU Lesser General Public License as
+  ~ published by the Free Software Foundation; either version 2.1 of
+  ~ the License, or (at your option) any later version.
+  ~
+  ~ This software is distributed in the hope that it will be useful,
+  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
+  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+  ~ Lesser General Public License for more details.
+  ~
+  ~ You should have received a copy of the GNU Lesser General Public
+  ~ License along with this software; if not, write to the Free
+  ~ Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+  ~ 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+  ~ 
+  ~ Author: Sanne Grinovero
+ -->
+<infinispan xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+    xsi:schemaLocation=""urn:infinispan:config:5.2 http://www.infinispan.org/schemas/infinispan-config-5.2.xsd""
+    xmlns=""urn:infinispan:config:5.2"">
+
+    <!-- *************************** -->
+    <!-- System-wide global settings -->
+    <!-- *************************** -->
+
+    <global>
+
+        <globalJmxStatistics
+            enabled=""true""
+            cacheManagerName=""QueryEnabledGrid-Repl""
+            allowDuplicateDomains=""true""
+            />
+
+        <!-- If the transport is omitted, there is no way to create distributed or clustered
+            caches. There is no added cost to defining a transport but not creating a cache that uses one,
+            since the transport is created and initialized lazily. -->
+        <transport
+            clusterName=""Infinispan-Query-Cluster""
+            >
+
+            <!-- Note that the JGroups transport uses sensible defaults if no configuration 
+                property is defined. See the JGroupsTransport javadocs for more flags -->
+        </transport>
+
+    </global>
+
+    <!-- *************************************** -->
+    <!--  Default Cache, with indexing enabled.  -->
+    <!-- *************************************** -->
+    <default>
+
+        <locking
+            lockAcquisitionTimeout=""20000""
+            writeSkewCheck=""false""
+            concurrencyLevel=""500""
+            useLockStriping=""false"" />
+
+        <!-- This element specifies that the cache is clustered. modes supported: distribution 
+            (d), replication (r) or invalidation (i). Don't use invalidation to store Lucene indexes (as 
+            with Hibernate Search DirectoryProvider). Replication is recommended for best performance of 
+            Lucene indexes, but make sure you have enough memory to store the index in your heap.
+            Also distribution scales much better than replication on high number of nodes in the cluster. -->
+        <clustering
+            mode=""replication"">
+
+            <!-- Prefer loading all data at startup than later -->
+            <stateTransfer
+                timeout=""480000""
+                fetchInMemoryState=""true"" />
+
+            <!-- Network calls are synchronous by default -->
+            <sync
+                replTimeout=""20000"" />
+        </clustering>
+
+        <jmxStatistics
+            enabled=""true"" />
+
+        <eviction
+            maxEntries=""-1""
+            strategy=""NONE"" />
+
+        <expiration
+            maxIdle=""-1""
+            reaperEnabled=""false"" />
+
+        <indexing enabled=""true"" indexLocalOnly=""true"">
+            <properties>
+
+                <!-- Use our custom IndexManager; TODO autoinject by default? -->
+                <property name=""hibernate.search.default.indexmanager"" value=""org.infinispan.query.indexmanager.InfinispanIndexManager"" />
+
+                <!-- specify the managed index is to be shared across the nodes -->
+                <property name=""hibernate.search.default.directory_provider"" value=""infinispan"" />
+
+                <!-- Supporting exclusive index usage will require lock cleanup on crashed nodes to be implemented -->
+                <property name=""hibernate.search.default.exclusive_index_use"" value=""false"" />
+
+                <!-- Use latest Lucene version -->
+                <property name=""hibernate.search.lucene_version"" value=""LUCENE_36"" />
+            </properties>
+        </indexing>
+    </default>
+
+    
+    <!-- ******************************************************************************* -->
+    <!-- Individually configured ""named"" caches.                                         -->
+    <!--                                                                                 -->
+    <!-- While default configuration happens to be fine with similar settings across the -->
+    <!-- three caches, they should generally be different in a production environment.   -->
+    <!--                                                                                 -->
+    <!-- Current settings could easily lead to OutOfMemory exception as a CacheStore     -->
+    <!-- should be enabled, and maybe distribution is more suited for LuceneIndexesData. -->
+    <!-- ******************************************************************************* -->
+
+    <!-- *************************************** -->
+    <!--  Cache to store Lucene's file metadata  -->
+    <!-- *************************************** -->
+    <namedCache
+        name=""LuceneIndexesMetadata"">
+        <clustering
+            mode=""replication"">
+            <stateTransfer
+                fetchInMemoryState=""true"" />
+            <sync
+                replTimeout=""25000"" />
+        </clustering>
+        <indexing enabled=""false"" />
+    </namedCache>
+
+    <!-- **************************** -->
+    <!--  Cache to store Lucene data  -->
+    <!-- **************************** -->
+    <namedCache
+        name=""LuceneIndexesData"">
+        <clustering
+            mode=""replication"">
+            <stateTransfer
+                fetchInMemoryState=""true"" />
+            <sync
+                replTimeout=""25000"" />
+        </clustering>
+        <indexing enabled=""false"" />
+    </namedCache>
+
+    <!-- ***************************** -->
+    <!--  Cache to store Lucene locks  -->
+    <!-- ***************************** -->
+    <namedCache
+        name=""LuceneIndexesLocking"">
+        <clustering
+            mode=""replication"">
+            <stateTransfer
+                fetchInMemoryState=""true"" />
+            <sync
+                replTimeout=""25000"" />
+        </clustering>
+        <indexing enabled=""false"" />
+    </namedCache>
+
+</infinispan>
\ No newline at end of file",2012-08-29T15:49:30Z,372
"@@ -294,10 +294,10 @@ private void doApplyState(Address sender, int segmentId, Collection<InternalCach
          log.tracef(""Received keys: %s"", keys);
       }
 
+      EnumSet<Flag> flags = EnumSet.of(IGNORE_RETURN_VALUES, SKIP_SHARED_CACHE_STORE, SKIP_LOCKING, SKIP_OWNERSHIP_CHECK, SKIP_XSITE_BACKUP);
       for (InternalCacheEntry e : cacheEntries) {
-         InvocationContext ctx = icc.createInvocationContext(false, 1);
+         InvocationContext ctx = icc.createRemoteInvocationContext(sender);
          // locking not necessary as during rehashing we block all transactions
-         EnumSet<Flag> flags = EnumSet.of(CACHE_MODE_LOCAL, IGNORE_RETURN_VALUES, SKIP_SHARED_CACHE_STORE, SKIP_LOCKING, SKIP_OWNERSHIP_CHECK, SKIP_XSITE_BACKUP);
          try {
             PutKeyValueCommand put = useVersionedPut ?
                   commandsFactory.buildVersionedPutKeyValueCommand(e.getKey(), e.getValue(), e.getLifespan(), e.getMaxIdle(), e.getVersion(), flags)",2012-10-02T13:40:12Z,54
"@@ -114,19 +114,20 @@ public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand
       // do the actual put first.
       Object toReturn = invokeNextInterceptor(ctx, command);
 
-      if (shouldModifyIndexes(command, ctx)) {
-         // First making a check to see if the key is already in the cache or not. If it isn't we can add the key no problem,
-         // otherwise we need to be updating the indexes as opposed to simply adding to the indexes.
-         getLog().debug(""Infinispan Query indexing is triggered"");
-         Object key = command.getKey();
-         Object value = extractValue(command.getValue());
+      // First making a check to see if the key is already in the cache or not. If it isn't we can add the key no problem,
+      // otherwise we need to be updating the indexes as opposed to simply adding to the indexes.
+      Object value = extractValue(command.getValue());
 
-         if (updateKnownTypesIfNeeded(value)) {
+      if (updateKnownTypesIfNeeded(value)) {
+         if (shouldModifyIndexes(command, ctx)) {
+            getLog().debug(""Infinispan Query indexing is triggered"");
             // This means that the entry is just modified so we need to update the indexes and not add to them.
-            updateIndexes(value, extractValue(key));
+            updateIndexes(value, extractValue(command.getKey()));
          }
-         else {
-            if (updateKnownTypesIfNeeded(toReturn)) {
+      }
+      else {
+         if (updateKnownTypesIfNeeded(toReturn)) {
+            if (shouldModifyIndexes(command, ctx)) {
                removeFromIndexes(toReturn, extractValue(command.getKey()));
             }
          }",2012-10-02T13:40:12Z,363
"@@ -0,0 +1,43 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.cacheloaders;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.cacheloaders.SharedCacheLoaderQueryDistributedIndexTest"", enabled = false,
+      description = ""Temporary disabled: https://issues.jboss.org/browse/ISPN-2249 , https://issues.jboss.org/browse/ISPN-1586"")
+public class SharedCacheLoaderQueryDistributedIndexTest extends SharedCacheLoaderQueryIndexTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      super.configureCache(builder);
+
+      builder.indexing().enable().indexLocalOnly(true)
+            .addProperty(""hibernate.search.default.directory_provider"", ""infinispan"")
+            .addProperty(""hibernate.search.default.indexmanager"", ""org.infinispan.query.indexmanager.InfinispanIndexManager"")
+            .addProperty(""hibernate.search.lucene_version"", ""LUCENE_36"")
+            .addProperty(""hibernate.search.default.exclusive_index_use"", ""false"");
+   }
+}",2012-10-02T13:40:12Z,373
"@@ -36,16 +36,15 @@
  * @since 5.2
  */
 @Test(groups = ""functional"", testName = ""query.cacheloaders.SharedCacheLoaderQueryIndexTest"", enabled = false,
-      description = ""Temporary disabled: https://issues.jboss.org/browse/ISPN-2249"")
+      description = ""Temporary disabled: https://issues.jboss.org/browse/ISPN-2249 , https://issues.jboss.org/browse/ISPN-1586"")
 public class SharedCacheLoaderQueryIndexTest extends BaseReIndexingTest {
 
    protected void configureCache(ConfigurationBuilder builder) {
       // To force a shared cache store, make sure storeName property
       // for dummy store is the same for all nodes
       builder.clustering().stateTransfer().fetchInMemoryState(false)
          .loaders().shared(true).preload(true).addStore()
-            .cacheStore(new DummyInMemoryCacheStore()).addProperty(""storeName"",
-            SharedCacheLoaderQueryIndexTest.class.getName());
+            .cacheStore(new DummyInMemoryCacheStore()).addProperty(""storeName"", getClass().getName());
    }
 
    public void testPreloadIndexingAfterAddingNewNode() throws Exception {
@@ -58,7 +57,7 @@ public void testPreloadIndexingAfterAddingNewNode() throws Exception {
          assert dimcs.stats().get(""clear"") == 0:
                ""Cache store should not be cleared, purgeOnStartup is false"";
          assert dimcs.stats().get(""store"") == 4:
-               ""Cache store should have been written to just once, but was written to "" + dimcs.stats().get(""store"") + "" times"";
+               ""Cache store should have been written to 4 times, but was written to "" + dimcs.stats().get(""store"") + "" times"";
       }
 
       // Before adding a node, verify that the query resolves properly",2012-10-02T13:40:12Z,7
"@@ -54,9 +54,7 @@ public abstract class BaseReIndexingTest extends MultipleCacheManagersTest {
    protected void createCacheManagers() throws Throwable {
       builder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, false);
 
-      // Explicitly disable fetching in-memory state in order
-      // to fetch it from the persistence layer
-      builder.indexing().enable().indexLocalOnly(true)
+      builder.indexing().enable().indexLocalOnly(false)
             .addProperty(""hibernate.search.default.directory_provider"", ""ram"")
             .addProperty(""hibernate.search.lucene_version"", ""LUCENE_CURRENT"");
 ",2012-10-02T13:40:12Z,51
"@@ -0,0 +1,42 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.PersistentStateTransferQueryDistributedIndexTest"")
+public class PersistentStateTransferQueryDistributedIndexTest extends PersistentStateTransferQueryIndexTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      super.configureCache(builder);
+
+      builder.indexing().enable().indexLocalOnly(true)
+            .addProperty(""hibernate.search.default.directory_provider"", ""infinispan"")
+            .addProperty(""hibernate.search.default.indexmanager"", ""org.infinispan.query.indexmanager.InfinispanIndexManager"")
+            .addProperty(""hibernate.search.lucene_version"", ""LUCENE_36"")
+            .addProperty(""hibernate.search.default.exclusive_index_use"", ""false"");
+   }
+}",2012-10-02T13:40:12Z,374
"@@ -44,6 +44,8 @@ public class PersistentStateTransferQueryIndexTest extends BaseReIndexingTest {
 
    @Override
    protected void configureCache(ConfigurationBuilder builder) {
+      // Explicitly disable fetching in-memory state in order
+      // to fetch it from the persistence layer
       builder.clustering().stateTransfer().fetchInMemoryState(false)
             .loaders().passivation(true).shared(false).addStore()
             .cacheStore(new DummyInMemoryCacheStore())",2012-10-02T13:40:12Z,52
"@@ -0,0 +1,42 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.testng.annotations.Test;
+
+/**
+ * @author anistor@redhat.com
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.StateTransferQueryIndexTest"")
+public class StateTransferQueryDistributedIndexTest extends StateTransferQueryIndexTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      super.configureCache(builder);
+
+      builder.indexing().enable().indexLocalOnly(true)
+            .addProperty(""hibernate.search.default.directory_provider"", ""infinispan"")
+            .addProperty(""hibernate.search.default.indexmanager"", ""org.infinispan.query.indexmanager.InfinispanIndexManager"")
+            .addProperty(""hibernate.search.lucene_version"", ""LUCENE_36"")
+            .addProperty(""hibernate.search.default.exclusive_index_use"", ""false"");
+   }
+}
\ No newline at end of file",2012-10-02T13:40:12Z,375
"@@ -26,7 +26,7 @@
 import org.infinispan.commons.api.BasicCacheContainer;
 import org.infinispan.commons.executors.ExecutorFactory;
 import org.infinispan.commons.marshall.Marshaller;
-import org.infinispan.commons.util.FileLookupFactory;
+import org.infinispan.commons.util.FileLookup;
 import org.infinispan.commons.util.TypedProperties;
 import org.infinispan.commons.util.Util;
 
@@ -356,7 +356,7 @@ public RemoteCacheManager(boolean start) {
       ConfigurationBuilder builder = new ConfigurationBuilder();
       ClassLoader cl = Thread.currentThread().getContextClassLoader();
       builder.classLoader(cl);
-      InputStream stream = FileLookupFactory.newInstance().lookupFile(HOTROD_CLIENT_PROPERTIES, cl);
+      InputStream stream = new FileLookup().lookupFile(HOTROD_CLIENT_PROPERTIES, cl);
       if (stream == null) {
          log.couldNotFindPropertiesFile(HOTROD_CLIENT_PROPERTIES);
       } else {",2014-04-23T15:01:10Z,192
"@@ -25,18 +25,12 @@ public class FileLookup {
     * @return an input stream to the file or null if nothing found through all lookup steps.
     */
    public InputStream lookupFile(String filename, ClassLoader cl) {
-      InputStream is = filename == null || filename.length() == 0 ? null : getAsInputStreamFromClassLoader(filename, cl);
-      if (is == null) {
-         if (log.isDebugEnabled())
-            log.debugf(""Unable to find file %s in classpath; searching for this file on the filesystem instead."", filename);
-         try {
-            is = new FileInputStream(filename);
-         }
-         catch (FileNotFoundException e) {
-            return null;
-         }
+      try {
+         return lookupFileStrict( filename, cl );
+      }
+      catch (FileNotFoundException e) {
+         return null;
       }
-      return is;
    }
 
    /**",2014-04-23T15:01:10Z,376
"@@ -19,148 +19,145 @@
  */
 public class OsgiClassLoader extends ClassLoader {
 
-	// TODO: Eventually, it would be better to limit this in scope to *only* what's needed, rather than all bundles
-	// in the container.
-	private final List<WeakReference<Bundle>> bundles;
-
-	private final Map<String, Class<?>> classCache = new HashMap<String, Class<?>>();
-	private final Map<String, URL> resourceCache = new HashMap<String, URL>();
-	
-	// TODO: For OSGi, this is *bad*.  But:
-	// The ctor currently loops through all Bundles in the BundleContext -- not a lightweight task.  But since most
-	// class/resource loading concepts get funneled through the static Util, this either needs to be
-	// singleton (bad) or on-demand (worse, imo).  Singleton will ""work"" for the time being, but it defeats ""dynamic""
-	// considerations within the container (ie, gracefully handling bundles being activated in the middle of runtime,
-	// etc.).  However, the rest of Infinispan isn't setup for that either.  So, this might be an acceptable baby step.
-	private static OsgiClassLoader instance = null;
-	public static OsgiClassLoader getInstance() {
-		if (instance == null) {
-			instance = new OsgiClassLoader();
-		}
-		return instance;
-	}
-
-	private OsgiClassLoader() {
-		// DO NOT use ClassLoader#parent, which is typically the SystemClassLoader for most containers. Instead,
-		// allow the ClassNotFoundException to be thrown. ClassLoaderServiceImpl will check the SystemClassLoader
-		// later on. This is especially important for embedded OSGi containers, etc.
-		super( null );
-		
-		final ClassLoader cl = OsgiClassLoader.class.getClassLoader();
-		if (cl instanceof BundleReference) {
-			final BundleContext bundleContext = ( (BundleReference) OsgiClassLoader.class.getClassLoader() ).getBundle()
-					.getBundleContext();
-			Bundle[] foundBundles = bundleContext.getBundles();
-			bundles = new ArrayList<WeakReference<Bundle>>(foundBundles.length);
-			for (Bundle foundBundle : foundBundles) {
-				bundles.add( new WeakReference<Bundle>(foundBundle) );
-			}
-		} else {
-			bundles = Collections.EMPTY_LIST;
-		}
-	}
-
-	/**
-	 * Load the class and break on first found match.  
-	 * 
-	 * TODO: Should this throw a different exception or warn if multiple
-	 * classes were found? Naming collisions can and do happen in OSGi...
-	 */
-	@Override
-	@SuppressWarnings(""rawtypes"")
-	protected Class<?> findClass(String name) throws ClassNotFoundException {
-		if ( classCache.containsKey( name ) ) {
-			return classCache.get( name );
-		}
-
-		for ( WeakReference<Bundle> bundle : bundles ) {
-			try {
-				final Class clazz = bundle.get().loadClass( name );
-				if ( clazz != null ) {
-					classCache.put( name, clazz );
-					return clazz;
-				}
-			}
-			catch (Exception ignore) {
-			}
-		}
-
-		throw new ClassNotFoundException( ""Could not load requested class : "" + name );
-	}
-
-	/**
-	 * Load the resource and break on first found match.
-	 * 
-	 * TODO: Should this throw a different exception or warn if multiple
-	 * resources were found? Naming collisions can and do happen in OSGi...
-	 */
-	@Override
-	protected URL findResource(String name) {
-		if ( resourceCache.containsKey( name ) ) {
-			return resourceCache.get( name );
-		}
-
-		for ( WeakReference<Bundle> bundle : bundles ) {
-			try {
-				final URL resource = bundle.get().getResource( name );
-				if ( resource != null ) {
-					resourceCache.put( name, resource );
-					return resource;
-				}
-			}
-			catch (Exception ignore) {
-			}
-		}
-
-		// TODO: Error?
-		return null;
-	}
-
-	/**
-	 * Load the resources and return an Enumeration
-	 * 
-	 * Note: Since they're Enumerations, do not cache these results!
-	 */
-	@Override
-	@SuppressWarnings(""unchecked"")
-	protected Enumeration<URL> findResources(String name) {
-		final List<Enumeration<URL>> enumerations = new ArrayList<Enumeration<URL>>();
-
-		for ( WeakReference<Bundle> bundle : bundles ) {
-			try {
-				final Enumeration<URL> resources = bundle.get().getResources( name );
-				if ( resources != null ) {
-					enumerations.add( resources );
-				}
-			}
-			catch (Exception ignore) {
-			}
-		}
-
-		final Enumeration<URL> aggEnumeration = new Enumeration<URL>() {
-
-			@Override
-			public boolean hasMoreElements() {
-				for ( Enumeration<URL> enumeration : enumerations ) {
-					if ( enumeration != null && enumeration.hasMoreElements() ) {
-						return true;
-					}
-				}
-				return false;
-			}
-
-			@Override
-			public URL nextElement() {
-				for ( Enumeration<URL> enumeration : enumerations ) {
-					if ( enumeration != null && enumeration.hasMoreElements() ) {
-						return enumeration.nextElement();
-					}
-				}
-				throw new NoSuchElementException();
-			}
-		};
-
-		return aggEnumeration;
-	}
+   // TODO: Eventually, it would be better to limit this in scope to *only* what's needed, rather than all bundles
+   // in the container.
+   private final List<WeakReference<Bundle>> bundles;
+
+   private final Map<String, Class<?>> classCache = new HashMap<String, Class<?>>();
+   private final Map<String, URL> resourceCache = new HashMap<String, URL>();
+
+   // TODO: For OSGi, this is *bad*.  But:
+   // The ctor currently loops through all Bundles in the BundleContext -- not a lightweight task.  But since most
+   // class/resource loading concepts get funneled through the static Util, this either needs to be
+   // singleton (bad) or on-demand (worse, imo).  Singleton will ""work"" for the time being, but it defeats ""dynamic""
+   // considerations within the container (ie, gracefully handling bundles being activated in the middle of runtime,
+   // etc.).  However, the rest of Infinispan isn't setup for that either.  So, this might be an acceptable baby step.
+   private static OsgiClassLoader instance = null;
+   public static OsgiClassLoader getInstance() {
+      if (instance == null) {
+         instance = new OsgiClassLoader();
+      }
+      return instance;
+   }
+
+   private OsgiClassLoader() {
+      // DO NOT use ClassLoader#parent, which is typically the SystemClassLoader for most containers. Instead,
+      // allow the ClassNotFoundException to be thrown. ClassLoaderServiceImpl will check the SystemClassLoader
+      // later on. This is especially important for embedded OSGi containers, etc.
+      super(null);
+
+      final ClassLoader cl = OsgiClassLoader.class.getClassLoader();
+      if (cl instanceof BundleReference) {
+         final BundleContext bundleContext = ((BundleReference) OsgiClassLoader.class.getClassLoader()).getBundle()
+               .getBundleContext();
+         Bundle[] foundBundles = bundleContext.getBundles();
+         bundles = new ArrayList<WeakReference<Bundle>>(foundBundles.length);
+         for (Bundle foundBundle : foundBundles) {
+            bundles.add(new WeakReference<Bundle>(foundBundle));
+         }
+      } else {
+         bundles = Collections.EMPTY_LIST;
+      }
+   }
+
+   /**
+    * Load the class and break on first found match.
+    * 
+    * TODO: Should this throw a different exception or warn if multiple classes were found? Naming
+    * collisions can and do happen in OSGi...
+    */
+   @Override
+   @SuppressWarnings(""rawtypes"")
+   protected Class<?> findClass(String name) throws ClassNotFoundException {
+      if (classCache.containsKey(name)) {
+         return classCache.get(name);
+      }
+
+      for (WeakReference<Bundle> bundle : bundles) {
+         try {
+            final Class clazz = bundle.get().loadClass(name);
+            if (clazz != null) {
+               classCache.put(name, clazz);
+               return clazz;
+            }
+         } catch (Exception ignore) {
+         }
+      }
+
+      throw new ClassNotFoundException(""Could not load requested class : "" + name);
+   }
+
+   /**
+    * Load the resource and break on first found match.
+    * 
+    * TODO: Should this throw a different exception or warn if multiple resources were found? Naming
+    * collisions can and do happen in OSGi...
+    */
+   @Override
+   protected URL findResource(String name) {
+      if (resourceCache.containsKey(name)) {
+         return resourceCache.get(name);
+      }
+
+      for (WeakReference<Bundle> bundle : bundles) {
+         try {
+            final URL resource = bundle.get().getResource(name);
+            if (resource != null) {
+               resourceCache.put(name, resource);
+               return resource;
+            }
+         } catch (Exception ignore) {
+         }
+      }
+
+      // TODO: Error?
+      return null;
+   }
+
+   /**
+    * Load the resources and return an Enumeration
+    * 
+    * Note: Since they're Enumerations, do not cache these results!
+    */
+   @Override
+   @SuppressWarnings(""unchecked"")
+   protected Enumeration<URL> findResources(String name) {
+      final List<Enumeration<URL>> enumerations = new ArrayList<Enumeration<URL>>();
+
+      for (WeakReference<Bundle> bundle : bundles) {
+         try {
+            final Enumeration<URL> resources = bundle.get().getResources(name);
+            if (resources != null) {
+               enumerations.add(resources);
+            }
+         } catch (Exception ignore) {
+         }
+      }
+
+      final Enumeration<URL> aggEnumeration = new Enumeration<URL>() {
+
+         @Override
+         public boolean hasMoreElements() {
+            for (Enumeration<URL> enumeration : enumerations) {
+               if (enumeration != null && enumeration.hasMoreElements()) {
+                  return true;
+               }
+            }
+            return false;
+         }
+
+         @Override
+         public URL nextElement() {
+            for (Enumeration<URL> enumeration : enumerations) {
+               if (enumeration != null && enumeration.hasMoreElements()) {
+                  return enumeration.nextElement();
+               }
+            }
+            throw new NoSuchElementException();
+         }
+      };
+
+      return aggEnumeration;
+   }
 
 }",2014-04-23T15:01:10Z,377
"@@ -137,61 +137,61 @@
             </plugin>
          </plugins>
       </pluginManagement>
-      <plugins>
-         <plugin>
-			<groupId>org.apache.felix</groupId>
-			<artifactId>maven-bundle-plugin</artifactId>
-			<configuration>
-				<instructions>
-					<Include-Resource>src/main/resources/infinispan-core-component-metadata.dat</Include-Resource>
-					<Export-Package>
-						!${project.groupId}.commons.*,
-						org.infinispan.marshall.core,
-						${project.groupId}.*;version=${project.version};-split-package:=error
-					</Export-Package>
-					<Import-Package>
-						javax.management,javax.naming,
-						javax.transaction;version=""[1.1,2)"",
-						javax.transaction.xa;version=""[1.1,2)"",
-						javax.xml.namespace,
-						javax.xml.parsers,
-						javax.xml.stream,
-						javax.xml.transform,
-						javax.xml.transform.dom,
-						javax.xml.transform.stream,
-						net.jcip.annotations;resolution:=optional,
-						org.infinispan.commons;version=""[6.0,7)"",
-						org.infinispan.commons.api;version=""[6.0,7)"",
-						org.infinispan.commons.configuration;version=""[6.0,7)"",
-						org.infinispan.commons.equivalence;version=""[6.0,7)"",
-						org.infinispan.commons.executors;version=""[6.0,7)"",
-						org.infinispan.commons.hash;version=""[6.0,7)"",
-						org.infinispan.commons.io;version=""[6.0,7)"",
-						org.infinispan.commons.marshall;version=""[6.0,7)"",
-						org.infinispan.commons.marshall.jboss;version=""[6.0,7)"",
-						org.infinispan.commons.util;version=""[6.0,7)"",
-						org.infinispan.commons.util.concurrent;version=""[6.0,7)"",
-						org.infinispan.commons.util.concurrent.jdk8backported;
-						version=""[6.0,7)"",org.jboss.logging;version=""[3.1,4)"",
-						org.jboss.marshalling;version=""[1.3,3)"",
-						org.jboss.marshalling.util;version=""[1.3,3)"",
-						org.jgroups;version=""[3.4,4)"",
-						org.jgroups.blocks;version=""[3.4,4)"",
-						org.jgroups.blocks.mux;version=""[3.4,4)"",
-						org.jgroups.jmx;version=""[3.4,4)"",
-						org.jgroups.logging;version=""[3.4,4)"",
-						org.jgroups.protocols;version=""[3.4,4)"",
-						org.jgroups.protocols.relay;version=""[3.4,4)"",
-						org.jgroups.protocols.tom;version=""[3.4,4)"",
-						org.jgroups.stack;version=""[3.4,4)"",
-						org.jgroups.util;version=""[3.4,4)"",
-						org.w3c.dom,
-						org.xml.sax
-					</Import-Package>
-				</instructions>
-			</configuration>
-		</plugin>
-      </plugins>
+		<plugins>
+			<plugin>
+				<groupId>org.apache.felix</groupId>
+				<artifactId>maven-bundle-plugin</artifactId>
+				<configuration>
+					<instructions>
+						<Include-Resource>src/main/resources/infinispan-core-component-metadata.dat</Include-Resource>
+						<Export-Package>
+							!${project.groupId}.commons.*,
+							org.infinispan.marshall.core,
+							${project.groupId}.*;version=${project.version};-split-package:=error
+						</Export-Package>
+						<Import-Package>
+							javax.management,javax.naming,
+							javax.transaction;version=""[1.1,2)"",
+							javax.transaction.xa;version=""[1.1,2)"",
+							javax.xml.namespace,
+							javax.xml.parsers,
+							javax.xml.stream,
+							javax.xml.transform,
+							javax.xml.transform.dom,
+							javax.xml.transform.stream,
+							net.jcip.annotations;resolution:=optional,
+							org.infinispan.commons;version=""[6.0,7)"",
+							org.infinispan.commons.api;version=""[6.0,7)"",
+							org.infinispan.commons.configuration;version=""[6.0,7)"",
+							org.infinispan.commons.equivalence;version=""[6.0,7)"",
+							org.infinispan.commons.executors;version=""[6.0,7)"",
+							org.infinispan.commons.hash;version=""[6.0,7)"",
+							org.infinispan.commons.io;version=""[6.0,7)"",
+							org.infinispan.commons.marshall;version=""[6.0,7)"",
+							org.infinispan.commons.marshall.jboss;version=""[6.0,7)"",
+							org.infinispan.commons.util;version=""[6.0,7)"",
+							org.infinispan.commons.util.concurrent;version=""[6.0,7)"",
+							org.infinispan.commons.util.concurrent.jdk8backported;
+							version=""[6.0,7)"",org.jboss.logging;version=""[3.1,4)"",
+							org.jboss.marshalling;version=""[1.3,3)"",
+							org.jboss.marshalling.util;version=""[1.3,3)"",
+							org.jgroups;version=""[3.4,4)"",
+							org.jgroups.blocks;version=""[3.4,4)"",
+							org.jgroups.blocks.mux;version=""[3.4,4)"",
+							org.jgroups.jmx;version=""[3.4,4)"",
+							org.jgroups.logging;version=""[3.4,4)"",
+							org.jgroups.protocols;version=""[3.4,4)"",
+							org.jgroups.protocols.relay;version=""[3.4,4)"",
+							org.jgroups.protocols.tom;version=""[3.4,4)"",
+							org.jgroups.stack;version=""[3.4,4)"",
+							org.jgroups.util;version=""[3.4,4)"",
+							org.w3c.dom,
+							org.xml.sax
+						</Import-Package>
+					</instructions>
+				</configuration>
+			</plugin>
+		</plugins>
    </build>
 
 </project>",2014-04-23T15:01:10Z,378
"@@ -5,6 +5,7 @@
 
 import org.infinispan.commons.configuration.Builder;
 import org.infinispan.commons.util.TypedProperties;
+import org.infinispan.commons.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -162,12 +163,7 @@ public void validate() {
          // Check that the query module is on the classpath.
          try {
             String clazz = ""org.infinispan.query.Search"";
-            // TODO
-//            ClassLoader classLoader = getBuilder().classLoader();
-//            if (classLoader == null)
-               Class.forName(clazz);
-//            else
-//               classLoader.loadClass(clazz);
+            Util.loadClassStrict( clazz, getClass().getClassLoader() );
          } catch (ClassNotFoundException e) {
             throw log.invalidConfigurationIndexingWithoutModule();
          }",2014-04-23T15:01:10Z,42
"@@ -1,14 +1,13 @@
 package org.infinispan.demo;
 
-import org.infinispan.manager.DefaultCacheManager;
-import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.commons.util.FileLookup;
-import org.infinispan.commons.util.FileLookupFactory;
-import org.infinispan.commons.util.Util;
-
 import java.io.IOException;
 import java.io.InputStream;
 
+import org.infinispan.commons.util.FileLookup;
+import org.infinispan.commons.util.Util;
+import org.infinispan.manager.DefaultCacheManager;
+import org.infinispan.manager.EmbeddedCacheManager;
+
 /**
  * Builds CacheManager given Infinispan configuration and transport file.
  */
@@ -25,7 +24,7 @@ public EmbeddedCacheManager getCacheManager() {
    }
 
    private String findConfigFile(String configFile) {
-      FileLookup fl = FileLookupFactory.newInstance();
+      FileLookup fl = new FileLookup();
       if (configFile != null) {
          InputStream inputStream = fl.lookupFile(configFile, Thread.currentThread().getContextClassLoader());
          try {",2014-04-23T15:01:10Z,379
"@@ -1,5 +1,8 @@
 package org.infinispan.jcache;
 
+import static org.infinispan.jcache.RIMBeanServerRegistrationUtility.ObjectNameType.CONFIGURATION;
+import static org.infinispan.jcache.RIMBeanServerRegistrationUtility.ObjectNameType.STATISTICS;
+
 import java.io.FileNotFoundException;
 import java.io.InputStream;
 import java.net.URI;
@@ -8,11 +11,13 @@
 import java.util.Properties;
 import java.util.Set;
 
-import javax.cache.*;
+import javax.cache.Cache;
+import javax.cache.CacheManager;
 import javax.cache.configuration.Configuration;
 import javax.cache.spi.CachingProvider;
 
 import org.infinispan.AdvancedCache;
+import org.infinispan.commons.util.FileLookup;
 import org.infinispan.commons.util.InfinispanCollections;
 import org.infinispan.commons.util.ReflectionUtil;
 import org.infinispan.configuration.global.GlobalConfigurationBuilder;
@@ -22,13 +27,8 @@
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.manager.DefaultCacheManager;
 import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.commons.util.FileLookup;
-import org.infinispan.commons.util.FileLookupFactory;
 import org.infinispan.util.logging.LogFactory;
 
-import static org.infinispan.jcache.RIMBeanServerRegistrationUtility.ObjectNameType.CONFIGURATION;
-import static org.infinispan.jcache.RIMBeanServerRegistrationUtility.ObjectNameType.STATISTICS;
-
 /**
  * Infinispan's implementation of {@link javax.cache.CacheManager}.
  *
@@ -136,7 +136,7 @@ private void registerPredefinedCaches() {
    private ConfigurationBuilderHolder getConfigurationBuilderHolder(
          ClassLoader classLoader) {
       try {
-         FileLookup fileLookup = FileLookupFactory.newInstance();
+         FileLookup fileLookup = new FileLookup();
          InputStream configurationStream = uri.isAbsolute()
                ? fileLookup.lookupFileStrict(uri, classLoader)
                : fileLookup.lookupFileStrict(uri.toString(), classLoader);",2014-04-23T15:01:10Z,380
"@@ -1,19 +1,20 @@
 package org.infinispan.persistence.jdbc.connectionfactory;
 
-import com.mchange.v2.c3p0.ComboPooledDataSource;
-import com.mchange.v2.c3p0.DataSources;
-import org.infinispan.persistence.spi.PersistenceException;
+import java.net.URL;
+import java.sql.Connection;
+import java.sql.SQLException;
+import java.util.Properties;
+
+import org.infinispan.commons.util.FileLookup;
 import org.infinispan.persistence.jdbc.JdbcUtil;
 import org.infinispan.persistence.jdbc.configuration.ConnectionFactoryConfiguration;
 import org.infinispan.persistence.jdbc.configuration.PooledConnectionFactoryConfiguration;
 import org.infinispan.persistence.jdbc.logging.Log;
-import org.infinispan.commons.util.FileLookupFactory;
+import org.infinispan.persistence.spi.PersistenceException;
 import org.infinispan.util.logging.LogFactory;
 
-import java.net.URL;
-import java.sql.Connection;
-import java.sql.SQLException;
-import java.util.Properties;
+import com.mchange.v2.c3p0.ComboPooledDataSource;
+import com.mchange.v2.c3p0.DataSources;
 
 /**
  * Pooled connection factory based on C3P0. For a complete configuration reference, look <a
@@ -63,8 +64,8 @@ public void start(ConnectionFactoryConfiguration config, ClassLoader classLoader
    }
 
    private void logFileOverride(ClassLoader classLoader) {
-      URL propsUrl = FileLookupFactory.newInstance().lookupFileLocation(""c3p0.properties"", classLoader);
-      URL xmlUrl = FileLookupFactory.newInstance().lookupFileLocation(""c3p0-config.xml"", classLoader);
+      URL propsUrl = new FileLookup().lookupFileLocation(""c3p0.properties"", classLoader);
+      URL xmlUrl = new FileLookup().lookupFileLocation(""c3p0-config.xml"", classLoader);
       if (log.isDebugEnabled() && propsUrl != null) {
          log.debugf(""Found 'c3p0.properties' in classpath: %s"", propsUrl);
       }",2014-04-23T15:01:10Z,381
"@@ -76,7 +76,7 @@ public void init(InitializationContext ctx) {
    public void start() throws PersistenceException {
       final Marshaller marshaller;
       if (configuration.marshaller() != null) {
-         marshaller = Util.getInstance(configuration.marshaller(), ctx.getCache().getCacheConfiguration().classLoader());
+         marshaller = Util.getInstance(configuration.marshaller(), ctx.getCache().getAdvancedCache().getClassLoader());
       } else if (configuration.hotRodWrapping()) {
          marshaller = new HotRodEntryMarshaller(ctx.getByteBufferFactory());
       } else if (configuration.rawValues()) {",2014-04-23T15:01:10Z,382
"@@ -1,9 +1,19 @@
 package org.infinispan.query.distributed;
 
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.ArrayList;
+import java.util.List;
+
+import javax.transaction.TransactionManager;
+
 import junit.framework.Assert;
+
 import org.apache.lucene.search.MatchAllDocsQuery;
 import org.hibernate.search.engine.spi.SearchFactoryImplementor;
 import org.infinispan.Cache;
+import org.infinispan.commons.util.FileLookup;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;
 import org.infinispan.configuration.parsing.ParserRegistry;
@@ -17,16 +27,8 @@
 import org.infinispan.test.AbstractInfinispanTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
-import org.infinispan.commons.util.FileLookupFactory;
 import org.testng.annotations.Test;
 
-import javax.transaction.TransactionManager;
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.io.InputStream;
-import java.util.ArrayList;
-import java.util.List;
-
 /**
  * Configures the Hibernate Search backend to use Infinispan custom commands as a backend
  * transport, and a consistent hash for Master election for each index.
@@ -125,7 +127,7 @@ protected boolean transactionsEnabled() {
    }
 
    protected ConfigurationBuilderHolder readFromXml() throws FileNotFoundException {
-      InputStream is = FileLookupFactory.newInstance().lookupFileStrict(
+      InputStream is = new FileLookup().lookupFileStrict(
             getConfigurationResourceName(), Thread.currentThread().getContextClassLoader());
       ParserRegistry parserRegistry = new ParserRegistry(Thread.currentThread().getContextClassLoader());
       ConfigurationBuilderHolder holder = parserRegistry.parse(is);",2014-04-23T15:01:10Z,8
"@@ -1,22 +1,23 @@
 package org.infinispan.query.jmx;
 
+import java.io.InputStream;
+
+import javax.management.MBeanServer;
+import javax.management.MalformedObjectNameException;
+import javax.management.ObjectName;
+
 import org.infinispan.Cache;
 import org.infinispan.commons.CacheException;
 import org.infinispan.commons.api.BasicCacheContainer;
+import org.infinispan.commons.util.FileLookup;
 import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;
 import org.infinispan.configuration.parsing.ParserRegistry;
 import org.infinispan.jmx.PerThreadMBeanServerLookup;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.query.distributed.DistributedMassIndexingTest;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
-import org.infinispan.commons.util.FileLookupFactory;
 import org.testng.annotations.Test;
 
-import javax.management.MBeanServer;
-import javax.management.MalformedObjectNameException;
-import javax.management.ObjectName;
-import java.io.InputStream;
-
 /**
  * Test reindexing happens when executed via JMX
  *
@@ -33,7 +34,7 @@ public class DistributedMassIndexingViaJmxTest extends DistributedMassIndexingTe
    protected void createCacheManagers() throws Throwable {
       server = PerThreadMBeanServerLookup.getThreadMBeanServer();
       for (int i = 0; i < NUM_NODES; i++) {
-         InputStream is = FileLookupFactory.newInstance().lookupFileStrict(
+         InputStream is = new FileLookup().lookupFileStrict(
                ""dynamic-indexing-distribution.xml"",
                Thread.currentThread().getContextClassLoader());
          ParserRegistry parserRegistry = new ParserRegistry(",2014-04-23T15:01:10Z,383
"@@ -64,13 +64,14 @@ protected EmbeddedCacheManager getCacheContainer() {
 
     @Override
     protected ConfigurationBuilder getConfigurationBuilder() {
-        if (this.moduleId != null) {
-            try {
-                builder.classLoader(this.dependencies.getModuleLoader().loadModule(this.moduleId).getClassLoader());
-            } catch (ModuleLoadException e) {
-                throw new IllegalArgumentException(e);
-            }
-        }
+       // TODO: Still needed?
+//        if (this.moduleId != null) {
+//            try {
+//                builder.classLoader(this.dependencies.getModuleLoader().loadModule(this.moduleId).getClassLoader());
+//            } catch (ModuleLoadException e) {
+//                throw new IllegalArgumentException(e);
+//            }
+//        }
         this.builder.jmxStatistics().enabled(this.dependencies.getCacheContainer().getCacheManagerConfiguration().globalJmxStatistics().enabled());
         TransactionManager tm = this.dependencies.getTransactionManager();
         if (tm != null) {",2014-04-23T15:01:10Z,384
"@@ -17,11 +17,12 @@
 @Test(groups = ""functional"", testName = ""query.blackbox.LocalCachePerformantConfTest"")
 public class LocalCachePerformantConfTest extends LocalCacheTest {
 
-   private final String indexDirectory = System.getProperty(""java.io.tmpdir"") + File.separator + ""tunedConfDir"";
+   /** the file constant needs to match what's defined in the configuration file **/
+   private final String indexDirectory = System.getProperty(""java.io.tmpdir"") + File.separator + ""LocalCachePerformantConfTest"";
 
    @Override
    protected EmbeddedCacheManager createCacheManager() throws Exception {
-      cacheManager = TestCacheManagerFactory.fromXml(""nrt-performance-writer.xml"");
+      cacheManager = TestCacheManagerFactory.fromXml(""testconfig-LocalCachePerformantConfTest.xml"");
       cache = cacheManager.getCache(""Indexed"");
 
       return cacheManager;",2014-02-11T16:02:54Z,385
"@@ -0,0 +1,103 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<infinispan xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+    xsi:schemaLocation=""urn:infinispan:config:6.0 http://www.infinispan.org/schemas/infinispan-config-6.0.xsd""
+    xmlns=""urn:infinispan:config:6.0"">
+
+    <!-- *************************** -->
+    <!-- System-wide global settings -->
+    <!-- *************************** -->
+
+    <global>
+        <globalJmxStatistics
+            enabled=""false""
+            cacheManagerName=""QueryEnabledGrid-Local-NRTIndexing""
+            allowDuplicateDomains=""true""
+            />
+    </global>
+
+    <!-- *************************************** -->
+    <!--  Default Cache                          -->
+    <!-- *************************************** -->
+    <default>
+
+        <jmxStatistics
+            enabled=""false"" />
+
+        <indexing
+            enabled=""false"" />
+
+        <eviction
+            maxEntries=""-1""
+            strategy=""NONE"" />
+
+        <expiration
+            maxIdle=""-1""
+            reaperEnabled=""false"" />
+
+    </default>
+
+    <!-- *************************************** -->
+    <!--  Tested Cache: indexing enabled         -->
+    <!-- *************************************** -->
+    <namedCache
+        name=""Indexed"">
+
+        <indexing enabled=""true"" indexLocalOnly=""false"">
+            <properties>
+
+                <!-- Enabled fastest writer: NRT backend -->
+                <property name=""default.indexmanager"" value=""near-real-time"" />
+                <property name=""default.indexBase"" value=""${java.io.tmpdir}/LocalCachePerformantConfTest"" />
+
+                <!-- Default is to write on FSDirectory; to write in a dedicated cache uncomment: -->
+                <!-- Write indexes in Infinispan
+                <property name=""default.directory_provider"" value=""infinispan"" />
+                <property name=""default.chunk_size"" value=""32000"" />
+                <property name=""default.metadata_cachename"" value=""LuceneIndexesMetadataOWR"" />
+                <property name=""default.data_cachename"" value=""LuceneIndexesDataOWR"" /> -->
+
+                <!-- This index is dedicated to the current node -->
+                <property name=""default.exclusive_index_use"" value=""true"" />
+
+                <!-- The default is 10, but we don't want to waste many cycles in merging
+                 (tune for writes at cost of reader fragmentation) -->
+                <property name=""default.indexwriter.merge_factor"" value=""30"" />
+
+                <!-- Never create segments larger than 4GB -->
+                <property name=""default.indexwriter.merge_max_size"" value=""4096"" />
+
+                <!-- IndexWriter flush buffer size in MB -->
+                <property name=""default.indexwriter.ram_buffer_size"" value=""220"" />
+
+                <!-- Make sure to use native locking -->
+                <property name=""default.locking_strategy"" value=""native"" />
+
+                <!-- Enable sharding on writers -->
+                <property name=""default.sharding_strategy.nbr_of_shards"" value=""6"" />
+
+                <!-- No need to be backwards compatible regarding Lucene version -->
+                <property name=""lucene_version"" value=""LUCENE_36"" />
+
+            </properties>
+        </indexing>
+
+        <!--  For our test we don't want to keep all data in memory: throw some away -->
+        <eviction
+            maxEntries=""200""
+            strategy=""LIRS"" />
+
+    </namedCache>
+
+    <!-- *************************************** -->
+    <!--  Cache to store Lucene's file metadata  -->
+    <!-- *************************************** -->
+    <namedCache
+        name=""LuceneIndexesMetadataOWR"" />
+
+    <!-- **************************** -->
+    <!--  Cache to store Lucene data  -->
+    <!-- **************************** -->
+    <namedCache
+        name=""LuceneIndexesDataOWR"" />
+
+</infinispan>
\ No newline at end of file",2014-02-11T16:02:54Z,386
"@@ -411,6 +411,31 @@ protected <K, V> List<Cache<K, V>> createClusteredCaches(int numMembersInCluster
       waitForClusterToForm();
       return caches;
    }
+   
+   /**
+    * Create cacheNames.lenght in each CacheManager (numMembersInCluster cacheManagers).
+    * 
+    * @param numMembersInCluster
+    * @param defaultConfigBuilder
+    * @param cacheNames
+    * @return A list with size numMembersInCluster containing a list of cacheNames.length caches
+    */
+   protected <K, V> List<List<Cache<K, V>>> createClusteredCaches(int numMembersInCluster,
+         ConfigurationBuilder defaultConfigBuilder, String[] cacheNames) {
+      List<List<Cache<K, V>>> allCaches = new ArrayList<List<Cache<K, V>>>(numMembersInCluster);
+      for (int i = 0; i < numMembersInCluster; i++) {
+         EmbeddedCacheManager cm = addClusterEnabledCacheManager(defaultConfigBuilder);
+         List<Cache<K, V>> currentCacheManagerCaches = new ArrayList<Cache<K, V>>(cacheNames.length);
+
+         for (String cacheName : cacheNames) {
+            Cache<K, V> cache = cm.getCache(cacheName);
+            currentCacheManagerCaches.add(cache);
+         }
+         allCaches.add(currentCacheManagerCaches);
+      }
+      waitForClusterToForm(cacheNames);
+      return allCaches;
+   }
 
    protected ReplListener replListener(Cache cache) {
       ReplListener listener = listeners.get(cache);",2013-04-11T08:28:17Z,387
"@@ -26,6 +26,7 @@
 import org.infinispan.Cache;
 import org.infinispan.commands.ReplicableCommand;
 import org.infinispan.commands.module.ModuleCommandInitializer;
+import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.query.backend.QueryInterceptor;
 import org.infinispan.query.impl.ComponentRegistryUtils;
 
@@ -41,8 +42,10 @@ public final class CommandInitializer implements ModuleCommandInitializer {
    private Cache<?, ?> cache;
    private SearchFactoryImplementor searchFactoryImplementor;
    private QueryInterceptor queryInterceptor;
+   private EmbeddedCacheManager cacheManager;
    
-   public void setCache(Cache<?, ?> cache){
+   public void setCache(Cache<?, ?> cache, EmbeddedCacheManager cacheManager){
+	   this.cacheManager = cacheManager;
       this.cache = cache;
       SearchManager searchManager = Search.getSearchManager(cache);
       SearchFactory searchFactory = searchManager.getSearchFactory();
@@ -58,16 +61,16 @@ public void initializeReplicableCommand(final ReplicableCommand c, final boolean
       queryCommand.fetchExecutionContext(this);
    }
 
-   public final Cache<?, ?> getCache() {
-      return cache;
-   }
-
    public final SearchFactoryImplementor getSearchFactory() {
       return searchFactoryImplementor;
    }
 
    public final QueryInterceptor getQueryInterceptor() {
       return queryInterceptor;
    }
+   
+   public EmbeddedCacheManager getCacheManager(){
+      return cacheManager;
+   }
 
 }",2013-04-11T08:28:17Z,360
"@@ -72,7 +72,7 @@ public ClusteredQueryCommand(String cacheName) {
 
    @Override
    public void fetchExecutionContext(CommandInitializer ci) {
-      this.cache = ci.getCache();
+      this.cache = ci.getCacheManager().getCache(cacheName);
    }
 
    public static ClusteredQueryCommand createLazyIterator(HSQuery query, Cache<?, ?> cache, UUID id) {",2013-04-11T08:28:17Z,388
"@@ -158,10 +158,12 @@ public void cacheStarted(ComponentRegistry cr, String cacheName) {
          throw new IllegalStateException( ""It was expected to find the Query interceptor registered in the InterceptorChain but it wasn't found"" );
       }
 
-      // initializing the query module command initializer. we can t inject Cache with @inject in there
+      // initializing the query module command initializer.
+      // we can t inject Cache and CacheManager with @inject in there
       Cache<?, ?> cache = cr.getComponent(Cache.class);
       CommandInitializer initializer = cr.getComponent(CommandInitializer.class);
-      initializer.setCache(cache);
+      EmbeddedCacheManager cacheManager = cr.getGlobalComponentRegistry().getComponent(EmbeddedCacheManager.class); 
+      initializer.setCache(cache, cacheManager);
 
       QueryBox queryBox = new QueryBox();
       queryBox.setCache(cache.getAdvancedCache());",2013-04-11T08:28:17Z,353
"@@ -0,0 +1,67 @@
+/* 
+ * JBoss, Home of Professional Open Source
+ * Copyright 2013 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.query.blackbox;
+
+import java.util.List;
+
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.query.test.Person;
+import org.testng.annotations.Test;
+
+/**
+ * Tests for testing clustered queries functionality on multiple cache instances
+ * (In these tests we have two caches in each CacheManager)
+ * 
+ * @author Israel Lacerra <israeldl@gmail.com>
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.blackbox.ClusteredQueryMultipleCachesTest"")
+public class ClusteredQueryMultipleCachesTest extends ClusteredQueryTest {
+
+   Cache<String, Person> cacheBMachine1, cacheBMachine2;
+   Person person5;
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      ConfigurationBuilder cacheCfg = getDefaultClusteredCacheConfig(getCacheMode(), false);
+      cacheCfg.indexing().enable().indexLocalOnly(true).addProperty(""default.directory_provider"", ""ram"")
+            .addProperty(""lucene_version"", ""LUCENE_CURRENT"");
+      enhanceConfig(cacheCfg);
+      String[] cacheNames = { ""cacheA"", ""cacheB"" };
+      List<List<Cache<String, Person>>> caches = createClusteredCaches(2, cacheCfg, cacheNames);
+      cacheAMachine1 = caches.get(0).get(0);
+      cacheAMachine2 = caches.get(1).get(0);
+      cacheBMachine1 = caches.get(0).get(1);
+      cacheBMachine2 = caches.get(1).get(1);
+   }
+
+   @Override
+   protected void prepareTestData() {
+      super.prepareTestData();
+
+      person5 = new Person();
+      person5.setName(""People In Another Cache"");
+      person5.setBlurb(""Also eats grass"");
+      person5.setAge(5);
+
+      cacheBMachine2.put(""anotherNewOne"", person5);
+   }
+
+}",2013-04-11T08:28:17Z,343
"@@ -50,7 +50,7 @@
 @Test(groups = ""functional"", testName = ""query.blackbox.ClusteredQueryTest"")
 public class ClusteredQueryTest extends MultipleCacheManagersTest {
 
-   Cache<String, Person> cache1, cache2;
+   Cache<String, Person> cacheAMachine1, cacheAMachine2;
    Person person1;
    Person person2;
    Person person3;
@@ -82,15 +82,15 @@ protected void createCacheManagers() throws Throwable {
             .addProperty(""lucene_version"", ""LUCENE_CURRENT"");
       enhanceConfig(cacheCfg);
       List<Cache<String, Person>> caches = createClusteredCaches(2, cacheCfg);
-      cache1 = caches.get(0);
-      cache2 = caches.get(1);
+      cacheAMachine1 = caches.get(0);
+      cacheAMachine2 = caches.get(1);
    }
 
    protected CacheMode getCacheMode() {
       return CacheMode.REPL_SYNC;
    }
 
-   private void prepareTestData() {
+   protected void prepareTestData() {
       person1 = new Person();
       person1.setName(""NavinSurtani"");
       person1.setBlurb(""Likes playing WoW"");
@@ -108,16 +108,16 @@ private void prepareTestData() {
 
       // Put the 3 created objects in the cache1.
 
-      cache2.put(key1, person1);
-      cache1.put(key2, person2);
-      cache1.put(key3, person3);
+      cacheAMachine2.put(key1, person1);
+      cacheAMachine1.put(key2, person2);
+      cacheAMachine1.put(key3, person3);
 
       person4 = new Person();
       person4.setName(""MightyGoat"");
       person4.setBlurb(""Also eats grass"");
       person4.setAge(66);
 
-      cache1.put(""newOne"", person4);
+      cacheAMachine1.put(""newOne"", person4);
    }
 
    public void testLazyOrdered() throws ParseException {
@@ -237,7 +237,7 @@ private void populateCache() throws ParseException {
       queries[1] = luceneQuery;
 
       luceneQuery = luceneQuery.combine(queries);
-      cacheQuery = Search.getSearchManager(cache1).getClusteredQuery(luceneQuery);
+      cacheQuery = Search.getSearchManager(cacheAMachine1).getClusteredQuery(luceneQuery);
    }
 
 }",2013-04-11T08:28:17Z,344
"@@ -47,9 +47,9 @@ protected void createCacheManagers() throws Throwable {
       for(Object cache : caches) {
          cacheManagers.add(((Cache) cache).getCacheManager());
       }
-
-      cache1 = (Cache<String, Person>) caches.get(0);
-      cache2 = (Cache<String, Person>) caches.get(1);
+      
+      cacheAMachine1 = (Cache<String, Person>) caches.get(0);
+      cacheAMachine2 = (Cache<String, Person>) caches.get(1);
 
       waitForClusterToForm();
    }",2013-04-11T08:28:17Z,389
"@@ -152,6 +152,7 @@ private Set<Class<? extends AbstractComponentFactory>> getHardcodedFactories() {
       s.add(DataContainerFactory.class);
       s.add(NamedExecutorsFactory.class);
       s.add(TransportFactory.class);
+      s.add(MarshallerFactory.class);
       return s;
    }
 ",2009-04-08T16:41:26Z,23
"@@ -5,30 +5,23 @@
 import org.infinispan.factories.annotations.DefaultFactoryFor;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
-import org.infinispan.marshall.Marshaller;
-import org.infinispan.marshall.VersionAwareMarshaller;
 import org.infinispan.notifications.cachemanagerlistener.CacheManagerNotifier;
 import org.infinispan.remoting.InboundInvocationHandler;
 
 /**
  * Factory for building global-scope components which have default empty constructors
  *
  * @author Manik Surtani
+ * @author <a href=""mailto:galder.zamarreno@jboss.com"">Galder Zamarreno</a>
  * @since 4.0
  */
-@DefaultFactoryFor(classes = {InboundInvocationHandler.class, CacheManagerNotifier.class, Marshaller.class, RemoteCommandFactory.class})
+@DefaultFactoryFor(classes = {InboundInvocationHandler.class, CacheManagerNotifier.class, RemoteCommandFactory.class})
 @Scope(Scopes.GLOBAL)
 public class EmptyConstructorFactory extends AbstractComponentFactory implements AutoInstantiableFactory {
    public <T> T construct(Class<T> componentType) {
       try {
          if (componentType.isInterface()) {
-            Class componentImpl;
-            if (componentType.equals(Marshaller.class)) {
-               componentImpl = VersionAwareMarshaller.class;
-            } else {
-               // add an ""Impl"" to the end of the class name and try again
-               componentImpl = getClass().getClassLoader().loadClass(componentType.getName() + ""Impl"");
-            }
+            Class componentImpl = getClass().getClassLoader().loadClass(componentType.getName() + ""Impl"");
             return componentType.cast(componentImpl.newInstance());
          } else {
             return componentType.newInstance();",2009-04-08T16:41:26Z,575
"@@ -0,0 +1,45 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2009, Red Hat Middleware LLC, and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.factories;
+
+import org.infinispan.config.ConfigurationException;
+import org.infinispan.factories.annotations.DefaultFactoryFor;
+import org.infinispan.marshall.Marshaller;
+import org.infinispan.util.Util;
+
+/**
+ * MarshallerFactory.
+ * 
+ * @author <a href=""mailto:galder.zamarreno@jboss.com"">Galder Zamarreno</a>
+ * @since 4.0
+ */
+@DefaultFactoryFor(classes = Marshaller.class)
+public class MarshallerFactory extends EmptyConstructorFactory implements AutoInstantiableFactory {   
+   @Override
+   public <T> T construct(Class<T> componentType) {
+      try {
+         return componentType.cast(Util.getInstance(globalConfiguration.getMarshallerClass()));
+      } catch (Exception e) {
+         throw new ConfigurationException(""Unable to create component "" + componentType, e);
+      }
+   }
+}",2009-04-08T16:41:26Z,576
"@@ -176,9 +176,31 @@ protected void readNewTopologyAndHash(Transport transport, AtomicInteger topolog
       int hashSpace = transport.readVInt();
       int clusterSize = transport.readVInt();
 
-      localLog.tracef(""Topology change request: newTopologyId=%d, numKeyOwners=%d, "" +
+      Map<SocketAddress, Set<Integer>> servers2Hash = computeNewHashes(
+            transport, localLog, newTopologyId, numKeyOwners,
+            hashFunctionVersion, hashSpace, clusterSize);
+
+      if (localLog.isInfoEnabled()) {
+         localLog.newTopology(transport.getRemoteSocketAddress(), newTopologyId,
+               servers2Hash.keySet());
+      }
+      transport.getTransportFactory().updateServers(servers2Hash.keySet());
+      if (hashFunctionVersion == 0) {
+         localLog.trace(""Not using a consistent hash function (hash function version == 0)."");
+      } else {
+         transport.getTransportFactory().updateHashFunction(
+               servers2Hash, numKeyOwners, hashFunctionVersion, hashSpace);
+      }
+   }
+
+   protected Map<SocketAddress, Set<Integer>> computeNewHashes(Transport transport,
+         Log localLog, int newTopologyId, int numKeyOwners,
+         short hashFunctionVersion, int hashSpace, int clusterSize) {
+      if (localLog.isTraceEnabled()) {
+         localLog.tracef(""Topology change request: newTopologyId=%d, numKeyOwners=%d, "" +
                        ""hashFunctionVersion=%d, hashSpaceSize=%d, clusterSize=%d"",
                  newTopologyId, numKeyOwners, hashFunctionVersion, hashSpace, clusterSize);
+      }
 
       Map<SocketAddress, Set<Integer>> servers2Hash = new LinkedHashMap<SocketAddress, Set<Integer>>();
 
@@ -196,16 +218,7 @@ protected void readNewTopologyAndHash(Transport transport, AtomicInteger topolog
          hashes.add(hashCode);
          localLog.tracef(""Hash code is: %d"", hashCode);
       }
-
-      if (localLog.isInfoEnabled()) {
-         localLog.newTopology(servers2Hash.keySet());
-      }
-      transport.getTransportFactory().updateServers(servers2Hash.keySet());
-      if (hashFunctionVersion == 0) {
-         localLog.trace(""Not using a consistent hash function (hash function version == 0)."");
-      } else {
-         transport.getTransportFactory().updateHashFunction(servers2Hash, numKeyOwners, hashFunctionVersion, hashSpace);
-      }
+      return servers2Hash;
    }
 
 }",2012-05-11T20:13:51Z,577
"@@ -48,55 +48,43 @@ public HeaderParams writeHeader(Transport transport, HeaderParams params) {
    }
 
    @Override
-   protected void readNewTopologyAndHash(Transport transport, AtomicInteger topologyId) {
-      final Log localLog = getLog();
-      int newTopologyId = transport.readVInt();
-      topologyId.set(newTopologyId);
-      int numKeyOwners = transport.readUnsignedShort();
-      short hashFctVersion = transport.readByte();
-      ConsistentHash ch = null;
-      if (hashFctVersion != 0)
-         ch = transport.getTransportFactory().getConsistentHashFactory()
-               .newConsistentHash(hashFctVersion);
-      else
-         localLog.trace(""Not using a consistent hash function (hash function version == 0)"");
-
-      int hashSpace = transport.readVInt();
-      int clusterSize = transport.readVInt();
+   protected Map<SocketAddress, Set<Integer>> computeNewHashes(Transport transport,
+         Log localLog, int newTopologyId, int numKeyOwners,
+         short hashFunctionVersion, int hashSpace, int clusterSize) {
       // New in 1.1
       int numVirtualNodes = transport.readVInt();
 
-      localLog.tracef(""Topology change request: newTopologyId=%d, numKeyOwners=%d, "" +
-            ""hashFunctionVersion=%d, hashSpaceSize=%d, clusterSize=%d, numVirtualNodes=%d"",
-            newTopologyId, numKeyOwners, hashFctVersion, hashSpace, clusterSize,
-            numVirtualNodes);
+      if (localLog.isTraceEnabled()) {
+         localLog.tracef(""Topology change request: newTopologyId=%d, numKeyOwners=%d, "" +
+               ""hashFunctionVersion=%d, hashSpaceSize=%d, clusterSize=%d, numVirtualNodes=%d"",
+               newTopologyId, numKeyOwners, hashFunctionVersion, hashSpace, clusterSize,
+               numVirtualNodes);
+      }
 
       Map<SocketAddress, Set<Integer>> servers2Hash =
             new LinkedHashMap<SocketAddress, Set<Integer>>();
 
+      ConsistentHash ch = null;
+      if (hashFunctionVersion != 0)
+         ch = transport.getTransportFactory().getConsistentHashFactory()
+               .newConsistentHash(hashFunctionVersion);
+      else
+         localLog.trace(""Not using a consistent hash function (hash function version == 0)"");
+
       for (int i = 0; i < clusterSize; i++) {
          String host = transport.readString();
          int port = transport.readUnsignedShort();
          // TODO: Performance improvement, since hash positions are fixed, we could maybe only calculate for those nodes that the client is not aware of?
          int baseHashCode = transport.read4ByteInt();
          int normalizedHashCode = getNormalizedHash(baseHashCode, ch);
          localLog.tracef(""Server(%s:%d) read with base hash code %d, and normalized hash code %d"",
-                    host, port, baseHashCode, normalizedHashCode);
+               host, port, baseHashCode, normalizedHashCode);
          cacheHashCode(servers2Hash, host, port, normalizedHashCode);
          if (numVirtualNodes > 1)
             calcVirtualHashCodes(baseHashCode, numVirtualNodes, servers2Hash, host, port, ch);
       }
 
-      if (localLog.isInfoEnabled()) {
-         localLog.newTopology(servers2Hash.keySet());
-      }
-      transport.getTransportFactory().updateServers(servers2Hash.keySet());
-      if (hashFctVersion == 0) {
-         localLog.trace(""Not using a consistent hash function (hash function version == 0)"");
-      } else {
-         transport.getTransportFactory().updateHashFunction(
-               servers2Hash, numKeyOwners, hashFctVersion, hashSpace);
-      }
+      return servers2Hash;
    }
 
    @Override",2012-05-11T20:13:51Z,578
"@@ -22,6 +22,9 @@
  */
 package org.infinispan.client.hotrod.impl.transport;
 
+import java.net.InetAddress;
+import java.net.SocketAddress;
+
 /**
  * Transport abstraction.
  *
@@ -70,4 +73,15 @@ public interface Transport {
    void writeString(String string);
 
    byte[] dumpStream();
+
+   /**
+    * Returns the address of the endpoint this transport is connected to, or
+    * <code>null</code> if it is unconnected.
+    *
+    * @return a <code>SocketAddress</code> reprensenting the remote endpoint
+    *         of this transport, or <code>null</code> if it is not connected
+    *         yet.
+    */
+   SocketAddress getRemoteSocketAddress();
+
 }",2012-05-11T20:13:51Z,579
"@@ -32,8 +32,10 @@
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
 import java.io.InputStream;
+import java.net.InetAddress;
 import java.net.InetSocketAddress;
 import java.net.Socket;
+import java.net.SocketAddress;
 import java.nio.channels.SocketChannel;
 import java.util.concurrent.atomic.AtomicLong;
 
@@ -323,4 +325,10 @@ public byte[] dumpStream() {
       }
       return os.toByteArray();
    }
+
+   @Override
+   public SocketAddress getRemoteSocketAddress() {
+      return socket.getRemoteSocketAddress();
+   }
+
 }",2012-05-11T20:13:51Z,199
"@@ -68,8 +68,8 @@ public interface Log extends BasicLogger {
    void errorFromServer(String message);
 
    @LogMessage(level = INFO)
-   @Message(value = ""New topology: %s"", id = 4006)
-   void newTopology(Set<SocketAddress> topology);
+   @Message(value = ""%s sent new topology view (id=%d): %s"", id = 4006)
+   void newTopology(SocketAddress address, int viewId, Set<SocketAddress> topology);
 
    @LogMessage(level = ERROR)
    @Message(value = ""Exception encountered. Retry %d out of %d"", id = 4007)",2012-05-11T20:13:51Z,580
"@@ -27,6 +27,7 @@
 import org.infinispan.io.UnsignedNumeric;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.util.Util;
 
 import java.io.IOException;
 import java.io.NotSerializableException;
@@ -207,11 +208,11 @@ public int hashCode() {
    @Override
    public String toString() {
       StringBuilder sb = new StringBuilder()
-         .append(""MarshalledValue("")
-         .append(""instance="").append(instance != null ? instance.toString() : ""<undeserialized>"")
-         .append(""; cachedHashCode="").append(cachedHashCode)
-         .append(""; serialized="").append(raw != null)
-         .append("")@"").append(Integer.toHexString(System.identityHashCode(this)));
+         .append(""MarshalledValue{"")
+         .append(""instance="").append(instance != null ? instance.toString() : ""<serialized>"")
+         .append("", serialized="").append(raw != null ?  Util.printArray(raw, false) : ""false"")
+         .append("", cachedHashCode="").append(cachedHashCode)
+         .append(""}@"").append(Integer.toHexString(System.identityHashCode(this)));
       return sb.toString();
    }
 ",2010-03-18T14:38:47Z,78
"@@ -244,5 +244,19 @@ public static String formatString(Object message, Object... params) {
          }
       }
       return value.toString();
-   }    
+   }
+
+   public static String printArray(byte[] array, boolean withHash) {
+      StringBuilder sb = new StringBuilder();
+      sb.append(""ByteArray{size="").append(array.length);
+      if (withHash)
+         sb.append("", hashCode="").append(Integer.toHexString(array.hashCode()));
+
+      sb.append("", array=["");
+      for (int i = 0; i < 10; i++)
+         sb.append(array[i]).append("", "");
+      sb.append(""..]}"");
+
+      return sb.toString();
+   }
 }",2010-03-18T14:38:47Z,79
"@@ -53,6 +53,9 @@
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionCoordinator;
 import org.infinispan.transaction.TransactionTable;
+import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.transaction.xa.recovery.RecoverableTransactionIdentifier;
+import org.infinispan.transaction.xa.recovery.RecoveryManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.rhq.helpers.pluginAnnotations.agent.DataType;
@@ -90,18 +93,21 @@ public class TxInterceptor extends CommandInterceptor {
    protected RpcManager rpcManager;
 
    private static final Log log = LogFactory.getLog(TxInterceptor.class);
+   private RecoveryManager recoveryManager;
 
    @Override
    protected Log getLog() {
       return log;
    }
 
    @Inject
-   public void init(TransactionTable txTable, Configuration c, TransactionCoordinator txCoordinator, RpcManager rpcManager) {
+   public void init(TransactionTable txTable, Configuration c, TransactionCoordinator txCoordinator, RpcManager rpcManager,
+                    RecoveryManager recoveryManager) {
       this.cacheConfiguration = c;
       this.txTable = txTable;
       this.txCoordinator = txCoordinator;
       this.rpcManager = rpcManager;
+      this.recoveryManager = recoveryManager;
       setStatisticsEnabled(cacheConfiguration.jmxStatistics().enabled());
    }
 
@@ -160,7 +166,16 @@ public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand comm
       if (!ctx.isOriginLocal()) {
          txTable.remoteTransactionRollback(command.getGlobalTransaction());
       }
-      return invokeNextInterceptor(ctx, command);
+      try {
+         return invokeNextInterceptor(ctx, command);
+      } finally {
+         //for tx that rollback we do not send a TxCompletionNotification, so we should cleanup
+         // the recovery info here
+         if (recoveryManager!=null) {
+            GlobalTransaction gtx = command.getGlobalTransaction();
+            recoveryManager.removeRecoveryInformation(((RecoverableTransactionIdentifier)gtx).getXid());
+         }
+      }
    }
 
    @Override",2012-11-02T12:56:26Z,87
"@@ -82,6 +82,7 @@ public void afterCompletion(int status) {
          } catch (XAException e) {
             throw new CacheException(""Could not commit."", e);
          }
+         releaseLocksForCompletedTransaction(localTransaction);
       } else if (status == Status.STATUS_ROLLEDBACK) {
          try {
             txCoordinator.rollback(localTransaction);
@@ -91,7 +92,6 @@ public void afterCompletion(int status) {
       } else {
          throw new IllegalArgumentException(""Unknown status: "" + status);
       }
-      releaseLocksForCompletedTransaction(localTransaction);
    }
 
    @Override",2012-11-02T12:56:26Z,581
"@@ -138,7 +138,6 @@ public void rollback(Xid externalXid) throws XAException {
       LocalXaTransaction localTransaction1 = getLocalTransactionAndValidateImpl(xid, txTable);
       localTransaction.markForRollback(true); //ISPN-879 : make sure that locks are no longer associated to this transactions
       txCoordinator.rollback(localTransaction1);
-      forgetSuccessfullyCompletedTransaction(recoveryManager, xid, localTransaction1);
    }
 
    @Override",2012-11-02T12:56:26Z,92
"@@ -0,0 +1,72 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.commands.remote.recovery.TxCompletionNotificationCommand;
+import org.infinispan.commands.tx.PrepareCommand;
+import org.infinispan.commands.tx.RollbackCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.util.mocks.ControlledCommandFactory;
+import org.testng.annotations.Test;
+
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNull;
+import static org.testng.Assert.fail;
+
+@Test(groups = ""functional"", testName = ""tx.TxCompletionForRolledBackTxOptTest"")
+public class TxCompletionForRolledBackTxOptTest extends MultipleCacheManagersTest {
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      ConfigurationBuilder dcc = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+      dcc.clustering().hash().numOwners(1).transaction().lockingMode(LockingMode.OPTIMISTIC);
+      createCluster(dcc, 3);
+      waitForClusterToForm();
+      advancedCache(2).addInterceptor(new RollbackBeforePrepareTest.FailPrepareInterceptor(), 1);
+   }
+
+   public void testTxCompletionNotSentForRollback() throws Throwable {
+      ControlledCommandFactory cf = ControlledCommandFactory.registerControlledCommandFactory(cache(1), null);
+
+      tm(0).begin();
+      Object k1 = getKeyForCache(1);
+      Object k2 = getKeyForCache(2);
+      cache(0).put(k1, k1);
+      cache(0).put(k2, k2);
+      try {
+         tm(0).commit();
+         fail();
+      } catch (Throwable t) {
+         //expected
+      }
+
+      assertNotLocked(k1);
+      assertNotLocked(k2);
+      assertNull(cache(0).get(k1));
+      assertNull(cache(0).get(k2));
+
+      assertEquals(cf.received(PrepareCommand.class), 1);
+      assertEquals(cf.received(RollbackCommand.class), 2);
+      assertEquals(cf.received(TxCompletionNotificationCommand.class), 0);
+   }
+}",2012-11-02T12:56:26Z,582
"@@ -0,0 +1,66 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.commands.remote.recovery.TxCompletionNotificationCommand;
+import org.infinispan.commands.tx.RollbackCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.util.mocks.ControlledCommandFactory;
+import org.testng.annotations.Test;
+
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNull;
+
+/**
+ * @author Mircea Markus
+ * @since 5.2
+ */
+@Test (groups = ""functional"", testName = ""tx.TxCompletionForRolledBackTxTest"")
+public class TxCompletionForRolledBackTxTest extends MultipleCacheManagersTest {
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      ConfigurationBuilder dcc = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+      dcc.clustering().hash().numOwners(1).transaction().lockingMode(LockingMode.PESSIMISTIC);
+      amend(dcc);
+      createCluster(dcc, 2);
+      waitForClusterToForm();
+   }
+
+   protected void amend(ConfigurationBuilder dcc) {}
+
+   public void testTxCompletionNotSentForRollback() throws Throwable {
+      ControlledCommandFactory cf = ControlledCommandFactory.registerControlledCommandFactory(cache(1), null);
+
+      tm(0).begin();
+      Object k = getKeyForCache(1);
+      cache(0).put(k,""k"");
+      tm(0).rollback();
+
+      assertNotLocked(k);
+      assertNull(cache(0).get(k));
+
+      assertEquals(cf.received(RollbackCommand.class), 1);
+      assertEquals(cf.received(TxCompletionNotificationCommand.class), 0);
+   }
+}",2012-11-02T12:56:26Z,583
"@@ -0,0 +1,32 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.testng.annotations.Test;
+
+@Test (testName = ""tx.TxCompletionForRolledBackXaTxTest"")
+public class TxCompletionForRolledBackXaTxTest extends TxCompletionForRolledBackTxTest {
+
+   @Override
+   protected void amend(ConfigurationBuilder dcc) {
+      dcc.transaction().useSynchronization(false);
+   }
+}",2012-11-02T12:56:26Z,584
"@@ -66,6 +66,7 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.xa.Xid;
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
 import java.util.Map;
@@ -86,15 +87,28 @@ public class ControlledCommandFactory implements CommandsFactory {
    public final ReclosableLatch gate = new ReclosableLatch(true);
    public final AtomicInteger remoteCommandsReceived = new AtomicInteger(0);
    public final AtomicInteger blockTypeCommandsReceived = new AtomicInteger(0);
+   public final List<ReplicableCommand> receivedCommands = new ArrayList<ReplicableCommand>();
    public final Class<? extends  ReplicableCommand> toBlock;
 
    public ControlledCommandFactory(CommandsFactory actual, Class<? extends ReplicableCommand> toBlock) {
       this.actual = actual;
       this.toBlock = toBlock;
    }
 
+   public int received(Class<? extends ReplicableCommand> command) {
+      int result = 0;
+      for (ReplicableCommand r : receivedCommands) {
+         if (r.getClass() == command) {
+            result++;
+         }
+      }
+      return result;
+   }
+
    @Override
    public void initializeReplicableCommand(ReplicableCommand command, boolean isRemote) {
+      log.tracef(""Received command %s"", command);
+      receivedCommands.add(command);
       if (isRemote) {
          remoteCommandsReceived.incrementAndGet();
          if (toBlock != null && command.getClass().isAssignableFrom(toBlock)) {",2012-11-02T12:56:26Z,585
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +41,24 @@
  */
 @Test(groups = ""unit"", enabled = true, testName = ""loaders.bdbje.BdbjeCacheStoreIntegrationVamTest"")
 public class BdbjeCacheStoreIntegrationVamTest extends BdbjeCacheStoreIntegrationTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,80
"@@ -39,21 +39,24 @@
  */
 @Test(groups = ""unit"", sequential = true, testName = ""loaders.cloud.CloudCacheStoreIntegrationVamTest"")
 public class CloudCacheStoreIntegrationVamTest extends CloudCacheStoreIntegrationTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,586
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,19 +41,24 @@
  */
 @Test(groups = ""unit"", testName = ""loaders.cloud.CloudCacheStoreVamTest"")
 public class CloudCacheStoreVamTest extends CloudCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
    }
 
-   @AfterMethod(alwaysRun = true)
-   @Override
-   public void tearDown() throws CacheLoaderException {
-      super.tearDown();
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
       cm.stop();
    }
 
+   @Override
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
+   }
+
 }",2011-09-13T09:07:28Z,587
"@@ -246,7 +246,7 @@ public final Set<InternalCacheEntry> loadSome(int maxEntries) throws CacheLoader
          rs.setFetchSize(tableManipulation.getFetchSize());
          Set<InternalCacheEntry> result = new HashSet<InternalCacheEntry>(maxEntries);
          while (rs.next()) {
-            loadAllProcess(rs, result);
+            loadAllProcess(rs, result, maxEntries);
          }
          return result;
       } catch (SQLException e) {
@@ -267,6 +267,8 @@ protected boolean includeKey(Object key, Set<Object> keysToExclude) {
 
    protected abstract void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result) throws SQLException, CacheLoaderException;
 
+   protected abstract void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result, int maxEntries) throws SQLException, CacheLoaderException;
+
    protected abstract void loadAllKeysProcess(ResultSet rs, Set<Object> keys, Set<Object> keysToExclude) throws SQLException, CacheLoaderException;
 
    protected abstract void toStreamProcess(ResultSet rs, InputStream is, ObjectOutput objectOutput) throws CacheLoaderException, SQLException, IOException;",2011-09-13T09:07:28Z,405
"@@ -118,6 +118,19 @@ public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result) throws
             }
          }
 
+         @Override
+         public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result, int maxEntries) throws SQLException, CacheLoaderException {
+            InputStream binaryStream = rs.getBinaryStream(1);
+            Bucket bucket = (Bucket) JdbcUtil.unmarshall(getMarshaller(), binaryStream);
+            for (InternalCacheEntry ice: bucket.getStoredEntries()) {
+               if (!ice.isExpired())
+                  result.add(ice);
+
+               if (result.size() == maxEntries)
+                  break;
+            }
+         }
+
          @Override
          public void loadAllKeysProcess(ResultSet rs, Set<Object> keys, Set<Object> keysToExclude) throws SQLException, CacheLoaderException {
             InputStream binaryStream = rs.getBinaryStream(1);",2011-09-13T09:07:28Z,407
"@@ -146,6 +146,11 @@ public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result) throws
             result.add(icv.toInternalCacheEntry(key));
          }
 
+         @Override
+         public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result, int maxEntries) throws SQLException, CacheLoaderException {
+            loadAllProcess(rs, result);
+         }
+
          @Override
          public void loadAllKeysProcess(ResultSet rs, Set<Object> keys, Set<Object> keysToExclude) throws SQLException, CacheLoaderException {
             String keyStr = rs.getString(1);",2011-09-13T09:07:28Z,82
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.binary.JdbcBinaryCacheStoreVamTest"")
 public class JdbcBinaryCacheStoreVamTest extends JdbcBinaryCacheStoreTest {   
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,588
"@@ -39,6 +39,7 @@
 import org.infinispan.test.fwk.UnitTestDatabaseManager;
 import org.testng.annotations.AfterMethod;
 import org.testng.annotations.AfterTest;
+import org.testng.annotations.BeforeMethod;
 import org.testng.annotations.BeforeTest;
 import org.testng.annotations.Test;
 
@@ -64,7 +65,7 @@ public class JdbcMixedCacheStoreTest {
    private static final Person MIRCEA = new Person(""Mircea"", ""Markus"", 28);
    private static final Person MANIK = new Person(""Manik"", ""Surtani"", 18);
 
-   @BeforeTest
+   @BeforeMethod
    public void createCacheStore() throws CacheLoaderException {
       stringsTm = UnitTestDatabaseManager.buildDefaultTableManipulation();
       stringsTm.setTableNamePrefix(""STRINGS_TABLE"");",2011-09-13T09:07:28Z,589
"@@ -22,10 +22,13 @@
  */
 package org.infinispan.loaders.jdbc.mixed;
 
+import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -38,21 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.mixed.JdbcMixedCacheStoreVamTest"")
 public class JdbcMixedCacheStoreVamTest extends JdbcMixedCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void clearStore() throws Exception {
-      try {
-         super.clearStore();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,589
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,22 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.mixed.JdbcMixedCacheStoreVamTest2"")
 public class JdbcMixedCacheStoreVamTest2 extends JdbcMixedCacheStoreTest2 {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
 
 }",2011-09-13T09:07:28Z,590
"@@ -26,7 +26,8 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
-import org.testng.annotations.AfterMethod;
+import org.testng.annotations.AfterClass;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +40,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.stringbased.JdbcStringBasedCacheStoreVamTest"")
 public class JdbcStringBasedCacheStoreVamTest extends JdbcStringBasedCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,591
"@@ -22,10 +22,13 @@
  */
 package org.infinispan.loaders.jdbc.stringbased;
 
+import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -38,21 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.stringbased.JdbcStringBasedCacheStoreVamTest2"")
 public class JdbcStringBasedCacheStoreVamTest2 extends JdbcStringBasedCacheStoreTest2 {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void clearStore() throws Exception {
-      try {
-         super.clearStore();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,591
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +41,24 @@
  */
 @Test(groups = ""unit"", testName = ""loaders.jdbm.JdbmCacheStoreVamTest"")
 public class JdbmCacheStoreVamTest extends JdbmCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,592
"@@ -46,6 +46,7 @@
 import java.util.*;
 
 import static java.util.Collections.emptySet;
+import static org.testng.AssertJUnit.assertEquals;
 
 /**
  * This is a base class containing various unit tests for each and every different CacheStore implementations. If you
@@ -443,7 +444,7 @@ public void testPreloadWithMaxSize() throws CacheLoaderException {
 
       Set<InternalCacheEntry> set = cs.load(2);
 
-      assert set.size() == 2;
+      assertEquals(2, set.size());
       Set expected = new HashSet();
       expected.add(""k1"");
       expected.add(""k2"");",2011-09-13T09:07:28Z,84
"@@ -36,6 +36,7 @@
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 import java.io.Serializable;
+import java.util.UUID;
 
 /**
  * @author bela
@@ -46,6 +47,7 @@ public class DummyBaseTransactionManager implements TransactionManager, Serializ
    private static final long serialVersionUID = -6716097342564237376l;
    private static final Log log = LogFactory.getLog(DummyBaseTransactionManager.class);
    private static final boolean trace = log.isTraceEnabled();
+   final UUID transactionManagerId = UUID.randomUUID();
 
    /**
     * Starts a new transaction, and associate it with the calling thread.",2012-01-11T17:05:42Z,593
"@@ -50,15 +50,16 @@ public class DummyTransaction implements Transaction {
    private static boolean trace = log.isTraceEnabled();
 
    private volatile int status = Status.STATUS_UNKNOWN;
-   protected DummyBaseTransactionManager tm_;
-   protected DummyXid xid = new DummyXid();
+   protected final DummyBaseTransactionManager tm_;
+   protected final DummyXid xid;
 
    protected Set<Synchronization> syncs;
-   private List<XAResource> enlistedResources = new ArrayList<XAResource>(2);
+   private final List<XAResource> enlistedResources = new ArrayList<XAResource>(2);
    private int prepareStatus;
 
    public DummyTransaction(DummyBaseTransactionManager tm) {
       tm_ = tm;
+      xid = new DummyXid(tm.transactionManagerId);
       status = Status.STATUS_ACTIVE;
    }
 ",2012-01-11T17:05:42Z,594
"@@ -28,6 +28,8 @@
 import javax.transaction.xa.Xid;
 import java.util.Arrays;
 import java.util.UUID;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicLong;
 
 /**
  * Implementation of Xid.
@@ -36,15 +38,19 @@
  */
 public class DummyXid implements Xid {
 
+   private static final AtomicLong GLOBAL_ID_GENERATOR = new AtomicLong(1);
+   private static final AtomicLong BRANCH_QUALIFIER_GENERATOR = new AtomicLong(1);
+
    private byte[] globalTransactionId = new byte[64];
    private byte[] branchQualifier = new byte[64];
+   private final int cachedHashcode;
 
    public int getFormatId() {
       return 1;
    }
 
-   public DummyXid() {
-      initialize();
+   public DummyXid(UUID transactionManagerId) {
+      cachedHashcode = initializeAndCalculateHash(transactionManagerId);
    }
 
    public byte[] getGlobalTransactionId() {
@@ -55,18 +61,23 @@ public byte[] getBranchQualifier() {
       return branchQualifier;
    }
 
-   private void initialize() {
-      initialize(globalTransactionId);
-      initialize(branchQualifier);
+   private int initializeAndCalculateHash(UUID transactionManagerId) {
+      int hc1 = initialize(transactionManagerId, GLOBAL_ID_GENERATOR, globalTransactionId);
+      return 37 * hc1 + initialize(transactionManagerId, BRANCH_QUALIFIER_GENERATOR, branchQualifier);
    }
 
-   private void initialize(byte[] field) {
-      UUID uuid = UUID.randomUUID();
-      long lsb = uuid.getLeastSignificantBits();
-      long msb = uuid.getMostSignificantBits();
+   private int initialize(UUID transactionManagerId, AtomicLong generator, byte[] field) {
+      long lsb = transactionManagerId.getLeastSignificantBits();
+      long msb = transactionManagerId.getMostSignificantBits();
+      long id = generator.getAndIncrement();
       Arrays.fill(field, (byte) 0);
       UnsignedNumeric.writeUnsignedLong(field, 0, lsb);
       UnsignedNumeric.writeUnsignedLong(field, 10, msb);
+      UnsignedNumeric.writeUnsignedLong(field, 20, id);
+      int hash = (int) (lsb ^ lsb >>> 32);
+      hash = 37 * hash + (int) (msb ^ msb >>> 32);
+      hash = 37 * hash + (int) (id ^ id >>> 32);
+      return hash;
    }
 
    @Override
@@ -93,8 +104,6 @@ public boolean equals(Object o) {
 
    @Override
    public int hashCode() {
-      int result = globalTransactionId != null ? Arrays.hashCode(globalTransactionId) : 0;
-      result = 31 * result + (branchQualifier != null ? Arrays.hashCode(branchQualifier) : 0);
-      return result;
+      return cachedHashcode;
    }
 }",2012-01-11T17:05:42Z,595
"@@ -30,13 +30,14 @@
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.transaction.xa.LocalXaTransaction;
 import org.infinispan.transaction.xa.TransactionFactory;
-import org.infinispan.transaction.xa.XaTransactionTable;
 import org.infinispan.transaction.xa.TransactionXaAdapter;
+import org.infinispan.transaction.xa.XaTransactionTable;
 import org.testng.annotations.BeforeMethod;
 import org.testng.annotations.Test;
 
 import javax.transaction.xa.XAException;
 import javax.transaction.xa.XAResource;
+import java.util.UUID;
 
 /**
  * @author Mircea.Markus@jboss.com
@@ -50,6 +51,7 @@ public class TransactionXaAdapterTmIntegrationTest {
    private LocalXaTransaction localTx;
    private TransactionXaAdapter xaAdapter;
    private DummyXid xid;
+   private UUID uuid = UUID.randomUUID();
 
    @BeforeMethod
    public void setUp() {
@@ -58,7 +60,7 @@ public void setUp() {
       gtf.init(false, false, true);
       globalTransaction = gtf.newGlobalTransaction(null, false);
       localTx = new LocalXaTransaction(new DummyTransaction(null), globalTransaction, false);
-      xid = new DummyXid();
+      xid = new DummyXid(uuid);
       localTx.setXid(xid);
       txTable.addLocalTransactionMapping(localTx);      
 
@@ -70,7 +72,7 @@ public void setUp() {
    }
 
    public void testPrepareOnNonexistentXid() {
-      DummyXid xid = new DummyXid();
+      DummyXid xid = new DummyXid(uuid);
       try {
          xaAdapter.prepare(xid);
          assert false;
@@ -80,7 +82,7 @@ public void testPrepareOnNonexistentXid() {
    }
 
    public void testCommitOnNonexistentXid() {
-      DummyXid xid = new DummyXid();
+      DummyXid xid = new DummyXid(uuid);
       try {
          xaAdapter.commit(xid, false);
          assert false;
@@ -90,7 +92,7 @@ public void testCommitOnNonexistentXid() {
    }
 
    public void testRollabckOnNonexistentXid() {
-      DummyXid xid = new DummyXid();
+      DummyXid xid = new DummyXid(uuid);
       try {
          xaAdapter.rollback(xid);
          assert false;
@@ -117,7 +119,7 @@ public void testOnePhaseCommitConfigured() throws XAException {
    public void test1PcAndNonExistentXid() {
       configuration.setCacheMode(Configuration.CacheMode.INVALIDATION_ASYNC);
       try {
-         DummyXid doesNotExists = new DummyXid();
+         DummyXid doesNotExists = new DummyXid(uuid);
          xaAdapter.commit(doesNotExists, false);
          assert false;
       } catch (XAException e) {
@@ -128,7 +130,7 @@ public void test1PcAndNonExistentXid() {
    public void test1PcAndNonExistentXid2() {
       configuration.setCacheMode(Configuration.CacheMode.DIST_SYNC);
       try {
-         DummyXid doesNotExists = new DummyXid();
+         DummyXid doesNotExists = new DummyXid(uuid);
          xaAdapter.commit(doesNotExists, true);
          assert false;
       } catch (XAException e) {",2012-01-11T17:05:42Z,94
"@@ -30,6 +30,7 @@
 import javax.transaction.xa.XAException;
 import java.util.Collections;
 import java.util.Map;
+import java.util.UUID;
 
 /**
  * @author Mircea Markus
@@ -74,7 +75,7 @@ public void testPutAll() throws Exception {
    protected void commit() {
       DummyTransactionManager dtm = (DummyTransactionManager) tm(0);
       try {
-         dtm.firstEnlistedResource().commit(new DummyXid(), true);
+         dtm.firstEnlistedResource().commit(new DummyXid(UUID.randomUUID()), true);
       } catch (XAException e) {
          throw new RuntimeException(e);
       }
@@ -83,7 +84,7 @@ protected void commit() {
    protected void prepare() {
       DummyTransactionManager dtm = (DummyTransactionManager) tm(0);
       try {
-         dtm.firstEnlistedResource().prepare(new DummyXid());
+         dtm.firstEnlistedResource().prepare(new DummyXid(UUID.randomUUID()));
       } catch (XAException e) {
          throw new RuntimeException(e);
       }",2012-01-11T17:05:42Z,596
"@@ -66,7 +66,9 @@ public class InboundTransferTask {
 
    private final long timeout;
 
-   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout) {
+   private final String cacheName;
+
+   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""segments must not be null or empty"");
       }
@@ -81,6 +83,7 @@ public InboundTransferTask(Set<Integer> segments, Address source, int topologyId
       this.rpcManager = rpcManager;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public Set<Integer> getSegments() {
@@ -93,7 +96,7 @@ public Address getSource() {
 
    public boolean requestTransactions() {
       if (trace) {
-         log.tracef(""Requesting transactions for segments %s"", segments);
+         log.tracef(""Requesting transactions for segments %s of cache %s from node %s"", segments, cacheName, source);
       }
       // get transactions and locks
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.GET_TRANSACTIONS, rpcManager.getAddress(), topologyId, segments);
@@ -109,6 +112,10 @@ public boolean requestTransactions() {
    }
 
    public boolean requestSegments() {
+      if (trace) {
+         log.tracef(""Requesting segments %s of cache %s from node %s"", segments, cacheName, source);
+      }
+
       // start transfer of cache entries
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.START_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
       Map<Address, Response> responses = rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
@@ -139,24 +146,21 @@ public void cancel() {
       if (!isCancelled) {
          isCancelled = true;
 
-         Set<Integer> cancelledSegments = new HashSet<Integer>(segments);
-         segments.clear();
-         finishedSegments.clear();
-
-         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, cancelledSegments);
+         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
          rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
 
          stateConsumer.onTaskCompletion(this);
       }
    }
 
    public void onStateReceived(int segmentId, boolean isLastChunk) {
-      if (!isCancelled && segments.contains(segmentId)) {
-         if (isLastChunk) {
-            finishedSegments.add(segmentId);
-            if (finishedSegments.containsAll(segments)) {
-               stateConsumer.onTaskCompletion(this);
+      if (!isCancelled && isLastChunk && segments.contains(segmentId)) {
+         finishedSegments.add(segmentId);
+         if (finishedSegments.containsAll(segments)) {
+            if (trace) {
+               log.tracef(""Finished receiving state for segments %s of cache %s"", segments, cacheName);
             }
+            stateConsumer.onTaskCompletion(this);
          }
       }
    }
@@ -166,11 +170,14 @@ public String toString() {
       HashSet<Integer> unfinishedSegments = new HashSet<Integer>(segments);
       unfinishedSegments.removeAll(finishedSegments);
       return ""InboundTransferTask{"" +
-            ""unfinishedSegments="" + unfinishedSegments +
+            ""segments="" + segments +
+            "", finishedSegments="" + finishedSegments +
+            "", unfinishedSegments="" + unfinishedSegments +
             "", source="" + source +
             "", isCancelled="" + isCancelled +
             "", topologyId="" + topologyId +
             "", timeout="" + timeout +
+            "", cacheName="" + cacheName +
             '}';
    }
 }",2012-11-07T14:07:34Z,120
"@@ -24,20 +24,19 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.commands.CommandsFactory;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheLoaderManager;
 import org.infinispan.loaders.CacheStore;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.SuspectException;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
-import org.infinispan.util.concurrent.AggregatingNotifyingFutureBuilder;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -70,8 +69,6 @@ public class OutboundTransferTask implements Runnable {
 
    private final int stateTransferChunkSize;
 
-   private final Configuration configuration;
-
    private final ConsistentHash readCh;
 
    private final DataContainer dataContainer;
@@ -84,27 +81,24 @@ public class OutboundTransferTask implements Runnable {
 
    private final long timeout;
 
+   private final String cacheName;
+
    private final Map<Integer, List<InternalCacheEntry>> entriesBySegment = ConcurrentMapFactory.makeConcurrentMap();
 
    /**
     * The total number of entries from all segments accumulated in entriesBySegment.
     */
    private int accumulatedEntries;
 
-   /**
-    * This is used with RpcManager.invokeRemotelyInFuture() to be able to cancel message sending if the task needs to be canceled.
-    */
-   private final NotifyingNotifiableFuture<Object> sendFuture = new AggregatingNotifyingFutureBuilder(null);
-
    /**
     * The Future obtained from submitting this task to an executor service. This is used for cancellation.
     */
    private FutureTask runnableFuture;
 
    public OutboundTransferTask(Address destination, Set<Integer> segments, int stateTransferChunkSize,
                                int topologyId, ConsistentHash readCh, StateProviderImpl stateProvider, DataContainer dataContainer,
-                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager, Configuration configuration,
-                               CommandsFactory commandsFactory, long timeout) {
+                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager,
+                               CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""Segments must not be null or empty"");
       }
@@ -123,9 +117,9 @@ public OutboundTransferTask(Address destination, Set<Integer> segments, int stat
       this.dataContainer = dataContainer;
       this.cacheLoaderManager = cacheLoaderManager;
       this.rpcManager = rpcManager;
-      this.configuration = configuration;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public void execute(ExecutorService executorService) {
@@ -154,7 +148,7 @@ public void run() {
       try {
          // send data container entries
          for (InternalCacheEntry ice : dataContainer) {
-            Object key = ice.getKey();
+            Object key = ice.getKey();  //todo [anistor] should we check for expired entries?
             int segmentId = readCh.getSegment(key);
             if (segments.contains(segmentId)) {
                sendEntry(ice, segmentId);
@@ -198,7 +192,7 @@ public void run() {
          }
       }
       if (trace) {
-         log.tracef(""Outbound transfer of segments %s to %s is complete"", segments, destination);
+         log.tracef(""Outbound transfer of segments %s of cache %s to node %s is complete"", segments, cacheName, destination);
       }
    }
 
@@ -217,7 +211,6 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
       // send if we have a full chunk
       if (accumulatedEntries >= stateTransferChunkSize) {
          sendEntries(false);
-         entriesBySegment.clear();
          accumulatedEntries = 0;
       }
 
@@ -232,32 +225,42 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
 
    private void sendEntries(boolean isLast) {
       List<StateChunk> chunks = new ArrayList<StateChunk>();
+      for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
+         List<InternalCacheEntry> entries = e.getValue();
+         if (!entries.isEmpty()) {
+            chunks.add(new StateChunk(e.getKey(), new ArrayList<InternalCacheEntry>(entries), isLast));
+            entries.clear();
+         }
+      }
+
       if (isLast) {
          for (int segmentId : segments) {
             List<InternalCacheEntry> entries = entriesBySegment.get(segmentId);
             if (entries == null) {
-               entries = InfinispanCollections.emptyList();
-            }
-            chunks.add(new StateChunk(segmentId, entries, isLast));
-         }
-      } else {
-         for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
-            List<InternalCacheEntry> entries = e.getValue();
-            if (!entries.isEmpty()) {
-               chunks.add(new StateChunk(e.getKey(), entries, isLast));
+               chunks.add(new StateChunk(segmentId, InfinispanCollections.<InternalCacheEntry>emptyList(), true));
             }
          }
       }
 
-      if (!chunks.isEmpty() || isLast) {
+      if (!chunks.isEmpty()) {
          if (trace) {
-            log.tracef(""Sending %d cache entries from segments %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), destination);
+            if (isLast) {
+               log.tracef(""Sending last chunk containing %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, segments, cacheName, destination);
+            } else {
+               log.tracef(""Sending %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), cacheName, destination);
+            }
          }
 
-         //todo [anistor] send back the received topologyId or my local one?
          StateResponseCommand cmd = commandsFactory.buildStateResponseCommand(rpcManager.getAddress(), topologyId, chunks);
-         // send synchronously, in FIFO mode. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
-         rpcManager.invokeRemotelyInFuture(Collections.singleton(destination), cmd, false, sendFuture, timeout);
+         // send synchronously, in order. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
+         try {
+            rpcManager.invokeRemotely(Collections.singleton(destination), cmd, ResponseMode.SYNCHRONOUS, timeout, false, null);
+         } catch (SuspectException e) {
+            log.errorf(e, ""Node %s left cache %s: %s"", destination, cacheName, e.getMessage());
+            cancel();
+         } catch (Exception e) {
+            log.errorf(e, ""Failed to send entries to node %s : %s"", destination, e.getMessage());
+         }
       }
    }
 
@@ -268,7 +271,7 @@ private void sendEntries(boolean isLast) {
     */
    public void cancelSegments(Set<Integer> cancelledSegments) {
       if (trace) {
-         log.tracef(""Cancelling outbound transfer of segments %s to %s"", cancelledSegments, destination);
+         log.tracef(""Cancelling outbound transfer of segments %s of cache %s to node %s"", cancelledSegments, cacheName, destination);
       }
       if (segments.removeAll(cancelledSegments)) {
          entriesBySegment.keySet().removeAll(cancelledSegments);  // here we do not update accumulatedEntries but this inaccuracy does not cause any harm
@@ -284,11 +287,22 @@ public void cancelSegments(Set<Integer> cancelledSegments) {
    public void cancel() {
       if (runnableFuture != null && !runnableFuture.isCancelled()) {
          runnableFuture.cancel(true);
-         sendFuture.cancel(true);
       }
    }
 
    public boolean isCancelled() {
       return runnableFuture != null && runnableFuture.isCancelled();
    }
+
+   @Override
+   public String toString() {
+      return ""OutboundTransferTask{"" +
+            ""topologyId="" + topologyId +
+            "", destination="" + destination +
+            "", segments="" + segments +
+            "", stateTransferChunkSize="" + stateTransferChunkSize +
+            "", timeout="" + timeout +
+            "", cacheName='"" + cacheName + '\'' +
+            '}';
+   }
 }",2012-11-07T14:07:34Z,121
"@@ -45,7 +45,6 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -62,7 +61,7 @@
 import static org.infinispan.context.Flag.*;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateConsumer} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -72,7 +71,7 @@ public class StateConsumerImpl implements StateConsumer {
    private static final Log log = LogFactory.getLog(StateConsumerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
-   private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
    private Configuration configuration;
    private RpcManager rpcManager;
@@ -119,7 +118,7 @@ public StateConsumerImpl() {
 
    @Inject
    public void init(Cache cache,
-                    LocalTopologyManager localTopologyManager,
+                    StateTransferManager stateTransferManager,
                     InterceptorChain interceptorChain,
                     InvocationContextContainer icc,
                     Configuration configuration,
@@ -130,7 +129,7 @@ public void init(Cache cache,
                     TransactionTable transactionTable,
                     StateTransferLock stateTransferLock) {
       this.cacheName = cache.getName();
-      this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
       this.interceptorChain = interceptorChain;
       this.icc = icc;
       this.configuration = configuration;
@@ -171,26 +170,30 @@ public boolean isStateTransferInProgressForKey(Object key) {
 
    @Override
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
-      if (trace) log.tracef(""Received new CH: %s"", cacheTopology.getWriteConsistentHash());
+      if (trace) log.tracef(""Received new CH %s for cache %s"", cacheTopology.getWriteConsistentHash(), cacheName);
 
       activeTopologyUpdates.incrementAndGet();
       if (isRebalance) {
          rebalanceInProgress.set(true);
       }
-      ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
+      final ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
       // Ensures writes to the data container use the right consistent hash
       // No need for a try/finally block, since it's just an assignment
       stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
       stateTransferLock.releaseExclusiveTopologyLock();
-      stateTransferLock.topologyInstalled(cacheTopology.getTopologyId());
+      stateTransferLock.notifyTopologyInstalled(cacheTopology.getTopologyId());
 
       try {
          Set<Integer> addedSegments;
          if (previousCh == null) {
             // we start fresh, without any data, so we need to pull everything we own according to writeCh
 
             addedSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
+
+            if (trace) {
+               log.tracef(""On cache %s we have: added segments: %s"", cacheName, addedSegments);
+            }
          } else {
             Set<Integer> previousSegments = getOwnedSegments(previousCh);
             Set<Integer> newSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
@@ -199,16 +202,16 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             Set<Integer> removedSegments = new HashSet<Integer>(previousSegments);
             removedSegments.removeAll(newSegments);
 
-            // remove inbound transfers and any data for segments we no longer own
+            addedSegments = new HashSet<Integer>(newSegments);
+            addedSegments.removeAll(previousSegments);
+
             if (trace) {
-               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                     removedSegments, newSegments, previousSegments);
+               log.tracef(""On cache %s we have: removed segments: %s; new segments: %s; old segments: %s; added segments: %s"",
+                     cacheName, removedSegments, newSegments, previousSegments, addedSegments);
             }
-            discardSegments(removedSegments);
 
-            Set<Integer> currentSegments = getOwnedSegments(cacheTopology.getReadConsistentHash());
-            addedSegments = new HashSet<Integer>(newSegments);
-            addedSegments.removeAll(currentSegments);
+            // remove inbound transfers and any data for segments we no longer own
+            discardSegments(removedSegments);
 
             // check if any of the existing transfers should be restarted from a different source because the initial source is no longer a member
             Set<Address> members = new HashSet<Address>(cacheTopology.getReadConsistentHash().getMembers());
@@ -230,24 +233,30 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
                      }
                   }
                }
+
+               // exclude those that are already in progress from a valid source
+               addedSegments.removeAll(transfersBySegment.keySet());
             }
          }
 
-         if (addedSegments != null && !addedSegments.isEmpty()) {
+         if (!addedSegments.isEmpty()) {
             addTransfers(addedSegments);  // add transfers for new or restarted segments
          }
       } finally {
-         stateTransferLock.transactionDataReceived(cacheTopology.getTopologyId());
+         stateTransferLock.notifyTransactionDataReceived(cacheTopology.getTopologyId());
 
-         if (activeTopologyUpdates.decrementAndGet() == 0 && !isStateTransferInProgress()) {
+         if (activeTopologyUpdates.decrementAndGet() == 0) {
             notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
          }
       }
    }
 
    private void notifyEndOfTopologyUpdate(int topologyId) {
-      if (rebalanceInProgress.compareAndSet(true, false)) {
-         localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+      if (!isStateTransferInProgress()) {
+         if (rebalanceInProgress.compareAndSet(true, false)) {
+            log.debugf(""Finished receiving of segments for cache %s for topology %d."", cacheName, topologyId);
+            stateTransferManager.notifyEndOfTopologyUpdate(topologyId);
+         }
       }
    }
 
@@ -262,43 +271,42 @@ public void applyState(Address sender, int topologyId, int segmentId, Collection
       //todo [anistor] this check should be based on topologyId
       if (!cacheTopology.getWriteConsistentHash().getSegmentsForOwner(rpcManager.getAddress()).contains(segmentId)) {
          if (trace) {
-            log.warnf(""Discarding received cache entries for segment %d because they do not belong to this node."", segmentId);
+            log.warnf(""Discarding received cache entries for segment %d of cache %s because they do not belong to this node."", segmentId, cacheName);
          }
          return;
       }
 
-      if (cacheEntries != null) {
-         doApplyState(sender, segmentId, cacheEntries);
-      }
-
       // notify the inbound task that a chunk of cache entries was received
       InboundTransferTask inboundTransfer;
       synchronized (this) {
          inboundTransfer = transfersBySegment.get(segmentId);
       }
       if (inboundTransfer != null) {
+         if (cacheEntries != null) {
+            doApplyState(sender, segmentId, cacheEntries);
+         }
+
          inboundTransfer.onStateReceived(segmentId, isLastChunk);
-      } else {
-         log.debugf(""Received unsolicited state for segment %d from node %s"", segmentId, sender);
-         return;
-      }
 
-      if (trace) {
-         log.tracef(""After applying the received state the data container has %d keys"", dataContainer.size());
-         synchronized (this) {
-            log.tracef(""Segments not received yet: %s"", transfersBySource);
+         if (trace) {
+            log.tracef(""After applying the received state the data container of cache %s has %d keys"", cacheName, dataContainer.size());
+            synchronized (this) {
+               log.tracef(""Segments not received yet for cache %s: %s"", cacheName, transfersBySource);
+            }
          }
+      } else {
+         log.warnf(""Received unsolicited state from node %s for segment %d of cache %s"", sender, segmentId, cacheName);
       }
    }
 
    private void doApplyState(Address sender, int segmentId, Collection<InternalCacheEntry> cacheEntries) {
-      log.debugf(""Applying new state for segment %d from %s: received %d cache entries"", segmentId, sender, cacheEntries.size());
+      log.debugf(""Applying new state for segment %d of cache %s from node %s: received %d cache entries"", segmentId, cacheName, sender, cacheEntries.size());
       if (trace) {
          List<Object> keys = new ArrayList<Object>(cacheEntries.size());
          for (InternalCacheEntry e : cacheEntries) {
             keys.add(e.getKey());
          }
-         log.tracef(""Received keys: %s"", keys);
+         log.tracef(""Received keys %s for segment %d of cache %s from node %s"", keys, segmentId, cacheName, sender);
       }
 
       // CACHE_MODE_LOCAL avoids handling by StateTransferInterceptor and any potential locks in StateTransferLock
@@ -316,10 +324,11 @@ private void doApplyState(Address sender, int segmentId, Collection<InternalCach
             log.problemApplyingStateForKey(ex.getMessage(), e.getKey());
          }
       }
+      log.debugf(""Finished applying state for segment %d of cache %s"", segmentId, cacheName);
    }
 
    public void applyTransactions(Address sender, int topologyId, Collection<TransactionInfo> transactions) {
-      log.debugf(""Applying %d transactions transferred from %s"", transactions.size(), sender);
+      log.debugf(""Applying %d transactions for cache %s transferred from node %s"", transactions.size(), cacheName, sender);
       if (configuration.transaction().transactionMode().isTransactional()) {
          for (TransactionInfo transactionInfo : transactions) {
             CacheTransaction tx = transactionTable.getLocalTransaction(transactionInfo.getGlobalTransaction());
@@ -374,30 +383,31 @@ public CacheTopology getCacheTopology() {
    }
 
    private void addTransfers(Set<Integer> segments) {
-      log.debugf(""Adding state transfer for segments: %s"", segments);
+      log.debugf(""Adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
 
       Set<Integer> segmentsToProcess = new HashSet<Integer>(segments);
-      Set<Address> blacklistedSources = new HashSet<Address>();
+      Set<Address> faultysources = new HashSet<Address>();
 
       // ignore all segments for which there are no other owners to pull data from.
       // these segments are considered empty (or lost) and do not require a state transfer
       for (Iterator<Integer> it = segmentsToProcess.iterator(); it.hasNext(); ) {
          Integer segmentId = it.next();
-         Address source = pickSourceOwner(segmentId, blacklistedSources);
+         Address source = pickSourceOwner(segmentId, faultysources);
          if (source == null) {
             it.remove();
          }
       }
 
-      synchronized (this) {
-         // already active transfers do not need to be added again
-         segmentsToProcess.removeAll(transfersBySegment.keySet());
-      }
-
       while (!segmentsToProcess.isEmpty()) {
          Map<Address, Set<Integer>> segmentsBySource = new HashMap<Address, Set<Integer>>();
          for (int segmentId : segmentsToProcess) {
-            Address source = pickSourceOwner(segmentId, blacklistedSources);
+            synchronized (this) {
+               // already active transfers do not need to be added again
+               if (transfersBySegment.containsKey(segmentId)) {
+                  continue;
+               }
+            }
+            Address source = pickSourceOwner(segmentId, faultysources);
             if (source != null) {
                Set<Integer> segmentsFromSource = segmentsBySource.get(source);
                if (segmentsFromSource == null) {
@@ -411,8 +421,14 @@ private void addTransfers(Set<Integer> segments) {
          Set<Integer> failedSegments = new HashSet<Integer>();
          for (Address source : segmentsBySource.keySet()) {
             Set<Integer> segmentsFromSource = segmentsBySource.get(source);
-            InboundTransferTask inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout);
+            InboundTransferTask inboundTransfer;
             synchronized (this) {
+               segmentsFromSource.removeAll(transfersBySegment.keySet());  // already in progress segments are excluded
+               if (segmentsFromSource.isEmpty()) {
+                  continue;
+               }
+
+               inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout, cacheName);
                for (int segmentId : segmentsFromSource) {
                   transfersBySegment.put(segmentId, inboundTransfer);
                }
@@ -427,9 +443,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the transactions fails we need to retry from another source
             if (configuration.transaction().transactionMode().isTransactional()) {
                if (!inboundTransfer.requestTransactions()) {
-                  log.errorf(""Failed to retrieve transactions for segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRetrieveTransactionsForSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                   continue;
                }
@@ -438,9 +454,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the segments fails we need to retry from another source
             if (fetchEnabled) {
                if (!inboundTransfer.requestSegments()) {
-                  log.errorf(""Failed to request segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRequestSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                }
             } else {
@@ -450,21 +466,22 @@ private void addTransfers(Set<Integer> segments) {
 
          segmentsToProcess = failedSegments;
       }
+      log.debugf(""Finished adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
    }
 
-   private Address pickSourceOwner(int segmentId, Set<Address> blacklistedSources) {
+   private Address pickSourceOwner(int segmentId, Set<Address> faultySources) {
       List<Address> owners = cacheTopology.getReadConsistentHash().locateOwnersForSegment(segmentId);
       if (owners.size() == 1 && owners.get(0).equals(rpcManager.getAddress())) {
          return null;
       }
 
       for (int i = owners.size() - 1; i >= 0; i--) {   // iterate backwards because we prefer to fetch from newer nodes
          Address o = owners.get(i);
-         if (!o.equals(rpcManager.getAddress()) && !blacklistedSources.contains(o)) {
+         if (!o.equals(rpcManager.getAddress()) && !faultySources.contains(o)) {
             return o;
          }
       }
-      log.errorf(""No live owners found for segment %d. Current owners are:  %s. Blacklisted owners: %s"", segmentId, owners, blacklistedSources);
+      log.noLiveOwnersFoundForSegment(segmentId, cacheName, owners, faultySources);
       return null;
    }
 
@@ -478,9 +495,9 @@ private void discardSegments(Set<Integer> segments) {
          List<Integer> segmentsToCancel = new ArrayList<Integer>(segments);
          while (!segmentsToCancel.isEmpty()) {
             int segmentId = segmentsToCancel.remove(0);
-            log.debugf(""Removing state transfer for segment %d"", segmentId);
             InboundTransferTask inboundTransfer = transfersBySegment.remove(segmentId);
             if (inboundTransfer != null) { // we need to check the transfer was not already completed
+               log.debugf(""Cancelling inbound state transfer for segment %d of cache %s"", segmentId, cacheName);
                Set<Integer> cancelledSegments = new HashSet<Integer>(segmentsToCancel);
                cancelledSegments.retainAll(inboundTransfer.getSegments());
                segmentsToCancel.removeAll(cancelledSegments);
@@ -489,6 +506,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      // gather all keys from data container that belong to the segments that are being removed
       Set<Object> keysToRemove = new HashSet<Object>();
       for (InternalCacheEntry ice : dataContainer) {
          Object key = ice.getKey();
@@ -497,7 +515,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
-      // we also remove keys from the cache store
+      // gather all keys from cache store that belong to the segments that are being removed
       CacheStore cacheStore = getCacheStore();
       if (cacheStore != null) {
          //todo [anistor] extend CacheStore interface to be able to specify a filter when loading keys (ie. keys should belong to desired segments)
@@ -514,13 +532,14 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      log.debugf(""Removing state for segments %s of cache %s"", segments, cacheName);
       if (!keysToRemove.isEmpty()) {
          try {
             InvalidateCommand invalidateCmd = commandsFactory.buildInvalidateFromL1Command(true, EnumSet.of(CACHE_MODE_LOCAL, SKIP_LOCKING), keysToRemove);
             InvocationContext ctx = icc.createNonTxInvocationContext();
             interceptorChain.invoke(ctx, invalidateCmd);
 
-            log.debugf(""Invalidated %d keys, data container now has %d keys"", keysToRemove.size(), dataContainer.size());
+            log.debugf(""Invalidated %d keys, data container of cache %s now has %d keys"", keysToRemove.size(), cacheName, dataContainer.size());
             if (trace) log.tracef(""Invalidated keys: %s"", keysToRemove);
          } catch (CacheException e) {
             log.failedToInvalidateKeys(e);
@@ -553,18 +572,17 @@ private void removeTransfer(InboundTransferTask inboundTransfer) {
                if (transfers.isEmpty()) {
                   transfersBySource.remove(inboundTransfer.getSource());
                }
-               for (int segmentId : inboundTransfer.getSegments()) {
-                  transfersBySegment.remove(segmentId);
-               }
+               transfersBySegment.keySet().removeAll(inboundTransfer.getSegments());
             }
          }
       }
    }
 
    void onTaskCompletion(InboundTransferTask inboundTransfer) {
+      log.tracef(""Completion of inbound transfer task: %s "", inboundTransfer);
       removeTransfer(inboundTransfer);
 
-      if (activeTopologyUpdates.get() == 0 && !isStateTransferInProgress()) {
+      if (activeTopologyUpdates.get() == 0) {
          notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
       }
    }",2012-11-07T14:07:34Z,54
"@@ -52,7 +52,7 @@
 import static org.infinispan.factories.KnownComponentNames.ASYNC_TRANSPORT_EXECUTOR;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateProvider} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -90,7 +90,7 @@ public StateProviderImpl() {
 
    @Inject
    public void init(Cache cache,
-                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //todo [anistor] use a separate ExecutorService
+                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //TODO Use a dedicated ExecutorService
                     Configuration configuration,
                     RpcManager rpcManager,
                     CommandsFactory commandsFactory,
@@ -184,7 +184,7 @@ public void stop() {
 
    public List<TransactionInfo> getTransactionsForSegments(Address destination, int requestTopologyId, Set<Integer> segments) throws InterruptedException {
       if (trace) {
-         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, requestTopologyId);
+         log.tracef(""Received request for transactions from node %s for segments %s of cache %s with topology id %d"", destination, segments, cacheName, requestTopologyId);
       }
 
       if (readCh == null) {
@@ -262,8 +262,8 @@ public void startOutboundTransfer(Address destination, int requestTopologyId, Se
       }
 
       // the destination node must already have an InboundTransferTask waiting for these segments
-      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, requestTopologyId,
-            readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
+      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId,
+            readCh, this, dataContainer, cacheLoaderManager, rpcManager, commandsFactory, timeout, cacheName);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);
    }
@@ -294,7 +294,7 @@ public void cancelOutboundTransfer(Address destination, int topologyId, Set<Inte
             // get an array copy of the collection to avoid ConcurrentModificationException if the entire task gets cancelled and removeTransfer(transferTask) is called
             OutboundTransferTask[] tasks = transferTasks.toArray(new OutboundTransferTask[transferTasks.size()]);
             for (OutboundTransferTask transferTask : tasks) {
-               transferTask.cancelSegments(segments); //this can potentially result in a removeTransfer(transferTask)
+               transferTask.cancelSegments(segments); //this can potentially result in a call to removeTransfer(transferTask)
             }
          }
       }",2012-11-07T14:07:34Z,55
"@@ -36,16 +36,13 @@
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
-import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
 import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
@@ -75,7 +72,7 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
+   public void init(StateTransferLock stateTransferLock, Configuration configuration,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
       this.commandFactory = commandFactory;",2012-11-07T14:07:34Z,115
"@@ -58,13 +58,13 @@ public interface StateTransferLock {
    void releaseSharedTopologyLock();
 
    // transaction data latch
-   void transactionDataReceived(int topologyId);
+   void notifyTransactionDataReceived(int topologyId);
 
    void waitForTransactionData(int expectedTopologyId) throws InterruptedException;
 
    // topology installation latch
    // TODO move this to Cluster/LocalTopologyManagerImpl and don't start requesting state until every node has the jgroups view with the local node
-   void topologyInstalled(int topologyId);
+   void notifyTopologyInstalled(int topologyId);
 
    void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-11-07T14:07:34Z,122
"@@ -23,12 +23,12 @@
 
 package org.infinispan.statetransfer;
 
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+
 /**
  * {@code StateTransferLock} implementation.
  *
@@ -38,6 +38,7 @@
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
+   private static final boolean trace = log.isTraceEnabled();
 
    private final ReadWriteLock ownershipLock = new ReentrantReadWriteLock();
 
@@ -68,8 +69,15 @@ public void releaseSharedTopologyLock() {
    }
 
    @Override
-   public void transactionDataReceived(int topologyId) {
-      this.transactionDataTopologyId = topologyId;
+   public void notifyTransactionDataReceived(int topologyId) {
+      if (topologyId < transactionDataTopologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + transactionDataTopologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling transaction data received for topology %d"", topologyId);
+      }
+      transactionDataTopologyId = topologyId;
       synchronized (transactionDataLock) {
          transactionDataLock.notifyAll();
       }
@@ -80,19 +88,32 @@ public void waitForTransactionData(int expectedTopologyId) throws InterruptedExc
       if (transactionDataTopologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
-            transactionDataTopologyId);
+      if (trace) {
+         log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
+               transactionDataTopologyId);
+      }
       synchronized (transactionDataLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (transactionDataTopologyId < expectedTopologyId) {
             transactionDataLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Received transaction data for topology %d, expected topology was %d"", transactionDataTopologyId,
+               expectedTopologyId);
+      }
    }
 
    @Override
-   public void topologyInstalled(int topologyId) {
+   public void notifyTopologyInstalled(int topologyId) {
+      if (topologyId < this.topologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + this.topologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling topology %d is installed"", topologyId);
+      }
       this.topologyId = topologyId;
       synchronized (topologyLock) {
          topologyLock.notifyAll();
@@ -104,14 +125,18 @@ public void waitForTopology(int expectedTopologyId) throws InterruptedException
       if (topologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId,
-            topologyId);
+      if (trace) {
+         log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId, topologyId);
+      }
       synchronized (topologyLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (topologyId < expectedTopologyId) {
             topologyLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Topology %d is now installed, expected topology was %d"", topologyId, expectedTopologyId);
+      }
    }
 }",2012-11-07T14:07:34Z,123
"@@ -81,4 +81,5 @@ public interface StateTransferManager {
     */
    void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
 
+   void notifyEndOfTopologyUpdate(int topologyId);
 }",2012-11-07T14:07:34Z,116
"@@ -70,7 +70,7 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private GroupManager groupManager;   // optional
    private LocalTopologyManager localTopologyManager;
 
-   private CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
+   private final CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
 
    public StateTransferManagerImpl() {
    }
@@ -170,13 +170,18 @@ private CacheTopology addGrouping(CacheTopology cacheTopology) {
 
    private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalance) {
       if (trace) {
-         log.tracef(""Installing new cache topology %s"", newCacheTopology);
+         log.tracef(""Installing new cache topology %s on cache %s"", newCacheTopology, cacheName);
       }
 
       // handle grouping
       newCacheTopology = addGrouping(newCacheTopology);
 
       CacheTopology oldCacheTopology = stateConsumer.getCacheTopology();
+
+      if (oldCacheTopology != null && oldCacheTopology.getTopologyId() > newCacheTopology.getTopologyId()) {
+         throw new IllegalStateException(""Old topology is higher: old="" + oldCacheTopology + "", new="" + newCacheTopology);
+      }
+
       ConsistentHash oldCH = oldCacheTopology != null ? oldCacheTopology.getWriteConsistentHash() : null;
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
@@ -188,15 +193,17 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
 
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
-      if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
+      boolean isJoined = stateConsumer.getCacheTopology().getReadConsistentHash().getMembers().contains(rpcManager.getAddress());
+      if (initialStateTransferComplete.getCount() > 0 && isJoined) {
          initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
    }
 
    @Start(priority = 1000)
    @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
-      if (trace) log.tracef(""Waiting for initial state transfer to finish"");
+      if (trace) log.tracef(""Waiting for initial state transfer to finish for cache %s on %s"", cacheName, rpcManager.getAddress());
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);
       if (!success) {
          throw new CacheException(String.format(""Initial state transfer timed out for cache %s on %s"",
@@ -210,6 +217,7 @@ public void stop() {
       if (trace) {
          log.tracef(""Shutting down StateTransferManager of cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
+      initialStateTransferComplete.countDown();
       localTopologyManager.leave(cacheName);
    }
 
@@ -268,4 +276,14 @@ public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object>
          }
       }
    }
+
+   @Override
+   public void notifyEndOfTopologyUpdate(int topologyId) {
+      if (initialStateTransferComplete.getCount() > 0
+            && stateConsumer.getCacheTopology().getWriteConsistentHash().getMembers().contains(rpcManager.getAddress())) {
+         initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
+      }
+      localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+   }
 }
\ No newline at end of file",2012-11-07T14:07:34Z,117
"@@ -126,13 +126,17 @@ public void triggerRebalance(final String cacheName) throws Exception {
       asyncTransportExecutor.submit(new Callable<Object>() {
          @Override
          public Object call() throws Exception {
-            startRebalance(cacheName);
-            return null;
+            try {
+               startRebalance(cacheName);
+               return null;
+            } catch (Throwable t) {
+               log.errorf(t, ""Failed to start rebalance: %s"", t.getMessage());
+               throw new Exception(t);
+            }
          }
       });
    }
 
-
    @Override
    public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo joinInfo, int viewId) throws Exception {
       waitForView(viewId);
@@ -594,6 +598,7 @@ public Object call() throws Exception {
             try {
                return command.perform(null);
             } catch (Throwable t) {
+               log.errorf(t, ""Failed to execute ReplicableCommand %s on cluster async: %s"", command, t.getMessage());
                throw new Exception(t);
             }
          }",2012-11-07T14:07:34Z,124
"@@ -280,6 +280,7 @@ public Object call() throws Exception {
                try {
                   return command.perform(null);
                } catch (Throwable t) {
+                  log.errorf(t, ""Failed to execute ReplicableCommand %s on coordinator async: %s"", command, t.getMessage());
                   throw new Exception(t);
                }
             }
@@ -298,8 +299,6 @@ class LocalCacheStatus {
    private final CacheTopologyHandler handler;
    private volatile CacheTopology topology;
 
-   private boolean joined;
-
    public LocalCacheStatus(CacheJoinInfo joinInfo, CacheTopologyHandler handler) {
       this.joinInfo = joinInfo;
       this.handler = handler;
@@ -320,12 +319,4 @@ public CacheTopology getTopology() {
    public void setTopology(CacheTopology topology) {
       this.topology = topology;
    }
-
-   public boolean isJoined() {
-      return joined;
-   }
-
-   public void setJoined(boolean joined) {
-      this.joined = joined;
-   }
 }",2012-11-07T14:07:34Z,125
"@@ -53,15 +53,14 @@ public class StaleTransactionCleanupService {
 
    private static Log log = LogFactory.getLog(StaleTransactionCleanupService.class);
 
+   private ScheduledExecutorService executorService;
 
    private TransactionTable transactionTable;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
-   private ScheduledExecutorService executorService;
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * because the main data owner left. Also unlocks keys for which the lock owner has changed as a result of a topology change.
@@ -71,15 +70,19 @@ public StaleTransactionCleanupService(TransactionTable transactionTable) {
    @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // Roll back remote transactions originating on nodes that have left the cluster.
-      if (tce.isPre()) {
-         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
-         if (consistentHashAtStart != null) {
-            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
-            if (!leavers.isEmpty()) {
-               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-               cleanTxForWhichTheOwnerLeft(leavers);
+      try {
+         if (tce.isPre()) {
+            ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+            if (consistentHashAtStart != null) {
+               List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+               if (!leavers.isEmpty()) {
+                  log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+                  cleanTxForWhichTheOwnerLeft(leavers);
+               }
             }
          }
+      } catch (Exception e) {
+         log.error(""Failed to process topology update"", e);
       }
    }
 
@@ -120,7 +123,6 @@ public void run() {
             transactionTable.cleanupCompletedTransactions();
          }
       }, interval, interval, TimeUnit.MILLISECONDS);
-
    }
 
    public void stop() {",2012-11-07T14:07:34Z,126
"@@ -523,25 +523,29 @@ public boolean isTransactionCompleted(GlobalTransaction gtx) {
    }
 
    public void cleanupCompletedTransactions() {
-      log.debugf(""About to cleanup completed transaction. Initial size is %s"", completedTransactions.size());
-      //this iterator is weekly consistent and will never throw ConcurrentModificationException
-      Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
-      long timeout = configuration.transaction().completedTxTimeout();
-
-      int removedEntries = 0;
-      long beginning = System.nanoTime();
-      while (iterator.hasNext()) {
-         Map.Entry<GlobalTransaction, Long> e = iterator.next();
-         long ageNanos = System.nanoTime() - e.getValue();
-         if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
-            iterator.remove();
-            removedEntries++;
+      try {
+         log.debugf(""About to cleanup completed transaction. Initial size is %d"", completedTransactions.size());
+         //this iterator is weekly consistent and will never throw ConcurrentModificationException
+         Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
+         long timeout = configuration.transaction().completedTxTimeout();
+
+         int removedEntries = 0;
+         long beginning = System.nanoTime();
+         while (iterator.hasNext()) {
+            Map.Entry<GlobalTransaction, Long> e = iterator.next();
+            long ageNanos = System.nanoTime() - e.getValue();
+            if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
+               iterator.remove();
+               removedEntries++;
+            }
          }
-      }
-      long duration = System.nanoTime() - beginning;
+         long duration = System.nanoTime() - beginning;
 
-      log.debugf(""Finished cleaning up completed transactions. %s transactions were removed, total duration was %s millis, "" +
-                      ""current number of completed transactions is %"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
-                 completedTransactions.size());
+         log.debugf(""Finished cleaning up completed transactions. %d transactions were removed, total duration was %d millis, "" +
+                         ""current number of completed transactions is %d"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
+                    completedTransactions.size());
+      } catch (Exception e) {
+         log.errorf(e, ""Failed to cleanup completed transactions: %s"", e.getMessage());
+      }
    }
 }",2012-11-07T14:07:34Z,127
"@@ -24,9 +24,7 @@
 
 import org.infinispan.CacheException;
 import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.commands.tx.PrepareCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.bucket.Bucket;
 import org.infinispan.loaders.decorators.SingletonStore;
@@ -60,7 +58,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.UUID;
-import java.util.concurrent.ExecutionException;
 
 import static org.jboss.logging.Logger.Level.*;
 
@@ -131,26 +128,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Can not select %s random members for %s"", id = 8)
    void cannotSelectRandomMembers(int numNeeded, List<Address> members);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Detected a view change. Member list changed from %s to %s"", id = 9)
-   void viewChangeDetected(List<Address> oldMembers, List<Address> newMembers);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a JOIN event! Wait for notification from new joiner %s"", id = 10)
-   void joinEvent(Address joiner);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a LEAVE event! Node %s has just left"", id = 11)
-   void leaveEvent(Address leaver);
-
-   @LogMessage(level = FATAL)
-   @Message(value = ""Unable to process leaver!!"", id = 12)
-   void unableToProcessLeaver(@Cause Exception e);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""I %s am participating in rehash, state providers %s, state receivers %s"", id = 13)
-   void participatingInRehash(Address address, List<Address> stateProviders, List<Address> receiversOfLeaverState);
-
    @LogMessage(level = INFO)
    @Message(value = ""DistributionManager not yet joined the cluster. Cannot do anything about other concurrent joiners."", id = 14)
    void distributionManagerNotJoined();
@@ -163,10 +140,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Problem %s encountered when applying state for key %s!"", id = 16)
    void problemApplyingStateForKey(String msg, Object key);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""View change interrupted; not rehashing!"", id = 17)
-   void viewChangeInterrupted();
-
    @LogMessage(level = WARN)
    @Message(value = ""Unable to apply prepare %s"", id = 18)
    void unableToApplyPrepare(PrepareCommand pc, @Cause Throwable t);
@@ -175,26 +148,10 @@ public interface Log extends BasicLogger {
    @Message(value = ""Couldn't acquire shared lock"", id = 19)
    void couldNotAcquireSharedLock();
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Caught exception replaying %s"", id = 20)
-   void exceptionWhenReplaying(WriteCommand cmd, @Cause Exception e);
-
    @LogMessage(level = WARN)
    @Message(value = ""Expected just one response; got %s"", id = 21)
    void expectedJustOneResponse(Map<Address, Response> lr);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Completed leave rehash on node %s in %s - leavers now are %s"", id = 22)
-   void completedLeaveRehash(Address self, String duration, List<Address> leavers);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error pushing tx log"", id = 23)
-   void errorPushingTxLog(@Cause ExecutionException e);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Unable to stop transaction logging!"", id = 24)
-   void unableToStopTransactionLogging(@Cause IllegalMonitorStateException imse);
-
    @LogMessage(level = INFO)
    @Message(value = ""wakeUpInterval is <= 0, not starting expired purge thread"", id = 25)
    void notStartingEvictionThread();
@@ -211,7 +168,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unable to passivate entry under %s"", id = 28)
    void unableToPassivateEntry(Object key, @Cause Exception e);
 
-
    @LogMessage(level = INFO)
    @Message(value = ""Passivating all entries to disk"", id = 29)
    void passivatingAllEntries();
@@ -296,14 +252,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Interrupted or timeout while waiting for AsyncStore worker threads to push all state to the decorated store"", id = 48)
    void interruptedWaitingAsyncStorePush(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing clear in async store"", id = 49)
-   void errorClearinAsyncStore(@Cause CacheLoaderException e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing purging expired from async store"", id = 50)
-   void errorPurgingAsyncStore(@Cause CacheLoaderException e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Unexpected error"", id = 51)
    void unexpectedErrorInAsyncProcessor(@Cause Throwable t);
@@ -376,14 +324,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Cache named %s does not exist on this cache manager!"", id = 68)
    void namedCacheDoesNotExist(String cacheName);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Cache named [%s] exists but isn't in a state to handle remote invocations"", id = 69)
-   void cacheCanNotHandleInvocations(String cacheName);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Quietly ignoring clustered get call %s since unable to acquire processing lock, even after %s"", id = 70)
-   void ignoreClusterGetCall(CacheRpcCommand cmd, String time);
-
    @LogMessage(level = WARN)
    @Message(value = ""Caught exception when handling command %s"", id = 71)
    void exceptionHandlingCommand(ReplicableCommand cmd, @Cause Throwable t);
@@ -396,18 +336,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unexpected error while replicating"", id = 73)
    void unexpectedErrorReplicating(@Cause Throwable t);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Trying to fetch state from %s"", id = 74)
-   void tryingToFetchState(Address member);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Could not find available peer for state, backing off and retrying"", id = 75)
-   void couldNotFindPeerForState();
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Successfully retrieved and applied state from %s"", id = 76)
-   void successfullyAppliedState(Address member);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Message or message buffer is null or empty."", id = 77)
    void msgOrMsgBufferEmpty();
@@ -461,15 +389,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""getCoordinator(): Interrupted while waiting for members to be set"", id = 89)
    void interruptedWaitingForCoordinator(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Unable to retrieve state from member %s"", id = 90)
-   void unableToRetrieveState(Address member, @Cause Exception e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Channel does not contain STREAMING_STATE_TRANSFER. "" +
-         ""Cannot support state transfers!"", id = 91)
-   void streamingStateTransferNotPresent();
-
    @LogMessage(level = WARN)
    @Message(value = ""Channel not set up properly!"", id = 92)
    void channelNotSetUp();
@@ -482,10 +401,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Received new cluster view: %s"", id = 94)
    void receivedClusterView(View newView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Caught while requesting or applying state"", id = 96)
-   void errorRequestingOrApplyingState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error while processing a prepare in a single-phase transaction"", id = 97)
    void errorProcessing1pcPrepareCommand(@Cause Throwable e);
@@ -688,14 +603,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Failed loading value for key %s from cache store"", id = 144)
    void failedLoadingValueFromCacheStore(Object key, @Cause Exception e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error during rehash"", id = 145)
-   void errorDuringRehash(@Cause Throwable th);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error transferring state to node after rehash"", id = 146)
-   void errorTransferringState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error invalidating keys from L1 after rehash"", id = 147)
    void failedToInvalidateKeys(@Cause Exception e);
@@ -729,14 +636,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Unable to unlock keys %2$s for transaction %1$s after they were rebalanced off node %3$s"", id = 154)
    void unableToUnlockRebalancedKeys(GlobalTransaction gtx, List<Object> keys, Address self, @Cause Throwable t);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm pushing data for view %d, received confirmations %s. Cancelling state transfer"", id = 157)
-   void stateTransferTimeoutWaitingForPushConfirmations(int viewId, Map<Address, Integer> pushConfirmations);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm joining for view %d, joined %s. Cancelling state transfer"", id = 158)
-   void stateTransferTimeoutWaitingForJoinConfirmations(int viewId, Map<Address, Integer> joinConfirmations);
-
    @LogMessage(level = WARN)
    @Message(value = ""Unblocking transactions failed"", id = 159)
    void errorUnblockingTransactions(@Cause Exception e);
@@ -761,26 +660,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Rolling back to cache view %d, but last committed view is %d"", id = 164)
    void cacheViewRollbackIdMismatch(int committedViewId, int committedView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error triggering a view installation for cache %s"", id = 165)
-   void errorTriggeringViewInstallation(@Cause RuntimeException e, String cacheName);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""View installation failed for cache %s"", id = 166)
-   void viewInstallationFailure(@Cause Throwable e, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Rejecting state pushed by node %s for view %d, there is no state transfer in progress (we are at view %d)"", id = 167)
-   void remoteStateRejected(Address sender, int viewId, int installedViewId);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error rolling back to cache view %1$d for cache %2$s"", id = 168)
-   void cacheViewRollbackFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error committing cache view %1$d for cache %2$s"", id = 169)
-   void cacheViewCommitFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
    @LogMessage(level = INFO)
    @Message(value = ""Strict peer-to-peer is enabled but the JGroups channel was started externally - this is very likely to result in RPC timeout errors on startup"", id = 171)
    void warnStrictPeerToPeerWithInjectedChannel();
@@ -926,5 +805,16 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @LogMessage(level = WARN)
    @Message(value = ""Could not interrupt as no thread found for command uuid %s"", id=207)
    void couldNotInterruptThread(UUID id);
-   
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""No live owners found for segment %d of cache %s. Current owners are:  %s. Faulty owners: %s"", id=208)
+   void noLiveOwnersFoundForSegment(int segmentId, String cacheName, Collection<Address> owners, Collection<Address> faultySources);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to retrieve transactions for segments %s of cache %s from node %s (node will not be retried)"", id=209)
+   void failedToRetrieveTransactionsForSegments(Collection<Integer> segments, String cacheName, Address source);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to request segments %s of cache %s from node %s (node will not be retried)"", id=210)
+   void failedToRequestSegments(Collection<Integer> segments, String cacheName, Address source);
 }",2012-11-07T14:07:34Z,45
"@@ -263,7 +263,7 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm, boolean deprecated) {
 
       assert gc.asyncTransportExecutor().factory() instanceof DefaultExecutorFactory;
       // Should be 25, but it's overriden by the test cache manager factory
-      assertEquals(""4"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
+      assertEquals(""6"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
       assert gc.asyncTransportExecutor().properties().getProperty(""threadNamePrefix"").equals(""AsyncSerializationThread"");
 
       assert gc.evictionScheduledExecutor().factory() instanceof DefaultScheduledExecutorFactory;",2012-11-07T14:07:34Z,128
"@@ -50,7 +50,6 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -126,7 +125,7 @@ public void test1() throws Exception {
       when(cache.getName()).thenReturn(""testCache"");
 
       StateProvider stateProvider = mock(StateProvider.class);
-      LocalTopologyManager localTopologyManager = mock(LocalTopologyManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
       CacheNotifier cacheNotifier = mock(CacheNotifier.class);
       ExecutorService mockExecutorService = mock(ExecutorService.class);
       RpcManager rpcManager = mock(RpcManager.class);
@@ -183,7 +182,7 @@ public Map<Address, Response> answer(InvocationOnMock invocation) {
 
       // create state provider
       StateConsumerImpl stateConsumer = new StateConsumerImpl();
-      stateConsumer.init(cache, localTopologyManager, interceptorChain, icc, configuration, rpcManager,
+      stateConsumer.init(cache, stateTransferManager, interceptorChain, icc, configuration, rpcManager,
             commandsFactory, cacheLoaderManager, dataContainer, transactionTable, stateTransferLock);
       stateConsumer.start();
 ",2012-11-07T14:07:34Z,56
"@@ -40,6 +40,7 @@
 
 /**
  * Test if state transfer happens properly on a cache with pessimistic transactions.
+ * See https://issues.jboss.org/browse/ISPN-2408.
  *
  * @since 5.2
  */",2012-11-07T14:07:34Z,129
"@@ -75,6 +75,8 @@
  */
 public class TestCacheManagerFactory {
 
+   private static final int MAX_ASYNC_EXEC_THREADS = 6;
+
    public static final String MARSHALLER = LegacyKeySupportSystemProperties.getProperty(""infinispan.test.marshaller.class"", ""infinispan.marshaller.class"");
    private static final Log log = LogFactory.getLog(TestCacheManagerFactory.class);
 
@@ -523,12 +525,12 @@ private static void checkTestName(String fullTestName) {
 
    public static void minimizeThreads(GlobalConfiguration gc) {
       Properties p = new Properties();
-      p.setProperty(""maxThreads"", ""4"");
+      p.setProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
       gc.setAsyncTransportExecutorProperties(p);
    }
 
    public static void minimizeThreads(GlobalConfigurationBuilder builder) {
-      builder.asyncTransportExecutor().addProperty(""maxThreads"", ""4"");
+      builder.asyncTransportExecutor().addProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
    }
 
    public static void amendMarshaller(GlobalConfiguration configuration) {",2012-11-07T14:07:34Z,130
"@@ -161,13 +161,12 @@ public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo
       waitForView(viewId);
 
       rebalancePolicy.initCache(cacheName, joinInfo);
-      rebalancePolicy.updateMembersList(cacheName, Collections.singletonList(joiner), Collections.<Address>emptyList());
-      return rebalancePolicy.getTopology(cacheName);
+      return rebalancePolicy.addJoiners(cacheName, Collections.singletonList(joiner));
    }
 
    @Override
    public void handleLeave(String cacheName, Address leaver, int viewId) throws Exception {
-      rebalancePolicy.updateMembersList(cacheName, Collections.<Address>emptyList(), Collections.singletonList(leaver));
+      rebalancePolicy.removeLeavers(cacheName, Collections.singletonList(leaver));
    }
 
    @Override",2012-08-31T21:05:51Z,124
"@@ -110,18 +110,26 @@ public void initCache(String cacheName, List<CacheTopology> partitionTopologies)
 
       synchronized (cacheStatus) {
          CacheTopology cacheTopology = new CacheTopology(unionTopologyId, currentCHUnion, pendingCHUnion);
-         updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+         updateConsistentHash(cacheName, cacheStatus, cacheTopology, true);
          // TODO Trigger a new rebalance
       }
    }
 
    /**
     * Should only be called while holding the cacheStatus lock
     */
-   private void updateConsistentHash(String cacheName, CacheStatus cacheStatus, CacheTopology cacheTopology) throws Exception {
+   private void updateConsistentHash(String cacheName, CacheStatus cacheStatus, CacheTopology cacheTopology,
+                                     boolean broadcast) throws Exception {
       log.tracef(""Updating cache %s topology: %s"", cacheName, cacheTopology);
       cacheStatus.setCacheTopology(cacheTopology);
-      clusterTopologyManager.updateConsistentHash(cacheName, cacheStatus.getCacheTopology());
+      ConsistentHash currentCH = cacheTopology.getCurrentCH();
+      if (currentCH != null) {
+         cacheStatus.getJoiners().removeAll(currentCH.getMembers());
+         log.tracef(""Updated joiners list for cache %s: %s"", cacheName, cacheStatus.getJoiners());
+      }
+      if (broadcast) {
+         clusterTopologyManager.updateConsistentHash(cacheName, cacheStatus.getCacheTopology());
+      }
    }
 
    @Override
@@ -142,30 +150,9 @@ public void updateMembersList(List<Address> newClusterMembers) throws Exception
             boolean currentMembersValid = newClusterMembers.containsAll(currentCH.getMembers());
             boolean pendingMembersValid = pendingCH == null || newClusterMembers.containsAll(pendingCH.getMembers());
             if (!currentMembersValid || !pendingMembersValid) {
-               int topologyId = cacheStatus.getCacheTopology().getTopologyId();
-               ConsistentHashFactory consistentHashFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
-
                List<Address> newCurrentMembers = new ArrayList<Address>(currentCH.getMembers());
                newCurrentMembers.retainAll(newClusterMembers);
-               if (newCurrentMembers.isEmpty()) {
-                  log.tracef(""Zero members remaining for cache %s"", cacheName);
-                  return;
-               }
-               ConsistentHash newCurrentCH = consistentHashFactory.updateMembers(currentCH, newCurrentMembers);
-
-               ConsistentHash newPendingCH = null;
-               if (pendingCH != null) {
-                  List<Address> newPendingMembers = new ArrayList<Address>(cacheStatus.getCacheTopology().getMembers());
-                  newPendingMembers.retainAll(newClusterMembers);
-                  if (newPendingMembers.isEmpty()) {
-                     log.tracef(""Zero members remaining for cache %s"", cacheName);
-                     return;
-                  }
-                  newPendingCH = consistentHashFactory.updateMembers(pendingCH, newPendingMembers);
-               }
-
-               CacheTopology cacheTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
-               updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+               updateCacheMembers(cacheName, cacheStatus, newCurrentMembers);
             }
 
             if (!isBalanced(cacheStatus.getCacheTopology().getCurrentCH()) || !cacheStatus.getJoiners().isEmpty()) {
@@ -179,62 +166,80 @@ public void updateMembersList(List<Address> newClusterMembers) throws Exception
    }
 
    @Override
-   public void updateMembersList(String cacheName, List<Address> joiners, List<Address> leavers) throws Exception {
-      // TODO Separate into two methods, join() and leave()
+   public CacheTopology addJoiners(String cacheName, List<Address> joiners) throws Exception {
       CacheStatus cacheStatus = cacheStatusMap.get(cacheName);
       if (cacheStatus == null) {
          log.tracef(""Ignoring members update for cache %s, as we haven't initialized it yet"", cacheName);
-         return;
+         return null;
       }
 
-      CacheJoinInfo joinInfo = cacheStatus.getJoinInfo();
-      if (!leavers.isEmpty()) {
-         synchronized (cacheStatus) {
-            int topologyId = cacheStatus.getCacheTopology().getTopologyId();
-            ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
-            ConsistentHash pendingCH = cacheStatus.getCacheTopology().getPendingCH();
-
-            // The list of ""current"" members will always be included in the set of ""pending"" members,
-            // because leaves are reflected at the same time in both collections
-            List<Address> newMembers = new ArrayList<Address>(clusterMembers);
-            newMembers.removeAll(leavers);
+      synchronized (cacheStatus) {
+         addUniqueJoiners(cacheStatus.getJoiners(), joiners);
 
-            ConsistentHash newPendingCH = null;
-            if (pendingCH != null) {
-               newMembers.retainAll(pendingCH.getMembers());
-               if (newMembers.isEmpty()) {
-                  log.tracef(""Zero members remaining for cache %s"", cacheName);
-                  return;
-               }
+         ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
+         if (currentCH == null) {
+            installInitialTopology(cacheName, cacheStatus);
+         } else {
+            triggerRebalance(cacheName, cacheStatus);
+         }
+         return cacheStatus.getCacheTopology();
+      }
+   }
 
-               newPendingCH = joinInfo.getConsistentHashFactory().updateMembers(pendingCH, newMembers);
-            }
+   @Override
+   public void removeLeavers(String cacheName, List<Address> leavers) throws Exception {
+      CacheStatus cacheStatus = cacheStatusMap.get(cacheName);
+      if (cacheStatus == null) {
+         log.tracef(""Ignoring members update for cache %s, as we haven't initialized it yet"", cacheName);
+         return;
+      }
 
-            newMembers.retainAll(currentCH.getMembers());
-            if (newMembers.isEmpty()) {
-               log.tracef(""Zero members remaining for cache %s"", cacheName);
-               return;
-            }
-            ConsistentHash newCurrentCH = joinInfo.getConsistentHashFactory().updateMembers(currentCH, newMembers);
+      synchronized (cacheStatus) {
+         // The list of ""current"" members will always be included in the set of ""pending"" members,
+         // because leaves are reflected at the same time in both collections
+         List<Address> newMembers = new ArrayList<Address>(clusterMembers);
+         newMembers.removeAll(leavers);
 
-            CacheTopology cacheTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
-            updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+         updateCacheMembers(cacheName, cacheStatus, newMembers);
+      }
+   }
 
-            triggerRebalance(cacheName, cacheStatus);
+   private void updateCacheMembers(String cacheName, CacheStatus cacheStatus, List<Address> newMembers)
+         throws Exception {
+      CacheJoinInfo joinInfo = cacheStatus.getJoinInfo();
+      int topologyId = cacheStatus.getCacheTopology().getTopologyId();
+      ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
+      ConsistentHash pendingCH = cacheStatus.getCacheTopology().getPendingCH();
+
+      ConsistentHash newPendingCH = null;
+      if (pendingCH != null) {
+         newMembers.retainAll(pendingCH.getMembers());
+         if (!newMembers.isEmpty()) {
+            newPendingCH = joinInfo.getConsistentHashFactory().updateMembers(pendingCH, newMembers);
+         } else {
+            log.tracef(""Zero new members remaining for cache %s"", cacheName);
          }
       }
 
-      if (!joiners.isEmpty()) {
-         synchronized (cacheStatus) {
-            addUniqueJoiners(cacheStatus.getJoiners(), joiners);
+      newMembers.retainAll(currentCH.getMembers());
+      ConsistentHash newCurrentCH;
+      if (!newMembers.isEmpty()) {
+         newCurrentCH = joinInfo.getConsistentHashFactory().updateMembers(currentCH, newMembers);
+      } else {
+         log.tracef(""Zero old members remaining for cache %s"", cacheName);
+         // use the new pending CH, it might be non-null if we have joiners
+         newCurrentCH = newPendingCH;
+      }
 
-            ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
-            if (currentCH == null) {
-               installInitialTopology(cacheName, cacheStatus);
-            } else {
-               triggerRebalance(cacheName, cacheStatus);
-            }
-         }
+      boolean hasMembers = newCurrentCH != null;
+      CacheTopology cacheTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
+
+      // Don't broadcast a cache topology when we don't have any members left
+      updateConsistentHash(cacheName, cacheStatus, cacheTopology, hasMembers);
+
+      // Don't trigger a rebalance without any members either
+      if (hasMembers) {
+         triggerRebalance(cacheName, cacheStatus);
       }
    }
 
@@ -247,7 +252,7 @@ private void installInitialTopology(String cacheName, CacheStatus cacheStatus) t
       CacheTopology cacheTopology = new CacheTopology(newTopologyId, balancedCH, null);
 
       log.tracef(""Installing initial topology for cache %s: %s"", cacheName, cacheTopology);
-      updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+      updateConsistentHash(cacheName, cacheStatus, cacheTopology, false);
    }
 
    private void addUniqueJoiners(List<Address> members, List<Address> joiners) {
@@ -269,33 +274,49 @@ public Object call() throws Exception {
    }
 
    private void doRebalance(String cacheName, CacheStatus cacheStatus) throws Exception {
+      CacheTopology cacheTopology = cacheStatus.getCacheTopology();
+      CacheTopology newCacheTopology;
+
       synchronized (cacheStatus) {
-         boolean isRebalanceInProgress = cacheStatus.getCacheTopology().getPendingCH() != null;
+         boolean isRebalanceInProgress = cacheTopology.getPendingCH() != null;
          if (isRebalanceInProgress) {
-            log.tracef(""Ignoring request to start rebalancing cache %s, there's already a rebalance in progress: %s"",
-                  cacheName, cacheStatus.getCacheTopology());
+            log.tracef(""Ignoring request to rebalance cache %s, there's already a rebalance in progress: %s"",
+                  cacheName, cacheTopology);
+            return;
+         }
+
+         List<Address> newMembers = new ArrayList<Address>(cacheTopology.getMembers());
+         if (newMembers.isEmpty()) {
+            log.tracef(""Ignoring request to rebalance cache %s, it doesn't have any member"", cacheName);
             return;
          }
 
-         List<Address> newMembers = new ArrayList<Address>(cacheStatus.getCacheTopology().getMembers());
          addUniqueJoiners(newMembers, cacheStatus.getJoiners());
          newMembers.retainAll(clusterMembers);
+
          log.tracef(""Rebalancing consistent hash for cache %s, members are %s"", cacheName, newMembers);
+         int newTopologyId = cacheTopology.getTopologyId() + 1;
+         ConsistentHash currentCH = cacheTopology.getCurrentCH();
+         if (currentCH == null) {
+            // There was one node in the cache before, and it left after the rebalance was triggered
+            // but before the rebalance actually started.
+            installInitialTopology(cacheName, cacheStatus);
+            return;
+         }
 
-         int newTopologyId = cacheStatus.getCacheTopology().getTopologyId() + 1;
-         ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
          ConsistentHashFactory chFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
          ConsistentHash updatedMembersCH = chFactory.updateMembers(currentCH, newMembers);
          ConsistentHash balancedCH = chFactory.rebalance(updatedMembersCH);
          if (balancedCH.equals(currentCH)) {
             log.tracef(""The balanced CH is the same as the current CH, not rebalancing"");
             return;
          }
-         CacheTopology cacheTopology = new CacheTopology(newTopologyId, currentCH, balancedCH);
-         log.tracef(""Updating cache %s topology for rebalance: %s"", cacheName, cacheTopology);
-         cacheStatus.setCacheTopology(cacheTopology);
+         newCacheTopology = new CacheTopology(newTopologyId, currentCH, balancedCH);
+         log.tracef(""Updating cache %s topology for rebalance: %s"", cacheName, newCacheTopology);
+         cacheStatus.setCacheTopology(newCacheTopology);
       }
-      clusterTopologyManager.rebalance(cacheName, cacheStatus.getCacheTopology());
+
+      clusterTopologyManager.rebalance(cacheName, newCacheTopology);
    }
 
    @Override
@@ -312,7 +333,7 @@ public void onRebalanceCompleted(String cacheName, int topologyId) throws Except
          ConsistentHash newCurrentCH = cacheStatus.getCacheTopology().getPendingCH();
 
          CacheTopology cacheTopology = new CacheTopology(newTopologyId, newCurrentCH, null);
-         updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+         updateConsistentHash(cacheName, cacheStatus, cacheTopology, true);
 
          // Update the list of joiners
          // TODO Add some cleanup for nodes that left the cluster before getting any state",2012-08-31T21:05:51Z,597
"@@ -55,9 +55,15 @@ public interface RebalancePolicy {
    void updateMembersList(List<Address> membersList) throws Exception;
 
    /**
-    * Called when a member joins or leaves an individual cache.
+    * Called when one or more members join a cache.
+    * @return The previous cache topology.
     */
-   void updateMembersList(String cacheName, List<Address> joiners, List<Address> leavers) throws Exception;
+   CacheTopology addJoiners(String cacheName, List<Address> joiners) throws Exception;
+
+   /**
+    * Called when one or more members leave an individual cache (as opposed to leaving the cluster).
+    */
+   void removeLeavers(String cacheName, List<Address> leavers) throws Exception;
 
    /**
     * Called when every member has completed receiving data.",2012-08-31T21:05:51Z,598
"@@ -30,7 +30,6 @@
 import org.testng.annotations.Test;
 
 import java.util.List;
-import java.util.Set;
 
 /**
  * @author Mircea Markus
@@ -73,17 +72,17 @@ public void run() {
          @Override
          public boolean isSatisfied() throws Exception {
             List<Address> members = advancedCache(0).getRpcManager().getTransport().getMembers();
-            System.out.println(""members = "" + members);
+            log.trace(""members = "" + members);
             return members.size() == 1;
          }
       });
 
-      System.out.println(""MultipleNodesLeavingTest.testMultipleLeaves"");
+      log.trace(""MultipleNodesLeavingTest.testMultipleLeaves"");
 
       TestingUtil.blockUntilViewsReceived(60000, false, cache(0));
       TestingUtil.waitForRehashToComplete(cache(0));
       List<Address> caches = advancedCache(0).getDistributionManager().getConsistentHash().getMembers();
-      System.out.println(""caches = "" + caches);
+      log.tracef(""caches = %s"", caches);
       int size = caches.size();
       assert size == 1;
    }",2012-10-02T12:10:18Z,599
"@@ -71,13 +71,12 @@
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.marshall.jboss.ExternalizerTable;
 import org.infinispan.remoting.ReplicationQueue;
-import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.remoting.transport.jgroups.JGroupsTransport;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.topology.DefaultRebalancePolicy;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.topology.RebalancePolicy;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.util.concurrent.locks.LockManager;
@@ -167,14 +166,14 @@ public static void waitForRehashToComplete(Cache... caches) {
       // give it 1 second to start rehashing
       // TODO Should look at the last committed view instead and check if it contains all the caches
       LockSupport.parkNanos(TimeUnit.SECONDS.toNanos(1));
-      int gracetime = 90000; // 60 seconds
+      int gracetime = 90000; // 90 seconds
       long giveup = System.currentTimeMillis() + gracetime;
       for (Cache c : caches) {
-         LocalTopologyManager localTopologyManager = TestingUtil.extractGlobalComponent(c.getCacheManager(), LocalTopologyManager.class);
+         StateTransferManager stateTransferManager = TestingUtil.extractComponent(c, StateTransferManager.class);
          DefaultRebalancePolicy rebalancePolicy = (DefaultRebalancePolicy) TestingUtil.extractGlobalComponent(c.getCacheManager(), RebalancePolicy.class);
-         RpcManager rpcManager = TestingUtil.extractComponent(c, RpcManager.class);
+         Address cacheAddress = c.getAdvancedCache().getRpcManager().getAddress();
          while (true) {
-            CacheTopology cacheTopology = localTopologyManager.getCacheTopology(c.getName());
+            CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
             boolean chContainsAllMembers = cacheTopology.getCurrentCH().getMembers().size() == caches.length;
             boolean chIsBalanced = rebalancePolicy.isBalanced(cacheTopology.getCurrentCH());
             boolean stateTransferInProgress = cacheTopology.getPendingCH() != null;
@@ -190,7 +189,7 @@ public static void waitForRehashToComplete(Cache... caches) {
                   }
                   message = String.format(""Timed out waiting for rebalancing to complete on node %s, "" +
                         ""expected member list is %s, current member list is %s!"",
-                        rpcManager.getAddress(), Arrays.toString(addresses), cacheTopology.getCurrentCH().getMembers());
+                        cacheAddress, Arrays.toString(addresses), cacheTopology.getCurrentCH().getMembers());
                } else {
                   message = String.format(""Timed out waiting for rebalancing to complete on node %s, "" +
                         ""current topology is %s"", c.getCacheManager().getAddress(), cacheTopology);
@@ -201,7 +200,7 @@ public static void waitForRehashToComplete(Cache... caches) {
 
             LockSupport.parkNanos(TimeUnit.MILLISECONDS.toNanos(100));
          }
-         log.trace(""Node "" + rpcManager.getAddress() + "" finished state transfer."");
+         log.trace(""Node "" + cacheAddress + "" finished state transfer."");
       }
    }
 ",2012-10-02T12:10:18Z,50
"@@ -79,6 +79,7 @@
 import org.infinispan.statetransfer.StateChunk;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.xa.DldGlobalTransaction;
@@ -128,6 +129,7 @@ public class CommandsFactoryImpl implements CommandsFactory {
    private LockManager lockManager;
    private InternalEntryFactory entryFactory;
    private MapReduceManager mapReduceManager;
+   private StateTransferManager stateTransferManager;
 
    private Map<Byte, ModuleCommandInitializer> moduleCommandInitializers;
 
@@ -137,7 +139,7 @@ public void setupDependencies(DataContainer container, CacheNotifier notifier, C
                                  InvocationContextContainer icc, TransactionTable txTable, Configuration configuration,
                                  @ComponentName(KnownComponentNames.MODULE_COMMAND_INITIALIZERS) Map<Byte, ModuleCommandInitializer> moduleCommandInitializers,
                                  RecoveryManager recoveryManager, StateProvider stateProvider, StateConsumer stateConsumer,
-                                 LockManager lockManager, InternalEntryFactory entryFactory, MapReduceManager mapReduceManager) {
+                                 LockManager lockManager, InternalEntryFactory entryFactory, MapReduceManager mapReduceManager, StateTransferManager stm) {
       this.dataContainer = container;
       this.notifier = notifier;
       this.cache = cache;
@@ -153,6 +155,7 @@ public void setupDependencies(DataContainer container, CacheNotifier notifier, C
       this.lockManager = lockManager;
       this.entryFactory = entryFactory;
       this.mapReduceManager = mapReduceManager;
+      this.stateTransferManager = stm;
    }
 
    @Start(priority = 1)
@@ -402,7 +405,7 @@ public void initializeReplicableCommand(ReplicableCommand c, boolean isRemote) {
             break;
          case TxCompletionNotificationCommand.COMMAND_ID:
             TxCompletionNotificationCommand ftx = (TxCompletionNotificationCommand) c;
-            ftx.init(txTable, lockManager, recoveryManager);
+            ftx.init(txTable, lockManager, recoveryManager, stateTransferManager);
             break;
          case MapCombineCommand.COMMAND_ID:
             MapCombineCommand mrc = (MapCombineCommand)c;",2012-10-12T16:37:21Z,111
"@@ -36,7 +36,7 @@
  * @author Sanne Grinovero <sanne@hibernate.org> (C) 2011 Red Hat Inc.
  * @since 5.0
  */
-public interface FlagAffectedCommand extends TopologyAffectedCommand {
+public interface FlagAffectedCommand extends VisitableCommand, TopologyAffectedCommand {
    
    /**
     * @return the Flags which where set in the context - only valid to invoke after {@link #setFlags(Set)}",2012-10-12T16:37:21Z,112
"@@ -28,7 +28,7 @@
  * @author anistor@redhat.com
  * @since 5.2
  */
-public interface TopologyAffectedCommand extends VisitableCommand {
+public interface TopologyAffectedCommand extends ReplicableCommand {
 
    int getTopologyId();
 ",2012-10-12T16:37:21Z,113
"@@ -22,7 +22,9 @@
  */
 package org.infinispan.commands.remote.recovery;
 
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.context.InvocationContext;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.xa.GlobalTransaction;
@@ -32,14 +34,15 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.xa.Xid;
+import java.util.Set;
 
 /**
  * Command for removing recovery related information from the cluster.
  *
  * @author Mircea.Markus@jboss.com
  * @since 5.0
  */
-public class TxCompletionNotificationCommand extends RecoveryCommand {
+public class TxCompletionNotificationCommand  extends RecoveryCommand implements TopologyAffectedCommand {
 
    private static Log log = LogFactory.getLog(TxCompletionNotificationCommand.class);
 
@@ -50,6 +53,8 @@ public class TxCompletionNotificationCommand extends RecoveryCommand {
    private GlobalTransaction gtx;
    private TransactionTable txTable;
    private LockManager lockManager;
+   private StateTransferManager stateTransferManager;
+   private int topologyId;
 
    private TxCompletionNotificationCommand() {
       super(null); // For command id uniqueness test
@@ -61,10 +66,11 @@ public TxCompletionNotificationCommand(Xid xid, GlobalTransaction gtx, String ca
       this.gtx = gtx;
    }
 
-   public void init(TransactionTable tt, LockManager lockManager, RecoveryManager rm) {
+   public void init(TransactionTable tt, LockManager lockManager, RecoveryManager rm, StateTransferManager stm) {
       super.init(rm);
       this.txTable = tt;
       this.lockManager = lockManager;
+      this.stateTransferManager = stm;
    }
 
 
@@ -77,6 +83,21 @@ public TxCompletionNotificationCommand(String cacheName) {
       super(cacheName);
    }
 
+   @Override
+   public int getTopologyId() {
+      return topologyId;
+   }
+
+   @Override
+   public void setTopologyId(int topologyId) {
+      this.topologyId = topologyId;
+   }
+
+   @Override
+   public boolean isReturnValueExpected() {
+      return false;
+   }
+
    @Override
    public Object perform(InvocationContext ctx) throws Throwable {
       log.tracef(""Processing completed transaction %s"", gtx);
@@ -92,10 +113,21 @@ public Object perform(InvocationContext ctx) throws Throwable {
          remoteTx = txTable.removeRemoteTransaction(gtx);
       }
       if (remoteTx == null) return null;
+      forwardCommandRemotely(remoteTx);
+
       lockManager.unlock(remoteTx.getLockedKeys(), remoteTx.getGlobalTransaction());
       return null;
    }
 
+   /**
+    * This only happens during state transfer.
+    */
+   private void forwardCommandRemotely(RemoteTransaction remoteTx) {
+      Set<Object> affectedKeys = remoteTx.getAffectedKeys();
+      log.tracef(""Invoking forward of TxCompletionNotification for transaction %s. Affected keys: %w"", gtx, affectedKeys);
+      stateTransferManager.forwardCommandIfNeeded(this, affectedKeys, false);
+   }
+
    @Override
    public byte getCommandId() {
       return COMMAND_ID;
@@ -124,6 +156,7 @@ public String toString() {
       return getClass().getSimpleName() +
             ""{ xid="" + xid +
             "", internalId="" + internalId +
+            "", topologyId="" + topologyId +
             "", gtx="" + gtx +
             "", cacheName="" + cacheName + ""} "";
    }",2012-10-12T16:37:21Z,114
"@@ -34,20 +34,18 @@
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.remoting.transport.Address;
-import org.infinispan.topology.CacheTopology;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.*;
+import java.util.Collections;
+import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
 /**
@@ -60,20 +58,16 @@ public class StateTransferInterceptor extends CommandInterceptor {   //todo [ani
 
    private static final Log log = LogFactory.getLog(StateTransferInterceptor.class);
 
-   private final AffectedKeysVisitor affectedKeysVisitor = new AffectedKeysVisitor();
-
    private StateTransferLock stateTransferLock;
 
    private StateTransferManager stateTransferManager;
 
-   private RpcManager rpcManager;
-
    private CommandsFactory commandFactory;
 
-   private long rpcTimeout;
-
    private boolean useVersioning;
 
+   private final AffectedKeysVisitor affectedKeysVisitor = new AffectedKeysVisitor();
+
    @Override
    protected Log getLog() {
       return log;
@@ -83,14 +77,9 @@ protected Log getLog() {
    public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
-      this.rpcManager = rpcManager;
       this.commandFactory = commandFactory;
       this.stateTransferManager = stateTransferManager;
 
-      // no need to retry for asynchronous caches
-      rpcTimeout = configuration.clustering().cacheMode().isSynchronous()
-            ? configuration.clustering().sync().replTimeout() : 0;
-
       useVersioning = configuration.transaction().transactionMode().isTransactional() && configuration.locking().writeSkewCheck() &&
             configuration.transaction().lockingMode() == LockingMode.OPTIMISTIC && configuration.versioning().enabled();
    }
@@ -205,25 +194,32 @@ private Object handleWriteCommand(InvocationContext ctx, WriteCommand command) t
    @Override
    protected Object handleDefault(InvocationContext ctx, VisitableCommand command) throws Throwable {
       if (command instanceof TopologyAffectedCommand) {
-         return handleTopologyAffectedCommand(ctx, (TopologyAffectedCommand) command, ctx.isOriginLocal());
+         return handleTopologyAffectedCommand(ctx, command, ctx.isOriginLocal());
       } else {
          return invokeNextInterceptor(ctx, command);
       }
    }
 
-   private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffectedCommand command,
-                                                boolean originLocal) throws Throwable {
-      boolean cacheModeLocal = false;
-      if (command instanceof FlagAffectedCommand) {
-         cacheModeLocal = ((FlagAffectedCommand)command).hasFlag(Flag.CACHE_MODE_LOCAL);
-      }
-      log.tracef(""handleTopologyAffectedCommand for command %s, originLocal=%s, cacheModeLocal=%s"", command, originLocal
-            , cacheModeLocal);
-      if (originLocal || cacheModeLocal) {
+   private Object handleTopologyAffectedCommand(InvocationContext ctx, VisitableCommand command, boolean originLocal) throws Throwable {
+
+      log.tracef(""handleTopologyAffectedCommand for command %s, originLocal=%s, cacheModeLocal=%s"", command, originLocal);
+
+      if (isLocal(command, originLocal)) {
          return invokeNextInterceptor(ctx, command);
       }
+      updateTopologyIdAndWaitForTransactionData((TopologyAffectedCommand) command);
+
+      // TODO we may need to skip local invocation for read/write/tx commands if the command is too old and none of its keys are local
+      Object localResult = invokeNextInterceptor(ctx, command);
+
+      if (command instanceof TransactionBoundaryCommand || (command instanceof WriteCommand && !ctx.isInTxScope())) {
+         stateTransferManager.forwardCommandIfNeeded(((TopologyAffectedCommand)command), getAffectedKeys(ctx, command), true);
+      }
 
+      return localResult;
+   }
 
+   private void updateTopologyIdAndWaitForTransactionData(TopologyAffectedCommand command) throws InterruptedException {
       // set the topology id if it was not set before (ie. this is local command)
       // TODO Make tx commands extend FlagAffectedCommand so we can use CACHE_MODE_LOCAL in StaleTransactionCleanupService
       if (command.getTopologyId() == -1) {
@@ -233,34 +229,16 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       // remote/forwarded command
       int cmdTopologyId = command.getTopologyId();
       stateTransferLock.waitForTransactionData(cmdTopologyId);
+   }
 
-      // TODO we may need to skip local invocation for read/write/tx commands if the command is too old and none of its keys are local
-      Object localResult = invokeNextInterceptor(ctx, command);
+   private boolean isLocal(VisitableCommand command, boolean originLocal) {
+      if (originLocal) return true;
 
-      // forward commands with older topology ids to their new targets
-      // but we need to make sure we have the latest topology
-      CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
-      int localTopologyId = cacheTopology.getTopologyId();
-      // if it's a tx/lock/write command, forward it to the new owners
-      log.tracef(""CommandTopologyId=%s, localTopologyId=%s"", cmdTopologyId, localTopologyId);
-
-      if (cmdTopologyId < localTopologyId) {
-         if (command instanceof TransactionBoundaryCommand  || (command instanceof WriteCommand && !ctx.isInTxScope())) {
-            ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
-            Set<Object> affectedKeys = getAffectedKeys(ctx, command);
-            Set<Address> newTargets = writeCh.locateAllOwners(affectedKeys);
-            newTargets.remove(rpcManager.getAddress());
-            if (!newTargets.isEmpty()) {
-               // Update the topology id to prevent cycles
-               command.setTopologyId(localTopologyId);
-               log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
-               // TODO find a way to forward the command async if it was received async
-               rpcManager.invokeRemotely(newTargets, command, true, false);
-            }
-         }
+      boolean cacheModeLocal = false;
+      if (command instanceof FlagAffectedCommand) {
+         cacheModeLocal = ((FlagAffectedCommand)command).hasFlag(Flag.CACHE_MODE_LOCAL);
       }
-
-      return localResult;
+      return cacheModeLocal;
    }
 
    @SuppressWarnings(""unchecked"")",2012-10-12T16:37:21Z,115
"@@ -23,14 +23,16 @@
 
 package org.infinispan.statetransfer;
 
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.topology.CacheTopology;
 import org.rhq.helpers.pluginAnnotations.agent.DataType;
 import org.rhq.helpers.pluginAnnotations.agent.Metric;
 
-//todo [anistor] remove this class and move the remaining functionality to StateConsumer
+import java.util.Set;
+
 /**
  * A component that manages the state transfer when the topology of the cluster changes.
  *
@@ -72,4 +74,11 @@ public interface StateTransferManager {
     * @return {@code true} if the local node was the first to start this cache in the cluster.
     */
    boolean isLocalNodeFirst();
+
+   /**
+    * If there is an state transfer happening at the moment, this method forwards the supplied
+    * command to the nodes that are new owners of the data, in order to assure consistency.
+    */
+   void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
+
 }",2012-10-12T16:37:21Z,116
"@@ -23,11 +23,13 @@
 
 package org.infinispan.statetransfer;
 
+import java.util.Set;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
 import org.infinispan.Cache;
 import org.infinispan.CacheException;
+import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.configuration.global.GlobalConfiguration;
@@ -40,6 +42,7 @@
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
 import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheJoinInfo;
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.topology.CacheTopologyHandler;
@@ -242,4 +245,27 @@ public boolean isLocalNodeFirst() {
       return cacheTopology.getMembers().get(0).equals(rpcManager.getAddress());
    }
 
+   @Override
+   public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync) {
+      int cmdTopologyId = command.getTopologyId();
+      // forward commands with older topology ids to their new targets
+      // but we need to make sure we have the latest topology
+      CacheTopology cacheTopology = getCacheTopology();
+      int localTopologyId = cacheTopology.getTopologyId();
+      // if it's a tx/lock/write command, forward it to the new owners
+      log.tracef(""CommandTopologyId=%s, localTopologyId=%s"", cmdTopologyId, localTopologyId);
+
+      if (cmdTopologyId < localTopologyId) {
+         ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
+         Set<Address> newTargets = writeCh.locateAllOwners(affectedKeys);
+         newTargets.remove(rpcManager.getAddress());
+         if (!newTargets.isEmpty()) {
+            // Update the topology id to prevent cycles
+            command.setTopologyId(localTopologyId);
+            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
+            // TODO find a way to forward the command async if it was received async
+            rpcManager.invokeRemotely(newTargets, command, sync, false);
+         }
+      }
+   }
 }
\ No newline at end of file",2012-10-12T16:37:21Z,117
"@@ -52,7 +52,6 @@
 import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.ConfigurationBuilder;
-import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.versioning.EntryVersion;
 import org.infinispan.context.Flag;
 import org.infinispan.distexec.mapreduce.Mapper;
@@ -67,16 +66,12 @@
 import org.infinispan.test.TestingUtil;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
-import org.infinispan.transaction.tm.DummyTransaction;
-import org.infinispan.transaction.tm.DummyTransactionManager;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.concurrent.ReclosableLatch;
 import org.testng.annotations.Test;
 
-import javax.transaction.HeuristicMixedException;
 import javax.transaction.xa.Xid;
 import java.util.Collection;
-import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -104,11 +99,18 @@ protected void createCacheManagers() throws Throwable {
       waitForClusterToForm();
    }
 
-   public void testLockReleasedCorrectly() throws Throwable {
+   public void testBelatedCommit() throws Throwable {
+      testLockReleasedCorrectly(CommitCommand.class);
+   }
+
+   public void testBelatedTxCompletionNotificationCommand() throws Throwable {
+      testLockReleasedCorrectly(TxCompletionNotificationCommand.class);
+   }
 
+   private void testLockReleasedCorrectly(Class<? extends  ReplicableCommand> toBlock ) throws Throwable {
 
       ComponentRegistry componentRegistry = advancedCache(1).getComponentRegistry();
-      final ControlledCommandFactory ccf = new ControlledCommandFactory(componentRegistry.getCommandsFactory());
+      final ControlledCommandFactory ccf = new ControlledCommandFactory(componentRegistry.getCommandsFactory(), toBlock);
       TestingUtil.replaceField(ccf, ""commandsFactory"", componentRegistry, ComponentRegistry.class);
 
       //hack: re-add the component registry to the GlobalComponentRegistry's ""namedComponents"" (CHM) in order to correctly publish it for
@@ -137,7 +139,7 @@ public Object call() throws Exception {
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            return ccf.receivedCommits.get() == 1;
+            return ccf.receivedCommands.get() == 1;
          }
       });
 
@@ -153,17 +155,12 @@ public boolean isSatisfied() throws Exception {
       }
 
       log.tracef(""Number of migrated keys is %s"", migratedKeys.size());
-      System.out.println(""Number of migrated tx is "" + migratedKeys.size());
       if (migratedKeys.size() == 0) return;
 
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            int remoteTxCount = TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount();
-            int localTxCount = TestingUtil.getTransactionTable(cache(2)).getLocalTxCount();
-            log.trace(""remoteTxCount = "" + remoteTxCount);
-            log.trace(""localTxCount = "" + localTxCount);
-            return remoteTxCount == 1;
+            return TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount() == 1;
          }
       });
 
@@ -173,7 +170,8 @@ public boolean isSatisfied() throws Exception {
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            return TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount() == 0;
+            int remoteTxCount = TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount();
+            return remoteTxCount == 0;
          }
       });
 
@@ -189,6 +187,12 @@ public boolean isSatisfied() throws Exception {
          assertNotLocked(key);
          assertEquals(key, cache(0).get(key));
       }
+
+      for (Object k : migratedKeys) {
+         assertFalse(advancedCache(0).getDataContainer().containsKey(k));
+         assertFalse(advancedCache(1).getDataContainer().containsKey(k));
+         assertTrue(advancedCache(2).getDataContainer().containsKey(k));
+      }
    }
 
    private boolean keyMapsToNode(Object key, int nodeIndex) {
@@ -203,10 +207,12 @@ private Address owner(Object key) {
    public class ControlledCommandFactory implements CommandsFactory {
       final CommandsFactory actual;
       final ReclosableLatch gate = new ReclosableLatch(true);
-      final AtomicInteger receivedCommits = new AtomicInteger(0);
+      final AtomicInteger receivedCommands = new AtomicInteger(0);
+      final Class<? extends  ReplicableCommand> toBlock;
 
-      public ControlledCommandFactory(CommandsFactory actual) {
+      public ControlledCommandFactory(CommandsFactory actual, Class<? extends  ReplicableCommand> toBlock) {
          this.actual = actual;
+         this.toBlock = toBlock;
       }
 
       @Override
@@ -316,11 +322,11 @@ public RollbackCommand buildRollbackCommand(GlobalTransaction gtx) {
 
       @Override
       public void initializeReplicableCommand(ReplicableCommand command, boolean isRemote) {
-         if (isRemote && command instanceof CommitCommand) {
-            receivedCommits.incrementAndGet();
+         if (isRemote && command.getClass().isAssignableFrom(toBlock)) {
+            receivedCommands.incrementAndGet();
             try {
                gate.await();
-               log.tracef(""gate is opened, processing the commit:  %s"", command);
+               log.tracef(""gate is opened, processing the lock cleanup:  %s"", command);
             } catch (InterruptedException e) {
                throw new RuntimeException(e);
             }",2012-10-12T16:37:21Z,118
"@@ -0,0 +1,188 @@
+/*
+ * JBoss, Home of Professional Open Source
+ *  Copyright 2013 Red Hat Inc. and/or its affiliates and other
+ *  contributors as indicated by the @author tags. All rights reserved
+ *  See the copyright.txt in the distribution for a full listing of
+ *  individual contributors.
+ *
+ *  This is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU Lesser General Public License as
+ *  published by the Free Software Foundation; either version 2.1 of
+ *  the License, or (at your option) any later version.
+ *
+ *  This software is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ *  Lesser General Public License for more details.
+ *
+ *  You should have received a copy of the GNU Lesser General Public
+ *  License along with this software; if not, write to the Free
+ *  Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ *  02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.statetransfer;
+
+import java.util.Collection;
+import java.util.Map;
+import java.util.concurrent.Callable;
+
+import org.infinispan.Cache;
+import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.JGroupsTransport;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.test.fwk.TransportFlags;
+import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
+import org.infinispan.util.InfinispanCollections;
+import org.jgroups.protocols.DISCARD;
+import org.testng.annotations.Test;
+
+import static org.junit.Assert.assertEquals;
+
+/**
+ * tests scenario for ISPN-2574
+ *
+ * - create nodes A, B - start node C - starts state transfer from B to C
+ * - abruptly kill B before it is able to send StateResponse to C
+ * - C resends the request to A
+ * - finally cluster A, C is formed where all entries are properly backed up on both nodes
+ *
+ * @author Michal Linhard
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""statetransfer.StateTransferRestartTest"")
+@CleanupAfterMethod
+public class StateTransferRestartTest extends MultipleCacheManagersTest {
+
+   private ConfigurationBuilder cfgBuilder;
+   private GlobalConfigurationBuilder gcfgBuilder;
+
+   private class MockTransport extends JGroupsTransport {
+      volatile Callable<Void> callOnStateResponseCommand;
+
+      @Override
+      public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout,
+                                                   boolean usePriorityQueue, ResponseFilter responseFilter) throws Exception {
+         if (callOnStateResponseCommand != null && rpcCommand.getClass() == StateResponseCommand.class) {
+            log.trace(""Ignoring StateResponseCommand"");
+            try {
+               callOnStateResponseCommand.call();
+            } catch (Exception e) {
+               log.error(""Error in callOnStateResponseCommand"", e);
+            }
+            return InfinispanCollections.emptyMap();
+         }
+         return super.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue, responseFilter);
+      }
+   }
+
+   private MockTransport mockTransport = new MockTransport();
+
+   private void waitForStateTransfer(Cache... caches) throws InterruptedException {
+      StateTransferManager[] stm = new StateTransferManager[caches.length];
+      for (int i = 0; i < stm.length; i++) {
+         stm[i] = TestingUtil.extractComponent(caches[i], StateTransferManager.class);
+      }
+      while (true) {
+         boolean inProgress = false;
+         for (StateTransferManager aStm : stm) {
+            if (aStm.isStateTransferInProgress()) {
+               inProgress = true;
+               break;
+            }
+         }
+         if (!inProgress) {
+            break;
+         }
+         wait(100);
+      }
+   }
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      cfgBuilder = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+      cfgBuilder.transaction().transactionManagerLookup(new DummyTransactionManagerLookup());
+      cfgBuilder.clustering().hash().numOwners(2);
+      cfgBuilder.clustering().stateTransfer().fetchInMemoryState(true);
+      cfgBuilder.clustering().stateTransfer().timeout(10000);
+
+      gcfgBuilder = new GlobalConfigurationBuilder();
+      gcfgBuilder.transport().transport(mockTransport);
+   }
+
+   public void testStateTransferRestart() throws Throwable {
+      addClusterEnabledCacheManager(cfgBuilder, new TransportFlags().withFD(true));
+      addClusterEnabledCacheManager(gcfgBuilder, cfgBuilder, new TransportFlags().withFD(true));
+      log.info(""waiting for cluster { c0, c1 }"");
+      waitForClusterToForm();
+
+      log.info(""putting in data"");
+      final Cache<Object, Object> c0 = cache(0);
+      final Cache<Object, Object> c1 = cache(1);
+      for (int k = 0; k < 1000; k++) {
+         c0.put(k, k);
+      }
+      waitForStateTransfer(c0, c1);
+
+      assertEquals(1000, c0.entrySet().size());
+      assertEquals(1000, c1.entrySet().size());
+
+      mockTransport.callOnStateResponseCommand = new Callable<Void>() {
+         @Override
+         public Void call() throws Exception {
+            fork(new Callable<Void>() {
+               @Override
+               public Void call() throws Exception {
+                  log.info(""KILLING the c1 cache"");
+                  try {
+                     DISCARD d3 = TestingUtil.getDiscardForCache(c1);
+                     d3.setDiscardAll(true);
+                     d3.setExcludeItself(true);
+                     TestingUtil.killCacheManagers(manager(c1));
+                  } catch (Exception e) {
+                     log.info(""there was some exception while killing cache"");
+                  }
+                  return null;
+               }
+            });
+            try {
+               // sleep and wait to be killed
+               Thread.sleep(20000);
+            } catch (InterruptedException e) {
+               log.info(""Interrupted as expected."");
+               Thread.currentThread().interrupt();
+            }
+            return null;
+         }
+      };
+
+      log.info(""adding cache c2"");
+      addClusterEnabledCacheManager(cfgBuilder, new TransportFlags().withFD(true));
+      log.info(""get c2"");
+      final Cache<Object, Object> c2 = cache(2);
+
+      log.info(""waiting for cluster { c0, c2 }"");
+      TestingUtil.blockUntilViewsChanged(10000, 2, c0, c2);
+
+      log.infof(""c0 entrySet size before : %d"", c0.entrySet().size());
+      log.infof(""c2 entrySet size before : %d"", c2.entrySet().size());
+
+      eventually(new Condition() {
+         @Override
+         public boolean isSatisfied() throws Exception {
+            return c0.entrySet().size() == 1000 && c2.entrySet().size() == 1000;
+         }
+      });
+
+      log.info(""Ending the test"");
+   }
+}",2013-01-23T11:38:31Z,119
"@@ -66,7 +66,9 @@ public class InboundTransferTask {
 
    private final long timeout;
 
-   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout) {
+   private final String cacheName;
+
+   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""segments must not be null or empty"");
       }
@@ -81,6 +83,7 @@ public InboundTransferTask(Set<Integer> segments, Address source, int topologyId
       this.rpcManager = rpcManager;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public Set<Integer> getSegments() {
@@ -93,7 +96,7 @@ public Address getSource() {
 
    public boolean requestTransactions() {
       if (trace) {
-         log.tracef(""Requesting transactions for segments %s"", segments);
+         log.tracef(""Requesting transactions for segments %s of cache %s from node %s"", segments, cacheName, source);
       }
       // get transactions and locks
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.GET_TRANSACTIONS, rpcManager.getAddress(), topologyId, segments);
@@ -109,6 +112,10 @@ public boolean requestTransactions() {
    }
 
    public boolean requestSegments() {
+      if (trace) {
+         log.tracef(""Requesting segments %s of cache %s from node %s"", segments, cacheName, source);
+      }
+
       // start transfer of cache entries
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.START_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
       Map<Address, Response> responses = rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
@@ -139,24 +146,21 @@ public void cancel() {
       if (!isCancelled) {
          isCancelled = true;
 
-         Set<Integer> cancelledSegments = new HashSet<Integer>(segments);
-         segments.clear();
-         finishedSegments.clear();
-
-         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, cancelledSegments);
+         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
          rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
 
          stateConsumer.onTaskCompletion(this);
       }
    }
 
    public void onStateReceived(int segmentId, boolean isLastChunk) {
-      if (!isCancelled && segments.contains(segmentId)) {
-         if (isLastChunk) {
-            finishedSegments.add(segmentId);
-            if (finishedSegments.containsAll(segments)) {
-               stateConsumer.onTaskCompletion(this);
+      if (!isCancelled && isLastChunk && segments.contains(segmentId)) {
+         finishedSegments.add(segmentId);
+         if (finishedSegments.containsAll(segments)) {
+            if (trace) {
+               log.tracef(""Finished receiving state for segments %s of cache %s"", segments, cacheName);
             }
+            stateConsumer.onTaskCompletion(this);
          }
       }
    }
@@ -166,11 +170,14 @@ public String toString() {
       HashSet<Integer> unfinishedSegments = new HashSet<Integer>(segments);
       unfinishedSegments.removeAll(finishedSegments);
       return ""InboundTransferTask{"" +
-            ""unfinishedSegments="" + unfinishedSegments +
+            ""segments="" + segments +
+            "", finishedSegments="" + finishedSegments +
+            "", unfinishedSegments="" + unfinishedSegments +
             "", source="" + source +
             "", isCancelled="" + isCancelled +
             "", topologyId="" + topologyId +
             "", timeout="" + timeout +
+            "", cacheName="" + cacheName +
             '}';
    }
 }",2012-11-07T14:07:34Z,120
"@@ -24,20 +24,19 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.commands.CommandsFactory;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheLoaderManager;
 import org.infinispan.loaders.CacheStore;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.SuspectException;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
-import org.infinispan.util.concurrent.AggregatingNotifyingFutureBuilder;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -70,8 +69,6 @@ public class OutboundTransferTask implements Runnable {
 
    private final int stateTransferChunkSize;
 
-   private final Configuration configuration;
-
    private final ConsistentHash readCh;
 
    private final DataContainer dataContainer;
@@ -84,27 +81,24 @@ public class OutboundTransferTask implements Runnable {
 
    private final long timeout;
 
+   private final String cacheName;
+
    private final Map<Integer, List<InternalCacheEntry>> entriesBySegment = ConcurrentMapFactory.makeConcurrentMap();
 
    /**
     * The total number of entries from all segments accumulated in entriesBySegment.
     */
    private int accumulatedEntries;
 
-   /**
-    * This is used with RpcManager.invokeRemotelyInFuture() to be able to cancel message sending if the task needs to be canceled.
-    */
-   private final NotifyingNotifiableFuture<Object> sendFuture = new AggregatingNotifyingFutureBuilder(null);
-
    /**
     * The Future obtained from submitting this task to an executor service. This is used for cancellation.
     */
    private FutureTask runnableFuture;
 
    public OutboundTransferTask(Address destination, Set<Integer> segments, int stateTransferChunkSize,
                                int topologyId, ConsistentHash readCh, StateProviderImpl stateProvider, DataContainer dataContainer,
-                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager, Configuration configuration,
-                               CommandsFactory commandsFactory, long timeout) {
+                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager,
+                               CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""Segments must not be null or empty"");
       }
@@ -123,9 +117,9 @@ public OutboundTransferTask(Address destination, Set<Integer> segments, int stat
       this.dataContainer = dataContainer;
       this.cacheLoaderManager = cacheLoaderManager;
       this.rpcManager = rpcManager;
-      this.configuration = configuration;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public void execute(ExecutorService executorService) {
@@ -154,7 +148,7 @@ public void run() {
       try {
          // send data container entries
          for (InternalCacheEntry ice : dataContainer) {
-            Object key = ice.getKey();
+            Object key = ice.getKey();  //todo [anistor] should we check for expired entries?
             int segmentId = readCh.getSegment(key);
             if (segments.contains(segmentId)) {
                sendEntry(ice, segmentId);
@@ -198,7 +192,7 @@ public void run() {
          }
       }
       if (trace) {
-         log.tracef(""Outbound transfer of segments %s to %s is complete"", segments, destination);
+         log.tracef(""Outbound transfer of segments %s of cache %s to node %s is complete"", segments, cacheName, destination);
       }
    }
 
@@ -217,7 +211,6 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
       // send if we have a full chunk
       if (accumulatedEntries >= stateTransferChunkSize) {
          sendEntries(false);
-         entriesBySegment.clear();
          accumulatedEntries = 0;
       }
 
@@ -232,32 +225,42 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
 
    private void sendEntries(boolean isLast) {
       List<StateChunk> chunks = new ArrayList<StateChunk>();
+      for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
+         List<InternalCacheEntry> entries = e.getValue();
+         if (!entries.isEmpty()) {
+            chunks.add(new StateChunk(e.getKey(), new ArrayList<InternalCacheEntry>(entries), isLast));
+            entries.clear();
+         }
+      }
+
       if (isLast) {
          for (int segmentId : segments) {
             List<InternalCacheEntry> entries = entriesBySegment.get(segmentId);
             if (entries == null) {
-               entries = InfinispanCollections.emptyList();
-            }
-            chunks.add(new StateChunk(segmentId, entries, isLast));
-         }
-      } else {
-         for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
-            List<InternalCacheEntry> entries = e.getValue();
-            if (!entries.isEmpty()) {
-               chunks.add(new StateChunk(e.getKey(), entries, isLast));
+               chunks.add(new StateChunk(segmentId, InfinispanCollections.<InternalCacheEntry>emptyList(), true));
             }
          }
       }
 
-      if (!chunks.isEmpty() || isLast) {
+      if (!chunks.isEmpty()) {
          if (trace) {
-            log.tracef(""Sending %d cache entries from segments %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), destination);
+            if (isLast) {
+               log.tracef(""Sending last chunk containing %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, segments, cacheName, destination);
+            } else {
+               log.tracef(""Sending %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), cacheName, destination);
+            }
          }
 
-         //todo [anistor] send back the received topologyId or my local one?
          StateResponseCommand cmd = commandsFactory.buildStateResponseCommand(rpcManager.getAddress(), topologyId, chunks);
-         // send synchronously, in FIFO mode. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
-         rpcManager.invokeRemotelyInFuture(Collections.singleton(destination), cmd, false, sendFuture, timeout);
+         // send synchronously, in order. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
+         try {
+            rpcManager.invokeRemotely(Collections.singleton(destination), cmd, ResponseMode.SYNCHRONOUS, timeout, false, null);
+         } catch (SuspectException e) {
+            log.errorf(e, ""Node %s left cache %s: %s"", destination, cacheName, e.getMessage());
+            cancel();
+         } catch (Exception e) {
+            log.errorf(e, ""Failed to send entries to node %s : %s"", destination, e.getMessage());
+         }
       }
    }
 
@@ -268,7 +271,7 @@ private void sendEntries(boolean isLast) {
     */
    public void cancelSegments(Set<Integer> cancelledSegments) {
       if (trace) {
-         log.tracef(""Cancelling outbound transfer of segments %s to %s"", cancelledSegments, destination);
+         log.tracef(""Cancelling outbound transfer of segments %s of cache %s to node %s"", cancelledSegments, cacheName, destination);
       }
       if (segments.removeAll(cancelledSegments)) {
          entriesBySegment.keySet().removeAll(cancelledSegments);  // here we do not update accumulatedEntries but this inaccuracy does not cause any harm
@@ -284,11 +287,22 @@ public void cancelSegments(Set<Integer> cancelledSegments) {
    public void cancel() {
       if (runnableFuture != null && !runnableFuture.isCancelled()) {
          runnableFuture.cancel(true);
-         sendFuture.cancel(true);
       }
    }
 
    public boolean isCancelled() {
       return runnableFuture != null && runnableFuture.isCancelled();
    }
+
+   @Override
+   public String toString() {
+      return ""OutboundTransferTask{"" +
+            ""topologyId="" + topologyId +
+            "", destination="" + destination +
+            "", segments="" + segments +
+            "", stateTransferChunkSize="" + stateTransferChunkSize +
+            "", timeout="" + timeout +
+            "", cacheName='"" + cacheName + '\'' +
+            '}';
+   }
 }",2012-11-07T14:07:34Z,121
"@@ -45,7 +45,6 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -62,7 +61,7 @@
 import static org.infinispan.context.Flag.*;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateConsumer} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -72,7 +71,7 @@ public class StateConsumerImpl implements StateConsumer {
    private static final Log log = LogFactory.getLog(StateConsumerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
-   private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
    private Configuration configuration;
    private RpcManager rpcManager;
@@ -119,7 +118,7 @@ public StateConsumerImpl() {
 
    @Inject
    public void init(Cache cache,
-                    LocalTopologyManager localTopologyManager,
+                    StateTransferManager stateTransferManager,
                     InterceptorChain interceptorChain,
                     InvocationContextContainer icc,
                     Configuration configuration,
@@ -130,7 +129,7 @@ public void init(Cache cache,
                     TransactionTable transactionTable,
                     StateTransferLock stateTransferLock) {
       this.cacheName = cache.getName();
-      this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
       this.interceptorChain = interceptorChain;
       this.icc = icc;
       this.configuration = configuration;
@@ -171,26 +170,30 @@ public boolean isStateTransferInProgressForKey(Object key) {
 
    @Override
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
-      if (trace) log.tracef(""Received new CH: %s"", cacheTopology.getWriteConsistentHash());
+      if (trace) log.tracef(""Received new CH %s for cache %s"", cacheTopology.getWriteConsistentHash(), cacheName);
 
       activeTopologyUpdates.incrementAndGet();
       if (isRebalance) {
          rebalanceInProgress.set(true);
       }
-      ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
+      final ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
       // Ensures writes to the data container use the right consistent hash
       // No need for a try/finally block, since it's just an assignment
       stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
       stateTransferLock.releaseExclusiveTopologyLock();
-      stateTransferLock.topologyInstalled(cacheTopology.getTopologyId());
+      stateTransferLock.notifyTopologyInstalled(cacheTopology.getTopologyId());
 
       try {
          Set<Integer> addedSegments;
          if (previousCh == null) {
             // we start fresh, without any data, so we need to pull everything we own according to writeCh
 
             addedSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
+
+            if (trace) {
+               log.tracef(""On cache %s we have: added segments: %s"", cacheName, addedSegments);
+            }
          } else {
             Set<Integer> previousSegments = getOwnedSegments(previousCh);
             Set<Integer> newSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
@@ -199,16 +202,16 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             Set<Integer> removedSegments = new HashSet<Integer>(previousSegments);
             removedSegments.removeAll(newSegments);
 
-            // remove inbound transfers and any data for segments we no longer own
+            addedSegments = new HashSet<Integer>(newSegments);
+            addedSegments.removeAll(previousSegments);
+
             if (trace) {
-               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                     removedSegments, newSegments, previousSegments);
+               log.tracef(""On cache %s we have: removed segments: %s; new segments: %s; old segments: %s; added segments: %s"",
+                     cacheName, removedSegments, newSegments, previousSegments, addedSegments);
             }
-            discardSegments(removedSegments);
 
-            Set<Integer> currentSegments = getOwnedSegments(cacheTopology.getReadConsistentHash());
-            addedSegments = new HashSet<Integer>(newSegments);
-            addedSegments.removeAll(currentSegments);
+            // remove inbound transfers and any data for segments we no longer own
+            discardSegments(removedSegments);
 
             // check if any of the existing transfers should be restarted from a different source because the initial source is no longer a member
             Set<Address> members = new HashSet<Address>(cacheTopology.getReadConsistentHash().getMembers());
@@ -230,24 +233,30 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
                      }
                   }
                }
+
+               // exclude those that are already in progress from a valid source
+               addedSegments.removeAll(transfersBySegment.keySet());
             }
          }
 
-         if (addedSegments != null && !addedSegments.isEmpty()) {
+         if (!addedSegments.isEmpty()) {
             addTransfers(addedSegments);  // add transfers for new or restarted segments
          }
       } finally {
-         stateTransferLock.transactionDataReceived(cacheTopology.getTopologyId());
+         stateTransferLock.notifyTransactionDataReceived(cacheTopology.getTopologyId());
 
-         if (activeTopologyUpdates.decrementAndGet() == 0 && !isStateTransferInProgress()) {
+         if (activeTopologyUpdates.decrementAndGet() == 0) {
             notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
          }
       }
    }
 
    private void notifyEndOfTopologyUpdate(int topologyId) {
-      if (rebalanceInProgress.compareAndSet(true, false)) {
-         localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+      if (!isStateTransferInProgress()) {
+         if (rebalanceInProgress.compareAndSet(true, false)) {
+            log.debugf(""Finished receiving of segments for cache %s for topology %d."", cacheName, topologyId);
+            stateTransferManager.notifyEndOfTopologyUpdate(topologyId);
+         }
       }
    }
 
@@ -262,43 +271,42 @@ public void applyState(Address sender, int topologyId, int segmentId, Collection
       //todo [anistor] this check should be based on topologyId
       if (!cacheTopology.getWriteConsistentHash().getSegmentsForOwner(rpcManager.getAddress()).contains(segmentId)) {
          if (trace) {
-            log.warnf(""Discarding received cache entries for segment %d because they do not belong to this node."", segmentId);
+            log.warnf(""Discarding received cache entries for segment %d of cache %s because they do not belong to this node."", segmentId, cacheName);
          }
          return;
       }
 
-      if (cacheEntries != null) {
-         doApplyState(sender, segmentId, cacheEntries);
-      }
-
       // notify the inbound task that a chunk of cache entries was received
       InboundTransferTask inboundTransfer;
       synchronized (this) {
          inboundTransfer = transfersBySegment.get(segmentId);
       }
       if (inboundTransfer != null) {
+         if (cacheEntries != null) {
+            doApplyState(sender, segmentId, cacheEntries);
+         }
+
          inboundTransfer.onStateReceived(segmentId, isLastChunk);
-      } else {
-         log.debugf(""Received unsolicited state for segment %d from node %s"", segmentId, sender);
-         return;
-      }
 
-      if (trace) {
-         log.tracef(""After applying the received state the data container has %d keys"", dataContainer.size());
-         synchronized (this) {
-            log.tracef(""Segments not received yet: %s"", transfersBySource);
+         if (trace) {
+            log.tracef(""After applying the received state the data container of cache %s has %d keys"", cacheName, dataContainer.size());
+            synchronized (this) {
+               log.tracef(""Segments not received yet for cache %s: %s"", cacheName, transfersBySource);
+            }
          }
+      } else {
+         log.warnf(""Received unsolicited state from node %s for segment %d of cache %s"", sender, segmentId, cacheName);
       }
    }
 
    private void doApplyState(Address sender, int segmentId, Collection<InternalCacheEntry> cacheEntries) {
-      log.debugf(""Applying new state for segment %d from %s: received %d cache entries"", segmentId, sender, cacheEntries.size());
+      log.debugf(""Applying new state for segment %d of cache %s from node %s: received %d cache entries"", segmentId, cacheName, sender, cacheEntries.size());
       if (trace) {
          List<Object> keys = new ArrayList<Object>(cacheEntries.size());
          for (InternalCacheEntry e : cacheEntries) {
             keys.add(e.getKey());
          }
-         log.tracef(""Received keys: %s"", keys);
+         log.tracef(""Received keys %s for segment %d of cache %s from node %s"", keys, segmentId, cacheName, sender);
       }
 
       // CACHE_MODE_LOCAL avoids handling by StateTransferInterceptor and any potential locks in StateTransferLock
@@ -316,10 +324,11 @@ private void doApplyState(Address sender, int segmentId, Collection<InternalCach
             log.problemApplyingStateForKey(ex.getMessage(), e.getKey());
          }
       }
+      log.debugf(""Finished applying state for segment %d of cache %s"", segmentId, cacheName);
    }
 
    public void applyTransactions(Address sender, int topologyId, Collection<TransactionInfo> transactions) {
-      log.debugf(""Applying %d transactions transferred from %s"", transactions.size(), sender);
+      log.debugf(""Applying %d transactions for cache %s transferred from node %s"", transactions.size(), cacheName, sender);
       if (configuration.transaction().transactionMode().isTransactional()) {
          for (TransactionInfo transactionInfo : transactions) {
             CacheTransaction tx = transactionTable.getLocalTransaction(transactionInfo.getGlobalTransaction());
@@ -374,30 +383,31 @@ public CacheTopology getCacheTopology() {
    }
 
    private void addTransfers(Set<Integer> segments) {
-      log.debugf(""Adding state transfer for segments: %s"", segments);
+      log.debugf(""Adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
 
       Set<Integer> segmentsToProcess = new HashSet<Integer>(segments);
-      Set<Address> blacklistedSources = new HashSet<Address>();
+      Set<Address> faultysources = new HashSet<Address>();
 
       // ignore all segments for which there are no other owners to pull data from.
       // these segments are considered empty (or lost) and do not require a state transfer
       for (Iterator<Integer> it = segmentsToProcess.iterator(); it.hasNext(); ) {
          Integer segmentId = it.next();
-         Address source = pickSourceOwner(segmentId, blacklistedSources);
+         Address source = pickSourceOwner(segmentId, faultysources);
          if (source == null) {
             it.remove();
          }
       }
 
-      synchronized (this) {
-         // already active transfers do not need to be added again
-         segmentsToProcess.removeAll(transfersBySegment.keySet());
-      }
-
       while (!segmentsToProcess.isEmpty()) {
          Map<Address, Set<Integer>> segmentsBySource = new HashMap<Address, Set<Integer>>();
          for (int segmentId : segmentsToProcess) {
-            Address source = pickSourceOwner(segmentId, blacklistedSources);
+            synchronized (this) {
+               // already active transfers do not need to be added again
+               if (transfersBySegment.containsKey(segmentId)) {
+                  continue;
+               }
+            }
+            Address source = pickSourceOwner(segmentId, faultysources);
             if (source != null) {
                Set<Integer> segmentsFromSource = segmentsBySource.get(source);
                if (segmentsFromSource == null) {
@@ -411,8 +421,14 @@ private void addTransfers(Set<Integer> segments) {
          Set<Integer> failedSegments = new HashSet<Integer>();
          for (Address source : segmentsBySource.keySet()) {
             Set<Integer> segmentsFromSource = segmentsBySource.get(source);
-            InboundTransferTask inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout);
+            InboundTransferTask inboundTransfer;
             synchronized (this) {
+               segmentsFromSource.removeAll(transfersBySegment.keySet());  // already in progress segments are excluded
+               if (segmentsFromSource.isEmpty()) {
+                  continue;
+               }
+
+               inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout, cacheName);
                for (int segmentId : segmentsFromSource) {
                   transfersBySegment.put(segmentId, inboundTransfer);
                }
@@ -427,9 +443,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the transactions fails we need to retry from another source
             if (configuration.transaction().transactionMode().isTransactional()) {
                if (!inboundTransfer.requestTransactions()) {
-                  log.errorf(""Failed to retrieve transactions for segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRetrieveTransactionsForSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                   continue;
                }
@@ -438,9 +454,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the segments fails we need to retry from another source
             if (fetchEnabled) {
                if (!inboundTransfer.requestSegments()) {
-                  log.errorf(""Failed to request segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRequestSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                }
             } else {
@@ -450,21 +466,22 @@ private void addTransfers(Set<Integer> segments) {
 
          segmentsToProcess = failedSegments;
       }
+      log.debugf(""Finished adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
    }
 
-   private Address pickSourceOwner(int segmentId, Set<Address> blacklistedSources) {
+   private Address pickSourceOwner(int segmentId, Set<Address> faultySources) {
       List<Address> owners = cacheTopology.getReadConsistentHash().locateOwnersForSegment(segmentId);
       if (owners.size() == 1 && owners.get(0).equals(rpcManager.getAddress())) {
          return null;
       }
 
       for (int i = owners.size() - 1; i >= 0; i--) {   // iterate backwards because we prefer to fetch from newer nodes
          Address o = owners.get(i);
-         if (!o.equals(rpcManager.getAddress()) && !blacklistedSources.contains(o)) {
+         if (!o.equals(rpcManager.getAddress()) && !faultySources.contains(o)) {
             return o;
          }
       }
-      log.errorf(""No live owners found for segment %d. Current owners are:  %s. Blacklisted owners: %s"", segmentId, owners, blacklistedSources);
+      log.noLiveOwnersFoundForSegment(segmentId, cacheName, owners, faultySources);
       return null;
    }
 
@@ -478,9 +495,9 @@ private void discardSegments(Set<Integer> segments) {
          List<Integer> segmentsToCancel = new ArrayList<Integer>(segments);
          while (!segmentsToCancel.isEmpty()) {
             int segmentId = segmentsToCancel.remove(0);
-            log.debugf(""Removing state transfer for segment %d"", segmentId);
             InboundTransferTask inboundTransfer = transfersBySegment.remove(segmentId);
             if (inboundTransfer != null) { // we need to check the transfer was not already completed
+               log.debugf(""Cancelling inbound state transfer for segment %d of cache %s"", segmentId, cacheName);
                Set<Integer> cancelledSegments = new HashSet<Integer>(segmentsToCancel);
                cancelledSegments.retainAll(inboundTransfer.getSegments());
                segmentsToCancel.removeAll(cancelledSegments);
@@ -489,6 +506,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      // gather all keys from data container that belong to the segments that are being removed
       Set<Object> keysToRemove = new HashSet<Object>();
       for (InternalCacheEntry ice : dataContainer) {
          Object key = ice.getKey();
@@ -497,7 +515,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
-      // we also remove keys from the cache store
+      // gather all keys from cache store that belong to the segments that are being removed
       CacheStore cacheStore = getCacheStore();
       if (cacheStore != null) {
          //todo [anistor] extend CacheStore interface to be able to specify a filter when loading keys (ie. keys should belong to desired segments)
@@ -514,13 +532,14 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      log.debugf(""Removing state for segments %s of cache %s"", segments, cacheName);
       if (!keysToRemove.isEmpty()) {
          try {
             InvalidateCommand invalidateCmd = commandsFactory.buildInvalidateFromL1Command(true, EnumSet.of(CACHE_MODE_LOCAL, SKIP_LOCKING), keysToRemove);
             InvocationContext ctx = icc.createNonTxInvocationContext();
             interceptorChain.invoke(ctx, invalidateCmd);
 
-            log.debugf(""Invalidated %d keys, data container now has %d keys"", keysToRemove.size(), dataContainer.size());
+            log.debugf(""Invalidated %d keys, data container of cache %s now has %d keys"", keysToRemove.size(), cacheName, dataContainer.size());
             if (trace) log.tracef(""Invalidated keys: %s"", keysToRemove);
          } catch (CacheException e) {
             log.failedToInvalidateKeys(e);
@@ -553,18 +572,17 @@ private void removeTransfer(InboundTransferTask inboundTransfer) {
                if (transfers.isEmpty()) {
                   transfersBySource.remove(inboundTransfer.getSource());
                }
-               for (int segmentId : inboundTransfer.getSegments()) {
-                  transfersBySegment.remove(segmentId);
-               }
+               transfersBySegment.keySet().removeAll(inboundTransfer.getSegments());
             }
          }
       }
    }
 
    void onTaskCompletion(InboundTransferTask inboundTransfer) {
+      log.tracef(""Completion of inbound transfer task: %s "", inboundTransfer);
       removeTransfer(inboundTransfer);
 
-      if (activeTopologyUpdates.get() == 0 && !isStateTransferInProgress()) {
+      if (activeTopologyUpdates.get() == 0) {
          notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
       }
    }",2012-11-07T14:07:34Z,54
"@@ -52,7 +52,7 @@
 import static org.infinispan.factories.KnownComponentNames.ASYNC_TRANSPORT_EXECUTOR;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateProvider} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -90,7 +90,7 @@ public StateProviderImpl() {
 
    @Inject
    public void init(Cache cache,
-                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //todo [anistor] use a separate ExecutorService
+                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //TODO Use a dedicated ExecutorService
                     Configuration configuration,
                     RpcManager rpcManager,
                     CommandsFactory commandsFactory,
@@ -184,7 +184,7 @@ public void stop() {
 
    public List<TransactionInfo> getTransactionsForSegments(Address destination, int requestTopologyId, Set<Integer> segments) throws InterruptedException {
       if (trace) {
-         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, requestTopologyId);
+         log.tracef(""Received request for transactions from node %s for segments %s of cache %s with topology id %d"", destination, segments, cacheName, requestTopologyId);
       }
 
       if (readCh == null) {
@@ -262,8 +262,8 @@ public void startOutboundTransfer(Address destination, int requestTopologyId, Se
       }
 
       // the destination node must already have an InboundTransferTask waiting for these segments
-      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, requestTopologyId,
-            readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
+      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId,
+            readCh, this, dataContainer, cacheLoaderManager, rpcManager, commandsFactory, timeout, cacheName);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);
    }
@@ -294,7 +294,7 @@ public void cancelOutboundTransfer(Address destination, int topologyId, Set<Inte
             // get an array copy of the collection to avoid ConcurrentModificationException if the entire task gets cancelled and removeTransfer(transferTask) is called
             OutboundTransferTask[] tasks = transferTasks.toArray(new OutboundTransferTask[transferTasks.size()]);
             for (OutboundTransferTask transferTask : tasks) {
-               transferTask.cancelSegments(segments); //this can potentially result in a removeTransfer(transferTask)
+               transferTask.cancelSegments(segments); //this can potentially result in a call to removeTransfer(transferTask)
             }
          }
       }",2012-11-07T14:07:34Z,55
"@@ -36,16 +36,13 @@
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
-import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
 import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
@@ -75,7 +72,7 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
+   public void init(StateTransferLock stateTransferLock, Configuration configuration,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
       this.commandFactory = commandFactory;",2012-11-07T14:07:34Z,115
"@@ -58,13 +58,13 @@ public interface StateTransferLock {
    void releaseSharedTopologyLock();
 
    // transaction data latch
-   void transactionDataReceived(int topologyId);
+   void notifyTransactionDataReceived(int topologyId);
 
    void waitForTransactionData(int expectedTopologyId) throws InterruptedException;
 
    // topology installation latch
    // TODO move this to Cluster/LocalTopologyManagerImpl and don't start requesting state until every node has the jgroups view with the local node
-   void topologyInstalled(int topologyId);
+   void notifyTopologyInstalled(int topologyId);
 
    void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-11-07T14:07:34Z,122
"@@ -23,12 +23,12 @@
 
 package org.infinispan.statetransfer;
 
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+
 /**
  * {@code StateTransferLock} implementation.
  *
@@ -38,6 +38,7 @@
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
+   private static final boolean trace = log.isTraceEnabled();
 
    private final ReadWriteLock ownershipLock = new ReentrantReadWriteLock();
 
@@ -68,8 +69,15 @@ public void releaseSharedTopologyLock() {
    }
 
    @Override
-   public void transactionDataReceived(int topologyId) {
-      this.transactionDataTopologyId = topologyId;
+   public void notifyTransactionDataReceived(int topologyId) {
+      if (topologyId < transactionDataTopologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + transactionDataTopologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling transaction data received for topology %d"", topologyId);
+      }
+      transactionDataTopologyId = topologyId;
       synchronized (transactionDataLock) {
          transactionDataLock.notifyAll();
       }
@@ -80,19 +88,32 @@ public void waitForTransactionData(int expectedTopologyId) throws InterruptedExc
       if (transactionDataTopologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
-            transactionDataTopologyId);
+      if (trace) {
+         log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
+               transactionDataTopologyId);
+      }
       synchronized (transactionDataLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (transactionDataTopologyId < expectedTopologyId) {
             transactionDataLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Received transaction data for topology %d, expected topology was %d"", transactionDataTopologyId,
+               expectedTopologyId);
+      }
    }
 
    @Override
-   public void topologyInstalled(int topologyId) {
+   public void notifyTopologyInstalled(int topologyId) {
+      if (topologyId < this.topologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + this.topologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling topology %d is installed"", topologyId);
+      }
       this.topologyId = topologyId;
       synchronized (topologyLock) {
          topologyLock.notifyAll();
@@ -104,14 +125,18 @@ public void waitForTopology(int expectedTopologyId) throws InterruptedException
       if (topologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId,
-            topologyId);
+      if (trace) {
+         log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId, topologyId);
+      }
       synchronized (topologyLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (topologyId < expectedTopologyId) {
             topologyLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Topology %d is now installed, expected topology was %d"", topologyId, expectedTopologyId);
+      }
    }
 }",2012-11-07T14:07:34Z,123
"@@ -81,4 +81,5 @@ public interface StateTransferManager {
     */
    void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
 
+   void notifyEndOfTopologyUpdate(int topologyId);
 }",2012-11-07T14:07:34Z,116
"@@ -70,7 +70,7 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private GroupManager groupManager;   // optional
    private LocalTopologyManager localTopologyManager;
 
-   private CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
+   private final CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
 
    public StateTransferManagerImpl() {
    }
@@ -170,13 +170,18 @@ private CacheTopology addGrouping(CacheTopology cacheTopology) {
 
    private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalance) {
       if (trace) {
-         log.tracef(""Installing new cache topology %s"", newCacheTopology);
+         log.tracef(""Installing new cache topology %s on cache %s"", newCacheTopology, cacheName);
       }
 
       // handle grouping
       newCacheTopology = addGrouping(newCacheTopology);
 
       CacheTopology oldCacheTopology = stateConsumer.getCacheTopology();
+
+      if (oldCacheTopology != null && oldCacheTopology.getTopologyId() > newCacheTopology.getTopologyId()) {
+         throw new IllegalStateException(""Old topology is higher: old="" + oldCacheTopology + "", new="" + newCacheTopology);
+      }
+
       ConsistentHash oldCH = oldCacheTopology != null ? oldCacheTopology.getWriteConsistentHash() : null;
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
@@ -188,15 +193,17 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
 
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
-      if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
+      boolean isJoined = stateConsumer.getCacheTopology().getReadConsistentHash().getMembers().contains(rpcManager.getAddress());
+      if (initialStateTransferComplete.getCount() > 0 && isJoined) {
          initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
    }
 
    @Start(priority = 1000)
    @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
-      if (trace) log.tracef(""Waiting for initial state transfer to finish"");
+      if (trace) log.tracef(""Waiting for initial state transfer to finish for cache %s on %s"", cacheName, rpcManager.getAddress());
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);
       if (!success) {
          throw new CacheException(String.format(""Initial state transfer timed out for cache %s on %s"",
@@ -210,6 +217,7 @@ public void stop() {
       if (trace) {
          log.tracef(""Shutting down StateTransferManager of cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
+      initialStateTransferComplete.countDown();
       localTopologyManager.leave(cacheName);
    }
 
@@ -268,4 +276,14 @@ public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object>
          }
       }
    }
+
+   @Override
+   public void notifyEndOfTopologyUpdate(int topologyId) {
+      if (initialStateTransferComplete.getCount() > 0
+            && stateConsumer.getCacheTopology().getWriteConsistentHash().getMembers().contains(rpcManager.getAddress())) {
+         initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
+      }
+      localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+   }
 }
\ No newline at end of file",2012-11-07T14:07:34Z,117
"@@ -126,13 +126,17 @@ public void triggerRebalance(final String cacheName) throws Exception {
       asyncTransportExecutor.submit(new Callable<Object>() {
          @Override
          public Object call() throws Exception {
-            startRebalance(cacheName);
-            return null;
+            try {
+               startRebalance(cacheName);
+               return null;
+            } catch (Throwable t) {
+               log.errorf(t, ""Failed to start rebalance: %s"", t.getMessage());
+               throw new Exception(t);
+            }
          }
       });
    }
 
-
    @Override
    public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo joinInfo, int viewId) throws Exception {
       waitForView(viewId);
@@ -594,6 +598,7 @@ public Object call() throws Exception {
             try {
                return command.perform(null);
             } catch (Throwable t) {
+               log.errorf(t, ""Failed to execute ReplicableCommand %s on cluster async: %s"", command, t.getMessage());
                throw new Exception(t);
             }
          }",2012-11-07T14:07:34Z,124
"@@ -280,6 +280,7 @@ public Object call() throws Exception {
                try {
                   return command.perform(null);
                } catch (Throwable t) {
+                  log.errorf(t, ""Failed to execute ReplicableCommand %s on coordinator async: %s"", command, t.getMessage());
                   throw new Exception(t);
                }
             }
@@ -298,8 +299,6 @@ class LocalCacheStatus {
    private final CacheTopologyHandler handler;
    private volatile CacheTopology topology;
 
-   private boolean joined;
-
    public LocalCacheStatus(CacheJoinInfo joinInfo, CacheTopologyHandler handler) {
       this.joinInfo = joinInfo;
       this.handler = handler;
@@ -320,12 +319,4 @@ public CacheTopology getTopology() {
    public void setTopology(CacheTopology topology) {
       this.topology = topology;
    }
-
-   public boolean isJoined() {
-      return joined;
-   }
-
-   public void setJoined(boolean joined) {
-      this.joined = joined;
-   }
 }",2012-11-07T14:07:34Z,125
"@@ -53,15 +53,14 @@ public class StaleTransactionCleanupService {
 
    private static Log log = LogFactory.getLog(StaleTransactionCleanupService.class);
 
+   private ScheduledExecutorService executorService;
 
    private TransactionTable transactionTable;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
-   private ScheduledExecutorService executorService;
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * because the main data owner left. Also unlocks keys for which the lock owner has changed as a result of a topology change.
@@ -71,15 +70,19 @@ public StaleTransactionCleanupService(TransactionTable transactionTable) {
    @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // Roll back remote transactions originating on nodes that have left the cluster.
-      if (tce.isPre()) {
-         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
-         if (consistentHashAtStart != null) {
-            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
-            if (!leavers.isEmpty()) {
-               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-               cleanTxForWhichTheOwnerLeft(leavers);
+      try {
+         if (tce.isPre()) {
+            ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+            if (consistentHashAtStart != null) {
+               List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+               if (!leavers.isEmpty()) {
+                  log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+                  cleanTxForWhichTheOwnerLeft(leavers);
+               }
             }
          }
+      } catch (Exception e) {
+         log.error(""Failed to process topology update"", e);
       }
    }
 
@@ -120,7 +123,6 @@ public void run() {
             transactionTable.cleanupCompletedTransactions();
          }
       }, interval, interval, TimeUnit.MILLISECONDS);
-
    }
 
    public void stop() {",2012-11-07T14:07:34Z,126
"@@ -523,25 +523,29 @@ public boolean isTransactionCompleted(GlobalTransaction gtx) {
    }
 
    public void cleanupCompletedTransactions() {
-      log.debugf(""About to cleanup completed transaction. Initial size is %s"", completedTransactions.size());
-      //this iterator is weekly consistent and will never throw ConcurrentModificationException
-      Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
-      long timeout = configuration.transaction().completedTxTimeout();
-
-      int removedEntries = 0;
-      long beginning = System.nanoTime();
-      while (iterator.hasNext()) {
-         Map.Entry<GlobalTransaction, Long> e = iterator.next();
-         long ageNanos = System.nanoTime() - e.getValue();
-         if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
-            iterator.remove();
-            removedEntries++;
+      try {
+         log.debugf(""About to cleanup completed transaction. Initial size is %d"", completedTransactions.size());
+         //this iterator is weekly consistent and will never throw ConcurrentModificationException
+         Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
+         long timeout = configuration.transaction().completedTxTimeout();
+
+         int removedEntries = 0;
+         long beginning = System.nanoTime();
+         while (iterator.hasNext()) {
+            Map.Entry<GlobalTransaction, Long> e = iterator.next();
+            long ageNanos = System.nanoTime() - e.getValue();
+            if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
+               iterator.remove();
+               removedEntries++;
+            }
          }
-      }
-      long duration = System.nanoTime() - beginning;
+         long duration = System.nanoTime() - beginning;
 
-      log.debugf(""Finished cleaning up completed transactions. %s transactions were removed, total duration was %s millis, "" +
-                      ""current number of completed transactions is %"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
-                 completedTransactions.size());
+         log.debugf(""Finished cleaning up completed transactions. %d transactions were removed, total duration was %d millis, "" +
+                         ""current number of completed transactions is %d"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
+                    completedTransactions.size());
+      } catch (Exception e) {
+         log.errorf(e, ""Failed to cleanup completed transactions: %s"", e.getMessage());
+      }
    }
 }",2012-11-07T14:07:34Z,127
"@@ -24,9 +24,7 @@
 
 import org.infinispan.CacheException;
 import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.commands.tx.PrepareCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.bucket.Bucket;
 import org.infinispan.loaders.decorators.SingletonStore;
@@ -60,7 +58,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.UUID;
-import java.util.concurrent.ExecutionException;
 
 import static org.jboss.logging.Logger.Level.*;
 
@@ -131,26 +128,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Can not select %s random members for %s"", id = 8)
    void cannotSelectRandomMembers(int numNeeded, List<Address> members);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Detected a view change. Member list changed from %s to %s"", id = 9)
-   void viewChangeDetected(List<Address> oldMembers, List<Address> newMembers);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a JOIN event! Wait for notification from new joiner %s"", id = 10)
-   void joinEvent(Address joiner);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a LEAVE event! Node %s has just left"", id = 11)
-   void leaveEvent(Address leaver);
-
-   @LogMessage(level = FATAL)
-   @Message(value = ""Unable to process leaver!!"", id = 12)
-   void unableToProcessLeaver(@Cause Exception e);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""I %s am participating in rehash, state providers %s, state receivers %s"", id = 13)
-   void participatingInRehash(Address address, List<Address> stateProviders, List<Address> receiversOfLeaverState);
-
    @LogMessage(level = INFO)
    @Message(value = ""DistributionManager not yet joined the cluster. Cannot do anything about other concurrent joiners."", id = 14)
    void distributionManagerNotJoined();
@@ -163,10 +140,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Problem %s encountered when applying state for key %s!"", id = 16)
    void problemApplyingStateForKey(String msg, Object key);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""View change interrupted; not rehashing!"", id = 17)
-   void viewChangeInterrupted();
-
    @LogMessage(level = WARN)
    @Message(value = ""Unable to apply prepare %s"", id = 18)
    void unableToApplyPrepare(PrepareCommand pc, @Cause Throwable t);
@@ -175,26 +148,10 @@ public interface Log extends BasicLogger {
    @Message(value = ""Couldn't acquire shared lock"", id = 19)
    void couldNotAcquireSharedLock();
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Caught exception replaying %s"", id = 20)
-   void exceptionWhenReplaying(WriteCommand cmd, @Cause Exception e);
-
    @LogMessage(level = WARN)
    @Message(value = ""Expected just one response; got %s"", id = 21)
    void expectedJustOneResponse(Map<Address, Response> lr);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Completed leave rehash on node %s in %s - leavers now are %s"", id = 22)
-   void completedLeaveRehash(Address self, String duration, List<Address> leavers);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error pushing tx log"", id = 23)
-   void errorPushingTxLog(@Cause ExecutionException e);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Unable to stop transaction logging!"", id = 24)
-   void unableToStopTransactionLogging(@Cause IllegalMonitorStateException imse);
-
    @LogMessage(level = INFO)
    @Message(value = ""wakeUpInterval is <= 0, not starting expired purge thread"", id = 25)
    void notStartingEvictionThread();
@@ -211,7 +168,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unable to passivate entry under %s"", id = 28)
    void unableToPassivateEntry(Object key, @Cause Exception e);
 
-
    @LogMessage(level = INFO)
    @Message(value = ""Passivating all entries to disk"", id = 29)
    void passivatingAllEntries();
@@ -296,14 +252,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Interrupted or timeout while waiting for AsyncStore worker threads to push all state to the decorated store"", id = 48)
    void interruptedWaitingAsyncStorePush(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing clear in async store"", id = 49)
-   void errorClearinAsyncStore(@Cause CacheLoaderException e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing purging expired from async store"", id = 50)
-   void errorPurgingAsyncStore(@Cause CacheLoaderException e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Unexpected error"", id = 51)
    void unexpectedErrorInAsyncProcessor(@Cause Throwable t);
@@ -376,14 +324,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Cache named %s does not exist on this cache manager!"", id = 68)
    void namedCacheDoesNotExist(String cacheName);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Cache named [%s] exists but isn't in a state to handle remote invocations"", id = 69)
-   void cacheCanNotHandleInvocations(String cacheName);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Quietly ignoring clustered get call %s since unable to acquire processing lock, even after %s"", id = 70)
-   void ignoreClusterGetCall(CacheRpcCommand cmd, String time);
-
    @LogMessage(level = WARN)
    @Message(value = ""Caught exception when handling command %s"", id = 71)
    void exceptionHandlingCommand(ReplicableCommand cmd, @Cause Throwable t);
@@ -396,18 +336,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unexpected error while replicating"", id = 73)
    void unexpectedErrorReplicating(@Cause Throwable t);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Trying to fetch state from %s"", id = 74)
-   void tryingToFetchState(Address member);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Could not find available peer for state, backing off and retrying"", id = 75)
-   void couldNotFindPeerForState();
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Successfully retrieved and applied state from %s"", id = 76)
-   void successfullyAppliedState(Address member);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Message or message buffer is null or empty."", id = 77)
    void msgOrMsgBufferEmpty();
@@ -461,15 +389,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""getCoordinator(): Interrupted while waiting for members to be set"", id = 89)
    void interruptedWaitingForCoordinator(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Unable to retrieve state from member %s"", id = 90)
-   void unableToRetrieveState(Address member, @Cause Exception e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Channel does not contain STREAMING_STATE_TRANSFER. "" +
-         ""Cannot support state transfers!"", id = 91)
-   void streamingStateTransferNotPresent();
-
    @LogMessage(level = WARN)
    @Message(value = ""Channel not set up properly!"", id = 92)
    void channelNotSetUp();
@@ -482,10 +401,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Received new cluster view: %s"", id = 94)
    void receivedClusterView(View newView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Caught while requesting or applying state"", id = 96)
-   void errorRequestingOrApplyingState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error while processing a prepare in a single-phase transaction"", id = 97)
    void errorProcessing1pcPrepareCommand(@Cause Throwable e);
@@ -688,14 +603,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Failed loading value for key %s from cache store"", id = 144)
    void failedLoadingValueFromCacheStore(Object key, @Cause Exception e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error during rehash"", id = 145)
-   void errorDuringRehash(@Cause Throwable th);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error transferring state to node after rehash"", id = 146)
-   void errorTransferringState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error invalidating keys from L1 after rehash"", id = 147)
    void failedToInvalidateKeys(@Cause Exception e);
@@ -729,14 +636,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Unable to unlock keys %2$s for transaction %1$s after they were rebalanced off node %3$s"", id = 154)
    void unableToUnlockRebalancedKeys(GlobalTransaction gtx, List<Object> keys, Address self, @Cause Throwable t);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm pushing data for view %d, received confirmations %s. Cancelling state transfer"", id = 157)
-   void stateTransferTimeoutWaitingForPushConfirmations(int viewId, Map<Address, Integer> pushConfirmations);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm joining for view %d, joined %s. Cancelling state transfer"", id = 158)
-   void stateTransferTimeoutWaitingForJoinConfirmations(int viewId, Map<Address, Integer> joinConfirmations);
-
    @LogMessage(level = WARN)
    @Message(value = ""Unblocking transactions failed"", id = 159)
    void errorUnblockingTransactions(@Cause Exception e);
@@ -761,26 +660,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Rolling back to cache view %d, but last committed view is %d"", id = 164)
    void cacheViewRollbackIdMismatch(int committedViewId, int committedView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error triggering a view installation for cache %s"", id = 165)
-   void errorTriggeringViewInstallation(@Cause RuntimeException e, String cacheName);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""View installation failed for cache %s"", id = 166)
-   void viewInstallationFailure(@Cause Throwable e, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Rejecting state pushed by node %s for view %d, there is no state transfer in progress (we are at view %d)"", id = 167)
-   void remoteStateRejected(Address sender, int viewId, int installedViewId);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error rolling back to cache view %1$d for cache %2$s"", id = 168)
-   void cacheViewRollbackFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error committing cache view %1$d for cache %2$s"", id = 169)
-   void cacheViewCommitFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
    @LogMessage(level = INFO)
    @Message(value = ""Strict peer-to-peer is enabled but the JGroups channel was started externally - this is very likely to result in RPC timeout errors on startup"", id = 171)
    void warnStrictPeerToPeerWithInjectedChannel();
@@ -926,5 +805,16 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @LogMessage(level = WARN)
    @Message(value = ""Could not interrupt as no thread found for command uuid %s"", id=207)
    void couldNotInterruptThread(UUID id);
-   
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""No live owners found for segment %d of cache %s. Current owners are:  %s. Faulty owners: %s"", id=208)
+   void noLiveOwnersFoundForSegment(int segmentId, String cacheName, Collection<Address> owners, Collection<Address> faultySources);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to retrieve transactions for segments %s of cache %s from node %s (node will not be retried)"", id=209)
+   void failedToRetrieveTransactionsForSegments(Collection<Integer> segments, String cacheName, Address source);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to request segments %s of cache %s from node %s (node will not be retried)"", id=210)
+   void failedToRequestSegments(Collection<Integer> segments, String cacheName, Address source);
 }",2012-11-07T14:07:34Z,45
"@@ -263,7 +263,7 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm, boolean deprecated) {
 
       assert gc.asyncTransportExecutor().factory() instanceof DefaultExecutorFactory;
       // Should be 25, but it's overriden by the test cache manager factory
-      assertEquals(""4"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
+      assertEquals(""6"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
       assert gc.asyncTransportExecutor().properties().getProperty(""threadNamePrefix"").equals(""AsyncSerializationThread"");
 
       assert gc.evictionScheduledExecutor().factory() instanceof DefaultScheduledExecutorFactory;",2012-11-07T14:07:34Z,128
"@@ -50,7 +50,6 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -126,7 +125,7 @@ public void test1() throws Exception {
       when(cache.getName()).thenReturn(""testCache"");
 
       StateProvider stateProvider = mock(StateProvider.class);
-      LocalTopologyManager localTopologyManager = mock(LocalTopologyManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
       CacheNotifier cacheNotifier = mock(CacheNotifier.class);
       ExecutorService mockExecutorService = mock(ExecutorService.class);
       RpcManager rpcManager = mock(RpcManager.class);
@@ -183,7 +182,7 @@ public Map<Address, Response> answer(InvocationOnMock invocation) {
 
       // create state provider
       StateConsumerImpl stateConsumer = new StateConsumerImpl();
-      stateConsumer.init(cache, localTopologyManager, interceptorChain, icc, configuration, rpcManager,
+      stateConsumer.init(cache, stateTransferManager, interceptorChain, icc, configuration, rpcManager,
             commandsFactory, cacheLoaderManager, dataContainer, transactionTable, stateTransferLock);
       stateConsumer.start();
 ",2012-11-07T14:07:34Z,56
"@@ -40,6 +40,7 @@
 
 /**
  * Test if state transfer happens properly on a cache with pessimistic transactions.
+ * See https://issues.jboss.org/browse/ISPN-2408.
  *
  * @since 5.2
  */",2012-11-07T14:07:34Z,129
"@@ -75,6 +75,8 @@
  */
 public class TestCacheManagerFactory {
 
+   private static final int MAX_ASYNC_EXEC_THREADS = 6;
+
    public static final String MARSHALLER = LegacyKeySupportSystemProperties.getProperty(""infinispan.test.marshaller.class"", ""infinispan.marshaller.class"");
    private static final Log log = LogFactory.getLog(TestCacheManagerFactory.class);
 
@@ -523,12 +525,12 @@ private static void checkTestName(String fullTestName) {
 
    public static void minimizeThreads(GlobalConfiguration gc) {
       Properties p = new Properties();
-      p.setProperty(""maxThreads"", ""4"");
+      p.setProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
       gc.setAsyncTransportExecutorProperties(p);
    }
 
    public static void minimizeThreads(GlobalConfigurationBuilder builder) {
-      builder.asyncTransportExecutor().addProperty(""maxThreads"", ""4"");
+      builder.asyncTransportExecutor().addProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
    }
 
    public static void amendMarshaller(GlobalConfiguration configuration) {",2012-11-07T14:07:34Z,130
"@@ -35,7 +35,6 @@
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.TransactionTable;
@@ -58,14 +57,9 @@ public abstract class AbstractTxLockingInterceptor extends AbstractLockingInterc
    public void setDependencies(TransactionTable txTable, RpcManager rpcManager) {
       this.txTable = txTable;
       this.rpcManager = rpcManager;
-   }
-
-   @Start
-   private void setClustered() {
       clustered = rpcManager != null;
    }
 
-
    @Override
    public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand command) throws Throwable {
       try {
@@ -169,10 +163,12 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
       TxInvocationContext txContext = (TxInvocationContext) ctx;
       int transactionViewId = -1;
+      boolean useStrictComparison = true;
       if (clustered) {
          transactionViewId = txContext.getCacheTransaction().getViewId();
          if (transactionViewId != TransactionTable.CACHE_STOPPED_VIEW_ID) {
-            checkForPendingLocks = transactionViewId > txTable.getMinViewId();
+            useStrictComparison = txTable.useStrictTopologyIdComparison();
+            checkForPendingLocks = isFromOlderTopology(txTable.getMinViewId(), transactionViewId, useStrictComparison);
          }
       }
 
@@ -183,15 +179,15 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
 
          // Check local transactions first
          for (CacheTransaction ct: txTable.getLocalTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
          }
 
          // ... then remote ones
          for (CacheTransaction ct: txTable.getRemoteTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
@@ -211,6 +207,19 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
    }
 
+   /**
+    * Checks if first topology id is smaller than the second. The comparison can be strict or non-strict,
+    * depending on the isStrictComparison flag.
+    *
+    * @param tx1TopologyId topology id of first transaction
+    * @param tx2TopologyId topology id of second transaction
+    * @param useStrictComparison a flag indicating if comparison must be strict
+    * @return if the first transaction was started in an older topology than the second transaction
+    */
+   private boolean isFromOlderTopology(int tx1TopologyId, int tx2TopologyId, boolean useStrictComparison) {
+      return useStrictComparison ? tx1TopologyId < tx2TopologyId : tx1TopologyId <= tx2TopologyId;
+   }
+
    private TimeoutException newTimeoutException(Object key, TxInvocationContext txContext) {
       return new TimeoutException(""Could not acquire lock on "" + key + "" on behalf of transaction "" +
                                        txContext.getGlobalTransaction() + "". Lock is being held by "" + lockManager.getOwner(key));",2012-09-21T12:26:43Z,131
"@@ -109,9 +109,7 @@ public interface CacheNotifier extends Listenable {
     */
    void notifyTransactionRegistered(GlobalTransaction globalTransaction, InvocationContext ctx);
 
-   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre);
-
-   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre);
-
+   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre);
 
+   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre);
 }
\ No newline at end of file",2012-09-21T12:26:43Z,132
"@@ -334,24 +334,25 @@ public void notifyTransactionRegistered(GlobalTransaction globalTransaction, Inv
    }
 
    @Override
-   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre) {
+   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre) {
       if (!dataRehashedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, DATA_REHASHED);
          e.setPre(pre);
          e.setMembersAtStart(oldView);
          e.setMembersAtEnd(newView);
-         e.setNewViewId(newViewId);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : dataRehashedListeners) listener.invoke(e);
       }
    }
 
    @Override
-   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre) {
+   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre) {
       if (!topologyChangedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, TOPOLOGY_CHANGED);
          e.setPre(pre);
          e.setConsistentHashAtStart(oldConsistentHash);
          e.setConsistentHashAtEnd(newConsistentHash);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : topologyChangedListeners) listener.invoke(e);
       }
    }",2012-09-21T12:26:43Z,133
"@@ -43,7 +43,7 @@ public interface DataRehashedEvent<K, V> extends Event<K, V> {
    Collection<Address> getMembersAtEnd();
 
    /**
-    * @return Retrieves the new view id after rehashing was triggered.
+    * @return Retrieves the new topology id after rehashing was triggered.
     */
-   long getNewViewId();
+   int getNewTopologyId();
 }",2012-09-21T12:26:43Z,134
"@@ -53,7 +53,7 @@ public class EventImpl<K, V> implements CacheEntryActivatedEvent, CacheEntryCrea
    private V value;
    private Collection<Address> membersAtStart, membersAtEnd;
    private ConsistentHash consistentHashAtStart, consistentHashAtEnd;
-   private long newViewId;
+   private int newTopologyId;
    private Map<Object, Object> entries;
 
    public EventImpl() {
@@ -150,8 +150,8 @@ public void setConsistentHashAtEnd(ConsistentHash consistentHashAtEnd) {
       this.consistentHashAtEnd = consistentHashAtEnd;
    }
 
-   public void setNewViewId(long newViewId) {
-      this.newViewId = newViewId;
+   public void setNewTopologyId(int newTopologyId) {
+      this.newTopologyId = newTopologyId;
    }
 
    @Override
@@ -189,7 +189,7 @@ public boolean equals(Object o) {
       if (!Util.safeEquals(consistentHashAtEnd, event.consistentHashAtEnd)) return false;
       if (!Util.safeEquals(membersAtStart, event.membersAtStart)) return false;
       if (!Util.safeEquals(membersAtEnd, event.membersAtEnd)) return false;
-      if (newViewId != event.newViewId) return false;
+      if (newTopologyId != event.newTopologyId) return false;
 
       return true;
    }
@@ -208,7 +208,7 @@ public int hashCode() {
       result = 31 * result + (membersAtEnd != null ? membersAtEnd.hashCode() : 0);
       result = 31 * result + (consistentHashAtStart != null ? consistentHashAtStart.hashCode() : 0);
       result = 31 * result + (consistentHashAtEnd != null ? consistentHashAtEnd.hashCode() : 0);
-      result = 31 * result + ((int) newViewId);
+      result = 31 * result + ((int) newTopologyId);
       return result;
    }
 
@@ -236,8 +236,8 @@ public Collection<Address> getMembersAtEnd() {
    }
 
    @Override
-   public long getNewViewId() {
-      return newViewId;
+   public int getNewTopologyId() {
+      return newTopologyId;
    }
 
    @Override",2012-09-21T12:26:43Z,135
"@@ -40,5 +40,7 @@ public interface TopologyChangedEvent<K, V> extends Event<K, V> {
     */
    ConsistentHash getConsistentHashAtEnd();
 
+   int getNewTopologyId();
+
    //todo [anistor] add topologyId, prevReadCH, prevWriteCH, newReadCH2, newWriteCH
 }",2012-09-21T12:26:43Z,136
"@@ -95,7 +95,7 @@ public class StateConsumerImpl implements StateConsumer {
    private AtomicInteger activeTopologyUpdates = new AtomicInteger(0);
 
    /**
-    * Indicates if currently executing topology update is a rabalance.
+    * Indicates if the currently executing topology update is a rebalance.
     */
    private AtomicBoolean rebalanceInProgress = new AtomicBoolean(false);
 
@@ -197,8 +197,10 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             removedSegments.removeAll(newSegments);
 
             // remove inbound transfers and any data for segments we no longer own
-            log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                  removedSegments, newSegments, previousSegments);
+            if (trace) {
+               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
+                     removedSegments, newSegments, previousSegments);
+            }
             discardSegments(removedSegments);
 
             if (fetchEnabled) {",2012-09-21T12:26:43Z,54
"@@ -80,7 +80,7 @@ public class StateProviderImpl implements StateProvider {
    private volatile ConsistentHash readCh;
 
    /**
-    * A map that keeps track of current outbound state transfers by source address. There could be multiple transfers
+    * A map that keeps track of current outbound state transfers by destination address. There could be multiple transfers
     * flowing to the same destination (but for different segments) so the values are lists.
     */
    private final Map<Address, List<OutboundTransferTask>> transfersByDestination = new HashMap<Address, List<OutboundTransferTask>>();
@@ -124,6 +124,7 @@ public boolean isStateTransferInProgress() {
    }
 
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // do all the work AFTER the consistent hash has changed
       if (tce.isPre())
@@ -236,12 +237,14 @@ private void collectTransactionsToTransfer(List<TransactionInfo> transactionsToT
                lockedKeys.add(key);
             }
          }
-         List<WriteCommand> txModifications = tx.getModifications();
-         WriteCommand[] modifications = null;
-         if (txModifications != null) {
-            modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+         if (!lockedKeys.isEmpty()) {
+            List<WriteCommand> txModifications = tx.getModifications();
+            WriteCommand[] modifications = null;
+            if (txModifications != null) {
+               modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+            }
+            transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), tx.getViewId(), modifications, lockedKeys));
          }
-         transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), modifications, lockedKeys));
       }
    }
 ",2012-09-21T12:26:43Z,55
"@@ -48,10 +48,9 @@
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 
+//todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
 /**
  * // TODO: Document this
  *
@@ -317,8 +316,8 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       } finally {
          stateTransferLock.commandsSharedUnlock();
 
-         log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
          if (newTargets != null && !newTargets.isEmpty()) {
+            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
             rpcManager.invokeRemotely(newTargets, command, true);
          }
       }",2012-09-21T12:26:43Z,115
"@@ -178,19 +178,20 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
       // TODO Improve notification to contain both CHs
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, true);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), true);
 
       stateConsumer.onTopologyUpdate(newCacheTopology, isRebalance);
       stateProvider.onTopologyUpdate(newCacheTopology, isRebalance);
 
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, false);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
       if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
          initialStateTransferComplete.countDown();
       }
    }
 
    @Start(priority = 1000)
+   @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
       if (trace) log.tracef(""Waiting for initial state transfer to finish"");
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);",2012-09-21T12:26:43Z,117
"@@ -50,8 +50,11 @@ public class TransactionInfo {
 
    private final Set<Object> lockedKeys;
 
-   public TransactionInfo(GlobalTransaction globalTransaction, WriteCommand[] modifications, Set<Object> lockedKeys) {
+   private final int topologyId;
+
+   public TransactionInfo(GlobalTransaction globalTransaction, int topologyId, WriteCommand[] modifications, Set<Object> lockedKeys) {
       this.globalTransaction = globalTransaction;
+      this.topologyId = topologyId;
       this.modifications = modifications;
       this.lockedKeys = lockedKeys;
    }
@@ -68,10 +71,15 @@ public Set<Object> getLockedKeys() {
       return lockedKeys;
    }
 
+   public int getTopologyId() {
+      return topologyId;
+   }
+
    @Override
    public String toString() {
       return ""TransactionInfo{"" +
             ""globalTransaction="" + globalTransaction +
+            "", topologyId="" + topologyId +
             "", modifications="" + Arrays.asList(modifications) +
             "", lockedKeys="" + lockedKeys +
             '}';
@@ -92,6 +100,7 @@ public Set<Class<? extends TransactionInfo>> getTypeClasses() {
       @Override
       public void writeObject(ObjectOutput output, TransactionInfo object) throws IOException {
          output.writeObject(object.globalTransaction);
+         output.writeInt(object.topologyId);
          output.writeObject(object.modifications);
          output.writeObject(object.lockedKeys);
       }
@@ -100,9 +109,10 @@ public void writeObject(ObjectOutput output, TransactionInfo object) throws IOEx
       @SuppressWarnings(""unchecked"")
       public TransactionInfo readObject(ObjectInput input) throws IOException, ClassNotFoundException {
          GlobalTransaction globalTransaction = (GlobalTransaction) input.readObject();
+         int topologyId = input.readInt();
          WriteCommand[] modifications = (WriteCommand[]) input.readObject();
          Set<Object> lockedKeys = (Set<Object>) input.readObject();
-         return new TransactionInfo(globalTransaction, modifications, lockedKeys);
+         return new TransactionInfo(globalTransaction, topologyId, modifications, lockedKeys);
       }
    }
 }",2012-09-21T12:26:43Z,137
"@@ -31,8 +31,6 @@
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
 import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.MembershipArithmetic;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
@@ -67,37 +65,41 @@ public class StaleTransactionCleanupService {
    private TransactionTable transactionTable;
    private InterceptorChain invoker;
    private String cacheName;
+   private boolean isDistributed;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
    private ExecutorService lockBreakingService; // a thread pool with max. 1 thread
 
-   /**
-    * Roll back remote transactions originating on nodes that have left the cluster.
-    */
-   @ViewChanged
-   public void onViewChange(ViewChangedEvent vce) {
-      final List<Address> leavers = MembershipArithmetic.getMembersLeft(vce.getOldMembers(),
-                                                                        vce.getNewMembers());
-      if (!leavers.isEmpty()) {
-         log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-         cleanTxForWhichTheOwnerLeft(leavers);
-      }
-   }
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * either because the main data owner left the cluster or because a node joined
     * the cluster and is the new data owner.
     * This method will only ever be called in distributed mode.
     */
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
-      // do all the work AFTER the consistent hash has changed
-      if (tce.isPre())
+      // Roll back remote transactions originating on nodes that have left the cluster.
+      if (tce.isPre()) {
+         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+         if (consistentHashAtStart != null) {
+            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+            if (!leavers.isEmpty()) {
+               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+               cleanTxForWhichTheOwnerLeft(leavers);
+            }
+         }
+         return;
+      }
+
+      if (!isDistributed) {
          return;
+      }
+
+      // do all the work AFTER the consistent hash has changed
 
       Address self = transactionTable.rpcManager.getAddress();
       ConsistentHash chOld = tce.getConsistentHashAtStart();
@@ -173,7 +175,7 @@ public void run() {
       }
    }
 
-   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain) {
+   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain, boolean isDistributed) {
       this.invoker = interceptorChain;
       ThreadFactory tf = new ThreadFactory() {
          @Override
@@ -185,8 +187,9 @@ public Thread newThread(Runnable r) {
          }
       };
       this.cacheName = cacheName;
+      this.isDistributed = isDistributed;
       lockBreakingService = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingDeque<Runnable>(), tf,
-                                                   new ThreadPoolExecutor.CallerRunsPolicy());
+                                                   new ThreadPoolExecutor.DiscardOldestPolicy());
    }
 
    public void stop() {",2012-09-21T12:26:43Z,126
"@@ -38,11 +38,10 @@
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.interceptors.InterceptorChain;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
-import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
+import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.synchronization.SyncLocalTransaction;
@@ -57,9 +56,7 @@
 
 import javax.transaction.Transaction;
 import javax.transaction.TransactionSynchronizationRegistry;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.locks.Lock;
@@ -76,7 +73,7 @@
  * @author Galder Zamarreño
  * @since 4.0
  */
-@Listener(sync = false)
+@Listener
 public class TransactionTable {
 
    public static final int CACHE_STOPPED_VIEW_ID = -1;
@@ -95,25 +92,23 @@ public class TransactionTable {
    protected CommandsFactory commandsFactory;
    private InterceptorChain invoker;
    private CacheNotifier notifier;
-   private EmbeddedCacheManager cm;
    private TransactionSynchronizationRegistry transactionSynchronizationRegistry;
    protected ClusteringDependentLogic clusteringLogic;
    protected boolean clustered = false;
    private Lock minViewRecalculationLock;
 
    /**
-    * minTxViewId is the minimum view ID across all ongoing local and remote transactions. It doesn't update on
-    * transaction creation, but only on removal. That's because it is not possible for a newly created transaction to
-    * have an bigger view ID than the current one.
+    * minTxViewId is the minimum view ID across all ongoing local and remote transactions.
     */
    private volatile int minTxViewId = CACHE_STOPPED_VIEW_ID;
    private volatile int currentViewId = CACHE_STOPPED_VIEW_ID;
+   private volatile boolean useStrictTopologyIdComparison = true;
    private String cacheName;
 
    @Inject
    public void initialize(RpcManager rpcManager, Configuration configuration,
                           InvocationContextContainer icc, InterceptorChain invoker, CacheNotifier notifier,
-                          TransactionFactory gtf, EmbeddedCacheManager cm, TransactionCoordinator txCoordinator,
+                          TransactionFactory gtf, TransactionCoordinator txCoordinator,
                           TransactionSynchronizationRegistry transactionSynchronizationRegistry,
                           CommandsFactory commandsFactory, ClusteringDependentLogic clusteringDependentLogic, Cache cache) {
       this.rpcManager = rpcManager;
@@ -122,7 +117,6 @@ public void initialize(RpcManager rpcManager, Configuration configuration,
       this.invoker = invoker;
       this.notifier = notifier;
       this.txFactory = gtf;
-      this.cm = cm;
       this.txCoordinator = txCoordinator;
       this.transactionSynchronizationRegistry = transactionSynchronizationRegistry;
       this.commandsFactory = commandsFactory;
@@ -139,24 +133,20 @@ private void start() {
          minViewRecalculationLock = new ReentrantLock();
          // Only initialize this if we are clustered.
          remoteTransactions = ConcurrentMapFactory.makeConcurrentMap(concurrencyLevel, 0.75f, concurrencyLevel);
-         cleanupService.start(cacheName, rpcManager, invoker);
-         cm.addListener(cleanupService);
-         cm.addListener(this);
+         cleanupService.start(cacheName, rpcManager, invoker, configuration.clustering().cacheMode().isDistributed());
          notifier.addListener(cleanupService);
-         minTxViewId = rpcManager.getTransport().getViewId();
-         currentViewId = minTxViewId;
-         log.debugf(""Min view id set to %s"", minTxViewId);
+         notifier.addListener(this);
          clustered = true;
       }
    }
 
    @Stop
+   @SuppressWarnings(""unused"")
    private void stop() {
       if (clustered) {
          notifier.removeListener(cleanupService);
-         cm.removeListener(cleanupService);
          cleanupService.stop();
-         cm.removeListener(this);
+         notifier.removeListener(this);
          currentViewId = CACHE_STOPPED_VIEW_ID; // indicate that the cache has stopped
       }
       shutDownGracefully();
@@ -223,6 +213,17 @@ public int getMinViewId() {
       return minTxViewId;
    }
 
+   /**
+    * Indicates if topology id comparisons should be strict if one wants to compare topology ids in oder to tell
+    * if a transaction was started in an older topology than a second transaction. This flag is true most of the time
+    * except when the current topology did not increase its id (it's not caused by a rebalance).
+    *
+    * @return true if strict topology id comparisons should be used, false otherwise
+    */
+   public boolean useStrictTopologyIdComparison() {
+      return useStrictTopologyIdComparison;
+   }
+
    protected void updateStateOnNodesLeaving(Collection<Address> leavers) {
       Set<GlobalTransaction> toKill = new HashSet<GlobalTransaction>();
       for (GlobalTransaction gt : remoteTransactions.keySet()) {
@@ -263,14 +264,24 @@ public void remoteTransactionRollback(GlobalTransaction gtx) {
    }
 
    /**
-    * Creates and register a {@link RemoteTransaction} with no modifications. Returns the created transaction.
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
     *
     * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
     *                               made.
     */
    public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications) {
-      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, currentViewId)
-            : txFactory.newRemoteTransaction(modifications, globalTx, currentViewId);
+      return createRemoteTransaction(globalTx, modifications, currentViewId);
+   }
+
+   /**
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
+    *
+    * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
+    *                               made.
+    */
+   public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications, int topologyId) {
+      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, topologyId)
+            : txFactory.newRemoteTransaction(modifications, globalTx, topologyId);
       registerRemoteTransaction(globalTx, remoteTransaction);
       return remoteTransaction;
    }
@@ -283,6 +294,10 @@ private void registerRemoteTransaction(GlobalTransaction gtx, RemoteTransaction
       }
 
       log.tracef(""Created and registered remote transaction %s"", rtx);
+      if (rtx.getViewId() < minTxViewId) {
+         log.tracef(""Changing minimum view ID from %d to %d"", minTxViewId, rtx.getViewId());
+         minTxViewId = rtx.getViewId();
+      }
    }
 
    /**
@@ -293,6 +308,9 @@ public LocalTransaction getOrCreateLocalTransaction(Transaction transaction, TxI
       LocalTransaction current = localTransactions.get(transaction);
       if (current == null) {
          Address localAddress = rpcManager != null ? rpcManager.getTransport().getAddress() : null;
+         if (rpcManager != null && currentViewId < 0) {
+            throw new IllegalStateException(""Cannot create transactions if topology id is not known yet!"");
+         }
          GlobalTransaction tx = txFactory.newGlobalTransaction(localAddress, false);
          current = txFactory.newLocalTransaction(transaction, tx, ctx.isImplicitTransaction(), currentViewId);
          log.tracef(""Created a new local transaction: %s"", current);
@@ -310,10 +328,6 @@ public boolean removeLocalTransaction(LocalTransaction localTransaction) {
       return localTransaction != null && (removeLocalTransactionInternal(localTransaction.getTransaction()) != null);
    }
 
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      return removeLocalTransactionInternal(tx);
-   }
-
    protected final LocalTransaction removeLocalTransactionInternal(Transaction tx) {
       LocalTransaction removed;
       removed = localTransactions.remove(tx);
@@ -357,8 +371,8 @@ public int getLocalTxCount() {
 
    /**
     * Looks up a LocalTransaction given a GlobalTransaction.
-    * @param txId
-    * @return
+    * @param txId the global transaction identifier
+    * @return the LocalTransaction or null if not found
     */
    public LocalTransaction getLocalTransaction(GlobalTransaction txId) {
       for (LocalTransaction localTx : localTransactions.values()) { //todo [anistor] optimize lookup!
@@ -402,17 +416,21 @@ protected final void recalculateMinViewIdIfNeeded(CacheTransaction removedTransa
       }
    }
 
-   @ViewChanged
-   public void recalculateMinViewIdOnTopologyChange(ViewChangedEvent vce) {
-      // don't do anything if this cache is not clustered - view changes are global
+   @TopologyChanged
+   @SuppressWarnings(""unused"")
+   public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
+      // don't do anything if this cache is not clustered
       if (clustered) {
-         log.debugf(""View changed, recalculating minViewId"");
-         currentViewId = vce.getViewId();
-         calculateMinViewId(-1);
+         if (tce.isPre()) {
+            useStrictTopologyIdComparison = tce.getNewTopologyId() != currentViewId;
+            currentViewId = tce.getNewTopologyId();
+         } else {
+            log.debugf(""Topology changed, recalculating minViewId"");
+            calculateMinViewId(-1);
+         }
       }
    }
 
-
    /**
     * This method calculates the minimum view ID known by the current node.  This method is only used in a clustered
     * cache, and only invoked when either a view change is detected, or a transaction whose view ID is not the same as
@@ -442,7 +460,7 @@ private void calculateMinViewId(int idOfRemovedTransaction) {
                int viewId = ct.getViewId();
                if (viewId < minViewIdFound) minViewIdFound = viewId;
             }
-            if (minViewIdFound > minTxViewId) {
+            if (minViewIdFound != minTxViewId) {
                log.tracef(""Changing minimum view ID from %s to %s"", minTxViewId, minViewIdFound);
                minTxViewId = minViewIdFound;
             } else {",2012-09-21T12:26:43Z,127
"@@ -80,13 +80,6 @@ private void removeXidTxMapping(LocalXaTransaction localTx) {
       xid2LocalTx.remove(xid);
    }
 
-   @Override
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      final LocalTransaction remove = removeLocalTransactionInternal(tx);
-      if (remove != null) removeXidTxMapping((LocalXaTransaction) remove);
-      return remove;
-   }
-
    public LocalXaTransaction getLocalTransaction(Xid xid) {
       return this.xid2LocalTx.get(xid);
    }",2012-09-21T12:26:43Z,138
"@@ -22,10 +22,8 @@
  */
 package org.infinispan.util.concurrent.locks;
 
-import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.jmx.annotations.MBean;",2012-09-21T12:26:43Z,139
"@@ -93,15 +93,16 @@ public boolean isSatisfied() throws Exception {
          public void run() {
             try {
                log.trace(""This thread runs a different tx"");
-               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).resume(suspend);
+               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).commit();
             } catch (Exception e) {
                e.printStackTrace();
             }
          }
       }, false);
 
+      // this 'ensures' transaction called 'suspend' has the chance to start the prepare phase and is waiting to acquire the locks on k held by first transaction before it gets resumed
       Thread.sleep(1000);
 
       log.trace(""Before completing the transaction!"");",2012-09-21T12:26:43Z,140
"@@ -21,7 +21,7 @@
 /**
  * @since 5.1
  */
-@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"", enabled = false) //todo [anistor] temporarily disabled for NBST
+@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"")
 @CleanupAfterMethod
 public class MainOwnerChangesLockTest extends MultipleCacheManagersTest {
 ",2012-09-21T12:26:43Z,141
"@@ -24,6 +24,7 @@
 package org.infinispan.lock.singlelock;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.CleanupAfterMethod;
@@ -33,8 +34,7 @@
 import org.infinispan.transaction.tm.DummyTransaction;
 import org.testng.annotations.Test;
 
-import javax.transaction.Status;
-
+import static org.testng.Assert.assertTrue;
 import static org.testng.Assert.assertEquals;
 
 
@@ -60,21 +60,22 @@ protected void createCacheManagers() throws Throwable {
       waitForClusterToForm();
    }
 
-   @Test(enabled = false, description = ""See ISPN-2113"")
    public void testMinViewId1() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
+
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);
 
       //add a new cache and check that min view is updated
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId2);
       assertEquals(tt1.getMinViewId(), viewId2);
@@ -88,8 +89,8 @@ public void testMinViewId2() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
 
       tm(1).begin();
       cache(1).put(getKeyForCache(0),""v"");
@@ -109,8 +110,8 @@ public boolean isSatisfied() throws Exception {
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);",2012-09-21T12:26:43Z,142
"@@ -36,7 +36,6 @@
 import javax.transaction.InvalidTransactionException;
 import javax.transaction.NotSupportedException;
 import javax.transaction.RollbackException;
-import javax.transaction.Status;
 import javax.transaction.SystemException;
 
 import static org.testng.Assert.assertEquals;
@@ -45,7 +44,7 @@
  * @author Mircea Markus
  * @since 5.1
  */
-@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"", enabled = false, description = ""See ISPN-2113"")
+@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"")
 @CleanupAfterMethod
 public class LockOwnerCrashPessimisticTest extends AbstractLockOwnerCrashTest {
 ",2012-09-21T12:26:43Z,143
"@@ -29,6 +29,7 @@
 import org.infinispan.util.logging.LogFactory;
 
 import java.sql.Connection;
+import java.sql.DatabaseMetaData;
 import java.sql.ResultSet;
 import java.sql.SQLException;
 import java.sql.Statement;
@@ -100,50 +101,18 @@ public TableManipulation() {
    }
 
    public boolean tableExists(Connection connection, String tableName) throws CacheLoaderException {
-     assertNotNull(getTableName(), ""table name is mandatory"");
-     Statement stmt = null;
+     assertNotNull(tableName, ""table name is mandatory"");
      ResultSet rs = null;
      try {
-        stmt = connection.createStatement();
-        String query;
-        switch(getDatabaseType()) {
-           case ORACLE:
-              query = ""SELECT count(*) from (SELECT 1 FROM "" + tableName + "" WHERE ROWNUM = 1) T"";
-              break;
-           case DB2:
-           case DB2_390:
-           case DERBY:
-              query = ""SELECT count(*) from (SELECT 1 FROM "" + tableName + "" FETCH FIRST 1 ROWS ONLY) T"";
-              break;
-           case INFORMIX:
-           case INTERBASE:
-           case FIREBIRD:
-              query = ""SELECT count(*) from (SELECT FIRST 1 1 FROM "" + tableName + "") T"";
-              break;
-           case SQL_SERVER:
-              query = ""SELECT count(*) from (SELECT TOP (1) 1 FROM "" + tableName + "") T"";
-              break;
-           case ACCESS:
-           case HSQL:
-           case SYBASE:
-              query = ""SELECT count(*) from (SELECT TOP 1 1 FROM "" + tableName + "") T"";
-              break;
-           default:
-              // the MySQL-style LIMIT clause
-              query = ""SELECT count(*) from (SELECT 1 FROM "" + tableName + "" LIMIT 1) T"";
-              break;
-        }
-        // Use implicit DB schema mapped to a particular user
-        // It makes environments where DBs are shared easier to support
-        rs = stmt.executeQuery(query);
+        DatabaseMetaData metaData = connection.getMetaData();
+        rs = metaData.getTables(null, null, tableName, new String[] {""TABLE""});
         return rs.next();
      } catch (SQLException e) {
         if (log.isTraceEnabled())
            log.tracef(e, ""SQLException occurs while checking the table %s"", tableName);
         return false;
      } finally {
         JdbcUtil.safeClose(rs);
-        JdbcUtil.safeClose(stmt);
      }
    }
 
@@ -258,7 +227,7 @@ public void start(ConnectionFactory connectionFactory) throws CacheLoaderExcepti
          Connection conn = null;
          try {
             conn = this.connectionFactory.getConnection();
-            if (!tableExists(conn, getTableName())) {
+            if (!tableExists(conn, getUnquotedTableName())) {
                createTable(conn);
             }
          } finally {
@@ -401,14 +370,18 @@ public TableManipulation clone() {
 
    public String getTableName() {
       if (tableName == null) {
-         if (tableNamePrefix == null || cacheName == null) {
-            throw new IllegalStateException(""Both tableNamePrefix and cacheName must be non null at this point!"");
-         }
-         tableName = getIdentifierQuoteString() + tableNamePrefix + ""_"" + cacheName.replace(""."", ""_"") + getIdentifierQuoteString();
+         tableName = getIdentifierQuoteString() + getUnquotedTableName() + getIdentifierQuoteString();
       }
       return tableName;
    }
 
+   public String getUnquotedTableName() {
+      if (tableNamePrefix == null || cacheName == null) {
+         throw new IllegalStateException(""Both tableNamePrefix and cacheName must be non null at this point!"");
+      }
+      return tableNamePrefix + ""_"" + cacheName.replace(""."", ""_"");
+   }
+
    public String getIdentifierQuoteString() {
       if (identifierQuoteString == null) {
          switch (getDatabaseType()) {
@@ -428,7 +401,7 @@ public String getTableNamePrefix() {
    }
 
    public boolean tableExists(Connection connection) throws CacheLoaderException {
-      return tableExists(connection, tableName);
+      return tableExists(connection, getUnquotedTableName());
    }
 
    public String getIdColumnName() {",2012-11-29T11:28:16Z,406
"@@ -122,10 +122,15 @@ public S purgeSynchronously(boolean b) {
    public void validate() {
       async.validate();
       singletonStore.validate();
+      ConfigurationBuilder builder = getBuilder();
       if (!loaders().shared() && !fetchPersistentState && !purgeOnStartup
-            && getBuilder().clustering().cacheMode().isClustered())
+            && builder.clustering().cacheMode().isClustered())
          log.staleEntriesWithoutFetchPersistentStateOrPurgeOnStartup();
-   }
 
+      if (loaders().shared() && !loaders().preload()
+            && builder.indexing().enabled()
+            && builder.indexing().indexLocalOnly())
+         log.localIndexingWithSharedCacheLoaderRequiresPreload();
+   }
 
 }",2012-08-30T15:45:20Z,41
"@@ -62,6 +62,10 @@ public IndexingConfigurationBuilder enabled(boolean enabled) {
       return this;
    }
 
+   boolean enabled() {
+      return enabled;
+   }
+
    /**
     * If true, only index changes made locally, ignoring remote changes. This is useful if indexes
     * are shared across a cluster to prevent redundant indexing of updates.
@@ -71,6 +75,10 @@ public IndexingConfigurationBuilder indexLocalOnly(boolean b) {
       return this;
    }
 
+   boolean indexLocalOnly() {
+      return indexLocalOnly;
+   }
+
    /**
     * <p>
     * Defines a single property. Can be used multiple times to define all needed properties, but the",2012-08-30T15:45:20Z,42
"@@ -49,4 +49,4 @@ public interface LoaderConfigurationBuilder<T extends LoaderConfiguration, S ext
     */
    S withProperties(Properties p);
 
-}
\ No newline at end of file
+}",2012-08-30T15:45:20Z,43
"@@ -72,6 +72,10 @@ public LoadersConfigurationBuilder preload(boolean b) {
       return this;
    }
 
+   boolean preload() {
+      return preload;
+   }
+
    /**
     * This setting should be set to true when multiple cache instances share the same cache store
     * (e.g., multiple nodes in a cluster using a JDBC-based CacheStore pointing to the same, shared
@@ -173,7 +177,7 @@ public LegacyStoreConfigurationBuilder addStore() {
    /**
     * Adds a cache store which uses the specified builder instance to build its configuration
     *
-    * @param klass an instance of {@link StoreConfigurationBuilder}
+    * @param builder an instance of {@link StoreConfigurationBuilder}
     */
    public LoaderConfigurationBuilder<?, ?> addStore(StoreConfigurationBuilder<?, ?> builder) {
       this.cacheLoaders.add(builder);",2012-08-30T15:45:20Z,44
"@@ -31,7 +31,10 @@
 import static org.infinispan.context.Flag.IGNORE_RETURN_VALUES;
 import static org.infinispan.factories.KnownComponentNames.CACHE_MARSHALLER;
 
+import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collections;
+import java.util.List;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
@@ -47,6 +50,7 @@
 import org.infinispan.configuration.cache.LoadersConfiguration;
 import org.infinispan.configuration.cache.StoreConfiguration;
 import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.annotations.ComponentName;
@@ -189,18 +193,24 @@ public void preload() {
                throw new CacheException(""Unable to preload!"", e);
             }
 
-            for (InternalCacheEntry e : state) {
-               if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
-                  cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, SKIP_CACHE_STORE, IGNORE_RETURN_VALUES, SKIP_INDEXING)
-                       .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
-               } else {
-                  cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES, SKIP_INDEXING)
-                       .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
-               }
+            List<Flag> flags = new ArrayList(Arrays.asList(
+                  CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES));
+
+            if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
+               flags.add(SKIP_CACHE_STORE);
+               if (!localIndexingEnabled())
+                  flags.add(SKIP_INDEXING);
+            } else {
+               flags.add(SKIP_INDEXING);
             }
 
+            AdvancedCache<Object, Object> flaggedCache = cache.getAdvancedCache()
+                  .withFlags(flags.toArray(new Flag[]{}));
+
+            for (InternalCacheEntry e : state)
+               flaggedCache.put(e.getKey(), e.getValue(),
+                     e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
+
             if (debugTiming) {
                final long stop = System.nanoTime();
                log.debugf(""Preloaded %s keys in %s"", state.size(), Util.prettyPrintTime(stop - start, TimeUnit.NANOSECONDS));
@@ -209,6 +219,10 @@ public void preload() {
       }
    }
 
+   private boolean localIndexingEnabled() {
+      return configuration.indexing().enabled() && configuration.indexing().indexLocalOnly();
+   }
+
    private Set<InternalCacheEntry> loadState() throws CacheLoaderException {
       int ne = -1;
       if (configuration.eviction().strategy().isEnabled()) ne = configuration.eviction().maxEntries();",2012-08-30T15:45:20Z,29
"@@ -863,6 +863,11 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    void componentFailedToStop(@Cause Throwable e);
 
    @LogMessage(level = WARN)
-   @Message(value = ""Use of the 'loader' element to configure a store is deprecated, please use the 'store' element instead"")
+   @Message(value = ""Use of the 'loader' element to configure a store is deprecated, please use the 'store' element instead"", id = 190)
    void deprecatedLoaderAsStoreConfiguration();
+
+   @LogMessage(level = DEBUG)
+   @Message(value = ""When indexing locally a cache with shared cache loader, preload must be enabled"", id = 191)
+   void localIndexingWithSharedCacheLoaderRequiresPreload();
+
 }",2012-08-30T15:45:20Z,45
"@@ -29,7 +29,6 @@
 import org.infinispan.test.TestingUtil;
 import org.testng.annotations.Test;
 
-import java.util.LinkedList;
 import java.util.List;
 
 @Test (testName = ""loaders.SharedCacheStoreTest"", groups = ""functional"")
@@ -50,13 +49,6 @@ protected void createCacheManagers() throws Throwable {
       // don't create the caches here, we want them to join the cluster one by one
    }
 
-   private List<CacheStore> cachestores() {
-      List<CacheStore> l = new LinkedList<CacheStore>();
-      for (Cache<?, ?> c: caches())
-         l.add(TestingUtil.extractComponent(c, CacheLoaderManager.class).getCacheStore());
-      return l;
-   }
-
    public void testUnnecessaryWrites() throws CacheLoaderException {
       cache(0).put(""key"", ""value"");
 
@@ -66,7 +58,8 @@ public void testUnnecessaryWrites() throws CacheLoaderException {
       for (Cache<Object, Object> c: caches())
          assert ""value"".equals(c.get(""key""));
 
-      for (CacheStore cs: cachestores()) {
+      List<CacheStore> cachestores = TestingUtil.cachestores(caches());
+      for (CacheStore cs: cachestores) {
          assert cs.containsKey(""key"");
          DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
          assert dimcs.stats().get(""clear"") == 0: ""Cache store should not be cleared, purgeOnStartup is false"";
@@ -78,7 +71,7 @@ public void testUnnecessaryWrites() throws CacheLoaderException {
       for (Cache<Object, Object> c: caches())
          assert c.get(""key"") == null;
 
-      for (CacheStore cs: cachestores()) {
+      for (CacheStore cs: cachestores) {
          assert !cs.containsKey(""key"");
          DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
          assert dimcs.stats().get(""remove"") == 1: ""Entry should have been removed from the cache store just once, but was removed "" + dimcs.stats().get(""store"") + "" times"";",2012-08-30T15:45:20Z,46
"@@ -0,0 +1,73 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.TestingUtil;
+
+import java.util.concurrent.Callable;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+
+/**
+ * Represents a joining node, designed for state transfer related tests.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public class JoiningNode {
+
+   private final EmbeddedCacheManager cm;
+   private final CountDownLatch latch;
+   private final MergeOrViewChangeListener listener;
+
+   public JoiningNode(EmbeddedCacheManager cm) {
+      this.cm = cm;
+      latch = new CountDownLatch(1);
+      listener = new MergeOrViewChangeListener(latch);
+      cm.addListener(listener);
+   }
+
+   public Cache getCache() {
+      return cm.getCache();
+   }
+
+   public Cache getCache(String cacheName) {
+      return cm.getCache(cacheName);
+   }
+
+   public void waitForJoin(long timeout, Cache... caches) throws InterruptedException {
+      // Wait for either a merge or view change to happen
+      latch.await(timeout, TimeUnit.MILLISECONDS);
+      // Wait for the state transfer to end
+      TestingUtil.waitForRehashToComplete(caches);
+   }
+
+   private boolean isStateTransferred() {
+      return !listener.merged;
+   }
+
+   void verifyStateTransfer(Callable<Void> verify) throws Exception {
+      if (isStateTransferred())
+         verify.call();
+   }
+
+}",2012-08-30T15:45:20Z,47
"@@ -0,0 +1,72 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.statetransfer;
+
+import org.infinispan.notifications.Listener;
+import org.infinispan.notifications.cachemanagerlistener.annotation.Merged;
+import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
+import org.infinispan.notifications.cachemanagerlistener.event.MergeEvent;
+import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+import java.util.concurrent.CountDownLatch;
+
+/**
+ * Listener implementation that detects whether a merge or
+ * a view change occurred.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Listener
+public class MergeOrViewChangeListener {
+
+   private static final Log log = LogFactory.getLog(MergeOrViewChangeListener.class);
+
+   // The latch provides the visibility guarantees
+   public boolean merged;
+
+   // The latch provides the visibility guarantees
+   public boolean viewChanged;
+
+   private final CountDownLatch latch;
+
+   public MergeOrViewChangeListener(CountDownLatch latch) {
+      this.latch = latch;
+   }
+
+   @Merged
+   @SuppressWarnings(""unused"")
+   public void mergedView(MergeEvent me) {
+      log.infof(""View merged received %s"", me);
+      merged = true;
+      latch.countDown();
+   }
+
+   @ViewChanged
+   @SuppressWarnings(""unused"")
+   public void viewChanged(ViewChangedEvent e) {
+      log.infof(""View change received %s"", e);
+      viewChanged = true;
+      latch.countDown();
+   }
+
+}",2012-08-30T15:45:20Z,48
"@@ -25,11 +25,6 @@
 import org.infinispan.Cache;
 import org.infinispan.config.Configuration;
 import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.notifications.Listener;
-import org.infinispan.notifications.cachemanagerlistener.annotation.Merged;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.MergeEvent;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
@@ -46,8 +41,7 @@
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.lang.reflect.Method;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.TimeUnit;
+import java.util.concurrent.Callable;
 
 @Test(groups = ""functional"", testName = ""statetransfer.StateTransferFunctionalTest"", enabled = true)
 public class StateTransferFunctionalTest extends MultipleCacheManagersTest {
@@ -183,10 +177,10 @@ public void testInitialStateTransfer(Method m) throws Exception {
       cache1 = cm1.getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node = new JoiningNode();
+      JoiningNode node = new JoiningNode(createCacheManager());
       cache2 = node.getCache(cacheName);
       node.waitForJoin(60000, cache1, cache2);
-      node.verifyStateTransfer(cache2);
+      node.verifyStateTransfer(new CacheVerifier(cache2));
 
       logTestEnd(m);
    }
@@ -199,10 +193,10 @@ public void testInitialStateTransferCacheNotPresent(Method m) throws Exception {
       cache1 = cacheManager1.getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node = new JoiningNode();
+      JoiningNode node = new JoiningNode(createCacheManager());
       cache2 = node.getCache(cacheName);
       node.waitForJoin(60000, cache1, cache2);
-      node.verifyStateTransfer(cache2);
+      node.verifyStateTransfer(new CacheVerifier(cache2));
 
       cacheManager1.defineConfiguration(""otherCache"", config.clone());
       cacheManager1.getCache(""otherCache"");
@@ -216,16 +210,16 @@ public void testConcurrentStateTransfer(Method m) throws Exception {
       cache1 = createCacheManager().getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
 
       cache1.put(""delay"", new StateTransferFunctionalTest.DelayTransfer());
 
       node2.waitForJoin(60000, cache1, cache2);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
-      final JoiningNode node3 = new JoiningNode();
-      final JoiningNode node4 = new JoiningNode();
+      final JoiningNode node3 = new JoiningNode(createCacheManager());
+      final JoiningNode node4 = new JoiningNode(createCacheManager());
 
       Thread t1 = new Thread(new Runnable() {
          public void run() {
@@ -252,8 +246,8 @@ public void run() {
       node3.waitForJoin(120000, cache1, cache2, cache3, cache4);
       node4.waitForJoin(120000, cache1, cache2, cache3, cache4);
 
-      node3.verifyStateTransfer(cache3);
-      node4.verifyStateTransfer(cache4);
+      node3.verifyStateTransfer(new CacheVerifier(cache3));
+      node4.verifyStateTransfer(new CacheVerifier(cache4));
 
       logTestEnd(m);
    }
@@ -300,10 +294,10 @@ public void testInitialStateTransferAfterRestart(Method m) throws Exception {
       cache1 = createCacheManager().getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
       node2.waitForJoin(60000, cache1, cache2);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       cache2.stop();
       cache2.start();
@@ -324,7 +318,7 @@ private void logTestLifecycle(Method m, String lifecycle) {
       log.infof(""%s %s - %s"", m.getName(), lifecycle, testCount);
    }
 
-   private void thirdWritingCacheTest(boolean tx) throws InterruptedException {
+   private void thirdWritingCacheTest(boolean tx) throws Exception {
       Cache<Object, Object> cache1, cache2, cache3;
       cache1 = createCacheManager().getCache(cacheName);
       cache3 = createCacheManager().getCache(cacheName);
@@ -340,15 +334,15 @@ private void thirdWritingCacheTest(boolean tx) throws InterruptedException {
       WritingThread writerThread = new WritingThread(cache3, tx);
       writerThread.start();
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
 
       node2.waitForJoin(60000, cache1, cache2, cache3);
 
       writerThread.stopThread();
       writerThread.join();
 
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       int count = writerThread.result();
 
@@ -374,7 +368,7 @@ protected void writeInitialData(final Cache<Object, Object> c) {
       c.put(A_C_AGE, FORTY);
    }
 
-   private void writingThreadTest(boolean tx) throws InterruptedException {
+   private void writingThreadTest(boolean tx) throws Exception {
       Cache<Object, Object> cache1, cache2;
       cache1 = createCacheManager().getCache(cacheName);
 
@@ -388,81 +382,34 @@ private void writingThreadTest(boolean tx) throws InterruptedException {
       writerThread.start();
       verifyInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
       node2.waitForJoin(60000, cache1, cache2);
 
       writerThread.stopThread();
       writerThread.join();
 
       verifyInitialData(cache1);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       int count = writerThread.result();
 
       for (int c = 0; c < count; c++)
          assert new Integer(c).equals(cache2.get(""test"" + c)) : ""Entry under key [test"" + c + ""] was ["" + cache2.get(""test"" + c) + ""] but expected ["" + c + ""]"";
    }
 
-   @Listener
-   public static class MergeOrViewChangeListener {
-      // The latch provides the visibility guarantees
-      public boolean merged;
-      // The latch provides the visibility guarantees
-      public boolean viewChanged;
-      private final CountDownLatch latch;
+   public class CacheVerifier implements Callable<Void> {
 
-      public MergeOrViewChangeListener(CountDownLatch latch) {
-         this.latch = latch;
-      }
-
-      @Merged
-      public void mergedView(MergeEvent me) {
-         log.infof(""View merged received %s"", me);
-         merged = true;
-         latch.countDown();
-      }
-
-      @ViewChanged
-      public void viewChanged(ViewChangedEvent e) {
-         log.infof(""View change received %s"", e);
-         viewChanged = true;
-         latch.countDown();
-      }
-
-   }
-
-   private class JoiningNode {
-
-      private final EmbeddedCacheManager cm;
-      private final CountDownLatch latch;
-      private final MergeOrViewChangeListener listener;
-
-      private JoiningNode() {
-         cm = createCacheManager();
-         latch = new CountDownLatch(1);
-         listener = new MergeOrViewChangeListener(latch);
-         cm.addListener(listener);
-      }
-
-      Cache getCache(String cacheName) {
-         return cm.getCache(cacheName);
-      }
-
-      void waitForJoin(long timeout, Cache... caches) throws InterruptedException {
-         // Wait for either a merge or view change to happen
-         latch.await(timeout, TimeUnit.MILLISECONDS);
-         // Wait for the state transfer to end
-         TestingUtil.waitForRehashToComplete(caches);
-      }
+      private final Cache<Object, Object> cache;
 
-      private boolean isStateTransferred() {
-         return !listener.merged;
+      public CacheVerifier(Cache<Object, Object> cache) {
+         this.cache = cache;
       }
 
-      void verifyStateTransfer(Cache cache) {
-         if (isStateTransferred())
-            StateTransferFunctionalTest.this.verifyInitialData(cache);
+      @Override
+      public Void call() throws Exception {
+         verifyInitialData(cache);
+         return null;
       }
 
    }",2012-08-30T15:45:20Z,49
"@@ -33,6 +33,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.LinkedList;
 import java.util.List;
 import java.util.Random;
 import java.util.Set;
@@ -62,6 +63,7 @@
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.loaders.CacheLoader;
 import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.loaders.CacheStore;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.AbstractDelegatingMarshaller;
@@ -754,6 +756,13 @@ public static void clearCacheLoader(Cache cache) {
       }
    }
 
+   public static <K, V> List<CacheStore> cachestores(List<Cache<K, V>> caches) {
+      List<CacheStore> l = new LinkedList<CacheStore>();
+      for (Cache<?, ?> c: caches)
+         l.add(TestingUtil.extractComponent(c, CacheLoaderManager.class).getCacheStore());
+      return l;
+   }
+
    private static void removeInMemoryData(Cache cache) {
       EmbeddedCacheManager mgr = cache.getCacheManager();
       Address a = mgr.getAddress();",2012-08-30T15:45:20Z,50
"@@ -0,0 +1,69 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.cacheloaders;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.query.statetransfer.BaseReIndexingTest;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.Test;
+
+/**
+ * Tests behaviour of indexing and querying when a cache is clustered and
+ * and it's configured with a shared cache store. If preload is enabled,
+ * it should be possible to index the preloaded contents.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.cacheloaders.SharedCacheLoaderQueryIndexTest"")
+public class SharedCacheLoaderQueryIndexTest extends BaseReIndexingTest {
+
+   protected void configureCache(ConfigurationBuilder builder) {
+      // To force a shared cache store, make sure storeName property
+      // for dummy store is the same for all nodes
+      builder.clustering().stateTransfer().fetchInMemoryState(false)
+         .loaders().shared(true).preload(true).addStore()
+            .cacheStore(new DummyInMemoryCacheStore()).addProperty(""storeName"",
+            SharedCacheLoaderQueryIndexTest.class.getName());
+   }
+
+   public void testPreloadIndexingAfterAddingNewNode() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      for (CacheStore cs: TestingUtil.cachestores(this.<String, Person>caches())) {
+         assert cs.containsKey(persons[0].getName()) :
+               ""Cache misconfigured, maybe cache store not pointing to same place, maybe passivation on...etc"";
+         DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
+         assert dimcs.stats().get(""clear"") == 0:
+               ""Cache store should not be cleared, purgeOnStartup is false"";
+         assert dimcs.stats().get(""store"") == 4:
+               ""Cache store should have been written to just once, but was written to "" + dimcs.stats().get(""store"") + "" times"";
+      }
+
+      // Before adding a node, verify that the query resolves properly
+      executeSimpleQuery(this.<String, Person>caches().get(0));
+
+      addNodeCheckingContentsAndQuery();
+   }
+
+}",2012-08-30T15:45:20Z,7
"@@ -0,0 +1,138 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.apache.lucene.queryParser.ParseException;
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.query.CacheQuery;
+import org.infinispan.query.test.Person;
+import org.infinispan.statetransfer.JoiningNode;
+import org.infinispan.test.CacheManagerCallable;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.fwk.TransportFlags;
+
+import java.util.List;
+
+import static org.infinispan.query.helper.TestQueryHelperFactory.createCacheQuery;
+import static org.infinispan.test.TestingUtil.withCacheManager;
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Base class for state transfer and query related tests
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public abstract class BaseReIndexingTest extends MultipleCacheManagersTest {
+
+   protected Person[] persons;
+   protected ConfigurationBuilder builder;
+
+   abstract protected void configureCache(ConfigurationBuilder builder);
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      builder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, false);
+
+      // Explicitly disable fetching in-memory state in order
+      // to fetch it from the persistence layer
+      builder.indexing().enable().indexLocalOnly(true)
+            .addProperty(""hibernate.search.default.directory_provider"", ""ram"")
+            .addProperty(""hibernate.search.lucene_version"", ""LUCENE_CURRENT"");
+
+      configureCache(builder);
+
+      createClusteredCaches(2, builder);
+   }
+
+   private EmbeddedCacheManager createCacheManager() {
+      return addClusterEnabledCacheManager(
+            builder, new TransportFlags().withMerge(true));
+   }
+
+   protected void executeSimpleQuery(Cache<String, Person> cache) throws ParseException {
+      CacheQuery cacheQuery = createCacheQuery(cache, ""blurb"", ""playing"");
+      List<Object> found = cacheQuery.list();
+      int elems = found.size();
+      assertEquals(1, elems);
+      Object val = found.get(0);
+      Person expectedPerson = persons[0];
+      assertEquals(expectedPerson, val);
+   }
+
+   protected void loadCacheEntries(Cache<String, Person> cache) {
+      Person person1 = new Person();
+      person1.setName(""NavinSurtani"");
+      person1.setBlurb(""Likes playing WoW"");
+      person1.setAge(45);
+
+      Person person2 = new Person();
+      person2.setName(""BigGoat"");
+      person2.setBlurb(""Eats grass"");
+      person2.setAge(30);
+
+      Person person3 = new Person();
+      person3.setName(""MiniGoat"");
+      person3.setBlurb(""Eats cheese"");
+      person3.setAge(35);
+
+      Person person4 = new Person();
+      person4.setName(""MightyGoat"");
+      person4.setBlurb(""Also eats grass"");
+      person4.setAge(66);
+
+      persons = new Person[]{person1, person2, person3, person4};
+
+      // Put the 3 created objects in the cache
+      cache.put(person1.getName(), person1);
+      cache.put(person2.getName(), person2);
+      cache.put(person3.getName(), person3);
+      cache.put(person4.getName(), person4);
+   }
+
+   protected void addNodeCheckingContentsAndQuery() {
+      withCacheManager(new CacheManagerCallable(createCacheManager()) {
+         @Override
+         public void call() {
+            try {
+               // New node joining
+               JoiningNode newNode = new JoiningNode(cm);
+               Cache<String, Person> newCache = newNode.getCache();
+               newNode.waitForJoin(120000, caches().get(0), caches().get(1), newCache);
+
+               // Verify state transfer
+               int size = newCache.size();
+               assertEquals(4, size);
+               for (int i = 0; i < size; i++)
+                  assertEquals(persons[i], newCache.get(persons[i].getName()));
+
+               // Repeat query on new node
+               executeSimpleQuery(newCache);
+            } catch (Exception e) {
+               throw new RuntimeException(e);
+            }
+         }
+      });
+   }
+
+}",2012-08-30T15:45:20Z,51
"@@ -0,0 +1,94 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.Test;
+
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Test that verifies that querying works even after multiple nodes have
+ * started with unshared, passivated, cache stores, and a new node comes in
+ * to fetch the persistent state from the other nodes.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.PersistentStateTransferQueryIndexTest"")
+public class PersistentStateTransferQueryIndexTest extends BaseReIndexingTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      builder.clustering().stateTransfer().fetchInMemoryState(false)
+            .loaders().passivation(true).shared(false).addStore()
+            .cacheStore(new DummyInMemoryCacheStore())
+                  .fetchPersistentState(true);
+   }
+
+   public void testFetchingPersistentStateUpdatesIndex() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      // Before adding a node, verify that the query resolves properly
+      Cache<String, Person> cache1 = this.<String, Person>caches().get(0);
+      executeSimpleQuery(cache1);
+
+      // Since passivation is enabled, cache stores should still be empty
+      checkCacheStoresEmpty();
+
+      // Evict manually entries from both nodes
+      for (Cache<Object, Object> cache : caches()) {
+         for (Person p2 : persons) {
+            cache.evict(p2.getName());
+         }
+      }
+
+      // After eviction, cache stores should be loaded with instances
+      checkCacheStoresContainPersons();
+
+      // Finally add a node and verify that state transfer happens and query works
+      addNodeCheckingContentsAndQuery();
+   }
+
+   private void checkCacheStoresContainPersons() throws CacheLoaderException {
+      for (Cache<Object, Object> cache : caches()) {
+         CacheStore store = TestingUtil.extractComponent(cache, CacheLoaderManager.class).getCacheStore();
+         for (int i = 0; i < persons.length; i++)
+            assertEquals(persons[i], store.load(persons[i].getName()).getValue());
+      }
+   }
+
+   private void checkCacheStoresEmpty() throws CacheLoaderException {
+      for (Cache<Object, Object> cache : caches()) {
+         CacheStore store = TestingUtil.extractComponent(cache, CacheLoaderManager.class).getCacheStore();
+         for (Person person : persons) {
+            assert !store.containsKey(person.getName());
+         }
+      }
+   }
+
+}",2012-08-30T15:45:20Z,52
"@@ -0,0 +1,50 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.query.test.Person;
+import org.testng.annotations.Test;
+
+/**
+ * Test that verifies that querying works even after a new node is added and
+ * state transfer has provided it with the data belonging to that node.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.StateTransferQueryIndexTest"")
+public class StateTransferQueryIndexTest extends BaseReIndexingTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      builder.clustering().stateTransfer().fetchInMemoryState(true);
+   }
+
+   public void testQueryAfterAddingNewNode() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      // Before adding a node, verify that the query resolves properly
+      executeSimpleQuery(this.<String, Person>caches().get(0));
+
+      addNodeCheckingContentsAndQuery();
+   }
+
+}",2012-08-30T15:45:20Z,53
"@@ -23,7 +23,11 @@
 
 package org.infinispan.statetransfer;
 
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+
 import org.infinispan.Cache;
+import org.infinispan.CacheException;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.configuration.global.GlobalConfiguration;
@@ -61,6 +65,8 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private GroupManager groupManager;   // optional
    private LocalTopologyManager localTopologyManager;
 
+   private CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
+
    public StateTransferManagerImpl() {
    }
 
@@ -170,12 +176,27 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
       ConsistentHash oldCH = oldCacheTopology != null ? oldCacheTopology.getWriteConsistentHash() : null;
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
+      // TODO Improve notification to contain both CHs
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, true);
 
       stateConsumer.onTopologyUpdate(newCacheTopology, isRebalance);
       stateProvider.onTopologyUpdate(newCacheTopology, isRebalance);
 
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, false);
+
+      if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
+         initialStateTransferComplete.countDown();
+      }
+   }
+
+   @Start(priority = 1000)
+   public void waitForInitialStateTransferToComplete() throws InterruptedException {
+      if (trace) log.tracef(""Waiting for initial state transfer to finish"");
+      boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);
+      if (!success) {
+         throw new CacheException(String.format(""Initial state transfer timed out for cache %s on %s"",
+               cacheName, rpcManager.getAddress()));
+      }
    }
 
    @Stop(priority = 20)",2012-08-31T21:05:45Z,117
"@@ -20,7 +20,7 @@
 
 import junit.framework.AssertionFailedError;
 
-import org.infinispan.commands.VisitableCommand;
+import org.infinispan.commands.AbstractFlagAffectedCommand;
 import org.infinispan.commands.write.ApplyDeltaCommand;
 import org.infinispan.commands.write.ClearCommand;
 import org.infinispan.commands.write.PutKeyValueCommand;
@@ -71,8 +71,8 @@ public Object visitApplyDeltaCommand(InvocationContext ctx, ApplyDeltaCommand co
       return handleDefaultCheckingAssertion(ctx, command);
    }
 
-   protected Object handleDefaultCheckingAssertion(InvocationContext ctx, VisitableCommand command) throws Throwable {
-      if (! ctx.hasFlag(Flag.SKIP_INDEXING)) {
+   protected Object handleDefaultCheckingAssertion(InvocationContext ctx, AbstractFlagAffectedCommand command) throws Throwable {
+      if (! command.hasFlag(Flag.SKIP_INDEXING)) {
          throw new AssertionFailedError(""A write operation was detected which is not using SKIP_INDEXING flag"");
       }
       return super.invokeNextInterceptor(ctx, command);",2012-09-18T12:40:22Z,600
"@@ -23,6 +23,7 @@
 package org.infinispan.query.backend;
 
 import org.hibernate.search.spi.SearchFactoryIntegrator;
+import org.infinispan.commands.AbstractFlagAffectedCommand;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.factories.KnownComponentNames;
@@ -72,7 +73,7 @@ public void injectDependencies(TransactionManager transactionManager,
    }
 
    @Override
-   protected boolean shouldModifyIndexes(InvocationContext ctx) {
-      return ctx.isOriginLocal() && ! ctx.hasFlag(Flag.SKIP_INDEXING);
+   protected boolean shouldModifyIndexes(AbstractFlagAffectedCommand command, InvocationContext ctx) {
+      return ctx.isOriginLocal() && ! command.hasFlag(Flag.SKIP_INDEXING);
    }
 }",2012-09-18T12:40:22Z,566
"@@ -27,6 +27,7 @@
 import org.hibernate.search.backend.spi.WorkType;
 import org.hibernate.search.engine.spi.EntityIndexBinder;
 import org.hibernate.search.spi.SearchFactoryIntegrator;
+import org.infinispan.commands.AbstractFlagAffectedCommand;
 import org.infinispan.commands.write.ClearCommand;
 import org.infinispan.commands.write.PutKeyValueCommand;
 import org.infinispan.commands.write.PutMapCommand;
@@ -94,8 +95,8 @@ public void injectDependencies(
       this.asyncExecutor = e;
    }
 
-   protected boolean shouldModifyIndexes(InvocationContext ctx) {
-      return ! ctx.hasFlag(Flag.SKIP_INDEXING);
+   protected boolean shouldModifyIndexes(AbstractFlagAffectedCommand command, InvocationContext ctx) {
+      return !command.hasFlag(Flag.SKIP_INDEXING);
    }
 
    /**
@@ -113,7 +114,7 @@ public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand
       // do the actual put first.
       Object toReturn = invokeNextInterceptor(ctx, command);
 
-      if (shouldModifyIndexes(ctx)) {
+      if (shouldModifyIndexes(command, ctx)) {
          // First making a check to see if the key is already in the cache or not. If it isn't we can add the key no problem,
          // otherwise we need to be updating the indexes as opposed to simply adding to the indexes.
          getLog().debug(""Infinispan Query indexing is triggered"");
@@ -138,7 +139,7 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
       // remove the object out of the cache first.
       Object valueRemoved = invokeNextInterceptor(ctx, command);
 
-      if (command.isSuccessful() && !command.isNonExistent() && shouldModifyIndexes(ctx)) {
+      if (command.isSuccessful() && !command.isNonExistent() && shouldModifyIndexes(command, ctx)) {
          Object value = extractValue(valueRemoved);
          if (updateKnownTypesIfNeeded( value )) {
             removeFromIndexes(value, extractValue(command.getKey()));
@@ -150,7 +151,7 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
    @Override
    public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
       Object valueReplaced = invokeNextInterceptor(ctx, command);
-      if (valueReplaced != null && command.isSuccessful() && shouldModifyIndexes(ctx)) {
+      if (valueReplaced != null && command.isSuccessful() && shouldModifyIndexes(command, ctx)) {
 
          Object[] parameters = command.getParameters();
          Object p1 = extractValue(parameters[1]);
@@ -174,7 +175,7 @@ public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command)
    public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
       Object mapPut = invokeNextInterceptor(ctx, command);
 
-      if (shouldModifyIndexes(ctx)) {
+      if (shouldModifyIndexes(command, ctx)) {
          Map<Object, Object> dataMap = command.getMap();
 
          // Loop through all the keys and put those key, value pairings into lucene.
@@ -195,7 +196,7 @@ public Object visitClearCommand(InvocationContext ctx, ClearCommand command) thr
       // This method is called when somebody calls a cache.clear() and we will need to wipe everything in the indexes.
       Object returnValue = invokeNextInterceptor(ctx, command);
 
-      if (shouldModifyIndexes(ctx)) {
+      if (shouldModifyIndexes(command, ctx)) {
          if (getLog().isTraceEnabled()) getLog().trace(""shouldModifyIndexes() is true and we can clear the indexes"");
 
          for (Class c : this.knownClasses.keySet()) {",2012-09-18T12:40:22Z,363
"@@ -26,6 +26,7 @@
 import org.infinispan.CacheException;
 import org.infinispan.commands.AbstractVisitor;
 import org.infinispan.commands.control.LockControlCommand;
+import org.infinispan.commands.read.GetKeyValueCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.write.ApplyDeltaCommand;
 import org.infinispan.commands.write.ClearCommand;
@@ -65,8 +66,8 @@ public class OptimisticLockingInterceptor extends AbstractTxLockingInterceptor {
 
    private LockAcquisitionVisitor lockAcquisitionVisitor;
    private static final MurmurHash3 HASH = new MurmurHash3();
+   private boolean needToMarkReads;
    private final static Comparator<Object> keyComparator = new Comparator<Object>() {
-
       @Override
       public int compare(Object o1, Object o2) {
          int thisVal = HASH.hash(o1);
@@ -95,11 +96,20 @@ public void start() {
             configuration.isWriteSkewCheck() &&
             configuration.getIsolationLevel() == IsolationLevel.REPEATABLE_READ) {
          lockAcquisitionVisitor = new LocalWriteSkewCheckingLockAcquisitionVisitor();
+         needToMarkReads = true;
       } else {
          lockAcquisitionVisitor = new LockAcquisitionVisitor();
+         needToMarkReads = false;
       }
    }
 
+   private void markKeyAsRead(InvocationContext ctx, Object key) {
+      if (needToMarkReads && ctx.isInTxScope()) {
+         TxInvocationContext tctx = (TxInvocationContext) ctx;
+         tctx.getCacheTransaction().addReadKey(key);
+      }
+   }
+   
    @Override
    public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand command) throws Throwable {
       abortIfRemoteTransactionInvalid(ctx, command);
@@ -125,12 +135,19 @@ public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand comman
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
       try {
+         if (command.isConditional()) markKeyAsRead(ctx, command.getKey());
          return invokeNextInterceptor(ctx, command);
       } catch (Throwable te) {
          throw cleanLocksAndRethrow(ctx, te);
       }
    }
    
+   @Override
+   public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand command) throws Throwable {
+      markKeyAsRead(ctx, command.getKey());
+      return super.visitGetKeyValueCommand(ctx, command);
+   }
+   
    @Override
    public Object visitApplyDeltaCommand(InvocationContext ctx, ApplyDeltaCommand command) throws Throwable {
       try {
@@ -152,6 +169,7 @@ public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) t
    @Override
    public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
       try {
+         if (command.isConditional()) markKeyAsRead(ctx, command.getKey());
          return invokeNextInterceptor(ctx, command);
       } catch (Throwable te) {
          throw cleanLocksAndRethrow(ctx, te);
@@ -161,6 +179,7 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
    @Override
    public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
       try {
+         markKeyAsRead(ctx, command.getKey());
          return invokeNextInterceptor(ctx, command);
       } catch (Throwable te) {
          throw cleanLocksAndRethrow(ctx, te);
@@ -254,8 +273,8 @@ private class LocalWriteSkewCheckingLockAcquisitionVisitor extends LockAcquisiti
       @Override
       protected void performWriteSkewCheck(TxInvocationContext ctx, Object key) {
          CacheEntry ce = ctx.lookupEntry(key);
-         if (ce instanceof RepeatableReadEntry) {
-            ((RepeatableReadEntry) ce).performLocalWriteSkewCheck(dataContainer, true);
+         if (ce instanceof RepeatableReadEntry && ctx.getCacheTransaction().keyRead(key)) {
+               ((RepeatableReadEntry) ce).performLocalWriteSkewCheck(dataContainer, true);
          }
       }
    }",2012-03-28T06:27:41Z,444
"@@ -200,4 +200,14 @@ public EntryVersionsMap getUpdatedEntryVersions() {
    public void setUpdatedEntryVersions(EntryVersionsMap updatedEntryVersions) {
       this.updatedEntryVersions = updatedEntryVersions;
    }
+   
+   @Override
+   public void addReadKey(Object key) {
+      // No-op
+   }
+   
+   @Override
+   public boolean keyRead(Object key) {
+      return false;
+   }
 }",2012-03-28T06:27:41Z,541
"@@ -53,6 +53,7 @@ public abstract class LocalTransaction extends AbstractCacheTransaction {
    private static final boolean trace = log.isTraceEnabled();
 
    private Set<Address> remoteLockedNodes;
+   protected Set<Object> readKeys = null;
 
    /** mark as volatile as this might be set from the tx thread code on view change*/
    private volatile boolean isMarkedForRollback;
@@ -169,4 +170,15 @@ public String toString() {
    public void setModifications(List<WriteCommand> modifications) {
       this.modifications = modifications;
    }
+
+   @Override
+   public void addReadKey(Object key) {
+      if (readKeys == null) readKeys = new HashSet<Object>(2);
+      readKeys.add(key);
+   }
+
+   @Override
+   public boolean keyRead(Object key) {
+      return readKeys != null && readKeys.contains(key);
+   }
 }",2012-03-28T06:27:41Z,454
"@@ -84,4 +84,8 @@ public interface CacheTransaction {
    EntryVersionsMap getUpdatedEntryVersions();
 
    void setUpdatedEntryVersions(EntryVersionsMap updatedEntryVersions);
+
+   boolean keyRead(Object key);
+
+   void addReadKey(Object key);
 }",2012-03-28T06:27:41Z,544
"@@ -53,6 +53,9 @@
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionCoordinator;
 import org.infinispan.transaction.TransactionTable;
+import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.transaction.xa.recovery.RecoverableTransactionIdentifier;
+import org.infinispan.transaction.xa.recovery.RecoveryManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.rhq.helpers.pluginAnnotations.agent.DataType;
@@ -90,18 +93,21 @@ public class TxInterceptor extends CommandInterceptor {
    protected RpcManager rpcManager;
 
    private static final Log log = LogFactory.getLog(TxInterceptor.class);
+   private RecoveryManager recoveryManager;
 
    @Override
    protected Log getLog() {
       return log;
    }
 
    @Inject
-   public void init(TransactionTable txTable, Configuration c, TransactionCoordinator txCoordinator, RpcManager rpcManager) {
+   public void init(TransactionTable txTable, Configuration c, TransactionCoordinator txCoordinator, RpcManager rpcManager,
+                    RecoveryManager recoveryManager) {
       this.cacheConfiguration = c;
       this.txTable = txTable;
       this.txCoordinator = txCoordinator;
       this.rpcManager = rpcManager;
+      this.recoveryManager = recoveryManager;
       setStatisticsEnabled(cacheConfiguration.jmxStatistics().enabled());
    }
 
@@ -160,7 +166,16 @@ public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand comm
       if (!ctx.isOriginLocal()) {
          txTable.remoteTransactionRollback(command.getGlobalTransaction());
       }
-      return invokeNextInterceptor(ctx, command);
+      try {
+         return invokeNextInterceptor(ctx, command);
+      } finally {
+         //for tx that rollback we do not send a TxCompletionNotification, so we should cleanup
+         // the recovery info here
+         if (recoveryManager!=null) {
+            GlobalTransaction gtx = command.getGlobalTransaction();
+            recoveryManager.removeRecoveryInformation(((RecoverableTransactionIdentifier)gtx).getXid());
+         }
+      }
    }
 
    @Override",2012-11-02T12:56:26Z,87
"@@ -82,6 +82,7 @@ public void afterCompletion(int status) {
          } catch (XAException e) {
             throw new CacheException(""Could not commit."", e);
          }
+         releaseLocksForCompletedTransaction(localTransaction);
       } else if (status == Status.STATUS_ROLLEDBACK) {
          try {
             txCoordinator.rollback(localTransaction);
@@ -91,7 +92,6 @@ public void afterCompletion(int status) {
       } else {
          throw new IllegalArgumentException(""Unknown status: "" + status);
       }
-      releaseLocksForCompletedTransaction(localTransaction);
    }
 
    @Override",2012-11-02T12:56:26Z,581
"@@ -138,7 +138,6 @@ public void rollback(Xid externalXid) throws XAException {
       LocalXaTransaction localTransaction1 = getLocalTransactionAndValidateImpl(xid, txTable);
       localTransaction.markForRollback(true); //ISPN-879 : make sure that locks are no longer associated to this transactions
       txCoordinator.rollback(localTransaction1);
-      forgetSuccessfullyCompletedTransaction(recoveryManager, xid, localTransaction1);
    }
 
    @Override",2012-11-02T12:56:26Z,92
"@@ -0,0 +1,72 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.commands.remote.recovery.TxCompletionNotificationCommand;
+import org.infinispan.commands.tx.PrepareCommand;
+import org.infinispan.commands.tx.RollbackCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.util.mocks.ControlledCommandFactory;
+import org.testng.annotations.Test;
+
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNull;
+import static org.testng.Assert.fail;
+
+@Test(groups = ""functional"", testName = ""tx.TxCompletionForRolledBackTxOptTest"")
+public class TxCompletionForRolledBackTxOptTest extends MultipleCacheManagersTest {
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      ConfigurationBuilder dcc = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+      dcc.clustering().hash().numOwners(1).transaction().lockingMode(LockingMode.OPTIMISTIC);
+      createCluster(dcc, 3);
+      waitForClusterToForm();
+      advancedCache(2).addInterceptor(new RollbackBeforePrepareTest.FailPrepareInterceptor(), 1);
+   }
+
+   public void testTxCompletionNotSentForRollback() throws Throwable {
+      ControlledCommandFactory cf = ControlledCommandFactory.registerControlledCommandFactory(cache(1), null);
+
+      tm(0).begin();
+      Object k1 = getKeyForCache(1);
+      Object k2 = getKeyForCache(2);
+      cache(0).put(k1, k1);
+      cache(0).put(k2, k2);
+      try {
+         tm(0).commit();
+         fail();
+      } catch (Throwable t) {
+         //expected
+      }
+
+      assertNotLocked(k1);
+      assertNotLocked(k2);
+      assertNull(cache(0).get(k1));
+      assertNull(cache(0).get(k2));
+
+      assertEquals(cf.received(PrepareCommand.class), 1);
+      assertEquals(cf.received(RollbackCommand.class), 2);
+      assertEquals(cf.received(TxCompletionNotificationCommand.class), 0);
+   }
+}",2012-11-02T12:56:26Z,582
"@@ -0,0 +1,66 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.commands.remote.recovery.TxCompletionNotificationCommand;
+import org.infinispan.commands.tx.RollbackCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.util.mocks.ControlledCommandFactory;
+import org.testng.annotations.Test;
+
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNull;
+
+/**
+ * @author Mircea Markus
+ * @since 5.2
+ */
+@Test (groups = ""functional"", testName = ""tx.TxCompletionForRolledBackTxTest"")
+public class TxCompletionForRolledBackTxTest extends MultipleCacheManagersTest {
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      ConfigurationBuilder dcc = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+      dcc.clustering().hash().numOwners(1).transaction().lockingMode(LockingMode.PESSIMISTIC);
+      amend(dcc);
+      createCluster(dcc, 2);
+      waitForClusterToForm();
+   }
+
+   protected void amend(ConfigurationBuilder dcc) {}
+
+   public void testTxCompletionNotSentForRollback() throws Throwable {
+      ControlledCommandFactory cf = ControlledCommandFactory.registerControlledCommandFactory(cache(1), null);
+
+      tm(0).begin();
+      Object k = getKeyForCache(1);
+      cache(0).put(k,""k"");
+      tm(0).rollback();
+
+      assertNotLocked(k);
+      assertNull(cache(0).get(k));
+
+      assertEquals(cf.received(RollbackCommand.class), 1);
+      assertEquals(cf.received(TxCompletionNotificationCommand.class), 0);
+   }
+}",2012-11-02T12:56:26Z,583
"@@ -0,0 +1,32 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.testng.annotations.Test;
+
+@Test (testName = ""tx.TxCompletionForRolledBackXaTxTest"")
+public class TxCompletionForRolledBackXaTxTest extends TxCompletionForRolledBackTxTest {
+
+   @Override
+   protected void amend(ConfigurationBuilder dcc) {
+      dcc.transaction().useSynchronization(false);
+   }
+}",2012-11-02T12:56:26Z,584
"@@ -66,6 +66,7 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.xa.Xid;
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
 import java.util.Map;
@@ -86,15 +87,28 @@ public class ControlledCommandFactory implements CommandsFactory {
    public final ReclosableLatch gate = new ReclosableLatch(true);
    public final AtomicInteger remoteCommandsReceived = new AtomicInteger(0);
    public final AtomicInteger blockTypeCommandsReceived = new AtomicInteger(0);
+   public final List<ReplicableCommand> receivedCommands = new ArrayList<ReplicableCommand>();
    public final Class<? extends  ReplicableCommand> toBlock;
 
    public ControlledCommandFactory(CommandsFactory actual, Class<? extends ReplicableCommand> toBlock) {
       this.actual = actual;
       this.toBlock = toBlock;
    }
 
+   public int received(Class<? extends ReplicableCommand> command) {
+      int result = 0;
+      for (ReplicableCommand r : receivedCommands) {
+         if (r.getClass() == command) {
+            result++;
+         }
+      }
+      return result;
+   }
+
    @Override
    public void initializeReplicableCommand(ReplicableCommand command, boolean isRemote) {
+      log.tracef(""Received command %s"", command);
+      receivedCommands.add(command);
       if (isRemote) {
          remoteCommandsReceived.incrementAndGet();
          if (toBlock != null && command.getClass().isAssignableFrom(toBlock)) {",2012-11-02T12:56:26Z,585
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +41,24 @@
  */
 @Test(groups = ""unit"", enabled = true, testName = ""loaders.bdbje.BdbjeCacheStoreIntegrationVamTest"")
 public class BdbjeCacheStoreIntegrationVamTest extends BdbjeCacheStoreIntegrationTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,80
"@@ -39,21 +39,24 @@
  */
 @Test(groups = ""unit"", sequential = true, testName = ""loaders.cloud.CloudCacheStoreIntegrationVamTest"")
 public class CloudCacheStoreIntegrationVamTest extends CloudCacheStoreIntegrationTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,586
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,19 +41,24 @@
  */
 @Test(groups = ""unit"", testName = ""loaders.cloud.CloudCacheStoreVamTest"")
 public class CloudCacheStoreVamTest extends CloudCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
    }
 
-   @AfterMethod(alwaysRun = true)
-   @Override
-   public void tearDown() throws CacheLoaderException {
-      super.tearDown();
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
       cm.stop();
    }
 
+   @Override
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
+   }
+
 }",2011-09-13T09:07:28Z,587
"@@ -246,7 +246,7 @@ public final Set<InternalCacheEntry> loadSome(int maxEntries) throws CacheLoader
          rs.setFetchSize(tableManipulation.getFetchSize());
          Set<InternalCacheEntry> result = new HashSet<InternalCacheEntry>(maxEntries);
          while (rs.next()) {
-            loadAllProcess(rs, result);
+            loadAllProcess(rs, result, maxEntries);
          }
          return result;
       } catch (SQLException e) {
@@ -267,6 +267,8 @@ protected boolean includeKey(Object key, Set<Object> keysToExclude) {
 
    protected abstract void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result) throws SQLException, CacheLoaderException;
 
+   protected abstract void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result, int maxEntries) throws SQLException, CacheLoaderException;
+
    protected abstract void loadAllKeysProcess(ResultSet rs, Set<Object> keys, Set<Object> keysToExclude) throws SQLException, CacheLoaderException;
 
    protected abstract void toStreamProcess(ResultSet rs, InputStream is, ObjectOutput objectOutput) throws CacheLoaderException, SQLException, IOException;",2011-09-13T09:07:28Z,405
"@@ -118,6 +118,19 @@ public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result) throws
             }
          }
 
+         @Override
+         public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result, int maxEntries) throws SQLException, CacheLoaderException {
+            InputStream binaryStream = rs.getBinaryStream(1);
+            Bucket bucket = (Bucket) JdbcUtil.unmarshall(getMarshaller(), binaryStream);
+            for (InternalCacheEntry ice: bucket.getStoredEntries()) {
+               if (!ice.isExpired())
+                  result.add(ice);
+
+               if (result.size() == maxEntries)
+                  break;
+            }
+         }
+
          @Override
          public void loadAllKeysProcess(ResultSet rs, Set<Object> keys, Set<Object> keysToExclude) throws SQLException, CacheLoaderException {
             InputStream binaryStream = rs.getBinaryStream(1);",2011-09-13T09:07:28Z,407
"@@ -146,6 +146,11 @@ public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result) throws
             result.add(icv.toInternalCacheEntry(key));
          }
 
+         @Override
+         public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result, int maxEntries) throws SQLException, CacheLoaderException {
+            loadAllProcess(rs, result);
+         }
+
          @Override
          public void loadAllKeysProcess(ResultSet rs, Set<Object> keys, Set<Object> keysToExclude) throws SQLException, CacheLoaderException {
             String keyStr = rs.getString(1);",2011-09-13T09:07:28Z,82
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.binary.JdbcBinaryCacheStoreVamTest"")
 public class JdbcBinaryCacheStoreVamTest extends JdbcBinaryCacheStoreTest {   
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,588
"@@ -39,6 +39,7 @@
 import org.infinispan.test.fwk.UnitTestDatabaseManager;
 import org.testng.annotations.AfterMethod;
 import org.testng.annotations.AfterTest;
+import org.testng.annotations.BeforeMethod;
 import org.testng.annotations.BeforeTest;
 import org.testng.annotations.Test;
 
@@ -64,7 +65,7 @@ public class JdbcMixedCacheStoreTest {
    private static final Person MIRCEA = new Person(""Mircea"", ""Markus"", 28);
    private static final Person MANIK = new Person(""Manik"", ""Surtani"", 18);
 
-   @BeforeTest
+   @BeforeMethod
    public void createCacheStore() throws CacheLoaderException {
       stringsTm = UnitTestDatabaseManager.buildDefaultTableManipulation();
       stringsTm.setTableNamePrefix(""STRINGS_TABLE"");",2011-09-13T09:07:28Z,589
"@@ -22,10 +22,13 @@
  */
 package org.infinispan.loaders.jdbc.mixed;
 
+import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -38,21 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.mixed.JdbcMixedCacheStoreVamTest"")
 public class JdbcMixedCacheStoreVamTest extends JdbcMixedCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void clearStore() throws Exception {
-      try {
-         super.clearStore();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,589
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,22 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.mixed.JdbcMixedCacheStoreVamTest2"")
 public class JdbcMixedCacheStoreVamTest2 extends JdbcMixedCacheStoreTest2 {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
 
 }",2011-09-13T09:07:28Z,590
"@@ -26,7 +26,8 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
-import org.testng.annotations.AfterMethod;
+import org.testng.annotations.AfterClass;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +40,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.stringbased.JdbcStringBasedCacheStoreVamTest"")
 public class JdbcStringBasedCacheStoreVamTest extends JdbcStringBasedCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,591
"@@ -22,10 +22,13 @@
  */
 package org.infinispan.loaders.jdbc.stringbased;
 
+import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -38,21 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.stringbased.JdbcStringBasedCacheStoreVamTest2"")
 public class JdbcStringBasedCacheStoreVamTest2 extends JdbcStringBasedCacheStoreTest2 {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void clearStore() throws Exception {
-      try {
-         super.clearStore();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,591
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +41,24 @@
  */
 @Test(groups = ""unit"", testName = ""loaders.jdbm.JdbmCacheStoreVamTest"")
 public class JdbmCacheStoreVamTest extends JdbmCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,592
"@@ -46,6 +46,7 @@
 import java.util.*;
 
 import static java.util.Collections.emptySet;
+import static org.testng.AssertJUnit.assertEquals;
 
 /**
  * This is a base class containing various unit tests for each and every different CacheStore implementations. If you
@@ -443,7 +444,7 @@ public void testPreloadWithMaxSize() throws CacheLoaderException {
 
       Set<InternalCacheEntry> set = cs.load(2);
 
-      assert set.size() == 2;
+      assertEquals(2, set.size());
       Set expected = new HashSet();
       expected.add(""k1"");
       expected.add(""k2"");",2011-09-13T09:07:28Z,84
"@@ -36,6 +36,7 @@
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 import java.io.Serializable;
+import java.util.UUID;
 
 /**
  * @author bela
@@ -46,6 +47,7 @@ public class DummyBaseTransactionManager implements TransactionManager, Serializ
    private static final long serialVersionUID = -6716097342564237376l;
    private static final Log log = LogFactory.getLog(DummyBaseTransactionManager.class);
    private static final boolean trace = log.isTraceEnabled();
+   final UUID transactionManagerId = UUID.randomUUID();
 
    /**
     * Starts a new transaction, and associate it with the calling thread.",2012-01-11T17:05:42Z,593
"@@ -50,15 +50,16 @@ public class DummyTransaction implements Transaction {
    private static boolean trace = log.isTraceEnabled();
 
    private volatile int status = Status.STATUS_UNKNOWN;
-   protected DummyBaseTransactionManager tm_;
-   protected DummyXid xid = new DummyXid();
+   protected final DummyBaseTransactionManager tm_;
+   protected final DummyXid xid;
 
    protected Set<Synchronization> syncs;
-   private List<XAResource> enlistedResources = new ArrayList<XAResource>(2);
+   private final List<XAResource> enlistedResources = new ArrayList<XAResource>(2);
    private int prepareStatus;
 
    public DummyTransaction(DummyBaseTransactionManager tm) {
       tm_ = tm;
+      xid = new DummyXid(tm.transactionManagerId);
       status = Status.STATUS_ACTIVE;
    }
 ",2012-01-11T17:05:42Z,594
"@@ -28,6 +28,8 @@
 import javax.transaction.xa.Xid;
 import java.util.Arrays;
 import java.util.UUID;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicLong;
 
 /**
  * Implementation of Xid.
@@ -36,15 +38,19 @@
  */
 public class DummyXid implements Xid {
 
+   private static final AtomicLong GLOBAL_ID_GENERATOR = new AtomicLong(1);
+   private static final AtomicLong BRANCH_QUALIFIER_GENERATOR = new AtomicLong(1);
+
    private byte[] globalTransactionId = new byte[64];
    private byte[] branchQualifier = new byte[64];
+   private final int cachedHashcode;
 
    public int getFormatId() {
       return 1;
    }
 
-   public DummyXid() {
-      initialize();
+   public DummyXid(UUID transactionManagerId) {
+      cachedHashcode = initializeAndCalculateHash(transactionManagerId);
    }
 
    public byte[] getGlobalTransactionId() {
@@ -55,18 +61,23 @@ public byte[] getBranchQualifier() {
       return branchQualifier;
    }
 
-   private void initialize() {
-      initialize(globalTransactionId);
-      initialize(branchQualifier);
+   private int initializeAndCalculateHash(UUID transactionManagerId) {
+      int hc1 = initialize(transactionManagerId, GLOBAL_ID_GENERATOR, globalTransactionId);
+      return 37 * hc1 + initialize(transactionManagerId, BRANCH_QUALIFIER_GENERATOR, branchQualifier);
    }
 
-   private void initialize(byte[] field) {
-      UUID uuid = UUID.randomUUID();
-      long lsb = uuid.getLeastSignificantBits();
-      long msb = uuid.getMostSignificantBits();
+   private int initialize(UUID transactionManagerId, AtomicLong generator, byte[] field) {
+      long lsb = transactionManagerId.getLeastSignificantBits();
+      long msb = transactionManagerId.getMostSignificantBits();
+      long id = generator.getAndIncrement();
       Arrays.fill(field, (byte) 0);
       UnsignedNumeric.writeUnsignedLong(field, 0, lsb);
       UnsignedNumeric.writeUnsignedLong(field, 10, msb);
+      UnsignedNumeric.writeUnsignedLong(field, 20, id);
+      int hash = (int) (lsb ^ lsb >>> 32);
+      hash = 37 * hash + (int) (msb ^ msb >>> 32);
+      hash = 37 * hash + (int) (id ^ id >>> 32);
+      return hash;
    }
 
    @Override
@@ -93,8 +104,6 @@ public boolean equals(Object o) {
 
    @Override
    public int hashCode() {
-      int result = globalTransactionId != null ? Arrays.hashCode(globalTransactionId) : 0;
-      result = 31 * result + (branchQualifier != null ? Arrays.hashCode(branchQualifier) : 0);
-      return result;
+      return cachedHashcode;
    }
 }",2012-01-11T17:05:42Z,595
"@@ -30,13 +30,14 @@
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.transaction.xa.LocalXaTransaction;
 import org.infinispan.transaction.xa.TransactionFactory;
-import org.infinispan.transaction.xa.XaTransactionTable;
 import org.infinispan.transaction.xa.TransactionXaAdapter;
+import org.infinispan.transaction.xa.XaTransactionTable;
 import org.testng.annotations.BeforeMethod;
 import org.testng.annotations.Test;
 
 import javax.transaction.xa.XAException;
 import javax.transaction.xa.XAResource;
+import java.util.UUID;
 
 /**
  * @author Mircea.Markus@jboss.com
@@ -50,6 +51,7 @@ public class TransactionXaAdapterTmIntegrationTest {
    private LocalXaTransaction localTx;
    private TransactionXaAdapter xaAdapter;
    private DummyXid xid;
+   private UUID uuid = UUID.randomUUID();
 
    @BeforeMethod
    public void setUp() {
@@ -58,7 +60,7 @@ public void setUp() {
       gtf.init(false, false, true);
       globalTransaction = gtf.newGlobalTransaction(null, false);
       localTx = new LocalXaTransaction(new DummyTransaction(null), globalTransaction, false);
-      xid = new DummyXid();
+      xid = new DummyXid(uuid);
       localTx.setXid(xid);
       txTable.addLocalTransactionMapping(localTx);      
 
@@ -70,7 +72,7 @@ public void setUp() {
    }
 
    public void testPrepareOnNonexistentXid() {
-      DummyXid xid = new DummyXid();
+      DummyXid xid = new DummyXid(uuid);
       try {
          xaAdapter.prepare(xid);
          assert false;
@@ -80,7 +82,7 @@ public void testPrepareOnNonexistentXid() {
    }
 
    public void testCommitOnNonexistentXid() {
-      DummyXid xid = new DummyXid();
+      DummyXid xid = new DummyXid(uuid);
       try {
          xaAdapter.commit(xid, false);
          assert false;
@@ -90,7 +92,7 @@ public void testCommitOnNonexistentXid() {
    }
 
    public void testRollabckOnNonexistentXid() {
-      DummyXid xid = new DummyXid();
+      DummyXid xid = new DummyXid(uuid);
       try {
          xaAdapter.rollback(xid);
          assert false;
@@ -117,7 +119,7 @@ public void testOnePhaseCommitConfigured() throws XAException {
    public void test1PcAndNonExistentXid() {
       configuration.setCacheMode(Configuration.CacheMode.INVALIDATION_ASYNC);
       try {
-         DummyXid doesNotExists = new DummyXid();
+         DummyXid doesNotExists = new DummyXid(uuid);
          xaAdapter.commit(doesNotExists, false);
          assert false;
       } catch (XAException e) {
@@ -128,7 +130,7 @@ public void test1PcAndNonExistentXid() {
    public void test1PcAndNonExistentXid2() {
       configuration.setCacheMode(Configuration.CacheMode.DIST_SYNC);
       try {
-         DummyXid doesNotExists = new DummyXid();
+         DummyXid doesNotExists = new DummyXid(uuid);
          xaAdapter.commit(doesNotExists, true);
          assert false;
       } catch (XAException e) {",2012-01-11T17:05:42Z,94
"@@ -30,6 +30,7 @@
 import javax.transaction.xa.XAException;
 import java.util.Collections;
 import java.util.Map;
+import java.util.UUID;
 
 /**
  * @author Mircea Markus
@@ -74,7 +75,7 @@ public void testPutAll() throws Exception {
    protected void commit() {
       DummyTransactionManager dtm = (DummyTransactionManager) tm(0);
       try {
-         dtm.firstEnlistedResource().commit(new DummyXid(), true);
+         dtm.firstEnlistedResource().commit(new DummyXid(UUID.randomUUID()), true);
       } catch (XAException e) {
          throw new RuntimeException(e);
       }
@@ -83,7 +84,7 @@ protected void commit() {
    protected void prepare() {
       DummyTransactionManager dtm = (DummyTransactionManager) tm(0);
       try {
-         dtm.firstEnlistedResource().prepare(new DummyXid());
+         dtm.firstEnlistedResource().prepare(new DummyXid(UUID.randomUUID()));
       } catch (XAException e) {
          throw new RuntimeException(e);
       }",2012-01-11T17:05:42Z,596
"@@ -66,7 +66,9 @@ public class InboundTransferTask {
 
    private final long timeout;
 
-   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout) {
+   private final String cacheName;
+
+   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""segments must not be null or empty"");
       }
@@ -81,6 +83,7 @@ public InboundTransferTask(Set<Integer> segments, Address source, int topologyId
       this.rpcManager = rpcManager;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public Set<Integer> getSegments() {
@@ -93,7 +96,7 @@ public Address getSource() {
 
    public boolean requestTransactions() {
       if (trace) {
-         log.tracef(""Requesting transactions for segments %s"", segments);
+         log.tracef(""Requesting transactions for segments %s of cache %s from node %s"", segments, cacheName, source);
       }
       // get transactions and locks
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.GET_TRANSACTIONS, rpcManager.getAddress(), topologyId, segments);
@@ -109,6 +112,10 @@ public boolean requestTransactions() {
    }
 
    public boolean requestSegments() {
+      if (trace) {
+         log.tracef(""Requesting segments %s of cache %s from node %s"", segments, cacheName, source);
+      }
+
       // start transfer of cache entries
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.START_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
       Map<Address, Response> responses = rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
@@ -139,24 +146,21 @@ public void cancel() {
       if (!isCancelled) {
          isCancelled = true;
 
-         Set<Integer> cancelledSegments = new HashSet<Integer>(segments);
-         segments.clear();
-         finishedSegments.clear();
-
-         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, cancelledSegments);
+         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
          rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
 
          stateConsumer.onTaskCompletion(this);
       }
    }
 
    public void onStateReceived(int segmentId, boolean isLastChunk) {
-      if (!isCancelled && segments.contains(segmentId)) {
-         if (isLastChunk) {
-            finishedSegments.add(segmentId);
-            if (finishedSegments.containsAll(segments)) {
-               stateConsumer.onTaskCompletion(this);
+      if (!isCancelled && isLastChunk && segments.contains(segmentId)) {
+         finishedSegments.add(segmentId);
+         if (finishedSegments.containsAll(segments)) {
+            if (trace) {
+               log.tracef(""Finished receiving state for segments %s of cache %s"", segments, cacheName);
             }
+            stateConsumer.onTaskCompletion(this);
          }
       }
    }
@@ -166,11 +170,14 @@ public String toString() {
       HashSet<Integer> unfinishedSegments = new HashSet<Integer>(segments);
       unfinishedSegments.removeAll(finishedSegments);
       return ""InboundTransferTask{"" +
-            ""unfinishedSegments="" + unfinishedSegments +
+            ""segments="" + segments +
+            "", finishedSegments="" + finishedSegments +
+            "", unfinishedSegments="" + unfinishedSegments +
             "", source="" + source +
             "", isCancelled="" + isCancelled +
             "", topologyId="" + topologyId +
             "", timeout="" + timeout +
+            "", cacheName="" + cacheName +
             '}';
    }
 }",2012-11-07T14:07:34Z,120
"@@ -24,20 +24,19 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.commands.CommandsFactory;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheLoaderManager;
 import org.infinispan.loaders.CacheStore;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.SuspectException;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
-import org.infinispan.util.concurrent.AggregatingNotifyingFutureBuilder;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -70,8 +69,6 @@ public class OutboundTransferTask implements Runnable {
 
    private final int stateTransferChunkSize;
 
-   private final Configuration configuration;
-
    private final ConsistentHash readCh;
 
    private final DataContainer dataContainer;
@@ -84,27 +81,24 @@ public class OutboundTransferTask implements Runnable {
 
    private final long timeout;
 
+   private final String cacheName;
+
    private final Map<Integer, List<InternalCacheEntry>> entriesBySegment = ConcurrentMapFactory.makeConcurrentMap();
 
    /**
     * The total number of entries from all segments accumulated in entriesBySegment.
     */
    private int accumulatedEntries;
 
-   /**
-    * This is used with RpcManager.invokeRemotelyInFuture() to be able to cancel message sending if the task needs to be canceled.
-    */
-   private final NotifyingNotifiableFuture<Object> sendFuture = new AggregatingNotifyingFutureBuilder(null);
-
    /**
     * The Future obtained from submitting this task to an executor service. This is used for cancellation.
     */
    private FutureTask runnableFuture;
 
    public OutboundTransferTask(Address destination, Set<Integer> segments, int stateTransferChunkSize,
                                int topologyId, ConsistentHash readCh, StateProviderImpl stateProvider, DataContainer dataContainer,
-                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager, Configuration configuration,
-                               CommandsFactory commandsFactory, long timeout) {
+                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager,
+                               CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""Segments must not be null or empty"");
       }
@@ -123,9 +117,9 @@ public OutboundTransferTask(Address destination, Set<Integer> segments, int stat
       this.dataContainer = dataContainer;
       this.cacheLoaderManager = cacheLoaderManager;
       this.rpcManager = rpcManager;
-      this.configuration = configuration;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public void execute(ExecutorService executorService) {
@@ -154,7 +148,7 @@ public void run() {
       try {
          // send data container entries
          for (InternalCacheEntry ice : dataContainer) {
-            Object key = ice.getKey();
+            Object key = ice.getKey();  //todo [anistor] should we check for expired entries?
             int segmentId = readCh.getSegment(key);
             if (segments.contains(segmentId)) {
                sendEntry(ice, segmentId);
@@ -198,7 +192,7 @@ public void run() {
          }
       }
       if (trace) {
-         log.tracef(""Outbound transfer of segments %s to %s is complete"", segments, destination);
+         log.tracef(""Outbound transfer of segments %s of cache %s to node %s is complete"", segments, cacheName, destination);
       }
    }
 
@@ -217,7 +211,6 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
       // send if we have a full chunk
       if (accumulatedEntries >= stateTransferChunkSize) {
          sendEntries(false);
-         entriesBySegment.clear();
          accumulatedEntries = 0;
       }
 
@@ -232,32 +225,42 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
 
    private void sendEntries(boolean isLast) {
       List<StateChunk> chunks = new ArrayList<StateChunk>();
+      for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
+         List<InternalCacheEntry> entries = e.getValue();
+         if (!entries.isEmpty()) {
+            chunks.add(new StateChunk(e.getKey(), new ArrayList<InternalCacheEntry>(entries), isLast));
+            entries.clear();
+         }
+      }
+
       if (isLast) {
          for (int segmentId : segments) {
             List<InternalCacheEntry> entries = entriesBySegment.get(segmentId);
             if (entries == null) {
-               entries = InfinispanCollections.emptyList();
-            }
-            chunks.add(new StateChunk(segmentId, entries, isLast));
-         }
-      } else {
-         for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
-            List<InternalCacheEntry> entries = e.getValue();
-            if (!entries.isEmpty()) {
-               chunks.add(new StateChunk(e.getKey(), entries, isLast));
+               chunks.add(new StateChunk(segmentId, InfinispanCollections.<InternalCacheEntry>emptyList(), true));
             }
          }
       }
 
-      if (!chunks.isEmpty() || isLast) {
+      if (!chunks.isEmpty()) {
          if (trace) {
-            log.tracef(""Sending %d cache entries from segments %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), destination);
+            if (isLast) {
+               log.tracef(""Sending last chunk containing %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, segments, cacheName, destination);
+            } else {
+               log.tracef(""Sending %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), cacheName, destination);
+            }
          }
 
-         //todo [anistor] send back the received topologyId or my local one?
          StateResponseCommand cmd = commandsFactory.buildStateResponseCommand(rpcManager.getAddress(), topologyId, chunks);
-         // send synchronously, in FIFO mode. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
-         rpcManager.invokeRemotelyInFuture(Collections.singleton(destination), cmd, false, sendFuture, timeout);
+         // send synchronously, in order. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
+         try {
+            rpcManager.invokeRemotely(Collections.singleton(destination), cmd, ResponseMode.SYNCHRONOUS, timeout, false, null);
+         } catch (SuspectException e) {
+            log.errorf(e, ""Node %s left cache %s: %s"", destination, cacheName, e.getMessage());
+            cancel();
+         } catch (Exception e) {
+            log.errorf(e, ""Failed to send entries to node %s : %s"", destination, e.getMessage());
+         }
       }
    }
 
@@ -268,7 +271,7 @@ private void sendEntries(boolean isLast) {
     */
    public void cancelSegments(Set<Integer> cancelledSegments) {
       if (trace) {
-         log.tracef(""Cancelling outbound transfer of segments %s to %s"", cancelledSegments, destination);
+         log.tracef(""Cancelling outbound transfer of segments %s of cache %s to node %s"", cancelledSegments, cacheName, destination);
       }
       if (segments.removeAll(cancelledSegments)) {
          entriesBySegment.keySet().removeAll(cancelledSegments);  // here we do not update accumulatedEntries but this inaccuracy does not cause any harm
@@ -284,11 +287,22 @@ public void cancelSegments(Set<Integer> cancelledSegments) {
    public void cancel() {
       if (runnableFuture != null && !runnableFuture.isCancelled()) {
          runnableFuture.cancel(true);
-         sendFuture.cancel(true);
       }
    }
 
    public boolean isCancelled() {
       return runnableFuture != null && runnableFuture.isCancelled();
    }
+
+   @Override
+   public String toString() {
+      return ""OutboundTransferTask{"" +
+            ""topologyId="" + topologyId +
+            "", destination="" + destination +
+            "", segments="" + segments +
+            "", stateTransferChunkSize="" + stateTransferChunkSize +
+            "", timeout="" + timeout +
+            "", cacheName='"" + cacheName + '\'' +
+            '}';
+   }
 }",2012-11-07T14:07:34Z,121
"@@ -45,7 +45,6 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -62,7 +61,7 @@
 import static org.infinispan.context.Flag.*;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateConsumer} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -72,7 +71,7 @@ public class StateConsumerImpl implements StateConsumer {
    private static final Log log = LogFactory.getLog(StateConsumerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
-   private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
    private Configuration configuration;
    private RpcManager rpcManager;
@@ -119,7 +118,7 @@ public StateConsumerImpl() {
 
    @Inject
    public void init(Cache cache,
-                    LocalTopologyManager localTopologyManager,
+                    StateTransferManager stateTransferManager,
                     InterceptorChain interceptorChain,
                     InvocationContextContainer icc,
                     Configuration configuration,
@@ -130,7 +129,7 @@ public void init(Cache cache,
                     TransactionTable transactionTable,
                     StateTransferLock stateTransferLock) {
       this.cacheName = cache.getName();
-      this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
       this.interceptorChain = interceptorChain;
       this.icc = icc;
       this.configuration = configuration;
@@ -171,26 +170,30 @@ public boolean isStateTransferInProgressForKey(Object key) {
 
    @Override
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
-      if (trace) log.tracef(""Received new CH: %s"", cacheTopology.getWriteConsistentHash());
+      if (trace) log.tracef(""Received new CH %s for cache %s"", cacheTopology.getWriteConsistentHash(), cacheName);
 
       activeTopologyUpdates.incrementAndGet();
       if (isRebalance) {
          rebalanceInProgress.set(true);
       }
-      ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
+      final ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
       // Ensures writes to the data container use the right consistent hash
       // No need for a try/finally block, since it's just an assignment
       stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
       stateTransferLock.releaseExclusiveTopologyLock();
-      stateTransferLock.topologyInstalled(cacheTopology.getTopologyId());
+      stateTransferLock.notifyTopologyInstalled(cacheTopology.getTopologyId());
 
       try {
          Set<Integer> addedSegments;
          if (previousCh == null) {
             // we start fresh, without any data, so we need to pull everything we own according to writeCh
 
             addedSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
+
+            if (trace) {
+               log.tracef(""On cache %s we have: added segments: %s"", cacheName, addedSegments);
+            }
          } else {
             Set<Integer> previousSegments = getOwnedSegments(previousCh);
             Set<Integer> newSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
@@ -199,16 +202,16 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             Set<Integer> removedSegments = new HashSet<Integer>(previousSegments);
             removedSegments.removeAll(newSegments);
 
-            // remove inbound transfers and any data for segments we no longer own
+            addedSegments = new HashSet<Integer>(newSegments);
+            addedSegments.removeAll(previousSegments);
+
             if (trace) {
-               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                     removedSegments, newSegments, previousSegments);
+               log.tracef(""On cache %s we have: removed segments: %s; new segments: %s; old segments: %s; added segments: %s"",
+                     cacheName, removedSegments, newSegments, previousSegments, addedSegments);
             }
-            discardSegments(removedSegments);
 
-            Set<Integer> currentSegments = getOwnedSegments(cacheTopology.getReadConsistentHash());
-            addedSegments = new HashSet<Integer>(newSegments);
-            addedSegments.removeAll(currentSegments);
+            // remove inbound transfers and any data for segments we no longer own
+            discardSegments(removedSegments);
 
             // check if any of the existing transfers should be restarted from a different source because the initial source is no longer a member
             Set<Address> members = new HashSet<Address>(cacheTopology.getReadConsistentHash().getMembers());
@@ -230,24 +233,30 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
                      }
                   }
                }
+
+               // exclude those that are already in progress from a valid source
+               addedSegments.removeAll(transfersBySegment.keySet());
             }
          }
 
-         if (addedSegments != null && !addedSegments.isEmpty()) {
+         if (!addedSegments.isEmpty()) {
             addTransfers(addedSegments);  // add transfers for new or restarted segments
          }
       } finally {
-         stateTransferLock.transactionDataReceived(cacheTopology.getTopologyId());
+         stateTransferLock.notifyTransactionDataReceived(cacheTopology.getTopologyId());
 
-         if (activeTopologyUpdates.decrementAndGet() == 0 && !isStateTransferInProgress()) {
+         if (activeTopologyUpdates.decrementAndGet() == 0) {
             notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
          }
       }
    }
 
    private void notifyEndOfTopologyUpdate(int topologyId) {
-      if (rebalanceInProgress.compareAndSet(true, false)) {
-         localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+      if (!isStateTransferInProgress()) {
+         if (rebalanceInProgress.compareAndSet(true, false)) {
+            log.debugf(""Finished receiving of segments for cache %s for topology %d."", cacheName, topologyId);
+            stateTransferManager.notifyEndOfTopologyUpdate(topologyId);
+         }
       }
    }
 
@@ -262,43 +271,42 @@ public void applyState(Address sender, int topologyId, int segmentId, Collection
       //todo [anistor] this check should be based on topologyId
       if (!cacheTopology.getWriteConsistentHash().getSegmentsForOwner(rpcManager.getAddress()).contains(segmentId)) {
          if (trace) {
-            log.warnf(""Discarding received cache entries for segment %d because they do not belong to this node."", segmentId);
+            log.warnf(""Discarding received cache entries for segment %d of cache %s because they do not belong to this node."", segmentId, cacheName);
          }
          return;
       }
 
-      if (cacheEntries != null) {
-         doApplyState(sender, segmentId, cacheEntries);
-      }
-
       // notify the inbound task that a chunk of cache entries was received
       InboundTransferTask inboundTransfer;
       synchronized (this) {
          inboundTransfer = transfersBySegment.get(segmentId);
       }
       if (inboundTransfer != null) {
+         if (cacheEntries != null) {
+            doApplyState(sender, segmentId, cacheEntries);
+         }
+
          inboundTransfer.onStateReceived(segmentId, isLastChunk);
-      } else {
-         log.debugf(""Received unsolicited state for segment %d from node %s"", segmentId, sender);
-         return;
-      }
 
-      if (trace) {
-         log.tracef(""After applying the received state the data container has %d keys"", dataContainer.size());
-         synchronized (this) {
-            log.tracef(""Segments not received yet: %s"", transfersBySource);
+         if (trace) {
+            log.tracef(""After applying the received state the data container of cache %s has %d keys"", cacheName, dataContainer.size());
+            synchronized (this) {
+               log.tracef(""Segments not received yet for cache %s: %s"", cacheName, transfersBySource);
+            }
          }
+      } else {
+         log.warnf(""Received unsolicited state from node %s for segment %d of cache %s"", sender, segmentId, cacheName);
       }
    }
 
    private void doApplyState(Address sender, int segmentId, Collection<InternalCacheEntry> cacheEntries) {
-      log.debugf(""Applying new state for segment %d from %s: received %d cache entries"", segmentId, sender, cacheEntries.size());
+      log.debugf(""Applying new state for segment %d of cache %s from node %s: received %d cache entries"", segmentId, cacheName, sender, cacheEntries.size());
       if (trace) {
          List<Object> keys = new ArrayList<Object>(cacheEntries.size());
          for (InternalCacheEntry e : cacheEntries) {
             keys.add(e.getKey());
          }
-         log.tracef(""Received keys: %s"", keys);
+         log.tracef(""Received keys %s for segment %d of cache %s from node %s"", keys, segmentId, cacheName, sender);
       }
 
       // CACHE_MODE_LOCAL avoids handling by StateTransferInterceptor and any potential locks in StateTransferLock
@@ -316,10 +324,11 @@ private void doApplyState(Address sender, int segmentId, Collection<InternalCach
             log.problemApplyingStateForKey(ex.getMessage(), e.getKey());
          }
       }
+      log.debugf(""Finished applying state for segment %d of cache %s"", segmentId, cacheName);
    }
 
    public void applyTransactions(Address sender, int topologyId, Collection<TransactionInfo> transactions) {
-      log.debugf(""Applying %d transactions transferred from %s"", transactions.size(), sender);
+      log.debugf(""Applying %d transactions for cache %s transferred from node %s"", transactions.size(), cacheName, sender);
       if (configuration.transaction().transactionMode().isTransactional()) {
          for (TransactionInfo transactionInfo : transactions) {
             CacheTransaction tx = transactionTable.getLocalTransaction(transactionInfo.getGlobalTransaction());
@@ -374,30 +383,31 @@ public CacheTopology getCacheTopology() {
    }
 
    private void addTransfers(Set<Integer> segments) {
-      log.debugf(""Adding state transfer for segments: %s"", segments);
+      log.debugf(""Adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
 
       Set<Integer> segmentsToProcess = new HashSet<Integer>(segments);
-      Set<Address> blacklistedSources = new HashSet<Address>();
+      Set<Address> faultysources = new HashSet<Address>();
 
       // ignore all segments for which there are no other owners to pull data from.
       // these segments are considered empty (or lost) and do not require a state transfer
       for (Iterator<Integer> it = segmentsToProcess.iterator(); it.hasNext(); ) {
          Integer segmentId = it.next();
-         Address source = pickSourceOwner(segmentId, blacklistedSources);
+         Address source = pickSourceOwner(segmentId, faultysources);
          if (source == null) {
             it.remove();
          }
       }
 
-      synchronized (this) {
-         // already active transfers do not need to be added again
-         segmentsToProcess.removeAll(transfersBySegment.keySet());
-      }
-
       while (!segmentsToProcess.isEmpty()) {
          Map<Address, Set<Integer>> segmentsBySource = new HashMap<Address, Set<Integer>>();
          for (int segmentId : segmentsToProcess) {
-            Address source = pickSourceOwner(segmentId, blacklistedSources);
+            synchronized (this) {
+               // already active transfers do not need to be added again
+               if (transfersBySegment.containsKey(segmentId)) {
+                  continue;
+               }
+            }
+            Address source = pickSourceOwner(segmentId, faultysources);
             if (source != null) {
                Set<Integer> segmentsFromSource = segmentsBySource.get(source);
                if (segmentsFromSource == null) {
@@ -411,8 +421,14 @@ private void addTransfers(Set<Integer> segments) {
          Set<Integer> failedSegments = new HashSet<Integer>();
          for (Address source : segmentsBySource.keySet()) {
             Set<Integer> segmentsFromSource = segmentsBySource.get(source);
-            InboundTransferTask inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout);
+            InboundTransferTask inboundTransfer;
             synchronized (this) {
+               segmentsFromSource.removeAll(transfersBySegment.keySet());  // already in progress segments are excluded
+               if (segmentsFromSource.isEmpty()) {
+                  continue;
+               }
+
+               inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout, cacheName);
                for (int segmentId : segmentsFromSource) {
                   transfersBySegment.put(segmentId, inboundTransfer);
                }
@@ -427,9 +443,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the transactions fails we need to retry from another source
             if (configuration.transaction().transactionMode().isTransactional()) {
                if (!inboundTransfer.requestTransactions()) {
-                  log.errorf(""Failed to retrieve transactions for segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRetrieveTransactionsForSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                   continue;
                }
@@ -438,9 +454,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the segments fails we need to retry from another source
             if (fetchEnabled) {
                if (!inboundTransfer.requestSegments()) {
-                  log.errorf(""Failed to request segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRequestSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                }
             } else {
@@ -450,21 +466,22 @@ private void addTransfers(Set<Integer> segments) {
 
          segmentsToProcess = failedSegments;
       }
+      log.debugf(""Finished adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
    }
 
-   private Address pickSourceOwner(int segmentId, Set<Address> blacklistedSources) {
+   private Address pickSourceOwner(int segmentId, Set<Address> faultySources) {
       List<Address> owners = cacheTopology.getReadConsistentHash().locateOwnersForSegment(segmentId);
       if (owners.size() == 1 && owners.get(0).equals(rpcManager.getAddress())) {
          return null;
       }
 
       for (int i = owners.size() - 1; i >= 0; i--) {   // iterate backwards because we prefer to fetch from newer nodes
          Address o = owners.get(i);
-         if (!o.equals(rpcManager.getAddress()) && !blacklistedSources.contains(o)) {
+         if (!o.equals(rpcManager.getAddress()) && !faultySources.contains(o)) {
             return o;
          }
       }
-      log.errorf(""No live owners found for segment %d. Current owners are:  %s. Blacklisted owners: %s"", segmentId, owners, blacklistedSources);
+      log.noLiveOwnersFoundForSegment(segmentId, cacheName, owners, faultySources);
       return null;
    }
 
@@ -478,9 +495,9 @@ private void discardSegments(Set<Integer> segments) {
          List<Integer> segmentsToCancel = new ArrayList<Integer>(segments);
          while (!segmentsToCancel.isEmpty()) {
             int segmentId = segmentsToCancel.remove(0);
-            log.debugf(""Removing state transfer for segment %d"", segmentId);
             InboundTransferTask inboundTransfer = transfersBySegment.remove(segmentId);
             if (inboundTransfer != null) { // we need to check the transfer was not already completed
+               log.debugf(""Cancelling inbound state transfer for segment %d of cache %s"", segmentId, cacheName);
                Set<Integer> cancelledSegments = new HashSet<Integer>(segmentsToCancel);
                cancelledSegments.retainAll(inboundTransfer.getSegments());
                segmentsToCancel.removeAll(cancelledSegments);
@@ -489,6 +506,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      // gather all keys from data container that belong to the segments that are being removed
       Set<Object> keysToRemove = new HashSet<Object>();
       for (InternalCacheEntry ice : dataContainer) {
          Object key = ice.getKey();
@@ -497,7 +515,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
-      // we also remove keys from the cache store
+      // gather all keys from cache store that belong to the segments that are being removed
       CacheStore cacheStore = getCacheStore();
       if (cacheStore != null) {
          //todo [anistor] extend CacheStore interface to be able to specify a filter when loading keys (ie. keys should belong to desired segments)
@@ -514,13 +532,14 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      log.debugf(""Removing state for segments %s of cache %s"", segments, cacheName);
       if (!keysToRemove.isEmpty()) {
          try {
             InvalidateCommand invalidateCmd = commandsFactory.buildInvalidateFromL1Command(true, EnumSet.of(CACHE_MODE_LOCAL, SKIP_LOCKING), keysToRemove);
             InvocationContext ctx = icc.createNonTxInvocationContext();
             interceptorChain.invoke(ctx, invalidateCmd);
 
-            log.debugf(""Invalidated %d keys, data container now has %d keys"", keysToRemove.size(), dataContainer.size());
+            log.debugf(""Invalidated %d keys, data container of cache %s now has %d keys"", keysToRemove.size(), cacheName, dataContainer.size());
             if (trace) log.tracef(""Invalidated keys: %s"", keysToRemove);
          } catch (CacheException e) {
             log.failedToInvalidateKeys(e);
@@ -553,18 +572,17 @@ private void removeTransfer(InboundTransferTask inboundTransfer) {
                if (transfers.isEmpty()) {
                   transfersBySource.remove(inboundTransfer.getSource());
                }
-               for (int segmentId : inboundTransfer.getSegments()) {
-                  transfersBySegment.remove(segmentId);
-               }
+               transfersBySegment.keySet().removeAll(inboundTransfer.getSegments());
             }
          }
       }
    }
 
    void onTaskCompletion(InboundTransferTask inboundTransfer) {
+      log.tracef(""Completion of inbound transfer task: %s "", inboundTransfer);
       removeTransfer(inboundTransfer);
 
-      if (activeTopologyUpdates.get() == 0 && !isStateTransferInProgress()) {
+      if (activeTopologyUpdates.get() == 0) {
          notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
       }
    }",2012-11-07T14:07:34Z,54
"@@ -52,7 +52,7 @@
 import static org.infinispan.factories.KnownComponentNames.ASYNC_TRANSPORT_EXECUTOR;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateProvider} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -90,7 +90,7 @@ public StateProviderImpl() {
 
    @Inject
    public void init(Cache cache,
-                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //todo [anistor] use a separate ExecutorService
+                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //TODO Use a dedicated ExecutorService
                     Configuration configuration,
                     RpcManager rpcManager,
                     CommandsFactory commandsFactory,
@@ -184,7 +184,7 @@ public void stop() {
 
    public List<TransactionInfo> getTransactionsForSegments(Address destination, int requestTopologyId, Set<Integer> segments) throws InterruptedException {
       if (trace) {
-         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, requestTopologyId);
+         log.tracef(""Received request for transactions from node %s for segments %s of cache %s with topology id %d"", destination, segments, cacheName, requestTopologyId);
       }
 
       if (readCh == null) {
@@ -262,8 +262,8 @@ public void startOutboundTransfer(Address destination, int requestTopologyId, Se
       }
 
       // the destination node must already have an InboundTransferTask waiting for these segments
-      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, requestTopologyId,
-            readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
+      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId,
+            readCh, this, dataContainer, cacheLoaderManager, rpcManager, commandsFactory, timeout, cacheName);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);
    }
@@ -294,7 +294,7 @@ public void cancelOutboundTransfer(Address destination, int topologyId, Set<Inte
             // get an array copy of the collection to avoid ConcurrentModificationException if the entire task gets cancelled and removeTransfer(transferTask) is called
             OutboundTransferTask[] tasks = transferTasks.toArray(new OutboundTransferTask[transferTasks.size()]);
             for (OutboundTransferTask transferTask : tasks) {
-               transferTask.cancelSegments(segments); //this can potentially result in a removeTransfer(transferTask)
+               transferTask.cancelSegments(segments); //this can potentially result in a call to removeTransfer(transferTask)
             }
          }
       }",2012-11-07T14:07:34Z,55
"@@ -36,16 +36,13 @@
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
-import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
 import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
@@ -75,7 +72,7 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
+   public void init(StateTransferLock stateTransferLock, Configuration configuration,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
       this.commandFactory = commandFactory;",2012-11-07T14:07:34Z,115
"@@ -58,13 +58,13 @@ public interface StateTransferLock {
    void releaseSharedTopologyLock();
 
    // transaction data latch
-   void transactionDataReceived(int topologyId);
+   void notifyTransactionDataReceived(int topologyId);
 
    void waitForTransactionData(int expectedTopologyId) throws InterruptedException;
 
    // topology installation latch
    // TODO move this to Cluster/LocalTopologyManagerImpl and don't start requesting state until every node has the jgroups view with the local node
-   void topologyInstalled(int topologyId);
+   void notifyTopologyInstalled(int topologyId);
 
    void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-11-07T14:07:34Z,122
"@@ -23,12 +23,12 @@
 
 package org.infinispan.statetransfer;
 
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+
 /**
  * {@code StateTransferLock} implementation.
  *
@@ -38,6 +38,7 @@
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
+   private static final boolean trace = log.isTraceEnabled();
 
    private final ReadWriteLock ownershipLock = new ReentrantReadWriteLock();
 
@@ -68,8 +69,15 @@ public void releaseSharedTopologyLock() {
    }
 
    @Override
-   public void transactionDataReceived(int topologyId) {
-      this.transactionDataTopologyId = topologyId;
+   public void notifyTransactionDataReceived(int topologyId) {
+      if (topologyId < transactionDataTopologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + transactionDataTopologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling transaction data received for topology %d"", topologyId);
+      }
+      transactionDataTopologyId = topologyId;
       synchronized (transactionDataLock) {
          transactionDataLock.notifyAll();
       }
@@ -80,19 +88,32 @@ public void waitForTransactionData(int expectedTopologyId) throws InterruptedExc
       if (transactionDataTopologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
-            transactionDataTopologyId);
+      if (trace) {
+         log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
+               transactionDataTopologyId);
+      }
       synchronized (transactionDataLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (transactionDataTopologyId < expectedTopologyId) {
             transactionDataLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Received transaction data for topology %d, expected topology was %d"", transactionDataTopologyId,
+               expectedTopologyId);
+      }
    }
 
    @Override
-   public void topologyInstalled(int topologyId) {
+   public void notifyTopologyInstalled(int topologyId) {
+      if (topologyId < this.topologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + this.topologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling topology %d is installed"", topologyId);
+      }
       this.topologyId = topologyId;
       synchronized (topologyLock) {
          topologyLock.notifyAll();
@@ -104,14 +125,18 @@ public void waitForTopology(int expectedTopologyId) throws InterruptedException
       if (topologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId,
-            topologyId);
+      if (trace) {
+         log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId, topologyId);
+      }
       synchronized (topologyLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (topologyId < expectedTopologyId) {
             topologyLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Topology %d is now installed, expected topology was %d"", topologyId, expectedTopologyId);
+      }
    }
 }",2012-11-07T14:07:34Z,123
"@@ -81,4 +81,5 @@ public interface StateTransferManager {
     */
    void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
 
+   void notifyEndOfTopologyUpdate(int topologyId);
 }",2012-11-07T14:07:34Z,116
"@@ -70,7 +70,7 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private GroupManager groupManager;   // optional
    private LocalTopologyManager localTopologyManager;
 
-   private CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
+   private final CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
 
    public StateTransferManagerImpl() {
    }
@@ -170,13 +170,18 @@ private CacheTopology addGrouping(CacheTopology cacheTopology) {
 
    private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalance) {
       if (trace) {
-         log.tracef(""Installing new cache topology %s"", newCacheTopology);
+         log.tracef(""Installing new cache topology %s on cache %s"", newCacheTopology, cacheName);
       }
 
       // handle grouping
       newCacheTopology = addGrouping(newCacheTopology);
 
       CacheTopology oldCacheTopology = stateConsumer.getCacheTopology();
+
+      if (oldCacheTopology != null && oldCacheTopology.getTopologyId() > newCacheTopology.getTopologyId()) {
+         throw new IllegalStateException(""Old topology is higher: old="" + oldCacheTopology + "", new="" + newCacheTopology);
+      }
+
       ConsistentHash oldCH = oldCacheTopology != null ? oldCacheTopology.getWriteConsistentHash() : null;
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
@@ -188,15 +193,17 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
 
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
-      if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
+      boolean isJoined = stateConsumer.getCacheTopology().getReadConsistentHash().getMembers().contains(rpcManager.getAddress());
+      if (initialStateTransferComplete.getCount() > 0 && isJoined) {
          initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
    }
 
    @Start(priority = 1000)
    @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
-      if (trace) log.tracef(""Waiting for initial state transfer to finish"");
+      if (trace) log.tracef(""Waiting for initial state transfer to finish for cache %s on %s"", cacheName, rpcManager.getAddress());
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);
       if (!success) {
          throw new CacheException(String.format(""Initial state transfer timed out for cache %s on %s"",
@@ -210,6 +217,7 @@ public void stop() {
       if (trace) {
          log.tracef(""Shutting down StateTransferManager of cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
+      initialStateTransferComplete.countDown();
       localTopologyManager.leave(cacheName);
    }
 
@@ -268,4 +276,14 @@ public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object>
          }
       }
    }
+
+   @Override
+   public void notifyEndOfTopologyUpdate(int topologyId) {
+      if (initialStateTransferComplete.getCount() > 0
+            && stateConsumer.getCacheTopology().getWriteConsistentHash().getMembers().contains(rpcManager.getAddress())) {
+         initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
+      }
+      localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+   }
 }
\ No newline at end of file",2012-11-07T14:07:34Z,117
"@@ -126,13 +126,17 @@ public void triggerRebalance(final String cacheName) throws Exception {
       asyncTransportExecutor.submit(new Callable<Object>() {
          @Override
          public Object call() throws Exception {
-            startRebalance(cacheName);
-            return null;
+            try {
+               startRebalance(cacheName);
+               return null;
+            } catch (Throwable t) {
+               log.errorf(t, ""Failed to start rebalance: %s"", t.getMessage());
+               throw new Exception(t);
+            }
          }
       });
    }
 
-
    @Override
    public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo joinInfo, int viewId) throws Exception {
       waitForView(viewId);
@@ -594,6 +598,7 @@ public Object call() throws Exception {
             try {
                return command.perform(null);
             } catch (Throwable t) {
+               log.errorf(t, ""Failed to execute ReplicableCommand %s on cluster async: %s"", command, t.getMessage());
                throw new Exception(t);
             }
          }",2012-11-07T14:07:34Z,124
"@@ -280,6 +280,7 @@ public Object call() throws Exception {
                try {
                   return command.perform(null);
                } catch (Throwable t) {
+                  log.errorf(t, ""Failed to execute ReplicableCommand %s on coordinator async: %s"", command, t.getMessage());
                   throw new Exception(t);
                }
             }
@@ -298,8 +299,6 @@ class LocalCacheStatus {
    private final CacheTopologyHandler handler;
    private volatile CacheTopology topology;
 
-   private boolean joined;
-
    public LocalCacheStatus(CacheJoinInfo joinInfo, CacheTopologyHandler handler) {
       this.joinInfo = joinInfo;
       this.handler = handler;
@@ -320,12 +319,4 @@ public CacheTopology getTopology() {
    public void setTopology(CacheTopology topology) {
       this.topology = topology;
    }
-
-   public boolean isJoined() {
-      return joined;
-   }
-
-   public void setJoined(boolean joined) {
-      this.joined = joined;
-   }
 }",2012-11-07T14:07:34Z,125
"@@ -53,15 +53,14 @@ public class StaleTransactionCleanupService {
 
    private static Log log = LogFactory.getLog(StaleTransactionCleanupService.class);
 
+   private ScheduledExecutorService executorService;
 
    private TransactionTable transactionTable;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
-   private ScheduledExecutorService executorService;
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * because the main data owner left. Also unlocks keys for which the lock owner has changed as a result of a topology change.
@@ -71,15 +70,19 @@ public StaleTransactionCleanupService(TransactionTable transactionTable) {
    @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // Roll back remote transactions originating on nodes that have left the cluster.
-      if (tce.isPre()) {
-         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
-         if (consistentHashAtStart != null) {
-            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
-            if (!leavers.isEmpty()) {
-               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-               cleanTxForWhichTheOwnerLeft(leavers);
+      try {
+         if (tce.isPre()) {
+            ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+            if (consistentHashAtStart != null) {
+               List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+               if (!leavers.isEmpty()) {
+                  log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+                  cleanTxForWhichTheOwnerLeft(leavers);
+               }
             }
          }
+      } catch (Exception e) {
+         log.error(""Failed to process topology update"", e);
       }
    }
 
@@ -120,7 +123,6 @@ public void run() {
             transactionTable.cleanupCompletedTransactions();
          }
       }, interval, interval, TimeUnit.MILLISECONDS);
-
    }
 
    public void stop() {",2012-11-07T14:07:34Z,126
"@@ -523,25 +523,29 @@ public boolean isTransactionCompleted(GlobalTransaction gtx) {
    }
 
    public void cleanupCompletedTransactions() {
-      log.debugf(""About to cleanup completed transaction. Initial size is %s"", completedTransactions.size());
-      //this iterator is weekly consistent and will never throw ConcurrentModificationException
-      Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
-      long timeout = configuration.transaction().completedTxTimeout();
-
-      int removedEntries = 0;
-      long beginning = System.nanoTime();
-      while (iterator.hasNext()) {
-         Map.Entry<GlobalTransaction, Long> e = iterator.next();
-         long ageNanos = System.nanoTime() - e.getValue();
-         if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
-            iterator.remove();
-            removedEntries++;
+      try {
+         log.debugf(""About to cleanup completed transaction. Initial size is %d"", completedTransactions.size());
+         //this iterator is weekly consistent and will never throw ConcurrentModificationException
+         Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
+         long timeout = configuration.transaction().completedTxTimeout();
+
+         int removedEntries = 0;
+         long beginning = System.nanoTime();
+         while (iterator.hasNext()) {
+            Map.Entry<GlobalTransaction, Long> e = iterator.next();
+            long ageNanos = System.nanoTime() - e.getValue();
+            if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
+               iterator.remove();
+               removedEntries++;
+            }
          }
-      }
-      long duration = System.nanoTime() - beginning;
+         long duration = System.nanoTime() - beginning;
 
-      log.debugf(""Finished cleaning up completed transactions. %s transactions were removed, total duration was %s millis, "" +
-                      ""current number of completed transactions is %"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
-                 completedTransactions.size());
+         log.debugf(""Finished cleaning up completed transactions. %d transactions were removed, total duration was %d millis, "" +
+                         ""current number of completed transactions is %d"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
+                    completedTransactions.size());
+      } catch (Exception e) {
+         log.errorf(e, ""Failed to cleanup completed transactions: %s"", e.getMessage());
+      }
    }
 }",2012-11-07T14:07:34Z,127
"@@ -24,9 +24,7 @@
 
 import org.infinispan.CacheException;
 import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.commands.tx.PrepareCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.bucket.Bucket;
 import org.infinispan.loaders.decorators.SingletonStore;
@@ -60,7 +58,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.UUID;
-import java.util.concurrent.ExecutionException;
 
 import static org.jboss.logging.Logger.Level.*;
 
@@ -131,26 +128,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Can not select %s random members for %s"", id = 8)
    void cannotSelectRandomMembers(int numNeeded, List<Address> members);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Detected a view change. Member list changed from %s to %s"", id = 9)
-   void viewChangeDetected(List<Address> oldMembers, List<Address> newMembers);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a JOIN event! Wait for notification from new joiner %s"", id = 10)
-   void joinEvent(Address joiner);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a LEAVE event! Node %s has just left"", id = 11)
-   void leaveEvent(Address leaver);
-
-   @LogMessage(level = FATAL)
-   @Message(value = ""Unable to process leaver!!"", id = 12)
-   void unableToProcessLeaver(@Cause Exception e);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""I %s am participating in rehash, state providers %s, state receivers %s"", id = 13)
-   void participatingInRehash(Address address, List<Address> stateProviders, List<Address> receiversOfLeaverState);
-
    @LogMessage(level = INFO)
    @Message(value = ""DistributionManager not yet joined the cluster. Cannot do anything about other concurrent joiners."", id = 14)
    void distributionManagerNotJoined();
@@ -163,10 +140,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Problem %s encountered when applying state for key %s!"", id = 16)
    void problemApplyingStateForKey(String msg, Object key);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""View change interrupted; not rehashing!"", id = 17)
-   void viewChangeInterrupted();
-
    @LogMessage(level = WARN)
    @Message(value = ""Unable to apply prepare %s"", id = 18)
    void unableToApplyPrepare(PrepareCommand pc, @Cause Throwable t);
@@ -175,26 +148,10 @@ public interface Log extends BasicLogger {
    @Message(value = ""Couldn't acquire shared lock"", id = 19)
    void couldNotAcquireSharedLock();
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Caught exception replaying %s"", id = 20)
-   void exceptionWhenReplaying(WriteCommand cmd, @Cause Exception e);
-
    @LogMessage(level = WARN)
    @Message(value = ""Expected just one response; got %s"", id = 21)
    void expectedJustOneResponse(Map<Address, Response> lr);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Completed leave rehash on node %s in %s - leavers now are %s"", id = 22)
-   void completedLeaveRehash(Address self, String duration, List<Address> leavers);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error pushing tx log"", id = 23)
-   void errorPushingTxLog(@Cause ExecutionException e);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Unable to stop transaction logging!"", id = 24)
-   void unableToStopTransactionLogging(@Cause IllegalMonitorStateException imse);
-
    @LogMessage(level = INFO)
    @Message(value = ""wakeUpInterval is <= 0, not starting expired purge thread"", id = 25)
    void notStartingEvictionThread();
@@ -211,7 +168,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unable to passivate entry under %s"", id = 28)
    void unableToPassivateEntry(Object key, @Cause Exception e);
 
-
    @LogMessage(level = INFO)
    @Message(value = ""Passivating all entries to disk"", id = 29)
    void passivatingAllEntries();
@@ -296,14 +252,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Interrupted or timeout while waiting for AsyncStore worker threads to push all state to the decorated store"", id = 48)
    void interruptedWaitingAsyncStorePush(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing clear in async store"", id = 49)
-   void errorClearinAsyncStore(@Cause CacheLoaderException e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing purging expired from async store"", id = 50)
-   void errorPurgingAsyncStore(@Cause CacheLoaderException e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Unexpected error"", id = 51)
    void unexpectedErrorInAsyncProcessor(@Cause Throwable t);
@@ -376,14 +324,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Cache named %s does not exist on this cache manager!"", id = 68)
    void namedCacheDoesNotExist(String cacheName);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Cache named [%s] exists but isn't in a state to handle remote invocations"", id = 69)
-   void cacheCanNotHandleInvocations(String cacheName);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Quietly ignoring clustered get call %s since unable to acquire processing lock, even after %s"", id = 70)
-   void ignoreClusterGetCall(CacheRpcCommand cmd, String time);
-
    @LogMessage(level = WARN)
    @Message(value = ""Caught exception when handling command %s"", id = 71)
    void exceptionHandlingCommand(ReplicableCommand cmd, @Cause Throwable t);
@@ -396,18 +336,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unexpected error while replicating"", id = 73)
    void unexpectedErrorReplicating(@Cause Throwable t);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Trying to fetch state from %s"", id = 74)
-   void tryingToFetchState(Address member);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Could not find available peer for state, backing off and retrying"", id = 75)
-   void couldNotFindPeerForState();
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Successfully retrieved and applied state from %s"", id = 76)
-   void successfullyAppliedState(Address member);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Message or message buffer is null or empty."", id = 77)
    void msgOrMsgBufferEmpty();
@@ -461,15 +389,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""getCoordinator(): Interrupted while waiting for members to be set"", id = 89)
    void interruptedWaitingForCoordinator(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Unable to retrieve state from member %s"", id = 90)
-   void unableToRetrieveState(Address member, @Cause Exception e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Channel does not contain STREAMING_STATE_TRANSFER. "" +
-         ""Cannot support state transfers!"", id = 91)
-   void streamingStateTransferNotPresent();
-
    @LogMessage(level = WARN)
    @Message(value = ""Channel not set up properly!"", id = 92)
    void channelNotSetUp();
@@ -482,10 +401,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Received new cluster view: %s"", id = 94)
    void receivedClusterView(View newView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Caught while requesting or applying state"", id = 96)
-   void errorRequestingOrApplyingState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error while processing a prepare in a single-phase transaction"", id = 97)
    void errorProcessing1pcPrepareCommand(@Cause Throwable e);
@@ -688,14 +603,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Failed loading value for key %s from cache store"", id = 144)
    void failedLoadingValueFromCacheStore(Object key, @Cause Exception e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error during rehash"", id = 145)
-   void errorDuringRehash(@Cause Throwable th);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error transferring state to node after rehash"", id = 146)
-   void errorTransferringState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error invalidating keys from L1 after rehash"", id = 147)
    void failedToInvalidateKeys(@Cause Exception e);
@@ -729,14 +636,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Unable to unlock keys %2$s for transaction %1$s after they were rebalanced off node %3$s"", id = 154)
    void unableToUnlockRebalancedKeys(GlobalTransaction gtx, List<Object> keys, Address self, @Cause Throwable t);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm pushing data for view %d, received confirmations %s. Cancelling state transfer"", id = 157)
-   void stateTransferTimeoutWaitingForPushConfirmations(int viewId, Map<Address, Integer> pushConfirmations);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm joining for view %d, joined %s. Cancelling state transfer"", id = 158)
-   void stateTransferTimeoutWaitingForJoinConfirmations(int viewId, Map<Address, Integer> joinConfirmations);
-
    @LogMessage(level = WARN)
    @Message(value = ""Unblocking transactions failed"", id = 159)
    void errorUnblockingTransactions(@Cause Exception e);
@@ -761,26 +660,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Rolling back to cache view %d, but last committed view is %d"", id = 164)
    void cacheViewRollbackIdMismatch(int committedViewId, int committedView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error triggering a view installation for cache %s"", id = 165)
-   void errorTriggeringViewInstallation(@Cause RuntimeException e, String cacheName);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""View installation failed for cache %s"", id = 166)
-   void viewInstallationFailure(@Cause Throwable e, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Rejecting state pushed by node %s for view %d, there is no state transfer in progress (we are at view %d)"", id = 167)
-   void remoteStateRejected(Address sender, int viewId, int installedViewId);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error rolling back to cache view %1$d for cache %2$s"", id = 168)
-   void cacheViewRollbackFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error committing cache view %1$d for cache %2$s"", id = 169)
-   void cacheViewCommitFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
    @LogMessage(level = INFO)
    @Message(value = ""Strict peer-to-peer is enabled but the JGroups channel was started externally - this is very likely to result in RPC timeout errors on startup"", id = 171)
    void warnStrictPeerToPeerWithInjectedChannel();
@@ -926,5 +805,16 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @LogMessage(level = WARN)
    @Message(value = ""Could not interrupt as no thread found for command uuid %s"", id=207)
    void couldNotInterruptThread(UUID id);
-   
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""No live owners found for segment %d of cache %s. Current owners are:  %s. Faulty owners: %s"", id=208)
+   void noLiveOwnersFoundForSegment(int segmentId, String cacheName, Collection<Address> owners, Collection<Address> faultySources);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to retrieve transactions for segments %s of cache %s from node %s (node will not be retried)"", id=209)
+   void failedToRetrieveTransactionsForSegments(Collection<Integer> segments, String cacheName, Address source);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to request segments %s of cache %s from node %s (node will not be retried)"", id=210)
+   void failedToRequestSegments(Collection<Integer> segments, String cacheName, Address source);
 }",2012-11-07T14:07:34Z,45
"@@ -263,7 +263,7 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm, boolean deprecated) {
 
       assert gc.asyncTransportExecutor().factory() instanceof DefaultExecutorFactory;
       // Should be 25, but it's overriden by the test cache manager factory
-      assertEquals(""4"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
+      assertEquals(""6"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
       assert gc.asyncTransportExecutor().properties().getProperty(""threadNamePrefix"").equals(""AsyncSerializationThread"");
 
       assert gc.evictionScheduledExecutor().factory() instanceof DefaultScheduledExecutorFactory;",2012-11-07T14:07:34Z,128
"@@ -50,7 +50,6 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -126,7 +125,7 @@ public void test1() throws Exception {
       when(cache.getName()).thenReturn(""testCache"");
 
       StateProvider stateProvider = mock(StateProvider.class);
-      LocalTopologyManager localTopologyManager = mock(LocalTopologyManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
       CacheNotifier cacheNotifier = mock(CacheNotifier.class);
       ExecutorService mockExecutorService = mock(ExecutorService.class);
       RpcManager rpcManager = mock(RpcManager.class);
@@ -183,7 +182,7 @@ public Map<Address, Response> answer(InvocationOnMock invocation) {
 
       // create state provider
       StateConsumerImpl stateConsumer = new StateConsumerImpl();
-      stateConsumer.init(cache, localTopologyManager, interceptorChain, icc, configuration, rpcManager,
+      stateConsumer.init(cache, stateTransferManager, interceptorChain, icc, configuration, rpcManager,
             commandsFactory, cacheLoaderManager, dataContainer, transactionTable, stateTransferLock);
       stateConsumer.start();
 ",2012-11-07T14:07:34Z,56
"@@ -40,6 +40,7 @@
 
 /**
  * Test if state transfer happens properly on a cache with pessimistic transactions.
+ * See https://issues.jboss.org/browse/ISPN-2408.
  *
  * @since 5.2
  */",2012-11-07T14:07:34Z,129
"@@ -75,6 +75,8 @@
  */
 public class TestCacheManagerFactory {
 
+   private static final int MAX_ASYNC_EXEC_THREADS = 6;
+
    public static final String MARSHALLER = LegacyKeySupportSystemProperties.getProperty(""infinispan.test.marshaller.class"", ""infinispan.marshaller.class"");
    private static final Log log = LogFactory.getLog(TestCacheManagerFactory.class);
 
@@ -523,12 +525,12 @@ private static void checkTestName(String fullTestName) {
 
    public static void minimizeThreads(GlobalConfiguration gc) {
       Properties p = new Properties();
-      p.setProperty(""maxThreads"", ""4"");
+      p.setProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
       gc.setAsyncTransportExecutorProperties(p);
    }
 
    public static void minimizeThreads(GlobalConfigurationBuilder builder) {
-      builder.asyncTransportExecutor().addProperty(""maxThreads"", ""4"");
+      builder.asyncTransportExecutor().addProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
    }
 
    public static void amendMarshaller(GlobalConfiguration configuration) {",2012-11-07T14:07:34Z,130
"@@ -161,13 +161,12 @@ public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo
       waitForView(viewId);
 
       rebalancePolicy.initCache(cacheName, joinInfo);
-      rebalancePolicy.updateMembersList(cacheName, Collections.singletonList(joiner), Collections.<Address>emptyList());
-      return rebalancePolicy.getTopology(cacheName);
+      return rebalancePolicy.addJoiners(cacheName, Collections.singletonList(joiner));
    }
 
    @Override
    public void handleLeave(String cacheName, Address leaver, int viewId) throws Exception {
-      rebalancePolicy.updateMembersList(cacheName, Collections.<Address>emptyList(), Collections.singletonList(leaver));
+      rebalancePolicy.removeLeavers(cacheName, Collections.singletonList(leaver));
    }
 
    @Override",2012-08-31T21:05:51Z,124
"@@ -110,18 +110,26 @@ public void initCache(String cacheName, List<CacheTopology> partitionTopologies)
 
       synchronized (cacheStatus) {
          CacheTopology cacheTopology = new CacheTopology(unionTopologyId, currentCHUnion, pendingCHUnion);
-         updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+         updateConsistentHash(cacheName, cacheStatus, cacheTopology, true);
          // TODO Trigger a new rebalance
       }
    }
 
    /**
     * Should only be called while holding the cacheStatus lock
     */
-   private void updateConsistentHash(String cacheName, CacheStatus cacheStatus, CacheTopology cacheTopology) throws Exception {
+   private void updateConsistentHash(String cacheName, CacheStatus cacheStatus, CacheTopology cacheTopology,
+                                     boolean broadcast) throws Exception {
       log.tracef(""Updating cache %s topology: %s"", cacheName, cacheTopology);
       cacheStatus.setCacheTopology(cacheTopology);
-      clusterTopologyManager.updateConsistentHash(cacheName, cacheStatus.getCacheTopology());
+      ConsistentHash currentCH = cacheTopology.getCurrentCH();
+      if (currentCH != null) {
+         cacheStatus.getJoiners().removeAll(currentCH.getMembers());
+         log.tracef(""Updated joiners list for cache %s: %s"", cacheName, cacheStatus.getJoiners());
+      }
+      if (broadcast) {
+         clusterTopologyManager.updateConsistentHash(cacheName, cacheStatus.getCacheTopology());
+      }
    }
 
    @Override
@@ -142,30 +150,9 @@ public void updateMembersList(List<Address> newClusterMembers) throws Exception
             boolean currentMembersValid = newClusterMembers.containsAll(currentCH.getMembers());
             boolean pendingMembersValid = pendingCH == null || newClusterMembers.containsAll(pendingCH.getMembers());
             if (!currentMembersValid || !pendingMembersValid) {
-               int topologyId = cacheStatus.getCacheTopology().getTopologyId();
-               ConsistentHashFactory consistentHashFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
-
                List<Address> newCurrentMembers = new ArrayList<Address>(currentCH.getMembers());
                newCurrentMembers.retainAll(newClusterMembers);
-               if (newCurrentMembers.isEmpty()) {
-                  log.tracef(""Zero members remaining for cache %s"", cacheName);
-                  return;
-               }
-               ConsistentHash newCurrentCH = consistentHashFactory.updateMembers(currentCH, newCurrentMembers);
-
-               ConsistentHash newPendingCH = null;
-               if (pendingCH != null) {
-                  List<Address> newPendingMembers = new ArrayList<Address>(cacheStatus.getCacheTopology().getMembers());
-                  newPendingMembers.retainAll(newClusterMembers);
-                  if (newPendingMembers.isEmpty()) {
-                     log.tracef(""Zero members remaining for cache %s"", cacheName);
-                     return;
-                  }
-                  newPendingCH = consistentHashFactory.updateMembers(pendingCH, newPendingMembers);
-               }
-
-               CacheTopology cacheTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
-               updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+               updateCacheMembers(cacheName, cacheStatus, newCurrentMembers);
             }
 
             if (!isBalanced(cacheStatus.getCacheTopology().getCurrentCH()) || !cacheStatus.getJoiners().isEmpty()) {
@@ -179,62 +166,80 @@ public void updateMembersList(List<Address> newClusterMembers) throws Exception
    }
 
    @Override
-   public void updateMembersList(String cacheName, List<Address> joiners, List<Address> leavers) throws Exception {
-      // TODO Separate into two methods, join() and leave()
+   public CacheTopology addJoiners(String cacheName, List<Address> joiners) throws Exception {
       CacheStatus cacheStatus = cacheStatusMap.get(cacheName);
       if (cacheStatus == null) {
          log.tracef(""Ignoring members update for cache %s, as we haven't initialized it yet"", cacheName);
-         return;
+         return null;
       }
 
-      CacheJoinInfo joinInfo = cacheStatus.getJoinInfo();
-      if (!leavers.isEmpty()) {
-         synchronized (cacheStatus) {
-            int topologyId = cacheStatus.getCacheTopology().getTopologyId();
-            ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
-            ConsistentHash pendingCH = cacheStatus.getCacheTopology().getPendingCH();
-
-            // The list of ""current"" members will always be included in the set of ""pending"" members,
-            // because leaves are reflected at the same time in both collections
-            List<Address> newMembers = new ArrayList<Address>(clusterMembers);
-            newMembers.removeAll(leavers);
+      synchronized (cacheStatus) {
+         addUniqueJoiners(cacheStatus.getJoiners(), joiners);
 
-            ConsistentHash newPendingCH = null;
-            if (pendingCH != null) {
-               newMembers.retainAll(pendingCH.getMembers());
-               if (newMembers.isEmpty()) {
-                  log.tracef(""Zero members remaining for cache %s"", cacheName);
-                  return;
-               }
+         ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
+         if (currentCH == null) {
+            installInitialTopology(cacheName, cacheStatus);
+         } else {
+            triggerRebalance(cacheName, cacheStatus);
+         }
+         return cacheStatus.getCacheTopology();
+      }
+   }
 
-               newPendingCH = joinInfo.getConsistentHashFactory().updateMembers(pendingCH, newMembers);
-            }
+   @Override
+   public void removeLeavers(String cacheName, List<Address> leavers) throws Exception {
+      CacheStatus cacheStatus = cacheStatusMap.get(cacheName);
+      if (cacheStatus == null) {
+         log.tracef(""Ignoring members update for cache %s, as we haven't initialized it yet"", cacheName);
+         return;
+      }
 
-            newMembers.retainAll(currentCH.getMembers());
-            if (newMembers.isEmpty()) {
-               log.tracef(""Zero members remaining for cache %s"", cacheName);
-               return;
-            }
-            ConsistentHash newCurrentCH = joinInfo.getConsistentHashFactory().updateMembers(currentCH, newMembers);
+      synchronized (cacheStatus) {
+         // The list of ""current"" members will always be included in the set of ""pending"" members,
+         // because leaves are reflected at the same time in both collections
+         List<Address> newMembers = new ArrayList<Address>(clusterMembers);
+         newMembers.removeAll(leavers);
 
-            CacheTopology cacheTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
-            updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+         updateCacheMembers(cacheName, cacheStatus, newMembers);
+      }
+   }
 
-            triggerRebalance(cacheName, cacheStatus);
+   private void updateCacheMembers(String cacheName, CacheStatus cacheStatus, List<Address> newMembers)
+         throws Exception {
+      CacheJoinInfo joinInfo = cacheStatus.getJoinInfo();
+      int topologyId = cacheStatus.getCacheTopology().getTopologyId();
+      ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
+      ConsistentHash pendingCH = cacheStatus.getCacheTopology().getPendingCH();
+
+      ConsistentHash newPendingCH = null;
+      if (pendingCH != null) {
+         newMembers.retainAll(pendingCH.getMembers());
+         if (!newMembers.isEmpty()) {
+            newPendingCH = joinInfo.getConsistentHashFactory().updateMembers(pendingCH, newMembers);
+         } else {
+            log.tracef(""Zero new members remaining for cache %s"", cacheName);
          }
       }
 
-      if (!joiners.isEmpty()) {
-         synchronized (cacheStatus) {
-            addUniqueJoiners(cacheStatus.getJoiners(), joiners);
+      newMembers.retainAll(currentCH.getMembers());
+      ConsistentHash newCurrentCH;
+      if (!newMembers.isEmpty()) {
+         newCurrentCH = joinInfo.getConsistentHashFactory().updateMembers(currentCH, newMembers);
+      } else {
+         log.tracef(""Zero old members remaining for cache %s"", cacheName);
+         // use the new pending CH, it might be non-null if we have joiners
+         newCurrentCH = newPendingCH;
+      }
 
-            ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
-            if (currentCH == null) {
-               installInitialTopology(cacheName, cacheStatus);
-            } else {
-               triggerRebalance(cacheName, cacheStatus);
-            }
-         }
+      boolean hasMembers = newCurrentCH != null;
+      CacheTopology cacheTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
+
+      // Don't broadcast a cache topology when we don't have any members left
+      updateConsistentHash(cacheName, cacheStatus, cacheTopology, hasMembers);
+
+      // Don't trigger a rebalance without any members either
+      if (hasMembers) {
+         triggerRebalance(cacheName, cacheStatus);
       }
    }
 
@@ -247,7 +252,7 @@ private void installInitialTopology(String cacheName, CacheStatus cacheStatus) t
       CacheTopology cacheTopology = new CacheTopology(newTopologyId, balancedCH, null);
 
       log.tracef(""Installing initial topology for cache %s: %s"", cacheName, cacheTopology);
-      updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+      updateConsistentHash(cacheName, cacheStatus, cacheTopology, false);
    }
 
    private void addUniqueJoiners(List<Address> members, List<Address> joiners) {
@@ -269,33 +274,49 @@ public Object call() throws Exception {
    }
 
    private void doRebalance(String cacheName, CacheStatus cacheStatus) throws Exception {
+      CacheTopology cacheTopology = cacheStatus.getCacheTopology();
+      CacheTopology newCacheTopology;
+
       synchronized (cacheStatus) {
-         boolean isRebalanceInProgress = cacheStatus.getCacheTopology().getPendingCH() != null;
+         boolean isRebalanceInProgress = cacheTopology.getPendingCH() != null;
          if (isRebalanceInProgress) {
-            log.tracef(""Ignoring request to start rebalancing cache %s, there's already a rebalance in progress: %s"",
-                  cacheName, cacheStatus.getCacheTopology());
+            log.tracef(""Ignoring request to rebalance cache %s, there's already a rebalance in progress: %s"",
+                  cacheName, cacheTopology);
+            return;
+         }
+
+         List<Address> newMembers = new ArrayList<Address>(cacheTopology.getMembers());
+         if (newMembers.isEmpty()) {
+            log.tracef(""Ignoring request to rebalance cache %s, it doesn't have any member"", cacheName);
             return;
          }
 
-         List<Address> newMembers = new ArrayList<Address>(cacheStatus.getCacheTopology().getMembers());
          addUniqueJoiners(newMembers, cacheStatus.getJoiners());
          newMembers.retainAll(clusterMembers);
+
          log.tracef(""Rebalancing consistent hash for cache %s, members are %s"", cacheName, newMembers);
+         int newTopologyId = cacheTopology.getTopologyId() + 1;
+         ConsistentHash currentCH = cacheTopology.getCurrentCH();
+         if (currentCH == null) {
+            // There was one node in the cache before, and it left after the rebalance was triggered
+            // but before the rebalance actually started.
+            installInitialTopology(cacheName, cacheStatus);
+            return;
+         }
 
-         int newTopologyId = cacheStatus.getCacheTopology().getTopologyId() + 1;
-         ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
          ConsistentHashFactory chFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
          ConsistentHash updatedMembersCH = chFactory.updateMembers(currentCH, newMembers);
          ConsistentHash balancedCH = chFactory.rebalance(updatedMembersCH);
          if (balancedCH.equals(currentCH)) {
             log.tracef(""The balanced CH is the same as the current CH, not rebalancing"");
             return;
          }
-         CacheTopology cacheTopology = new CacheTopology(newTopologyId, currentCH, balancedCH);
-         log.tracef(""Updating cache %s topology for rebalance: %s"", cacheName, cacheTopology);
-         cacheStatus.setCacheTopology(cacheTopology);
+         newCacheTopology = new CacheTopology(newTopologyId, currentCH, balancedCH);
+         log.tracef(""Updating cache %s topology for rebalance: %s"", cacheName, newCacheTopology);
+         cacheStatus.setCacheTopology(newCacheTopology);
       }
-      clusterTopologyManager.rebalance(cacheName, cacheStatus.getCacheTopology());
+
+      clusterTopologyManager.rebalance(cacheName, newCacheTopology);
    }
 
    @Override
@@ -312,7 +333,7 @@ public void onRebalanceCompleted(String cacheName, int topologyId) throws Except
          ConsistentHash newCurrentCH = cacheStatus.getCacheTopology().getPendingCH();
 
          CacheTopology cacheTopology = new CacheTopology(newTopologyId, newCurrentCH, null);
-         updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+         updateConsistentHash(cacheName, cacheStatus, cacheTopology, true);
 
          // Update the list of joiners
          // TODO Add some cleanup for nodes that left the cluster before getting any state",2012-08-31T21:05:51Z,597
"@@ -55,9 +55,15 @@ public interface RebalancePolicy {
    void updateMembersList(List<Address> membersList) throws Exception;
 
    /**
-    * Called when a member joins or leaves an individual cache.
+    * Called when one or more members join a cache.
+    * @return The previous cache topology.
     */
-   void updateMembersList(String cacheName, List<Address> joiners, List<Address> leavers) throws Exception;
+   CacheTopology addJoiners(String cacheName, List<Address> joiners) throws Exception;
+
+   /**
+    * Called when one or more members leave an individual cache (as opposed to leaving the cluster).
+    */
+   void removeLeavers(String cacheName, List<Address> leavers) throws Exception;
 
    /**
     * Called when every member has completed receiving data.",2012-08-31T21:05:51Z,598
"@@ -30,7 +30,6 @@
 import org.testng.annotations.Test;
 
 import java.util.List;
-import java.util.Set;
 
 /**
  * @author Mircea Markus
@@ -73,17 +72,17 @@ public void run() {
          @Override
          public boolean isSatisfied() throws Exception {
             List<Address> members = advancedCache(0).getRpcManager().getTransport().getMembers();
-            System.out.println(""members = "" + members);
+            log.trace(""members = "" + members);
             return members.size() == 1;
          }
       });
 
-      System.out.println(""MultipleNodesLeavingTest.testMultipleLeaves"");
+      log.trace(""MultipleNodesLeavingTest.testMultipleLeaves"");
 
       TestingUtil.blockUntilViewsReceived(60000, false, cache(0));
       TestingUtil.waitForRehashToComplete(cache(0));
       List<Address> caches = advancedCache(0).getDistributionManager().getConsistentHash().getMembers();
-      System.out.println(""caches = "" + caches);
+      log.tracef(""caches = %s"", caches);
       int size = caches.size();
       assert size == 1;
    }",2012-10-02T12:10:18Z,599
"@@ -71,13 +71,12 @@
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.marshall.jboss.ExternalizerTable;
 import org.infinispan.remoting.ReplicationQueue;
-import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.remoting.transport.jgroups.JGroupsTransport;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.topology.DefaultRebalancePolicy;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.topology.RebalancePolicy;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.util.concurrent.locks.LockManager;
@@ -167,14 +166,14 @@ public static void waitForRehashToComplete(Cache... caches) {
       // give it 1 second to start rehashing
       // TODO Should look at the last committed view instead and check if it contains all the caches
       LockSupport.parkNanos(TimeUnit.SECONDS.toNanos(1));
-      int gracetime = 90000; // 60 seconds
+      int gracetime = 90000; // 90 seconds
       long giveup = System.currentTimeMillis() + gracetime;
       for (Cache c : caches) {
-         LocalTopologyManager localTopologyManager = TestingUtil.extractGlobalComponent(c.getCacheManager(), LocalTopologyManager.class);
+         StateTransferManager stateTransferManager = TestingUtil.extractComponent(c, StateTransferManager.class);
          DefaultRebalancePolicy rebalancePolicy = (DefaultRebalancePolicy) TestingUtil.extractGlobalComponent(c.getCacheManager(), RebalancePolicy.class);
-         RpcManager rpcManager = TestingUtil.extractComponent(c, RpcManager.class);
+         Address cacheAddress = c.getAdvancedCache().getRpcManager().getAddress();
          while (true) {
-            CacheTopology cacheTopology = localTopologyManager.getCacheTopology(c.getName());
+            CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
             boolean chContainsAllMembers = cacheTopology.getCurrentCH().getMembers().size() == caches.length;
             boolean chIsBalanced = rebalancePolicy.isBalanced(cacheTopology.getCurrentCH());
             boolean stateTransferInProgress = cacheTopology.getPendingCH() != null;
@@ -190,7 +189,7 @@ public static void waitForRehashToComplete(Cache... caches) {
                   }
                   message = String.format(""Timed out waiting for rebalancing to complete on node %s, "" +
                         ""expected member list is %s, current member list is %s!"",
-                        rpcManager.getAddress(), Arrays.toString(addresses), cacheTopology.getCurrentCH().getMembers());
+                        cacheAddress, Arrays.toString(addresses), cacheTopology.getCurrentCH().getMembers());
                } else {
                   message = String.format(""Timed out waiting for rebalancing to complete on node %s, "" +
                         ""current topology is %s"", c.getCacheManager().getAddress(), cacheTopology);
@@ -201,7 +200,7 @@ public static void waitForRehashToComplete(Cache... caches) {
 
             LockSupport.parkNanos(TimeUnit.MILLISECONDS.toNanos(100));
          }
-         log.trace(""Node "" + rpcManager.getAddress() + "" finished state transfer."");
+         log.trace(""Node "" + cacheAddress + "" finished state transfer."");
       }
    }
 ",2012-10-02T12:10:18Z,50
"@@ -647,15 +647,24 @@ public NotifyingFuture<V> getAsync(final K key) {
       if (asyncSkipsThread(flags, key)) {
          return wrapInFuture(get(key));
       } else {
+         // Make sure the flags are cleared
+         final EnumSet<Flag> appliedFlags;
+         if (flags == null) {
+            appliedFlags = null;
+         }
+         else {
+            appliedFlags = flags.clone();
+            flags.clear();
+         }
          Callable<V> c = new Callable<V>() {
             @Override
             public V call() throws Exception {
                assertKeyNotNull(key);
                InvocationContext ctx = getInvocationContext(tx);
-               if (flags != null)
-                  ctx.setFlags(flags);
+               if (appliedFlags != null)
+                  ctx.setFlags(appliedFlags);
 
-               GetKeyValueCommand command = commandsFactory.buildGetKeyValueCommand(key, flags);
+               GetKeyValueCommand command = commandsFactory.buildGetKeyValueCommand(key, appliedFlags);
                Object ret = invoker.invoke(ctx, command);
                f.notifyDone();
                return (V) ret;",2011-08-04T21:58:05Z,438
"@@ -32,6 +32,7 @@
 
 import java.util.HashMap;
 import java.util.Map;
+import java.util.concurrent.Future;
 
 /**
  * DistSyncSharedTest.
@@ -87,6 +88,26 @@ public void testGetFromNonOwnerWithFlags() throws Exception {
       assertOwnershipAndNonOwnership(key, true);
    }
    
+   public void testAsyncGetCleansContextFlags() throws Exception {
+      String key = ""k2"", value = ""value2"";
+      for (Cache<Object, String> c : caches) assert c.isEmpty();
+
+      Cache<Object, String> nonOwner = getFirstNonOwner(key);
+      Cache<Object, String> owner = getFirstOwner(key);
+      owner.put(key, value);
+
+      owner.getAdvancedCache().withFlags(Flag.SKIP_CACHE_STORE).clear();
+
+      Future<String> async = nonOwner.getAdvancedCache().withFlags(Flag.SKIP_CACHE_STORE).getAsync(key);
+      assert async != null;
+      assert async.get() == null;
+
+      async = nonOwner.getAdvancedCache().getAsync(key);
+      assert async != null;
+      String returnedValue = async.get();
+      assert value.equals(returnedValue);
+   }
+
    public void testPutFromNonOwnerWithFlags() throws Exception {
       String key = ""k2"", value = ""value2"";
       for (Cache<Object, String> c : caches) assert c.isEmpty();",2011-08-04T21:58:05Z,3
"@@ -72,6 +72,7 @@ public class ResourceDMBean implements DynamicMBean {
    private final Object obj;
    private final Class<?> objectClass;
    private final MBeanOperationInfo[] opInfos;
+   private final MBeanAttributeInfo[] attInfos;
    private final HashMap<String, InvokableMBeanAttributeInfo> atts = new HashMap<String, InvokableMBeanAttributeInfo>(2);
    private final ManageableComponentMetadata mBeanMetadata;
 
@@ -92,18 +93,22 @@ public ResourceDMBean(Object instance, ManageableComponentMetadata mBeanMetadata
 
       // Load up all fields.
       InvokableMBeanAttributeInfo info;
+      int i = 0;
+      attInfos = new MBeanAttributeInfo[mBeanMetadata.getAttributeMetadata().size()];
       for (JmxAttributeMetadata attributeMetadata : mBeanMetadata.getAttributeMetadata()) {
          info = toJmxInfo(attributeMetadata);
-         atts.put(info.getName(), info);
+         atts.put(info.getMBeanAttributeInfo().getName(), info);
+         attInfos[i++] = info.getMBeanAttributeInfo();
          if (trace)
-            log.tracef(""Attribute %s [r=%b,w=%b,is=%b,type=%s]"", info.getName(), info.isReadable(), info.isWritable(), info.isIs(), info.getType());
+            log.tracef(""Attribute %s [r=%b,w=%b,is=%b,type=%s]"", info.getMBeanAttributeInfo().getName(),
+                       info.getMBeanAttributeInfo().isReadable(), info.getMBeanAttributeInfo().isWritable(),
+                       info.getMBeanAttributeInfo().isIs(), info.getMBeanAttributeInfo().getType());
       }
 
       // And operations
       MBeanOperationInfo op;
       opInfos = new MBeanOperationInfo[mBeanMetadata.getOperationMetadata().size()];
-      int i = 0;
-
+      i = 0;
       for (JmxOperationMetadata operation : mBeanMetadata.getOperationMetadata()) {
          op = toJmxInfo(operation);
          opInfos[i++] = op;
@@ -182,10 +187,9 @@ Object getObject() {
    }
 
    public synchronized MBeanInfo getMBeanInfo() {
-      return new MBeanInfo(getObject().getClass().getCanonicalName(), mBeanMetadata.getDescription(),
-                           atts.values().toArray(new MBeanAttributeInfo[atts.size()]), null, opInfos, null);
+      return new MBeanInfo(getObject().getClass().getCanonicalName(), mBeanMetadata.getDescription(), attInfos, null, opInfos, null);
    }
-
+   
    public synchronized Object getAttribute(String name) throws AttributeNotFoundException {
       if (name == null || name.length() == 0)
          throw new NullPointerException(""Invalid attribute requested "" + name);
@@ -282,7 +286,7 @@ private synchronized Attribute getNamedAttribute(String name) {
                result = new Attribute(name, i.invoke(null));
                if (log.isDebugEnabled())
                   log.debugf(""Attribute %s has r=%b,w=%b,is=%b and value %s"",
-                             name, i.isReadable(), i.isWritable(), i.isIs(), result.getValue());
+                             name, i.getMBeanAttributeInfo().isReadable(), i.getMBeanAttributeInfo().isWritable(), i.getMBeanAttributeInfo().isIs(), result.getValue());
             } catch (Exception e) {
                log.debugf(""Exception while reading value of attribute %s: %s"", name, e);
             }
@@ -323,12 +327,19 @@ private boolean setNamedAttribute(Attribute attribute) {
       return result;
    }
 
-   private static abstract class InvokableMBeanAttributeInfo extends MBeanAttributeInfo {
+   private static abstract class InvokableMBeanAttributeInfo {
+
+      private final MBeanAttributeInfo attributeInfo;
+
       public InvokableMBeanAttributeInfo(String name, String type, String description, boolean isReadable, boolean isWritable, boolean isIs) {
-         super(name, type, description, isReadable, isWritable, isIs);
+         attributeInfo = new MBeanAttributeInfo(name, type, description, isReadable, isWritable, isIs);
       }
 
       public abstract Object invoke(Attribute a) throws IllegalAccessException, InvocationTargetException;
+
+      public MBeanAttributeInfo getMBeanAttributeInfo() {
+         return attributeInfo;
+      }
    }
 
    private static class InvokableFieldBasedMBeanAttributeInfo extends InvokableMBeanAttributeInfo {",2012-01-05T08:57:21Z,601
"@@ -35,7 +35,6 @@
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.TransactionTable;
@@ -58,14 +57,9 @@ public abstract class AbstractTxLockingInterceptor extends AbstractLockingInterc
    public void setDependencies(TransactionTable txTable, RpcManager rpcManager) {
       this.txTable = txTable;
       this.rpcManager = rpcManager;
-   }
-
-   @Start
-   private void setClustered() {
       clustered = rpcManager != null;
    }
 
-
    @Override
    public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand command) throws Throwable {
       try {
@@ -169,10 +163,12 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
       TxInvocationContext txContext = (TxInvocationContext) ctx;
       int transactionViewId = -1;
+      boolean useStrictComparison = true;
       if (clustered) {
          transactionViewId = txContext.getCacheTransaction().getViewId();
          if (transactionViewId != TransactionTable.CACHE_STOPPED_VIEW_ID) {
-            checkForPendingLocks = transactionViewId > txTable.getMinViewId();
+            useStrictComparison = txTable.useStrictTopologyIdComparison();
+            checkForPendingLocks = isFromOlderTopology(txTable.getMinViewId(), transactionViewId, useStrictComparison);
          }
       }
 
@@ -183,15 +179,15 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
 
          // Check local transactions first
          for (CacheTransaction ct: txTable.getLocalTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
          }
 
          // ... then remote ones
          for (CacheTransaction ct: txTable.getRemoteTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
@@ -211,6 +207,19 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
    }
 
+   /**
+    * Checks if first topology id is smaller than the second. The comparison can be strict or non-strict,
+    * depending on the isStrictComparison flag.
+    *
+    * @param tx1TopologyId topology id of first transaction
+    * @param tx2TopologyId topology id of second transaction
+    * @param useStrictComparison a flag indicating if comparison must be strict
+    * @return if the first transaction was started in an older topology than the second transaction
+    */
+   private boolean isFromOlderTopology(int tx1TopologyId, int tx2TopologyId, boolean useStrictComparison) {
+      return useStrictComparison ? tx1TopologyId < tx2TopologyId : tx1TopologyId <= tx2TopologyId;
+   }
+
    private TimeoutException newTimeoutException(Object key, TxInvocationContext txContext) {
       return new TimeoutException(""Could not acquire lock on "" + key + "" on behalf of transaction "" +
                                        txContext.getGlobalTransaction() + "". Lock is being held by "" + lockManager.getOwner(key));",2012-09-21T12:26:43Z,131
"@@ -109,9 +109,7 @@ public interface CacheNotifier extends Listenable {
     */
    void notifyTransactionRegistered(GlobalTransaction globalTransaction, InvocationContext ctx);
 
-   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre);
-
-   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre);
-
+   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre);
 
+   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre);
 }
\ No newline at end of file",2012-09-21T12:26:43Z,132
"@@ -334,24 +334,25 @@ public void notifyTransactionRegistered(GlobalTransaction globalTransaction, Inv
    }
 
    @Override
-   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre) {
+   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre) {
       if (!dataRehashedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, DATA_REHASHED);
          e.setPre(pre);
          e.setMembersAtStart(oldView);
          e.setMembersAtEnd(newView);
-         e.setNewViewId(newViewId);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : dataRehashedListeners) listener.invoke(e);
       }
    }
 
    @Override
-   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre) {
+   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre) {
       if (!topologyChangedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, TOPOLOGY_CHANGED);
          e.setPre(pre);
          e.setConsistentHashAtStart(oldConsistentHash);
          e.setConsistentHashAtEnd(newConsistentHash);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : topologyChangedListeners) listener.invoke(e);
       }
    }",2012-09-21T12:26:43Z,133
"@@ -43,7 +43,7 @@ public interface DataRehashedEvent<K, V> extends Event<K, V> {
    Collection<Address> getMembersAtEnd();
 
    /**
-    * @return Retrieves the new view id after rehashing was triggered.
+    * @return Retrieves the new topology id after rehashing was triggered.
     */
-   long getNewViewId();
+   int getNewTopologyId();
 }",2012-09-21T12:26:43Z,134
"@@ -53,7 +53,7 @@ public class EventImpl<K, V> implements CacheEntryActivatedEvent, CacheEntryCrea
    private V value;
    private Collection<Address> membersAtStart, membersAtEnd;
    private ConsistentHash consistentHashAtStart, consistentHashAtEnd;
-   private long newViewId;
+   private int newTopologyId;
    private Map<Object, Object> entries;
 
    public EventImpl() {
@@ -150,8 +150,8 @@ public void setConsistentHashAtEnd(ConsistentHash consistentHashAtEnd) {
       this.consistentHashAtEnd = consistentHashAtEnd;
    }
 
-   public void setNewViewId(long newViewId) {
-      this.newViewId = newViewId;
+   public void setNewTopologyId(int newTopologyId) {
+      this.newTopologyId = newTopologyId;
    }
 
    @Override
@@ -189,7 +189,7 @@ public boolean equals(Object o) {
       if (!Util.safeEquals(consistentHashAtEnd, event.consistentHashAtEnd)) return false;
       if (!Util.safeEquals(membersAtStart, event.membersAtStart)) return false;
       if (!Util.safeEquals(membersAtEnd, event.membersAtEnd)) return false;
-      if (newViewId != event.newViewId) return false;
+      if (newTopologyId != event.newTopologyId) return false;
 
       return true;
    }
@@ -208,7 +208,7 @@ public int hashCode() {
       result = 31 * result + (membersAtEnd != null ? membersAtEnd.hashCode() : 0);
       result = 31 * result + (consistentHashAtStart != null ? consistentHashAtStart.hashCode() : 0);
       result = 31 * result + (consistentHashAtEnd != null ? consistentHashAtEnd.hashCode() : 0);
-      result = 31 * result + ((int) newViewId);
+      result = 31 * result + ((int) newTopologyId);
       return result;
    }
 
@@ -236,8 +236,8 @@ public Collection<Address> getMembersAtEnd() {
    }
 
    @Override
-   public long getNewViewId() {
-      return newViewId;
+   public int getNewTopologyId() {
+      return newTopologyId;
    }
 
    @Override",2012-09-21T12:26:43Z,135
"@@ -40,5 +40,7 @@ public interface TopologyChangedEvent<K, V> extends Event<K, V> {
     */
    ConsistentHash getConsistentHashAtEnd();
 
+   int getNewTopologyId();
+
    //todo [anistor] add topologyId, prevReadCH, prevWriteCH, newReadCH2, newWriteCH
 }",2012-09-21T12:26:43Z,136
"@@ -95,7 +95,7 @@ public class StateConsumerImpl implements StateConsumer {
    private AtomicInteger activeTopologyUpdates = new AtomicInteger(0);
 
    /**
-    * Indicates if currently executing topology update is a rabalance.
+    * Indicates if the currently executing topology update is a rebalance.
     */
    private AtomicBoolean rebalanceInProgress = new AtomicBoolean(false);
 
@@ -197,8 +197,10 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             removedSegments.removeAll(newSegments);
 
             // remove inbound transfers and any data for segments we no longer own
-            log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                  removedSegments, newSegments, previousSegments);
+            if (trace) {
+               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
+                     removedSegments, newSegments, previousSegments);
+            }
             discardSegments(removedSegments);
 
             if (fetchEnabled) {",2012-09-21T12:26:43Z,54
"@@ -80,7 +80,7 @@ public class StateProviderImpl implements StateProvider {
    private volatile ConsistentHash readCh;
 
    /**
-    * A map that keeps track of current outbound state transfers by source address. There could be multiple transfers
+    * A map that keeps track of current outbound state transfers by destination address. There could be multiple transfers
     * flowing to the same destination (but for different segments) so the values are lists.
     */
    private final Map<Address, List<OutboundTransferTask>> transfersByDestination = new HashMap<Address, List<OutboundTransferTask>>();
@@ -124,6 +124,7 @@ public boolean isStateTransferInProgress() {
    }
 
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // do all the work AFTER the consistent hash has changed
       if (tce.isPre())
@@ -236,12 +237,14 @@ private void collectTransactionsToTransfer(List<TransactionInfo> transactionsToT
                lockedKeys.add(key);
             }
          }
-         List<WriteCommand> txModifications = tx.getModifications();
-         WriteCommand[] modifications = null;
-         if (txModifications != null) {
-            modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+         if (!lockedKeys.isEmpty()) {
+            List<WriteCommand> txModifications = tx.getModifications();
+            WriteCommand[] modifications = null;
+            if (txModifications != null) {
+               modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+            }
+            transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), tx.getViewId(), modifications, lockedKeys));
          }
-         transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), modifications, lockedKeys));
       }
    }
 ",2012-09-21T12:26:43Z,55
"@@ -48,10 +48,9 @@
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 
+//todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
 /**
  * // TODO: Document this
  *
@@ -317,8 +316,8 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       } finally {
          stateTransferLock.commandsSharedUnlock();
 
-         log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
          if (newTargets != null && !newTargets.isEmpty()) {
+            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
             rpcManager.invokeRemotely(newTargets, command, true);
          }
       }",2012-09-21T12:26:43Z,115
"@@ -178,19 +178,20 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
       // TODO Improve notification to contain both CHs
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, true);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), true);
 
       stateConsumer.onTopologyUpdate(newCacheTopology, isRebalance);
       stateProvider.onTopologyUpdate(newCacheTopology, isRebalance);
 
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, false);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
       if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
          initialStateTransferComplete.countDown();
       }
    }
 
    @Start(priority = 1000)
+   @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
       if (trace) log.tracef(""Waiting for initial state transfer to finish"");
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);",2012-09-21T12:26:43Z,117
"@@ -50,8 +50,11 @@ public class TransactionInfo {
 
    private final Set<Object> lockedKeys;
 
-   public TransactionInfo(GlobalTransaction globalTransaction, WriteCommand[] modifications, Set<Object> lockedKeys) {
+   private final int topologyId;
+
+   public TransactionInfo(GlobalTransaction globalTransaction, int topologyId, WriteCommand[] modifications, Set<Object> lockedKeys) {
       this.globalTransaction = globalTransaction;
+      this.topologyId = topologyId;
       this.modifications = modifications;
       this.lockedKeys = lockedKeys;
    }
@@ -68,10 +71,15 @@ public Set<Object> getLockedKeys() {
       return lockedKeys;
    }
 
+   public int getTopologyId() {
+      return topologyId;
+   }
+
    @Override
    public String toString() {
       return ""TransactionInfo{"" +
             ""globalTransaction="" + globalTransaction +
+            "", topologyId="" + topologyId +
             "", modifications="" + Arrays.asList(modifications) +
             "", lockedKeys="" + lockedKeys +
             '}';
@@ -92,6 +100,7 @@ public Set<Class<? extends TransactionInfo>> getTypeClasses() {
       @Override
       public void writeObject(ObjectOutput output, TransactionInfo object) throws IOException {
          output.writeObject(object.globalTransaction);
+         output.writeInt(object.topologyId);
          output.writeObject(object.modifications);
          output.writeObject(object.lockedKeys);
       }
@@ -100,9 +109,10 @@ public void writeObject(ObjectOutput output, TransactionInfo object) throws IOEx
       @SuppressWarnings(""unchecked"")
       public TransactionInfo readObject(ObjectInput input) throws IOException, ClassNotFoundException {
          GlobalTransaction globalTransaction = (GlobalTransaction) input.readObject();
+         int topologyId = input.readInt();
          WriteCommand[] modifications = (WriteCommand[]) input.readObject();
          Set<Object> lockedKeys = (Set<Object>) input.readObject();
-         return new TransactionInfo(globalTransaction, modifications, lockedKeys);
+         return new TransactionInfo(globalTransaction, topologyId, modifications, lockedKeys);
       }
    }
 }",2012-09-21T12:26:43Z,137
"@@ -31,8 +31,6 @@
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
 import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.MembershipArithmetic;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
@@ -67,37 +65,41 @@ public class StaleTransactionCleanupService {
    private TransactionTable transactionTable;
    private InterceptorChain invoker;
    private String cacheName;
+   private boolean isDistributed;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
    private ExecutorService lockBreakingService; // a thread pool with max. 1 thread
 
-   /**
-    * Roll back remote transactions originating on nodes that have left the cluster.
-    */
-   @ViewChanged
-   public void onViewChange(ViewChangedEvent vce) {
-      final List<Address> leavers = MembershipArithmetic.getMembersLeft(vce.getOldMembers(),
-                                                                        vce.getNewMembers());
-      if (!leavers.isEmpty()) {
-         log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-         cleanTxForWhichTheOwnerLeft(leavers);
-      }
-   }
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * either because the main data owner left the cluster or because a node joined
     * the cluster and is the new data owner.
     * This method will only ever be called in distributed mode.
     */
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
-      // do all the work AFTER the consistent hash has changed
-      if (tce.isPre())
+      // Roll back remote transactions originating on nodes that have left the cluster.
+      if (tce.isPre()) {
+         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+         if (consistentHashAtStart != null) {
+            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+            if (!leavers.isEmpty()) {
+               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+               cleanTxForWhichTheOwnerLeft(leavers);
+            }
+         }
+         return;
+      }
+
+      if (!isDistributed) {
          return;
+      }
+
+      // do all the work AFTER the consistent hash has changed
 
       Address self = transactionTable.rpcManager.getAddress();
       ConsistentHash chOld = tce.getConsistentHashAtStart();
@@ -173,7 +175,7 @@ public void run() {
       }
    }
 
-   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain) {
+   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain, boolean isDistributed) {
       this.invoker = interceptorChain;
       ThreadFactory tf = new ThreadFactory() {
          @Override
@@ -185,8 +187,9 @@ public Thread newThread(Runnable r) {
          }
       };
       this.cacheName = cacheName;
+      this.isDistributed = isDistributed;
       lockBreakingService = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingDeque<Runnable>(), tf,
-                                                   new ThreadPoolExecutor.CallerRunsPolicy());
+                                                   new ThreadPoolExecutor.DiscardOldestPolicy());
    }
 
    public void stop() {",2012-09-21T12:26:43Z,126
"@@ -38,11 +38,10 @@
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.interceptors.InterceptorChain;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
-import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
+import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.synchronization.SyncLocalTransaction;
@@ -57,9 +56,7 @@
 
 import javax.transaction.Transaction;
 import javax.transaction.TransactionSynchronizationRegistry;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.locks.Lock;
@@ -76,7 +73,7 @@
  * @author Galder Zamarreño
  * @since 4.0
  */
-@Listener(sync = false)
+@Listener
 public class TransactionTable {
 
    public static final int CACHE_STOPPED_VIEW_ID = -1;
@@ -95,25 +92,23 @@ public class TransactionTable {
    protected CommandsFactory commandsFactory;
    private InterceptorChain invoker;
    private CacheNotifier notifier;
-   private EmbeddedCacheManager cm;
    private TransactionSynchronizationRegistry transactionSynchronizationRegistry;
    protected ClusteringDependentLogic clusteringLogic;
    protected boolean clustered = false;
    private Lock minViewRecalculationLock;
 
    /**
-    * minTxViewId is the minimum view ID across all ongoing local and remote transactions. It doesn't update on
-    * transaction creation, but only on removal. That's because it is not possible for a newly created transaction to
-    * have an bigger view ID than the current one.
+    * minTxViewId is the minimum view ID across all ongoing local and remote transactions.
     */
    private volatile int minTxViewId = CACHE_STOPPED_VIEW_ID;
    private volatile int currentViewId = CACHE_STOPPED_VIEW_ID;
+   private volatile boolean useStrictTopologyIdComparison = true;
    private String cacheName;
 
    @Inject
    public void initialize(RpcManager rpcManager, Configuration configuration,
                           InvocationContextContainer icc, InterceptorChain invoker, CacheNotifier notifier,
-                          TransactionFactory gtf, EmbeddedCacheManager cm, TransactionCoordinator txCoordinator,
+                          TransactionFactory gtf, TransactionCoordinator txCoordinator,
                           TransactionSynchronizationRegistry transactionSynchronizationRegistry,
                           CommandsFactory commandsFactory, ClusteringDependentLogic clusteringDependentLogic, Cache cache) {
       this.rpcManager = rpcManager;
@@ -122,7 +117,6 @@ public void initialize(RpcManager rpcManager, Configuration configuration,
       this.invoker = invoker;
       this.notifier = notifier;
       this.txFactory = gtf;
-      this.cm = cm;
       this.txCoordinator = txCoordinator;
       this.transactionSynchronizationRegistry = transactionSynchronizationRegistry;
       this.commandsFactory = commandsFactory;
@@ -139,24 +133,20 @@ private void start() {
          minViewRecalculationLock = new ReentrantLock();
          // Only initialize this if we are clustered.
          remoteTransactions = ConcurrentMapFactory.makeConcurrentMap(concurrencyLevel, 0.75f, concurrencyLevel);
-         cleanupService.start(cacheName, rpcManager, invoker);
-         cm.addListener(cleanupService);
-         cm.addListener(this);
+         cleanupService.start(cacheName, rpcManager, invoker, configuration.clustering().cacheMode().isDistributed());
          notifier.addListener(cleanupService);
-         minTxViewId = rpcManager.getTransport().getViewId();
-         currentViewId = minTxViewId;
-         log.debugf(""Min view id set to %s"", minTxViewId);
+         notifier.addListener(this);
          clustered = true;
       }
    }
 
    @Stop
+   @SuppressWarnings(""unused"")
    private void stop() {
       if (clustered) {
          notifier.removeListener(cleanupService);
-         cm.removeListener(cleanupService);
          cleanupService.stop();
-         cm.removeListener(this);
+         notifier.removeListener(this);
          currentViewId = CACHE_STOPPED_VIEW_ID; // indicate that the cache has stopped
       }
       shutDownGracefully();
@@ -223,6 +213,17 @@ public int getMinViewId() {
       return minTxViewId;
    }
 
+   /**
+    * Indicates if topology id comparisons should be strict if one wants to compare topology ids in oder to tell
+    * if a transaction was started in an older topology than a second transaction. This flag is true most of the time
+    * except when the current topology did not increase its id (it's not caused by a rebalance).
+    *
+    * @return true if strict topology id comparisons should be used, false otherwise
+    */
+   public boolean useStrictTopologyIdComparison() {
+      return useStrictTopologyIdComparison;
+   }
+
    protected void updateStateOnNodesLeaving(Collection<Address> leavers) {
       Set<GlobalTransaction> toKill = new HashSet<GlobalTransaction>();
       for (GlobalTransaction gt : remoteTransactions.keySet()) {
@@ -263,14 +264,24 @@ public void remoteTransactionRollback(GlobalTransaction gtx) {
    }
 
    /**
-    * Creates and register a {@link RemoteTransaction} with no modifications. Returns the created transaction.
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
     *
     * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
     *                               made.
     */
    public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications) {
-      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, currentViewId)
-            : txFactory.newRemoteTransaction(modifications, globalTx, currentViewId);
+      return createRemoteTransaction(globalTx, modifications, currentViewId);
+   }
+
+   /**
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
+    *
+    * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
+    *                               made.
+    */
+   public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications, int topologyId) {
+      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, topologyId)
+            : txFactory.newRemoteTransaction(modifications, globalTx, topologyId);
       registerRemoteTransaction(globalTx, remoteTransaction);
       return remoteTransaction;
    }
@@ -283,6 +294,10 @@ private void registerRemoteTransaction(GlobalTransaction gtx, RemoteTransaction
       }
 
       log.tracef(""Created and registered remote transaction %s"", rtx);
+      if (rtx.getViewId() < minTxViewId) {
+         log.tracef(""Changing minimum view ID from %d to %d"", minTxViewId, rtx.getViewId());
+         minTxViewId = rtx.getViewId();
+      }
    }
 
    /**
@@ -293,6 +308,9 @@ public LocalTransaction getOrCreateLocalTransaction(Transaction transaction, TxI
       LocalTransaction current = localTransactions.get(transaction);
       if (current == null) {
          Address localAddress = rpcManager != null ? rpcManager.getTransport().getAddress() : null;
+         if (rpcManager != null && currentViewId < 0) {
+            throw new IllegalStateException(""Cannot create transactions if topology id is not known yet!"");
+         }
          GlobalTransaction tx = txFactory.newGlobalTransaction(localAddress, false);
          current = txFactory.newLocalTransaction(transaction, tx, ctx.isImplicitTransaction(), currentViewId);
          log.tracef(""Created a new local transaction: %s"", current);
@@ -310,10 +328,6 @@ public boolean removeLocalTransaction(LocalTransaction localTransaction) {
       return localTransaction != null && (removeLocalTransactionInternal(localTransaction.getTransaction()) != null);
    }
 
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      return removeLocalTransactionInternal(tx);
-   }
-
    protected final LocalTransaction removeLocalTransactionInternal(Transaction tx) {
       LocalTransaction removed;
       removed = localTransactions.remove(tx);
@@ -357,8 +371,8 @@ public int getLocalTxCount() {
 
    /**
     * Looks up a LocalTransaction given a GlobalTransaction.
-    * @param txId
-    * @return
+    * @param txId the global transaction identifier
+    * @return the LocalTransaction or null if not found
     */
    public LocalTransaction getLocalTransaction(GlobalTransaction txId) {
       for (LocalTransaction localTx : localTransactions.values()) { //todo [anistor] optimize lookup!
@@ -402,17 +416,21 @@ protected final void recalculateMinViewIdIfNeeded(CacheTransaction removedTransa
       }
    }
 
-   @ViewChanged
-   public void recalculateMinViewIdOnTopologyChange(ViewChangedEvent vce) {
-      // don't do anything if this cache is not clustered - view changes are global
+   @TopologyChanged
+   @SuppressWarnings(""unused"")
+   public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
+      // don't do anything if this cache is not clustered
       if (clustered) {
-         log.debugf(""View changed, recalculating minViewId"");
-         currentViewId = vce.getViewId();
-         calculateMinViewId(-1);
+         if (tce.isPre()) {
+            useStrictTopologyIdComparison = tce.getNewTopologyId() != currentViewId;
+            currentViewId = tce.getNewTopologyId();
+         } else {
+            log.debugf(""Topology changed, recalculating minViewId"");
+            calculateMinViewId(-1);
+         }
       }
    }
 
-
    /**
     * This method calculates the minimum view ID known by the current node.  This method is only used in a clustered
     * cache, and only invoked when either a view change is detected, or a transaction whose view ID is not the same as
@@ -442,7 +460,7 @@ private void calculateMinViewId(int idOfRemovedTransaction) {
                int viewId = ct.getViewId();
                if (viewId < minViewIdFound) minViewIdFound = viewId;
             }
-            if (minViewIdFound > minTxViewId) {
+            if (minViewIdFound != minTxViewId) {
                log.tracef(""Changing minimum view ID from %s to %s"", minTxViewId, minViewIdFound);
                minTxViewId = minViewIdFound;
             } else {",2012-09-21T12:26:43Z,127
"@@ -80,13 +80,6 @@ private void removeXidTxMapping(LocalXaTransaction localTx) {
       xid2LocalTx.remove(xid);
    }
 
-   @Override
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      final LocalTransaction remove = removeLocalTransactionInternal(tx);
-      if (remove != null) removeXidTxMapping((LocalXaTransaction) remove);
-      return remove;
-   }
-
    public LocalXaTransaction getLocalTransaction(Xid xid) {
       return this.xid2LocalTx.get(xid);
    }",2012-09-21T12:26:43Z,138
"@@ -22,10 +22,8 @@
  */
 package org.infinispan.util.concurrent.locks;
 
-import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.jmx.annotations.MBean;",2012-09-21T12:26:43Z,139
"@@ -93,15 +93,16 @@ public boolean isSatisfied() throws Exception {
          public void run() {
             try {
                log.trace(""This thread runs a different tx"");
-               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).resume(suspend);
+               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).commit();
             } catch (Exception e) {
                e.printStackTrace();
             }
          }
       }, false);
 
+      // this 'ensures' transaction called 'suspend' has the chance to start the prepare phase and is waiting to acquire the locks on k held by first transaction before it gets resumed
       Thread.sleep(1000);
 
       log.trace(""Before completing the transaction!"");",2012-09-21T12:26:43Z,140
"@@ -21,7 +21,7 @@
 /**
  * @since 5.1
  */
-@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"", enabled = false) //todo [anistor] temporarily disabled for NBST
+@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"")
 @CleanupAfterMethod
 public class MainOwnerChangesLockTest extends MultipleCacheManagersTest {
 ",2012-09-21T12:26:43Z,141
"@@ -24,6 +24,7 @@
 package org.infinispan.lock.singlelock;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.CleanupAfterMethod;
@@ -33,8 +34,7 @@
 import org.infinispan.transaction.tm.DummyTransaction;
 import org.testng.annotations.Test;
 
-import javax.transaction.Status;
-
+import static org.testng.Assert.assertTrue;
 import static org.testng.Assert.assertEquals;
 
 
@@ -60,21 +60,22 @@ protected void createCacheManagers() throws Throwable {
       waitForClusterToForm();
    }
 
-   @Test(enabled = false, description = ""See ISPN-2113"")
    public void testMinViewId1() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
+
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);
 
       //add a new cache and check that min view is updated
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId2);
       assertEquals(tt1.getMinViewId(), viewId2);
@@ -88,8 +89,8 @@ public void testMinViewId2() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
 
       tm(1).begin();
       cache(1).put(getKeyForCache(0),""v"");
@@ -109,8 +110,8 @@ public boolean isSatisfied() throws Exception {
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);",2012-09-21T12:26:43Z,142
"@@ -36,7 +36,6 @@
 import javax.transaction.InvalidTransactionException;
 import javax.transaction.NotSupportedException;
 import javax.transaction.RollbackException;
-import javax.transaction.Status;
 import javax.transaction.SystemException;
 
 import static org.testng.Assert.assertEquals;
@@ -45,7 +44,7 @@
  * @author Mircea Markus
  * @since 5.1
  */
-@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"", enabled = false, description = ""See ISPN-2113"")
+@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"")
 @CleanupAfterMethod
 public class LockOwnerCrashPessimisticTest extends AbstractLockOwnerCrashTest {
 ",2012-09-21T12:26:43Z,143
"@@ -106,17 +106,14 @@ public void doPerformStateTransfer() throws Exception {
       //distributionManager.getTransactionLogger().enable();
       stateTransferLock.blockNewTransactions(newViewId);
 
-      if (trace) {
-         log.tracef(""Rebalancing: chOld = %s, chNew = %s"", chOld, chNew);
-      }
+      if (trace) log.tracef(""Rebalancing: chOld = %s, chNew = %s"", chOld, chNew);
+      int numOwners = configuration.clustering().hash().numOwners();
 
       if (configuration.clustering().stateTransfer().fetchInMemoryState() && !initialView) {
 
          // notify listeners that a rehash is about to start
          cacheNotifier.notifyDataRehashed(oldCacheSet, newCacheSet, newViewId, true);
 
-         int numOwners = configuration.clustering().hash().numOwners();
-
          // Contains the state to be pushed to various servers. The state is a hashmap of servers to entry collections
          final Map<Address, Collection<InternalCacheEntry>> states = new HashMap<Address, Collection<InternalCacheEntry>>();
 
@@ -156,8 +153,30 @@ public void doPerformStateTransfer() throws Exception {
          
          // And wait for all the push RPCs to end
          finishPushingState();
+      } else if (initialView) {
+         // Only remove data from the cache store if the cache store is not shared
+         CacheStore cacheStore = stateTransferManager.getCacheStoreForStateTransfer();
+         if (cacheStore != null) {
+            if (trace) log.trace(""Non-shared cache store, cleaning up persisted entries that we don't own after we joined the cache"");
+            for (Object key : cacheStore.loadAllKeys(new ReadOnlyDataContainerBackedKeySet(dataContainer))) {
+               if (!chNew.isKeyLocalToAddress(self, key, numOwners)) {
+                  keysToRemove.add(key);
+               }
+            }
+         }
+
+         checkIfCancelled();
+
+         if (trace) log.trace(""Cleaning up preloaded entries (if preloading) that we don't own after we joined the cache"");
+         for (InternalCacheEntry ice : dataContainer) {
+            if (!chNew.isKeyLocalToAddress(self, ice.getKey(), numOwners)) {
+               keysToRemove.add(ice.getKey());
+            }
+         }
+         if (trace) log.tracef(""Keys to remove after join is complete: %s"", keysToRemove.size());
+
       } else {
-         if (!initialView) log.trace(""Rehash not enabled, so not pushing state"");
+         if (trace) log.trace(""Rehash not enabled, so not pushing state"");
       }
    }
 
@@ -188,11 +207,13 @@ public void commitStateTransfer() {
       // update the distribution manager's consistent hash
       dm.setConsistentHash(chNew);
 
-      if (configuration.clustering().stateTransfer().fetchInMemoryState() && !initialView) {
+      if (configuration.clustering().stateTransfer().fetchInMemoryState()) {
          // now we can invalidate the keys
          stateTransferManager.invalidateKeys(keysToRemove);
 
-         cacheNotifier.notifyDataRehashed(oldCacheSet, newCacheSet, newViewId, false);
+         if (!initialView) {
+            cacheNotifier.notifyDataRehashed(oldCacheSet, newCacheSet, newViewId, false);
+         }
       }
 
       super.commitStateTransfer();",2012-05-29T15:53:25Z,229
"@@ -0,0 +1,156 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.distribution.rehash;
+
+import java.util.HashMap;
+import java.util.Map;
+
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.Configuration;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.cache.FileCacheStoreConfigurationBuilder;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.testng.annotations.AfterClass;
+import org.testng.annotations.Test;
+
+/**
+ * Test with a distributed cache (numOwners=1), a shared cache store and 'preload' enabled
+ * (ISPN-1964).
+ *
+ * @author Carsten Lohmann
+ */
+@Test(testName = ""distribution.rehash.RehashAfterJoinWithPreloadTest"", groups = ""functional"")
+public class RehashAfterJoinWithPreloadTest extends MultipleCacheManagersTest {
+
+   private static final Log log = LogFactory.getLog(RehashAfterJoinWithPreloadTest.class);
+
+   private final String testCacheName = ""testCache"" + getClass().getSimpleName();
+
+   private final String fileCacheStoreTmpDir = TestingUtil.tmpDirectory(this);
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      // cacheManagers started one after another in test()
+   }
+
+   private void addNewCacheManagerAndWaitForRehash() {
+      EmbeddedCacheManager cacheManager = addClusterEnabledCacheManager(getDefaultClusteredCacheConfig(
+            CacheMode.DIST_SYNC, false));
+      cacheManager.defineConfiguration(testCacheName, buildCfg(true));
+      log.debug(""\n\nstarted CacheManager #"" + (getCacheManagers().size() - 1));
+      waitForClusterToForm(testCacheName);
+   }
+
+   private Configuration buildCfg(boolean clustered) {
+      ConfigurationBuilder cb = new ConfigurationBuilder();
+
+      FileCacheStoreConfigurationBuilder fileStoreCB = cb.loaders().addFileCacheStore().location(fileCacheStoreTmpDir);
+      fileStoreCB.purgeOnStartup(false);
+
+      cb.loaders().passivation(false);
+      cb.loaders().preload(true);
+      cb.loaders().shared(true);
+
+      if (clustered) {
+         cb.clustering().l1().disable();
+         cb.clustering().cacheMode(CacheMode.DIST_SYNC);
+         cb.clustering().hash().numOwners(1); // one owner!
+
+         cb.clustering().hash().numVirtualNodes(1);
+         cb.clustering().stateTransfer().fetchInMemoryState(true);
+         cb.clustering().hash().groups().enabled();
+      }
+      return cb.build(true);
+   }
+
+   public void test() {
+      // first initialize the file based cache store with 3 entries in a cache
+      putTestDataInCacheStore();
+
+      // start a cluster that uses this cache store
+      // add 1st member
+      addNewCacheManagerAndWaitForRehash();
+      printCacheContents();
+//      assertEvenDistribution();
+
+      // add 2nd member
+      addNewCacheManagerAndWaitForRehash();
+      printCacheContents();
+//      assertEvenDistribution();
+
+      // add 3rd member
+      addNewCacheManagerAndWaitForRehash();
+      printCacheContents();
+      assertEvenDistribution();
+   }
+
+   private void assertEvenDistribution() {
+      for (int i = 0; i < getCacheManagers().size(); i++) {
+         Cache<String, String> testCache = manager(i).getCache(testCacheName);
+         for (String key : testCache.keySet()) {
+            // each key must only occur once (numOwners is one)
+            assert testCache.getAdvancedCache().getDistributionManager().getLocality(key).isLocal()
+                  : ""Key '"" + key + ""' is not owned by node "" + address(i) + "" but it still appears there"";
+         }
+      }
+   }
+
+   private void putTestDataInCacheStore() {
+      log.debug(""Using cache store dir "" + fileCacheStoreTmpDir);
+      EmbeddedCacheManager cmForCacheStoreInit = TestCacheManagerFactory.createCacheManager(TestCacheManagerFactory
+            .getDefaultConfiguration(true));
+      try {
+         cmForCacheStoreInit.defineConfiguration(testCacheName, buildCfg(false));
+
+         Cache<String, String> cache = cmForCacheStoreInit.getCache(testCacheName);
+         cache.put(""key1"", ""one"");
+         cache.put(""key2"", ""two"");
+         cache.put(""key3"", ""three"");
+
+         log.debug(""added 3 entries to test cache"");
+      } finally {
+         TestingUtil.killCacheManagers(cmForCacheStoreInit);
+      }
+   }
+
+   private void printCacheContents() {
+      log.debug(""----------------------------------------------------"");
+      for (int i = 0; i < getCacheManagers().size(); i++) {
+         log.debug("" Content of Cache with CacheManager #"" + i + "" ("" + address(i) + "", all members: ""
+               + manager(i).getMembers() + "")"");
+         Cache<String, String> testCache = manager(i).getCache(testCacheName);
+         for (String key : testCache.keySet()) {
+            log.debug(""  key: "" + key + ""  value: "" + testCache.get(key));
+         }
+      }
+   }
+
+   @AfterClass(alwaysRun = true)
+   protected void clearTempDir() {
+      TestingUtil.recursiveFileRemove(fileCacheStoreTmpDir);
+   }
+}
\ No newline at end of file",2012-05-29T15:53:25Z,4
"@@ -66,7 +66,9 @@ public class InboundTransferTask {
 
    private final long timeout;
 
-   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout) {
+   private final String cacheName;
+
+   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""segments must not be null or empty"");
       }
@@ -81,6 +83,7 @@ public InboundTransferTask(Set<Integer> segments, Address source, int topologyId
       this.rpcManager = rpcManager;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public Set<Integer> getSegments() {
@@ -93,7 +96,7 @@ public Address getSource() {
 
    public boolean requestTransactions() {
       if (trace) {
-         log.tracef(""Requesting transactions for segments %s"", segments);
+         log.tracef(""Requesting transactions for segments %s of cache %s from node %s"", segments, cacheName, source);
       }
       // get transactions and locks
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.GET_TRANSACTIONS, rpcManager.getAddress(), topologyId, segments);
@@ -109,6 +112,10 @@ public boolean requestTransactions() {
    }
 
    public boolean requestSegments() {
+      if (trace) {
+         log.tracef(""Requesting segments %s of cache %s from node %s"", segments, cacheName, source);
+      }
+
       // start transfer of cache entries
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.START_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
       Map<Address, Response> responses = rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
@@ -139,24 +146,21 @@ public void cancel() {
       if (!isCancelled) {
          isCancelled = true;
 
-         Set<Integer> cancelledSegments = new HashSet<Integer>(segments);
-         segments.clear();
-         finishedSegments.clear();
-
-         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, cancelledSegments);
+         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
          rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
 
          stateConsumer.onTaskCompletion(this);
       }
    }
 
    public void onStateReceived(int segmentId, boolean isLastChunk) {
-      if (!isCancelled && segments.contains(segmentId)) {
-         if (isLastChunk) {
-            finishedSegments.add(segmentId);
-            if (finishedSegments.containsAll(segments)) {
-               stateConsumer.onTaskCompletion(this);
+      if (!isCancelled && isLastChunk && segments.contains(segmentId)) {
+         finishedSegments.add(segmentId);
+         if (finishedSegments.containsAll(segments)) {
+            if (trace) {
+               log.tracef(""Finished receiving state for segments %s of cache %s"", segments, cacheName);
             }
+            stateConsumer.onTaskCompletion(this);
          }
       }
    }
@@ -166,11 +170,14 @@ public String toString() {
       HashSet<Integer> unfinishedSegments = new HashSet<Integer>(segments);
       unfinishedSegments.removeAll(finishedSegments);
       return ""InboundTransferTask{"" +
-            ""unfinishedSegments="" + unfinishedSegments +
+            ""segments="" + segments +
+            "", finishedSegments="" + finishedSegments +
+            "", unfinishedSegments="" + unfinishedSegments +
             "", source="" + source +
             "", isCancelled="" + isCancelled +
             "", topologyId="" + topologyId +
             "", timeout="" + timeout +
+            "", cacheName="" + cacheName +
             '}';
    }
 }",2012-11-07T14:07:34Z,120
"@@ -24,20 +24,19 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.commands.CommandsFactory;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheLoaderManager;
 import org.infinispan.loaders.CacheStore;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.SuspectException;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
-import org.infinispan.util.concurrent.AggregatingNotifyingFutureBuilder;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -70,8 +69,6 @@ public class OutboundTransferTask implements Runnable {
 
    private final int stateTransferChunkSize;
 
-   private final Configuration configuration;
-
    private final ConsistentHash readCh;
 
    private final DataContainer dataContainer;
@@ -84,27 +81,24 @@ public class OutboundTransferTask implements Runnable {
 
    private final long timeout;
 
+   private final String cacheName;
+
    private final Map<Integer, List<InternalCacheEntry>> entriesBySegment = ConcurrentMapFactory.makeConcurrentMap();
 
    /**
     * The total number of entries from all segments accumulated in entriesBySegment.
     */
    private int accumulatedEntries;
 
-   /**
-    * This is used with RpcManager.invokeRemotelyInFuture() to be able to cancel message sending if the task needs to be canceled.
-    */
-   private final NotifyingNotifiableFuture<Object> sendFuture = new AggregatingNotifyingFutureBuilder(null);
-
    /**
     * The Future obtained from submitting this task to an executor service. This is used for cancellation.
     */
    private FutureTask runnableFuture;
 
    public OutboundTransferTask(Address destination, Set<Integer> segments, int stateTransferChunkSize,
                                int topologyId, ConsistentHash readCh, StateProviderImpl stateProvider, DataContainer dataContainer,
-                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager, Configuration configuration,
-                               CommandsFactory commandsFactory, long timeout) {
+                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager,
+                               CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""Segments must not be null or empty"");
       }
@@ -123,9 +117,9 @@ public OutboundTransferTask(Address destination, Set<Integer> segments, int stat
       this.dataContainer = dataContainer;
       this.cacheLoaderManager = cacheLoaderManager;
       this.rpcManager = rpcManager;
-      this.configuration = configuration;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public void execute(ExecutorService executorService) {
@@ -154,7 +148,7 @@ public void run() {
       try {
          // send data container entries
          for (InternalCacheEntry ice : dataContainer) {
-            Object key = ice.getKey();
+            Object key = ice.getKey();  //todo [anistor] should we check for expired entries?
             int segmentId = readCh.getSegment(key);
             if (segments.contains(segmentId)) {
                sendEntry(ice, segmentId);
@@ -198,7 +192,7 @@ public void run() {
          }
       }
       if (trace) {
-         log.tracef(""Outbound transfer of segments %s to %s is complete"", segments, destination);
+         log.tracef(""Outbound transfer of segments %s of cache %s to node %s is complete"", segments, cacheName, destination);
       }
    }
 
@@ -217,7 +211,6 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
       // send if we have a full chunk
       if (accumulatedEntries >= stateTransferChunkSize) {
          sendEntries(false);
-         entriesBySegment.clear();
          accumulatedEntries = 0;
       }
 
@@ -232,32 +225,42 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
 
    private void sendEntries(boolean isLast) {
       List<StateChunk> chunks = new ArrayList<StateChunk>();
+      for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
+         List<InternalCacheEntry> entries = e.getValue();
+         if (!entries.isEmpty()) {
+            chunks.add(new StateChunk(e.getKey(), new ArrayList<InternalCacheEntry>(entries), isLast));
+            entries.clear();
+         }
+      }
+
       if (isLast) {
          for (int segmentId : segments) {
             List<InternalCacheEntry> entries = entriesBySegment.get(segmentId);
             if (entries == null) {
-               entries = InfinispanCollections.emptyList();
-            }
-            chunks.add(new StateChunk(segmentId, entries, isLast));
-         }
-      } else {
-         for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
-            List<InternalCacheEntry> entries = e.getValue();
-            if (!entries.isEmpty()) {
-               chunks.add(new StateChunk(e.getKey(), entries, isLast));
+               chunks.add(new StateChunk(segmentId, InfinispanCollections.<InternalCacheEntry>emptyList(), true));
             }
          }
       }
 
-      if (!chunks.isEmpty() || isLast) {
+      if (!chunks.isEmpty()) {
          if (trace) {
-            log.tracef(""Sending %d cache entries from segments %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), destination);
+            if (isLast) {
+               log.tracef(""Sending last chunk containing %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, segments, cacheName, destination);
+            } else {
+               log.tracef(""Sending %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), cacheName, destination);
+            }
          }
 
-         //todo [anistor] send back the received topologyId or my local one?
          StateResponseCommand cmd = commandsFactory.buildStateResponseCommand(rpcManager.getAddress(), topologyId, chunks);
-         // send synchronously, in FIFO mode. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
-         rpcManager.invokeRemotelyInFuture(Collections.singleton(destination), cmd, false, sendFuture, timeout);
+         // send synchronously, in order. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
+         try {
+            rpcManager.invokeRemotely(Collections.singleton(destination), cmd, ResponseMode.SYNCHRONOUS, timeout, false, null);
+         } catch (SuspectException e) {
+            log.errorf(e, ""Node %s left cache %s: %s"", destination, cacheName, e.getMessage());
+            cancel();
+         } catch (Exception e) {
+            log.errorf(e, ""Failed to send entries to node %s : %s"", destination, e.getMessage());
+         }
       }
    }
 
@@ -268,7 +271,7 @@ private void sendEntries(boolean isLast) {
     */
    public void cancelSegments(Set<Integer> cancelledSegments) {
       if (trace) {
-         log.tracef(""Cancelling outbound transfer of segments %s to %s"", cancelledSegments, destination);
+         log.tracef(""Cancelling outbound transfer of segments %s of cache %s to node %s"", cancelledSegments, cacheName, destination);
       }
       if (segments.removeAll(cancelledSegments)) {
          entriesBySegment.keySet().removeAll(cancelledSegments);  // here we do not update accumulatedEntries but this inaccuracy does not cause any harm
@@ -284,11 +287,22 @@ public void cancelSegments(Set<Integer> cancelledSegments) {
    public void cancel() {
       if (runnableFuture != null && !runnableFuture.isCancelled()) {
          runnableFuture.cancel(true);
-         sendFuture.cancel(true);
       }
    }
 
    public boolean isCancelled() {
       return runnableFuture != null && runnableFuture.isCancelled();
    }
+
+   @Override
+   public String toString() {
+      return ""OutboundTransferTask{"" +
+            ""topologyId="" + topologyId +
+            "", destination="" + destination +
+            "", segments="" + segments +
+            "", stateTransferChunkSize="" + stateTransferChunkSize +
+            "", timeout="" + timeout +
+            "", cacheName='"" + cacheName + '\'' +
+            '}';
+   }
 }",2012-11-07T14:07:34Z,121
"@@ -45,7 +45,6 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -62,7 +61,7 @@
 import static org.infinispan.context.Flag.*;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateConsumer} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -72,7 +71,7 @@ public class StateConsumerImpl implements StateConsumer {
    private static final Log log = LogFactory.getLog(StateConsumerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
-   private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
    private Configuration configuration;
    private RpcManager rpcManager;
@@ -119,7 +118,7 @@ public StateConsumerImpl() {
 
    @Inject
    public void init(Cache cache,
-                    LocalTopologyManager localTopologyManager,
+                    StateTransferManager stateTransferManager,
                     InterceptorChain interceptorChain,
                     InvocationContextContainer icc,
                     Configuration configuration,
@@ -130,7 +129,7 @@ public void init(Cache cache,
                     TransactionTable transactionTable,
                     StateTransferLock stateTransferLock) {
       this.cacheName = cache.getName();
-      this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
       this.interceptorChain = interceptorChain;
       this.icc = icc;
       this.configuration = configuration;
@@ -171,26 +170,30 @@ public boolean isStateTransferInProgressForKey(Object key) {
 
    @Override
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
-      if (trace) log.tracef(""Received new CH: %s"", cacheTopology.getWriteConsistentHash());
+      if (trace) log.tracef(""Received new CH %s for cache %s"", cacheTopology.getWriteConsistentHash(), cacheName);
 
       activeTopologyUpdates.incrementAndGet();
       if (isRebalance) {
          rebalanceInProgress.set(true);
       }
-      ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
+      final ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
       // Ensures writes to the data container use the right consistent hash
       // No need for a try/finally block, since it's just an assignment
       stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
       stateTransferLock.releaseExclusiveTopologyLock();
-      stateTransferLock.topologyInstalled(cacheTopology.getTopologyId());
+      stateTransferLock.notifyTopologyInstalled(cacheTopology.getTopologyId());
 
       try {
          Set<Integer> addedSegments;
          if (previousCh == null) {
             // we start fresh, without any data, so we need to pull everything we own according to writeCh
 
             addedSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
+
+            if (trace) {
+               log.tracef(""On cache %s we have: added segments: %s"", cacheName, addedSegments);
+            }
          } else {
             Set<Integer> previousSegments = getOwnedSegments(previousCh);
             Set<Integer> newSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
@@ -199,16 +202,16 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             Set<Integer> removedSegments = new HashSet<Integer>(previousSegments);
             removedSegments.removeAll(newSegments);
 
-            // remove inbound transfers and any data for segments we no longer own
+            addedSegments = new HashSet<Integer>(newSegments);
+            addedSegments.removeAll(previousSegments);
+
             if (trace) {
-               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                     removedSegments, newSegments, previousSegments);
+               log.tracef(""On cache %s we have: removed segments: %s; new segments: %s; old segments: %s; added segments: %s"",
+                     cacheName, removedSegments, newSegments, previousSegments, addedSegments);
             }
-            discardSegments(removedSegments);
 
-            Set<Integer> currentSegments = getOwnedSegments(cacheTopology.getReadConsistentHash());
-            addedSegments = new HashSet<Integer>(newSegments);
-            addedSegments.removeAll(currentSegments);
+            // remove inbound transfers and any data for segments we no longer own
+            discardSegments(removedSegments);
 
             // check if any of the existing transfers should be restarted from a different source because the initial source is no longer a member
             Set<Address> members = new HashSet<Address>(cacheTopology.getReadConsistentHash().getMembers());
@@ -230,24 +233,30 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
                      }
                   }
                }
+
+               // exclude those that are already in progress from a valid source
+               addedSegments.removeAll(transfersBySegment.keySet());
             }
          }
 
-         if (addedSegments != null && !addedSegments.isEmpty()) {
+         if (!addedSegments.isEmpty()) {
             addTransfers(addedSegments);  // add transfers for new or restarted segments
          }
       } finally {
-         stateTransferLock.transactionDataReceived(cacheTopology.getTopologyId());
+         stateTransferLock.notifyTransactionDataReceived(cacheTopology.getTopologyId());
 
-         if (activeTopologyUpdates.decrementAndGet() == 0 && !isStateTransferInProgress()) {
+         if (activeTopologyUpdates.decrementAndGet() == 0) {
             notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
          }
       }
    }
 
    private void notifyEndOfTopologyUpdate(int topologyId) {
-      if (rebalanceInProgress.compareAndSet(true, false)) {
-         localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+      if (!isStateTransferInProgress()) {
+         if (rebalanceInProgress.compareAndSet(true, false)) {
+            log.debugf(""Finished receiving of segments for cache %s for topology %d."", cacheName, topologyId);
+            stateTransferManager.notifyEndOfTopologyUpdate(topologyId);
+         }
       }
    }
 
@@ -262,43 +271,42 @@ public void applyState(Address sender, int topologyId, int segmentId, Collection
       //todo [anistor] this check should be based on topologyId
       if (!cacheTopology.getWriteConsistentHash().getSegmentsForOwner(rpcManager.getAddress()).contains(segmentId)) {
          if (trace) {
-            log.warnf(""Discarding received cache entries for segment %d because they do not belong to this node."", segmentId);
+            log.warnf(""Discarding received cache entries for segment %d of cache %s because they do not belong to this node."", segmentId, cacheName);
          }
          return;
       }
 
-      if (cacheEntries != null) {
-         doApplyState(sender, segmentId, cacheEntries);
-      }
-
       // notify the inbound task that a chunk of cache entries was received
       InboundTransferTask inboundTransfer;
       synchronized (this) {
          inboundTransfer = transfersBySegment.get(segmentId);
       }
       if (inboundTransfer != null) {
+         if (cacheEntries != null) {
+            doApplyState(sender, segmentId, cacheEntries);
+         }
+
          inboundTransfer.onStateReceived(segmentId, isLastChunk);
-      } else {
-         log.debugf(""Received unsolicited state for segment %d from node %s"", segmentId, sender);
-         return;
-      }
 
-      if (trace) {
-         log.tracef(""After applying the received state the data container has %d keys"", dataContainer.size());
-         synchronized (this) {
-            log.tracef(""Segments not received yet: %s"", transfersBySource);
+         if (trace) {
+            log.tracef(""After applying the received state the data container of cache %s has %d keys"", cacheName, dataContainer.size());
+            synchronized (this) {
+               log.tracef(""Segments not received yet for cache %s: %s"", cacheName, transfersBySource);
+            }
          }
+      } else {
+         log.warnf(""Received unsolicited state from node %s for segment %d of cache %s"", sender, segmentId, cacheName);
       }
    }
 
    private void doApplyState(Address sender, int segmentId, Collection<InternalCacheEntry> cacheEntries) {
-      log.debugf(""Applying new state for segment %d from %s: received %d cache entries"", segmentId, sender, cacheEntries.size());
+      log.debugf(""Applying new state for segment %d of cache %s from node %s: received %d cache entries"", segmentId, cacheName, sender, cacheEntries.size());
       if (trace) {
          List<Object> keys = new ArrayList<Object>(cacheEntries.size());
          for (InternalCacheEntry e : cacheEntries) {
             keys.add(e.getKey());
          }
-         log.tracef(""Received keys: %s"", keys);
+         log.tracef(""Received keys %s for segment %d of cache %s from node %s"", keys, segmentId, cacheName, sender);
       }
 
       // CACHE_MODE_LOCAL avoids handling by StateTransferInterceptor and any potential locks in StateTransferLock
@@ -316,10 +324,11 @@ private void doApplyState(Address sender, int segmentId, Collection<InternalCach
             log.problemApplyingStateForKey(ex.getMessage(), e.getKey());
          }
       }
+      log.debugf(""Finished applying state for segment %d of cache %s"", segmentId, cacheName);
    }
 
    public void applyTransactions(Address sender, int topologyId, Collection<TransactionInfo> transactions) {
-      log.debugf(""Applying %d transactions transferred from %s"", transactions.size(), sender);
+      log.debugf(""Applying %d transactions for cache %s transferred from node %s"", transactions.size(), cacheName, sender);
       if (configuration.transaction().transactionMode().isTransactional()) {
          for (TransactionInfo transactionInfo : transactions) {
             CacheTransaction tx = transactionTable.getLocalTransaction(transactionInfo.getGlobalTransaction());
@@ -374,30 +383,31 @@ public CacheTopology getCacheTopology() {
    }
 
    private void addTransfers(Set<Integer> segments) {
-      log.debugf(""Adding state transfer for segments: %s"", segments);
+      log.debugf(""Adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
 
       Set<Integer> segmentsToProcess = new HashSet<Integer>(segments);
-      Set<Address> blacklistedSources = new HashSet<Address>();
+      Set<Address> faultysources = new HashSet<Address>();
 
       // ignore all segments for which there are no other owners to pull data from.
       // these segments are considered empty (or lost) and do not require a state transfer
       for (Iterator<Integer> it = segmentsToProcess.iterator(); it.hasNext(); ) {
          Integer segmentId = it.next();
-         Address source = pickSourceOwner(segmentId, blacklistedSources);
+         Address source = pickSourceOwner(segmentId, faultysources);
          if (source == null) {
             it.remove();
          }
       }
 
-      synchronized (this) {
-         // already active transfers do not need to be added again
-         segmentsToProcess.removeAll(transfersBySegment.keySet());
-      }
-
       while (!segmentsToProcess.isEmpty()) {
          Map<Address, Set<Integer>> segmentsBySource = new HashMap<Address, Set<Integer>>();
          for (int segmentId : segmentsToProcess) {
-            Address source = pickSourceOwner(segmentId, blacklistedSources);
+            synchronized (this) {
+               // already active transfers do not need to be added again
+               if (transfersBySegment.containsKey(segmentId)) {
+                  continue;
+               }
+            }
+            Address source = pickSourceOwner(segmentId, faultysources);
             if (source != null) {
                Set<Integer> segmentsFromSource = segmentsBySource.get(source);
                if (segmentsFromSource == null) {
@@ -411,8 +421,14 @@ private void addTransfers(Set<Integer> segments) {
          Set<Integer> failedSegments = new HashSet<Integer>();
          for (Address source : segmentsBySource.keySet()) {
             Set<Integer> segmentsFromSource = segmentsBySource.get(source);
-            InboundTransferTask inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout);
+            InboundTransferTask inboundTransfer;
             synchronized (this) {
+               segmentsFromSource.removeAll(transfersBySegment.keySet());  // already in progress segments are excluded
+               if (segmentsFromSource.isEmpty()) {
+                  continue;
+               }
+
+               inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout, cacheName);
                for (int segmentId : segmentsFromSource) {
                   transfersBySegment.put(segmentId, inboundTransfer);
                }
@@ -427,9 +443,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the transactions fails we need to retry from another source
             if (configuration.transaction().transactionMode().isTransactional()) {
                if (!inboundTransfer.requestTransactions()) {
-                  log.errorf(""Failed to retrieve transactions for segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRetrieveTransactionsForSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                   continue;
                }
@@ -438,9 +454,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the segments fails we need to retry from another source
             if (fetchEnabled) {
                if (!inboundTransfer.requestSegments()) {
-                  log.errorf(""Failed to request segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRequestSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                }
             } else {
@@ -450,21 +466,22 @@ private void addTransfers(Set<Integer> segments) {
 
          segmentsToProcess = failedSegments;
       }
+      log.debugf(""Finished adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
    }
 
-   private Address pickSourceOwner(int segmentId, Set<Address> blacklistedSources) {
+   private Address pickSourceOwner(int segmentId, Set<Address> faultySources) {
       List<Address> owners = cacheTopology.getReadConsistentHash().locateOwnersForSegment(segmentId);
       if (owners.size() == 1 && owners.get(0).equals(rpcManager.getAddress())) {
          return null;
       }
 
       for (int i = owners.size() - 1; i >= 0; i--) {   // iterate backwards because we prefer to fetch from newer nodes
          Address o = owners.get(i);
-         if (!o.equals(rpcManager.getAddress()) && !blacklistedSources.contains(o)) {
+         if (!o.equals(rpcManager.getAddress()) && !faultySources.contains(o)) {
             return o;
          }
       }
-      log.errorf(""No live owners found for segment %d. Current owners are:  %s. Blacklisted owners: %s"", segmentId, owners, blacklistedSources);
+      log.noLiveOwnersFoundForSegment(segmentId, cacheName, owners, faultySources);
       return null;
    }
 
@@ -478,9 +495,9 @@ private void discardSegments(Set<Integer> segments) {
          List<Integer> segmentsToCancel = new ArrayList<Integer>(segments);
          while (!segmentsToCancel.isEmpty()) {
             int segmentId = segmentsToCancel.remove(0);
-            log.debugf(""Removing state transfer for segment %d"", segmentId);
             InboundTransferTask inboundTransfer = transfersBySegment.remove(segmentId);
             if (inboundTransfer != null) { // we need to check the transfer was not already completed
+               log.debugf(""Cancelling inbound state transfer for segment %d of cache %s"", segmentId, cacheName);
                Set<Integer> cancelledSegments = new HashSet<Integer>(segmentsToCancel);
                cancelledSegments.retainAll(inboundTransfer.getSegments());
                segmentsToCancel.removeAll(cancelledSegments);
@@ -489,6 +506,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      // gather all keys from data container that belong to the segments that are being removed
       Set<Object> keysToRemove = new HashSet<Object>();
       for (InternalCacheEntry ice : dataContainer) {
          Object key = ice.getKey();
@@ -497,7 +515,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
-      // we also remove keys from the cache store
+      // gather all keys from cache store that belong to the segments that are being removed
       CacheStore cacheStore = getCacheStore();
       if (cacheStore != null) {
          //todo [anistor] extend CacheStore interface to be able to specify a filter when loading keys (ie. keys should belong to desired segments)
@@ -514,13 +532,14 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      log.debugf(""Removing state for segments %s of cache %s"", segments, cacheName);
       if (!keysToRemove.isEmpty()) {
          try {
             InvalidateCommand invalidateCmd = commandsFactory.buildInvalidateFromL1Command(true, EnumSet.of(CACHE_MODE_LOCAL, SKIP_LOCKING), keysToRemove);
             InvocationContext ctx = icc.createNonTxInvocationContext();
             interceptorChain.invoke(ctx, invalidateCmd);
 
-            log.debugf(""Invalidated %d keys, data container now has %d keys"", keysToRemove.size(), dataContainer.size());
+            log.debugf(""Invalidated %d keys, data container of cache %s now has %d keys"", keysToRemove.size(), cacheName, dataContainer.size());
             if (trace) log.tracef(""Invalidated keys: %s"", keysToRemove);
          } catch (CacheException e) {
             log.failedToInvalidateKeys(e);
@@ -553,18 +572,17 @@ private void removeTransfer(InboundTransferTask inboundTransfer) {
                if (transfers.isEmpty()) {
                   transfersBySource.remove(inboundTransfer.getSource());
                }
-               for (int segmentId : inboundTransfer.getSegments()) {
-                  transfersBySegment.remove(segmentId);
-               }
+               transfersBySegment.keySet().removeAll(inboundTransfer.getSegments());
             }
          }
       }
    }
 
    void onTaskCompletion(InboundTransferTask inboundTransfer) {
+      log.tracef(""Completion of inbound transfer task: %s "", inboundTransfer);
       removeTransfer(inboundTransfer);
 
-      if (activeTopologyUpdates.get() == 0 && !isStateTransferInProgress()) {
+      if (activeTopologyUpdates.get() == 0) {
          notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
       }
    }",2012-11-07T14:07:34Z,54
"@@ -52,7 +52,7 @@
 import static org.infinispan.factories.KnownComponentNames.ASYNC_TRANSPORT_EXECUTOR;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateProvider} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -90,7 +90,7 @@ public StateProviderImpl() {
 
    @Inject
    public void init(Cache cache,
-                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //todo [anistor] use a separate ExecutorService
+                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //TODO Use a dedicated ExecutorService
                     Configuration configuration,
                     RpcManager rpcManager,
                     CommandsFactory commandsFactory,
@@ -184,7 +184,7 @@ public void stop() {
 
    public List<TransactionInfo> getTransactionsForSegments(Address destination, int requestTopologyId, Set<Integer> segments) throws InterruptedException {
       if (trace) {
-         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, requestTopologyId);
+         log.tracef(""Received request for transactions from node %s for segments %s of cache %s with topology id %d"", destination, segments, cacheName, requestTopologyId);
       }
 
       if (readCh == null) {
@@ -262,8 +262,8 @@ public void startOutboundTransfer(Address destination, int requestTopologyId, Se
       }
 
       // the destination node must already have an InboundTransferTask waiting for these segments
-      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, requestTopologyId,
-            readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
+      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId,
+            readCh, this, dataContainer, cacheLoaderManager, rpcManager, commandsFactory, timeout, cacheName);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);
    }
@@ -294,7 +294,7 @@ public void cancelOutboundTransfer(Address destination, int topologyId, Set<Inte
             // get an array copy of the collection to avoid ConcurrentModificationException if the entire task gets cancelled and removeTransfer(transferTask) is called
             OutboundTransferTask[] tasks = transferTasks.toArray(new OutboundTransferTask[transferTasks.size()]);
             for (OutboundTransferTask transferTask : tasks) {
-               transferTask.cancelSegments(segments); //this can potentially result in a removeTransfer(transferTask)
+               transferTask.cancelSegments(segments); //this can potentially result in a call to removeTransfer(transferTask)
             }
          }
       }",2012-11-07T14:07:34Z,55
"@@ -36,16 +36,13 @@
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
-import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
 import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
@@ -75,7 +72,7 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
+   public void init(StateTransferLock stateTransferLock, Configuration configuration,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
       this.commandFactory = commandFactory;",2012-11-07T14:07:34Z,115
"@@ -58,13 +58,13 @@ public interface StateTransferLock {
    void releaseSharedTopologyLock();
 
    // transaction data latch
-   void transactionDataReceived(int topologyId);
+   void notifyTransactionDataReceived(int topologyId);
 
    void waitForTransactionData(int expectedTopologyId) throws InterruptedException;
 
    // topology installation latch
    // TODO move this to Cluster/LocalTopologyManagerImpl and don't start requesting state until every node has the jgroups view with the local node
-   void topologyInstalled(int topologyId);
+   void notifyTopologyInstalled(int topologyId);
 
    void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-11-07T14:07:34Z,122
"@@ -23,12 +23,12 @@
 
 package org.infinispan.statetransfer;
 
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+
 /**
  * {@code StateTransferLock} implementation.
  *
@@ -38,6 +38,7 @@
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
+   private static final boolean trace = log.isTraceEnabled();
 
    private final ReadWriteLock ownershipLock = new ReentrantReadWriteLock();
 
@@ -68,8 +69,15 @@ public void releaseSharedTopologyLock() {
    }
 
    @Override
-   public void transactionDataReceived(int topologyId) {
-      this.transactionDataTopologyId = topologyId;
+   public void notifyTransactionDataReceived(int topologyId) {
+      if (topologyId < transactionDataTopologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + transactionDataTopologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling transaction data received for topology %d"", topologyId);
+      }
+      transactionDataTopologyId = topologyId;
       synchronized (transactionDataLock) {
          transactionDataLock.notifyAll();
       }
@@ -80,19 +88,32 @@ public void waitForTransactionData(int expectedTopologyId) throws InterruptedExc
       if (transactionDataTopologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
-            transactionDataTopologyId);
+      if (trace) {
+         log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
+               transactionDataTopologyId);
+      }
       synchronized (transactionDataLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (transactionDataTopologyId < expectedTopologyId) {
             transactionDataLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Received transaction data for topology %d, expected topology was %d"", transactionDataTopologyId,
+               expectedTopologyId);
+      }
    }
 
    @Override
-   public void topologyInstalled(int topologyId) {
+   public void notifyTopologyInstalled(int topologyId) {
+      if (topologyId < this.topologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + this.topologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling topology %d is installed"", topologyId);
+      }
       this.topologyId = topologyId;
       synchronized (topologyLock) {
          topologyLock.notifyAll();
@@ -104,14 +125,18 @@ public void waitForTopology(int expectedTopologyId) throws InterruptedException
       if (topologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId,
-            topologyId);
+      if (trace) {
+         log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId, topologyId);
+      }
       synchronized (topologyLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (topologyId < expectedTopologyId) {
             topologyLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Topology %d is now installed, expected topology was %d"", topologyId, expectedTopologyId);
+      }
    }
 }",2012-11-07T14:07:34Z,123
"@@ -81,4 +81,5 @@ public interface StateTransferManager {
     */
    void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
 
+   void notifyEndOfTopologyUpdate(int topologyId);
 }",2012-11-07T14:07:34Z,116
"@@ -70,7 +70,7 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private GroupManager groupManager;   // optional
    private LocalTopologyManager localTopologyManager;
 
-   private CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
+   private final CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
 
    public StateTransferManagerImpl() {
    }
@@ -170,13 +170,18 @@ private CacheTopology addGrouping(CacheTopology cacheTopology) {
 
    private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalance) {
       if (trace) {
-         log.tracef(""Installing new cache topology %s"", newCacheTopology);
+         log.tracef(""Installing new cache topology %s on cache %s"", newCacheTopology, cacheName);
       }
 
       // handle grouping
       newCacheTopology = addGrouping(newCacheTopology);
 
       CacheTopology oldCacheTopology = stateConsumer.getCacheTopology();
+
+      if (oldCacheTopology != null && oldCacheTopology.getTopologyId() > newCacheTopology.getTopologyId()) {
+         throw new IllegalStateException(""Old topology is higher: old="" + oldCacheTopology + "", new="" + newCacheTopology);
+      }
+
       ConsistentHash oldCH = oldCacheTopology != null ? oldCacheTopology.getWriteConsistentHash() : null;
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
@@ -188,15 +193,17 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
 
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
-      if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
+      boolean isJoined = stateConsumer.getCacheTopology().getReadConsistentHash().getMembers().contains(rpcManager.getAddress());
+      if (initialStateTransferComplete.getCount() > 0 && isJoined) {
          initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
    }
 
    @Start(priority = 1000)
    @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
-      if (trace) log.tracef(""Waiting for initial state transfer to finish"");
+      if (trace) log.tracef(""Waiting for initial state transfer to finish for cache %s on %s"", cacheName, rpcManager.getAddress());
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);
       if (!success) {
          throw new CacheException(String.format(""Initial state transfer timed out for cache %s on %s"",
@@ -210,6 +217,7 @@ public void stop() {
       if (trace) {
          log.tracef(""Shutting down StateTransferManager of cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
+      initialStateTransferComplete.countDown();
       localTopologyManager.leave(cacheName);
    }
 
@@ -268,4 +276,14 @@ public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object>
          }
       }
    }
+
+   @Override
+   public void notifyEndOfTopologyUpdate(int topologyId) {
+      if (initialStateTransferComplete.getCount() > 0
+            && stateConsumer.getCacheTopology().getWriteConsistentHash().getMembers().contains(rpcManager.getAddress())) {
+         initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
+      }
+      localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+   }
 }
\ No newline at end of file",2012-11-07T14:07:34Z,117
"@@ -126,13 +126,17 @@ public void triggerRebalance(final String cacheName) throws Exception {
       asyncTransportExecutor.submit(new Callable<Object>() {
          @Override
          public Object call() throws Exception {
-            startRebalance(cacheName);
-            return null;
+            try {
+               startRebalance(cacheName);
+               return null;
+            } catch (Throwable t) {
+               log.errorf(t, ""Failed to start rebalance: %s"", t.getMessage());
+               throw new Exception(t);
+            }
          }
       });
    }
 
-
    @Override
    public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo joinInfo, int viewId) throws Exception {
       waitForView(viewId);
@@ -594,6 +598,7 @@ public Object call() throws Exception {
             try {
                return command.perform(null);
             } catch (Throwable t) {
+               log.errorf(t, ""Failed to execute ReplicableCommand %s on cluster async: %s"", command, t.getMessage());
                throw new Exception(t);
             }
          }",2012-11-07T14:07:34Z,124
"@@ -280,6 +280,7 @@ public Object call() throws Exception {
                try {
                   return command.perform(null);
                } catch (Throwable t) {
+                  log.errorf(t, ""Failed to execute ReplicableCommand %s on coordinator async: %s"", command, t.getMessage());
                   throw new Exception(t);
                }
             }
@@ -298,8 +299,6 @@ class LocalCacheStatus {
    private final CacheTopologyHandler handler;
    private volatile CacheTopology topology;
 
-   private boolean joined;
-
    public LocalCacheStatus(CacheJoinInfo joinInfo, CacheTopologyHandler handler) {
       this.joinInfo = joinInfo;
       this.handler = handler;
@@ -320,12 +319,4 @@ public CacheTopology getTopology() {
    public void setTopology(CacheTopology topology) {
       this.topology = topology;
    }
-
-   public boolean isJoined() {
-      return joined;
-   }
-
-   public void setJoined(boolean joined) {
-      this.joined = joined;
-   }
 }",2012-11-07T14:07:34Z,125
"@@ -53,15 +53,14 @@ public class StaleTransactionCleanupService {
 
    private static Log log = LogFactory.getLog(StaleTransactionCleanupService.class);
 
+   private ScheduledExecutorService executorService;
 
    private TransactionTable transactionTable;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
-   private ScheduledExecutorService executorService;
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * because the main data owner left. Also unlocks keys for which the lock owner has changed as a result of a topology change.
@@ -71,15 +70,19 @@ public StaleTransactionCleanupService(TransactionTable transactionTable) {
    @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // Roll back remote transactions originating on nodes that have left the cluster.
-      if (tce.isPre()) {
-         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
-         if (consistentHashAtStart != null) {
-            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
-            if (!leavers.isEmpty()) {
-               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-               cleanTxForWhichTheOwnerLeft(leavers);
+      try {
+         if (tce.isPre()) {
+            ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+            if (consistentHashAtStart != null) {
+               List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+               if (!leavers.isEmpty()) {
+                  log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+                  cleanTxForWhichTheOwnerLeft(leavers);
+               }
             }
          }
+      } catch (Exception e) {
+         log.error(""Failed to process topology update"", e);
       }
    }
 
@@ -120,7 +123,6 @@ public void run() {
             transactionTable.cleanupCompletedTransactions();
          }
       }, interval, interval, TimeUnit.MILLISECONDS);
-
    }
 
    public void stop() {",2012-11-07T14:07:34Z,126
"@@ -523,25 +523,29 @@ public boolean isTransactionCompleted(GlobalTransaction gtx) {
    }
 
    public void cleanupCompletedTransactions() {
-      log.debugf(""About to cleanup completed transaction. Initial size is %s"", completedTransactions.size());
-      //this iterator is weekly consistent and will never throw ConcurrentModificationException
-      Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
-      long timeout = configuration.transaction().completedTxTimeout();
-
-      int removedEntries = 0;
-      long beginning = System.nanoTime();
-      while (iterator.hasNext()) {
-         Map.Entry<GlobalTransaction, Long> e = iterator.next();
-         long ageNanos = System.nanoTime() - e.getValue();
-         if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
-            iterator.remove();
-            removedEntries++;
+      try {
+         log.debugf(""About to cleanup completed transaction. Initial size is %d"", completedTransactions.size());
+         //this iterator is weekly consistent and will never throw ConcurrentModificationException
+         Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
+         long timeout = configuration.transaction().completedTxTimeout();
+
+         int removedEntries = 0;
+         long beginning = System.nanoTime();
+         while (iterator.hasNext()) {
+            Map.Entry<GlobalTransaction, Long> e = iterator.next();
+            long ageNanos = System.nanoTime() - e.getValue();
+            if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
+               iterator.remove();
+               removedEntries++;
+            }
          }
-      }
-      long duration = System.nanoTime() - beginning;
+         long duration = System.nanoTime() - beginning;
 
-      log.debugf(""Finished cleaning up completed transactions. %s transactions were removed, total duration was %s millis, "" +
-                      ""current number of completed transactions is %"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
-                 completedTransactions.size());
+         log.debugf(""Finished cleaning up completed transactions. %d transactions were removed, total duration was %d millis, "" +
+                         ""current number of completed transactions is %d"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
+                    completedTransactions.size());
+      } catch (Exception e) {
+         log.errorf(e, ""Failed to cleanup completed transactions: %s"", e.getMessage());
+      }
    }
 }",2012-11-07T14:07:34Z,127
"@@ -24,9 +24,7 @@
 
 import org.infinispan.CacheException;
 import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.commands.tx.PrepareCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.bucket.Bucket;
 import org.infinispan.loaders.decorators.SingletonStore;
@@ -60,7 +58,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.UUID;
-import java.util.concurrent.ExecutionException;
 
 import static org.jboss.logging.Logger.Level.*;
 
@@ -131,26 +128,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Can not select %s random members for %s"", id = 8)
    void cannotSelectRandomMembers(int numNeeded, List<Address> members);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Detected a view change. Member list changed from %s to %s"", id = 9)
-   void viewChangeDetected(List<Address> oldMembers, List<Address> newMembers);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a JOIN event! Wait for notification from new joiner %s"", id = 10)
-   void joinEvent(Address joiner);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a LEAVE event! Node %s has just left"", id = 11)
-   void leaveEvent(Address leaver);
-
-   @LogMessage(level = FATAL)
-   @Message(value = ""Unable to process leaver!!"", id = 12)
-   void unableToProcessLeaver(@Cause Exception e);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""I %s am participating in rehash, state providers %s, state receivers %s"", id = 13)
-   void participatingInRehash(Address address, List<Address> stateProviders, List<Address> receiversOfLeaverState);
-
    @LogMessage(level = INFO)
    @Message(value = ""DistributionManager not yet joined the cluster. Cannot do anything about other concurrent joiners."", id = 14)
    void distributionManagerNotJoined();
@@ -163,10 +140,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Problem %s encountered when applying state for key %s!"", id = 16)
    void problemApplyingStateForKey(String msg, Object key);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""View change interrupted; not rehashing!"", id = 17)
-   void viewChangeInterrupted();
-
    @LogMessage(level = WARN)
    @Message(value = ""Unable to apply prepare %s"", id = 18)
    void unableToApplyPrepare(PrepareCommand pc, @Cause Throwable t);
@@ -175,26 +148,10 @@ public interface Log extends BasicLogger {
    @Message(value = ""Couldn't acquire shared lock"", id = 19)
    void couldNotAcquireSharedLock();
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Caught exception replaying %s"", id = 20)
-   void exceptionWhenReplaying(WriteCommand cmd, @Cause Exception e);
-
    @LogMessage(level = WARN)
    @Message(value = ""Expected just one response; got %s"", id = 21)
    void expectedJustOneResponse(Map<Address, Response> lr);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Completed leave rehash on node %s in %s - leavers now are %s"", id = 22)
-   void completedLeaveRehash(Address self, String duration, List<Address> leavers);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error pushing tx log"", id = 23)
-   void errorPushingTxLog(@Cause ExecutionException e);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Unable to stop transaction logging!"", id = 24)
-   void unableToStopTransactionLogging(@Cause IllegalMonitorStateException imse);
-
    @LogMessage(level = INFO)
    @Message(value = ""wakeUpInterval is <= 0, not starting expired purge thread"", id = 25)
    void notStartingEvictionThread();
@@ -211,7 +168,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unable to passivate entry under %s"", id = 28)
    void unableToPassivateEntry(Object key, @Cause Exception e);
 
-
    @LogMessage(level = INFO)
    @Message(value = ""Passivating all entries to disk"", id = 29)
    void passivatingAllEntries();
@@ -296,14 +252,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Interrupted or timeout while waiting for AsyncStore worker threads to push all state to the decorated store"", id = 48)
    void interruptedWaitingAsyncStorePush(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing clear in async store"", id = 49)
-   void errorClearinAsyncStore(@Cause CacheLoaderException e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing purging expired from async store"", id = 50)
-   void errorPurgingAsyncStore(@Cause CacheLoaderException e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Unexpected error"", id = 51)
    void unexpectedErrorInAsyncProcessor(@Cause Throwable t);
@@ -376,14 +324,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Cache named %s does not exist on this cache manager!"", id = 68)
    void namedCacheDoesNotExist(String cacheName);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Cache named [%s] exists but isn't in a state to handle remote invocations"", id = 69)
-   void cacheCanNotHandleInvocations(String cacheName);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Quietly ignoring clustered get call %s since unable to acquire processing lock, even after %s"", id = 70)
-   void ignoreClusterGetCall(CacheRpcCommand cmd, String time);
-
    @LogMessage(level = WARN)
    @Message(value = ""Caught exception when handling command %s"", id = 71)
    void exceptionHandlingCommand(ReplicableCommand cmd, @Cause Throwable t);
@@ -396,18 +336,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unexpected error while replicating"", id = 73)
    void unexpectedErrorReplicating(@Cause Throwable t);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Trying to fetch state from %s"", id = 74)
-   void tryingToFetchState(Address member);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Could not find available peer for state, backing off and retrying"", id = 75)
-   void couldNotFindPeerForState();
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Successfully retrieved and applied state from %s"", id = 76)
-   void successfullyAppliedState(Address member);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Message or message buffer is null or empty."", id = 77)
    void msgOrMsgBufferEmpty();
@@ -461,15 +389,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""getCoordinator(): Interrupted while waiting for members to be set"", id = 89)
    void interruptedWaitingForCoordinator(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Unable to retrieve state from member %s"", id = 90)
-   void unableToRetrieveState(Address member, @Cause Exception e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Channel does not contain STREAMING_STATE_TRANSFER. "" +
-         ""Cannot support state transfers!"", id = 91)
-   void streamingStateTransferNotPresent();
-
    @LogMessage(level = WARN)
    @Message(value = ""Channel not set up properly!"", id = 92)
    void channelNotSetUp();
@@ -482,10 +401,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Received new cluster view: %s"", id = 94)
    void receivedClusterView(View newView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Caught while requesting or applying state"", id = 96)
-   void errorRequestingOrApplyingState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error while processing a prepare in a single-phase transaction"", id = 97)
    void errorProcessing1pcPrepareCommand(@Cause Throwable e);
@@ -688,14 +603,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Failed loading value for key %s from cache store"", id = 144)
    void failedLoadingValueFromCacheStore(Object key, @Cause Exception e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error during rehash"", id = 145)
-   void errorDuringRehash(@Cause Throwable th);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error transferring state to node after rehash"", id = 146)
-   void errorTransferringState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error invalidating keys from L1 after rehash"", id = 147)
    void failedToInvalidateKeys(@Cause Exception e);
@@ -729,14 +636,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Unable to unlock keys %2$s for transaction %1$s after they were rebalanced off node %3$s"", id = 154)
    void unableToUnlockRebalancedKeys(GlobalTransaction gtx, List<Object> keys, Address self, @Cause Throwable t);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm pushing data for view %d, received confirmations %s. Cancelling state transfer"", id = 157)
-   void stateTransferTimeoutWaitingForPushConfirmations(int viewId, Map<Address, Integer> pushConfirmations);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm joining for view %d, joined %s. Cancelling state transfer"", id = 158)
-   void stateTransferTimeoutWaitingForJoinConfirmations(int viewId, Map<Address, Integer> joinConfirmations);
-
    @LogMessage(level = WARN)
    @Message(value = ""Unblocking transactions failed"", id = 159)
    void errorUnblockingTransactions(@Cause Exception e);
@@ -761,26 +660,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Rolling back to cache view %d, but last committed view is %d"", id = 164)
    void cacheViewRollbackIdMismatch(int committedViewId, int committedView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error triggering a view installation for cache %s"", id = 165)
-   void errorTriggeringViewInstallation(@Cause RuntimeException e, String cacheName);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""View installation failed for cache %s"", id = 166)
-   void viewInstallationFailure(@Cause Throwable e, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Rejecting state pushed by node %s for view %d, there is no state transfer in progress (we are at view %d)"", id = 167)
-   void remoteStateRejected(Address sender, int viewId, int installedViewId);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error rolling back to cache view %1$d for cache %2$s"", id = 168)
-   void cacheViewRollbackFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error committing cache view %1$d for cache %2$s"", id = 169)
-   void cacheViewCommitFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
    @LogMessage(level = INFO)
    @Message(value = ""Strict peer-to-peer is enabled but the JGroups channel was started externally - this is very likely to result in RPC timeout errors on startup"", id = 171)
    void warnStrictPeerToPeerWithInjectedChannel();
@@ -926,5 +805,16 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @LogMessage(level = WARN)
    @Message(value = ""Could not interrupt as no thread found for command uuid %s"", id=207)
    void couldNotInterruptThread(UUID id);
-   
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""No live owners found for segment %d of cache %s. Current owners are:  %s. Faulty owners: %s"", id=208)
+   void noLiveOwnersFoundForSegment(int segmentId, String cacheName, Collection<Address> owners, Collection<Address> faultySources);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to retrieve transactions for segments %s of cache %s from node %s (node will not be retried)"", id=209)
+   void failedToRetrieveTransactionsForSegments(Collection<Integer> segments, String cacheName, Address source);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to request segments %s of cache %s from node %s (node will not be retried)"", id=210)
+   void failedToRequestSegments(Collection<Integer> segments, String cacheName, Address source);
 }",2012-11-07T14:07:34Z,45
"@@ -263,7 +263,7 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm, boolean deprecated) {
 
       assert gc.asyncTransportExecutor().factory() instanceof DefaultExecutorFactory;
       // Should be 25, but it's overriden by the test cache manager factory
-      assertEquals(""4"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
+      assertEquals(""6"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
       assert gc.asyncTransportExecutor().properties().getProperty(""threadNamePrefix"").equals(""AsyncSerializationThread"");
 
       assert gc.evictionScheduledExecutor().factory() instanceof DefaultScheduledExecutorFactory;",2012-11-07T14:07:34Z,128
"@@ -50,7 +50,6 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -126,7 +125,7 @@ public void test1() throws Exception {
       when(cache.getName()).thenReturn(""testCache"");
 
       StateProvider stateProvider = mock(StateProvider.class);
-      LocalTopologyManager localTopologyManager = mock(LocalTopologyManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
       CacheNotifier cacheNotifier = mock(CacheNotifier.class);
       ExecutorService mockExecutorService = mock(ExecutorService.class);
       RpcManager rpcManager = mock(RpcManager.class);
@@ -183,7 +182,7 @@ public Map<Address, Response> answer(InvocationOnMock invocation) {
 
       // create state provider
       StateConsumerImpl stateConsumer = new StateConsumerImpl();
-      stateConsumer.init(cache, localTopologyManager, interceptorChain, icc, configuration, rpcManager,
+      stateConsumer.init(cache, stateTransferManager, interceptorChain, icc, configuration, rpcManager,
             commandsFactory, cacheLoaderManager, dataContainer, transactionTable, stateTransferLock);
       stateConsumer.start();
 ",2012-11-07T14:07:34Z,56
"@@ -40,6 +40,7 @@
 
 /**
  * Test if state transfer happens properly on a cache with pessimistic transactions.
+ * See https://issues.jboss.org/browse/ISPN-2408.
  *
  * @since 5.2
  */",2012-11-07T14:07:34Z,129
"@@ -75,6 +75,8 @@
  */
 public class TestCacheManagerFactory {
 
+   private static final int MAX_ASYNC_EXEC_THREADS = 6;
+
    public static final String MARSHALLER = LegacyKeySupportSystemProperties.getProperty(""infinispan.test.marshaller.class"", ""infinispan.marshaller.class"");
    private static final Log log = LogFactory.getLog(TestCacheManagerFactory.class);
 
@@ -523,12 +525,12 @@ private static void checkTestName(String fullTestName) {
 
    public static void minimizeThreads(GlobalConfiguration gc) {
       Properties p = new Properties();
-      p.setProperty(""maxThreads"", ""4"");
+      p.setProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
       gc.setAsyncTransportExecutorProperties(p);
    }
 
    public static void minimizeThreads(GlobalConfigurationBuilder builder) {
-      builder.asyncTransportExecutor().addProperty(""maxThreads"", ""4"");
+      builder.asyncTransportExecutor().addProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
    }
 
    public static void amendMarshaller(GlobalConfiguration configuration) {",2012-11-07T14:07:34Z,130
"@@ -112,9 +112,11 @@ public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand
 
       final TxInvocationContext txContext = (TxInvocationContext) ctx;
       try {
-         final boolean localNodeOwnsLock = cdl.localNodeIsPrimaryOwner(command.getKey());
-         acquireRemoteIfNeeded(ctx, command, localNodeOwnsLock);
-         if (command.hasFlag(Flag.SKIP_OWNERSHIP_CHECK) || localNodeOwnsLock) {
+         // The primary owner check doesn't work for preload, as we don't have a topology yet
+         boolean localOnly = command.hasFlag(Flag.CACHE_MODE_LOCAL);
+         boolean localLock = localOnly || cdl.localNodeIsPrimaryOwner(command.getKey());
+         acquireRemoteIfNeeded(ctx, command, localLock);
+         if (localLock) {
             boolean skipLocking = hasSkipLocking(command);
             long lockTimeout = getLockAcquisitionTimeout(command, skipLocking);
             lockKeyAndCheckOwnership(ctx, command.getKey(), lockTimeout, skipLocking);",2012-11-30T18:42:42Z,602
"@@ -60,14 +60,12 @@
 import org.infinispan.loaders.decorators.SingletonStore;
 import org.infinispan.loaders.decorators.SingletonStoreConfig;
 import org.infinispan.marshall.StreamingMarshaller;
-import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
 public class CacheLoaderManagerImpl implements CacheLoaderManager {
-   private static final Log log = LogFactory.getLog(CacheLoaderManagerImpl.class);
 
    Configuration configuration;
    LoadersConfiguration clmConfig;
@@ -76,19 +74,17 @@ public class CacheLoaderManagerImpl implements CacheLoaderManager {
    CacheLoader loader;
    InvocationContextContainer icc;
    TransactionManager transactionManager;
-   StateTransferManager stateTransferManager;
+   private static final Log log = LogFactory.getLog(CacheLoaderManagerImpl.class);
 
    @Inject
    public void inject(AdvancedCache<Object, Object> cache,
                       @ComponentName(CACHE_MARSHALLER) StreamingMarshaller marshaller,
-                      Configuration configuration, InvocationContextContainer icc,
-                      TransactionManager transactionManager, StateTransferManager stateTransferManager) {
+                      Configuration configuration, InvocationContextContainer icc, TransactionManager transactionManager) {
       this.cache = cache;
       this.m = marshaller;
       this.configuration = configuration;
       this.icc = icc;
       this.transactionManager = transactionManager;
-      this.stateTransferManager = stateTransferManager;
    }
 
    @Override
@@ -210,19 +206,12 @@ public void disableCacheStore(String loaderType) {
 
    /**
     * Performs a preload on the cache based on the cache loader preload configs used when configuring the cache.
-    * The preload will happen only on the first node to start this cache in a cluster - the other nodes
-    * will receive this data via state transfer.
     */
    @Override
    @Start(priority = 56)
    public void preload() {
       if (loader != null) {
          if (clmConfig.preload()) {
-            // Don't preload anything if we're not the first member to start up
-            if (stateTransferManager != null && !stateTransferManager.isLocalNodeFirst()) {
-               log.debugf(""We are not the first node to join cache %s, skipping preload"", cache.getName());
-               return;
-            }
             long start = 0;
             boolean debugTiming = log.isDebugEnabled();
             if (debugTiming) {
@@ -251,7 +240,7 @@ public void preload() {
                   .withFlags(flags.toArray(new Flag[]{}));
 
             for (InternalCacheEntry e : state)
-               flaggedCache.putIfAbsent(e.getKey(), e.getValue(),
+               flaggedCache.put(e.getKey(), e.getValue(),
                      e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
 
             if (debugTiming) {",2012-11-30T18:42:42Z,29
"@@ -204,27 +204,6 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             addedSegments = new HashSet<Integer>(newSegments);
             addedSegments.removeAll(previousSegments);
 
-            // The actual owners keep track of the nodes that hold a key in L1 (""requestors"") and
-            // they invalidate the key on every requestor after a change.
-            // But this information is only present on the owners where the ClusteredGetKeyValueCommand
-            // got executed - if the requestor only contacted one owner, and that node is no longer an owner
-            // (perhaps because it left the cluster), the other owners will not know to invalidate the key
-            // on that requestor. Furthermore, the requestors list is not copied to the new owners during
-            // state transfers.
-            // To compensate for this, we delete all L1 entries in segments that changed ownership during
-            // this topology update. We can't actually differentiate between L1 entries and regular entries,
-            // so we delete all entries that don't belong to this node in the current OR previous topology.
-            Set<Integer> invalidL1Segments = new HashSet<Integer>();
-            for (int segment = 0; segment < cacheTopology.getCurrentCH().getNumSegments(); segment++) {
-               if (!previousSegments.contains(segment) && newSegments.contains(segment)) {
-                  List<Address> previousOwners = previousCh.locateOwnersForSegment(segment);
-                  List<Address> newOwners = cacheTopology.getWriteConsistentHash().locateOwnersForSegment(segment);
-                  if (!newOwners.containsAll(previousOwners)) {
-                     invalidL1Segments.add(segment);
-                  }
-               }
-            }
-
             // remove inbound transfers and any data for segments we no longer own
             if (trace) {
                log.tracef(""On cache %s we have: removed segments: %s; new segments: %s; old segments: %s; added segments: %s"",
@@ -236,7 +215,7 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
 
             // If L1.onRehash is enabled, ""removed"" segments are actually moved to L1. The new (and old) owners
             // will automatically add the nodes that no longer own a key to that key's requestors list.
-            invalidateSegments(removedSegments, invalidL1Segments);
+            invalidateSegments(newSegments, removedSegments);
 
             // check if any of the existing transfers should be restarted from a different source because the initial source is no longer a member
             Set<Address> members = new HashSet<Address>(cacheTopology.getReadConsistentHash().getMembers());
@@ -533,16 +512,27 @@ private void cancelTransfers(Set<Integer> removedSegments) {
       }
    }
 
-   private void invalidateSegments(Set<Integer> segmentsToL1, Set<Integer> segmentsToRemove) {
+   private void invalidateSegments(Set<Integer> newSegments, Set<Integer> segmentsToL1) {
+      // The actual owners keep track of the nodes that hold a key in L1 (""requestors"") and
+      // they invalidate the key on every requestor after a change.
+      // But this information is only present on the owners where the ClusteredGetKeyValueCommand
+      // got executed - if the requestor only contacted one owner, and that node is no longer an owner
+      // (perhaps because it left the cluster), the other owners will not know to invalidate the key
+      // on that requestor. Furthermore, the requestors list is not copied to the new owners during
+      // state transfers.
+      // To compensate for this, we delete all L1 entries in segments that changed ownership during
+      // this topology update. We can't actually differentiate between L1 entries and regular entries,
+      // so we delete all entries that don't belong to this node in the current OR previous topology.
       Set<Object> keysToL1 = new HashSet<Object>();
       Set<Object> keysToRemove = new HashSet<Object>();
+
       // gather all keys from cache store that belong to the segments that are being removed/moved to L1
       for (InternalCacheEntry ice : dataContainer) {
          Object key = ice.getKey();
          int keySegment = getSegment(key);
-         if (segmentsToRemove.contains(keySegment)) {
+         if (segmentsToL1.contains(keySegment)) {
             keysToL1.add(key);
-         } else if (segmentsToL1.contains(keySegment)) {
+         } else if (!newSegments.contains(keySegment)) {
             keysToRemove.add(key);
          }
       }
@@ -554,9 +544,9 @@ private void invalidateSegments(Set<Integer> segmentsToL1, Set<Integer> segments
             Set<Object> storedKeys = cacheStore.loadAllKeys(new ReadOnlyDataContainerBackedKeySet(dataContainer));
             for (Object key : storedKeys) {
                int keySegment = getSegment(key);
-               if (segmentsToRemove.contains(keySegment)) {
+               if (segmentsToL1.contains(keySegment)) {
                   keysToL1.add(key);
-               } else if (segmentsToL1.contains(keySegment)) {
+               } else if (!newSegments.contains(keySegment)) {
                   keysToRemove.add(key);
                }
             }
@@ -584,7 +574,7 @@ private void invalidateSegments(Set<Integer> segmentsToL1, Set<Integer> segments
          }
       }
 
-      log.debugf(""Removing L1 state for segments %s of cache %s"", segmentsToRemove, cacheName);
+      log.debugf(""Removing L1 state for segments not in %s or %s for cache %s"", newSegments, segmentsToL1, cacheName);
       if (!keysToRemove.isEmpty()) {
          try {
             InvalidateCommand invalidateCmd = commandsFactory.buildInvalidateFromL1Command(false, EnumSet.of(CACHE_MODE_LOCAL, SKIP_LOCKING), keysToRemove);",2012-11-30T18:42:42Z,54
"@@ -37,6 +37,7 @@
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.topology.CacheTopology;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
@@ -230,7 +231,10 @@ private void updateTopologyIdAndWaitForTransactionData(TopologyAffectedCommand c
       // set the topology id if it was not set before (ie. this is local command)
       // TODO Make tx commands extend FlagAffectedCommand so we can use CACHE_MODE_LOCAL in StaleTransactionCleanupService
       if (command.getTopologyId() == -1) {
-         command.setTopologyId(stateTransferManager.getCacheTopology().getTopologyId());
+         CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
+         if (cacheTopology != null) {
+            command.setTopologyId(cacheTopology.getTopologyId());
+         }
       }
 
       // remote/forwarded command",2012-11-30T18:42:42Z,115
"@@ -96,7 +96,8 @@ public void init(StateConsumer stateConsumer,
       this.localTopologyManager = localTopologyManager;
    }
 
-   @Start(priority = 50)
+   // needs to be AFTER the DistributionManager and *after* the cache loader manager (if any) inits and preloads
+   @Start(priority = 60)
    @Override
    public void start() throws Exception {
       if (trace) {
@@ -259,7 +260,7 @@ public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object>
       // forward commands with older topology ids to their new targets
       // but we need to make sure we have the latest topology
       CacheTopology cacheTopology = getCacheTopology();
-      int localTopologyId = cacheTopology.getTopologyId();
+      int localTopologyId = cacheTopology != null ? cacheTopology.getTopologyId() : -1;
       // if it's a tx/lock/write command, forward it to the new owners
       log.tracef(""CommandTopologyId=%s, localTopologyId=%s"", cmdTopologyId, localTopologyId);
 ",2012-11-30T18:42:42Z,117
"@@ -312,9 +312,6 @@ public LocalTransaction getOrCreateLocalTransaction(Transaction transaction, TxI
       LocalTransaction current = localTransactions.get(transaction);
       if (current == null) {
          Address localAddress = rpcManager != null ? rpcManager.getTransport().getAddress() : null;
-         if (rpcManager != null && currentTopologyId < 0) {
-            throw new IllegalStateException(""Cannot create transactions if topology id is not known yet!"");
-         }
          GlobalTransaction tx = txFactory.newGlobalTransaction(localAddress, false);
          current = txFactory.newLocalTransaction(transaction, tx, ctx.isImplicitTransaction(), currentTopologyId);
          log.tracef(""Created a new local transaction: %s"", current);",2012-11-30T18:42:42Z,127
"@@ -76,10 +76,13 @@ public void testPreloadOnStart() throws CacheLoaderException {
       EmbeddedCacheManager cm2 = cacheManagers.get(1);
       cm2.defineConfiguration(cacheName, buildConfiguration().build());
       c2 = cache(1, cacheName);
-      waitForClusterToForm(cacheName);
-      caches.add(c2);
+      waitForClusterToForm();
 
       DataContainer dc2 = c2.getAdvancedCache().getDataContainer();
-      assertEquals(""No keys should be preloaded on the second cache"", 0, dc2.size());
+      assertEquals(""Expected all the cache store entries to be preloaded on the second cache"", NUM_KEYS, dc2.size());
+
+      for (int i = 0; i < NUM_KEYS; i++) {
+         assertOwnershipAndNonOwnership(""k"" + i, true);
+      }
    }
 }",2012-11-30T18:42:42Z,603
"@@ -23,15 +23,22 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.Cache;
-import org.infinispan.config.CacheLoaderManagerConfig;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.loaders.CacheLoader;
 import org.infinispan.loaders.CacheLoaderManager;
-import org.infinispan.loaders.CacheStoreConfig;
-import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStoreConfigurationBuilder;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.test.TestingUtil;
 import org.testng.annotations.Test;
 
+import java.io.IOException;
+import java.io.ObjectInputStream;
+import java.io.ObjectOutputStream;
+import java.io.Serializable;
+
+import static org.testng.Assert.assertEquals;
+
 @Test(groups = ""functional"", testName = ""statetransfer.StateTransferCacheLoaderFunctionalTest"", enabled = true)
 public class StateTransferCacheLoaderFunctionalTest extends StateTransferFunctionalTest {
    int id;
@@ -47,13 +54,14 @@ public StateTransferCacheLoaderFunctionalTest() {
 
    @Override
    protected EmbeddedCacheManager createCacheManager() {
+      configurationBuilder.loaders().clearCacheLoaders();
       // increment the DIMCS store id
-      CacheLoaderManagerConfig clmc = new CacheLoaderManagerConfig();
-      CacheStoreConfig clc = new DummyInMemoryCacheStore.Cfg(""store number "" + id++);
-      clmc.addCacheLoaderConfig(clc);
-      clc.setFetchPersistentState(true);
-      clmc.setShared(sharedCacheLoader.get());
-      config.setCacheLoaderManagerConfig(clmc);
+      DummyInMemoryCacheStoreConfigurationBuilder dimcs = new DummyInMemoryCacheStoreConfigurationBuilder(configurationBuilder.loaders());
+      dimcs.storeName(""store number "" + id++);
+      dimcs.fetchPersistentState(true);
+      configurationBuilder.loaders().addLoader(dimcs);
+      configurationBuilder.loaders().shared(sharedCacheLoader.get()).preload(true);
+
       return super.createCacheManager();
    }
 
@@ -102,8 +110,8 @@ public void testSharedLoader() throws Exception {
 
          // starting the second cache would initialize an in-memory state transfer but not a persistent one since the loader is shared
          Cache<Object, Object> c2 = createCacheManager().getCache(cacheName);
-
          TestingUtil.blockUntilViewsReceived(60000, c1, c2);
+         TestingUtil.waitForRehashToComplete(c1, c2);
 
          verifyInitialDataOnLoader(c1);
          verifyInitialData(c1);
@@ -114,4 +122,76 @@ public void testSharedLoader() throws Exception {
          sharedCacheLoader.set(false);
       }
    }
+
+   public void testInitialSlowPreload() throws Exception {
+      // Test for ISPN-2495
+      // Preload on cache on node 1 is slow and unfinished at the point, where cache on node 2 starts.
+      // Node 2 requests state, got answer that no entries available. Since node 2 is not coordinator,
+      // preload is ignored. At the end, node 1 contains REPL cache with all entries, node 2 has same cache without entries.
+      try {
+         sharedCacheLoader.set(true);
+         EmbeddedCacheManager cm1 = createCacheManager();
+         Cache<Object, Object> cache1 = cm1.getCache(cacheName);
+         verifyNoDataOnLoader(cache1);
+         verifyNoData(cache1);
+
+         // write initial data
+         cache1.put(""A"", new DelayedUnmarshal());
+         cache1.put(""B"", new DelayedUnmarshal());
+         cache1.put(""C"", new DelayedUnmarshal());
+         assertEquals(cache1.size(), 3);
+         cm1.stop();
+
+         // this cache is only used to start networking
+         final ConfigurationBuilder defaultConfigurationBuilder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, true);
+
+         // now lets start cm and shortly after another cache manager
+         final EmbeddedCacheManager cm2 = super.createCacheManager();
+         cm2.defineConfiguration(""initialCache"", defaultConfigurationBuilder.build());
+         cm2.startCaches(""initialCache"");
+
+         EmbeddedCacheManager cm3 = super.createCacheManager();
+         cm3.defineConfiguration(""initialCache"", defaultConfigurationBuilder.build());
+         cm3.startCaches(""initialCache"");
+
+         // networking is started and cluster has 2 members
+         TestingUtil.blockUntilViewsReceived(60000, cm2.getCache(""initialCache""), cm3.getCache(""initialCache""));
+
+         // now fork start of ""slow"" cache
+         Thread worker = new Thread(){
+            @Override
+            public void run() {
+               cm2.startCaches(cacheName);
+            }
+         };
+         worker.start();
+         // lets wait a bit, cache is started pon cm2, but preload is not finished
+         TestingUtil.sleepThread(1000);
+
+         // uncomment this to see failing test
+         worker.join();
+
+         // at this point node is not alone, so preload is not used
+         // the start of the cache must be blocked until state transfer is finished
+         cm3.startCaches(cacheName);
+         assertEquals(cm3.getCache(cacheName).size(), 3);
+      } finally {
+         sharedCacheLoader.set(false);
+      }
+   }
+
+   public static class DelayedUnmarshal implements Serializable {
+
+      private static final long serialVersionUID = 1L;
+
+      private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {
+         TestingUtil.sleepThread(2000);
+         in.defaultReadObject();
+      }
+
+      private void writeObject(ObjectOutputStream out) throws IOException {
+         out.defaultWriteObject();
+      }
+   }
+
 }",2012-11-30T18:42:42Z,604
"@@ -22,31 +22,30 @@
  */
 package org.infinispan.statetransfer;
 
-import java.io.File;
+import java.io.*;
 import java.lang.reflect.Method;
 import java.util.concurrent.Callable;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
 import java.util.concurrent.Future;
-import java.util.concurrent.ThreadFactory;
 
 import org.infinispan.Cache;
-import org.infinispan.config.CacheLoaderManagerConfig;
-import org.infinispan.config.Configuration;
-import org.infinispan.loaders.file.FileCacheStoreConfig;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.cache.FileCacheStoreConfigurationBuilder;
+import org.infinispan.loaders.CacheLoader;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.marshall.AdvancedExternalizer;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
+import org.infinispan.transaction.LockingMode;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.testng.annotations.AfterMethod;
 import org.testng.annotations.BeforeTest;
-import org.testng.annotations.Optional;
-import org.testng.annotations.Parameters;
 import org.testng.annotations.Test;
 
 import static org.infinispan.statetransfer.StateTransferTestingUtil.*;
+import static org.testng.Assert.assertEquals;
 
 /**
  * StateTransferFileCacheStoreFunctionalTest.
@@ -69,7 +68,7 @@ protected Boolean initialValue() {
    String tmpDirectory3;
    String tmpDirectory4;
 
-   Configuration config;
+   ConfigurationBuilder configurationBuilder;
 
    @BeforeTest
    protected void setUpTempDir() {
@@ -95,26 +94,26 @@ protected void clearTempDir() {
    @Override
    protected void createCacheManagers() throws Throwable {
       // This impl only really sets up a configuration for use later.
-      config = getDefaultClusteredConfig(Configuration.CacheMode.REPL_SYNC, true);
-      config.setSyncReplTimeout(30000);
-      config.setFetchInMemoryState(true);
-      config.setUseLockStriping(false); // reduces the odd chance of a key collision and deadlock
+      configurationBuilder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, true);
+      configurationBuilder.transaction().lockingMode(LockingMode.PESSIMISTIC);
+      configurationBuilder.clustering().sync().replTimeout(30000);
+      configurationBuilder.clustering().stateTransfer().fetchInMemoryState(true);
+      configurationBuilder.locking().useLockStriping(false); // reduces the odd chance of a key collision and deadlock
    }
 
-   protected CacheContainer createCacheManager(String tmpDirectory) {
-      // increment the DIMCS store id
-      FileCacheStoreConfig cfg = new FileCacheStoreConfig();
-      cfg.setLocation(tmpDirectory);
-      cfg.setPurgeSynchronously(true); // for more accurate unit testing
-      cfg.setFetchPersistentState(true);
+   protected EmbeddedCacheManager createCacheManager(String tmpDirectory) {
+      configurationBuilder.loaders().clearCacheLoaders();
+      configurationBuilder.loaders().shared(sharedCacheLoader.get());
 
-      CacheLoaderManagerConfig clmc = new CacheLoaderManagerConfig();
-      clmc.addCacheLoaderConfig(cfg);
-      clmc.setShared(sharedCacheLoader.get());
-      config.setCacheLoaderManagerConfig(clmc);
+      FileCacheStoreConfigurationBuilder fcsBuilder = configurationBuilder.loaders().addFileCacheStore();
+      fcsBuilder
+            .purgeSynchronously(true) // for more accurate unit testing
+            .fetchPersistentState(true)
+            .purgeOnStartup(false)
+            .location(tmpDirectory);
 
       EmbeddedCacheManager cm = addClusterEnabledCacheManager();
-      cm.defineConfiguration(cacheName, config.clone());
+      cm.defineConfiguration(cacheName, configurationBuilder.build());
       return cm;
    }
 
@@ -270,6 +269,4 @@ public Void call() throws Exception {
          if (cm40 != null) cm40.stop();
       }
    }
-
-
 }",2012-11-30T18:42:42Z,223
"@@ -23,13 +23,15 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.Cache;
-import org.infinispan.config.Configuration;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
 import org.infinispan.test.fwk.TransportFlags;
+import org.infinispan.transaction.LockingMode;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.testng.annotations.Test;
@@ -58,7 +60,7 @@ public class StateTransferFunctionalTest extends MultipleCacheManagersTest {
    public static final Integer TWENTY = 20;
    public static final Integer FORTY = 40;
 
-   Configuration config;
+   ConfigurationBuilder configurationBuilder;
    protected final String cacheName;
 
    private volatile int testCount = 0;
@@ -75,16 +77,16 @@ public StateTransferFunctionalTest(String testCacheName) {
    }
 
    protected void createCacheManagers() throws Throwable {
-      // This impl only really sets up a configuration for use later.
-      config = getDefaultClusteredConfig(Configuration.CacheMode.REPL_SYNC, true);
-      config.setSyncReplTimeout(30000);
-      config.setFetchInMemoryState(true);
-      config.setUseLockStriping(false); // reduces the odd chance of a key collision and deadlock
+      configurationBuilder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, true);
+      configurationBuilder.transaction().lockingMode(LockingMode.PESSIMISTIC);
+      configurationBuilder.clustering().sync().replTimeout(30000);
+      configurationBuilder.clustering().stateTransfer().fetchInMemoryState(true);
+      configurationBuilder.locking().useLockStriping(false); // reduces the odd chance of a key collision and deadlock
    }
 
    protected EmbeddedCacheManager createCacheManager() {
       EmbeddedCacheManager cm = addClusterEnabledCacheManager(new TransportFlags().withMerge(true));
-      cm.defineConfiguration(cacheName, config.clone());
+      cm.defineConfiguration(cacheName, configurationBuilder.build());
       return cm;
    }
 
@@ -143,12 +145,12 @@ public void run() {
             try {
                if (tx)
                   tm.begin();
-               cache.put(""test"" + c, c++);
+               cache.put(""test"" + c, c);
                if (tx)
                   tm.commit();
                success = true;
+               c++;
             } catch (Exception e) {
-               c--;
                log.errorf(""Error writing key test%s"", c, e);
                stopThread();
             } finally {
@@ -198,7 +200,7 @@ public void testInitialStateTransferCacheNotPresent(Method m) throws Exception {
       node.waitForJoin(60000, cache1, cache2);
       node.verifyStateTransfer(new CacheVerifier(cache2));
 
-      cacheManager1.defineConfiguration(""otherCache"", config.clone());
+      cacheManager1.defineConfiguration(""otherCache"", configurationBuilder.build());
       cacheManager1.getCache(""otherCache"");
       logTestEnd(m);
    }",2012-11-30T18:42:42Z,49
"@@ -174,8 +174,8 @@ public void run() {
                if (tx) tm.begin();
                cache.put(""test"" + c, new PojoValue(c));
                cache.remove(""test"" + c);
-               c++;
                if (tx) tm.commit();
+               c++;
                if (c % 1000 == 0) TestingUtil.sleepThread(1); // Slow it down a bit
             }
             catch (Exception e) {",2012-11-30T18:42:42Z,605
"@@ -0,0 +1,109 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+/**
+ * AbstractRemoteCacheStoreConfigurationChildBuilder.
+ *
+ * @author Tristan Tarrant
+ * @since 5.2
+ */
+public class AbstractRemoteCacheStoreConfigurationChildBuilder implements RemoteCacheStoreConfigurationChildBuilder {
+   private final RemoteCacheStoreConfigurationBuilder builder;
+
+   protected AbstractRemoteCacheStoreConfigurationChildBuilder(RemoteCacheStoreConfigurationBuilder builder) {
+      this.builder = builder;
+   }
+
+   @Override
+   public RemoteServerConfigurationBuilder addServer() {
+      return builder.addServer();
+   }
+
+   @Override
+   public ExecutorFactoryConfigurationBuilder asyncExecutorFactory() {
+      return builder.asyncExecutorFactory();
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder balancingStrategy(String balancingStrategy) {
+      return builder.balancingStrategy(balancingStrategy);
+   }
+
+   @Override
+   public ConnectionPoolConfigurationBuilder connectionPool() {
+      return builder.connectionPool();
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder connectionTimeout(long connectionTimeout) {
+      return builder.connectionTimeout(connectionTimeout);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder forceReturnValues(boolean forceReturnValues) {
+      return builder.forceReturnValues(forceReturnValues);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder keySizeEstimate(int keySizeEstimate) {
+      return builder.keySizeEstimate(keySizeEstimate);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder marshaller(String marshaller) {
+      return builder.marshaller(marshaller);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder pingOnStartup(boolean pingOnStartup) {
+      return builder.pingOnStartup(pingOnStartup);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder protocolVersion(String protocolVersion) {
+      return builder.protocolVersion(protocolVersion);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder remoteCacheName(String remoteCacheName) {
+      return builder.remoteCacheName(remoteCacheName);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder socketTimeout(long socketTimeout) {
+      return builder.socketTimeout(socketTimeout);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder tcpNoDelay(boolean tcpNoDelay) {
+      return builder.tcpNoDelay(tcpNoDelay);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder transportFactory(String transportFactory) {
+      return builder.transportFactory(transportFactory);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder valueSizeEstimate(int valueSizeEstimate) {
+      return builder.valueSizeEstimate(valueSizeEstimate);
+   }
+
+}",2012-09-04T16:57:31Z,606
"@@ -0,0 +1,91 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * Enumerates the attributes used by the Remote cache store configuration
+ *
+ * @author Tristan Tarrant
+ * @since 5.2
+ */
+public enum Attribute {
+   // must be first
+   UNKNOWN(null),
+
+   BALANCING_STRATEGY(""balancingStrategy""),
+   CONNECT_TIMEOUT(""connectTimeout""),
+   EXHAUSTED_ACTION(""exhaustedAction""),
+   FACTORY(""factory""),
+   FORCE_RETURN_VALUES(""forceReturnValues""),
+   HOST(""host""),
+   MARSHALLER(""marshaller""),
+   MAX_ACTIVE(""maxActive""),
+   MAX_IDLE(""maxIdle""),
+   MAX_TOTAL(""maxTotal""),
+   MIN_EVICTABLE_IDLE_TIME(""minEvictableIdleTime""),
+   MIN_IDLE(""minIdle""),
+   KEY_SIZE_ESTIMATE(""keySizeEstimate""),
+   PING_ON_STARTUP(""pingOnStartup""),
+   PORT(""port""),
+   PROTOCOL_VERSION(""protocolVersion""),
+   REMOTE_CACHE_NAME(""remoteCacheName""),
+   SOCKET_TIMEOUT(""socketTimeout""),
+   TCP_NO_DELAY(""tcpNoDelay""),
+   TEST_WHILE_IDLE(""testWhileIdle""),
+   TIME_BETWEEN_EVICTION_RUNS(""timeBetweenEvictionRuns""),
+   TRANSPORT_FACTORY(""transportFactory""),
+   VALUE_SIZE_ESTIMATE(""valueSizeEstimate""),
+   ;
+
+   private final String name;
+
+   private Attribute(final String name) {
+      this.name = name;
+   }
+
+   /**
+    * Get the local name of this element.
+    *
+    * @return the local name
+    */
+   public String getLocalName() {
+      return name;
+   }
+
+   private static final Map<String, Attribute> attributes;
+
+   static {
+      final Map<String, Attribute> map = new HashMap<String, Attribute>(64);
+      for (Attribute attribute : values()) {
+         final String name = attribute.getLocalName();
+         if (name != null) {
+            map.put(name, attribute);
+         }
+      }
+      attributes = map;
+   }
+
+   public static Attribute forName(final String localName) {
+      final Attribute attribute = attributes.get(localName);
+      return attribute == null ? UNKNOWN : attribute;
+   }
+}",2012-09-04T16:57:31Z,607
"@@ -0,0 +1,83 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+public class ConnectionPoolConfiguration {
+   private final ExhaustedAction exhaustedAction;
+   private final int maxActive;
+   private final int maxTotal;
+   private final int maxIdle;
+   private final int minIdle;
+   private final long timeBetweenEvictionRuns;
+   private final long minEvictableIdleTime;
+   private final boolean testWhileIdle;
+
+   ConnectionPoolConfiguration(ExhaustedAction exhaustedAction, int maxActive, int maxTotal, int maxIdle, int minIdle,
+         long timeBetweenEvictionRuns, long minEvictableIdleTime, boolean testWhileIdle) {
+      this.exhaustedAction = exhaustedAction;
+      this.maxActive = maxActive;
+      this.maxTotal = maxTotal;
+      this.maxIdle = maxIdle;
+      this.minIdle = minIdle;
+      this.timeBetweenEvictionRuns = timeBetweenEvictionRuns;
+      this.minEvictableIdleTime = minEvictableIdleTime;
+      this.testWhileIdle = testWhileIdle;
+   }
+
+   public ExhaustedAction exhaustedAction() {
+      return exhaustedAction;
+   }
+
+   public int maxActive() {
+      return maxActive;
+   }
+
+   public int maxTotal() {
+      return maxTotal;
+   }
+
+   public int maxIdle() {
+      return maxIdle;
+   }
+
+   public int minIdle() {
+      return minIdle;
+   }
+
+   public long timeBetweenEvictionRuns() {
+      return timeBetweenEvictionRuns;
+   }
+
+   public long minEvictableIdleTime() {
+      return minEvictableIdleTime;
+   }
+
+   public boolean testWhileIdle() {
+      return testWhileIdle;
+   }
+
+   @Override
+   public String toString() {
+      return ""ConnectionPoolConfiguration [exhaustedAction="" + exhaustedAction + "", maxActive="" + maxActive
+            + "", maxTotal="" + maxTotal + "", maxIdle="" + maxIdle + "", minIdle="" + minIdle + "", timeBetweenEvictionRuns=""
+            + timeBetweenEvictionRuns + "", minEvictableIdleTime="" + minEvictableIdleTime + "", testWhileIdle=""
+            + testWhileIdle + ""]"";
+   }
+
+}",2012-09-04T16:57:31Z,608
"@@ -0,0 +1,101 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+import org.infinispan.configuration.Builder;
+
+public class ConnectionPoolConfigurationBuilder extends AbstractRemoteCacheStoreConfigurationChildBuilder implements
+      Builder<ConnectionPoolConfiguration> {
+   private ExhaustedAction exhaustedAction = ExhaustedAction.WAIT;
+   private int maxActive = -1;
+   private int maxTotal = -1;
+   private int maxIdle = -1;
+   private int minIdle = 1;
+   private long timeBetweenEvictionRuns = 120000;
+   private long minEvictableIdleTime = 1800000;
+   private boolean testWhileIdle = true;
+
+   ConnectionPoolConfigurationBuilder(RemoteCacheStoreConfigurationBuilder builder) {
+      super(builder);
+   }
+
+   public ConnectionPoolConfigurationBuilder exhaustedAction(ExhaustedAction exhaustedAction) {
+      this.exhaustedAction = exhaustedAction;
+      return this;
+   }
+
+   public ConnectionPoolConfigurationBuilder maxActive(int maxActive) {
+      this.maxActive = maxActive;
+      return this;
+   }
+
+   public ConnectionPoolConfigurationBuilder maxTotal(int maxTotal) {
+      this.maxTotal = maxTotal;
+      return this;
+   }
+
+   public ConnectionPoolConfigurationBuilder maxIdle(int maxIdle) {
+      this.maxIdle = maxIdle;
+      return this;
+   }
+
+   public ConnectionPoolConfigurationBuilder minIdle(int minIdle) {
+      this.minIdle = minIdle;
+      return this;
+   }
+
+   public ConnectionPoolConfigurationBuilder timeBetweenEvictionRuns(long timeBetweenEvictionRuns) {
+      this.timeBetweenEvictionRuns = timeBetweenEvictionRuns;
+      return this;
+   }
+
+   public ConnectionPoolConfigurationBuilder minEvictableIdleTime(long minEvictableIdleTime) {
+      this.minEvictableIdleTime = minEvictableIdleTime;
+      return this;
+   }
+
+   public ConnectionPoolConfigurationBuilder testWhileIdle(boolean testWhileIdle) {
+      this.testWhileIdle = testWhileIdle;
+      return this;
+   }
+
+   @Override
+   public void validate() {
+   }
+
+   @Override
+   public ConnectionPoolConfiguration create() {
+      return new ConnectionPoolConfiguration(exhaustedAction, maxActive, maxTotal, maxIdle, minIdle, timeBetweenEvictionRuns,
+            minEvictableIdleTime, testWhileIdle);
+   }
+
+   @Override
+   public ConnectionPoolConfigurationBuilder read(ConnectionPoolConfiguration template) {
+      exhaustedAction = template.exhaustedAction();
+      maxActive = template.maxActive();
+      maxTotal = template.maxTotal();
+      maxIdle = template.maxIdle();
+      minIdle = template.minIdle();
+      timeBetweenEvictionRuns = template.timeBetweenEvictionRuns();
+      minEvictableIdleTime = template.minEvictableIdleTime();
+      testWhileIdle = template.testWhileIdle();
+      return this;
+   }
+
+}",2012-09-04T16:57:31Z,608
"@@ -0,0 +1,80 @@
+/*
+ * JBoss, Home of Professional Open Source.
+ * Copyright 2011, Red Hat, Inc., and individual contributors
+ * as indicated by the @author tags. See the copyright.txt file in the
+ * distribution for a full listing of individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.loaders.remote.configuration;
+
+import java.util.HashMap;
+import java.util.Map;
+
+import org.infinispan.loaders.file.FileCacheStore;
+
+/**
+ * An enumeration of all the recognized XML element local names for the {@link FileCacheStore}
+ *
+ * @author Tristan Tarrant
+ * @since 5.2
+ */
+public enum Element {
+    // must be first
+    UNKNOWN(null),
+
+    ASYNC_TRANSPORT_EXECUTOR(""asyncTransportExecutor""),
+    CONNECTION_POOL(""connectionPool""),
+    PROPERTIES(""properties""),
+    REMOTE_STORE(""remoteStore""),
+    SERVERS(""servers""),
+    SERVER(""server"")
+    ;
+
+    private final String name;
+
+    Element(final String name) {
+        this.name = name;
+    }
+
+    /**
+     * Get the local name of this element.
+     *
+     * @return the local name
+     */
+    public String getLocalName() {
+        return name;
+    }
+
+    private static final Map<String, Element> MAP;
+
+    static {
+        final Map<String, Element> map = new HashMap<String, Element>(8);
+        for (Element element : values()) {
+            final String name = element.getLocalName();
+            if (name != null) {
+               map.put(name, element);
+            }
+        }
+        MAP = map;
+    }
+
+    public static Element forName(final String localName) {
+        final Element element = MAP.get(localName);
+        return element == null ? UNKNOWN : element;
+    }
+}",2012-09-04T16:57:31Z,609
"@@ -0,0 +1,45 @@
+/*
+ * Copyright 2011 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+package org.infinispan.loaders.remote.configuration;
+
+import org.infinispan.configuration.AbstractTypedPropertiesConfiguration;
+import org.infinispan.executors.ExecutorFactory;
+import org.infinispan.util.TypedProperties;
+
+public class ExecutorFactoryConfiguration extends AbstractTypedPropertiesConfiguration {
+
+   private final ExecutorFactory factory;
+   
+   ExecutorFactoryConfiguration(ExecutorFactory factory, TypedProperties properties) {
+      super(properties);
+      this.factory = factory;
+   }
+
+   public ExecutorFactory factory() {
+      return factory;
+   }
+
+   @Override
+   public String toString() {
+      return ""ExecutorFactoryConfiguration{"" +
+            ""factory="" + factory +
+            '}';
+   }
+
+}
\ No newline at end of file",2012-09-04T16:57:31Z,610
"@@ -0,0 +1,106 @@
+/*
+ * Copyright 2011 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+package org.infinispan.loaders.remote.configuration;
+
+import java.util.Properties;
+
+import org.infinispan.configuration.Builder;
+import org.infinispan.executors.DefaultExecutorFactory;
+import org.infinispan.executors.ExecutorFactory;
+import org.infinispan.util.TypedProperties;
+
+/**
+ * Configures executor factory.
+ */
+public class ExecutorFactoryConfigurationBuilder extends AbstractRemoteCacheStoreConfigurationChildBuilder implements Builder<ExecutorFactoryConfiguration> {
+
+   private ExecutorFactory factory = new DefaultExecutorFactory();
+   private Properties properties;
+
+   ExecutorFactoryConfigurationBuilder(RemoteCacheStoreConfigurationBuilder builder) {
+      super(builder);
+      this.properties = new Properties();
+   }
+
+   /**
+    * Specify factory class for executor
+    *
+    * NOTE: Currently Infinispan will not use the object instance, but instead instantiate a new
+    * instance of the class. Therefore, do not expect any state to survive, and provide a no-args
+    * constructor to any instance. This will be resolved in Infinispan 5.2.0
+    *
+    * @param factory
+    *           clazz
+    * @return this ExecutorFactoryConfig
+    */
+   public ExecutorFactoryConfigurationBuilder factory(ExecutorFactory factory) {
+      this.factory = factory;
+      return this;
+   }
+
+   /**
+    * Add key/value property pair to this executor factory configuration
+    *
+    * @param key
+    *           property key
+    * @param value
+    *           property value
+    * @return previous value if exists, null otherwise
+    */
+   public ExecutorFactoryConfigurationBuilder addProperty(String key, String value) {
+      this.properties.put(key, value);
+      return this;
+   }
+
+   /**
+    * Set key/value properties to this executor factory configuration
+    *
+    * @param props
+    *           Properties
+    * @return this ExecutorFactoryConfig
+    */
+   public ExecutorFactoryConfigurationBuilder withProperties(Properties props) {
+      this.properties = props;
+      return this;
+   }
+
+   @Override
+   public void validate() {
+      // No-op, no validation required
+   }
+
+   @Override
+   public ExecutorFactoryConfiguration create() {
+      return new ExecutorFactoryConfiguration(factory, TypedProperties.toTypedProperties(properties));
+   }
+
+   @Override
+   public ExecutorFactoryConfigurationBuilder read(ExecutorFactoryConfiguration template) {
+      this.factory = template.factory();
+      this.properties = template.properties();
+
+      return this;
+   }
+
+   @Override
+   public String toString() {
+      return ""ExecutorFactoryConfigurationBuilder{"" + ""factory="" + factory + "", properties="" + properties + '}';
+   }
+
+}
\ No newline at end of file",2012-09-04T16:57:31Z,610
"@@ -0,0 +1,25 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+public enum ExhaustedAction {
+   EXCEPTION,
+   WAIT,
+   CREATE_NEW
+}",2012-09-04T16:57:31Z,611
"@@ -0,0 +1,197 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+import java.util.Collections;
+import java.util.List;
+import java.util.Properties;
+
+import org.infinispan.client.hotrod.impl.ConfigurationProperties;
+import org.infinispan.configuration.BuiltBy;
+import org.infinispan.configuration.cache.AbstractStoreConfiguration;
+import org.infinispan.configuration.cache.AsyncStoreConfiguration;
+import org.infinispan.configuration.cache.LegacyLoaderAdapter;
+import org.infinispan.configuration.cache.SingletonStoreConfiguration;
+import org.infinispan.loaders.remote.RemoteCacheStoreConfig;
+import org.infinispan.util.TypedProperties;
+
+@BuiltBy(RemoteCacheStoreConfigurationBuilder.class)
+public class RemoteCacheStoreConfiguration extends AbstractStoreConfiguration implements
+      LegacyLoaderAdapter<RemoteCacheStoreConfig> {
+
+   private final ExecutorFactoryConfiguration asyncExecutorFactory;
+   private final String balancingStrategy;
+   private final ConnectionPoolConfiguration connectionPool;
+   private final long connectionTimeout;
+   private final boolean forceReturnValues;
+   private final int keySizeEstimate;
+   private final String marshaller;
+   private final boolean pingOnStartup;
+   private final String protocolVersion;
+   private final String remoteCacheName;
+   private final List<RemoteServerConfiguration> servers;
+   private final long socketTimeout;
+   private final boolean tcpNoDelay;
+   private final String transportFactory;
+   private final int valueSizeEstimate;
+
+   RemoteCacheStoreConfiguration(ExecutorFactoryConfiguration asyncExecutorFactory, String balancingStrategy,
+         ConnectionPoolConfiguration connectionPool, long connectionTimeout, boolean forceReturnValues,
+         int keySizeEstimate, String marshaller, boolean pingOnStartup, String protocolVersion, String remoteCacheName,
+         List<RemoteServerConfiguration> servers, long socketTimeout, boolean tcpNoDelay, String transportFactory,
+         int valueSizeEstimate, boolean purgeOnStartup, boolean purgeSynchronously, int purgerThreads,
+         boolean fetchPersistentState, boolean ignoreModifications, TypedProperties properties,
+         AsyncStoreConfiguration asyncStoreConfiguration, SingletonStoreConfiguration singletonStoreConfiguration) {
+      super(purgeOnStartup, purgeSynchronously, purgerThreads, fetchPersistentState, ignoreModifications, properties,
+            asyncStoreConfiguration, singletonStoreConfiguration);
+      this.asyncExecutorFactory = asyncExecutorFactory;
+      this.balancingStrategy = balancingStrategy;
+      this.connectionPool = connectionPool;
+      this.connectionTimeout = connectionTimeout;
+      this.forceReturnValues = forceReturnValues;
+      this.keySizeEstimate = keySizeEstimate;
+      this.marshaller = marshaller;
+      this.pingOnStartup = pingOnStartup;
+      this.protocolVersion = protocolVersion;
+      this.remoteCacheName = remoteCacheName;
+      this.servers = Collections.unmodifiableList(servers);
+      this.socketTimeout = socketTimeout;
+      this.tcpNoDelay = tcpNoDelay;
+      this.transportFactory = transportFactory;
+      this.valueSizeEstimate = valueSizeEstimate;
+   }
+
+   public ExecutorFactoryConfiguration asyncExecutorFactory() {
+      return asyncExecutorFactory;
+   }
+
+   public String balancingStrategy() {
+      return balancingStrategy;
+   }
+
+   public ConnectionPoolConfiguration connectionPool() {
+      return connectionPool;
+   }
+
+   public long connectionTimeout() {
+      return connectionTimeout;
+   }
+
+   public boolean forceReturnValues() {
+      return forceReturnValues;
+   }
+
+   public int keySizeEstimate() {
+      return keySizeEstimate;
+   }
+
+   public String marshaller() {
+      return marshaller;
+   }
+
+   public boolean pingOnStartup() {
+      return pingOnStartup;
+   }
+
+   public String protocolVersion() {
+      return protocolVersion;
+   }
+
+   public String remoteCacheName() {
+      return remoteCacheName;
+   }
+
+   public List<RemoteServerConfiguration> servers() {
+      return servers;
+   }
+
+   public long socketTimeout() {
+      return socketTimeout;
+   }
+
+   public boolean tcpNoDelay() {
+      return tcpNoDelay;
+   }
+
+   public String transportFactory() {
+      return transportFactory;
+   }
+
+   public int valueSizeEstimate() {
+      return valueSizeEstimate;
+   }
+
+   @Override
+   public RemoteCacheStoreConfig adapt() {
+      RemoteCacheStoreConfig config = new RemoteCacheStoreConfig();
+      // StoreConfiguration
+      config.fetchPersistentState(fetchPersistentState());
+      config.ignoreModifications(ignoreModifications());
+      config.purgeOnStartup(purgeOnStartup());
+      config.purgeSynchronously(purgeSynchronously());
+      config.purgerThreads(purgerThreads());
+
+      // RemoteCacheStoreConfiguration
+      config.setRemoteCacheName(remoteCacheName);
+      config.setAsyncExecutorFactory(asyncExecutorFactory.factory());
+
+      TypedProperties p = new TypedProperties();
+
+      // Async Executor
+      p.putAll(asyncExecutorFactory.properties());
+
+      // Connection Pool
+      p.put(""maxActive"", Integer.toString(connectionPool.maxActive()));
+      p.put(""maxIdle"", Integer.toString(connectionPool.maxIdle()));
+      p.put(""maxTotal"", Integer.toString(connectionPool.maxTotal()));
+      p.put(""minIdle"", connectionPool.minIdle());
+      p.put(""minEvictableIdleTimeMillis"", Long.toString(connectionPool.minEvictableIdleTime()));
+      p.put(""testWhileIdle"", Boolean.toString(connectionPool.testWhileIdle()));
+      p.put(""timeBetweenEvictionRunsMillis"", Long.toString(connectionPool.timeBetweenEvictionRuns()));
+      p.put(""whenExhaustedAction"", Integer.toString(connectionPool.exhaustedAction().ordinal()));
+
+      config.setTypedProperties(p);
+
+      Properties hrp = new Properties();
+      hrp.put(ConfigurationProperties.CONNECT_TIMEOUT, Long.toString(connectionTimeout));
+      hrp.put(ConfigurationProperties.FORCE_RETURN_VALUES, Boolean.toString(forceReturnValues));
+      hrp.put(ConfigurationProperties.KEY_SIZE_ESTIMATE, Integer.toString(keySizeEstimate));
+      hrp.put(ConfigurationProperties.PING_ON_STARTUP, Boolean.toString(pingOnStartup));
+      StringBuilder serverList = new StringBuilder();
+      for (RemoteServerConfiguration server : servers) {
+         if (serverList.length() > 0)
+            serverList.append("";"");
+         serverList.append(server.host());
+         serverList.append("":"");
+         serverList.append(server.port());
+      }
+      hrp.put(ConfigurationProperties.SERVER_LIST, serverList.toString());
+      hrp.put(ConfigurationProperties.SO_TIMEOUT, Long.toString(socketTimeout));
+      hrp.put(ConfigurationProperties.TCP_NO_DELAY, Boolean.toString(tcpNoDelay));
+      hrp.put(ConfigurationProperties.VALUE_SIZE_ESTIMATE, Integer.toString(valueSizeEstimate));
+      if (marshaller != null)
+         hrp.put(ConfigurationProperties.MARSHALLER, marshaller);
+      if (transportFactory != null)
+         hrp.put(ConfigurationProperties.TRANSPORT_FACTORY, transportFactory);
+
+      config.setHotRodClientProperties(hrp);
+      return config;
+   }
+
+}",2012-09-04T16:57:31Z,612
"@@ -0,0 +1,189 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.infinispan.api.BasicCacheContainer;
+import org.infinispan.client.hotrod.impl.ConfigurationProperties;
+import org.infinispan.client.hotrod.impl.transport.tcp.RoundRobinBalancingStrategy;
+import org.infinispan.configuration.cache.AbstractStoreConfigurationBuilder;
+import org.infinispan.configuration.cache.LoadersConfigurationBuilder;
+import org.infinispan.loaders.remote.RemoteCacheStore;
+import org.infinispan.util.TypedProperties;
+
+/**
+ * RemoteCacheStoreConfigurationBuilde. Configures a {@link RemoteCacheStore}
+ *
+ * @author Tristan Tarrant
+ * @since 5.2
+ */
+public class RemoteCacheStoreConfigurationBuilder extends
+      AbstractStoreConfigurationBuilder<RemoteCacheStoreConfiguration, RemoteCacheStoreConfigurationBuilder> implements
+      RemoteCacheStoreConfigurationChildBuilder {
+   private final ExecutorFactoryConfigurationBuilder asyncExecutorFactory;
+   private String balancingStrategy = RoundRobinBalancingStrategy.class.getName();
+   private final ConnectionPoolConfigurationBuilder connectionPool;
+   private long connectionTimeout = ConfigurationProperties.DEFAULT_CONNECT_TIMEOUT;
+   private boolean forceReturnValues;
+   private int keySizeEstimate = ConfigurationProperties.DEFAULT_KEY_SIZE;
+   private String marshaller;
+   private boolean pingOnStartup = true;
+   private String protocolVersion;
+   private String remoteCacheName = BasicCacheContainer.DEFAULT_CACHE_NAME;
+   private List<RemoteServerConfigurationBuilder> servers = new ArrayList<RemoteServerConfigurationBuilder>();
+   private long socketTimeout = ConfigurationProperties.DEFAULT_SO_TIMEOUT;
+   private boolean tcpNoDelay = true;
+   private String transportFactory;
+   private int valueSizeEstimate = ConfigurationProperties.DEFAULT_VALUE_SIZE;
+
+   public RemoteCacheStoreConfigurationBuilder(LoadersConfigurationBuilder builder) {
+      super(builder);
+      asyncExecutorFactory = new ExecutorFactoryConfigurationBuilder(this);
+      connectionPool = new ConnectionPoolConfigurationBuilder(this);
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder self() {
+      return this;
+   }
+
+   @Override
+   public ExecutorFactoryConfigurationBuilder asyncExecutorFactory() {
+      return asyncExecutorFactory;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder balancingStrategy(String balancingStrategy) {
+      this.balancingStrategy = balancingStrategy;
+      return this;
+   }
+
+   @Override
+   public ConnectionPoolConfigurationBuilder connectionPool() {
+      return connectionPool;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder connectionTimeout(long connectionTimeout) {
+      this.connectionTimeout = connectionTimeout;
+      return this;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder forceReturnValues(boolean forceReturnValues) {
+      this.forceReturnValues = forceReturnValues;
+      return this;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder keySizeEstimate(int keySizeEstimate) {
+      this.keySizeEstimate = keySizeEstimate;
+      return this;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder marshaller(String marshaller) {
+      this.marshaller = marshaller;
+      return this;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder pingOnStartup(boolean pingOnStartup) {
+      this.pingOnStartup = pingOnStartup;
+      return this;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder protocolVersion(String protocolVersion) {
+      this.protocolVersion = protocolVersion;
+      return this;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder remoteCacheName(String remoteCacheName) {
+      this.remoteCacheName = remoteCacheName;
+      return this;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder socketTimeout(long socketTimeout) {
+      this.socketTimeout = socketTimeout;
+      return this;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder tcpNoDelay(boolean tcpNoDelay) {
+      this.tcpNoDelay = tcpNoDelay;
+      return this;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder transportFactory(String transportFactory) {
+      this.transportFactory = transportFactory;
+      return this;
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder valueSizeEstimate(int valueSizeEstimate) {
+      this.valueSizeEstimate = valueSizeEstimate;
+      return this;
+   }
+
+   @Override
+   public RemoteServerConfigurationBuilder addServer() {
+      RemoteServerConfigurationBuilder builder = new RemoteServerConfigurationBuilder(this);
+      this.servers.add(builder);
+      return builder;
+   }
+
+   @Override
+   public RemoteCacheStoreConfiguration create() {
+      List<RemoteServerConfiguration> remoteServers = new ArrayList<RemoteServerConfiguration>();
+      for (RemoteServerConfigurationBuilder server : servers) {
+         remoteServers.add(server.create());
+      }
+      return new RemoteCacheStoreConfiguration(asyncExecutorFactory.create(), balancingStrategy,
+            connectionPool.create(), connectionTimeout, forceReturnValues, keySizeEstimate, marshaller, pingOnStartup,
+            protocolVersion, remoteCacheName, remoteServers, socketTimeout, tcpNoDelay, transportFactory,
+            valueSizeEstimate, purgeOnStartup, purgeSynchronously, purgerThreads, fetchPersistentState,
+            ignoreModifications, TypedProperties.toTypedProperties(properties), async.create(), singletonStore.create());
+   }
+
+   @Override
+   public RemoteCacheStoreConfigurationBuilder read(RemoteCacheStoreConfiguration template) {
+      this.asyncExecutorFactory.read(template.asyncExecutorFactory());
+      this.balancingStrategy = template.balancingStrategy();
+      this.connectionPool.read(template.connectionPool());
+      this.connectionTimeout = template.connectionTimeout();
+      this.forceReturnValues = template.forceReturnValues();
+      this.keySizeEstimate = template.keySizeEstimate();
+      this.marshaller = template.marshaller();
+      this.pingOnStartup = template.pingOnStartup();
+      this.protocolVersion = template.protocolVersion();
+      this.remoteCacheName = template.remoteCacheName();
+      this.socketTimeout = template.socketTimeout();
+      this.tcpNoDelay = template.tcpNoDelay();
+      this.transportFactory = template.transportFactory();
+      this.valueSizeEstimate = template.valueSizeEstimate();
+      return this;
+   }
+
+}",2012-09-04T16:57:31Z,612
"@@ -0,0 +1,53 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+public interface RemoteCacheStoreConfigurationChildBuilder {
+
+   RemoteServerConfigurationBuilder addServer();
+
+   ExecutorFactoryConfigurationBuilder asyncExecutorFactory();
+
+   RemoteCacheStoreConfigurationBuilder balancingStrategy(String balancingStrategy);
+
+   ConnectionPoolConfigurationBuilder connectionPool();
+
+   RemoteCacheStoreConfigurationBuilder connectionTimeout(long connectionTimeout);
+
+   RemoteCacheStoreConfigurationBuilder forceReturnValues(boolean forceReturnValues);
+
+   RemoteCacheStoreConfigurationBuilder keySizeEstimate(int keySizeEstimate);
+
+   RemoteCacheStoreConfigurationBuilder marshaller(String marshaller);
+
+   RemoteCacheStoreConfigurationBuilder pingOnStartup(boolean pingOnStartup);
+
+   RemoteCacheStoreConfigurationBuilder protocolVersion(String protocolVersion);
+
+   RemoteCacheStoreConfigurationBuilder remoteCacheName(String remoteCacheName);
+
+   RemoteCacheStoreConfigurationBuilder socketTimeout(long socketTimeout);
+
+   RemoteCacheStoreConfigurationBuilder tcpNoDelay(boolean tcpNoDelay);
+
+   RemoteCacheStoreConfigurationBuilder transportFactory(String transportFactory);
+
+   RemoteCacheStoreConfigurationBuilder valueSizeEstimate(int valueSizeEstimate);
+
+}
\ No newline at end of file",2012-09-04T16:57:31Z,612
"@@ -0,0 +1,278 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+import static org.infinispan.util.StringPropertyReplacer.replaceProperties;
+
+import javax.xml.stream.XMLStreamConstants;
+import javax.xml.stream.XMLStreamException;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.cache.LoadersConfigurationBuilder;
+import org.infinispan.configuration.parsing.ConfigurationBuilderHolder;
+import org.infinispan.configuration.parsing.ConfigurationParser;
+import org.infinispan.configuration.parsing.Namespace;
+import org.infinispan.configuration.parsing.ParseUtils;
+import org.infinispan.configuration.parsing.Parser52;
+import org.infinispan.executors.ExecutorFactory;
+import org.infinispan.util.Util;
+import org.jboss.staxmapper.XMLExtendedStreamReader;
+
+/**
+ *
+ * JdbcCacheStoreConfigurationParser52.
+ *
+ * @author Tristan Tarrant
+ * @since 5.2
+ */
+public class RemoteCacheStoreConfigurationParser52 implements ConfigurationParser<ConfigurationBuilderHolder> {
+
+   private static final Namespace NAMESPACES[] = {
+         new Namespace(Namespace.INFINISPAN_NS_BASE_URI, ""remote"", Element.REMOTE_STORE.getLocalName(), 5, 2),
+         new Namespace("""", Element.REMOTE_STORE.getLocalName(), 0, 0) };
+
+   public RemoteCacheStoreConfigurationParser52() {
+   }
+
+   @Override
+   public Namespace[] getSupportedNamespaces() {
+      return NAMESPACES;
+   }
+
+   @Override
+   public void readElement(final XMLExtendedStreamReader reader, final ConfigurationBuilderHolder holder)
+         throws XMLStreamException {
+      ConfigurationBuilder builder = holder.getCurrentConfigurationBuilder();
+
+      Element element = Element.forName(reader.getLocalName());
+      switch (element) {
+      case REMOTE_STORE: {
+         parseRemoteStore(reader, builder.loaders(), holder.getClassLoader());
+         break;
+      }
+      default: {
+         throw ParseUtils.unexpectedElement(reader);
+      }
+      }
+   }
+
+   private void parseRemoteStore(final XMLExtendedStreamReader reader, LoadersConfigurationBuilder loadersBuilder,
+         ClassLoader classLoader) throws XMLStreamException {
+      RemoteCacheStoreConfigurationBuilder builder = new RemoteCacheStoreConfigurationBuilder(loadersBuilder);
+      parseRemoteStoreAttributes(reader, builder);
+
+      while (reader.hasNext() && (reader.nextTag() != XMLStreamConstants.END_ELEMENT)) {
+         Element element = Element.forName(reader.getLocalName());
+         switch (element) {
+         case ASYNC_TRANSPORT_EXECUTOR: {
+            parseAsyncTransportExecutor(reader, builder.asyncExecutorFactory(), classLoader);
+            break;
+         }
+         case CONNECTION_POOL: {
+            parseConnectionPool(reader, builder.connectionPool());
+            break;
+         }
+         case SERVERS: {
+            parseServers(reader, builder);
+            break;
+         }
+         default: {
+            Parser52.parseCommonStoreChildren(reader, builder);
+            break;
+         }
+         }
+      }
+      loadersBuilder.addStore(builder);
+   }
+
+   private void parseAsyncTransportExecutor(final XMLExtendedStreamReader reader,
+         final ExecutorFactoryConfigurationBuilder builder, ClassLoader classLoader) throws XMLStreamException {
+      for (int i = 0; i < reader.getAttributeCount(); i++) {
+         ParseUtils.requireNoNamespaceAttribute(reader, i);
+         String value = replaceProperties(reader.getAttributeValue(i));
+         Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
+         switch (attribute) {
+         case FACTORY: {
+            builder.factory(Util.<ExecutorFactory> getInstance(value, classLoader));
+            break;
+         }
+         default: {
+            throw ParseUtils.unexpectedAttribute(reader, i);
+         }
+         }
+      }
+
+      while (reader.hasNext() && (reader.nextTag() != XMLStreamConstants.END_ELEMENT)) {
+         Element element = Element.forName(reader.getLocalName());
+         switch (element) {
+         case PROPERTIES: {
+            builder.withProperties(Parser52.parseProperties(reader));
+            break;
+         }
+         default: {
+            throw ParseUtils.unexpectedElement(reader);
+         }
+         }
+      }
+   }
+
+   private void parseConnectionPool(XMLExtendedStreamReader reader, ConnectionPoolConfigurationBuilder builder) throws XMLStreamException {
+      for (int i = 0; i < reader.getAttributeCount(); i++) {
+         ParseUtils.requireNoNamespaceAttribute(reader, i);
+         String value = replaceProperties(reader.getAttributeValue(i));
+         Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
+         switch (attribute) {
+         case EXHAUSTED_ACTION: {
+            builder.exhaustedAction(ExhaustedAction.valueOf(value));
+            break;
+         }
+         case MAX_ACTIVE: {
+            builder.maxActive(Integer.parseInt(value));
+            break;
+         }
+         case MAX_IDLE: {
+            builder.maxIdle(Integer.parseInt(value));
+            break;
+         }
+         case MAX_TOTAL: {
+            builder.maxTotal(Integer.parseInt(value));
+            break;
+         }
+         case MIN_EVICTABLE_IDLE_TIME: {
+            builder.minEvictableIdleTime(Long.parseLong(value));
+            break;
+         }
+         case MIN_IDLE: {
+            builder.minIdle(Integer.parseInt(value));
+            break;
+         }
+         case TEST_WHILE_IDLE: {
+            builder.testWhileIdle(Boolean.parseBoolean(value));
+            break;
+         }
+         case TIME_BETWEEN_EVICTION_RUNS: {
+            builder.timeBetweenEvictionRuns(Long.parseLong(value));
+            break;
+         }
+         default: {
+            throw ParseUtils.unexpectedAttribute(reader, i);
+         }
+         }
+      }
+      ParseUtils.requireNoContent(reader);
+   }
+
+   private void parseServers(XMLExtendedStreamReader reader, RemoteCacheStoreConfigurationBuilder builder)
+         throws XMLStreamException {
+      while (reader.hasNext() && (reader.nextTag() != XMLStreamConstants.END_ELEMENT)) {
+         Element element = Element.forName(reader.getLocalName());
+         switch (element) {
+         case SERVER: {
+            parseServer(reader, builder.addServer());
+            break;
+         }
+         default:
+            throw ParseUtils.unexpectedElement(reader);
+         }
+      }
+   }
+
+   private void parseServer(XMLExtendedStreamReader reader, RemoteServerConfigurationBuilder builder)
+         throws XMLStreamException {
+      for (int i = 0; i < reader.getAttributeCount(); i++) {
+         ParseUtils.requireNoNamespaceAttribute(reader, i);
+         String value = replaceProperties(reader.getAttributeValue(i));
+         Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
+         switch (attribute) {
+         case HOST:
+            builder.host(value);
+            break;
+         case PORT:
+            builder.port(Integer.parseInt(value));
+            break;
+         default:
+            throw ParseUtils.unexpectedAttribute(reader, i);
+         }
+      }
+      ParseUtils.requireNoContent(reader);
+   }
+
+   private void parseRemoteStoreAttributes(XMLExtendedStreamReader reader, RemoteCacheStoreConfigurationBuilder builder)
+         throws XMLStreamException {
+      for (int i = 0; i < reader.getAttributeCount(); i++) {
+         ParseUtils.requireNoNamespaceAttribute(reader, i);
+         String value = replaceProperties(reader.getAttributeValue(i));
+         Attribute attribute = Attribute.forName(reader.getAttributeLocalName(i));
+         switch (attribute) {
+         case BALANCING_STRATEGY: {
+            builder.balancingStrategy(value);
+            break;
+         }
+         case CONNECT_TIMEOUT: {
+            builder.connectionTimeout(Long.parseLong(value));
+            break;
+         }
+         case FORCE_RETURN_VALUES: {
+            builder.forceReturnValues(Boolean.parseBoolean(value));
+            break;
+         }
+         case KEY_SIZE_ESTIMATE: {
+            builder.keySizeEstimate(Integer.parseInt(value));
+            break;
+         }
+         case MARSHALLER: {
+            builder.marshaller(value);
+            break;
+         }
+         case PING_ON_STARTUP: {
+            builder.pingOnStartup(Boolean.parseBoolean(value));
+            break;
+         }
+         case PROTOCOL_VERSION: {
+            builder.protocolVersion(value);
+            break;
+         }
+         case REMOTE_CACHE_NAME: {
+            builder.remoteCacheName(value);
+            break;
+         }
+         case SOCKET_TIMEOUT: {
+            builder.socketTimeout(Long.parseLong(value));
+            break;
+         }
+         case TCP_NO_DELAY: {
+            builder.tcpNoDelay(Boolean.parseBoolean(value));
+            break;
+         }
+         case TRANSPORT_FACTORY: {
+            builder.transportFactory(value);
+            break;
+         }
+         case VALUE_SIZE_ESTIMATE: {
+            builder.valueSizeEstimate(Integer.parseInt(value));
+            break;
+         }
+         default: {
+            Parser52.parseCommonStoreAttributes(reader, i, builder);
+            break;
+         }
+         }
+      }
+   }
+}",2012-09-04T16:57:31Z,612
"@@ -0,0 +1,38 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+public class RemoteServerConfiguration {
+   private final String host;
+   private final int port;
+
+   RemoteServerConfiguration(String host, int port) {
+      this.host = host;
+      this.port = port;
+   }
+
+   public String host() {
+      return host;
+   }
+
+   public int port() {
+      return port;
+   }
+
+}",2012-09-04T16:57:31Z,613
"@@ -0,0 +1,59 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+import org.infinispan.configuration.Builder;
+
+public class RemoteServerConfigurationBuilder extends AbstractRemoteCacheStoreConfigurationChildBuilder implements Builder<RemoteServerConfiguration> {
+   private String host;
+   private int port = 11222;
+
+   RemoteServerConfigurationBuilder(RemoteCacheStoreConfigurationBuilder builder) {
+      super(builder);
+   }
+
+   public RemoteServerConfigurationBuilder host(String host) {
+      this.host = host;
+      return this;
+   }
+
+   public RemoteServerConfigurationBuilder port(int port) {
+      this.port = port;
+      return this;
+   }
+
+   @Override
+   public void validate() {
+   }
+
+   @Override
+   public RemoteServerConfiguration create() {
+      return new RemoteServerConfiguration(host, port);
+   }
+
+   @Override
+   public RemoteServerConfigurationBuilder read(RemoteServerConfiguration template) {
+      this.host = template.host();
+      this.port = template.port();
+
+      return this;
+   }
+
+
+}",2012-09-04T16:57:31Z,613
"@@ -0,0 +1 @@
+org.infinispan.loaders.remote.configuration.RemoteCacheStoreConfigurationParser52",2012-09-04T16:57:31Z,614
"@@ -0,0 +1,247 @@
+<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?>
+
+<!--
+  ~ Copyright 2012 Red Hat, Inc. and/or its affiliates.
+  ~
+  ~ This is free software; you can redistribute it and/or modify it
+  ~ under the terms of the GNU Lesser General Public License as
+  ~ published by the Free Software Foundation; either version 2.1 of
+  ~ the License, or (at your option) any later version.
+  ~
+  ~ This software is distributed in the hope that it will be useful,
+  ~ but WITHOUT ANY WARRANTY; without even the implied warranty of
+  ~ MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  ~ Lesser General Public License for more details.
+  ~
+  ~ You should have received a copy of the GNU Lesser General Public
+  ~ License along with this library; if not, write to the Free Software
+  ~ Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+  ~ 02110-1301 USA
+  -->
+
+<xs:schema attributeFormDefault=""unqualified"" elementFormDefault=""qualified"" version=""1.0"" targetNamespace=""urn:infinispan:config:remote:5.2"" xmlns:tns=""urn:infinispan:config:remote:5.2"" xmlns:config=""urn:infinispan:config:5.2"" xmlns:xs=""http://www.w3.org/2001/XMLSchema"">
+  <xs:import namespace=""urn:infinispan:config:5.2"" schemaLocation=""http://www.infinispan.org/schemas/infinispan-config-5.2.xsd"" />
+
+  <xs:complexType name=""remoteStore"">
+    <xs:complexContent>
+      <xs:extension base=""config:store"">
+        <xs:sequence>
+          <xs:element name=""servers"" type=""tns:servers"" minOccurs=""0"">
+            <xs:annotation>
+              <xs:documentation>
+                This is the initial list of Hot Rod servers to connect to.
+              </xs:documentation>
+            </xs:annotation>
+          </xs:element>
+          <xs:element name=""connectionPool"" type=""tns:connectionPool"" minOccurs=""0"">
+            <xs:annotation>
+              <xs:documentation>
+                Configuration of the connection pool
+              </xs:documentation>
+            </xs:annotation>
+          </xs:element>
+          <xs:element name=""asyncTransportExecutor"" type=""config:executorFactory"" minOccurs=""0"">
+            <xs:annotation>
+              <xs:documentation>
+                Configuration for the executor service used for asynchronous work on the Transport, including asynchronous marshalling and Cache 'async operations' such as Cache.putAsync().
+              </xs:documentation>
+            </xs:annotation>
+          </xs:element>
+        </xs:sequence>
+        <xs:attribute name=""balancingStrategy"" type=""xs:string"" default=""org.infinispan.client.hotrod.impl.transport.tcp.RoundRobinBalancingStrategy"">
+          <xs:annotation>
+            <xs:documentation>
+              For replicated (vs distributed) Hot Rod server clusters, the client balances requests to the servers according to this strategy.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""connectionTimeout"" type=""xs:int"" default=""60000"">
+          <xs:annotation>
+            <xs:documentation>
+              This property defines the maximum socket connect timeout before giving up connecting to the server.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""forceReturnValues"" type=""xs:boolean"" default=""false"">
+          <xs:annotation>
+            <xs:documentation>
+              Whether or not to implicitly FORCE_RETURN_VALUE for all calls.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""keySizeEstimate"" type=""xs:int"" default=""64"">
+          <xs:annotation>
+            <xs:documentation>
+              The class name of the driver used for connecting to the database.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""marshaller"" type=""xs:string"">
+          <xs:annotation>
+            <xs:documentation>
+              Allows you to specify a custom {@link org.infinispan.marshall.Marshaller} implementation to serialize and deserialize user objects.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""pingOnStartup"" type=""xs:boolean"" default=""true"">
+          <xs:annotation>
+            <xs:documentation>
+              If true, a ping request is sent to a back end server in order to fetch cluster's topology.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""protocolVersion"" type=""xs:string"" default=""1.1"">
+          <xs:annotation>
+            <xs:documentation>
+              This property defines the protocol version that this client should use. Other valid values include 1.0.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""remoteCacheName"" type=""xs:string"">
+          <xs:annotation>
+            <xs:documentation>
+              The name of the remote cache in the remote infinispan cluster, to which to connect to. If unspecified, the default
+              cache will be used
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""socketTimeout"" type=""xs:int"" default=""60000"">
+          <xs:annotation>
+            <xs:documentation>
+              This property defines the protocol version that this client should use. Other valid values include 1.0.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""tcpNoDelay"" type=""xs:boolean"" default=""true"">
+          <xs:annotation>
+            <xs:documentation>
+              This property defines the protocol version that this client should use. Other valid values include 1.0.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""transportFactory"" type=""xs:string"">
+          <xs:annotation>
+            <xs:documentation>
+              Controls which transport to use. Currently only the TcpTransport is supported.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+        <xs:attribute name=""valueSizeEstimate"" type=""xs:int"" default=""512"">
+          <xs:annotation>
+            <xs:documentation>
+              his hint allows sizing of byte buffers when serializing and deserializing values, to minimize array resizing.
+            </xs:documentation>
+          </xs:annotation>
+        </xs:attribute>
+      </xs:extension>
+    </xs:complexContent>
+  </xs:complexType>
+
+  <xs:complexType name=""servers"">
+    <xs:sequence>
+      <xs:element name=""server"" minOccurs=""1"" maxOccurs=""unbounded"">
+        <xs:complexType>
+          <xs:attribute name=""host"" type=""xs:string"">
+            <xs:annotation>
+              <xs:documentation>
+                The hostname or ip address of a remote Hot Rod server
+              </xs:documentation>
+            </xs:annotation>
+          </xs:attribute>
+          <xs:attribute name=""port"" type=""xs:int"" default=""11222"">
+            <xs:annotation>
+              <xs:documentation>
+                The port on which the server is listening (default 11222)
+              </xs:documentation>
+            </xs:annotation>
+          </xs:attribute>
+        </xs:complexType>
+      </xs:element>
+    </xs:sequence>
+  </xs:complexType>
+
+  <xs:complexType name=""connectionPool"">
+    <xs:attribute name=""exhaustedAction"" type=""tns:exhaustedAction"" default=""WAIT"">
+      <xs:annotation>
+        <xs:documentation>
+           Specifies what happens when asking for a connection from a server's pool, and that pool is exhausted.
+        </xs:documentation>
+      </xs:annotation>
+    </xs:attribute>
+    <xs:attribute name=""maxActive"" type=""xs:int"" default=""-1"">
+      <xs:annotation>
+        <xs:documentation>
+          Controls the maximum number of connections per server that are allocated (checked out to client threads, or idle in the pool) at one time. When non-positive, there is no limit to the number of connections per server. When maxActive is reached, the connection pool for that server is said to be exhausted. The default setting for this parameter is -1, i.e. there is no limit.
+        </xs:documentation>
+      </xs:annotation>
+    </xs:attribute>
+    <xs:attribute name=""maxIdle"" type=""xs:int"" default=""-1"">
+      <xs:annotation>
+        <xs:documentation>
+          Controls the maximum number of idle persistent connections, per server, at any time. When negative, there is no limit to the number of connections that may be idle per server. The default setting for this parameter is -1.
+        </xs:documentation>
+      </xs:annotation>
+    </xs:attribute>
+    <xs:attribute name=""maxTotal"" type=""xs:int"" default=""-1"">
+      <xs:annotation>
+        <xs:documentation>
+          Sets a global limit on the number persistent connections that can be in circulation within the combined set of servers. When non-positive, there is no limit to the total number of persistent connections in circulation. When maxTotal is exceeded, all connections pools are exhausted. The default setting for this parameter is -1 (no limit). 
+        </xs:documentation>
+      </xs:annotation>
+    </xs:attribute>
+    <xs:attribute name=""minIdle"" type=""xs:int"" default=""1"">
+      <xs:annotation>
+        <xs:documentation>
+          Sets a target value for the minimum number of idle connections (per server) that should always be available. If this parameter is set to a positive number and timeBetweenEvictionRunsMillis > 0, each time the idle connection eviction thread runs, it will try to create enough idle instances so that there will be minIdle idle instances available for each server. The default setting for this parameter is 1. 
+        </xs:documentation>
+      </xs:annotation>
+    </xs:attribute>
+    <xs:attribute name=""timeBetweenEvictionRuns"" type=""xs:long"" default=""120000"">
+      <xs:annotation>
+        <xs:documentation>
+          Indicates how long the eviction thread should sleep before ""runs"" of examining idle connections. When non-positive, no eviction thread will be launched. The default setting for this parameter is 2 minutes. 
+        </xs:documentation>
+      </xs:annotation>
+    </xs:attribute>
+    <xs:attribute name=""minEvictableIdleTime"" type=""xs:long"" default=""1800000"">
+      <xs:annotation>
+        <xs:documentation>
+          Specifies the minimum amount of time that an connection may sit idle in the pool before it is eligible for eviction due to idle time. When non-positive, no connection will be dropped from the pool due to idle time alone. This setting has no effect unless timeBetweenEvictionRunsMillis > 0. The default setting for this parameter is 1800000(30 minutes).  
+        </xs:documentation>
+      </xs:annotation>
+    </xs:attribute>
+    <xs:attribute name=""testWhileIdle"" type=""xs:boolean"" default=""true"">
+      <xs:annotation>
+        <xs:documentation>
+          Indicates whether or not idle connections should be validated by sending an TCP packet to the server, during idle connection eviction runs. Connections that fail to validate will be dropped from the pool. This setting has no effect unless timeBetweenEvictionRunsMillis > 0. The default setting for this parameter is true.  
+        </xs:documentation>
+      </xs:annotation>
+    </xs:attribute>
+  </xs:complexType>
+  
+  <xs:simpleType name=""exhaustedAction"">
+    <xs:restriction base=""xs:string"">
+      <xs:enumeration value=""EXCEPTION"">
+        <xs:annotation>
+          <xs:documentation>
+            An exception will be thrown to the calling user
+          </xs:documentation>
+        </xs:annotation>
+      </xs:enumeration>
+      <xs:enumeration value=""WAIT"">
+        <xs:annotation>
+          <xs:documentation>
+            The caller will block (invoke waits until a new or idle connections is available. 
+          </xs:documentation>
+        </xs:annotation>
+      </xs:enumeration>
+      <xs:enumeration value=""CREATE_NEW"">
+        <xs:annotation>
+          <xs:documentation>
+            A new persistent connection will be created and returned (essentially making maxActive meaningless.) 
+          </xs:documentation>
+        </xs:annotation>
+      </xs:enumeration>
+    </xs:restriction>
+  </xs:simpleType>
+</xs:schema>",2012-09-04T16:57:31Z,615
"@@ -0,0 +1,46 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+import org.infinispan.client.hotrod.impl.ConfigurationProperties;
+import org.infinispan.configuration.cache.Configuration;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.remote.RemoteCacheStoreConfig;
+import org.testng.annotations.Test;
+
+@Test(groups = ""unit"", testName = ""loaders.jdbc.configuration.ConfigurationTest"")
+public class ConfigurationTest {
+
+   public void testRemoteCacheStoreConfigurationAdaptor() {
+      ConfigurationBuilder b = new ConfigurationBuilder();
+      b.loaders().addStore(RemoteCacheStoreConfigurationBuilder.class).remoteCacheName(""RemoteCache"").addServer()
+            .host(""one"").port(12111).addServer().host(""two"").connectionPool().maxActive(10).minIdle(5)
+            .exhaustedAction(ExhaustedAction.EXCEPTION).minEvictableIdleTime(10000);
+      Configuration configuration = b.build();
+      RemoteCacheStoreConfiguration store = (RemoteCacheStoreConfiguration) configuration.loaders().cacheLoaders()
+            .get(0);
+      assert store.servers().size() == 2;
+      assert store.connectionPool().exhaustedAction() == ExhaustedAction.EXCEPTION;
+      RemoteCacheStoreConfig cacheStoreConfig = store.adapt();
+      assert ""RemoteCache"".equals(cacheStoreConfig.getRemoteCacheName());
+      assert ""one:12111;two:11222"".equals(cacheStoreConfig.getHotRodClientProperties().get(
+            ConfigurationProperties.SERVER_LIST));
+      assert cacheStoreConfig.getTypedProperties().getIntProperty(""whenExhaustedAction"", -1) == 0;
+   }
+}
\ No newline at end of file",2012-09-04T16:57:31Z,616
"@@ -0,0 +1,82 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2009 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.loaders.remote.configuration;
+
+import static org.infinispan.test.TestingUtil.INFINISPAN_START_TAG;
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+
+import org.infinispan.configuration.cache.LoaderConfiguration;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.AbstractInfinispanTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterMethod;
+import org.testng.annotations.Test;
+
+@Test(groups = ""unit"", testName = ""loaders.remote.configuration.XmlFileParsingTest"")
+public class XmlFileParsingTest extends AbstractInfinispanTest {
+
+   private EmbeddedCacheManager cacheManager;
+
+   @AfterMethod(alwaysRun = true)
+   public void cleanup() {
+      TestingUtil.killCacheManagers(cacheManager);
+   }
+
+   public void testRemoteCacheStore() throws Exception {
+      String config = INFINISPAN_START_TAG +
+            ""   <default>\n"" +
+            ""     <loaders>\n"" +
+            ""       <remoteStore xmlns=\""urn:infinispan:config:remote:5.2\"" >\n"" +
+            ""         <servers>\n"" +
+            ""           <server host=\""one\"" />\n"" +
+            ""           <server host=\""two\"" />\n"" +
+            ""         </servers>\n"" +
+            ""         <connectionPool maxActive=\""10\"" exhaustedAction=\""CREATE_NEW\"" />\n"" +
+            ""         <asyncTransportExecutor>\n"" +
+            ""           <properties>\n"" +
+            ""             <property name=\""maxThreads\"" value=\""4\"" />"" +
+            ""           </properties>\n"" +
+            ""         </asyncTransportExecutor>\n"" +
+            ""         <async enabled=\""true\"" />\n"" +
+            ""       </remoteStore>\n"" +
+            ""     </loaders>\n"" +
+            ""   </default>\n"" +
+            TestingUtil.INFINISPAN_END_TAG;
+
+      RemoteCacheStoreConfiguration store = (RemoteCacheStoreConfiguration) buildCacheManagerWithCacheStore(config);
+      assert store.servers().size() == 2;
+      assert store.connectionPool().exhaustedAction() == ExhaustedAction.CREATE_NEW;
+      assert store.asyncExecutorFactory().properties().getIntProperty(""maxThreads"", 0) == 4;
+      assert store.async().enabled();
+   }
+
+   private LoaderConfiguration buildCacheManagerWithCacheStore(final String config) throws IOException {
+      InputStream is = new ByteArrayInputStream(config.getBytes());
+      cacheManager = TestCacheManagerFactory.fromStream(is);
+      assert cacheManager.getDefaultCacheConfiguration().loaders().cacheLoaders().size() == 1;
+      return cacheManager.getDefaultCacheConfiguration().loaders().cacheLoaders().get(0);
+   }
+}
\ No newline at end of file",2012-09-04T16:57:31Z,617
"@@ -60,14 +60,14 @@ public class ConfigurationProperties {
 
    // defaults
 
-   private static final int DEFAULT_KEY_SIZE = 64;
-   private static final int DEFAULT_VALUE_SIZE = 512;
-   private static final int DEFAULT_HOTROD_PORT = 11222;
-   private static final int DEFAULT_SO_TIMEOUT = 60000;
-   private static final int DEFAULT_CONNECT_TIMEOUT = 60000;
+   public static final int DEFAULT_KEY_SIZE = 64;
+   public static final int DEFAULT_VALUE_SIZE = 512;
+   public static final int DEFAULT_HOTROD_PORT = 11222;
+   public static final int DEFAULT_SO_TIMEOUT = 60000;
+   public static final int DEFAULT_CONNECT_TIMEOUT = 60000;
    public static final String PROTOCOL_VERSION_11 = ""1.1"";
    public static final String PROTOCOL_VERSION_10 = ""1.0"";
-   private static final String DEFAULT_PROTOCOL_VERSION = PROTOCOL_VERSION_11;
+   public static final String DEFAULT_PROTOCOL_VERSION = PROTOCOL_VERSION_11;
 
    private final TypedProperties props;
 ",2012-09-04T16:57:31Z,618
"@@ -63,6 +63,7 @@ public static void cleanup() throws IOException {
    protected CacheStore createCacheStore() throws Exception {
       CassandraCacheStore cs = new CassandraCacheStore();
       CassandraCacheStoreConfig clc = new CassandraCacheStoreConfig();
+      clc.setPurgeSynchronously(true);
       clc.setHost(""127.0.0.1"");
       clc.setAutoCreateKeyspace(true);
       clc.setKeySpace(""Infinispan"");",2012-08-24T10:05:51Z,81
"@@ -57,6 +57,7 @@ public class CloudCacheStoreTest extends BaseCacheStoreTest {
    private CacheStore buildCloudCacheStoreWithStubCloudService(String bucketName) throws CacheLoaderException {
       CloudCacheStore cs = new CloudCacheStore();
       CloudCacheStoreConfig cfg = new CloudCacheStoreConfig();
+      cfg.setPurgeSynchronously(true);
       cfg.setBucketPrefix(bucketName);
       cfg.setCloudService(""transient"");
       cfg.setIdentity(""unit-test-stub"");
@@ -71,6 +72,7 @@ private CacheStore buildCloudCacheStoreWithStubCloudService(String bucketName) t
       return cs;
    }
 
+   @Override
    protected CacheStore createCacheStore() throws Exception {
       CacheStore store = buildCloudCacheStoreWithStubCloudService(csBucket);
       store.start();",2012-08-24T10:05:51Z,619
"@@ -35,7 +35,7 @@ public class HBaseCacheStoreTest extends BaseCacheStoreTest {
 
    /**
     * Set embedded hbase up and spawn it in a new thread.
-    * 
+    *
     * @throws InterruptedException
     */
    @BeforeClass
@@ -59,6 +59,7 @@ protected CacheStore createCacheStore() throws Exception {
       HBaseCacheStore cs = new HBaseCacheStore();
       // This uses the default config settings in HBaseCacheStoreConfig
       HBaseCacheStoreConfig conf = new HBaseCacheStoreConfig();
+      conf.setPurgeSynchronously(true);
 
       if (USE_EMBEDDED) {
          // overwrite the ZooKeeper client port with the port from the embedded server",2012-08-24T10:05:51Z,620
"@@ -50,6 +50,7 @@ public class RemoteCacheStoreTest extends BaseCacheStoreTest {
    @Override
    protected CacheStore createCacheStore() throws Exception {
       RemoteCacheStoreConfig remoteCacheStoreConfig = new RemoteCacheStoreConfig();
+      remoteCacheStoreConfig.setPurgeSynchronously(true);
       remoteCacheStoreConfig.setUseDefaultRemoteCache(true);
       assert remoteCacheStoreConfig.isUseDefaultRemoteCache();
 
@@ -69,6 +70,7 @@ protected CacheStore createCacheStore() throws Exception {
       return remoteCacheStore;
    }
 
+   @Override
    @AfterMethod(alwaysRun = true)
    public void tearDown() {
       hrServer.stop();",2012-08-24T10:05:51Z,621
"@@ -26,8 +26,8 @@
 import org.infinispan.context.impl.NonTxInvocationContext;
 import org.infinispan.context.impl.RemoteTxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
+import org.infinispan.transaction.xa.LocalTransaction;
 import org.infinispan.transaction.xa.TransactionTable;
-import org.infinispan.transaction.xa.TransactionXaAdapter;
 
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
@@ -64,8 +64,8 @@ public InvocationContext createInvocationContext() {
          } else {
             localContext = (LocalTxInvocationContext) existing;
          }
-         TransactionXaAdapter xaAdapter = transactionTable.getXaCacheAdapter(tx);
-         localContext.setXaCache(xaAdapter);
+         LocalTransaction localTransaction = transactionTable.getLocalTransaction(tx);
+         localContext.setLocalTransaction(localTransaction);
          return localContext;
       } else {
          NonTxInvocationContext nonTxContext;",2010-12-09T08:05:14Z,85
"@@ -4,7 +4,7 @@
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.xa.GlobalTransaction;
-import org.infinispan.transaction.xa.TransactionXaAdapter;
+import org.infinispan.transaction.xa.LocalTransaction;
 import org.infinispan.util.BidirectionalMap;
 
 import javax.transaction.Transaction;
@@ -20,10 +20,10 @@
  */
 public class LocalTxInvocationContext extends AbstractTxInvocationContext {
 
-   private volatile TransactionXaAdapter xaAdapter;
+   private volatile LocalTransaction localTransaction;
 
    public Transaction getRunningTransaction() {
-      return xaAdapter.getTransaction();
+      return localTransaction.getTransaction();
    }
 
    public boolean isOriginLocal() {
@@ -35,53 +35,53 @@ public boolean isInTxScope() {
    }
 
    public Object getLockOwner() {
-      return xaAdapter.getGlobalTx();
+      return localTransaction.getGlobalTransaction();
    }
 
    public GlobalTransaction getGlobalTransaction() {
-      return xaAdapter.getGlobalTx();
+      return localTransaction.getGlobalTransaction();
    }
 
    public List<WriteCommand> getModifications() {
-      return xaAdapter == null ? null : xaAdapter.getModifications();
+      return localTransaction == null ? null : localTransaction.getModifications();
    }
 
-   public void setXaCache(TransactionXaAdapter xaAdapter) {
-      this.xaAdapter = xaAdapter;
+   public void setLocalTransaction(LocalTransaction localTransaction) {
+      this.localTransaction = localTransaction;
    }
 
    public CacheEntry lookupEntry(Object key) {
-      return xaAdapter != null ? xaAdapter.lookupEntry(key) : null;
+      return localTransaction != null ? localTransaction.lookupEntry(key) : null;
    }
 
    public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
-      return xaAdapter.getLookedUpEntries();
+      return localTransaction.getLookedUpEntries();
    }
 
    public void putLookedUpEntry(Object key, CacheEntry e) {
-      xaAdapter.putLookedUpEntry(key, e);
+      localTransaction.putLookedUpEntry(key, e);
    }
 
    public void putLookedUpEntries(Map<Object, CacheEntry> lookedUpEntries) {
       for (Map.Entry<Object, CacheEntry> ce: lookedUpEntries.entrySet()) {
-         xaAdapter.putLookedUpEntry(ce.getKey(), ce.getValue());
+         localTransaction.putLookedUpEntry(ce.getKey(), ce.getValue());
       }
    }
 
    public void removeLookedUpEntry(Object key) {
-      xaAdapter.removeLookedUpEntry(key);
+      localTransaction.removeLookedUpEntry(key);
    }
 
    public void clearLookedUpEntries() {
-      xaAdapter.clearLookedUpEntries();
+      localTransaction.clearLookedUpEntries();
    }
 
    @Override
    public boolean hasLockedKey(Object key) {
-      return xaAdapter != null && super.hasLockedKey(key);
+      return localTransaction != null && super.hasLockedKey(key);
    }
 
    public void remoteLocksAcquired(Collection<Address> nodes) {
-      xaAdapter.locksAcquired(nodes);
+      localTransaction.locksAcquired(nodes);
    }
 }",2010-12-09T08:05:14Z,86
"@@ -1,5 +1,7 @@
 package org.infinispan.interceptors;
 
+import org.infinispan.CacheException;
+import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.GetKeyValueCommand;
@@ -16,6 +18,7 @@
 import org.infinispan.config.Configuration;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
+import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
@@ -24,6 +27,7 @@
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.transaction.TransactionLog;
+import org.infinispan.transaction.xa.LocalTransaction;
 import org.infinispan.transaction.xa.TransactionTable;
 import org.infinispan.transaction.xa.TransactionXaAdapter;
 import org.rhq.helpers.pluginAnnotations.agent.DataType;
@@ -61,14 +65,20 @@ public class TxInterceptor extends CommandInterceptor {
    private final AtomicLong rollbacks = new AtomicLong(0);
    @ManagedAttribute(description = ""Enables or disables the gathering of statistics by this component"", writable = true)
    private boolean statisticsEnabled;
+   private CommandsFactory commandsFactory;
+   private InvocationContextContainer icc;
+   private InterceptorChain invoker;
 
 
    @Inject
-   public void init(TransactionManager tm, TransactionTable txTable, TransactionLog transactionLog, Configuration c) {
+   public void init(TransactionManager tm, TransactionTable txTable, TransactionLog transactionLog, Configuration c, CommandsFactory commandsFactory, InvocationContextContainer icc, InterceptorChain invoker) {
       this.configuration = c;
       this.tm = tm;
       this.transactionLog = transactionLog;
       this.txTable = txTable;
+      this.commandsFactory = commandsFactory;
+      this.icc = icc;
+      this.invoker = invoker;
       setStatisticsEnabled(configuration.isExposeJmxStatistics());
    }
 
@@ -152,37 +162,46 @@ public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand
 
    private Object enlistReadAndInvokeNext(InvocationContext ctx, VisitableCommand command) throws Throwable {
       if (shouldEnlist(ctx)) {
-         TransactionXaAdapter xaAdapter = enlist(ctx);
+         LocalTransaction localTransaction = enlist(ctx);
          LocalTxInvocationContext localTxContext = (LocalTxInvocationContext) ctx;
-         localTxContext.setXaCache(xaAdapter);
+         localTxContext.setLocalTransaction(localTransaction);
       }
       return invokeNextInterceptor(ctx, command);
    }
 
    private Object enlistWriteAndInvokeNext(InvocationContext ctx, WriteCommand command) throws Throwable {
-      TransactionXaAdapter xaAdapter = null;
+      LocalTransaction localTransaction = null;
       boolean shouldAddMod = false;
       if (shouldEnlist(ctx)) {
-         xaAdapter = enlist(ctx);
+         localTransaction = enlist(ctx);
          LocalTxInvocationContext localTxContext = (LocalTxInvocationContext) ctx;
          if (localModeNotForced(ctx)) shouldAddMod = true;
-         localTxContext.setXaCache(xaAdapter);
+         localTxContext.setLocalTransaction(localTransaction);
       }
       Object rv;
       rv = invokeNextInterceptor(ctx, command);
       if (!ctx.isInTxScope())
          transactionLog.logNoTxWrite(command);
-      if (command.isSuccessful() && shouldAddMod) xaAdapter.addModification(command);
+      if (command.isSuccessful() && shouldAddMod) localTransaction.addModification(command);
       return rv;
    }
 
-   public TransactionXaAdapter enlist(InvocationContext ctx) throws SystemException, RollbackException {
+   public LocalTransaction enlist(InvocationContext ctx) throws SystemException, RollbackException {
       Transaction transaction = tm.getTransaction();
       if (transaction == null) throw new IllegalStateException(""This should only be called in an tx scope"");
       int status = transaction.getStatus();
       if (isNotValid(status)) throw new IllegalStateException(""Transaction "" + transaction +
             "" is not in a valid state to be invoking cache operations on."");
-      return txTable.getOrCreateXaAdapter(transaction, ctx);
+      LocalTransaction localTransaction = txTable.getOrCreateLocalTransaction(transaction, ctx);
+      if (!localTransaction.isEnlisted()) { //make sure that you only enlist it once
+         try {
+            transaction.enlistResource(new TransactionXaAdapter(localTransaction, txTable, commandsFactory, configuration, invoker, icc));
+         } catch (Exception e) {
+            log.error(""Failed to enlist TransactionXaAdapter to transaction"");
+            throw new CacheException(e);
+         }
+      }
+      return localTransaction;
    }
 
    private boolean isNotValid(int status) {",2010-12-09T08:05:14Z,87
"@@ -0,0 +1,46 @@
+package org.infinispan.transaction.xa;
+
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.util.BidirectionalLinkedHashMap;
+import org.infinispan.util.BidirectionalMap;
+
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * Base class for local and remote transaction.
+ * Impl note: The aggregated modification list and lookedUpEntries are not instantiated here but in subclasses.
+ * This is done in order to take advantage of the fact that, for remote transactions we already know the size of the
+ * modifications list at creation time.
+ *
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+public abstract class AbstractCacheTransaction implements CacheTransaction {
+
+   protected List<WriteCommand> modifications;
+   protected BidirectionalLinkedHashMap<Object, CacheEntry> lookedUpEntries;
+   protected GlobalTransaction tx;
+
+
+   public GlobalTransaction getGlobalTransaction() {
+      return tx;
+   }
+
+   public List<WriteCommand> getModifications() {
+      return modifications;
+   }
+
+   public void setModifications(WriteCommand[] modifications) {
+      this.modifications = Arrays.asList(modifications);
+   }
+
+   public CacheEntry lookupEntry(Object key) {
+      return lookedUpEntries.get(key);
+   }
+
+   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
+      return lookedUpEntries;
+   }
+}",2010-12-09T08:05:14Z,88
"@@ -0,0 +1,117 @@
+package org.infinispan.transaction.xa;
+
+import org.infinispan.commands.write.WriteCommand;
+import org.infinispan.container.entries.CacheEntry;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.util.BidirectionalLinkedHashMap;
+import org.infinispan.util.BidirectionalMap;
+import org.infinispan.util.InfinispanCollections;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+import javax.transaction.Transaction;
+import javax.transaction.xa.Xid;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+
+/**
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+public class LocalTransaction extends AbstractCacheTransaction {
+
+   private static Log log = LogFactory.getLog(LocalTransaction.class);
+   private static final boolean trace = log.isTraceEnabled();
+
+   private Set<Address> remoteLockedNodes;
+
+   /** mark as volatile as this might be set from the tx thread code on view change*/
+   private volatile boolean isMarkedForRollback;
+
+   private final Transaction transaction;
+   private Xid xid;
+
+   public LocalTransaction(Transaction transaction, GlobalTransaction tx) {
+      super.tx = tx;
+      this.transaction = transaction;
+   }
+
+   public void addModification(WriteCommand mod) {
+      if (trace) log.trace(""Adding modification {0}. Mod list is {1}"", mod, modifications);
+      if (modifications == null) {
+         modifications = new ArrayList<WriteCommand>(8);
+      }
+      modifications.add(mod);
+   }
+
+   public boolean hasRemoteLocksAcquired(List<Address> leavers) {
+      if (log.isTraceEnabled()) {
+         log.trace(""My remote locks: "" + remoteLockedNodes + "", leavers are:"" + leavers);
+      }
+      return (remoteLockedNodes != null) && !Collections.disjoint(remoteLockedNodes, leavers);
+   }
+
+   public void locksAcquired(Collection<Address> nodes) {
+      if (remoteLockedNodes == null) remoteLockedNodes = new HashSet<Address>();
+      remoteLockedNodes.addAll(nodes);
+   }
+
+   public void markForRollback() {
+      isMarkedForRollback = true;
+   }
+
+   public boolean isMarkedForRollback() {
+      return isMarkedForRollback;
+   }
+
+   public Transaction getTransaction() {
+      return transaction;
+   }
+
+   public CacheEntry lookupEntry(Object key) {
+      if (lookedUpEntries == null) return null;
+      return lookedUpEntries.get(key);
+   }
+
+   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
+      return (BidirectionalMap<Object, CacheEntry>)
+            (lookedUpEntries == null ? InfinispanCollections.emptyBidirectionalMap() : lookedUpEntries);
+   }
+
+   public void putLookedUpEntry(Object key, CacheEntry e) {
+      if (lookedUpEntries == null) lookedUpEntries = new BidirectionalLinkedHashMap<Object, CacheEntry>(4);
+      lookedUpEntries.put(key, e);
+   }
+
+   public void removeLookedUpEntry(Object key) {
+      if (lookedUpEntries != null) lookedUpEntries.remove(key);
+   }
+
+   public void clearLookedUpEntries() {
+      if (lookedUpEntries != null) lookedUpEntries.clear();
+   }
+
+   public boolean isReadOnly() {
+      return (modifications == null || modifications.isEmpty()) && (lookedUpEntries == null || lookedUpEntries.isEmpty());
+   }
+
+   public void setXid(Xid xid) {
+      this.xid = xid;
+   }
+
+   public Xid getXid() {
+      return xid;
+   }
+
+   /**
+    * As per the JTA spec, XAResource.start is called on enlistment. That method also sets the xid for this local
+    * transaction.
+    */
+   public boolean isEnlisted() {
+      return xid != null;
+   }
+}",2010-12-09T08:05:14Z,89
"@@ -21,19 +21,12 @@
  * @author Mircea.Markus@jboss.com
  * @since 4.0
  */
-public class RemoteTransaction implements CacheTransaction, Cloneable {
+public class RemoteTransaction extends AbstractCacheTransaction implements Cloneable {
 
    private static Log log = LogFactory.getLog(RemoteTransaction.class);
 
-   private List<WriteCommand> modifications;
-
-   private BidirectionalLinkedHashMap<Object, CacheEntry> lookedUpEntries;
-
-   private GlobalTransaction tx;
-
    private volatile boolean valid = true;
 
-
    public RemoteTransaction(WriteCommand[] modifications, GlobalTransaction tx) {
       this.modifications = modifications == null || modifications.length == 0 ? Collections.<WriteCommand>emptyList() : Arrays.asList(modifications);
       lookedUpEntries = new BidirectionalLinkedHashMap<Object, CacheEntry>(this.modifications.size());
@@ -50,26 +43,6 @@ public void invalidate() {
       valid = false;
    }
 
-   public GlobalTransaction getGlobalTransaction() {
-      return tx;
-   }
-
-   public List<WriteCommand> getModifications() {
-      return modifications;
-   }
-
-   public void setModifications(WriteCommand[] modifications) {
-      this.modifications = Arrays.asList(modifications);
-   }
-
-   public CacheEntry lookupEntry(Object key) {
-      return lookedUpEntries.get(key);
-   }
-
-   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
-      return lookedUpEntries;
-   }
-
    public void putLookedUpEntry(Object key, CacheEntry e) {
       if (valid) {
          if (log.isTraceEnabled()) {",2010-12-09T08:05:14Z,90
"@@ -1,7 +1,5 @@
 package org.infinispan.transaction.xa;
 
-import org.infinispan.CacheException;
-import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.tx.RollbackCommand;
 import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.config.Configuration;
@@ -23,6 +21,7 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.Transaction;
+import javax.transaction.xa.Xid;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
@@ -46,13 +45,14 @@ public class TransactionTable {
    private static final Log log = LogFactory.getLog(TransactionTable.class);
    private static boolean trace = log.isTraceEnabled();
 
-   private final Map<Transaction, TransactionXaAdapter> localTransactions = new ConcurrentHashMap<Transaction, TransactionXaAdapter>();
+   private final Map<Transaction, LocalTransaction> localTransactions = new ConcurrentHashMap<Transaction, LocalTransaction>();
 
    private final Map<GlobalTransaction, RemoteTransaction> remoteTransactions = new ConcurrentHashMap<GlobalTransaction, RemoteTransaction>();
 
+   private final Map<Xid, LocalTransaction> xid2LocalTx = new ConcurrentHashMap<Xid, LocalTransaction>();
+
    private final Object listener = new StaleTransactionCleanup();
    
-   private CommandsFactory commandsFactory;
    private Configuration configuration;
    private InvocationContextContainer icc;
    private InterceptorChain invoker;
@@ -63,10 +63,9 @@ public class TransactionTable {
    private EmbeddedCacheManager cm;
 
    @Inject
-   public void initialize(CommandsFactory commandsFactory, RpcManager rpcManager, Configuration configuration,
+   public void initialize(RpcManager rpcManager, Configuration configuration,
                           InvocationContextContainer icc, InterceptorChain invoker, CacheNotifier notifier,
                           GlobalTransactionFactory gtf, EmbeddedCacheManager cm) {
-      this.commandsFactory = commandsFactory;
       this.rpcManager = rpcManager;
       this.configuration = configuration;
       this.icc = icc;
@@ -94,6 +93,15 @@ public Set<Object> getLockedKeysForRemoteTransaction(GlobalTransaction gtx) {
       return transaction.getLockedKeys();
    }
 
+   public LocalTransaction getLocalTransaction(Xid xid) {
+      return this.xid2LocalTx.get(xid);
+   }
+
+   public void addLocalTransactionMapping(LocalTransaction localTransaction) {
+      if (localTransaction.getXid() == null) throw new IllegalStateException(""Initialize xid first!"");
+      this.xid2LocalTx.put(localTransaction.getXid(), localTransaction);
+   }
+
    @Listener
    public class StaleTransactionCleanup {
       @ViewChanged
@@ -103,9 +111,9 @@ public void onViewChange(ViewChangedEvent vce) {
             if (trace) log.trace(""Saw {0} leavers - kicking off a lock breaking task"", leavers.size());
             cleanTxForWhichTheOwnerLeft(leavers);
             if (configuration.isUseEagerLocking() && configuration.isEagerLockSingleNode() && configuration.getCacheMode().isDistributed()) {
-               for (TransactionXaAdapter xaAdapter : localTransactions.values()) {
-                  if (xaAdapter.hasRemoteLocksAcquired(leavers)) {
-                     xaAdapter.markForRollback();
+               for (LocalTransaction localTx : localTransactions.values()) {
+                  if (localTx.hasRemoteLocksAcquired(leavers)) {
+                     localTx.markForRollback();
                   }
                }
             }
@@ -198,20 +206,14 @@ private void registerRemoteTransaction(GlobalTransaction gtx, RemoteTransaction
     * Returns the {@link org.infinispan.transaction.xa.TransactionXaAdapter} corresponding to the supplied transaction.
     * If none exists, will be created first.
     */
-   public TransactionXaAdapter getOrCreateXaAdapter(Transaction transaction, InvocationContext ctx) {
-      TransactionXaAdapter current = localTransactions.get(transaction);
+   public LocalTransaction getOrCreateLocalTransaction(Transaction transaction, InvocationContext ctx) {
+      LocalTransaction current = localTransactions.get(transaction);
       if (current == null) {
          Address localAddress = rpcManager != null ? rpcManager.getTransport().getAddress() : null;
          GlobalTransaction tx = gtf.newGlobalTransaction(localAddress, false);
          if (trace) log.trace(""Created a new GlobalTransaction {0}"", tx);
-         current = new TransactionXaAdapter(tx, icc, invoker, commandsFactory, configuration, this, transaction);
+         current = new LocalTransaction(transaction, tx);
          localTransactions.put(transaction, current);
-         try {
-            transaction.enlistResource(current);
-         } catch (Exception e) {
-            log.error(""Failed to enlist TransactionXaAdapter to transaction"");
-            throw new CacheException(e);
-         }
          notifier.notifyTransactionRegistered(tx, ctx);
       }
       return current;
@@ -221,8 +223,9 @@ public TransactionXaAdapter getOrCreateXaAdapter(Transaction transaction, Invoca
     * Removes the {@link org.infinispan.transaction.xa.TransactionXaAdapter} corresponding to the given tx. Returns true
     * if such an tx exists.
     */
-   public boolean removeLocalTransaction(Transaction tx) {
-      return localTransactions.remove(tx) != null;
+   public boolean removeLocalTransaction(LocalTransaction localTransaction) {
+      xid2LocalTx.remove(localTransaction.getXid());
+      return localTransactions.remove(localTransaction.getTransaction()) != null;
    }
 
    /**
@@ -245,13 +248,11 @@ public int getLocalTxCount() {
       return localTransactions.size();
    }
 
-   public TransactionXaAdapter getXaCacheAdapter(Transaction tx) {
+   public LocalTransaction getLocalTransaction(Transaction tx) {
       return localTransactions.get(tx);
    }
 
    public boolean containRemoteTx(GlobalTransaction globalTransaction) {
       return remoteTransactions.containsKey(globalTransaction);
    }
-
-
 }",2010-12-09T08:05:14Z,91
"@@ -4,29 +4,16 @@
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.tx.RollbackCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.config.Configuration;
-import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.context.impl.LocalTxInvocationContext;
 import org.infinispan.interceptors.InterceptorChain;
-import org.infinispan.remoting.transport.Address;
-import org.infinispan.util.BidirectionalLinkedHashMap;
-import org.infinispan.util.BidirectionalMap;
-import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import javax.transaction.Transaction;
 import javax.transaction.xa.XAException;
 import javax.transaction.xa.XAResource;
 import javax.transaction.xa.Xid;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
 
 /**
  * This acts both as an local {@link org.infinispan.transaction.xa.CacheTransaction} and implementor of an {@link
@@ -35,91 +22,94 @@
  * @author Mircea.Markus@jboss.com
  * @since 4.0
  */
-public class TransactionXaAdapter implements CacheTransaction, XAResource {
+public class TransactionXaAdapter implements XAResource {
 
    private static final Log log = LogFactory.getLog(TransactionXaAdapter.class);
    private static boolean trace = log.isTraceEnabled();
 
    private int txTimeout;
 
-   private volatile List<WriteCommand> modifications;
-   private BidirectionalMap<Object, CacheEntry> lookedUpEntries;
+   private final InvocationContextContainer icc;
+   private final InterceptorChain invoker;
 
-   private GlobalTransaction globalTx;
-   private InvocationContextContainer icc;
-   private InterceptorChain invoker;
+   private final CommandsFactory commandsFactory;
+   private final Configuration configuration;
 
-   private CommandsFactory commandsFactory;
-   private Configuration configuration;
+   private final TransactionTable txTable;
 
-   private TransactionTable txTable;
-   private Transaction transaction;
+   /**
+    * XAResource is associated with a transaction between enlistment (XAResource.start()) XAResource.end(). It's only the
+    * boundary methods (prepare, commit, rollback) that need to be ""stateless"".
+    * Reefer to section 3.4.4 from JTA spec v.1.1
+    */
+   private final LocalTransaction localTransaction;
 
-   private Set<Address> remoteLockedNodes;
-   private boolean isMarkedForRollback;
 
-
-   public TransactionXaAdapter(GlobalTransaction globalTx, InvocationContextContainer icc, InterceptorChain invoker,
-                               CommandsFactory commandsFactory, Configuration configuration, TransactionTable txTable,
-                               Transaction transaction) {
-      this.globalTx = globalTx;
-      this.icc = icc;
-      this.invoker = invoker;
+   public TransactionXaAdapter(LocalTransaction localTransaction, TransactionTable txTable, CommandsFactory commandsFactory,
+                               Configuration configuration, InterceptorChain invoker, InvocationContextContainer icc) {
+      this.localTransaction = localTransaction;
+      this.txTable = txTable;
       this.commandsFactory = commandsFactory;
       this.configuration = configuration;
-      this.txTable = txTable;
-      this.transaction = transaction;
-   }
-
-   public void addModification(WriteCommand mod) {
-      if (trace) log.trace(""Adding modification {0}. Mod list is {1}"", mod, modifications);
-      if (modifications == null) {
-         modifications = new ArrayList<WriteCommand>(8);
-      }
-      modifications.add(mod);
+      this.invoker = invoker;
+      this.icc = icc;
    }
 
+   /**
+    * This can be call for any transaction object. See Section 3.4.6 (Resource Sharing) from JTA spec v1.1.
+    */
    public int prepare(Xid xid) throws XAException {
-      checkMarkedForRollback();
+      LocalTransaction localTransaction = getLocalTransactionAndValidate(xid);
+      
+      validateNotMarkedForRollback(localTransaction);
+
       if (configuration.isOnePhaseCommit()) {
-         if (trace)
-            log.trace(""Received prepare for tx: "" + xid + "" . Skipping call as 1PC will be used."");
+         if (trace) log.trace(""Received prepare for tx: {0}. Skipping call as 1PC will be used."", xid);
          return XA_OK;
       }
 
-      PrepareCommand prepareCommand = commandsFactory.buildPrepareCommand(globalTx, modifications, configuration.isOnePhaseCommit());
+      PrepareCommand prepareCommand = commandsFactory.buildPrepareCommand(localTransaction.getGlobalTransaction(), localTransaction.getModifications(), configuration.isOnePhaseCommit());
       if (trace) log.trace(""Sending prepare command through the chain: "" + prepareCommand);
 
       LocalTxInvocationContext ctx = icc.createTxInvocationContext();
-      ctx.setXaCache(this);
+      ctx.setLocalTransaction(localTransaction);
       try {
          invoker.invoke(ctx, prepareCommand);
-         return XA_OK;
+         if (localTransaction.isReadOnly()) {
+            if (trace) log.trace(""Readonly transaction: "" + localTransaction.getGlobalTransaction());
+            return XA_RDONLY;
+         } else {
+            return XA_OK;
+         }
       } catch (Throwable e) {
          log.error(""Error while processing PrepareCommand"", e);
          throw new XAException(XAException.XAER_RMERR);
       }
    }
 
+   /**
+    * Same comment as for {@link #prepare(javax.transaction.xa.Xid)} applies for commit.
+    */
    public void commit(Xid xid, boolean isOnePhase) throws XAException {
-      // always call prepare() - even if this is just a 1PC!
-      if (isOnePhase) prepare(xid);
-      if (trace) log.trace(""committing transaction: "" + globalTx);
+      LocalTransaction localTransaction = getLocalTransactionAndValidate(xid);
+
+      if (trace) log.trace(""committing transaction {0}"" + localTransaction.getGlobalTransaction());
       try {
          LocalTxInvocationContext ctx = icc.createTxInvocationContext();
-         ctx.setXaCache(this);
-         if (configuration.isOnePhaseCommit()) {
-            checkMarkedForRollback();
+         ctx.setLocalTransaction(localTransaction);
+         if (configuration.isOnePhaseCommit() || isOnePhase) {
+            validateNotMarkedForRollback(localTransaction);
+
             if (trace) log.trace(""Doing an 1PC prepare call on the interceptor chain"");
-            PrepareCommand command = commandsFactory.buildPrepareCommand(globalTx, modifications, true);
+            PrepareCommand command = commandsFactory.buildPrepareCommand(localTransaction.getGlobalTransaction(), localTransaction.getModifications(), true);
             try {
                invoker.invoke(ctx, command);
             } catch (Throwable e) {
                log.error(""Error while processing 1PC PrepareCommand"", e);
                throw new XAException(XAException.XAER_RMERR);
             }
          } else {
-            CommitCommand commitCommand = commandsFactory.buildCommitCommand(globalTx);
+            CommitCommand commitCommand = commandsFactory.buildCommitCommand(localTransaction.getGlobalTransaction());
             try {
                invoker.invoke(ctx, commitCommand);
             } catch (Throwable e) {
@@ -128,35 +118,46 @@ public void commit(Xid xid, boolean isOnePhase) throws XAException {
             }
          }
       } finally {
-         txTable.removeLocalTransaction(transaction);
-         icc.suspend();
-         this.modifications = null;
+         cleanup(localTransaction);
       }
    }
 
-   public void rollback(Xid xid) throws XAException {
-      if (trace) log.trace(""rollback transaction: "" + globalTx);
-      RollbackCommand rollbackCommand = commandsFactory.buildRollbackCommand(globalTx);
+   /**
+    * Same comment as for {@link #prepare(javax.transaction.xa.Xid)} applies for commit.
+    */   
+   public void rollback(Xid xid) throws XAException {      
+      LocalTransaction localTransaction = getLocalTransactionAndValidate(xid);
+      if (trace) log.trace(""rollback transaction {0} "", localTransaction.getGlobalTransaction());
+      RollbackCommand rollbackCommand = commandsFactory.buildRollbackCommand(localTransaction.getGlobalTransaction());
       LocalTxInvocationContext ctx = icc.createTxInvocationContext();
-      ctx.setXaCache(this);
+      ctx.setLocalTransaction(localTransaction);
       try {
          invoker.invoke(ctx, rollbackCommand);
       } catch (Throwable e) {
          log.error(""Exception while rollback"", e);
          throw new XAException(XAException.XA_HEURHAZ);
       } finally {
-         txTable.removeLocalTransaction(transaction);
-         icc.suspend();
-         this.modifications = null;
+         cleanup(localTransaction);
+      }
+   }
+
+   private LocalTransaction getLocalTransactionAndValidate(Xid xid) throws XAException {
+      LocalTransaction localTransaction = txTable.getLocalTransaction(xid);
+      if  (localTransaction == null) {
+         if (trace) log.trace(""no tx found for {0}"", xid);
+         throw new XAException(XAException.XAER_NOTA);
       }
+      return localTransaction;
    }
 
    public void start(Xid xid, int i) throws XAException {
-      if (trace) log.trace(""start called on tx "" + this.globalTx);
+      localTransaction.setXid(xid);
+      txTable.addLocalTransactionMapping(localTransaction);
+      if (trace) log.trace(""start called on tx "" + this.localTransaction.getGlobalTransaction());
    }
 
    public void end(Xid xid, int i) throws XAException {
-      if (trace) log.trace(""end called on tx "" + this.globalTx);
+      if (trace) log.trace(""end called on tx "" + this.localTransaction.getGlobalTransaction());
    }
 
    public void forget(Xid xid) throws XAException {
@@ -186,95 +187,35 @@ public boolean setTransactionTimeout(int i) throws XAException {
       return true;
    }
 
-   public CacheEntry lookupEntry(Object key) {
-      if (lookedUpEntries == null) return null;
-      return lookedUpEntries.get(key);
-   }
-
-   public BidirectionalMap<Object, CacheEntry> getLookedUpEntries() {
-      return (BidirectionalMap<Object, CacheEntry>)
-            (lookedUpEntries == null ? InfinispanCollections.emptyBidirectionalMap() : lookedUpEntries);
-   }
-
-   public void putLookedUpEntry(Object key, CacheEntry e) {
-      initLookedUpEntries();
-      lookedUpEntries.put(key, e);
-   }
-
-   private void initLookedUpEntries() {
-      if (lookedUpEntries == null) lookedUpEntries = new BidirectionalLinkedHashMap<Object, CacheEntry>(4);
-   }
-
-   public GlobalTransaction getGlobalTx() {
-      return globalTx;
-   }
-
-   public List<WriteCommand> getModifications() {
-      if (trace) log.trace(""Retrieving modification list {0}."", modifications);
-      return modifications;
-   }
-
-   public Transaction getTransaction() {
-      return transaction;
-   }
-
-   public GlobalTransaction getGlobalTransaction() {
-      return globalTx;
-   }
-
-   public void removeLookedUpEntry(Object key) {
-      if (lookedUpEntries != null) lookedUpEntries.remove(key);
-   }
-
-   public void clearLookedUpEntries() {
-      if (lookedUpEntries != null) lookedUpEntries.clear();
-   }
-
    @Override
    public boolean equals(Object o) {
       if (this == o) return true;
       if (!(o instanceof TransactionXaAdapter)) return false;
-
       TransactionXaAdapter that = (TransactionXaAdapter) o;
-
-      if (!globalTx.equals(that.globalTx)) return false;
-
-      return true;
+      return this.localTransaction.equals(that.localTransaction);
    }
 
    @Override
    public int hashCode() {
-      return globalTx.hashCode();
+      return localTransaction.getGlobalTransaction().hashCode();
    }
 
    @Override
    public String toString() {
       return ""TransactionXaAdapter{"" +
-            ""modifications="" + modifications +
-            "", lookedUpEntries="" + lookedUpEntries +
-            "", globalTx="" + globalTx +
-            "", transaction="" + transaction +
-            "", txTimeout="" + txTimeout +
+            ""localTransaction="" + localTransaction +
             '}';
    }
 
-   public boolean hasRemoteLocksAcquired(List<Address> leavers) {
-      if (log.isTraceEnabled()) {
-         log.trace(""My remote locks: "" + remoteLockedNodes + "", leavers are:"" + leavers);
+   private void validateNotMarkedForRollback(LocalTransaction localTransaction) throws XAException {
+      if (localTransaction.isMarkedForRollback()) {
+         if (trace) log.trace(""Transaction already marked for rollback: {0}"", localTransaction);
+         throw new XAException(XAException.XA_RBROLLBACK);
       }
-      return (remoteLockedNodes != null) && !Collections.disjoint(remoteLockedNodes, leavers);
-   }
-
-   public void locksAcquired(Collection<Address> nodes) {
-      if (remoteLockedNodes == null) remoteLockedNodes = new HashSet<Address>();
-      remoteLockedNodes.addAll(nodes);
-   }
-
-   public void markForRollback() {
-      isMarkedForRollback = true;
    }
 
-   private void checkMarkedForRollback() throws XAException {
-      if (isMarkedForRollback) throw new XAException(XAException.XA_RBOTHER);
+   private void cleanup(LocalTransaction localTransaction) {
+      txTable.removeLocalTransaction(localTransaction);
+      icc.suspend();
    }   
 }",2010-12-09T08:05:14Z,92
"@@ -0,0 +1,61 @@
+package org.infinispan.tx;
+
+import org.infinispan.config.Configuration;
+import org.infinispan.context.Flag;
+import org.infinispan.manager.DefaultCacheManager;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.SingleCacheManagerTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.CleanupAfterMethod;
+import org.infinispan.transaction.xa.LocalTransaction;
+import org.infinispan.transaction.xa.TransactionTable;
+import org.testng.annotations.Test;
+
+import javax.transaction.Transaction;
+
+/**
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+@Test (groups = ""functional"", testName = ""tx.ReadOnlyTxTest"")
+@CleanupAfterMethod
+public class ReadOnlyTxTest extends SingleCacheManagerTest {
+
+   @Override
+   protected EmbeddedCacheManager createCacheManager() throws Exception {
+      Configuration configuration = getDefaultClusteredConfig(Configuration.CacheMode.LOCAL, true);
+      return new DefaultCacheManager(configuration);
+   }
+
+   public void testSimpleReadOnlTx() throws Exception {
+      tm().begin();
+      assert cache.get(""k"") == null;
+      Transaction transaction = tm().suspend();
+      LocalTransaction localTransaction = txTable().getLocalTransaction(transaction);
+      assert localTransaction != null && localTransaction.isReadOnly();
+   }
+
+   public void testNotROWhenHasWrites() throws Exception {
+      tm().begin();
+      cache.put(""k"", ""v"");
+      assert TestingUtil.extractLockManager(cache).isLocked(""k"");
+      Transaction transaction = tm().suspend();
+      LocalTransaction localTransaction = txTable().getLocalTransaction(transaction);
+      assert localTransaction != null && !localTransaction.isReadOnly();
+   }
+
+   public void testNotROWhenHasOnlyLocks() throws Exception {
+      cache.put(""k"", ""v"");
+      tm().begin();
+      cache.getAdvancedCache().withFlags(Flag.FORCE_WRITE_LOCK).get(""k"");
+      assert TestingUtil.extractLockManager(cache).isLocked(""k"");
+      Transaction transaction = tm().suspend();
+      LocalTransaction localTransaction = txTable().getLocalTransaction(transaction);
+      assert localTransaction != null && !localTransaction.isReadOnly();
+   }
+
+
+   private TransactionTable txTable() {
+      return TestingUtil.getTransactionTable(cache);
+   }
+}",2010-12-09T08:05:14Z,93
"@@ -0,0 +1,110 @@
+package org.infinispan.tx;
+
+import org.infinispan.config.Configuration;
+import org.infinispan.transaction.tm.DummyTransaction;
+import org.infinispan.transaction.tm.DummyXid;
+import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.transaction.xa.GlobalTransactionFactory;
+import org.infinispan.transaction.xa.LocalTransaction;
+import org.infinispan.transaction.xa.TransactionTable;
+import org.infinispan.transaction.xa.TransactionXaAdapter;
+import org.testng.annotations.BeforeMethod;
+import org.testng.annotations.Test;
+
+import javax.transaction.xa.XAException;
+import javax.transaction.xa.XAResource;
+
+/**
+ * @author Mircea.Markus@jboss.com
+ * @since 4.2
+ */
+@Test(testName = ""tx.TransactionXaAdapterTest"", groups = ""unit"")
+public class TransactionXaAdapterTmIntegrationTest {
+   private Configuration configuration;
+   private TransactionTable txTable;
+   private GlobalTransaction globalTransaction;
+   private LocalTransaction localTx;
+   private TransactionXaAdapter xaAdapter;
+   private DummyXid xid;
+
+   @BeforeMethod
+   public void setUp() {
+      txTable = new TransactionTable();
+      GlobalTransactionFactory gtf = new GlobalTransactionFactory();
+      globalTransaction = gtf.newGlobalTransaction(null, false);
+      localTx = new LocalTransaction(new DummyTransaction(null), globalTransaction);
+      xid = new DummyXid();
+      localTx.setXid(xid);
+      txTable.addLocalTransactionMapping(localTx);      
+
+      configuration = new Configuration();
+      xaAdapter = new TransactionXaAdapter(localTx, txTable, null, configuration, null, null);
+   }
+
+   public void testPrepareOnNonexistentXid() {
+      DummyXid xid = new DummyXid();
+      try {
+         xaAdapter.prepare(xid);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void testCommitOnNonexistentXid() {
+      DummyXid xid = new DummyXid();
+      try {
+         xaAdapter.commit(xid, false);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void testRollabckOnNonexistentXid() {
+      DummyXid xid = new DummyXid();
+      try {
+         xaAdapter.rollback(xid);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void testPrepareTxMarkedForRollback() {
+      localTx.markForRollback();
+      try {
+         xaAdapter.prepare(xid);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XA_RBROLLBACK;
+      }
+   }
+
+   public void testOnePhaseCommitConfigured() throws XAException {
+      configuration.setCacheMode(Configuration.CacheMode.INVALIDATION_ASYNC);//this would force 1pc
+      assert XAResource.XA_OK == xaAdapter.prepare(xid);
+   }
+
+   public void test1PcAndNonExistentXid() {
+      configuration.setCacheMode(Configuration.CacheMode.INVALIDATION_ASYNC);
+      try {
+         DummyXid doesNotExists = new DummyXid();
+         xaAdapter.commit(doesNotExists, false);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+
+   public void test1PcAndNonExistentXid2() {
+      configuration.setCacheMode(Configuration.CacheMode.DIST_SYNC);
+      try {
+         DummyXid doesNotExists = new DummyXid();
+         xaAdapter.commit(doesNotExists, true);
+         assert false;
+      } catch (XAException e) {
+         assert e.errorCode == XAException.XAER_NOTA;
+      }
+   }
+}",2010-12-09T08:05:14Z,94
"@@ -8,11 +8,11 @@
 import org.infinispan.factories.ComponentRegistry;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.util.concurrent.NotifyingFuture;
 
 import java.util.Collection;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
 /**
@@ -130,51 +130,51 @@ public boolean replace(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, lo
       return cache.replace(k, oV, nV, lifespan, lifespanUnit, maxIdle, maxIdleUnit, flags);
    }
 
-   public Future<V> putAsync(K key, V value, Flag... flags) {
+   public NotifyingFuture<V> putAsync(K key, V value, Flag... flags) {
       return cache.putAsync(key, value, flags);
    }
 
-   public Future<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
+   public NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
       return cache.putAsync(key, value, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
    }
 
-   public Future<V> putIfAbsentAsync(K key, V value, Flag... flags) {
+   public NotifyingFuture<V> putIfAbsentAsync(K key, V value, Flag... flags) {
       return cache.putIfAbsentAsync(key, value, flags);
    }
 
-   public Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
+   public NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
       return cache.putIfAbsentAsync(key, value, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
    }
 
-   public Future<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags) {
+   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags) {
       return cache.putAllAsync(map, flags);
    }
 
-   public Future<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
+   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags) {
       return cache.putAllAsync(map, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit, flags);
    }
 
-   public Future<V> removeAsync(Object key, Flag... flags) {
+   public NotifyingFuture<V> removeAsync(Object key, Flag... flags) {
       return cache.removeAsync(key, flags);
    }
 
-   public Future<Void> clearAsync(Flag... flags) {
+   public NotifyingFuture<Void> clearAsync(Flag... flags) {
       return cache.clearAsync(flags);
    }
 
-   public Future<V> replaceAsync(K k, V v, Flag... flags) {
+   public NotifyingFuture<V> replaceAsync(K k, V v, Flag... flags) {
       return cache.replaceAsync(k, v, flags);
    }
 
-   public Future<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags) {
+   public NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags) {
       return cache.replaceAsync(k, oV, nV, flags);
    }
 
-   public Future<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
+   public NotifyingFuture<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
       return cache.replaceAsync(k, v, lifespan, lifespanUnit, maxIdle, maxIdleUnit, flags);
    }
 
-   public Future<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
+   public NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags) {
       return cache.replaceAsync(k, oV, nV, lifespan, lifespanUnit, maxIdle, maxIdleUnit, flags);
    }
 
@@ -186,78 +186,6 @@ public V get(Object key, Flag... flags) {
       return cache.get(key, flags);
    }
 
-   public Future<V> putAsync(K key, V value) {
-      return cache.putAsync(key, value);
-   }
-
-   public Future<V> putAsync(K key, V value, long lifespan, TimeUnit unit) {
-      return cache.putAsync(key, value, lifespan, unit);
-   }
-
-   public Future<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return cache.putAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
-   }
-
-   public Future<Void> putAllAsync(Map<? extends K, ? extends V> data) {
-      return cache.putAllAsync(data);
-   }
-
-   public Future<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit unit) {
-      return cache.putAllAsync(data, lifespan, unit);
-   }
-
-   public Future<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return cache.putAllAsync(data, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
-   }
-
-   public Future<Void> clearAsync() {
-      return cache.clearAsync();
-   }
-
-   public Future<V> putIfAbsentAsync(K key, V value) {
-      return cache.putIfAbsentAsync(key, value);
-   }
-
-   public Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit unit) {
-      return cache.putIfAbsentAsync(key, value, lifespan, unit);
-   }
-
-   public Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return cache.putIfAbsentAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
-   }
-
-   public Future<V> removeAsync(Object key) {
-      return cache.removeAsync(key);
-   }
-
-   public Future<Boolean> removeAsync(Object key, Object value) {
-      return cache.removeAsync(key, value);
-   }
-
-   public Future<V> replaceAsync(K key, V value) {
-      return cache.replaceAsync(key, value);
-   }
-
-   public Future<V> replaceAsync(K key, V value, long lifespan, TimeUnit unit) {
-      return cache.replaceAsync(key, value, lifespan, unit);
-   }
-
-   public Future<V> replaceAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return cache.replaceAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
-   }
-
-   public Future<Boolean> replaceAsync(K key, V oldValue, V newValue) {
-      return cache.replaceAsync(key, oldValue, newValue);
-   }
-
-   public Future<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit unit) {
-      return cache.replaceAsync(key, oldValue, newValue, lifespan, unit);
-   }
-
-   public Future<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
-      return cache.replaceAsync(key, oldValue, newValue, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
-   }
-
    public void lock(K key) {
       cache.lock(key);
    }",2009-05-20T15:18:23Z,95
"@@ -3,22 +3,23 @@
 import org.infinispan.config.Configuration;
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.manager.CacheManager;
+import org.infinispan.util.concurrent.NotifyingFuture;
 
 import java.util.Collection;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
-/**                                                                 
- * This is a convenient base class for implementing a cache delegate. The only constructor takes a {@link Cache} argument, to
- * which each method call is delegated. One can extend this class and override the method sub-set it is interested in.
- * There is also an similar implmentation for {@link org.infinispan.AdvancedCache}:
- * {@link org.infinispan.AbstractDelegatingAdvancedCache}.
+/**
+ * This is a convenient base class for implementing a cache delegate. The only constructor takes a {@link Cache}
+ * argument, to which each method call is delegated. One can extend this class and override the method sub-set it is
+ * interested in. There is also an similar implmentation for {@link org.infinispan.AdvancedCache}: {@link
+ * org.infinispan.AbstractDelegatingAdvancedCache}.
  *
- * @see org.infinispan.AbstractDelegatingAdvancedCache
  * @author Mircea.Markus@jboss.com
+ * @see org.infinispan.AbstractDelegatingAdvancedCache
  */
-public abstract class AbstractDelegatingCache<K, V> implements Cache<K, V> {
+public class AbstractDelegatingCache<K, V> implements Cache<K, V> {
 
    private Cache<K, V> cache;
 
@@ -98,6 +99,78 @@ public boolean replace(K key, V oldValue, V value, long lifespan, TimeUnit lifes
       return cache.replace(key, oldValue, value, lifespan, lifespanUnit, maxIdleTime, maxIdleTimeUnit);
    }
 
+   public NotifyingFuture<V> putAsync(K key, V value) {
+      return cache.putAsync(key, value);
+   }
+
+   public NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit unit) {
+      return cache.putAsync(key, value, lifespan, unit);
+   }
+
+   public NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
+      return cache.putAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
+   }
+
+   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data) {
+      return cache.putAllAsync(data);
+   }
+
+   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit unit) {
+      return cache.putAllAsync(data, lifespan, unit);
+   }
+
+   public NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
+      return cache.putAllAsync(data, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
+   }
+
+   public NotifyingFuture<Void> clearAsync() {
+      return cache.clearAsync();
+   }
+
+   public NotifyingFuture<V> putIfAbsentAsync(K key, V value) {
+      return cache.putIfAbsentAsync(key, value);
+   }
+
+   public NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit unit) {
+      return cache.putIfAbsentAsync(key, value, lifespan, unit);
+   }
+
+   public NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
+      return cache.putIfAbsentAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
+   }
+
+   public NotifyingFuture<V> removeAsync(Object key) {
+      return cache.removeAsync(key);
+   }
+
+   public NotifyingFuture<Boolean> removeAsync(Object key, Object value) {
+      return cache.removeAsync(key, value);
+   }
+
+   public NotifyingFuture<V> replaceAsync(K key, V value) {
+      return cache.replaceAsync(key, value);
+   }
+
+   public NotifyingFuture<V> replaceAsync(K key, V value, long lifespan, TimeUnit unit) {
+      return cache.replaceAsync(key, value, lifespan, unit);
+   }
+
+   public NotifyingFuture<V> replaceAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
+      return cache.replaceAsync(key, value, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
+   }
+
+   public NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue) {
+      return cache.replaceAsync(key, oldValue, newValue);
+   }
+
+   public NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit unit) {
+      return cache.replaceAsync(key, oldValue, newValue, lifespan, unit);
+   }
+
+   public NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit) {
+      return cache.replaceAsync(key, oldValue, newValue, lifespan, lifespanUnit, maxIdle, maxIdleUnit);
+   }
+
    public AdvancedCache<K, V> getAdvancedCache() {
       return cache.getAdvancedCache();
    }",2009-05-20T15:18:23Z,96
"@@ -8,11 +8,11 @@
 import org.infinispan.factories.ComponentRegistry;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.util.concurrent.NotifyingFuture;
 
 import java.util.Collection;
 import java.util.List;
 import java.util.Map;
-import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
 /**
@@ -123,29 +123,29 @@ public interface AdvancedCache<K, V> extends Cache<K, V> {
 
 
    // -- async methods --
-   Future<V> putAsync(K key, V value, Flag... flags);
+   NotifyingFuture<V> putAsync(K key, V value, Flag... flags);
 
-   Future<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
+   NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
 
-   Future<V> putIfAbsentAsync(K key, V value, Flag... flags);
+   NotifyingFuture<V> putIfAbsentAsync(K key, V value, Flag... flags);
 
-   Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
+   NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
 
-   Future<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags);
+   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, Flag... flags);
 
-   Future<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
+   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> map, long lifespan, TimeUnit lifespanUnit, long maxIdleTime, TimeUnit maxIdleTimeUnit, Flag... flags);
 
-   Future<V> removeAsync(Object key, Flag... flags);
+   NotifyingFuture<V> removeAsync(Object key, Flag... flags);
 
-   Future<Void> clearAsync(Flag... flags);
+   NotifyingFuture<Void> clearAsync(Flag... flags);
 
-   Future<V> replaceAsync(K k, V v, Flag... flags);
+   NotifyingFuture<V> replaceAsync(K k, V v, Flag... flags);
 
-   Future<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags);
+   NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, Flag... flags);
 
-   Future<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
+   NotifyingFuture<V> replaceAsync(K k, V v, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
 
-   Future<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
+   NotifyingFuture<Boolean> replaceAsync(K k, V oV, V nV, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit, Flag... flags);
 
    boolean containsKey(Object key, Flag... flags);
 ",2009-05-20T15:18:23Z,97
"@@ -1,44 +0,0 @@
-package org.infinispan;
-
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.Future;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.TimeoutException;
-
-/**
- * Wraps up return values for the asunc API
- *
- * @author Manik Surtani
- * @since 4.0
- */
-public class AsyncReturnValue implements Future<Object> {
-   final Future<Object> networkCallFuture;
-   final Object actualReturnValue;
-
-   public AsyncReturnValue(Future<Object> networkCallFuture, Object actualReturnValue) {
-      this.networkCallFuture = networkCallFuture;
-      this.actualReturnValue = actualReturnValue;
-   }
-
-   public boolean cancel(boolean mayInterruptIfRunning) {
-      return networkCallFuture.cancel(mayInterruptIfRunning);
-   }
-
-   public boolean isCancelled() {
-      return networkCallFuture.isCancelled();
-   }
-
-   public boolean isDone() {
-      return networkCallFuture.isDone();
-   }
-
-   public Object get() throws InterruptedException, ExecutionException {
-      networkCallFuture.get();
-      return actualReturnValue;
-   }
-
-   public Object get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {
-      networkCallFuture.get(timeout, unit);
-      return actualReturnValue;
-   }
-}",2009-05-20T15:18:23Z,98
"@@ -28,10 +28,10 @@
 import org.infinispan.manager.CacheManager;
 import org.infinispan.manager.DefaultCacheManager;
 import org.infinispan.notifications.Listenable;
+import org.infinispan.util.concurrent.NotifyingFuture;
 
 import java.util.Map;
 import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.Future;
 import java.util.concurrent.TimeUnit;
 
 /**
@@ -54,15 +54,16 @@
  * <h3>Asynchronous operations</h3> Cache also supports the use of ""async"" remote operations.  Note that these methods
  * only really make sense if you are using a clustered cache.  I.e., when used in LOCAL mode, these ""async"" operations
  * offer no benefit whatsoever.  These methods, such as {@link #putAsync(Object, Object)} offer the best of both worlds
- * between a fully synchronous and a fully asynchronous cache in that a {@link Future} is returned.  The <tt>Future</tt>
- * can then be ignored or thrown away for typical asynchronous behaviour, or queried for synchronous behaviour, which
- * would block until any remote calls complete.  Note that all remote calls are, as far as the transport is concerned,
- * synchronous.  This allows you the guarantees that remote calls succeed, while not blocking your application thread
- * unnecessarily.  For example, usage such as the following could benefit from the async operations:
+ * between a fully synchronous and a fully asynchronous cache in that a {@link NotifyingFuture} is returned.  The
+ * <tt>NotifyingFuture</tt> can then be ignored or thrown away for typical asynchronous behaviour, or queried for
+ * synchronous behaviour, which would block until any remote calls complete.  Note that all remote calls are, as far as
+ * the transport is concerned, synchronous.  This allows you the guarantees that remote calls succeed, while not
+ * blocking your application thread unnecessarily.  For example, usage such as the following could benefit from the
+ * async operations:
  * <pre>
- *   Future f1 = cache.putAsync(""key1"", ""value1"");
- *   Future f2 = cache.putAsync(""key2"", ""value2"");
- *   Future f3 = cache.putAsync(""key3"", ""value3"");
+ *   NotifyingFuture f1 = cache.putAsync(""key1"", ""value1"");
+ *   NotifyingFuture f2 = cache.putAsync(""key2"", ""value2"");
+ *   NotifyingFuture f3 = cache.putAsync(""key3"", ""value3"");
  *   f1.get();
  *   f2.get();
  *   f3.get();
@@ -72,8 +73,8 @@
  * especially advantageous if the cache uses distribution and the three keys map to different cache instances in the
  * cluster.
  * <p/>
- * Also, the use of async operations when within a transaction return your local value only, as expected.  A Future is
- * still returned though for API consistency.
+ * Also, the use of async operations when within a transaction return your local value only, as expected.  A
+ * NotifyingFuture is still returned though for API consistency.
  * <p/>
  * <h3>Constructing a Cache</h3> An instance of the Cache is usually obtained by using a {@link CacheManager}.
  * <pre>
@@ -310,7 +311,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param value value to store
     * @return a future containing the old value replaced.
     */
-   Future<V> putAsync(K key, V value);
+   NotifyingFuture<V> putAsync(K key, V value);
 
    /**
     * Asynchronous version of {@link #put(Object, Object, long, TimeUnit)} .  This method does not block on remote
@@ -323,7 +324,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param unit     time unit for lifespan
     * @return a future containing the old value replaced
     */
-   Future<V> putAsync(K key, V value, long lifespan, TimeUnit unit);
+   NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit unit);
 
    /**
     * Asynchronous version of {@link #put(Object, Object, long, TimeUnit, long, TimeUnit)}.  This method does not block
@@ -339,7 +340,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param maxIdleUnit  time unit for max idle time
     * @return a future containing the old value replaced
     */
-   Future<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
+   NotifyingFuture<V> putAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
    /**
     * Asynchronous version of {@link #putAll(Map)}.  This method does not block on remote calls, even if your cache mode
@@ -348,7 +349,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param data to store
     * @return a future containing a void return type
     */
-   Future<Void> putAllAsync(Map<? extends K, ? extends V> data);
+   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data);
 
    /**
     * Asynchronous version of {@link #putAll(Map, long, TimeUnit)}.  This method does not block on remote calls, even if
@@ -359,7 +360,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param unit     time unit for lifespan
     * @return a future containing a void return type
     */
-   Future<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit unit);
+   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit unit);
 
    /**
     * Asynchronous version of {@link #putAll(Map, long, TimeUnit, long, TimeUnit)}.  This method does not block on
@@ -374,15 +375,15 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param maxIdleUnit  time unit for max idle time
     * @return a future containing a void return type
     */
-   Future<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
+   NotifyingFuture<Void> putAllAsync(Map<? extends K, ? extends V> data, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
    /**
     * Asynchronous version of {@link #clear()}.  This method does not block on remote calls, even if your cache mode is
     * synchronous.  Has no benefit over {@link #clear()} if used in LOCAL mode.
     *
     * @return a future containing a void return type
     */
-   Future<Void> clearAsync();
+   NotifyingFuture<Void> clearAsync();
 
    /**
     * Asynchronous version of {@link #putIfAbsent(Object, Object)}.  This method does not block on remote calls, even if
@@ -393,7 +394,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param value value to store
     * @return a future containing the old value replaced.
     */
-   Future<V> putIfAbsentAsync(K key, V value);
+   NotifyingFuture<V> putIfAbsentAsync(K key, V value);
 
    /**
     * Asynchronous version of {@link #putIfAbsent(Object, Object, long, TimeUnit)} .  This method does not block on
@@ -406,7 +407,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param unit     time unit for lifespan
     * @return a future containing the old value replaced
     */
-   Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit unit);
+   NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit unit);
 
    /**
     * Asynchronous version of {@link #putIfAbsent(Object, Object, long, TimeUnit, long, TimeUnit)}.  This method does
@@ -422,7 +423,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param maxIdleUnit  time unit for max idle time
     * @return a future containing the old value replaced
     */
-   Future<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
+   NotifyingFuture<V> putIfAbsentAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
    /**
     * Asynchronous version of {@link #remove(Object)}.  This method does not block on remote calls, even if your cache
@@ -431,7 +432,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param key key to remove
     * @return a future containing the value removed
     */
-   Future<V> removeAsync(Object key);
+   NotifyingFuture<V> removeAsync(Object key);
 
    /**
     * Asynchronous version of {@link #remove(Object, Object)}.  This method does not block on remote calls, even if your
@@ -441,7 +442,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param value value to match on
     * @return a future containing a boolean, indicating whether the entry was removed or not
     */
-   Future<Boolean> removeAsync(Object key, Object value);
+   NotifyingFuture<Boolean> removeAsync(Object key, Object value);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object)}.  This method does not block on remote calls, even if
@@ -451,7 +452,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param value value to store
     * @return a future containing the previous value overwritten
     */
-   Future<V> replaceAsync(K key, V value);
+   NotifyingFuture<V> replaceAsync(K key, V value);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object, long, TimeUnit)}.  This method does not block on remote
@@ -464,7 +465,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param unit     time unit for lifespan
     * @return a future containing the previous value overwritten
     */
-   Future<V> replaceAsync(K key, V value, long lifespan, TimeUnit unit);
+   NotifyingFuture<V> replaceAsync(K key, V value, long lifespan, TimeUnit unit);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object, long, TimeUnit, long, TimeUnit)}.  This method does not
@@ -480,7 +481,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param maxIdleUnit  time unit for max idle time
     * @return a future containing the previous value overwritten
     */
-   Future<V> replaceAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
+   NotifyingFuture<V> replaceAsync(K key, V value, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object, Object)}.  This method does not block on remote calls,
@@ -492,7 +493,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param newValue value to store
     * @return a future containing a boolean, indicating whether the entry was replaced or not
     */
-   Future<Boolean> replaceAsync(K key, V oldValue, V newValue);
+   NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object, Object, long, TimeUnit)}.  This method does not block on
@@ -506,7 +507,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param unit     time unit for lifespan
     * @return a future containing a boolean, indicating whether the entry was replaced or not
     */
-   Future<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit unit);
+   NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit unit);
 
    /**
     * Asynchronous version of {@link #replace(Object, Object, Object, long, TimeUnit, long, TimeUnit)}.  This method
@@ -523,7 +524,7 @@ public interface Cache<K, V> extends ConcurrentMap<K, V>, Lifecycle, Listenable
     * @param maxIdleUnit  time unit for max idle time
     * @return a future containing a boolean, indicating whether the entry was replaced or not
     */
-   Future<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
+   NotifyingFuture<Boolean> replaceAsync(K key, V oldValue, V newValue, long lifespan, TimeUnit lifespanUnit, long maxIdle, TimeUnit maxIdleUnit);
 
 
    AdvancedCache<K, V> getAdvancedCache();",2009-05-20T15:18:23Z,99
"@@ -1,49 +0,0 @@
-package org.infinispan.distribution;
-
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.Future;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.TimeoutException;
-
-/**
- * A version of the async return values for dist
- *
- * @author Manik Surtani
- * @since 4.0
- */
-public class DistAsyncReturnValue implements Future<Object> {
-   final Future<Object> invalFuture, replFuture;
-   final Object returnValue;
-
-   public DistAsyncReturnValue(Future<Object> invalFuture, Future<Object> replFuture, Object returnValue) {
-      this.invalFuture = invalFuture;
-      this.replFuture = replFuture;
-      this.returnValue = returnValue;
-   }
-
-   public boolean cancel(boolean mayInterruptIfRunning) {
-      boolean invalCancelled = true;
-      if (invalFuture != null) invalCancelled = invalFuture.cancel(mayInterruptIfRunning);
-      return replFuture.cancel(mayInterruptIfRunning) && invalCancelled;
-   }
-
-   public boolean isCancelled() {
-      return replFuture.isCancelled() && (invalFuture == null || invalFuture.isCancelled());
-   }
-
-   public boolean isDone() {
-      return replFuture.isDone() && (invalFuture == null || invalFuture.isDone());
-   }
-
-   public Object get() throws InterruptedException, ExecutionException {
-      if (invalFuture != null) invalFuture.get();
-      replFuture.get();
-      return returnValue;
-   }
-
-   public Object get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {
-      if (invalFuture != null) invalFuture.get(timeout, unit);
-      replFuture.get(timeout, unit);
-      return returnValue;
-   }
-}",2009-05-20T15:18:23Z,100
"@@ -17,21 +17,22 @@
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.DistAsyncReturnValue;
 import org.infinispan.distribution.DistributionManager;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Start;
 import org.infinispan.interceptors.base.BaseRpcInterceptor;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.util.Immutables;
+import org.infinispan.util.concurrent.AggregatingNotifyingFutureImpl;
+import org.infinispan.util.concurrent.NotifyingFutureImpl;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 
 import java.util.ArrayList;
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.concurrent.Future;
 
 /**
  * The interceptor that handles distribution of entries across a cluster, as well as transparent lookup
@@ -233,39 +234,37 @@ private Object handleWriteCommand(InvocationContext ctx, WriteCommand command, R
             if (ctx.isOriginLocal()) {
                List<Address> rec = recipientGenerator.generateRecipients();
                if (trace) log.trace(""Invoking command {0} on hosts {1}"", command, rec);
-               Future<Object> f1 = null, f2;
                boolean useFuture = ctx.isUseFutureReturnType();
                boolean sync = isSynchronous(ctx);
-
+               NotifyingNotifiableFuture<Object> future = null;
                // if L1 caching is used make sure we broadcast an invalidate message
                if (isL1CacheEnabled && rec != null && rpcManager.getTransport().getMembers().size() > rec.size()) {
                   InvalidateCommand ic = cf.buildInvalidateFromL1Command(recipientGenerator.getKeys());
-                  f1 = submitRpc(null, ic, sync, useFuture);
+                  if (useFuture) {
+                     future = new AggregatingNotifyingFutureImpl(returnValue, 2);
+                     rpcManager.broadcastRpcCommandInFuture(ic, future);
+                  } else {
+                     rpcManager.broadcastRpcCommand(ic, sync);
+                  }
                }
-               f2 = submitRpc(rec, command, sync, useFuture);
 
-               if (f2 != null) return new DistAsyncReturnValue(f1, f2, returnValue);
+               if (useFuture) {
+                  if (future == null) future = new NotifyingFutureImpl(returnValue);
+                  rpcManager.anycastRpcCommandInFuture(rec, command, future);
+                  return future;
+               } else {
+                  rpcManager.anycastRpcCommand(rec, command, sync);
+               }
             }
          } else {
             if (!localModeForced) {
                ((TxInvocationContext) ctx).addTransactionParticipants(recipientGenerator.generateRecipients());
-            } else {
-               // add to list of participants
             }
          }
       }
       return returnValue;
    }
 
-   private Future<Object> submitRpc(final List<Address> recipients, final WriteCommand cmd, final boolean sync, boolean useFuture) {
-      if (useFuture) {
-         return rpcManager.anycastRpcCommandInFuture(recipients, cmd);
-      } else {
-         rpcManager.anycastRpcCommand(recipients, cmd, sync);
-         return null;
-      }
-   }
-
    interface RecipientGenerator {
       List<Address> generateRecipients();
 ",2009-05-20T15:18:23Z,101
"@@ -21,7 +21,6 @@
  */
 package org.infinispan.interceptors;
 
-import org.infinispan.AsyncReturnValue;
 import org.infinispan.commands.AbstractVisitor;
 import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.VisitableCommand;
@@ -41,6 +40,8 @@
 import org.infinispan.jmx.annotations.ManagedAttribute;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.util.concurrent.NotifyingFutureImpl;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 
 import javax.transaction.SystemException;
 import javax.transaction.Transaction;
@@ -195,7 +196,9 @@ protected Object invalidateAcrossCluster(boolean synchronous, InvocationContext
             log.debug(""Cache ["" + rpcManager.getTransport().getAddress() + ""] replicating "" + command);
          // voila, invalidated!
          if (useFuture) {
-            return new AsyncReturnValue(rpcManager.broadcastRpcCommandInFuture(command), retvalForFuture);
+            NotifyingNotifiableFuture<Object> future = new NotifyingFutureImpl(retvalForFuture);
+            rpcManager.broadcastRpcCommandInFuture(command, future);
+            return future;
          } else {
             rpcManager.broadcastRpcCommand(command, synchronous);
          }",2009-05-20T15:18:23Z,102
"@@ -21,7 +21,6 @@
  */
 package org.infinispan.interceptors;
 
-import org.infinispan.AsyncReturnValue;
 import org.infinispan.commands.LockControlCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
@@ -36,6 +35,8 @@
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.interceptors.base.BaseRpcInterceptor;
+import org.infinispan.util.concurrent.NotifyingFutureImpl;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 
 /**
  * Takes care of replicating modifications to other caches in a cluster. Also listens for prepare(), commit() and
@@ -116,7 +117,9 @@ private Object handleCrudMethod(final InvocationContext ctx, final WriteCommand
       final Object returnValue = invokeNextInterceptor(ctx, command);
       if (!isLocalModeForced(ctx) && command.isSuccessful() && ctx.isOriginLocal() && !ctx.isInTxScope()) {
          if (ctx.isUseFutureReturnType()) {
-            return new AsyncReturnValue(rpcManager.broadcastRpcCommandInFuture(command), returnValue);
+            NotifyingNotifiableFuture<Object> future = new NotifyingFutureImpl(returnValue);
+            rpcManager.broadcastRpcCommandInFuture(command, future);
+            return future;
          } else {
             rpcManager.broadcastRpcCommand(command, isSynchronous(ctx));
          }",2009-05-20T15:18:23Z,103
"@@ -27,9 +27,9 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.statetransfer.StateTransferException;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 
 import java.util.List;
-import java.util.concurrent.Future;
 
 /**
  * Provides a mechanism for communicating with other caches in the cluster, by formatting and passing requests down to
@@ -119,10 +119,10 @@ public interface RpcManager {
     * is passed to the transport executor and a Future is returned.  The transport always deals with this
     * synchronously.
     *
-    * @param rpc command to execute remotely
-    * @return a future
+    * @param rpc    command to execute remotely
+    * @param future the future which will be passed back to the user
     */
-   Future<Object> broadcastRpcCommandInFuture(ReplicableCommand rpc);
+   void broadcastRpcCommandInFuture(ReplicableCommand rpc, NotifyingNotifiableFuture<Object> future);
 
    /**
     * The same as {@link #broadcastRpcCommand(org.infinispan.commands.ReplicableCommand, boolean, boolean)} except that
@@ -131,9 +131,9 @@ public interface RpcManager {
     *
     * @param rpc              command to execute remotely
     * @param usePriorityQueue if true, a priority queue is used
-    * @return a future
+    * @param future           the future which will be passed back to the user
     */
-   Future<Object> broadcastRpcCommandInFuture(ReplicableCommand rpc, boolean usePriorityQueue);
+   void broadcastRpcCommandInFuture(ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future);
 
    /**
     * Broadcasts an RPC command to a specified set of recipients
@@ -164,9 +164,9 @@ public interface RpcManager {
     *
     * @param recipients recipients to invoke remote call on
     * @param rpc        command to execute remotely
-    * @return a future
+    * @param future     the future which will be passed back to the user
     */
-   Future<Object> anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc);
+   void anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc, NotifyingNotifiableFuture<Object> future);
 
    /**
     * The same as {@link #anycastRpcCommand(java.util.List, org.infinispan.commands.ReplicableCommand, boolean)} except
@@ -176,9 +176,9 @@ public interface RpcManager {
     * @param recipients       recipients to invoke remote call on
     * @param rpc              command to execute remotely
     * @param usePriorityQueue if true, a priority queue is used
-    * @return a future
+    * @param future           the future which will be passed back to the user
     */
-   Future<Object> anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc, boolean usePriorityQueue);
+   void anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future);
 
    /**
     * @return a reference to the underlying transport.",2009-05-20T15:18:23Z,104
"@@ -18,6 +18,7 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.statetransfer.StateTransferException;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -27,7 +28,6 @@
 import java.util.Random;
 import java.util.concurrent.Callable;
 import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Future;
 import java.util.concurrent.atomic.AtomicLong;
 
 /**
@@ -180,12 +180,12 @@ public final void broadcastRpcCommand(ReplicableCommand rpc, boolean sync, boole
       }
    }
 
-   public final Future<Object> broadcastRpcCommandInFuture(ReplicableCommand rpc) {
-      return broadcastRpcCommandInFuture(rpc, false);
+   public final void broadcastRpcCommandInFuture(ReplicableCommand rpc, NotifyingNotifiableFuture<Object> l) {
+      broadcastRpcCommandInFuture(rpc, false, l);
    }
 
-   public final Future<Object> broadcastRpcCommandInFuture(ReplicableCommand rpc, boolean usePriorityQueue) {
-      return anycastRpcCommandInFuture(null, rpc, usePriorityQueue);
+   public final void broadcastRpcCommandInFuture(ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> l) {
+      anycastRpcCommandInFuture(null, rpc, usePriorityQueue, l);
    }
 
    public final void anycastRpcCommand(List<Address> recipients, ReplicableCommand rpc, boolean sync) throws ReplicationException {
@@ -219,18 +219,19 @@ public final void anycastRpcCommand(List<Address> recipients, ReplicableCommand
       }
    }
 
-   public final Future<Object> anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc) {
-      return anycastRpcCommandInFuture(recipients, rpc, false);
+   public final void anycastRpcCommandInFuture(List<Address> recipients, ReplicableCommand rpc, NotifyingNotifiableFuture<Object> l) {
+      anycastRpcCommandInFuture(recipients, rpc, false, l);
    }
 
-   public final Future<Object> anycastRpcCommandInFuture(final List<Address> recipients, final ReplicableCommand rpc, final boolean usePriorityQueue) {
+   public final void anycastRpcCommandInFuture(final List<Address> recipients, final ReplicableCommand rpc, final boolean usePriorityQueue, final NotifyingNotifiableFuture<Object> l) {
       Callable<Object> c = new Callable<Object>() {
          public Object call() {
             anycastRpcCommand(recipients, rpc, true, usePriorityQueue);
+            l.notifyDone();
             return null;
          }
       };
-      return asyncExecutor.submit(c);
+      l.setNetworkFuture(asyncExecutor.submit(c));
    }
 
    public Transport getTransport() {",2009-05-20T15:18:23Z,105
"@@ -0,0 +1,69 @@
+package org.infinispan.util.concurrent;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * For use with > 1 underlying network future
+ *
+ * @author Manik Surtani
+ * @since 4.0
+ */
+public class AggregatingNotifyingFutureImpl extends NotifyingFutureImpl {
+   final List<Future<Object>> futures;
+   final AtomicInteger awaitingCompletions = new AtomicInteger();
+
+   public AggregatingNotifyingFutureImpl(Object actualReturnValue, int maxFutures) {
+      super(actualReturnValue);
+      futures = new ArrayList<Future<Object>>(maxFutures);
+      awaitingCompletions.set(maxFutures);
+   }
+
+   @Override
+   public void setNetworkFuture(Future<Object> future) {
+      futures.add(future);
+   }
+
+   @Override
+   public boolean cancel(boolean mayInterruptIfRunning) {
+      boolean aggregateValue = false;
+      for (Future<Object> f : futures) aggregateValue = f.cancel(mayInterruptIfRunning) && aggregateValue;
+      return aggregateValue;
+   }
+
+   @Override
+   public boolean isCancelled() {
+      for (Future<Object> f : futures) if (f.isCancelled()) return true;
+      return false;
+   }
+
+   @Override
+   public boolean isDone() {
+      for (Future<Object> f : futures) if (!f.isDone()) return false;
+      return true;
+   }
+
+   @Override
+   public Object get() throws InterruptedException, ExecutionException {
+      for (Future<Object> f : futures) f.get();
+      return actualReturnValue;
+   }
+
+   @Override
+   public Object get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, java.util.concurrent.TimeoutException {
+      for (Future<Object> f : futures) f.get(timeout, unit);
+      return actualReturnValue;
+   }
+
+   @Override
+   public void notifyDone() {
+      if (awaitingCompletions.decrementAndGet() == 0) {
+         callCompleted = true;
+         for (FutureListener<Object> l : listeners) l.futureDone(this);
+      }
+   }
+}",2009-05-20T15:18:23Z,106
"@@ -0,0 +1,18 @@
+package org.infinispan.util.concurrent;
+
+import java.util.concurrent.Future;
+
+/**
+ * A listener that is called back when a future is done.  FutureListener instances are attached to {@link
+ * NotifyingFuture}s by passing them in to {@link NotifyingFuture#attachListener(FutureListener)}
+ * <p/>
+ * Note that the {@link #futureDone(Future)} callback is invoked when the future completes, regardless of how the future
+ * completes (i.e., normally, due to an exception, or cancelled}.  As such, implementations should check the future
+ * passed in by calling <tt>future.get()</tt>.
+ *
+ * @author Manik Surtani
+ * @since 4.0
+ */
+public interface FutureListener<T> {
+   void futureDone(Future<T> future);
+}",2009-05-20T15:18:23Z,107
"@@ -0,0 +1,29 @@
+package org.infinispan.util.concurrent;
+
+import java.util.concurrent.Future;
+
+/**
+ * A sub-interface of a Future, that allows for listeners to be attached so that observers can be notified of when the
+ * future completes.
+ * <p/>
+ * See {@link FutureListener} for more details.
+ * <p/>
+ * {@link #attachListener(FutureListener)} returns the same future instance, which is useful for 'building' a future.
+ * E.g.,
+ * <p/>
+ * <code> Future<Void> f = cache.clearAsync().attachListener(new MyCustomListener()); </code>
+ *
+ * @author Manik Surtani
+ * @since 4.0
+ */
+public interface NotifyingFuture<T> extends Future<T> {
+
+   /**
+    * Attaches a listener and returns the same future instance, to allow for 'building'.
+    *
+    * @param listener listener to attach
+    * @return the same future instance
+    */
+   NotifyingFuture<T> attachListener(FutureListener<T> listener);
+
+}",2009-05-20T15:18:23Z,108
"@@ -0,0 +1,67 @@
+package org.infinispan.util.concurrent;
+
+import java.util.Set;
+import java.util.concurrent.CopyOnWriteArraySet;
+import java.util.concurrent.ExecutionException;
+import java.util.concurrent.Future;
+import java.util.concurrent.TimeUnit;
+
+/**
+ * Constructs an instance of a {@link org.infinispan.util.concurrent.NotifyingFuture}.
+ * <p/>
+ * Typical usage:
+ * <p/>
+ * <code> Object retval = .... // do some work here NotifyingFuture nf = new NotifyingFutureImpl(retval);
+ * rpcManager.broadcastRpcCommandInFuture(nf, command); return nf; </code>
+ *
+ * @author Manik Surtani
+ * @since 4.0
+ */
+public class NotifyingFutureImpl implements NotifyingNotifiableFuture<Object> {
+
+   final Object actualReturnValue;
+   volatile Future<Object> ioFuture;
+   volatile boolean callCompleted = false;
+   final Set<FutureListener<Object>> listeners = new CopyOnWriteArraySet<FutureListener<Object>>();
+
+   public NotifyingFutureImpl(Object actualReturnValue) {
+      this.actualReturnValue = actualReturnValue;
+   }
+
+   public void setNetworkFuture(Future<Object> future) {
+      this.ioFuture = future;
+   }
+
+   public boolean cancel(boolean mayInterruptIfRunning) {
+      return ioFuture.cancel(mayInterruptIfRunning);
+   }
+
+   public boolean isCancelled() {
+      return ioFuture.isCancelled();
+   }
+
+   public boolean isDone() {
+      return ioFuture.isDone();
+   }
+
+   public Object get() throws InterruptedException, ExecutionException {
+      ioFuture.get();
+      return actualReturnValue;
+   }
+
+   public Object get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, java.util.concurrent.TimeoutException {
+      ioFuture.get(timeout, unit);
+      return actualReturnValue;
+   }
+
+   public void notifyDone() {
+      callCompleted = true;
+      for (FutureListener<Object> l : listeners) l.futureDone(this);
+   }
+
+   public NotifyingFuture<Object> attachListener(FutureListener<Object> objectFutureListener) {
+      if (!callCompleted) listeners.add(objectFutureListener);
+      if (callCompleted) objectFutureListener.futureDone(this);
+      return this;
+   }
+}
\ No newline at end of file",2009-05-20T15:18:23Z,109
"@@ -0,0 +1,15 @@
+package org.infinispan.util.concurrent;
+
+import java.util.concurrent.Future;
+
+/**
+ * An internal interface which adds the ability to inform the future of completion.
+ *
+ * @author Manik Surtani
+ * @since 4.0
+ */
+public interface NotifyingNotifiableFuture<Object> extends NotifyingFuture<Object> {
+   void notifyDone();
+
+   void setNetworkFuture(Future<java.lang.Object> future);
+}",2009-05-20T15:18:23Z,110
"@@ -66,7 +66,9 @@ public class InboundTransferTask {
 
    private final long timeout;
 
-   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout) {
+   private final String cacheName;
+
+   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""segments must not be null or empty"");
       }
@@ -81,6 +83,7 @@ public InboundTransferTask(Set<Integer> segments, Address source, int topologyId
       this.rpcManager = rpcManager;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public Set<Integer> getSegments() {
@@ -93,7 +96,7 @@ public Address getSource() {
 
    public boolean requestTransactions() {
       if (trace) {
-         log.tracef(""Requesting transactions for segments %s"", segments);
+         log.tracef(""Requesting transactions for segments %s of cache %s from node %s"", segments, cacheName, source);
       }
       // get transactions and locks
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.GET_TRANSACTIONS, rpcManager.getAddress(), topologyId, segments);
@@ -109,6 +112,10 @@ public boolean requestTransactions() {
    }
 
    public boolean requestSegments() {
+      if (trace) {
+         log.tracef(""Requesting segments %s of cache %s from node %s"", segments, cacheName, source);
+      }
+
       // start transfer of cache entries
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.START_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
       Map<Address, Response> responses = rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
@@ -139,24 +146,21 @@ public void cancel() {
       if (!isCancelled) {
          isCancelled = true;
 
-         Set<Integer> cancelledSegments = new HashSet<Integer>(segments);
-         segments.clear();
-         finishedSegments.clear();
-
-         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, cancelledSegments);
+         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
          rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
 
          stateConsumer.onTaskCompletion(this);
       }
    }
 
    public void onStateReceived(int segmentId, boolean isLastChunk) {
-      if (!isCancelled && segments.contains(segmentId)) {
-         if (isLastChunk) {
-            finishedSegments.add(segmentId);
-            if (finishedSegments.containsAll(segments)) {
-               stateConsumer.onTaskCompletion(this);
+      if (!isCancelled && isLastChunk && segments.contains(segmentId)) {
+         finishedSegments.add(segmentId);
+         if (finishedSegments.containsAll(segments)) {
+            if (trace) {
+               log.tracef(""Finished receiving state for segments %s of cache %s"", segments, cacheName);
             }
+            stateConsumer.onTaskCompletion(this);
          }
       }
    }
@@ -166,11 +170,14 @@ public String toString() {
       HashSet<Integer> unfinishedSegments = new HashSet<Integer>(segments);
       unfinishedSegments.removeAll(finishedSegments);
       return ""InboundTransferTask{"" +
-            ""unfinishedSegments="" + unfinishedSegments +
+            ""segments="" + segments +
+            "", finishedSegments="" + finishedSegments +
+            "", unfinishedSegments="" + unfinishedSegments +
             "", source="" + source +
             "", isCancelled="" + isCancelled +
             "", topologyId="" + topologyId +
             "", timeout="" + timeout +
+            "", cacheName="" + cacheName +
             '}';
    }
 }",2012-11-07T14:07:34Z,120
"@@ -24,20 +24,19 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.commands.CommandsFactory;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheLoaderManager;
 import org.infinispan.loaders.CacheStore;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.SuspectException;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
-import org.infinispan.util.concurrent.AggregatingNotifyingFutureBuilder;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -70,8 +69,6 @@ public class OutboundTransferTask implements Runnable {
 
    private final int stateTransferChunkSize;
 
-   private final Configuration configuration;
-
    private final ConsistentHash readCh;
 
    private final DataContainer dataContainer;
@@ -84,27 +81,24 @@ public class OutboundTransferTask implements Runnable {
 
    private final long timeout;
 
+   private final String cacheName;
+
    private final Map<Integer, List<InternalCacheEntry>> entriesBySegment = ConcurrentMapFactory.makeConcurrentMap();
 
    /**
     * The total number of entries from all segments accumulated in entriesBySegment.
     */
    private int accumulatedEntries;
 
-   /**
-    * This is used with RpcManager.invokeRemotelyInFuture() to be able to cancel message sending if the task needs to be canceled.
-    */
-   private final NotifyingNotifiableFuture<Object> sendFuture = new AggregatingNotifyingFutureBuilder(null);
-
    /**
     * The Future obtained from submitting this task to an executor service. This is used for cancellation.
     */
    private FutureTask runnableFuture;
 
    public OutboundTransferTask(Address destination, Set<Integer> segments, int stateTransferChunkSize,
                                int topologyId, ConsistentHash readCh, StateProviderImpl stateProvider, DataContainer dataContainer,
-                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager, Configuration configuration,
-                               CommandsFactory commandsFactory, long timeout) {
+                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager,
+                               CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""Segments must not be null or empty"");
       }
@@ -123,9 +117,9 @@ public OutboundTransferTask(Address destination, Set<Integer> segments, int stat
       this.dataContainer = dataContainer;
       this.cacheLoaderManager = cacheLoaderManager;
       this.rpcManager = rpcManager;
-      this.configuration = configuration;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public void execute(ExecutorService executorService) {
@@ -154,7 +148,7 @@ public void run() {
       try {
          // send data container entries
          for (InternalCacheEntry ice : dataContainer) {
-            Object key = ice.getKey();
+            Object key = ice.getKey();  //todo [anistor] should we check for expired entries?
             int segmentId = readCh.getSegment(key);
             if (segments.contains(segmentId)) {
                sendEntry(ice, segmentId);
@@ -198,7 +192,7 @@ public void run() {
          }
       }
       if (trace) {
-         log.tracef(""Outbound transfer of segments %s to %s is complete"", segments, destination);
+         log.tracef(""Outbound transfer of segments %s of cache %s to node %s is complete"", segments, cacheName, destination);
       }
    }
 
@@ -217,7 +211,6 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
       // send if we have a full chunk
       if (accumulatedEntries >= stateTransferChunkSize) {
          sendEntries(false);
-         entriesBySegment.clear();
          accumulatedEntries = 0;
       }
 
@@ -232,32 +225,42 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
 
    private void sendEntries(boolean isLast) {
       List<StateChunk> chunks = new ArrayList<StateChunk>();
+      for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
+         List<InternalCacheEntry> entries = e.getValue();
+         if (!entries.isEmpty()) {
+            chunks.add(new StateChunk(e.getKey(), new ArrayList<InternalCacheEntry>(entries), isLast));
+            entries.clear();
+         }
+      }
+
       if (isLast) {
          for (int segmentId : segments) {
             List<InternalCacheEntry> entries = entriesBySegment.get(segmentId);
             if (entries == null) {
-               entries = InfinispanCollections.emptyList();
-            }
-            chunks.add(new StateChunk(segmentId, entries, isLast));
-         }
-      } else {
-         for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
-            List<InternalCacheEntry> entries = e.getValue();
-            if (!entries.isEmpty()) {
-               chunks.add(new StateChunk(e.getKey(), entries, isLast));
+               chunks.add(new StateChunk(segmentId, InfinispanCollections.<InternalCacheEntry>emptyList(), true));
             }
          }
       }
 
-      if (!chunks.isEmpty() || isLast) {
+      if (!chunks.isEmpty()) {
          if (trace) {
-            log.tracef(""Sending %d cache entries from segments %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), destination);
+            if (isLast) {
+               log.tracef(""Sending last chunk containing %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, segments, cacheName, destination);
+            } else {
+               log.tracef(""Sending %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), cacheName, destination);
+            }
          }
 
-         //todo [anistor] send back the received topologyId or my local one?
          StateResponseCommand cmd = commandsFactory.buildStateResponseCommand(rpcManager.getAddress(), topologyId, chunks);
-         // send synchronously, in FIFO mode. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
-         rpcManager.invokeRemotelyInFuture(Collections.singleton(destination), cmd, false, sendFuture, timeout);
+         // send synchronously, in order. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
+         try {
+            rpcManager.invokeRemotely(Collections.singleton(destination), cmd, ResponseMode.SYNCHRONOUS, timeout, false, null);
+         } catch (SuspectException e) {
+            log.errorf(e, ""Node %s left cache %s: %s"", destination, cacheName, e.getMessage());
+            cancel();
+         } catch (Exception e) {
+            log.errorf(e, ""Failed to send entries to node %s : %s"", destination, e.getMessage());
+         }
       }
    }
 
@@ -268,7 +271,7 @@ private void sendEntries(boolean isLast) {
     */
    public void cancelSegments(Set<Integer> cancelledSegments) {
       if (trace) {
-         log.tracef(""Cancelling outbound transfer of segments %s to %s"", cancelledSegments, destination);
+         log.tracef(""Cancelling outbound transfer of segments %s of cache %s to node %s"", cancelledSegments, cacheName, destination);
       }
       if (segments.removeAll(cancelledSegments)) {
          entriesBySegment.keySet().removeAll(cancelledSegments);  // here we do not update accumulatedEntries but this inaccuracy does not cause any harm
@@ -284,11 +287,22 @@ public void cancelSegments(Set<Integer> cancelledSegments) {
    public void cancel() {
       if (runnableFuture != null && !runnableFuture.isCancelled()) {
          runnableFuture.cancel(true);
-         sendFuture.cancel(true);
       }
    }
 
    public boolean isCancelled() {
       return runnableFuture != null && runnableFuture.isCancelled();
    }
+
+   @Override
+   public String toString() {
+      return ""OutboundTransferTask{"" +
+            ""topologyId="" + topologyId +
+            "", destination="" + destination +
+            "", segments="" + segments +
+            "", stateTransferChunkSize="" + stateTransferChunkSize +
+            "", timeout="" + timeout +
+            "", cacheName='"" + cacheName + '\'' +
+            '}';
+   }
 }",2012-11-07T14:07:34Z,121
"@@ -45,7 +45,6 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -62,7 +61,7 @@
 import static org.infinispan.context.Flag.*;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateConsumer} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -72,7 +71,7 @@ public class StateConsumerImpl implements StateConsumer {
    private static final Log log = LogFactory.getLog(StateConsumerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
-   private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
    private Configuration configuration;
    private RpcManager rpcManager;
@@ -119,7 +118,7 @@ public StateConsumerImpl() {
 
    @Inject
    public void init(Cache cache,
-                    LocalTopologyManager localTopologyManager,
+                    StateTransferManager stateTransferManager,
                     InterceptorChain interceptorChain,
                     InvocationContextContainer icc,
                     Configuration configuration,
@@ -130,7 +129,7 @@ public void init(Cache cache,
                     TransactionTable transactionTable,
                     StateTransferLock stateTransferLock) {
       this.cacheName = cache.getName();
-      this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
       this.interceptorChain = interceptorChain;
       this.icc = icc;
       this.configuration = configuration;
@@ -171,26 +170,30 @@ public boolean isStateTransferInProgressForKey(Object key) {
 
    @Override
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
-      if (trace) log.tracef(""Received new CH: %s"", cacheTopology.getWriteConsistentHash());
+      if (trace) log.tracef(""Received new CH %s for cache %s"", cacheTopology.getWriteConsistentHash(), cacheName);
 
       activeTopologyUpdates.incrementAndGet();
       if (isRebalance) {
          rebalanceInProgress.set(true);
       }
-      ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
+      final ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
       // Ensures writes to the data container use the right consistent hash
       // No need for a try/finally block, since it's just an assignment
       stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
       stateTransferLock.releaseExclusiveTopologyLock();
-      stateTransferLock.topologyInstalled(cacheTopology.getTopologyId());
+      stateTransferLock.notifyTopologyInstalled(cacheTopology.getTopologyId());
 
       try {
          Set<Integer> addedSegments;
          if (previousCh == null) {
             // we start fresh, without any data, so we need to pull everything we own according to writeCh
 
             addedSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
+
+            if (trace) {
+               log.tracef(""On cache %s we have: added segments: %s"", cacheName, addedSegments);
+            }
          } else {
             Set<Integer> previousSegments = getOwnedSegments(previousCh);
             Set<Integer> newSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
@@ -199,16 +202,16 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             Set<Integer> removedSegments = new HashSet<Integer>(previousSegments);
             removedSegments.removeAll(newSegments);
 
-            // remove inbound transfers and any data for segments we no longer own
+            addedSegments = new HashSet<Integer>(newSegments);
+            addedSegments.removeAll(previousSegments);
+
             if (trace) {
-               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                     removedSegments, newSegments, previousSegments);
+               log.tracef(""On cache %s we have: removed segments: %s; new segments: %s; old segments: %s; added segments: %s"",
+                     cacheName, removedSegments, newSegments, previousSegments, addedSegments);
             }
-            discardSegments(removedSegments);
 
-            Set<Integer> currentSegments = getOwnedSegments(cacheTopology.getReadConsistentHash());
-            addedSegments = new HashSet<Integer>(newSegments);
-            addedSegments.removeAll(currentSegments);
+            // remove inbound transfers and any data for segments we no longer own
+            discardSegments(removedSegments);
 
             // check if any of the existing transfers should be restarted from a different source because the initial source is no longer a member
             Set<Address> members = new HashSet<Address>(cacheTopology.getReadConsistentHash().getMembers());
@@ -230,24 +233,30 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
                      }
                   }
                }
+
+               // exclude those that are already in progress from a valid source
+               addedSegments.removeAll(transfersBySegment.keySet());
             }
          }
 
-         if (addedSegments != null && !addedSegments.isEmpty()) {
+         if (!addedSegments.isEmpty()) {
             addTransfers(addedSegments);  // add transfers for new or restarted segments
          }
       } finally {
-         stateTransferLock.transactionDataReceived(cacheTopology.getTopologyId());
+         stateTransferLock.notifyTransactionDataReceived(cacheTopology.getTopologyId());
 
-         if (activeTopologyUpdates.decrementAndGet() == 0 && !isStateTransferInProgress()) {
+         if (activeTopologyUpdates.decrementAndGet() == 0) {
             notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
          }
       }
    }
 
    private void notifyEndOfTopologyUpdate(int topologyId) {
-      if (rebalanceInProgress.compareAndSet(true, false)) {
-         localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+      if (!isStateTransferInProgress()) {
+         if (rebalanceInProgress.compareAndSet(true, false)) {
+            log.debugf(""Finished receiving of segments for cache %s for topology %d."", cacheName, topologyId);
+            stateTransferManager.notifyEndOfTopologyUpdate(topologyId);
+         }
       }
    }
 
@@ -262,43 +271,42 @@ public void applyState(Address sender, int topologyId, int segmentId, Collection
       //todo [anistor] this check should be based on topologyId
       if (!cacheTopology.getWriteConsistentHash().getSegmentsForOwner(rpcManager.getAddress()).contains(segmentId)) {
          if (trace) {
-            log.warnf(""Discarding received cache entries for segment %d because they do not belong to this node."", segmentId);
+            log.warnf(""Discarding received cache entries for segment %d of cache %s because they do not belong to this node."", segmentId, cacheName);
          }
          return;
       }
 
-      if (cacheEntries != null) {
-         doApplyState(sender, segmentId, cacheEntries);
-      }
-
       // notify the inbound task that a chunk of cache entries was received
       InboundTransferTask inboundTransfer;
       synchronized (this) {
          inboundTransfer = transfersBySegment.get(segmentId);
       }
       if (inboundTransfer != null) {
+         if (cacheEntries != null) {
+            doApplyState(sender, segmentId, cacheEntries);
+         }
+
          inboundTransfer.onStateReceived(segmentId, isLastChunk);
-      } else {
-         log.debugf(""Received unsolicited state for segment %d from node %s"", segmentId, sender);
-         return;
-      }
 
-      if (trace) {
-         log.tracef(""After applying the received state the data container has %d keys"", dataContainer.size());
-         synchronized (this) {
-            log.tracef(""Segments not received yet: %s"", transfersBySource);
+         if (trace) {
+            log.tracef(""After applying the received state the data container of cache %s has %d keys"", cacheName, dataContainer.size());
+            synchronized (this) {
+               log.tracef(""Segments not received yet for cache %s: %s"", cacheName, transfersBySource);
+            }
          }
+      } else {
+         log.warnf(""Received unsolicited state from node %s for segment %d of cache %s"", sender, segmentId, cacheName);
       }
    }
 
    private void doApplyState(Address sender, int segmentId, Collection<InternalCacheEntry> cacheEntries) {
-      log.debugf(""Applying new state for segment %d from %s: received %d cache entries"", segmentId, sender, cacheEntries.size());
+      log.debugf(""Applying new state for segment %d of cache %s from node %s: received %d cache entries"", segmentId, cacheName, sender, cacheEntries.size());
       if (trace) {
          List<Object> keys = new ArrayList<Object>(cacheEntries.size());
          for (InternalCacheEntry e : cacheEntries) {
             keys.add(e.getKey());
          }
-         log.tracef(""Received keys: %s"", keys);
+         log.tracef(""Received keys %s for segment %d of cache %s from node %s"", keys, segmentId, cacheName, sender);
       }
 
       // CACHE_MODE_LOCAL avoids handling by StateTransferInterceptor and any potential locks in StateTransferLock
@@ -316,10 +324,11 @@ private void doApplyState(Address sender, int segmentId, Collection<InternalCach
             log.problemApplyingStateForKey(ex.getMessage(), e.getKey());
          }
       }
+      log.debugf(""Finished applying state for segment %d of cache %s"", segmentId, cacheName);
    }
 
    public void applyTransactions(Address sender, int topologyId, Collection<TransactionInfo> transactions) {
-      log.debugf(""Applying %d transactions transferred from %s"", transactions.size(), sender);
+      log.debugf(""Applying %d transactions for cache %s transferred from node %s"", transactions.size(), cacheName, sender);
       if (configuration.transaction().transactionMode().isTransactional()) {
          for (TransactionInfo transactionInfo : transactions) {
             CacheTransaction tx = transactionTable.getLocalTransaction(transactionInfo.getGlobalTransaction());
@@ -374,30 +383,31 @@ public CacheTopology getCacheTopology() {
    }
 
    private void addTransfers(Set<Integer> segments) {
-      log.debugf(""Adding state transfer for segments: %s"", segments);
+      log.debugf(""Adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
 
       Set<Integer> segmentsToProcess = new HashSet<Integer>(segments);
-      Set<Address> blacklistedSources = new HashSet<Address>();
+      Set<Address> faultysources = new HashSet<Address>();
 
       // ignore all segments for which there are no other owners to pull data from.
       // these segments are considered empty (or lost) and do not require a state transfer
       for (Iterator<Integer> it = segmentsToProcess.iterator(); it.hasNext(); ) {
          Integer segmentId = it.next();
-         Address source = pickSourceOwner(segmentId, blacklistedSources);
+         Address source = pickSourceOwner(segmentId, faultysources);
          if (source == null) {
             it.remove();
          }
       }
 
-      synchronized (this) {
-         // already active transfers do not need to be added again
-         segmentsToProcess.removeAll(transfersBySegment.keySet());
-      }
-
       while (!segmentsToProcess.isEmpty()) {
          Map<Address, Set<Integer>> segmentsBySource = new HashMap<Address, Set<Integer>>();
          for (int segmentId : segmentsToProcess) {
-            Address source = pickSourceOwner(segmentId, blacklistedSources);
+            synchronized (this) {
+               // already active transfers do not need to be added again
+               if (transfersBySegment.containsKey(segmentId)) {
+                  continue;
+               }
+            }
+            Address source = pickSourceOwner(segmentId, faultysources);
             if (source != null) {
                Set<Integer> segmentsFromSource = segmentsBySource.get(source);
                if (segmentsFromSource == null) {
@@ -411,8 +421,14 @@ private void addTransfers(Set<Integer> segments) {
          Set<Integer> failedSegments = new HashSet<Integer>();
          for (Address source : segmentsBySource.keySet()) {
             Set<Integer> segmentsFromSource = segmentsBySource.get(source);
-            InboundTransferTask inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout);
+            InboundTransferTask inboundTransfer;
             synchronized (this) {
+               segmentsFromSource.removeAll(transfersBySegment.keySet());  // already in progress segments are excluded
+               if (segmentsFromSource.isEmpty()) {
+                  continue;
+               }
+
+               inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout, cacheName);
                for (int segmentId : segmentsFromSource) {
                   transfersBySegment.put(segmentId, inboundTransfer);
                }
@@ -427,9 +443,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the transactions fails we need to retry from another source
             if (configuration.transaction().transactionMode().isTransactional()) {
                if (!inboundTransfer.requestTransactions()) {
-                  log.errorf(""Failed to retrieve transactions for segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRetrieveTransactionsForSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                   continue;
                }
@@ -438,9 +454,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the segments fails we need to retry from another source
             if (fetchEnabled) {
                if (!inboundTransfer.requestSegments()) {
-                  log.errorf(""Failed to request segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRequestSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                }
             } else {
@@ -450,21 +466,22 @@ private void addTransfers(Set<Integer> segments) {
 
          segmentsToProcess = failedSegments;
       }
+      log.debugf(""Finished adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
    }
 
-   private Address pickSourceOwner(int segmentId, Set<Address> blacklistedSources) {
+   private Address pickSourceOwner(int segmentId, Set<Address> faultySources) {
       List<Address> owners = cacheTopology.getReadConsistentHash().locateOwnersForSegment(segmentId);
       if (owners.size() == 1 && owners.get(0).equals(rpcManager.getAddress())) {
          return null;
       }
 
       for (int i = owners.size() - 1; i >= 0; i--) {   // iterate backwards because we prefer to fetch from newer nodes
          Address o = owners.get(i);
-         if (!o.equals(rpcManager.getAddress()) && !blacklistedSources.contains(o)) {
+         if (!o.equals(rpcManager.getAddress()) && !faultySources.contains(o)) {
             return o;
          }
       }
-      log.errorf(""No live owners found for segment %d. Current owners are:  %s. Blacklisted owners: %s"", segmentId, owners, blacklistedSources);
+      log.noLiveOwnersFoundForSegment(segmentId, cacheName, owners, faultySources);
       return null;
    }
 
@@ -478,9 +495,9 @@ private void discardSegments(Set<Integer> segments) {
          List<Integer> segmentsToCancel = new ArrayList<Integer>(segments);
          while (!segmentsToCancel.isEmpty()) {
             int segmentId = segmentsToCancel.remove(0);
-            log.debugf(""Removing state transfer for segment %d"", segmentId);
             InboundTransferTask inboundTransfer = transfersBySegment.remove(segmentId);
             if (inboundTransfer != null) { // we need to check the transfer was not already completed
+               log.debugf(""Cancelling inbound state transfer for segment %d of cache %s"", segmentId, cacheName);
                Set<Integer> cancelledSegments = new HashSet<Integer>(segmentsToCancel);
                cancelledSegments.retainAll(inboundTransfer.getSegments());
                segmentsToCancel.removeAll(cancelledSegments);
@@ -489,6 +506,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      // gather all keys from data container that belong to the segments that are being removed
       Set<Object> keysToRemove = new HashSet<Object>();
       for (InternalCacheEntry ice : dataContainer) {
          Object key = ice.getKey();
@@ -497,7 +515,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
-      // we also remove keys from the cache store
+      // gather all keys from cache store that belong to the segments that are being removed
       CacheStore cacheStore = getCacheStore();
       if (cacheStore != null) {
          //todo [anistor] extend CacheStore interface to be able to specify a filter when loading keys (ie. keys should belong to desired segments)
@@ -514,13 +532,14 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      log.debugf(""Removing state for segments %s of cache %s"", segments, cacheName);
       if (!keysToRemove.isEmpty()) {
          try {
             InvalidateCommand invalidateCmd = commandsFactory.buildInvalidateFromL1Command(true, EnumSet.of(CACHE_MODE_LOCAL, SKIP_LOCKING), keysToRemove);
             InvocationContext ctx = icc.createNonTxInvocationContext();
             interceptorChain.invoke(ctx, invalidateCmd);
 
-            log.debugf(""Invalidated %d keys, data container now has %d keys"", keysToRemove.size(), dataContainer.size());
+            log.debugf(""Invalidated %d keys, data container of cache %s now has %d keys"", keysToRemove.size(), cacheName, dataContainer.size());
             if (trace) log.tracef(""Invalidated keys: %s"", keysToRemove);
          } catch (CacheException e) {
             log.failedToInvalidateKeys(e);
@@ -553,18 +572,17 @@ private void removeTransfer(InboundTransferTask inboundTransfer) {
                if (transfers.isEmpty()) {
                   transfersBySource.remove(inboundTransfer.getSource());
                }
-               for (int segmentId : inboundTransfer.getSegments()) {
-                  transfersBySegment.remove(segmentId);
-               }
+               transfersBySegment.keySet().removeAll(inboundTransfer.getSegments());
             }
          }
       }
    }
 
    void onTaskCompletion(InboundTransferTask inboundTransfer) {
+      log.tracef(""Completion of inbound transfer task: %s "", inboundTransfer);
       removeTransfer(inboundTransfer);
 
-      if (activeTopologyUpdates.get() == 0 && !isStateTransferInProgress()) {
+      if (activeTopologyUpdates.get() == 0) {
          notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
       }
    }",2012-11-07T14:07:34Z,54
"@@ -52,7 +52,7 @@
 import static org.infinispan.factories.KnownComponentNames.ASYNC_TRANSPORT_EXECUTOR;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateProvider} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -90,7 +90,7 @@ public StateProviderImpl() {
 
    @Inject
    public void init(Cache cache,
-                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //todo [anistor] use a separate ExecutorService
+                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //TODO Use a dedicated ExecutorService
                     Configuration configuration,
                     RpcManager rpcManager,
                     CommandsFactory commandsFactory,
@@ -184,7 +184,7 @@ public void stop() {
 
    public List<TransactionInfo> getTransactionsForSegments(Address destination, int requestTopologyId, Set<Integer> segments) throws InterruptedException {
       if (trace) {
-         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, requestTopologyId);
+         log.tracef(""Received request for transactions from node %s for segments %s of cache %s with topology id %d"", destination, segments, cacheName, requestTopologyId);
       }
 
       if (readCh == null) {
@@ -262,8 +262,8 @@ public void startOutboundTransfer(Address destination, int requestTopologyId, Se
       }
 
       // the destination node must already have an InboundTransferTask waiting for these segments
-      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, requestTopologyId,
-            readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
+      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId,
+            readCh, this, dataContainer, cacheLoaderManager, rpcManager, commandsFactory, timeout, cacheName);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);
    }
@@ -294,7 +294,7 @@ public void cancelOutboundTransfer(Address destination, int topologyId, Set<Inte
             // get an array copy of the collection to avoid ConcurrentModificationException if the entire task gets cancelled and removeTransfer(transferTask) is called
             OutboundTransferTask[] tasks = transferTasks.toArray(new OutboundTransferTask[transferTasks.size()]);
             for (OutboundTransferTask transferTask : tasks) {
-               transferTask.cancelSegments(segments); //this can potentially result in a removeTransfer(transferTask)
+               transferTask.cancelSegments(segments); //this can potentially result in a call to removeTransfer(transferTask)
             }
          }
       }",2012-11-07T14:07:34Z,55
"@@ -36,16 +36,13 @@
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
-import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
 import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
@@ -75,7 +72,7 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
+   public void init(StateTransferLock stateTransferLock, Configuration configuration,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
       this.commandFactory = commandFactory;",2012-11-07T14:07:34Z,115
"@@ -58,13 +58,13 @@ public interface StateTransferLock {
    void releaseSharedTopologyLock();
 
    // transaction data latch
-   void transactionDataReceived(int topologyId);
+   void notifyTransactionDataReceived(int topologyId);
 
    void waitForTransactionData(int expectedTopologyId) throws InterruptedException;
 
    // topology installation latch
    // TODO move this to Cluster/LocalTopologyManagerImpl and don't start requesting state until every node has the jgroups view with the local node
-   void topologyInstalled(int topologyId);
+   void notifyTopologyInstalled(int topologyId);
 
    void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-11-07T14:07:34Z,122
"@@ -23,12 +23,12 @@
 
 package org.infinispan.statetransfer;
 
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+
 /**
  * {@code StateTransferLock} implementation.
  *
@@ -38,6 +38,7 @@
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
+   private static final boolean trace = log.isTraceEnabled();
 
    private final ReadWriteLock ownershipLock = new ReentrantReadWriteLock();
 
@@ -68,8 +69,15 @@ public void releaseSharedTopologyLock() {
    }
 
    @Override
-   public void transactionDataReceived(int topologyId) {
-      this.transactionDataTopologyId = topologyId;
+   public void notifyTransactionDataReceived(int topologyId) {
+      if (topologyId < transactionDataTopologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + transactionDataTopologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling transaction data received for topology %d"", topologyId);
+      }
+      transactionDataTopologyId = topologyId;
       synchronized (transactionDataLock) {
          transactionDataLock.notifyAll();
       }
@@ -80,19 +88,32 @@ public void waitForTransactionData(int expectedTopologyId) throws InterruptedExc
       if (transactionDataTopologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
-            transactionDataTopologyId);
+      if (trace) {
+         log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
+               transactionDataTopologyId);
+      }
       synchronized (transactionDataLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (transactionDataTopologyId < expectedTopologyId) {
             transactionDataLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Received transaction data for topology %d, expected topology was %d"", transactionDataTopologyId,
+               expectedTopologyId);
+      }
    }
 
    @Override
-   public void topologyInstalled(int topologyId) {
+   public void notifyTopologyInstalled(int topologyId) {
+      if (topologyId < this.topologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + this.topologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling topology %d is installed"", topologyId);
+      }
       this.topologyId = topologyId;
       synchronized (topologyLock) {
          topologyLock.notifyAll();
@@ -104,14 +125,18 @@ public void waitForTopology(int expectedTopologyId) throws InterruptedException
       if (topologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId,
-            topologyId);
+      if (trace) {
+         log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId, topologyId);
+      }
       synchronized (topologyLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (topologyId < expectedTopologyId) {
             topologyLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Topology %d is now installed, expected topology was %d"", topologyId, expectedTopologyId);
+      }
    }
 }",2012-11-07T14:07:34Z,123
"@@ -81,4 +81,5 @@ public interface StateTransferManager {
     */
    void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
 
+   void notifyEndOfTopologyUpdate(int topologyId);
 }",2012-11-07T14:07:34Z,116
"@@ -70,7 +70,7 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private GroupManager groupManager;   // optional
    private LocalTopologyManager localTopologyManager;
 
-   private CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
+   private final CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
 
    public StateTransferManagerImpl() {
    }
@@ -170,13 +170,18 @@ private CacheTopology addGrouping(CacheTopology cacheTopology) {
 
    private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalance) {
       if (trace) {
-         log.tracef(""Installing new cache topology %s"", newCacheTopology);
+         log.tracef(""Installing new cache topology %s on cache %s"", newCacheTopology, cacheName);
       }
 
       // handle grouping
       newCacheTopology = addGrouping(newCacheTopology);
 
       CacheTopology oldCacheTopology = stateConsumer.getCacheTopology();
+
+      if (oldCacheTopology != null && oldCacheTopology.getTopologyId() > newCacheTopology.getTopologyId()) {
+         throw new IllegalStateException(""Old topology is higher: old="" + oldCacheTopology + "", new="" + newCacheTopology);
+      }
+
       ConsistentHash oldCH = oldCacheTopology != null ? oldCacheTopology.getWriteConsistentHash() : null;
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
@@ -188,15 +193,17 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
 
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
-      if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
+      boolean isJoined = stateConsumer.getCacheTopology().getReadConsistentHash().getMembers().contains(rpcManager.getAddress());
+      if (initialStateTransferComplete.getCount() > 0 && isJoined) {
          initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
    }
 
    @Start(priority = 1000)
    @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
-      if (trace) log.tracef(""Waiting for initial state transfer to finish"");
+      if (trace) log.tracef(""Waiting for initial state transfer to finish for cache %s on %s"", cacheName, rpcManager.getAddress());
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);
       if (!success) {
          throw new CacheException(String.format(""Initial state transfer timed out for cache %s on %s"",
@@ -210,6 +217,7 @@ public void stop() {
       if (trace) {
          log.tracef(""Shutting down StateTransferManager of cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
+      initialStateTransferComplete.countDown();
       localTopologyManager.leave(cacheName);
    }
 
@@ -268,4 +276,14 @@ public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object>
          }
       }
    }
+
+   @Override
+   public void notifyEndOfTopologyUpdate(int topologyId) {
+      if (initialStateTransferComplete.getCount() > 0
+            && stateConsumer.getCacheTopology().getWriteConsistentHash().getMembers().contains(rpcManager.getAddress())) {
+         initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
+      }
+      localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+   }
 }
\ No newline at end of file",2012-11-07T14:07:34Z,117
"@@ -126,13 +126,17 @@ public void triggerRebalance(final String cacheName) throws Exception {
       asyncTransportExecutor.submit(new Callable<Object>() {
          @Override
          public Object call() throws Exception {
-            startRebalance(cacheName);
-            return null;
+            try {
+               startRebalance(cacheName);
+               return null;
+            } catch (Throwable t) {
+               log.errorf(t, ""Failed to start rebalance: %s"", t.getMessage());
+               throw new Exception(t);
+            }
          }
       });
    }
 
-
    @Override
    public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo joinInfo, int viewId) throws Exception {
       waitForView(viewId);
@@ -594,6 +598,7 @@ public Object call() throws Exception {
             try {
                return command.perform(null);
             } catch (Throwable t) {
+               log.errorf(t, ""Failed to execute ReplicableCommand %s on cluster async: %s"", command, t.getMessage());
                throw new Exception(t);
             }
          }",2012-11-07T14:07:34Z,124
"@@ -280,6 +280,7 @@ public Object call() throws Exception {
                try {
                   return command.perform(null);
                } catch (Throwable t) {
+                  log.errorf(t, ""Failed to execute ReplicableCommand %s on coordinator async: %s"", command, t.getMessage());
                   throw new Exception(t);
                }
             }
@@ -298,8 +299,6 @@ class LocalCacheStatus {
    private final CacheTopologyHandler handler;
    private volatile CacheTopology topology;
 
-   private boolean joined;
-
    public LocalCacheStatus(CacheJoinInfo joinInfo, CacheTopologyHandler handler) {
       this.joinInfo = joinInfo;
       this.handler = handler;
@@ -320,12 +319,4 @@ public CacheTopology getTopology() {
    public void setTopology(CacheTopology topology) {
       this.topology = topology;
    }
-
-   public boolean isJoined() {
-      return joined;
-   }
-
-   public void setJoined(boolean joined) {
-      this.joined = joined;
-   }
 }",2012-11-07T14:07:34Z,125
"@@ -53,15 +53,14 @@ public class StaleTransactionCleanupService {
 
    private static Log log = LogFactory.getLog(StaleTransactionCleanupService.class);
 
+   private ScheduledExecutorService executorService;
 
    private TransactionTable transactionTable;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
-   private ScheduledExecutorService executorService;
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * because the main data owner left. Also unlocks keys for which the lock owner has changed as a result of a topology change.
@@ -71,15 +70,19 @@ public StaleTransactionCleanupService(TransactionTable transactionTable) {
    @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // Roll back remote transactions originating on nodes that have left the cluster.
-      if (tce.isPre()) {
-         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
-         if (consistentHashAtStart != null) {
-            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
-            if (!leavers.isEmpty()) {
-               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-               cleanTxForWhichTheOwnerLeft(leavers);
+      try {
+         if (tce.isPre()) {
+            ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+            if (consistentHashAtStart != null) {
+               List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+               if (!leavers.isEmpty()) {
+                  log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+                  cleanTxForWhichTheOwnerLeft(leavers);
+               }
             }
          }
+      } catch (Exception e) {
+         log.error(""Failed to process topology update"", e);
       }
    }
 
@@ -120,7 +123,6 @@ public void run() {
             transactionTable.cleanupCompletedTransactions();
          }
       }, interval, interval, TimeUnit.MILLISECONDS);
-
    }
 
    public void stop() {",2012-11-07T14:07:34Z,126
"@@ -523,25 +523,29 @@ public boolean isTransactionCompleted(GlobalTransaction gtx) {
    }
 
    public void cleanupCompletedTransactions() {
-      log.debugf(""About to cleanup completed transaction. Initial size is %s"", completedTransactions.size());
-      //this iterator is weekly consistent and will never throw ConcurrentModificationException
-      Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
-      long timeout = configuration.transaction().completedTxTimeout();
-
-      int removedEntries = 0;
-      long beginning = System.nanoTime();
-      while (iterator.hasNext()) {
-         Map.Entry<GlobalTransaction, Long> e = iterator.next();
-         long ageNanos = System.nanoTime() - e.getValue();
-         if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
-            iterator.remove();
-            removedEntries++;
+      try {
+         log.debugf(""About to cleanup completed transaction. Initial size is %d"", completedTransactions.size());
+         //this iterator is weekly consistent and will never throw ConcurrentModificationException
+         Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
+         long timeout = configuration.transaction().completedTxTimeout();
+
+         int removedEntries = 0;
+         long beginning = System.nanoTime();
+         while (iterator.hasNext()) {
+            Map.Entry<GlobalTransaction, Long> e = iterator.next();
+            long ageNanos = System.nanoTime() - e.getValue();
+            if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
+               iterator.remove();
+               removedEntries++;
+            }
          }
-      }
-      long duration = System.nanoTime() - beginning;
+         long duration = System.nanoTime() - beginning;
 
-      log.debugf(""Finished cleaning up completed transactions. %s transactions were removed, total duration was %s millis, "" +
-                      ""current number of completed transactions is %"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
-                 completedTransactions.size());
+         log.debugf(""Finished cleaning up completed transactions. %d transactions were removed, total duration was %d millis, "" +
+                         ""current number of completed transactions is %d"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
+                    completedTransactions.size());
+      } catch (Exception e) {
+         log.errorf(e, ""Failed to cleanup completed transactions: %s"", e.getMessage());
+      }
    }
 }",2012-11-07T14:07:34Z,127
"@@ -24,9 +24,7 @@
 
 import org.infinispan.CacheException;
 import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.commands.tx.PrepareCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.bucket.Bucket;
 import org.infinispan.loaders.decorators.SingletonStore;
@@ -60,7 +58,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.UUID;
-import java.util.concurrent.ExecutionException;
 
 import static org.jboss.logging.Logger.Level.*;
 
@@ -131,26 +128,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Can not select %s random members for %s"", id = 8)
    void cannotSelectRandomMembers(int numNeeded, List<Address> members);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Detected a view change. Member list changed from %s to %s"", id = 9)
-   void viewChangeDetected(List<Address> oldMembers, List<Address> newMembers);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a JOIN event! Wait for notification from new joiner %s"", id = 10)
-   void joinEvent(Address joiner);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a LEAVE event! Node %s has just left"", id = 11)
-   void leaveEvent(Address leaver);
-
-   @LogMessage(level = FATAL)
-   @Message(value = ""Unable to process leaver!!"", id = 12)
-   void unableToProcessLeaver(@Cause Exception e);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""I %s am participating in rehash, state providers %s, state receivers %s"", id = 13)
-   void participatingInRehash(Address address, List<Address> stateProviders, List<Address> receiversOfLeaverState);
-
    @LogMessage(level = INFO)
    @Message(value = ""DistributionManager not yet joined the cluster. Cannot do anything about other concurrent joiners."", id = 14)
    void distributionManagerNotJoined();
@@ -163,10 +140,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Problem %s encountered when applying state for key %s!"", id = 16)
    void problemApplyingStateForKey(String msg, Object key);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""View change interrupted; not rehashing!"", id = 17)
-   void viewChangeInterrupted();
-
    @LogMessage(level = WARN)
    @Message(value = ""Unable to apply prepare %s"", id = 18)
    void unableToApplyPrepare(PrepareCommand pc, @Cause Throwable t);
@@ -175,26 +148,10 @@ public interface Log extends BasicLogger {
    @Message(value = ""Couldn't acquire shared lock"", id = 19)
    void couldNotAcquireSharedLock();
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Caught exception replaying %s"", id = 20)
-   void exceptionWhenReplaying(WriteCommand cmd, @Cause Exception e);
-
    @LogMessage(level = WARN)
    @Message(value = ""Expected just one response; got %s"", id = 21)
    void expectedJustOneResponse(Map<Address, Response> lr);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Completed leave rehash on node %s in %s - leavers now are %s"", id = 22)
-   void completedLeaveRehash(Address self, String duration, List<Address> leavers);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error pushing tx log"", id = 23)
-   void errorPushingTxLog(@Cause ExecutionException e);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Unable to stop transaction logging!"", id = 24)
-   void unableToStopTransactionLogging(@Cause IllegalMonitorStateException imse);
-
    @LogMessage(level = INFO)
    @Message(value = ""wakeUpInterval is <= 0, not starting expired purge thread"", id = 25)
    void notStartingEvictionThread();
@@ -211,7 +168,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unable to passivate entry under %s"", id = 28)
    void unableToPassivateEntry(Object key, @Cause Exception e);
 
-
    @LogMessage(level = INFO)
    @Message(value = ""Passivating all entries to disk"", id = 29)
    void passivatingAllEntries();
@@ -296,14 +252,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Interrupted or timeout while waiting for AsyncStore worker threads to push all state to the decorated store"", id = 48)
    void interruptedWaitingAsyncStorePush(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing clear in async store"", id = 49)
-   void errorClearinAsyncStore(@Cause CacheLoaderException e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing purging expired from async store"", id = 50)
-   void errorPurgingAsyncStore(@Cause CacheLoaderException e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Unexpected error"", id = 51)
    void unexpectedErrorInAsyncProcessor(@Cause Throwable t);
@@ -376,14 +324,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Cache named %s does not exist on this cache manager!"", id = 68)
    void namedCacheDoesNotExist(String cacheName);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Cache named [%s] exists but isn't in a state to handle remote invocations"", id = 69)
-   void cacheCanNotHandleInvocations(String cacheName);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Quietly ignoring clustered get call %s since unable to acquire processing lock, even after %s"", id = 70)
-   void ignoreClusterGetCall(CacheRpcCommand cmd, String time);
-
    @LogMessage(level = WARN)
    @Message(value = ""Caught exception when handling command %s"", id = 71)
    void exceptionHandlingCommand(ReplicableCommand cmd, @Cause Throwable t);
@@ -396,18 +336,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unexpected error while replicating"", id = 73)
    void unexpectedErrorReplicating(@Cause Throwable t);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Trying to fetch state from %s"", id = 74)
-   void tryingToFetchState(Address member);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Could not find available peer for state, backing off and retrying"", id = 75)
-   void couldNotFindPeerForState();
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Successfully retrieved and applied state from %s"", id = 76)
-   void successfullyAppliedState(Address member);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Message or message buffer is null or empty."", id = 77)
    void msgOrMsgBufferEmpty();
@@ -461,15 +389,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""getCoordinator(): Interrupted while waiting for members to be set"", id = 89)
    void interruptedWaitingForCoordinator(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Unable to retrieve state from member %s"", id = 90)
-   void unableToRetrieveState(Address member, @Cause Exception e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Channel does not contain STREAMING_STATE_TRANSFER. "" +
-         ""Cannot support state transfers!"", id = 91)
-   void streamingStateTransferNotPresent();
-
    @LogMessage(level = WARN)
    @Message(value = ""Channel not set up properly!"", id = 92)
    void channelNotSetUp();
@@ -482,10 +401,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Received new cluster view: %s"", id = 94)
    void receivedClusterView(View newView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Caught while requesting or applying state"", id = 96)
-   void errorRequestingOrApplyingState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error while processing a prepare in a single-phase transaction"", id = 97)
    void errorProcessing1pcPrepareCommand(@Cause Throwable e);
@@ -688,14 +603,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Failed loading value for key %s from cache store"", id = 144)
    void failedLoadingValueFromCacheStore(Object key, @Cause Exception e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error during rehash"", id = 145)
-   void errorDuringRehash(@Cause Throwable th);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error transferring state to node after rehash"", id = 146)
-   void errorTransferringState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error invalidating keys from L1 after rehash"", id = 147)
    void failedToInvalidateKeys(@Cause Exception e);
@@ -729,14 +636,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Unable to unlock keys %2$s for transaction %1$s after they were rebalanced off node %3$s"", id = 154)
    void unableToUnlockRebalancedKeys(GlobalTransaction gtx, List<Object> keys, Address self, @Cause Throwable t);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm pushing data for view %d, received confirmations %s. Cancelling state transfer"", id = 157)
-   void stateTransferTimeoutWaitingForPushConfirmations(int viewId, Map<Address, Integer> pushConfirmations);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm joining for view %d, joined %s. Cancelling state transfer"", id = 158)
-   void stateTransferTimeoutWaitingForJoinConfirmations(int viewId, Map<Address, Integer> joinConfirmations);
-
    @LogMessage(level = WARN)
    @Message(value = ""Unblocking transactions failed"", id = 159)
    void errorUnblockingTransactions(@Cause Exception e);
@@ -761,26 +660,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Rolling back to cache view %d, but last committed view is %d"", id = 164)
    void cacheViewRollbackIdMismatch(int committedViewId, int committedView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error triggering a view installation for cache %s"", id = 165)
-   void errorTriggeringViewInstallation(@Cause RuntimeException e, String cacheName);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""View installation failed for cache %s"", id = 166)
-   void viewInstallationFailure(@Cause Throwable e, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Rejecting state pushed by node %s for view %d, there is no state transfer in progress (we are at view %d)"", id = 167)
-   void remoteStateRejected(Address sender, int viewId, int installedViewId);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error rolling back to cache view %1$d for cache %2$s"", id = 168)
-   void cacheViewRollbackFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error committing cache view %1$d for cache %2$s"", id = 169)
-   void cacheViewCommitFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
    @LogMessage(level = INFO)
    @Message(value = ""Strict peer-to-peer is enabled but the JGroups channel was started externally - this is very likely to result in RPC timeout errors on startup"", id = 171)
    void warnStrictPeerToPeerWithInjectedChannel();
@@ -926,5 +805,16 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @LogMessage(level = WARN)
    @Message(value = ""Could not interrupt as no thread found for command uuid %s"", id=207)
    void couldNotInterruptThread(UUID id);
-   
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""No live owners found for segment %d of cache %s. Current owners are:  %s. Faulty owners: %s"", id=208)
+   void noLiveOwnersFoundForSegment(int segmentId, String cacheName, Collection<Address> owners, Collection<Address> faultySources);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to retrieve transactions for segments %s of cache %s from node %s (node will not be retried)"", id=209)
+   void failedToRetrieveTransactionsForSegments(Collection<Integer> segments, String cacheName, Address source);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to request segments %s of cache %s from node %s (node will not be retried)"", id=210)
+   void failedToRequestSegments(Collection<Integer> segments, String cacheName, Address source);
 }",2012-11-07T14:07:34Z,45
"@@ -263,7 +263,7 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm, boolean deprecated) {
 
       assert gc.asyncTransportExecutor().factory() instanceof DefaultExecutorFactory;
       // Should be 25, but it's overriden by the test cache manager factory
-      assertEquals(""4"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
+      assertEquals(""6"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
       assert gc.asyncTransportExecutor().properties().getProperty(""threadNamePrefix"").equals(""AsyncSerializationThread"");
 
       assert gc.evictionScheduledExecutor().factory() instanceof DefaultScheduledExecutorFactory;",2012-11-07T14:07:34Z,128
"@@ -50,7 +50,6 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -126,7 +125,7 @@ public void test1() throws Exception {
       when(cache.getName()).thenReturn(""testCache"");
 
       StateProvider stateProvider = mock(StateProvider.class);
-      LocalTopologyManager localTopologyManager = mock(LocalTopologyManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
       CacheNotifier cacheNotifier = mock(CacheNotifier.class);
       ExecutorService mockExecutorService = mock(ExecutorService.class);
       RpcManager rpcManager = mock(RpcManager.class);
@@ -183,7 +182,7 @@ public Map<Address, Response> answer(InvocationOnMock invocation) {
 
       // create state provider
       StateConsumerImpl stateConsumer = new StateConsumerImpl();
-      stateConsumer.init(cache, localTopologyManager, interceptorChain, icc, configuration, rpcManager,
+      stateConsumer.init(cache, stateTransferManager, interceptorChain, icc, configuration, rpcManager,
             commandsFactory, cacheLoaderManager, dataContainer, transactionTable, stateTransferLock);
       stateConsumer.start();
 ",2012-11-07T14:07:34Z,56
"@@ -40,6 +40,7 @@
 
 /**
  * Test if state transfer happens properly on a cache with pessimistic transactions.
+ * See https://issues.jboss.org/browse/ISPN-2408.
  *
  * @since 5.2
  */",2012-11-07T14:07:34Z,129
"@@ -75,6 +75,8 @@
  */
 public class TestCacheManagerFactory {
 
+   private static final int MAX_ASYNC_EXEC_THREADS = 6;
+
    public static final String MARSHALLER = LegacyKeySupportSystemProperties.getProperty(""infinispan.test.marshaller.class"", ""infinispan.marshaller.class"");
    private static final Log log = LogFactory.getLog(TestCacheManagerFactory.class);
 
@@ -523,12 +525,12 @@ private static void checkTestName(String fullTestName) {
 
    public static void minimizeThreads(GlobalConfiguration gc) {
       Properties p = new Properties();
-      p.setProperty(""maxThreads"", ""4"");
+      p.setProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
       gc.setAsyncTransportExecutorProperties(p);
    }
 
    public static void minimizeThreads(GlobalConfigurationBuilder builder) {
-      builder.asyncTransportExecutor().addProperty(""maxThreads"", ""4"");
+      builder.asyncTransportExecutor().addProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
    }
 
    public static void amendMarshaller(GlobalConfiguration configuration) {",2012-11-07T14:07:34Z,130
"@@ -49,6 +49,12 @@ public CommitCommand(String cacheName) {
       super(cacheName);
    }
 
+   @Override
+   public Object perform(InvocationContext ctx) throws Throwable {
+      txTable.markTransactionCompleted(globalTx);
+      return super.perform(ctx);
+   }
+
    @Override
    public Object acceptVisitor(InvocationContext ctx, Visitor visitor) throws Throwable {
       return visitor.visitCommitCommand((TxInvocationContext) ctx, this);",2012-10-17T08:29:36Z,622
"@@ -50,6 +50,12 @@ public RollbackCommand(String cacheName) {
       super(cacheName);
    }
 
+   @Override
+   public Object perform(InvocationContext ctx) throws Throwable {
+      txTable.markTransactionCompleted(globalTx);
+      return super.perform(ctx);
+   }
+
    @Override
    public Object acceptVisitor(InvocationContext ctx, Visitor visitor) throws Throwable {
       return visitor.visitRollbackCommand((TxInvocationContext) ctx, this);",2012-10-17T08:29:36Z,623
"@@ -44,12 +44,15 @@ public class TransactionConfiguration {
    private final boolean useSynchronization;
    private final RecoveryConfiguration recovery;
    private final boolean use1PcForAutoCommitTransactions;
+   private final long reaperWakeUpInterval;
+   private final long completedTxTimeout;
+
 
    TransactionConfiguration(boolean autoCommit, long cacheStopTimeout, boolean eagerLockingSingleNode, LockingMode lockingMode,
-         boolean syncCommitPhase, boolean syncRollbackPhase, TransactionManagerLookup transactionManagerLookup,
-         TransactionSynchronizationRegistryLookup transactionSynchronizationRegistryLookup, TransactionMode transactionMode,
-         boolean useEagerLocking, boolean useSynchronization, boolean use1PcForAutoCommitTransactions,
-         RecoveryConfiguration recovery) {
+                            boolean syncCommitPhase, boolean syncRollbackPhase, TransactionManagerLookup transactionManagerLookup,
+                            TransactionSynchronizationRegistryLookup transactionSynchronizationRegistryLookup, TransactionMode transactionMode,
+                            boolean useEagerLocking, boolean useSynchronization, boolean use1PcForAutoCommitTransactions,
+                            long reaperWakeUpInterval, long completedTxTimeout, RecoveryConfiguration recovery) {
       this.autoCommit = autoCommit;
       this.cacheStopTimeout = cacheStopTimeout;
       this.eagerLockingSingleNode = eagerLockingSingleNode;
@@ -63,6 +66,8 @@ public class TransactionConfiguration {
       this.useSynchronization = useSynchronization;
       this.recovery = recovery;
       this.use1PcForAutoCommitTransactions = use1PcForAutoCommitTransactions;
+      this.reaperWakeUpInterval = reaperWakeUpInterval;
+      this.completedTxTimeout = completedTxTimeout;
    }
 
    /**
@@ -243,6 +248,20 @@ public RecoveryConfiguration recovery() {
       return recovery;
    }
 
+   /**
+    * @see TransactionConfigurationBuilder#reaperWakeUpInterval(long)
+    */
+   public long reaperWakeUpInterval() {
+      return reaperWakeUpInterval;
+   }
+
+   /**
+    * @see TransactionConfigurationBuilder#completedTxTimeout(long)
+    */
+   public long completedTxTimeout()  {
+      return completedTxTimeout;
+   }
+
    /**
     * Before Infinispan 5.1 you could access the cache both transactionally and
     * non-transactionally. Naturally the non-transactional access is faster and
@@ -275,6 +294,8 @@ public String toString() {
             "", useEagerLocking="" + useEagerLocking +
             "", useSynchronization="" + useSynchronization +
             "", recovery="" + recovery +
+            "", reaperWakeUpInterval="" + reaperWakeUpInterval +
+            "", completedTxTimeout="" + completedTxTimeout +
             "", use1PcForAutoCommitTransactions="" + use1PcForAutoCommitTransactions +
             '}';
    }",2012-10-17T08:29:36Z,624
"@@ -18,6 +18,7 @@
  */
 package org.infinispan.configuration.cache;
 
+import org.infinispan.CacheConfigurationException;
 import org.infinispan.configuration.Builder;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.TransactionMode;
@@ -49,6 +50,9 @@ public class TransactionConfigurationBuilder extends AbstractConfigurationChildB
    private boolean useSynchronization = true;
    private final RecoveryConfigurationBuilder recovery;
    private boolean use1PcForAutoCommitTransactions = false;
+   private long reaperWakeUpInterval = 1000;
+   private long completedTxTimeout = 3000;
+
 
    TransactionConfigurationBuilder(ConfigurationBuilder builder) {
       super(builder);
@@ -142,9 +146,6 @@ public TransactionConfigurationBuilder syncCommitPhase(boolean b) {
     * <p />
     *
     * This configuration property may be adjusted at runtime.
-    *
-    * @param b
-    * @return
     */
    public TransactionConfigurationBuilder syncRollbackPhase(boolean b) {
       this.syncRollbackPhase = b;
@@ -185,9 +186,6 @@ public TransactionConfigurationBuilder transactionMode(TransactionMode transacti
     * <p />
     * Note: Starting with infinispan 5.1 eager locking is replaced with pessimistic locking and can
     * be enforced by setting transaction's locking mode to PESSIMISTIC.
-    *
-    * @param b
-    * @return
     */
    @Deprecated
    public TransactionConfigurationBuilder useEagerLocking(boolean b) {
@@ -234,8 +232,28 @@ public TransactionConfigurationBuilder use1PcForAutoCommitTransactions(boolean b
       return this;
    }
 
+   /**
+    *The time interval (millis) at which the thread that cleans up transaction completion information kicks in. Defaults to 1000.
+    */
+   public TransactionConfigurationBuilder reaperWakeUpInterval(long interval) {
+      this.reaperWakeUpInterval = interval;
+      return this;
+   }
+
+   /**
+    * The duration (millis) in which to keep information about the completion of a transaction. Defaults to 3000.
+    */
+   public TransactionConfigurationBuilder completedTxTimeout(long timeout) {
+      this.completedTxTimeout = timeout;
+      return this;
+   }
+
    @Override
    public void validate() {
+      if (reaperWakeUpInterval < 0)
+         throw new CacheConfigurationException(""reaperWakeUpInterval must be > 0, we got "" + reaperWakeUpInterval);
+      if (completedTxTimeout < 0)
+         throw new CacheConfigurationException(""completedTxTimeout must be > 0, we got "" + reaperWakeUpInterval);
    }
 
    @Override
@@ -249,7 +267,7 @@ else if (transactionMode == null)
          transactionMode = TransactionMode.NON_TRANSACTIONAL;
       return new TransactionConfiguration(autoCommit, cacheStopTimeout, eagerLockingSingleNode, lockingMode, syncCommitPhase,
             syncRollbackPhase, transactionManagerLookup, transactionSynchronizationRegistryLookup, transactionMode,
-            useEagerLocking, useSynchronization, use1PcForAutoCommitTransactions, recovery.create());
+            useEagerLocking, useSynchronization, use1PcForAutoCommitTransactions, reaperWakeUpInterval, completedTxTimeout, recovery.create());
    }
 
    @Override
@@ -267,6 +285,8 @@ public TransactionConfigurationBuilder read(TransactionConfiguration template) {
       this.useSynchronization = template.useSynchronization();
       this.use1PcForAutoCommitTransactions = template.use1PcForAutoCommitTransactions();
       this.recovery.read(template.recovery());
+      this.reaperWakeUpInterval = template.reaperWakeUpInterval();
+      this.completedTxTimeout = template.completedTxTimeout();
 
       return this;
    }
@@ -287,6 +307,8 @@ public String toString() {
             "", useSynchronization="" + useSynchronization +
             "", recovery="" + recovery +
             "", use1PcForAutoCommitTransactions="" + use1PcForAutoCommitTransactions +
+            "", completedTxTimeout="" + completedTxTimeout +
+            "", reaperWakeUpInterval="" + reaperWakeUpInterval +
             '}';
    }
 ",2012-10-17T08:29:36Z,625
"@@ -143,8 +143,9 @@ public enum Attribute {
     FAILURE_POLICY_CLASS(""failurePolicyClass""),
     BACKUP_SITES(""backupSites""),
     AFTER_FAILURES(""afterFailures""),
-    MIN_TIME_TO_WAIT(""minTimeToWait"")
-   ;
+    MIN_TIME_TO_WAIT(""minTimeToWait""),
+    REAPER_WAKE_UP_INTERVAL(""reaperWakeUpInterval""),
+    COMPLETED_TX_TIMEOUT(""completedTxTimeout"");
 
     private final String name;
 ",2012-10-17T08:29:36Z,165
"@@ -424,6 +424,12 @@ private void parseTransaction(final XMLExtendedStreamReader reader, final Config
             case USE_1PC_FOR_AUTOCOMMIT_TX:
                builder.transaction().use1PcForAutoCommitTransactions(Boolean.parseBoolean(value));
                break;
+            case REAPER_WAKE_UP_INTERVAL:
+               builder.transaction().reaperWakeUpInterval(Long.parseLong(value));
+               break;
+            case COMPLETED_TX_TIMEOUT:
+               builder.transaction().completedTxTimeout(Long.parseLong(value));
+               break;
             default:
                throw ParseUtils.unexpectedAttribute(reader, i);
          }",2012-10-17T08:29:36Z,166
"@@ -26,6 +26,7 @@
 import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
 import org.infinispan.commands.read.GetKeyValueCommand;
+import org.infinispan.commands.tx.AbstractTransactionBoundaryCommand;
 import org.infinispan.commands.tx.CommitCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.tx.RollbackCommand;
@@ -104,7 +105,7 @@ public void init(TransactionTable txTable, Configuration c, TransactionCoordinat
    public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand command) throws Throwable {
       //if it is remote and 2PC then first log the tx only after replying mods
       if (this.statisticsEnabled) prepares.incrementAndGet();
-      Object result = invokeNextInterceptor(ctx, command);
+      Object result = invokeNextInterceptorAndCheckIfCompleted(ctx, command);
       if (!ctx.isOriginLocal()) {
          if (command.isOnePhaseCommit()) {
             txTable.remoteTransactionCommitted(command.getGlobalTransaction());
@@ -115,6 +116,20 @@ public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand comman
       return result;
    }
 
+   private Object invokeNextInterceptorAndCheckIfCompleted(TxInvocationContext ctx, AbstractTransactionBoundaryCommand command) throws Throwable {
+      try {
+         return invokeNextInterceptor(ctx, command);
+      } finally {
+         if (!ctx.isOriginLocal() && txTable.isTransactionCompleted(command.getGlobalTransaction())) {
+            log.tracef(""Remote transaction %s already completed, rolling back."",
+                       command.getGlobalTransaction());
+            RollbackCommand rollback = new RollbackCommand(command.getCacheName(), command.getGlobalTransaction());
+            invokeNextInterceptor(ctx, rollback);
+            txTable.removeRemoteTransaction(command.getGlobalTransaction());
+         }
+      }
+   }
+
    @Override
    public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command) throws Throwable {
       if (this.statisticsEnabled) commits.incrementAndGet();
@@ -142,7 +157,7 @@ public Object visitLockControlCommand(TxInvocationContext ctx, LockControlComman
          command.setGlobalTransaction(ctx.getGlobalTransaction());
       }
 
-      return invokeNextInterceptor(ctx, command);
+      return invokeNextInterceptorAndCheckIfCompleted(ctx, command);
    }
 
    @Override",2012-10-17T08:29:36Z,87
"@@ -23,31 +23,23 @@
 
 package org.infinispan.transaction;
 
-import org.infinispan.commands.control.LockControlCommand;
-import org.infinispan.context.Flag;
+import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.distribution.ch.ConsistentHash;
-import org.infinispan.interceptors.InterceptorChain;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
 import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
 import org.infinispan.remoting.MembershipArithmetic;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
-import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.ArrayList;
 import java.util.Collection;
-import java.util.EnumSet;
 import java.util.List;
-import java.util.Set;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.LinkedBlockingDeque;
+import java.util.concurrent.Executors;
 import java.util.concurrent.RejectedExecutionException;
 import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.ThreadFactory;
-import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 
 /**
@@ -68,7 +60,7 @@ public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
-   private ExecutorService lockBreakingService; // a thread pool with max. 1 thread
+   private ScheduledExecutorService executorService;
 
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
@@ -93,7 +85,7 @@ public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
 
    private void cleanTxForWhichTheOwnerLeft(final Collection<Address> leavers) {
       try {
-         lockBreakingService.submit(new Runnable() {
+         executorService.submit(new Runnable() {
             @Override
             public void run() {
                try {
@@ -108,7 +100,7 @@ public void run() {
       }
    }
 
-   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain, boolean isDistributed) {
+   public void start(final String cacheName, final RpcManager rpcManager, Configuration configuration) {
       ThreadFactory tf = new ThreadFactory() {
          @Override
          public Thread newThread(Runnable r) {
@@ -118,12 +110,20 @@ public Thread newThread(Runnable r) {
             return th;
          }
       };
-      lockBreakingService = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingDeque<Runnable>(), tf,
-                                                   new ThreadPoolExecutor.DiscardOldestPolicy());
+
+      executorService = Executors.newSingleThreadScheduledExecutor(tf);
+
+      executorService.schedule(new Runnable() {
+         @Override
+         public void run() {
+            transactionTable.cleanupCompletedTransactions();
+         }
+      }, configuration.transaction().reaperWakeUpInterval(), TimeUnit.MILLISECONDS);
+
    }
 
    public void stop() {
-      if (lockBreakingService != null)
-         lockBreakingService.shutdownNow();
+      if (executorService != null)
+         executorService.shutdownNow();
    }
 }",2012-10-17T08:29:36Z,126
"@@ -58,6 +58,8 @@
 import javax.transaction.TransactionSynchronizationRegistry;
 import java.util.*;
 import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReentrantLock;
@@ -96,6 +98,8 @@ public class TransactionTable {
    protected ClusteringDependentLogic clusteringLogic;
    protected boolean clustered = false;
    private Lock minTopologyRecalculationLock;
+   private final ConcurrentMap<GlobalTransaction, Long> completedTransactions = ConcurrentMapFactory.makeConcurrentMap();
+
 
    /**
     * minTxTopologyId is the minimum topology ID across all ongoing local and remote transactions.
@@ -133,7 +137,7 @@ private void start() {
          minTopologyRecalculationLock = new ReentrantLock();
          // Only initialize this if we are clustered.
          remoteTransactions = ConcurrentMapFactory.makeConcurrentMap(concurrencyLevel, 0.75f, concurrencyLevel);
-         cleanupService.start(cacheName, rpcManager, invoker, configuration.clustering().cacheMode().isDistributed());
+         cleanupService.start(cacheName, rpcManager, configuration);
          notifier.addListener(cleanupService);
          notifier.addListener(this);
          clustered = true;
@@ -357,6 +361,7 @@ public void remoteTransactionCommitted(GlobalTransaction gtx) {
    public final RemoteTransaction removeRemoteTransaction(GlobalTransaction txId) {
       RemoteTransaction removed;
       removed = remoteTransactions.remove(txId);
+      log.tracef(""Removed remote transaction %s ? %s"", txId, removed);
       releaseResources(removed);
       return removed;
    }
@@ -503,4 +508,42 @@ private void shutDownGracefully() {
       }
    }
 
+   /**
+    * With the current state transfer implementation it is possible for a transaction to be prepared several times
+    * on a remote node. This might cause leaks, e.g. if the transaction is prepared, committed and prepared again.
+    * Once marked as completed (because of commit or rollback) any further prepare received on that transaction are discarded.
+    */
+   public void markTransactionCompleted(GlobalTransaction globalTx) {
+      completedTransactions.put(globalTx, System.nanoTime());
+   }
+
+   /**
+    * @see #markTransactionCompleted(org.infinispan.transaction.xa.GlobalTransaction)
+    */
+   public boolean isTransactionCompleted(GlobalTransaction gtx) {
+      return completedTransactions.containsKey(gtx);
+   }
+
+   public void cleanupCompletedTransactions() {
+      log.debugf(""About to cleanup completed transaction. Initial size is %s"", completedTransactions.size());
+      //this iterator is weekly consistent and will never throw ConcurrentModificationException
+      Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
+      long timeout = configuration.transaction().completedTxTimeout();
+
+      int removedEntries = 0;
+      long beginning = System.nanoTime();
+      while (iterator.hasNext()) {
+         Map.Entry<GlobalTransaction, Long> e = iterator.next();
+         long ageNanos = System.nanoTime() - e.getValue();
+         if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
+            iterator.remove();
+            removedEntries++;
+         }
+      }
+      long duration = System.nanoTime() - beginning;
+
+      log.debugf(""Finished cleaning up completed transactions. %s transactions were removed, total duration was %s millis, "" +
+                      ""current number of completed transactions is %"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
+                 completedTransactions.size());
+   }
 }",2012-10-17T08:29:36Z,127
"@@ -513,6 +513,20 @@
               </xs:documentation>
             </xs:annotation>
           </xs:attribute>
+          <xs:attribute name=""completedTxTimeout"" type=""xs:long"">
+            <xs:annotation>
+              <xs:documentation>
+                The duration (millis) in which to keep information about the completion of a transaction. Defaults to 3000.
+              </xs:documentation>
+            </xs:annotation>
+          </xs:attribute>
+          <xs:attribute name=""reaperWakeUpInterval"" type=""xs:long"">
+            <xs:annotation>
+              <xs:documentation>
+                The time interval (millis) at which the thread that cleans up transaction completion information kicks in. Defaults to 1000.
+              </xs:documentation>
+            </xs:annotation>
+          </xs:attribute>
           <xs:attribute name=""eagerLockSingleNode"" type=""xs:boolean"">
             <xs:annotation>
               <xs:documentation>",2012-10-17T08:29:36Z,170
"@@ -293,13 +293,20 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm, boolean deprecated) {
       assert defaultCfg.locking().lockAcquisitionTimeout() == 1000;
       assert defaultCfg.locking().concurrencyLevel() == 100;
       assert defaultCfg.locking().isolationLevel() == IsolationLevel.READ_COMMITTED;
+      if (!deprecated) {
+         assertReaperAndTimeoutInfo(defaultCfg);
+      }
+
 
       Configuration c = cm.getCacheConfiguration(""transactional"");
       assert !c.clustering().cacheMode().isClustered();
       assert c.transaction().transactionManagerLookup() instanceof GenericTransactionManagerLookup;
       assert c.transaction().useEagerLocking();
       assert c.transaction().eagerLockingSingleNode();
       assert !c.transaction().syncRollbackPhase();
+      if (!deprecated) {
+         assertReaperAndTimeoutInfo(defaultCfg);
+      }
 
       c = cm.getCacheConfiguration(""transactional2"");
       assert c.transaction().transactionManagerLookup() instanceof TestLookup;
@@ -437,4 +444,9 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm, boolean deprecated) {
       assert !c.storeAsBinary().storeValuesAsBinary();
    }
 
+   private void assertReaperAndTimeoutInfo(Configuration defaultCfg) {
+      assertEquals(123, defaultCfg.transaction().reaperWakeUpInterval());
+      assertEquals(3123, defaultCfg.transaction().completedTxTimeout());
+   }
+
 }
\ No newline at end of file",2012-10-17T08:29:36Z,128
"@@ -0,0 +1,119 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2011 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.lock.singlelock;
+
+import org.infinispan.commands.tx.CommitCommand;
+import org.infinispan.config.Configuration;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.tx.LockCleanupStateTransferTest;
+import org.infinispan.util.mocks.ControlledCommandFactory;
+import org.testng.annotations.BeforeMethod;
+import org.testng.annotations.Test;
+
+import javax.transaction.HeuristicMixedException;
+import javax.transaction.HeuristicRollbackException;
+import javax.transaction.NotSupportedException;
+import javax.transaction.RollbackException;
+import javax.transaction.SystemException;
+
+import static org.testng.Assert.assertEquals;
+
+/**
+ * @author Mircea Markus
+ * @since 5.1
+ */
+@Test(groups = ""functional"", testName = ""lock.singlelock.NoPrepareRpcForPessimisticTransactionsTest"")
+public class NoPrepareRpcForPessimisticTransactionsTest extends MultipleCacheManagersTest {
+
+   private Object k1;
+   private ControlledCommandFactory commandFactory;
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      final Configuration c = getDefaultClusteredConfig(Configuration.CacheMode.DIST_SYNC, true);
+      c.fluent().transaction().lockingMode(LockingMode.PESSIMISTIC);
+      c.fluent().hash().numOwners(1);
+      c.fluent().l1().disable();
+      createCluster(c, 2);
+      waitForClusterToForm();
+
+      k1 = getKeyForCache(1);
+      commandFactory = ControlledCommandFactory.registerControlledCommandFactory(cache(1), CommitCommand.class);
+   }
+
+   @BeforeMethod
+   void clearStats() {
+      commandFactory.remoteCommandsReceived.set(0);
+   }
+
+   public void testSingleGetOnPut() throws Exception {
+
+      Operation o = new Operation() {
+         @Override
+         public void execute() {
+            cache(0).put(k1, ""v0"");
+         }
+      };
+
+      runtTest(o);
+   }
+
+   public void testSingleGetOnRemove() throws Exception {
+
+      Operation o = new Operation() {
+         @Override
+         public void execute() {
+            cache(0).remove(k1);
+         }
+      };
+
+      runtTest(o);
+   }
+
+   private void runtTest(Operation o) throws NotSupportedException, SystemException, RollbackException, HeuristicMixedException, HeuristicRollbackException {
+      log.trace(""Here is where the fun starts.."");
+      tm(0).begin();
+
+      o.execute();
+
+      assertKeyLockedCorrectly(k1);
+
+      assertEquals(commandFactory.remoteCommandsReceived.get(), 2, ""2 = cluster get + lock"");
+
+      tm(0).commit();
+
+      eventually(new Condition() {
+         @Override
+         public boolean isSatisfied() throws Exception {
+            //prepare + tx completion notification
+            return  commandFactory.remoteCommandsReceived.get()  == 4;
+         }
+      });
+   }
+
+   private interface Operation {
+      void execute();
+   }
+}",2012-10-17T08:29:36Z,626
"@@ -1,262 +0,0 @@
-/*
- * JBoss, Home of Professional Open Source
- * Copyright 2011 Red Hat Inc. and/or its affiliates and other
- * contributors as indicated by the @author tags. All rights reserved.
- * See the copyright.txt in the distribution for a full listing of
- * individual contributors.
- *
- * This is free software; you can redistribute it and/or modify it
- * under the terms of the GNU Lesser General Public License as
- * published by the Free Software Foundation; either version 2.1 of
- * the License, or (at your option) any later version.
- *
- * This software is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this software; if not, write to the Free
- * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
- * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
- */
-
-package org.infinispan.lock.singlelock;
-
-import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.commands.control.LockControlCommand;
-import org.infinispan.commands.remote.ClusteredGetCommand;
-import org.infinispan.config.Configuration;
-import org.infinispan.remoting.RpcException;
-import org.infinispan.remoting.responses.Response;
-import org.infinispan.remoting.rpc.ResponseFilter;
-import org.infinispan.remoting.rpc.ResponseMode;
-import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.remoting.transport.Address;
-import org.infinispan.remoting.transport.Transport;
-import org.infinispan.test.MultipleCacheManagersTest;
-import org.infinispan.transaction.LockingMode;
-import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
-import org.infinispan.util.logging.Log;
-import org.infinispan.util.logging.LogFactory;
-import org.testng.annotations.BeforeMethod;
-import org.testng.annotations.Test;
-
-import javax.transaction.HeuristicMixedException;
-import javax.transaction.HeuristicRollbackException;
-import javax.transaction.NotSupportedException;
-import javax.transaction.RollbackException;
-import javax.transaction.SystemException;
-import java.util.Collection;
-import java.util.Map;
-
-import static org.testng.Assert.assertEquals;
-
-/**
- * @author Mircea Markus
- * @since 5.1
- */
-@Test(groups = ""functional"", testName = ""lock.singlelock.SingleRpcOnPessimisticLockingTest"")
-public class SingleRpcOnPessimisticLockingTest extends MultipleCacheManagersTest {
-
-   private Object k0;
-   private CountingRpcManager crm;
-
-   @Override
-   protected void createCacheManagers() throws Throwable {
-      final Configuration c = getDefaultClusteredConfig(Configuration.CacheMode.DIST_SYNC, true);
-      c.fluent().transaction().lockingMode(LockingMode.PESSIMISTIC);
-      c.fluent().hash().numOwners(1);
-      c.fluent().l1().disable();
-      createCluster(c, 2);
-      waitForClusterToForm();
-
-      k0 = getKeyForCache(1);
-      crm = new CountingRpcManager(advancedCache(0).getRpcManager());
-      advancedCache(0).getComponentRegistry().registerComponent(crm, RpcManager.class);
-      advancedCache(0).getComponentRegistry().rewire();
-      assert advancedCache(0).getRpcManager().equals(crm);
-   }
-
-   @BeforeMethod
-   void clearStats() {
-      crm.resetStats();
-   }
-
-   public void testSingleGetOnPut() throws Exception {
-
-      Operation o = new Operation() {
-         @Override
-         public void execute() {
-            cache(0).put(k0, ""v0"");
-         }
-      };
-
-      runtTest(o);
-   }
-
-   public void testSingleGetOnRemove() throws Exception {
-
-      Operation o = new Operation() {
-         @Override
-         public void execute() {
-            cache(0).remove(k0);
-         }
-      };
-
-      runtTest(o);
-   }
-
-   private void runtTest(Operation o) throws NotSupportedException, SystemException, RollbackException, HeuristicMixedException, HeuristicRollbackException {
-      log.trace(""Here is where the fun starts.."");
-      tm(0).begin();
-
-      o.execute();
-
-      assertKeyLockedCorrectly(k0);
-
-      assertEquals(crm.lockCount, 0);
-      assertEquals(crm.clusterGet, 1);
-      assertEquals(crm.otherCount, 0);
-
-      tm(0).commit();
-
-      eventually(new Condition() {
-         @Override
-         public boolean isSatisfied() throws Exception {
-            return crm.lockCount == 0 && crm.clusterGet == 1 &&
-                  crm.otherCount == 1;//1-phase commit
-         }
-      });
-   }
-
-   public static class CountingRpcManager implements RpcManager {
-
-      private static final Log log = LogFactory.getLog(CountingRpcManager.class);
-
-      public volatile int lockCount;
-      public volatile int clusterGet;
-      public volatile int otherCount;
-
-      protected final RpcManager realOne;
-
-      public CountingRpcManager(RpcManager realOne) {
-         this.realOne = realOne;
-      }
-
-      protected void aboutToInvokeRpc(ReplicableCommand rpcCommand) {
-         System.out.println(""rpcCommand = "" + rpcCommand);
-         if (rpcCommand instanceof LockControlCommand) {
-            lockCount++;
-         } else if (rpcCommand instanceof ClusteredGetCommand) {
-            clusterGet++;
-         } else {
-            otherCount++;
-         }
-      }
-
-      void resetStats() {
-         lockCount = 0;
-         clusterGet = 0;
-         otherCount = 0;
-      }
-
-      public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout, boolean usePriorityQueue, ResponseFilter responseFilter) {
-         log.trace(""invokeRemotely1"");
-         aboutToInvokeRpc(rpcCommand);
-         return realOne.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue, responseFilter);
-      }
-
-      public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout, boolean usePriorityQueue) {
-         log.trace(""invokeRemotely2"");
-         aboutToInvokeRpc(rpcCommand);
-         return realOne.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue);
-      }
-
-      public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout) {
-         log.trace(""invokeRemotely3"");
-         aboutToInvokeRpc(rpcCommand);
-         return realOne.invokeRemotely(recipients, rpcCommand, mode, timeout);
-      }
-
-      public void invokeRemotely(Collection<Address> recipients, ReplicableCommand rpc, boolean sync) throws RpcException {
-         log.trace(""invokeRemotely4"");
-         aboutToInvokeRpc(rpc);
-         realOne.invokeRemotely(recipients, rpc, sync);
-      }
-
-      public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpc, boolean sync, boolean usePriorityQueue) throws RpcException {
-         log.trace(""invokeRemotely5"");
-         Map<Address, Response> responses = realOne.invokeRemotely(recipients, rpc, sync, usePriorityQueue);
-         return responses;
-      }
-
-
-      public void broadcastRpcCommand(ReplicableCommand rpc, boolean sync) throws RpcException {
-         log.trace(""ControlledRpcManager.broadcastRpcCommand1"");
-         aboutToInvokeRpc(rpc);
-         realOne.broadcastRpcCommand(rpc, sync);
-      }
-
-      public void broadcastRpcCommand(ReplicableCommand rpc, boolean sync, boolean usePriorityQueue) throws RpcException {
-         log.trace(""ControlledRpcManager.broadcastRpcCommand2"");
-         realOne.broadcastRpcCommand(rpc, sync, usePriorityQueue);
-      }
-
-
-      public void broadcastRpcCommandInFuture(ReplicableCommand rpc, NotifyingNotifiableFuture<Object> future) {
-         log.trace(""ControlledRpcManager.broadcastRpcCommandInFuture1"");
-         aboutToInvokeRpc(rpc);
-         realOne.broadcastRpcCommandInFuture(rpc, future);
-      }
-
-      public void broadcastRpcCommandInFuture(ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future) {
-         log.trace(""ControlledRpcManager.broadcastRpcCommandInFuture2"");
-         aboutToInvokeRpc(rpc);
-         realOne.broadcastRpcCommandInFuture(rpc, usePriorityQueue, future);
-      }
-
-
-      public void invokeRemotelyInFuture(Collection<Address> recipients, ReplicableCommand rpc, NotifyingNotifiableFuture<Object> future) {
-         log.trace(""ControlledRpcManager.invokeRemotelyInFuture1"");
-         aboutToInvokeRpc(rpc);
-         realOne.invokeRemotelyInFuture(recipients, rpc, future);
-      }
-
-      public void invokeRemotelyInFuture(Collection<Address> recipients, ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future) {
-         log.trace(""ControlledRpcManager.invokeRemotelyInFuture2"");
-         aboutToInvokeRpc(rpc);
-         realOne.invokeRemotelyInFuture(recipients, rpc, usePriorityQueue, future);
-      }
-
-      public void invokeRemotelyInFuture(Collection<Address> recipients, ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future, long timeout) {
-         log.trace(""ControlledRpcManager.invokeRemotelyInFuture3"");
-         aboutToInvokeRpc(rpc);
-         realOne.invokeRemotelyInFuture(recipients, rpc, usePriorityQueue, future, timeout);
-      }
-
-      @Override
-      public void invokeRemotelyInFuture(Collection<Address> recipients, ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future, long timeout, boolean ignoreLeavers) {
-         log.trace(""ControlledRpcManager.invokeRemotelyInFuture4"");
-         aboutToInvokeRpc(rpc);
-         realOne.invokeRemotelyInFuture(recipients, rpc, usePriorityQueue, future, timeout, ignoreLeavers);
-      }
-
-      public Transport getTransport() {
-         return realOne.getTransport();
-      }
-
-      public Address getAddress() {
-         return realOne.getAddress();
-      }
-
-      @Override
-      public int getTopologyId() {
-         return realOne.getTopologyId();
-      }
-   }
-
-   private interface Operation {
-      void execute();
-   }
-}",2012-10-17T08:29:36Z,627
"@@ -30,8 +30,6 @@
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.container.DataContainer;
-import org.infinispan.factories.ComponentRegistry;
-import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
@@ -84,13 +82,7 @@ public void testBelatedTxCompletionNotificationCommand() throws Throwable {
 
    private void testLockReleasedCorrectly(Class<? extends  ReplicableCommand> toBlock ) throws Throwable {
 
-      ComponentRegistry componentRegistry = advancedCache(1).getComponentRegistry();
-      final ControlledCommandFactory ccf = new ControlledCommandFactory(componentRegistry.getCommandsFactory(), toBlock);
-      TestingUtil.replaceField(ccf, ""commandsFactory"", componentRegistry, ComponentRegistry.class);
-
-      //hack: re-add the component registry to the GlobalComponentRegistry's ""namedComponents"" (CHM) in order to correctly publish it for
-      // when it will be read by the InboundInvocationHandlder. IIH reads the value from the GlobalComponentRegistry.namedComponents before using it
-      advancedCache(1).getComponentRegistry().getGlobalComponentRegistry().registerNamedComponentRegistry(componentRegistry, EmbeddedCacheManager.DEFAULT_CACHE_NAME);
+      final ControlledCommandFactory ccf = ControlledCommandFactory.registerControlledCommandFactory(advancedCache(1), toBlock);
       ccf.gate.close();
 
       final Set<Object> keys = new HashSet<Object>(KEY_SET_SIZE);
@@ -114,8 +106,8 @@ public Object call() throws Exception {
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            log.tracef(""receivedCommands == %s"", ccf.receivedCommands.get());
-            return ccf.receivedCommands.get() == 1;
+            log.tracef(""receivedCommands == %s"", ccf.blockTypeCommandsReceived.get());
+            return ccf.blockTypeCommandsReceived.get() == 1;
          }
       });
 
@@ -161,6 +153,7 @@ public boolean isSatisfied() throws Exception {
          @Override
          public boolean isSatisfied() throws Exception {
             int remoteTxCount = TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount();
+            log.trace(""remoteTxCount=="" + remoteTxCount);
             return remoteTxCount == 0;
          }
       });",2012-10-17T08:29:36Z,118
"@@ -0,0 +1,32 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.testng.annotations.Test;
+
+@Test(testName = ""tx.RollbackBeforePrepareDistTest"", groups = ""functional"")
+public class RollbackBeforePrepareDistTest extends RollbackBeforePrepareTest {
+
+   public RollbackBeforePrepareDistTest() {
+      cacheMode = CacheMode.DIST_SYNC;
+      numOwners = 3;
+   }
+}",2012-10-17T08:29:36Z,628
"@@ -0,0 +1,124 @@
+/*
+ * JBoss, Home of Professional Open Source
+ *  Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ *  contributors as indicated by the @author tags. All rights reserved.
+ *  See the copyright.txt in the distribution for a full listing of
+ *  individual contributors.
+ *
+ *  This is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU Lesser General Public License as
+ *  published by the Free Software Foundation; either version 2.1 of
+ *  the License, or (at your option) any later version.
+ *
+ *  This software is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ *  Lesser General Public License for more details.
+ *
+ *  You should have received a copy of the GNU Lesser General Public
+ *  License along with this software; if not, write to the Free
+ *  Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ *  02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.commands.tx.PrepareCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.context.impl.TxInvocationContext;
+import org.infinispan.interceptors.base.CommandInterceptor;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
+import org.infinispan.util.concurrent.TimeoutException;
+import org.infinispan.util.mocks.ControlledCommandFactory;
+import org.testng.annotations.Test;
+
+import java.util.concurrent.CountDownLatch;
+
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNull;
+import static org.testng.Assert.fail;
+
+@Test(testName = ""tx.RollbackBeforePrepareTest"", groups = ""functional"")
+public class RollbackBeforePrepareTest extends MultipleCacheManagersTest {
+
+   public static final long REPL_TIMEOUT = 1000;
+   public static final long LOCK_TIMEOUT = 500;
+   private FailPrepareInterceptor failPrepareInterceptor;
+   protected CacheMode cacheMode;
+   protected int numOwners;
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      cacheMode = CacheMode.REPL_SYNC;
+      ConfigurationBuilder config = getDefaultClusteredCacheConfig(cacheMode, true);
+      numOwners = 3;
+      config
+            .locking().lockAcquisitionTimeout(LOCK_TIMEOUT)
+            .clustering().sync().replTimeout(REPL_TIMEOUT)
+            .clustering().hash().numOwners(numOwners)
+            .transaction().transactionManagerLookup(new DummyTransactionManagerLookup());
+
+      createCluster(config, 3);
+      waitForClusterToForm();
+      failPrepareInterceptor = new FailPrepareInterceptor();
+      advancedCache(2).addInterceptor(failPrepareInterceptor, 1);
+
+   }
+
+
+   public void testCommitNotSentBeforeAllPrepareAreAck() throws Exception {
+
+      ControlledCommandFactory ccf = ControlledCommandFactory.registerControlledCommandFactory(cache(1), PrepareCommand.class);
+      ccf.gate.close();
+
+      try {
+         cache(0).put(""k"", ""v"");
+         fail();
+      } catch (Exception e) {
+         //expected
+      }
+
+      //this will also cause a replication timeout
+      allowRollbackToRun();
+
+      ccf.gate.open();
+
+      allowRollbackToRun();
+
+      assertEquals(0, TestingUtil.getTransactionTable(cache(0)).getRemoteTxCount());
+      assertEquals(0, TestingUtil.getTransactionTable(cache(1)).getRemoteTxCount());
+      assertEquals(0, TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount());
+
+      assertNull(cache(0).get(""k""));
+      assertNull(cache(1).get(""k""));
+      assertNull(cache(2).get(""k""));
+
+      assertNotLocked(""k"");
+   }
+
+   /**
+    * by using timeouts here the worse case is to have false positives, i.e. the test to pass when it shouldn't. no
+    * false negatives should be possible. In single threaded suit runs this test will generally fail in order
+    * to highlight a bug.
+    */
+   private static void allowRollbackToRun() throws InterruptedException {
+      Thread.sleep(REPL_TIMEOUT * 5);
+   }
+
+   public static class FailPrepareInterceptor extends CommandInterceptor {
+
+      CountDownLatch failureFinish = new CountDownLatch(1);
+
+      @Override
+      public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand command) throws Throwable {
+         try {
+            throw new TimeoutException(""Induced!"");
+         } finally {
+            failureFinish.countDown();
+         }
+      }
+   }
+}",2012-10-17T08:29:36Z,629
"@@ -106,7 +106,7 @@ public Object call() throws Exception {
       eventually(new Condition() {
          @Override
          public boolean isSatisfied() throws Exception {
-            return ccf.receivedCommands.get() == TX_COUNT;
+            return ccf.blockTypeCommandsReceived.get() == TX_COUNT;
          }
       });
 ",2012-10-17T08:29:36Z,630
"@@ -0,0 +1,182 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.util;
+
+import org.infinispan.AdvancedCache;
+import org.infinispan.Cache;
+import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.commands.control.LockControlCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
+import org.infinispan.remoting.RpcException;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.rpc.ResponseFilter;
+import org.infinispan.remoting.rpc.ResponseMode;
+import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.Transport;
+import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+import java.util.Collection;
+import java.util.Map;
+
+/**
+* Use the {@link CountingRpcManager#replaceRpcManager(org.infinispan.Cache)}.
+* @author Mircea Markus
+* @since 5.2
+*/
+public class CountingRpcManager implements RpcManager {
+
+   private static final Log log = LogFactory.getLog(CountingRpcManager.class);
+
+   public volatile int lockCount;
+   public volatile int clusterGet;
+   public volatile int otherCount;
+
+   protected final RpcManager realOne;
+
+
+   public static CountingRpcManager replaceRpcManager(Cache c) {
+      AdvancedCache advancedCache = c.getAdvancedCache();
+      CountingRpcManager crm = new CountingRpcManager(advancedCache.getRpcManager());
+      advancedCache.getComponentRegistry().registerComponent(crm, RpcManager.class);
+      advancedCache.getComponentRegistry().rewire();
+      assert advancedCache.getRpcManager().equals(crm);
+      return crm;
+   }
+
+   public CountingRpcManager(RpcManager realOne) {
+      this.realOne = realOne;
+   }
+
+   protected void aboutToInvokeRpc(ReplicableCommand rpcCommand) {
+      System.out.println(""rpcCommand = "" + rpcCommand);
+      if (rpcCommand instanceof LockControlCommand) {
+         lockCount++;
+      } else if (rpcCommand instanceof ClusteredGetCommand) {
+         clusterGet++;
+      } else {
+         otherCount++;
+      }
+   }
+
+   public void resetStats() {
+      lockCount = 0;
+      clusterGet = 0;
+      otherCount = 0;
+   }
+
+   public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout, boolean usePriorityQueue, ResponseFilter responseFilter) {
+      log.trace(""invokeRemotely1"");
+      aboutToInvokeRpc(rpcCommand);
+      return realOne.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue, responseFilter);
+   }
+
+   public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout, boolean usePriorityQueue) {
+      log.trace(""invokeRemotely2"");
+      aboutToInvokeRpc(rpcCommand);
+      return realOne.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue);
+   }
+
+   public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpcCommand, ResponseMode mode, long timeout) {
+      log.trace(""invokeRemotely3"");
+      aboutToInvokeRpc(rpcCommand);
+      return realOne.invokeRemotely(recipients, rpcCommand, mode, timeout);
+   }
+
+   public void invokeRemotely(Collection<Address> recipients, ReplicableCommand rpc, boolean sync) throws RpcException {
+      log.trace(""invokeRemotely4"");
+      aboutToInvokeRpc(rpc);
+      realOne.invokeRemotely(recipients, rpc, sync);
+   }
+
+   public Map<Address, Response> invokeRemotely(Collection<Address> recipients, ReplicableCommand rpc, boolean sync, boolean usePriorityQueue) throws RpcException {
+      log.trace(""invokeRemotely5"");
+      aboutToInvokeRpc(rpc);
+      Map<Address, Response> responses = realOne.invokeRemotely(recipients, rpc, sync, usePriorityQueue);
+      return responses;
+   }
+
+
+   public void broadcastRpcCommand(ReplicableCommand rpc, boolean sync) throws RpcException {
+      log.trace(""ControlledRpcManager.broadcastRpcCommand1"");
+      aboutToInvokeRpc(rpc);
+      realOne.broadcastRpcCommand(rpc, sync);
+   }
+
+   public void broadcastRpcCommand(ReplicableCommand rpc, boolean sync, boolean usePriorityQueue) throws RpcException {
+      log.trace(""ControlledRpcManager.broadcastRpcCommand2"");
+      aboutToInvokeRpc(rpc);
+      realOne.broadcastRpcCommand(rpc, sync, usePriorityQueue);
+   }
+
+
+   public void broadcastRpcCommandInFuture(ReplicableCommand rpc, NotifyingNotifiableFuture<Object> future) {
+      log.trace(""ControlledRpcManager.broadcastRpcCommandInFuture1"");
+      aboutToInvokeRpc(rpc);
+      realOne.broadcastRpcCommandInFuture(rpc, future);
+   }
+
+   public void broadcastRpcCommandInFuture(ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future) {
+      log.trace(""ControlledRpcManager.broadcastRpcCommandInFuture2"");
+      aboutToInvokeRpc(rpc);
+      realOne.broadcastRpcCommandInFuture(rpc, usePriorityQueue, future);
+   }
+
+
+   public void invokeRemotelyInFuture(Collection<Address> recipients, ReplicableCommand rpc, NotifyingNotifiableFuture<Object> future) {
+      log.trace(""ControlledRpcManager.invokeRemotelyInFuture1"");
+      aboutToInvokeRpc(rpc);
+      realOne.invokeRemotelyInFuture(recipients, rpc, future);
+   }
+
+   public void invokeRemotelyInFuture(Collection<Address> recipients, ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future) {
+      log.trace(""ControlledRpcManager.invokeRemotelyInFuture2"");
+      aboutToInvokeRpc(rpc);
+      realOne.invokeRemotelyInFuture(recipients, rpc, usePriorityQueue, future);
+   }
+
+   public void invokeRemotelyInFuture(Collection<Address> recipients, ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future, long timeout) {
+      log.trace(""ControlledRpcManager.invokeRemotelyInFuture3"");
+      aboutToInvokeRpc(rpc);
+      realOne.invokeRemotelyInFuture(recipients, rpc, usePriorityQueue, future, timeout);
+   }
+
+   @Override
+   public void invokeRemotelyInFuture(Collection<Address> recipients, ReplicableCommand rpc, boolean usePriorityQueue, NotifyingNotifiableFuture<Object> future, long timeout, boolean ignoreLeavers) {
+      log.trace(""ControlledRpcManager.invokeRemotelyInFuture4"");
+      aboutToInvokeRpc(rpc);
+      realOne.invokeRemotelyInFuture(recipients, rpc, usePriorityQueue, future, timeout, ignoreLeavers);
+   }
+
+   public Transport getTransport() {
+      return realOne.getTransport();
+   }
+
+   public Address getAddress() {
+      return realOne.getAddress();
+   }
+
+   @Override
+   public int getTopologyId() {
+      return realOne.getTopologyId();
+   }
+}",2012-10-17T08:29:36Z,631
"@@ -19,6 +19,8 @@
 
 package org.infinispan.util.mocks;
 
+import org.infinispan.AdvancedCache;
+import org.infinispan.Cache;
 import org.infinispan.atomic.Delta;
 import org.infinispan.commands.CommandsFactory;
 import org.infinispan.commands.CreateCacheCommand;
@@ -49,10 +51,13 @@
 import org.infinispan.context.Flag;
 import org.infinispan.distexec.mapreduce.Mapper;
 import org.infinispan.distexec.mapreduce.Reducer;
+import org.infinispan.factories.ComponentRegistry;
+import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.statetransfer.StateChunk;
 import org.infinispan.statetransfer.StateRequestCommand;
 import org.infinispan.statetransfer.StateResponseCommand;
+import org.infinispan.test.TestingUtil;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.concurrent.ReclosableLatch;
 import org.infinispan.util.logging.Log;
@@ -67,24 +72,53 @@
 import java.util.concurrent.atomic.AtomicInteger;
 
 /**
-* @author Mircea Markus
-* @since 5.2
-*/
+ * @author Mircea Markus
+ * @since 5.2
+ */
 public class ControlledCommandFactory implements CommandsFactory {
 
    private static Log log = LogFactory.getLog(ControlledCommandFactory.class);
 
+   public final CommandsFactory actual;
    public final ReclosableLatch gate = new ReclosableLatch(true);
-   public final AtomicInteger receivedCommands = new AtomicInteger(0);
-
-   final CommandsFactory actual;
-   final Class<? extends ReplicableCommand> toBlock;
+   public final AtomicInteger remoteCommandsReceived = new AtomicInteger(0);
+   public final AtomicInteger blockTypeCommandsReceived = new AtomicInteger(0);
+   public final Class<? extends  ReplicableCommand> toBlock;
 
    public ControlledCommandFactory(CommandsFactory actual, Class<? extends ReplicableCommand> toBlock) {
       this.actual = actual;
       this.toBlock = toBlock;
    }
 
+   @Override
+   public void initializeReplicableCommand(ReplicableCommand command, boolean isRemote) {
+      if (isRemote) {
+         remoteCommandsReceived.incrementAndGet();
+         if (toBlock != null && command.getClass().isAssignableFrom(toBlock)) {
+            blockTypeCommandsReceived.incrementAndGet();
+            try {
+               gate.await();
+               log.tracef(""gate is opened, processing the lock cleanup:  %s"", command);
+            } catch (InterruptedException e) {
+               throw new RuntimeException(e);
+            }
+         }
+      }
+      actual.initializeReplicableCommand(command, isRemote);
+   }
+
+   public static ControlledCommandFactory registerControlledCommandFactory(Cache cache, Class<? extends ReplicableCommand> toBlock) {
+      AdvancedCache advancedCache = cache.getAdvancedCache();
+      ComponentRegistry componentRegistry = advancedCache.getComponentRegistry();
+      final ControlledCommandFactory ccf = new ControlledCommandFactory(componentRegistry.getCommandsFactory(), toBlock);
+      TestingUtil.replaceField(ccf, ""commandsFactory"", componentRegistry, ComponentRegistry.class);
+
+      //hack: re-add the component registry to the GlobalComponentRegistry's ""namedComponents"" (CHM) in order to correctly publish it for
+      // when it will be read by the InboundInvocationHandlder. InboundInvocationHandlder reads the value from the GlobalComponentRegistry.namedComponents before using it
+      advancedCache.getComponentRegistry().getGlobalComponentRegistry().registerNamedComponentRegistry(componentRegistry, EmbeddedCacheManager.DEFAULT_CACHE_NAME);
+      return ccf;
+   }
+
    @Override
    public PutKeyValueCommand buildPutKeyValueCommand(Object key, Object value, long lifespanMillis, long maxIdleTimeMillis, Set<Flag> flags) {
       return actual.buildPutKeyValueCommand(key, value, lifespanMillis, maxIdleTimeMillis, flags);
@@ -190,21 +224,6 @@ public RollbackCommand buildRollbackCommand(GlobalTransaction gtx) {
       return actual.buildRollbackCommand(gtx);
    }
 
-   @Override
-   public void initializeReplicableCommand(ReplicableCommand command, boolean isRemote) {
-      if (isRemote && command.getClass().isAssignableFrom(toBlock)) {
-         log.tracef(""Received command %s. gate.isOpened() %s?"", command, gate.isOpened());
-         receivedCommands.incrementAndGet();
-         try {
-            gate.await();
-            log.tracef(""gate is opened, processing the lock cleanup:  %s"", command);
-         } catch (InterruptedException e) {
-            throw new RuntimeException(e);
-         }
-      }
-      actual.initializeReplicableCommand(command, isRemote);
-   }
-
    @Override
    public MultipleRpcCommand buildReplicateCommand(List<ReplicableCommand> toReplicate) {
       return actual.buildReplicateCommand(toReplicate);",2012-10-17T08:29:36Z,585
"@@ -79,7 +79,7 @@
 
    <default>
       <locking concurrencyLevel=""100"" lockAcquisitionTimeout=""1000""/>
-      <transaction transactionMode=""NON_TRANSACTIONAL""/>
+      <transaction transactionMode=""NON_TRANSACTIONAL"" reaperWakeUpInterval=""123"" completedTxTimeout=""3123""/>
       <jmxStatistics enabled=""false""/>
    </default>
 ",2012-10-17T08:29:36Z,171
"@@ -53,6 +53,9 @@
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionCoordinator;
 import org.infinispan.transaction.TransactionTable;
+import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.transaction.xa.recovery.RecoverableTransactionIdentifier;
+import org.infinispan.transaction.xa.recovery.RecoveryManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 import org.rhq.helpers.pluginAnnotations.agent.DataType;
@@ -90,18 +93,21 @@ public class TxInterceptor extends CommandInterceptor {
    protected RpcManager rpcManager;
 
    private static final Log log = LogFactory.getLog(TxInterceptor.class);
+   private RecoveryManager recoveryManager;
 
    @Override
    protected Log getLog() {
       return log;
    }
 
    @Inject
-   public void init(TransactionTable txTable, Configuration c, TransactionCoordinator txCoordinator, RpcManager rpcManager) {
+   public void init(TransactionTable txTable, Configuration c, TransactionCoordinator txCoordinator, RpcManager rpcManager,
+                    RecoveryManager recoveryManager) {
       this.cacheConfiguration = c;
       this.txTable = txTable;
       this.txCoordinator = txCoordinator;
       this.rpcManager = rpcManager;
+      this.recoveryManager = recoveryManager;
       setStatisticsEnabled(cacheConfiguration.jmxStatistics().enabled());
    }
 
@@ -160,7 +166,16 @@ public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand comm
       if (!ctx.isOriginLocal()) {
          txTable.remoteTransactionRollback(command.getGlobalTransaction());
       }
-      return invokeNextInterceptor(ctx, command);
+      try {
+         return invokeNextInterceptor(ctx, command);
+      } finally {
+         //for tx that rollback we do not send a TxCompletionNotification, so we should cleanup
+         // the recovery info here
+         if (recoveryManager!=null) {
+            GlobalTransaction gtx = command.getGlobalTransaction();
+            recoveryManager.removeRecoveryInformation(((RecoverableTransactionIdentifier)gtx).getXid());
+         }
+      }
    }
 
    @Override",2012-11-02T12:56:26Z,87
"@@ -82,6 +82,7 @@ public void afterCompletion(int status) {
          } catch (XAException e) {
             throw new CacheException(""Could not commit."", e);
          }
+         releaseLocksForCompletedTransaction(localTransaction);
       } else if (status == Status.STATUS_ROLLEDBACK) {
          try {
             txCoordinator.rollback(localTransaction);
@@ -91,7 +92,6 @@ public void afterCompletion(int status) {
       } else {
          throw new IllegalArgumentException(""Unknown status: "" + status);
       }
-      releaseLocksForCompletedTransaction(localTransaction);
    }
 
    @Override",2012-11-02T12:56:26Z,581
"@@ -138,7 +138,6 @@ public void rollback(Xid externalXid) throws XAException {
       LocalXaTransaction localTransaction1 = getLocalTransactionAndValidateImpl(xid, txTable);
       localTransaction.markForRollback(true); //ISPN-879 : make sure that locks are no longer associated to this transactions
       txCoordinator.rollback(localTransaction1);
-      forgetSuccessfullyCompletedTransaction(recoveryManager, xid, localTransaction1);
    }
 
    @Override",2012-11-02T12:56:26Z,92
"@@ -0,0 +1,72 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.commands.remote.recovery.TxCompletionNotificationCommand;
+import org.infinispan.commands.tx.PrepareCommand;
+import org.infinispan.commands.tx.RollbackCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.util.mocks.ControlledCommandFactory;
+import org.testng.annotations.Test;
+
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNull;
+import static org.testng.Assert.fail;
+
+@Test(groups = ""functional"", testName = ""tx.TxCompletionForRolledBackTxOptTest"")
+public class TxCompletionForRolledBackTxOptTest extends MultipleCacheManagersTest {
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      ConfigurationBuilder dcc = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+      dcc.clustering().hash().numOwners(1).transaction().lockingMode(LockingMode.OPTIMISTIC);
+      createCluster(dcc, 3);
+      waitForClusterToForm();
+      advancedCache(2).addInterceptor(new RollbackBeforePrepareTest.FailPrepareInterceptor(), 1);
+   }
+
+   public void testTxCompletionNotSentForRollback() throws Throwable {
+      ControlledCommandFactory cf = ControlledCommandFactory.registerControlledCommandFactory(cache(1), null);
+
+      tm(0).begin();
+      Object k1 = getKeyForCache(1);
+      Object k2 = getKeyForCache(2);
+      cache(0).put(k1, k1);
+      cache(0).put(k2, k2);
+      try {
+         tm(0).commit();
+         fail();
+      } catch (Throwable t) {
+         //expected
+      }
+
+      assertNotLocked(k1);
+      assertNotLocked(k2);
+      assertNull(cache(0).get(k1));
+      assertNull(cache(0).get(k2));
+
+      assertEquals(cf.received(PrepareCommand.class), 1);
+      assertEquals(cf.received(RollbackCommand.class), 2);
+      assertEquals(cf.received(TxCompletionNotificationCommand.class), 0);
+   }
+}",2012-11-02T12:56:26Z,582
"@@ -0,0 +1,66 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.commands.remote.recovery.TxCompletionNotificationCommand;
+import org.infinispan.commands.tx.RollbackCommand;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.transaction.LockingMode;
+import org.infinispan.util.mocks.ControlledCommandFactory;
+import org.testng.annotations.Test;
+
+import static org.testng.Assert.assertEquals;
+import static org.testng.Assert.assertNull;
+
+/**
+ * @author Mircea Markus
+ * @since 5.2
+ */
+@Test (groups = ""functional"", testName = ""tx.TxCompletionForRolledBackTxTest"")
+public class TxCompletionForRolledBackTxTest extends MultipleCacheManagersTest {
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      ConfigurationBuilder dcc = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+      dcc.clustering().hash().numOwners(1).transaction().lockingMode(LockingMode.PESSIMISTIC);
+      amend(dcc);
+      createCluster(dcc, 2);
+      waitForClusterToForm();
+   }
+
+   protected void amend(ConfigurationBuilder dcc) {}
+
+   public void testTxCompletionNotSentForRollback() throws Throwable {
+      ControlledCommandFactory cf = ControlledCommandFactory.registerControlledCommandFactory(cache(1), null);
+
+      tm(0).begin();
+      Object k = getKeyForCache(1);
+      cache(0).put(k,""k"");
+      tm(0).rollback();
+
+      assertNotLocked(k);
+      assertNull(cache(0).get(k));
+
+      assertEquals(cf.received(RollbackCommand.class), 1);
+      assertEquals(cf.received(TxCompletionNotificationCommand.class), 0);
+   }
+}",2012-11-02T12:56:26Z,583
"@@ -0,0 +1,32 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.tx;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.testng.annotations.Test;
+
+@Test (testName = ""tx.TxCompletionForRolledBackXaTxTest"")
+public class TxCompletionForRolledBackXaTxTest extends TxCompletionForRolledBackTxTest {
+
+   @Override
+   protected void amend(ConfigurationBuilder dcc) {
+      dcc.transaction().useSynchronization(false);
+   }
+}",2012-11-02T12:56:26Z,584
"@@ -66,6 +66,7 @@
 import org.infinispan.util.logging.LogFactory;
 
 import javax.transaction.xa.Xid;
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.List;
 import java.util.Map;
@@ -86,15 +87,28 @@ public class ControlledCommandFactory implements CommandsFactory {
    public final ReclosableLatch gate = new ReclosableLatch(true);
    public final AtomicInteger remoteCommandsReceived = new AtomicInteger(0);
    public final AtomicInteger blockTypeCommandsReceived = new AtomicInteger(0);
+   public final List<ReplicableCommand> receivedCommands = new ArrayList<ReplicableCommand>();
    public final Class<? extends  ReplicableCommand> toBlock;
 
    public ControlledCommandFactory(CommandsFactory actual, Class<? extends ReplicableCommand> toBlock) {
       this.actual = actual;
       this.toBlock = toBlock;
    }
 
+   public int received(Class<? extends ReplicableCommand> command) {
+      int result = 0;
+      for (ReplicableCommand r : receivedCommands) {
+         if (r.getClass() == command) {
+            result++;
+         }
+      }
+      return result;
+   }
+
    @Override
    public void initializeReplicableCommand(ReplicableCommand command, boolean isRemote) {
+      log.tracef(""Received command %s"", command);
+      receivedCommands.add(command);
       if (isRemote) {
          remoteCommandsReceived.incrementAndGet();
          if (toBlock != null && command.getClass().isAssignableFrom(toBlock)) {",2012-11-02T12:56:26Z,585
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +41,24 @@
  */
 @Test(groups = ""unit"", enabled = true, testName = ""loaders.bdbje.BdbjeCacheStoreIntegrationVamTest"")
 public class BdbjeCacheStoreIntegrationVamTest extends BdbjeCacheStoreIntegrationTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,80
"@@ -39,21 +39,24 @@
  */
 @Test(groups = ""unit"", sequential = true, testName = ""loaders.cloud.CloudCacheStoreIntegrationVamTest"")
 public class CloudCacheStoreIntegrationVamTest extends CloudCacheStoreIntegrationTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,586
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,19 +41,24 @@
  */
 @Test(groups = ""unit"", testName = ""loaders.cloud.CloudCacheStoreVamTest"")
 public class CloudCacheStoreVamTest extends CloudCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
    }
 
-   @AfterMethod(alwaysRun = true)
-   @Override
-   public void tearDown() throws CacheLoaderException {
-      super.tearDown();
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
       cm.stop();
    }
 
+   @Override
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
+   }
+
 }",2011-09-13T09:07:28Z,587
"@@ -246,7 +246,7 @@ public final Set<InternalCacheEntry> loadSome(int maxEntries) throws CacheLoader
          rs.setFetchSize(tableManipulation.getFetchSize());
          Set<InternalCacheEntry> result = new HashSet<InternalCacheEntry>(maxEntries);
          while (rs.next()) {
-            loadAllProcess(rs, result);
+            loadAllProcess(rs, result, maxEntries);
          }
          return result;
       } catch (SQLException e) {
@@ -267,6 +267,8 @@ protected boolean includeKey(Object key, Set<Object> keysToExclude) {
 
    protected abstract void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result) throws SQLException, CacheLoaderException;
 
+   protected abstract void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result, int maxEntries) throws SQLException, CacheLoaderException;
+
    protected abstract void loadAllKeysProcess(ResultSet rs, Set<Object> keys, Set<Object> keysToExclude) throws SQLException, CacheLoaderException;
 
    protected abstract void toStreamProcess(ResultSet rs, InputStream is, ObjectOutput objectOutput) throws CacheLoaderException, SQLException, IOException;",2011-09-13T09:07:28Z,405
"@@ -118,6 +118,19 @@ public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result) throws
             }
          }
 
+         @Override
+         public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result, int maxEntries) throws SQLException, CacheLoaderException {
+            InputStream binaryStream = rs.getBinaryStream(1);
+            Bucket bucket = (Bucket) JdbcUtil.unmarshall(getMarshaller(), binaryStream);
+            for (InternalCacheEntry ice: bucket.getStoredEntries()) {
+               if (!ice.isExpired())
+                  result.add(ice);
+
+               if (result.size() == maxEntries)
+                  break;
+            }
+         }
+
          @Override
          public void loadAllKeysProcess(ResultSet rs, Set<Object> keys, Set<Object> keysToExclude) throws SQLException, CacheLoaderException {
             InputStream binaryStream = rs.getBinaryStream(1);",2011-09-13T09:07:28Z,407
"@@ -146,6 +146,11 @@ public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result) throws
             result.add(icv.toInternalCacheEntry(key));
          }
 
+         @Override
+         public void loadAllProcess(ResultSet rs, Set<InternalCacheEntry> result, int maxEntries) throws SQLException, CacheLoaderException {
+            loadAllProcess(rs, result);
+         }
+
          @Override
          public void loadAllKeysProcess(ResultSet rs, Set<Object> keys, Set<Object> keysToExclude) throws SQLException, CacheLoaderException {
             String keyStr = rs.getString(1);",2011-09-13T09:07:28Z,82
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.binary.JdbcBinaryCacheStoreVamTest"")
 public class JdbcBinaryCacheStoreVamTest extends JdbcBinaryCacheStoreTest {   
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,588
"@@ -39,6 +39,7 @@
 import org.infinispan.test.fwk.UnitTestDatabaseManager;
 import org.testng.annotations.AfterMethod;
 import org.testng.annotations.AfterTest;
+import org.testng.annotations.BeforeMethod;
 import org.testng.annotations.BeforeTest;
 import org.testng.annotations.Test;
 
@@ -64,7 +65,7 @@ public class JdbcMixedCacheStoreTest {
    private static final Person MIRCEA = new Person(""Mircea"", ""Markus"", 28);
    private static final Person MANIK = new Person(""Manik"", ""Surtani"", 18);
 
-   @BeforeTest
+   @BeforeMethod
    public void createCacheStore() throws CacheLoaderException {
       stringsTm = UnitTestDatabaseManager.buildDefaultTableManipulation();
       stringsTm.setTableNamePrefix(""STRINGS_TABLE"");",2011-09-13T09:07:28Z,589
"@@ -22,10 +22,13 @@
  */
 package org.infinispan.loaders.jdbc.mixed;
 
+import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -38,21 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.mixed.JdbcMixedCacheStoreVamTest"")
 public class JdbcMixedCacheStoreVamTest extends JdbcMixedCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void clearStore() throws Exception {
-      try {
-         super.clearStore();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,589
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,22 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.mixed.JdbcMixedCacheStoreVamTest2"")
 public class JdbcMixedCacheStoreVamTest2 extends JdbcMixedCacheStoreTest2 {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
 
 }",2011-09-13T09:07:28Z,590
"@@ -26,7 +26,8 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
-import org.testng.annotations.AfterMethod;
+import org.testng.annotations.AfterClass;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +40,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.stringbased.JdbcStringBasedCacheStoreVamTest"")
 public class JdbcStringBasedCacheStoreVamTest extends JdbcStringBasedCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,591
"@@ -22,10 +22,13 @@
  */
 package org.infinispan.loaders.jdbc.stringbased;
 
+import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -38,21 +41,24 @@
  */
 @Test(groups = ""functional"", testName = ""loaders.jdbc.stringbased.JdbcStringBasedCacheStoreVamTest2"")
 public class JdbcStringBasedCacheStoreVamTest2 extends JdbcStringBasedCacheStoreTest2 {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void clearStore() throws Exception {
-      try {
-         super.clearStore();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,591
"@@ -26,7 +26,9 @@
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
+import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
+import org.testng.annotations.BeforeClass;
 import org.testng.annotations.Test;
 
 import static org.infinispan.test.TestingUtil.extractCacheMarshaller;
@@ -39,21 +41,24 @@
  */
 @Test(groups = ""unit"", testName = ""loaders.jdbm.JdbmCacheStoreVamTest"")
 public class JdbmCacheStoreVamTest extends JdbmCacheStoreTest {
-   private EmbeddedCacheManager cm;
 
-   @Override
-   protected StreamingMarshaller getMarshaller() {
+   EmbeddedCacheManager cm;
+   StreamingMarshaller marshaller;
+
+   @BeforeClass(alwaysRun = true)
+   public void setUpClass() {
       cm = TestCacheManagerFactory.createLocalCacheManager();
-      return extractCacheMarshaller(cm.getCache());
+      marshaller = extractCacheMarshaller(cm.getCache());
+   }
+
+   @AfterClass(alwaysRun = true)
+   public void tearDownClass() throws CacheLoaderException {
+      cm.stop();
    }
 
-   @AfterMethod(alwaysRun = true)
    @Override
-   public void tearDown() throws CacheLoaderException {
-      try {
-         super.tearDown();
-      } finally {
-         cm.stop();
-      }
+   protected StreamingMarshaller getMarshaller() {
+      return marshaller;
    }
+
 }",2011-09-13T09:07:28Z,592
"@@ -46,6 +46,7 @@
 import java.util.*;
 
 import static java.util.Collections.emptySet;
+import static org.testng.AssertJUnit.assertEquals;
 
 /**
  * This is a base class containing various unit tests for each and every different CacheStore implementations. If you
@@ -443,7 +444,7 @@ public void testPreloadWithMaxSize() throws CacheLoaderException {
 
       Set<InternalCacheEntry> set = cs.load(2);
 
-      assert set.size() == 2;
+      assertEquals(2, set.size());
       Set expected = new HashSet();
       expected.add(""k1"");
       expected.add(""k2"");",2011-09-13T09:07:28Z,84
"@@ -36,6 +36,7 @@
 import javax.transaction.Transaction;
 import javax.transaction.TransactionManager;
 import java.io.Serializable;
+import java.util.UUID;
 
 /**
  * @author bela
@@ -46,6 +47,7 @@ public class DummyBaseTransactionManager implements TransactionManager, Serializ
    private static final long serialVersionUID = -6716097342564237376l;
    private static final Log log = LogFactory.getLog(DummyBaseTransactionManager.class);
    private static final boolean trace = log.isTraceEnabled();
+   final UUID transactionManagerId = UUID.randomUUID();
 
    /**
     * Starts a new transaction, and associate it with the calling thread.",2012-01-11T17:05:42Z,593
"@@ -50,15 +50,16 @@ public class DummyTransaction implements Transaction {
    private static boolean trace = log.isTraceEnabled();
 
    private volatile int status = Status.STATUS_UNKNOWN;
-   protected DummyBaseTransactionManager tm_;
-   protected DummyXid xid = new DummyXid();
+   protected final DummyBaseTransactionManager tm_;
+   protected final DummyXid xid;
 
    protected Set<Synchronization> syncs;
-   private List<XAResource> enlistedResources = new ArrayList<XAResource>(2);
+   private final List<XAResource> enlistedResources = new ArrayList<XAResource>(2);
    private int prepareStatus;
 
    public DummyTransaction(DummyBaseTransactionManager tm) {
       tm_ = tm;
+      xid = new DummyXid(tm.transactionManagerId);
       status = Status.STATUS_ACTIVE;
    }
 ",2012-01-11T17:05:42Z,594
"@@ -28,6 +28,8 @@
 import javax.transaction.xa.Xid;
 import java.util.Arrays;
 import java.util.UUID;
+import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.atomic.AtomicLong;
 
 /**
  * Implementation of Xid.
@@ -36,15 +38,19 @@
  */
 public class DummyXid implements Xid {
 
+   private static final AtomicLong GLOBAL_ID_GENERATOR = new AtomicLong(1);
+   private static final AtomicLong BRANCH_QUALIFIER_GENERATOR = new AtomicLong(1);
+
    private byte[] globalTransactionId = new byte[64];
    private byte[] branchQualifier = new byte[64];
+   private final int cachedHashcode;
 
    public int getFormatId() {
       return 1;
    }
 
-   public DummyXid() {
-      initialize();
+   public DummyXid(UUID transactionManagerId) {
+      cachedHashcode = initializeAndCalculateHash(transactionManagerId);
    }
 
    public byte[] getGlobalTransactionId() {
@@ -55,18 +61,23 @@ public byte[] getBranchQualifier() {
       return branchQualifier;
    }
 
-   private void initialize() {
-      initialize(globalTransactionId);
-      initialize(branchQualifier);
+   private int initializeAndCalculateHash(UUID transactionManagerId) {
+      int hc1 = initialize(transactionManagerId, GLOBAL_ID_GENERATOR, globalTransactionId);
+      return 37 * hc1 + initialize(transactionManagerId, BRANCH_QUALIFIER_GENERATOR, branchQualifier);
    }
 
-   private void initialize(byte[] field) {
-      UUID uuid = UUID.randomUUID();
-      long lsb = uuid.getLeastSignificantBits();
-      long msb = uuid.getMostSignificantBits();
+   private int initialize(UUID transactionManagerId, AtomicLong generator, byte[] field) {
+      long lsb = transactionManagerId.getLeastSignificantBits();
+      long msb = transactionManagerId.getMostSignificantBits();
+      long id = generator.getAndIncrement();
       Arrays.fill(field, (byte) 0);
       UnsignedNumeric.writeUnsignedLong(field, 0, lsb);
       UnsignedNumeric.writeUnsignedLong(field, 10, msb);
+      UnsignedNumeric.writeUnsignedLong(field, 20, id);
+      int hash = (int) (lsb ^ lsb >>> 32);
+      hash = 37 * hash + (int) (msb ^ msb >>> 32);
+      hash = 37 * hash + (int) (id ^ id >>> 32);
+      return hash;
    }
 
    @Override
@@ -93,8 +104,6 @@ public boolean equals(Object o) {
 
    @Override
    public int hashCode() {
-      int result = globalTransactionId != null ? Arrays.hashCode(globalTransactionId) : 0;
-      result = 31 * result + (branchQualifier != null ? Arrays.hashCode(branchQualifier) : 0);
-      return result;
+      return cachedHashcode;
    }
 }",2012-01-11T17:05:42Z,595
"@@ -30,13 +30,14 @@
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.transaction.xa.LocalXaTransaction;
 import org.infinispan.transaction.xa.TransactionFactory;
-import org.infinispan.transaction.xa.XaTransactionTable;
 import org.infinispan.transaction.xa.TransactionXaAdapter;
+import org.infinispan.transaction.xa.XaTransactionTable;
 import org.testng.annotations.BeforeMethod;
 import org.testng.annotations.Test;
 
 import javax.transaction.xa.XAException;
 import javax.transaction.xa.XAResource;
+import java.util.UUID;
 
 /**
  * @author Mircea.Markus@jboss.com
@@ -50,6 +51,7 @@ public class TransactionXaAdapterTmIntegrationTest {
    private LocalXaTransaction localTx;
    private TransactionXaAdapter xaAdapter;
    private DummyXid xid;
+   private UUID uuid = UUID.randomUUID();
 
    @BeforeMethod
    public void setUp() {
@@ -58,7 +60,7 @@ public void setUp() {
       gtf.init(false, false, true);
       globalTransaction = gtf.newGlobalTransaction(null, false);
       localTx = new LocalXaTransaction(new DummyTransaction(null), globalTransaction, false);
-      xid = new DummyXid();
+      xid = new DummyXid(uuid);
       localTx.setXid(xid);
       txTable.addLocalTransactionMapping(localTx);      
 
@@ -70,7 +72,7 @@ public void setUp() {
    }
 
    public void testPrepareOnNonexistentXid() {
-      DummyXid xid = new DummyXid();
+      DummyXid xid = new DummyXid(uuid);
       try {
          xaAdapter.prepare(xid);
          assert false;
@@ -80,7 +82,7 @@ public void testPrepareOnNonexistentXid() {
    }
 
    public void testCommitOnNonexistentXid() {
-      DummyXid xid = new DummyXid();
+      DummyXid xid = new DummyXid(uuid);
       try {
          xaAdapter.commit(xid, false);
          assert false;
@@ -90,7 +92,7 @@ public void testCommitOnNonexistentXid() {
    }
 
    public void testRollabckOnNonexistentXid() {
-      DummyXid xid = new DummyXid();
+      DummyXid xid = new DummyXid(uuid);
       try {
          xaAdapter.rollback(xid);
          assert false;
@@ -117,7 +119,7 @@ public void testOnePhaseCommitConfigured() throws XAException {
    public void test1PcAndNonExistentXid() {
       configuration.setCacheMode(Configuration.CacheMode.INVALIDATION_ASYNC);
       try {
-         DummyXid doesNotExists = new DummyXid();
+         DummyXid doesNotExists = new DummyXid(uuid);
          xaAdapter.commit(doesNotExists, false);
          assert false;
       } catch (XAException e) {
@@ -128,7 +130,7 @@ public void test1PcAndNonExistentXid() {
    public void test1PcAndNonExistentXid2() {
       configuration.setCacheMode(Configuration.CacheMode.DIST_SYNC);
       try {
-         DummyXid doesNotExists = new DummyXid();
+         DummyXid doesNotExists = new DummyXid(uuid);
          xaAdapter.commit(doesNotExists, true);
          assert false;
       } catch (XAException e) {",2012-01-11T17:05:42Z,94
"@@ -30,6 +30,7 @@
 import javax.transaction.xa.XAException;
 import java.util.Collections;
 import java.util.Map;
+import java.util.UUID;
 
 /**
  * @author Mircea Markus
@@ -74,7 +75,7 @@ public void testPutAll() throws Exception {
    protected void commit() {
       DummyTransactionManager dtm = (DummyTransactionManager) tm(0);
       try {
-         dtm.firstEnlistedResource().commit(new DummyXid(), true);
+         dtm.firstEnlistedResource().commit(new DummyXid(UUID.randomUUID()), true);
       } catch (XAException e) {
          throw new RuntimeException(e);
       }
@@ -83,7 +84,7 @@ protected void commit() {
    protected void prepare() {
       DummyTransactionManager dtm = (DummyTransactionManager) tm(0);
       try {
-         dtm.firstEnlistedResource().prepare(new DummyXid());
+         dtm.firstEnlistedResource().prepare(new DummyXid(UUID.randomUUID()));
       } catch (XAException e) {
          throw new RuntimeException(e);
       }",2012-01-11T17:05:42Z,596
"@@ -66,7 +66,9 @@ public class InboundTransferTask {
 
    private final long timeout;
 
-   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout) {
+   private final String cacheName;
+
+   public InboundTransferTask(Set<Integer> segments, Address source, int topologyId, StateConsumerImpl stateConsumer, RpcManager rpcManager, CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""segments must not be null or empty"");
       }
@@ -81,6 +83,7 @@ public InboundTransferTask(Set<Integer> segments, Address source, int topologyId
       this.rpcManager = rpcManager;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public Set<Integer> getSegments() {
@@ -93,7 +96,7 @@ public Address getSource() {
 
    public boolean requestTransactions() {
       if (trace) {
-         log.tracef(""Requesting transactions for segments %s"", segments);
+         log.tracef(""Requesting transactions for segments %s of cache %s from node %s"", segments, cacheName, source);
       }
       // get transactions and locks
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.GET_TRANSACTIONS, rpcManager.getAddress(), topologyId, segments);
@@ -109,6 +112,10 @@ public boolean requestTransactions() {
    }
 
    public boolean requestSegments() {
+      if (trace) {
+         log.tracef(""Requesting segments %s of cache %s from node %s"", segments, cacheName, source);
+      }
+
       // start transfer of cache entries
       StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.START_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
       Map<Address, Response> responses = rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
@@ -139,24 +146,21 @@ public void cancel() {
       if (!isCancelled) {
          isCancelled = true;
 
-         Set<Integer> cancelledSegments = new HashSet<Integer>(segments);
-         segments.clear();
-         finishedSegments.clear();
-
-         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, cancelledSegments);
+         StateRequestCommand cmd = commandsFactory.buildStateRequestCommand(StateRequestCommand.Type.CANCEL_STATE_TRANSFER, rpcManager.getAddress(), topologyId, segments);
          rpcManager.invokeRemotely(Collections.singleton(source), cmd, ResponseMode.SYNCHRONOUS_IGNORE_LEAVERS, timeout);
 
          stateConsumer.onTaskCompletion(this);
       }
    }
 
    public void onStateReceived(int segmentId, boolean isLastChunk) {
-      if (!isCancelled && segments.contains(segmentId)) {
-         if (isLastChunk) {
-            finishedSegments.add(segmentId);
-            if (finishedSegments.containsAll(segments)) {
-               stateConsumer.onTaskCompletion(this);
+      if (!isCancelled && isLastChunk && segments.contains(segmentId)) {
+         finishedSegments.add(segmentId);
+         if (finishedSegments.containsAll(segments)) {
+            if (trace) {
+               log.tracef(""Finished receiving state for segments %s of cache %s"", segments, cacheName);
             }
+            stateConsumer.onTaskCompletion(this);
          }
       }
    }
@@ -166,11 +170,14 @@ public String toString() {
       HashSet<Integer> unfinishedSegments = new HashSet<Integer>(segments);
       unfinishedSegments.removeAll(finishedSegments);
       return ""InboundTransferTask{"" +
-            ""unfinishedSegments="" + unfinishedSegments +
+            ""segments="" + segments +
+            "", finishedSegments="" + finishedSegments +
+            "", unfinishedSegments="" + unfinishedSegments +
             "", source="" + source +
             "", isCancelled="" + isCancelled +
             "", topologyId="" + topologyId +
             "", timeout="" + timeout +
+            "", cacheName="" + cacheName +
             '}';
    }
 }",2012-11-07T14:07:34Z,120
"@@ -24,20 +24,19 @@
 package org.infinispan.statetransfer;
 
 import org.infinispan.commands.CommandsFactory;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.CacheLoaderManager;
 import org.infinispan.loaders.CacheStore;
+import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.remoting.transport.jgroups.SuspectException;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.ReadOnlyDataContainerBackedKeySet;
-import org.infinispan.util.concurrent.AggregatingNotifyingFutureBuilder;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.NotifyingNotifiableFuture;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -70,8 +69,6 @@ public class OutboundTransferTask implements Runnable {
 
    private final int stateTransferChunkSize;
 
-   private final Configuration configuration;
-
    private final ConsistentHash readCh;
 
    private final DataContainer dataContainer;
@@ -84,27 +81,24 @@ public class OutboundTransferTask implements Runnable {
 
    private final long timeout;
 
+   private final String cacheName;
+
    private final Map<Integer, List<InternalCacheEntry>> entriesBySegment = ConcurrentMapFactory.makeConcurrentMap();
 
    /**
     * The total number of entries from all segments accumulated in entriesBySegment.
     */
    private int accumulatedEntries;
 
-   /**
-    * This is used with RpcManager.invokeRemotelyInFuture() to be able to cancel message sending if the task needs to be canceled.
-    */
-   private final NotifyingNotifiableFuture<Object> sendFuture = new AggregatingNotifyingFutureBuilder(null);
-
    /**
     * The Future obtained from submitting this task to an executor service. This is used for cancellation.
     */
    private FutureTask runnableFuture;
 
    public OutboundTransferTask(Address destination, Set<Integer> segments, int stateTransferChunkSize,
                                int topologyId, ConsistentHash readCh, StateProviderImpl stateProvider, DataContainer dataContainer,
-                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager, Configuration configuration,
-                               CommandsFactory commandsFactory, long timeout) {
+                               CacheLoaderManager cacheLoaderManager, RpcManager rpcManager,
+                               CommandsFactory commandsFactory, long timeout, String cacheName) {
       if (segments == null || segments.isEmpty()) {
          throw new IllegalArgumentException(""Segments must not be null or empty"");
       }
@@ -123,9 +117,9 @@ public OutboundTransferTask(Address destination, Set<Integer> segments, int stat
       this.dataContainer = dataContainer;
       this.cacheLoaderManager = cacheLoaderManager;
       this.rpcManager = rpcManager;
-      this.configuration = configuration;
       this.commandsFactory = commandsFactory;
       this.timeout = timeout;
+      this.cacheName = cacheName;
    }
 
    public void execute(ExecutorService executorService) {
@@ -154,7 +148,7 @@ public void run() {
       try {
          // send data container entries
          for (InternalCacheEntry ice : dataContainer) {
-            Object key = ice.getKey();
+            Object key = ice.getKey();  //todo [anistor] should we check for expired entries?
             int segmentId = readCh.getSegment(key);
             if (segments.contains(segmentId)) {
                sendEntry(ice, segmentId);
@@ -198,7 +192,7 @@ public void run() {
          }
       }
       if (trace) {
-         log.tracef(""Outbound transfer of segments %s to %s is complete"", segments, destination);
+         log.tracef(""Outbound transfer of segments %s of cache %s to node %s is complete"", segments, cacheName, destination);
       }
    }
 
@@ -217,7 +211,6 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
       // send if we have a full chunk
       if (accumulatedEntries >= stateTransferChunkSize) {
          sendEntries(false);
-         entriesBySegment.clear();
          accumulatedEntries = 0;
       }
 
@@ -232,32 +225,42 @@ private void sendEntry(InternalCacheEntry ice, int segmentId) {
 
    private void sendEntries(boolean isLast) {
       List<StateChunk> chunks = new ArrayList<StateChunk>();
+      for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
+         List<InternalCacheEntry> entries = e.getValue();
+         if (!entries.isEmpty()) {
+            chunks.add(new StateChunk(e.getKey(), new ArrayList<InternalCacheEntry>(entries), isLast));
+            entries.clear();
+         }
+      }
+
       if (isLast) {
          for (int segmentId : segments) {
             List<InternalCacheEntry> entries = entriesBySegment.get(segmentId);
             if (entries == null) {
-               entries = InfinispanCollections.emptyList();
-            }
-            chunks.add(new StateChunk(segmentId, entries, isLast));
-         }
-      } else {
-         for (Map.Entry<Integer, List<InternalCacheEntry>> e : entriesBySegment.entrySet()) {
-            List<InternalCacheEntry> entries = e.getValue();
-            if (!entries.isEmpty()) {
-               chunks.add(new StateChunk(e.getKey(), entries, isLast));
+               chunks.add(new StateChunk(segmentId, InfinispanCollections.<InternalCacheEntry>emptyList(), true));
             }
          }
       }
 
-      if (!chunks.isEmpty() || isLast) {
+      if (!chunks.isEmpty()) {
          if (trace) {
-            log.tracef(""Sending %d cache entries from segments %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), destination);
+            if (isLast) {
+               log.tracef(""Sending last chunk containing %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, segments, cacheName, destination);
+            } else {
+               log.tracef(""Sending %d cache entries from segments %s of cache %s to node %s"", accumulatedEntries, entriesBySegment.keySet(), cacheName, destination);
+            }
          }
 
-         //todo [anistor] send back the received topologyId or my local one?
          StateResponseCommand cmd = commandsFactory.buildStateResponseCommand(rpcManager.getAddress(), topologyId, chunks);
-         // send synchronously, in FIFO mode. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
-         rpcManager.invokeRemotelyInFuture(Collections.singleton(destination), cmd, false, sendFuture, timeout);
+         // send synchronously, in order. it is important that the last chunk is received last in order to correctly detect completion of the stream of chunks
+         try {
+            rpcManager.invokeRemotely(Collections.singleton(destination), cmd, ResponseMode.SYNCHRONOUS, timeout, false, null);
+         } catch (SuspectException e) {
+            log.errorf(e, ""Node %s left cache %s: %s"", destination, cacheName, e.getMessage());
+            cancel();
+         } catch (Exception e) {
+            log.errorf(e, ""Failed to send entries to node %s : %s"", destination, e.getMessage());
+         }
       }
    }
 
@@ -268,7 +271,7 @@ private void sendEntries(boolean isLast) {
     */
    public void cancelSegments(Set<Integer> cancelledSegments) {
       if (trace) {
-         log.tracef(""Cancelling outbound transfer of segments %s to %s"", cancelledSegments, destination);
+         log.tracef(""Cancelling outbound transfer of segments %s of cache %s to node %s"", cancelledSegments, cacheName, destination);
       }
       if (segments.removeAll(cancelledSegments)) {
          entriesBySegment.keySet().removeAll(cancelledSegments);  // here we do not update accumulatedEntries but this inaccuracy does not cause any harm
@@ -284,11 +287,22 @@ public void cancelSegments(Set<Integer> cancelledSegments) {
    public void cancel() {
       if (runnableFuture != null && !runnableFuture.isCancelled()) {
          runnableFuture.cancel(true);
-         sendFuture.cancel(true);
       }
    }
 
    public boolean isCancelled() {
       return runnableFuture != null && runnableFuture.isCancelled();
    }
+
+   @Override
+   public String toString() {
+      return ""OutboundTransferTask{"" +
+            ""topologyId="" + topologyId +
+            "", destination="" + destination +
+            "", segments="" + segments +
+            "", stateTransferChunkSize="" + stateTransferChunkSize +
+            "", timeout="" + timeout +
+            "", cacheName='"" + cacheName + '\'' +
+            '}';
+   }
 }",2012-11-07T14:07:34Z,121
"@@ -45,7 +45,6 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -62,7 +61,7 @@
 import static org.infinispan.context.Flag.*;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateConsumer} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -72,7 +71,7 @@ public class StateConsumerImpl implements StateConsumer {
    private static final Log log = LogFactory.getLog(StateConsumerImpl.class);
    private static final boolean trace = log.isTraceEnabled();
 
-   private LocalTopologyManager localTopologyManager;
+   private StateTransferManager stateTransferManager;
    private String cacheName;
    private Configuration configuration;
    private RpcManager rpcManager;
@@ -119,7 +118,7 @@ public StateConsumerImpl() {
 
    @Inject
    public void init(Cache cache,
-                    LocalTopologyManager localTopologyManager,
+                    StateTransferManager stateTransferManager,
                     InterceptorChain interceptorChain,
                     InvocationContextContainer icc,
                     Configuration configuration,
@@ -130,7 +129,7 @@ public void init(Cache cache,
                     TransactionTable transactionTable,
                     StateTransferLock stateTransferLock) {
       this.cacheName = cache.getName();
-      this.localTopologyManager = localTopologyManager;
+      this.stateTransferManager = stateTransferManager;
       this.interceptorChain = interceptorChain;
       this.icc = icc;
       this.configuration = configuration;
@@ -171,26 +170,30 @@ public boolean isStateTransferInProgressForKey(Object key) {
 
    @Override
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
-      if (trace) log.tracef(""Received new CH: %s"", cacheTopology.getWriteConsistentHash());
+      if (trace) log.tracef(""Received new CH %s for cache %s"", cacheTopology.getWriteConsistentHash(), cacheName);
 
       activeTopologyUpdates.incrementAndGet();
       if (isRebalance) {
          rebalanceInProgress.set(true);
       }
-      ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
+      final ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
       // Ensures writes to the data container use the right consistent hash
       // No need for a try/finally block, since it's just an assignment
       stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
       stateTransferLock.releaseExclusiveTopologyLock();
-      stateTransferLock.topologyInstalled(cacheTopology.getTopologyId());
+      stateTransferLock.notifyTopologyInstalled(cacheTopology.getTopologyId());
 
       try {
          Set<Integer> addedSegments;
          if (previousCh == null) {
             // we start fresh, without any data, so we need to pull everything we own according to writeCh
 
             addedSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
+
+            if (trace) {
+               log.tracef(""On cache %s we have: added segments: %s"", cacheName, addedSegments);
+            }
          } else {
             Set<Integer> previousSegments = getOwnedSegments(previousCh);
             Set<Integer> newSegments = getOwnedSegments(cacheTopology.getWriteConsistentHash());
@@ -199,16 +202,16 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             Set<Integer> removedSegments = new HashSet<Integer>(previousSegments);
             removedSegments.removeAll(newSegments);
 
-            // remove inbound transfers and any data for segments we no longer own
+            addedSegments = new HashSet<Integer>(newSegments);
+            addedSegments.removeAll(previousSegments);
+
             if (trace) {
-               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                     removedSegments, newSegments, previousSegments);
+               log.tracef(""On cache %s we have: removed segments: %s; new segments: %s; old segments: %s; added segments: %s"",
+                     cacheName, removedSegments, newSegments, previousSegments, addedSegments);
             }
-            discardSegments(removedSegments);
 
-            Set<Integer> currentSegments = getOwnedSegments(cacheTopology.getReadConsistentHash());
-            addedSegments = new HashSet<Integer>(newSegments);
-            addedSegments.removeAll(currentSegments);
+            // remove inbound transfers and any data for segments we no longer own
+            discardSegments(removedSegments);
 
             // check if any of the existing transfers should be restarted from a different source because the initial source is no longer a member
             Set<Address> members = new HashSet<Address>(cacheTopology.getReadConsistentHash().getMembers());
@@ -230,24 +233,30 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
                      }
                   }
                }
+
+               // exclude those that are already in progress from a valid source
+               addedSegments.removeAll(transfersBySegment.keySet());
             }
          }
 
-         if (addedSegments != null && !addedSegments.isEmpty()) {
+         if (!addedSegments.isEmpty()) {
             addTransfers(addedSegments);  // add transfers for new or restarted segments
          }
       } finally {
-         stateTransferLock.transactionDataReceived(cacheTopology.getTopologyId());
+         stateTransferLock.notifyTransactionDataReceived(cacheTopology.getTopologyId());
 
-         if (activeTopologyUpdates.decrementAndGet() == 0 && !isStateTransferInProgress()) {
+         if (activeTopologyUpdates.decrementAndGet() == 0) {
             notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
          }
       }
    }
 
    private void notifyEndOfTopologyUpdate(int topologyId) {
-      if (rebalanceInProgress.compareAndSet(true, false)) {
-         localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+      if (!isStateTransferInProgress()) {
+         if (rebalanceInProgress.compareAndSet(true, false)) {
+            log.debugf(""Finished receiving of segments for cache %s for topology %d."", cacheName, topologyId);
+            stateTransferManager.notifyEndOfTopologyUpdate(topologyId);
+         }
       }
    }
 
@@ -262,43 +271,42 @@ public void applyState(Address sender, int topologyId, int segmentId, Collection
       //todo [anistor] this check should be based on topologyId
       if (!cacheTopology.getWriteConsistentHash().getSegmentsForOwner(rpcManager.getAddress()).contains(segmentId)) {
          if (trace) {
-            log.warnf(""Discarding received cache entries for segment %d because they do not belong to this node."", segmentId);
+            log.warnf(""Discarding received cache entries for segment %d of cache %s because they do not belong to this node."", segmentId, cacheName);
          }
          return;
       }
 
-      if (cacheEntries != null) {
-         doApplyState(sender, segmentId, cacheEntries);
-      }
-
       // notify the inbound task that a chunk of cache entries was received
       InboundTransferTask inboundTransfer;
       synchronized (this) {
          inboundTransfer = transfersBySegment.get(segmentId);
       }
       if (inboundTransfer != null) {
+         if (cacheEntries != null) {
+            doApplyState(sender, segmentId, cacheEntries);
+         }
+
          inboundTransfer.onStateReceived(segmentId, isLastChunk);
-      } else {
-         log.debugf(""Received unsolicited state for segment %d from node %s"", segmentId, sender);
-         return;
-      }
 
-      if (trace) {
-         log.tracef(""After applying the received state the data container has %d keys"", dataContainer.size());
-         synchronized (this) {
-            log.tracef(""Segments not received yet: %s"", transfersBySource);
+         if (trace) {
+            log.tracef(""After applying the received state the data container of cache %s has %d keys"", cacheName, dataContainer.size());
+            synchronized (this) {
+               log.tracef(""Segments not received yet for cache %s: %s"", cacheName, transfersBySource);
+            }
          }
+      } else {
+         log.warnf(""Received unsolicited state from node %s for segment %d of cache %s"", sender, segmentId, cacheName);
       }
    }
 
    private void doApplyState(Address sender, int segmentId, Collection<InternalCacheEntry> cacheEntries) {
-      log.debugf(""Applying new state for segment %d from %s: received %d cache entries"", segmentId, sender, cacheEntries.size());
+      log.debugf(""Applying new state for segment %d of cache %s from node %s: received %d cache entries"", segmentId, cacheName, sender, cacheEntries.size());
       if (trace) {
          List<Object> keys = new ArrayList<Object>(cacheEntries.size());
          for (InternalCacheEntry e : cacheEntries) {
             keys.add(e.getKey());
          }
-         log.tracef(""Received keys: %s"", keys);
+         log.tracef(""Received keys %s for segment %d of cache %s from node %s"", keys, segmentId, cacheName, sender);
       }
 
       // CACHE_MODE_LOCAL avoids handling by StateTransferInterceptor and any potential locks in StateTransferLock
@@ -316,10 +324,11 @@ private void doApplyState(Address sender, int segmentId, Collection<InternalCach
             log.problemApplyingStateForKey(ex.getMessage(), e.getKey());
          }
       }
+      log.debugf(""Finished applying state for segment %d of cache %s"", segmentId, cacheName);
    }
 
    public void applyTransactions(Address sender, int topologyId, Collection<TransactionInfo> transactions) {
-      log.debugf(""Applying %d transactions transferred from %s"", transactions.size(), sender);
+      log.debugf(""Applying %d transactions for cache %s transferred from node %s"", transactions.size(), cacheName, sender);
       if (configuration.transaction().transactionMode().isTransactional()) {
          for (TransactionInfo transactionInfo : transactions) {
             CacheTransaction tx = transactionTable.getLocalTransaction(transactionInfo.getGlobalTransaction());
@@ -374,30 +383,31 @@ public CacheTopology getCacheTopology() {
    }
 
    private void addTransfers(Set<Integer> segments) {
-      log.debugf(""Adding state transfer for segments: %s"", segments);
+      log.debugf(""Adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
 
       Set<Integer> segmentsToProcess = new HashSet<Integer>(segments);
-      Set<Address> blacklistedSources = new HashSet<Address>();
+      Set<Address> faultysources = new HashSet<Address>();
 
       // ignore all segments for which there are no other owners to pull data from.
       // these segments are considered empty (or lost) and do not require a state transfer
       for (Iterator<Integer> it = segmentsToProcess.iterator(); it.hasNext(); ) {
          Integer segmentId = it.next();
-         Address source = pickSourceOwner(segmentId, blacklistedSources);
+         Address source = pickSourceOwner(segmentId, faultysources);
          if (source == null) {
             it.remove();
          }
       }
 
-      synchronized (this) {
-         // already active transfers do not need to be added again
-         segmentsToProcess.removeAll(transfersBySegment.keySet());
-      }
-
       while (!segmentsToProcess.isEmpty()) {
          Map<Address, Set<Integer>> segmentsBySource = new HashMap<Address, Set<Integer>>();
          for (int segmentId : segmentsToProcess) {
-            Address source = pickSourceOwner(segmentId, blacklistedSources);
+            synchronized (this) {
+               // already active transfers do not need to be added again
+               if (transfersBySegment.containsKey(segmentId)) {
+                  continue;
+               }
+            }
+            Address source = pickSourceOwner(segmentId, faultysources);
             if (source != null) {
                Set<Integer> segmentsFromSource = segmentsBySource.get(source);
                if (segmentsFromSource == null) {
@@ -411,8 +421,14 @@ private void addTransfers(Set<Integer> segments) {
          Set<Integer> failedSegments = new HashSet<Integer>();
          for (Address source : segmentsBySource.keySet()) {
             Set<Integer> segmentsFromSource = segmentsBySource.get(source);
-            InboundTransferTask inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout);
+            InboundTransferTask inboundTransfer;
             synchronized (this) {
+               segmentsFromSource.removeAll(transfersBySegment.keySet());  // already in progress segments are excluded
+               if (segmentsFromSource.isEmpty()) {
+                  continue;
+               }
+
+               inboundTransfer = new InboundTransferTask(segmentsFromSource, source, cacheTopology.getTopologyId(), this, rpcManager, commandsFactory, timeout, cacheName);
                for (int segmentId : segmentsFromSource) {
                   transfersBySegment.put(segmentId, inboundTransfer);
                }
@@ -427,9 +443,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the transactions fails we need to retry from another source
             if (configuration.transaction().transactionMode().isTransactional()) {
                if (!inboundTransfer.requestTransactions()) {
-                  log.errorf(""Failed to retrieve transactions for segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRetrieveTransactionsForSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                   continue;
                }
@@ -438,9 +454,9 @@ private void addTransfers(Set<Integer> segments) {
             // if requesting the segments fails we need to retry from another source
             if (fetchEnabled) {
                if (!inboundTransfer.requestSegments()) {
-                  log.errorf(""Failed to request segments %s from node %s (node will be blacklisted)"", segmentsFromSource, source);
+                  log.failedToRequestSegments(segmentsFromSource, cacheName, source);
                   failedSegments.addAll(segmentsFromSource);
-                  blacklistedSources.add(source);
+                  faultysources.add(source);
                   removeTransfer(inboundTransfer);  // will be retried from another source
                }
             } else {
@@ -450,21 +466,22 @@ private void addTransfers(Set<Integer> segments) {
 
          segmentsToProcess = failedSegments;
       }
+      log.debugf(""Finished adding inbound state transfer for segments %s of cache %s"", segments, cacheName);
    }
 
-   private Address pickSourceOwner(int segmentId, Set<Address> blacklistedSources) {
+   private Address pickSourceOwner(int segmentId, Set<Address> faultySources) {
       List<Address> owners = cacheTopology.getReadConsistentHash().locateOwnersForSegment(segmentId);
       if (owners.size() == 1 && owners.get(0).equals(rpcManager.getAddress())) {
          return null;
       }
 
       for (int i = owners.size() - 1; i >= 0; i--) {   // iterate backwards because we prefer to fetch from newer nodes
          Address o = owners.get(i);
-         if (!o.equals(rpcManager.getAddress()) && !blacklistedSources.contains(o)) {
+         if (!o.equals(rpcManager.getAddress()) && !faultySources.contains(o)) {
             return o;
          }
       }
-      log.errorf(""No live owners found for segment %d. Current owners are:  %s. Blacklisted owners: %s"", segmentId, owners, blacklistedSources);
+      log.noLiveOwnersFoundForSegment(segmentId, cacheName, owners, faultySources);
       return null;
    }
 
@@ -478,9 +495,9 @@ private void discardSegments(Set<Integer> segments) {
          List<Integer> segmentsToCancel = new ArrayList<Integer>(segments);
          while (!segmentsToCancel.isEmpty()) {
             int segmentId = segmentsToCancel.remove(0);
-            log.debugf(""Removing state transfer for segment %d"", segmentId);
             InboundTransferTask inboundTransfer = transfersBySegment.remove(segmentId);
             if (inboundTransfer != null) { // we need to check the transfer was not already completed
+               log.debugf(""Cancelling inbound state transfer for segment %d of cache %s"", segmentId, cacheName);
                Set<Integer> cancelledSegments = new HashSet<Integer>(segmentsToCancel);
                cancelledSegments.retainAll(inboundTransfer.getSegments());
                segmentsToCancel.removeAll(cancelledSegments);
@@ -489,6 +506,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      // gather all keys from data container that belong to the segments that are being removed
       Set<Object> keysToRemove = new HashSet<Object>();
       for (InternalCacheEntry ice : dataContainer) {
          Object key = ice.getKey();
@@ -497,7 +515,7 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
-      // we also remove keys from the cache store
+      // gather all keys from cache store that belong to the segments that are being removed
       CacheStore cacheStore = getCacheStore();
       if (cacheStore != null) {
          //todo [anistor] extend CacheStore interface to be able to specify a filter when loading keys (ie. keys should belong to desired segments)
@@ -514,13 +532,14 @@ private void discardSegments(Set<Integer> segments) {
          }
       }
 
+      log.debugf(""Removing state for segments %s of cache %s"", segments, cacheName);
       if (!keysToRemove.isEmpty()) {
          try {
             InvalidateCommand invalidateCmd = commandsFactory.buildInvalidateFromL1Command(true, EnumSet.of(CACHE_MODE_LOCAL, SKIP_LOCKING), keysToRemove);
             InvocationContext ctx = icc.createNonTxInvocationContext();
             interceptorChain.invoke(ctx, invalidateCmd);
 
-            log.debugf(""Invalidated %d keys, data container now has %d keys"", keysToRemove.size(), dataContainer.size());
+            log.debugf(""Invalidated %d keys, data container of cache %s now has %d keys"", keysToRemove.size(), cacheName, dataContainer.size());
             if (trace) log.tracef(""Invalidated keys: %s"", keysToRemove);
          } catch (CacheException e) {
             log.failedToInvalidateKeys(e);
@@ -553,18 +572,17 @@ private void removeTransfer(InboundTransferTask inboundTransfer) {
                if (transfers.isEmpty()) {
                   transfersBySource.remove(inboundTransfer.getSource());
                }
-               for (int segmentId : inboundTransfer.getSegments()) {
-                  transfersBySegment.remove(segmentId);
-               }
+               transfersBySegment.keySet().removeAll(inboundTransfer.getSegments());
             }
          }
       }
    }
 
    void onTaskCompletion(InboundTransferTask inboundTransfer) {
+      log.tracef(""Completion of inbound transfer task: %s "", inboundTransfer);
       removeTransfer(inboundTransfer);
 
-      if (activeTopologyUpdates.get() == 0 && !isStateTransferInProgress()) {
+      if (activeTopologyUpdates.get() == 0) {
          notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
       }
    }",2012-11-07T14:07:34Z,54
"@@ -52,7 +52,7 @@
 import static org.infinispan.factories.KnownComponentNames.ASYNC_TRANSPORT_EXECUTOR;
 
 /**
- * // TODO [anistor] Document this
+ * {@link StateProvider} implementation.
  *
  * @author anistor@redhat.com
  * @since 5.2
@@ -90,7 +90,7 @@ public StateProviderImpl() {
 
    @Inject
    public void init(Cache cache,
-                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //todo [anistor] use a separate ExecutorService
+                    @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService executorService, //TODO Use a dedicated ExecutorService
                     Configuration configuration,
                     RpcManager rpcManager,
                     CommandsFactory commandsFactory,
@@ -184,7 +184,7 @@ public void stop() {
 
    public List<TransactionInfo> getTransactionsForSegments(Address destination, int requestTopologyId, Set<Integer> segments) throws InterruptedException {
       if (trace) {
-         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, requestTopologyId);
+         log.tracef(""Received request for transactions from node %s for segments %s of cache %s with topology id %d"", destination, segments, cacheName, requestTopologyId);
       }
 
       if (readCh == null) {
@@ -262,8 +262,8 @@ public void startOutboundTransfer(Address destination, int requestTopologyId, Se
       }
 
       // the destination node must already have an InboundTransferTask waiting for these segments
-      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, requestTopologyId,
-            readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
+      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId,
+            readCh, this, dataContainer, cacheLoaderManager, rpcManager, commandsFactory, timeout, cacheName);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);
    }
@@ -294,7 +294,7 @@ public void cancelOutboundTransfer(Address destination, int topologyId, Set<Inte
             // get an array copy of the collection to avoid ConcurrentModificationException if the entire task gets cancelled and removeTransfer(transferTask) is called
             OutboundTransferTask[] tasks = transferTasks.toArray(new OutboundTransferTask[transferTasks.size()]);
             for (OutboundTransferTask transferTask : tasks) {
-               transferTask.cancelSegments(segments); //this can potentially result in a removeTransfer(transferTask)
+               transferTask.cancelSegments(segments); //this can potentially result in a call to removeTransfer(transferTask)
             }
          }
       }",2012-11-07T14:07:34Z,55
"@@ -36,16 +36,13 @@
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
-import org.infinispan.remoting.rpc.RpcManager;
-import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
 import java.util.Set;
 
 //todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
@@ -75,7 +72,7 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager,
+   public void init(StateTransferLock stateTransferLock, Configuration configuration,
                     CommandsFactory commandFactory, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
       this.commandFactory = commandFactory;",2012-11-07T14:07:34Z,115
"@@ -58,13 +58,13 @@ public interface StateTransferLock {
    void releaseSharedTopologyLock();
 
    // transaction data latch
-   void transactionDataReceived(int topologyId);
+   void notifyTransactionDataReceived(int topologyId);
 
    void waitForTransactionData(int expectedTopologyId) throws InterruptedException;
 
    // topology installation latch
    // TODO move this to Cluster/LocalTopologyManagerImpl and don't start requesting state until every node has the jgroups view with the local node
-   void topologyInstalled(int topologyId);
+   void notifyTopologyInstalled(int topologyId);
 
    void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-11-07T14:07:34Z,122
"@@ -23,12 +23,12 @@
 
 package org.infinispan.statetransfer;
 
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
+
 /**
  * {@code StateTransferLock} implementation.
  *
@@ -38,6 +38,7 @@
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
+   private static final boolean trace = log.isTraceEnabled();
 
    private final ReadWriteLock ownershipLock = new ReentrantReadWriteLock();
 
@@ -68,8 +69,15 @@ public void releaseSharedTopologyLock() {
    }
 
    @Override
-   public void transactionDataReceived(int topologyId) {
-      this.transactionDataTopologyId = topologyId;
+   public void notifyTransactionDataReceived(int topologyId) {
+      if (topologyId < transactionDataTopologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + transactionDataTopologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling transaction data received for topology %d"", topologyId);
+      }
+      transactionDataTopologyId = topologyId;
       synchronized (transactionDataLock) {
          transactionDataLock.notifyAll();
       }
@@ -80,19 +88,32 @@ public void waitForTransactionData(int expectedTopologyId) throws InterruptedExc
       if (transactionDataTopologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
-            transactionDataTopologyId);
+      if (trace) {
+         log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
+               transactionDataTopologyId);
+      }
       synchronized (transactionDataLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (transactionDataTopologyId < expectedTopologyId) {
             transactionDataLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Received transaction data for topology %d, expected topology was %d"", transactionDataTopologyId,
+               expectedTopologyId);
+      }
    }
 
    @Override
-   public void topologyInstalled(int topologyId) {
+   public void notifyTopologyInstalled(int topologyId) {
+      if (topologyId < this.topologyId) {
+         throw new IllegalStateException(""Cannot set a topology id ("" + topologyId +
+               "") that is lower that the current one ("" + this.topologyId + "")"");
+      }
+      if (trace) {
+         log.tracef(""Signalling topology %d is installed"", topologyId);
+      }
       this.topologyId = topologyId;
       synchronized (topologyLock) {
          topologyLock.notifyAll();
@@ -104,14 +125,18 @@ public void waitForTopology(int expectedTopologyId) throws InterruptedException
       if (topologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId,
-            topologyId);
+      if (trace) {
+         log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId, topologyId);
+      }
       synchronized (topologyLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()
          while (topologyId < expectedTopologyId) {
             topologyLock.wait();
          }
       }
+      if (trace) {
+         log.tracef(""Topology %d is now installed, expected topology was %d"", topologyId, expectedTopologyId);
+      }
    }
 }",2012-11-07T14:07:34Z,123
"@@ -81,4 +81,5 @@ public interface StateTransferManager {
     */
    void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object> affectedKeys, boolean sync);
 
+   void notifyEndOfTopologyUpdate(int topologyId);
 }",2012-11-07T14:07:34Z,116
"@@ -70,7 +70,7 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private GroupManager groupManager;   // optional
    private LocalTopologyManager localTopologyManager;
 
-   private CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
+   private final CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
 
    public StateTransferManagerImpl() {
    }
@@ -170,13 +170,18 @@ private CacheTopology addGrouping(CacheTopology cacheTopology) {
 
    private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalance) {
       if (trace) {
-         log.tracef(""Installing new cache topology %s"", newCacheTopology);
+         log.tracef(""Installing new cache topology %s on cache %s"", newCacheTopology, cacheName);
       }
 
       // handle grouping
       newCacheTopology = addGrouping(newCacheTopology);
 
       CacheTopology oldCacheTopology = stateConsumer.getCacheTopology();
+
+      if (oldCacheTopology != null && oldCacheTopology.getTopologyId() > newCacheTopology.getTopologyId()) {
+         throw new IllegalStateException(""Old topology is higher: old="" + oldCacheTopology + "", new="" + newCacheTopology);
+      }
+
       ConsistentHash oldCH = oldCacheTopology != null ? oldCacheTopology.getWriteConsistentHash() : null;
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
@@ -188,15 +193,17 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
 
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
-      if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
+      boolean isJoined = stateConsumer.getCacheTopology().getReadConsistentHash().getMembers().contains(rpcManager.getAddress());
+      if (initialStateTransferComplete.getCount() > 0 && isJoined) {
          initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
    }
 
    @Start(priority = 1000)
    @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
-      if (trace) log.tracef(""Waiting for initial state transfer to finish"");
+      if (trace) log.tracef(""Waiting for initial state transfer to finish for cache %s on %s"", cacheName, rpcManager.getAddress());
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);
       if (!success) {
          throw new CacheException(String.format(""Initial state transfer timed out for cache %s on %s"",
@@ -210,6 +217,7 @@ public void stop() {
       if (trace) {
          log.tracef(""Shutting down StateTransferManager of cache %s on node %s"", cacheName, rpcManager.getAddress());
       }
+      initialStateTransferComplete.countDown();
       localTopologyManager.leave(cacheName);
    }
 
@@ -268,4 +276,14 @@ public void forwardCommandIfNeeded(TopologyAffectedCommand command, Set<Object>
          }
       }
    }
+
+   @Override
+   public void notifyEndOfTopologyUpdate(int topologyId) {
+      if (initialStateTransferComplete.getCount() > 0
+            && stateConsumer.getCacheTopology().getWriteConsistentHash().getMembers().contains(rpcManager.getAddress())) {
+         initialStateTransferComplete.countDown();
+         log.tracef(""Initial state transfer complete for cache %s on node %s"", cacheName, rpcManager.getAddress());
+      }
+      localTopologyManager.confirmRebalance(cacheName, topologyId, null);
+   }
 }
\ No newline at end of file",2012-11-07T14:07:34Z,117
"@@ -126,13 +126,17 @@ public void triggerRebalance(final String cacheName) throws Exception {
       asyncTransportExecutor.submit(new Callable<Object>() {
          @Override
          public Object call() throws Exception {
-            startRebalance(cacheName);
-            return null;
+            try {
+               startRebalance(cacheName);
+               return null;
+            } catch (Throwable t) {
+               log.errorf(t, ""Failed to start rebalance: %s"", t.getMessage());
+               throw new Exception(t);
+            }
          }
       });
    }
 
-
    @Override
    public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo joinInfo, int viewId) throws Exception {
       waitForView(viewId);
@@ -594,6 +598,7 @@ public Object call() throws Exception {
             try {
                return command.perform(null);
             } catch (Throwable t) {
+               log.errorf(t, ""Failed to execute ReplicableCommand %s on cluster async: %s"", command, t.getMessage());
                throw new Exception(t);
             }
          }",2012-11-07T14:07:34Z,124
"@@ -280,6 +280,7 @@ public Object call() throws Exception {
                try {
                   return command.perform(null);
                } catch (Throwable t) {
+                  log.errorf(t, ""Failed to execute ReplicableCommand %s on coordinator async: %s"", command, t.getMessage());
                   throw new Exception(t);
                }
             }
@@ -298,8 +299,6 @@ class LocalCacheStatus {
    private final CacheTopologyHandler handler;
    private volatile CacheTopology topology;
 
-   private boolean joined;
-
    public LocalCacheStatus(CacheJoinInfo joinInfo, CacheTopologyHandler handler) {
       this.joinInfo = joinInfo;
       this.handler = handler;
@@ -320,12 +319,4 @@ public CacheTopology getTopology() {
    public void setTopology(CacheTopology topology) {
       this.topology = topology;
    }
-
-   public boolean isJoined() {
-      return joined;
-   }
-
-   public void setJoined(boolean joined) {
-      this.joined = joined;
-   }
 }",2012-11-07T14:07:34Z,125
"@@ -53,15 +53,14 @@ public class StaleTransactionCleanupService {
 
    private static Log log = LogFactory.getLog(StaleTransactionCleanupService.class);
 
+   private ScheduledExecutorService executorService;
 
    private TransactionTable transactionTable;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
-   private ScheduledExecutorService executorService;
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * because the main data owner left. Also unlocks keys for which the lock owner has changed as a result of a topology change.
@@ -71,15 +70,19 @@ public StaleTransactionCleanupService(TransactionTable transactionTable) {
    @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // Roll back remote transactions originating on nodes that have left the cluster.
-      if (tce.isPre()) {
-         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
-         if (consistentHashAtStart != null) {
-            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
-            if (!leavers.isEmpty()) {
-               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-               cleanTxForWhichTheOwnerLeft(leavers);
+      try {
+         if (tce.isPre()) {
+            ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+            if (consistentHashAtStart != null) {
+               List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+               if (!leavers.isEmpty()) {
+                  log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+                  cleanTxForWhichTheOwnerLeft(leavers);
+               }
             }
          }
+      } catch (Exception e) {
+         log.error(""Failed to process topology update"", e);
       }
    }
 
@@ -120,7 +123,6 @@ public void run() {
             transactionTable.cleanupCompletedTransactions();
          }
       }, interval, interval, TimeUnit.MILLISECONDS);
-
    }
 
    public void stop() {",2012-11-07T14:07:34Z,126
"@@ -523,25 +523,29 @@ public boolean isTransactionCompleted(GlobalTransaction gtx) {
    }
 
    public void cleanupCompletedTransactions() {
-      log.debugf(""About to cleanup completed transaction. Initial size is %s"", completedTransactions.size());
-      //this iterator is weekly consistent and will never throw ConcurrentModificationException
-      Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
-      long timeout = configuration.transaction().completedTxTimeout();
-
-      int removedEntries = 0;
-      long beginning = System.nanoTime();
-      while (iterator.hasNext()) {
-         Map.Entry<GlobalTransaction, Long> e = iterator.next();
-         long ageNanos = System.nanoTime() - e.getValue();
-         if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
-            iterator.remove();
-            removedEntries++;
+      try {
+         log.debugf(""About to cleanup completed transaction. Initial size is %d"", completedTransactions.size());
+         //this iterator is weekly consistent and will never throw ConcurrentModificationException
+         Iterator<Map.Entry<GlobalTransaction, Long>> iterator = completedTransactions.entrySet().iterator();
+         long timeout = configuration.transaction().completedTxTimeout();
+
+         int removedEntries = 0;
+         long beginning = System.nanoTime();
+         while (iterator.hasNext()) {
+            Map.Entry<GlobalTransaction, Long> e = iterator.next();
+            long ageNanos = System.nanoTime() - e.getValue();
+            if (TimeUnit.NANOSECONDS.toMillis(ageNanos) >= timeout) {
+               iterator.remove();
+               removedEntries++;
+            }
          }
-      }
-      long duration = System.nanoTime() - beginning;
+         long duration = System.nanoTime() - beginning;
 
-      log.debugf(""Finished cleaning up completed transactions. %s transactions were removed, total duration was %s millis, "" +
-                      ""current number of completed transactions is %"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
-                 completedTransactions.size());
+         log.debugf(""Finished cleaning up completed transactions. %d transactions were removed, total duration was %d millis, "" +
+                         ""current number of completed transactions is %d"", removedEntries, TimeUnit.NANOSECONDS.toMillis(duration),
+                    completedTransactions.size());
+      } catch (Exception e) {
+         log.errorf(e, ""Failed to cleanup completed transactions: %s"", e.getMessage());
+      }
    }
 }",2012-11-07T14:07:34Z,127
"@@ -24,9 +24,7 @@
 
 import org.infinispan.CacheException;
 import org.infinispan.commands.ReplicableCommand;
-import org.infinispan.commands.remote.CacheRpcCommand;
 import org.infinispan.commands.tx.PrepareCommand;
-import org.infinispan.commands.write.WriteCommand;
 import org.infinispan.loaders.CacheLoaderException;
 import org.infinispan.loaders.bucket.Bucket;
 import org.infinispan.loaders.decorators.SingletonStore;
@@ -60,7 +58,6 @@
 import java.util.List;
 import java.util.Map;
 import java.util.UUID;
-import java.util.concurrent.ExecutionException;
 
 import static org.jboss.logging.Logger.Level.*;
 
@@ -131,26 +128,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Can not select %s random members for %s"", id = 8)
    void cannotSelectRandomMembers(int numNeeded, List<Address> members);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Detected a view change. Member list changed from %s to %s"", id = 9)
-   void viewChangeDetected(List<Address> oldMembers, List<Address> newMembers);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a JOIN event! Wait for notification from new joiner %s"", id = 10)
-   void joinEvent(Address joiner);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""This is a LEAVE event! Node %s has just left"", id = 11)
-   void leaveEvent(Address leaver);
-
-   @LogMessage(level = FATAL)
-   @Message(value = ""Unable to process leaver!!"", id = 12)
-   void unableToProcessLeaver(@Cause Exception e);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""I %s am participating in rehash, state providers %s, state receivers %s"", id = 13)
-   void participatingInRehash(Address address, List<Address> stateProviders, List<Address> receiversOfLeaverState);
-
    @LogMessage(level = INFO)
    @Message(value = ""DistributionManager not yet joined the cluster. Cannot do anything about other concurrent joiners."", id = 14)
    void distributionManagerNotJoined();
@@ -163,10 +140,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Problem %s encountered when applying state for key %s!"", id = 16)
    void problemApplyingStateForKey(String msg, Object key);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""View change interrupted; not rehashing!"", id = 17)
-   void viewChangeInterrupted();
-
    @LogMessage(level = WARN)
    @Message(value = ""Unable to apply prepare %s"", id = 18)
    void unableToApplyPrepare(PrepareCommand pc, @Cause Throwable t);
@@ -175,26 +148,10 @@ public interface Log extends BasicLogger {
    @Message(value = ""Couldn't acquire shared lock"", id = 19)
    void couldNotAcquireSharedLock();
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Caught exception replaying %s"", id = 20)
-   void exceptionWhenReplaying(WriteCommand cmd, @Cause Exception e);
-
    @LogMessage(level = WARN)
    @Message(value = ""Expected just one response; got %s"", id = 21)
    void expectedJustOneResponse(Map<Address, Response> lr);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Completed leave rehash on node %s in %s - leavers now are %s"", id = 22)
-   void completedLeaveRehash(Address self, String duration, List<Address> leavers);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error pushing tx log"", id = 23)
-   void errorPushingTxLog(@Cause ExecutionException e);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Unable to stop transaction logging!"", id = 24)
-   void unableToStopTransactionLogging(@Cause IllegalMonitorStateException imse);
-
    @LogMessage(level = INFO)
    @Message(value = ""wakeUpInterval is <= 0, not starting expired purge thread"", id = 25)
    void notStartingEvictionThread();
@@ -211,7 +168,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unable to passivate entry under %s"", id = 28)
    void unableToPassivateEntry(Object key, @Cause Exception e);
 
-
    @LogMessage(level = INFO)
    @Message(value = ""Passivating all entries to disk"", id = 29)
    void passivatingAllEntries();
@@ -296,14 +252,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Interrupted or timeout while waiting for AsyncStore worker threads to push all state to the decorated store"", id = 48)
    void interruptedWaitingAsyncStorePush(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing clear in async store"", id = 49)
-   void errorClearinAsyncStore(@Cause CacheLoaderException e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error performing purging expired from async store"", id = 50)
-   void errorPurgingAsyncStore(@Cause CacheLoaderException e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Unexpected error"", id = 51)
    void unexpectedErrorInAsyncProcessor(@Cause Throwable t);
@@ -376,14 +324,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Cache named %s does not exist on this cache manager!"", id = 68)
    void namedCacheDoesNotExist(String cacheName);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Cache named [%s] exists but isn't in a state to handle remote invocations"", id = 69)
-   void cacheCanNotHandleInvocations(String cacheName);
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Quietly ignoring clustered get call %s since unable to acquire processing lock, even after %s"", id = 70)
-   void ignoreClusterGetCall(CacheRpcCommand cmd, String time);
-
    @LogMessage(level = WARN)
    @Message(value = ""Caught exception when handling command %s"", id = 71)
    void exceptionHandlingCommand(ReplicableCommand cmd, @Cause Throwable t);
@@ -396,18 +336,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Unexpected error while replicating"", id = 73)
    void unexpectedErrorReplicating(@Cause Throwable t);
 
-   @LogMessage(level = INFO)
-   @Message(value = ""Trying to fetch state from %s"", id = 74)
-   void tryingToFetchState(Address member);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Could not find available peer for state, backing off and retrying"", id = 75)
-   void couldNotFindPeerForState();
-
-   @LogMessage(level = INFO)
-   @Message(value = ""Successfully retrieved and applied state from %s"", id = 76)
-   void successfullyAppliedState(Address member);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Message or message buffer is null or empty."", id = 77)
    void msgOrMsgBufferEmpty();
@@ -461,15 +389,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""getCoordinator(): Interrupted while waiting for members to be set"", id = 89)
    void interruptedWaitingForCoordinator(@Cause InterruptedException e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Unable to retrieve state from member %s"", id = 90)
-   void unableToRetrieveState(Address member, @Cause Exception e);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Channel does not contain STREAMING_STATE_TRANSFER. "" +
-         ""Cannot support state transfers!"", id = 91)
-   void streamingStateTransferNotPresent();
-
    @LogMessage(level = WARN)
    @Message(value = ""Channel not set up properly!"", id = 92)
    void channelNotSetUp();
@@ -482,10 +401,6 @@ public interface Log extends BasicLogger {
    @Message(value = ""Received new cluster view: %s"", id = 94)
    void receivedClusterView(View newView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Caught while requesting or applying state"", id = 96)
-   void errorRequestingOrApplyingState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error while processing a prepare in a single-phase transaction"", id = 97)
    void errorProcessing1pcPrepareCommand(@Cause Throwable e);
@@ -688,14 +603,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Failed loading value for key %s from cache store"", id = 144)
    void failedLoadingValueFromCacheStore(Object key, @Cause Exception e);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error during rehash"", id = 145)
-   void errorDuringRehash(@Cause Throwable th);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error transferring state to node after rehash"", id = 146)
-   void errorTransferringState(@Cause Exception e);
-
    @LogMessage(level = ERROR)
    @Message(value = ""Error invalidating keys from L1 after rehash"", id = 147)
    void failedToInvalidateKeys(@Cause Exception e);
@@ -729,14 +636,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Unable to unlock keys %2$s for transaction %1$s after they were rebalanced off node %3$s"", id = 154)
    void unableToUnlockRebalancedKeys(GlobalTransaction gtx, List<Object> keys, Address self, @Cause Throwable t);
 
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm pushing data for view %d, received confirmations %s. Cancelling state transfer"", id = 157)
-   void stateTransferTimeoutWaitingForPushConfirmations(int viewId, Map<Address, Integer> pushConfirmations);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Timed out waiting for all cluster members to confirm joining for view %d, joined %s. Cancelling state transfer"", id = 158)
-   void stateTransferTimeoutWaitingForJoinConfirmations(int viewId, Map<Address, Integer> joinConfirmations);
-
    @LogMessage(level = WARN)
    @Message(value = ""Unblocking transactions failed"", id = 159)
    void errorUnblockingTransactions(@Cause Exception e);
@@ -761,26 +660,6 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @Message(value = ""Rolling back to cache view %d, but last committed view is %d"", id = 164)
    void cacheViewRollbackIdMismatch(int committedViewId, int committedView);
 
-   @LogMessage(level = ERROR)
-   @Message(value = ""Error triggering a view installation for cache %s"", id = 165)
-   void errorTriggeringViewInstallation(@Cause RuntimeException e, String cacheName);
-
-   @LogMessage(level = ERROR)
-   @Message(value = ""View installation failed for cache %s"", id = 166)
-   void viewInstallationFailure(@Cause Throwable e, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Rejecting state pushed by node %s for view %d, there is no state transfer in progress (we are at view %d)"", id = 167)
-   void remoteStateRejected(Address sender, int viewId, int installedViewId);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error rolling back to cache view %1$d for cache %2$s"", id = 168)
-   void cacheViewRollbackFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
-   @LogMessage(level = WARN)
-   @Message(value = ""Error committing cache view %1$d for cache %2$s"", id = 169)
-   void cacheViewCommitFailure(@Cause Throwable t, int committedViewId, String cacheName);
-
    @LogMessage(level = INFO)
    @Message(value = ""Strict peer-to-peer is enabled but the JGroups channel was started externally - this is very likely to result in RPC timeout errors on startup"", id = 171)
    void warnStrictPeerToPeerWithInjectedChannel();
@@ -926,5 +805,16 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    @LogMessage(level = WARN)
    @Message(value = ""Could not interrupt as no thread found for command uuid %s"", id=207)
    void couldNotInterruptThread(UUID id);
-   
+
+   @LogMessage(level = ERROR)
+   @Message(value = ""No live owners found for segment %d of cache %s. Current owners are:  %s. Faulty owners: %s"", id=208)
+   void noLiveOwnersFoundForSegment(int segmentId, String cacheName, Collection<Address> owners, Collection<Address> faultySources);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to retrieve transactions for segments %s of cache %s from node %s (node will not be retried)"", id=209)
+   void failedToRetrieveTransactionsForSegments(Collection<Integer> segments, String cacheName, Address source);
+
+   @LogMessage(level = WARN)
+   @Message(value = ""Failed to request segments %s of cache %s from node %s (node will not be retried)"", id=210)
+   void failedToRequestSegments(Collection<Integer> segments, String cacheName, Address source);
 }",2012-11-07T14:07:34Z,45
"@@ -263,7 +263,7 @@ private void assertNamedCacheFile(EmbeddedCacheManager cm, boolean deprecated) {
 
       assert gc.asyncTransportExecutor().factory() instanceof DefaultExecutorFactory;
       // Should be 25, but it's overriden by the test cache manager factory
-      assertEquals(""4"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
+      assertEquals(""6"", gc.asyncTransportExecutor().properties().getProperty(""maxThreads""));
       assert gc.asyncTransportExecutor().properties().getProperty(""threadNamePrefix"").equals(""AsyncSerializationThread"");
 
       assert gc.evictionScheduledExecutor().factory() instanceof DefaultScheduledExecutorFactory;",2012-11-07T14:07:34Z,128
"@@ -50,7 +50,6 @@
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.topology.CacheTopology;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.TransactionTable;
@@ -126,7 +125,7 @@ public void test1() throws Exception {
       when(cache.getName()).thenReturn(""testCache"");
 
       StateProvider stateProvider = mock(StateProvider.class);
-      LocalTopologyManager localTopologyManager = mock(LocalTopologyManager.class);
+      StateTransferManager stateTransferManager = mock(StateTransferManager.class);
       CacheNotifier cacheNotifier = mock(CacheNotifier.class);
       ExecutorService mockExecutorService = mock(ExecutorService.class);
       RpcManager rpcManager = mock(RpcManager.class);
@@ -183,7 +182,7 @@ public Map<Address, Response> answer(InvocationOnMock invocation) {
 
       // create state provider
       StateConsumerImpl stateConsumer = new StateConsumerImpl();
-      stateConsumer.init(cache, localTopologyManager, interceptorChain, icc, configuration, rpcManager,
+      stateConsumer.init(cache, stateTransferManager, interceptorChain, icc, configuration, rpcManager,
             commandsFactory, cacheLoaderManager, dataContainer, transactionTable, stateTransferLock);
       stateConsumer.start();
 ",2012-11-07T14:07:34Z,56
"@@ -40,6 +40,7 @@
 
 /**
  * Test if state transfer happens properly on a cache with pessimistic transactions.
+ * See https://issues.jboss.org/browse/ISPN-2408.
  *
  * @since 5.2
  */",2012-11-07T14:07:34Z,129
"@@ -75,6 +75,8 @@
  */
 public class TestCacheManagerFactory {
 
+   private static final int MAX_ASYNC_EXEC_THREADS = 6;
+
    public static final String MARSHALLER = LegacyKeySupportSystemProperties.getProperty(""infinispan.test.marshaller.class"", ""infinispan.marshaller.class"");
    private static final Log log = LogFactory.getLog(TestCacheManagerFactory.class);
 
@@ -523,12 +525,12 @@ private static void checkTestName(String fullTestName) {
 
    public static void minimizeThreads(GlobalConfiguration gc) {
       Properties p = new Properties();
-      p.setProperty(""maxThreads"", ""4"");
+      p.setProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
       gc.setAsyncTransportExecutorProperties(p);
    }
 
    public static void minimizeThreads(GlobalConfigurationBuilder builder) {
-      builder.asyncTransportExecutor().addProperty(""maxThreads"", ""4"");
+      builder.asyncTransportExecutor().addProperty(""maxThreads"", String.valueOf(MAX_ASYNC_EXEC_THREADS));
    }
 
    public static void amendMarshaller(GlobalConfiguration configuration) {",2012-11-07T14:07:34Z,130
"@@ -161,13 +161,12 @@ public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo
       waitForView(viewId);
 
       rebalancePolicy.initCache(cacheName, joinInfo);
-      rebalancePolicy.updateMembersList(cacheName, Collections.singletonList(joiner), Collections.<Address>emptyList());
-      return rebalancePolicy.getTopology(cacheName);
+      return rebalancePolicy.addJoiners(cacheName, Collections.singletonList(joiner));
    }
 
    @Override
    public void handleLeave(String cacheName, Address leaver, int viewId) throws Exception {
-      rebalancePolicy.updateMembersList(cacheName, Collections.<Address>emptyList(), Collections.singletonList(leaver));
+      rebalancePolicy.removeLeavers(cacheName, Collections.singletonList(leaver));
    }
 
    @Override",2012-08-31T21:05:51Z,124
"@@ -110,18 +110,26 @@ public void initCache(String cacheName, List<CacheTopology> partitionTopologies)
 
       synchronized (cacheStatus) {
          CacheTopology cacheTopology = new CacheTopology(unionTopologyId, currentCHUnion, pendingCHUnion);
-         updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+         updateConsistentHash(cacheName, cacheStatus, cacheTopology, true);
          // TODO Trigger a new rebalance
       }
    }
 
    /**
     * Should only be called while holding the cacheStatus lock
     */
-   private void updateConsistentHash(String cacheName, CacheStatus cacheStatus, CacheTopology cacheTopology) throws Exception {
+   private void updateConsistentHash(String cacheName, CacheStatus cacheStatus, CacheTopology cacheTopology,
+                                     boolean broadcast) throws Exception {
       log.tracef(""Updating cache %s topology: %s"", cacheName, cacheTopology);
       cacheStatus.setCacheTopology(cacheTopology);
-      clusterTopologyManager.updateConsistentHash(cacheName, cacheStatus.getCacheTopology());
+      ConsistentHash currentCH = cacheTopology.getCurrentCH();
+      if (currentCH != null) {
+         cacheStatus.getJoiners().removeAll(currentCH.getMembers());
+         log.tracef(""Updated joiners list for cache %s: %s"", cacheName, cacheStatus.getJoiners());
+      }
+      if (broadcast) {
+         clusterTopologyManager.updateConsistentHash(cacheName, cacheStatus.getCacheTopology());
+      }
    }
 
    @Override
@@ -142,30 +150,9 @@ public void updateMembersList(List<Address> newClusterMembers) throws Exception
             boolean currentMembersValid = newClusterMembers.containsAll(currentCH.getMembers());
             boolean pendingMembersValid = pendingCH == null || newClusterMembers.containsAll(pendingCH.getMembers());
             if (!currentMembersValid || !pendingMembersValid) {
-               int topologyId = cacheStatus.getCacheTopology().getTopologyId();
-               ConsistentHashFactory consistentHashFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
-
                List<Address> newCurrentMembers = new ArrayList<Address>(currentCH.getMembers());
                newCurrentMembers.retainAll(newClusterMembers);
-               if (newCurrentMembers.isEmpty()) {
-                  log.tracef(""Zero members remaining for cache %s"", cacheName);
-                  return;
-               }
-               ConsistentHash newCurrentCH = consistentHashFactory.updateMembers(currentCH, newCurrentMembers);
-
-               ConsistentHash newPendingCH = null;
-               if (pendingCH != null) {
-                  List<Address> newPendingMembers = new ArrayList<Address>(cacheStatus.getCacheTopology().getMembers());
-                  newPendingMembers.retainAll(newClusterMembers);
-                  if (newPendingMembers.isEmpty()) {
-                     log.tracef(""Zero members remaining for cache %s"", cacheName);
-                     return;
-                  }
-                  newPendingCH = consistentHashFactory.updateMembers(pendingCH, newPendingMembers);
-               }
-
-               CacheTopology cacheTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
-               updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+               updateCacheMembers(cacheName, cacheStatus, newCurrentMembers);
             }
 
             if (!isBalanced(cacheStatus.getCacheTopology().getCurrentCH()) || !cacheStatus.getJoiners().isEmpty()) {
@@ -179,62 +166,80 @@ public void updateMembersList(List<Address> newClusterMembers) throws Exception
    }
 
    @Override
-   public void updateMembersList(String cacheName, List<Address> joiners, List<Address> leavers) throws Exception {
-      // TODO Separate into two methods, join() and leave()
+   public CacheTopology addJoiners(String cacheName, List<Address> joiners) throws Exception {
       CacheStatus cacheStatus = cacheStatusMap.get(cacheName);
       if (cacheStatus == null) {
          log.tracef(""Ignoring members update for cache %s, as we haven't initialized it yet"", cacheName);
-         return;
+         return null;
       }
 
-      CacheJoinInfo joinInfo = cacheStatus.getJoinInfo();
-      if (!leavers.isEmpty()) {
-         synchronized (cacheStatus) {
-            int topologyId = cacheStatus.getCacheTopology().getTopologyId();
-            ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
-            ConsistentHash pendingCH = cacheStatus.getCacheTopology().getPendingCH();
-
-            // The list of ""current"" members will always be included in the set of ""pending"" members,
-            // because leaves are reflected at the same time in both collections
-            List<Address> newMembers = new ArrayList<Address>(clusterMembers);
-            newMembers.removeAll(leavers);
+      synchronized (cacheStatus) {
+         addUniqueJoiners(cacheStatus.getJoiners(), joiners);
 
-            ConsistentHash newPendingCH = null;
-            if (pendingCH != null) {
-               newMembers.retainAll(pendingCH.getMembers());
-               if (newMembers.isEmpty()) {
-                  log.tracef(""Zero members remaining for cache %s"", cacheName);
-                  return;
-               }
+         ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
+         if (currentCH == null) {
+            installInitialTopology(cacheName, cacheStatus);
+         } else {
+            triggerRebalance(cacheName, cacheStatus);
+         }
+         return cacheStatus.getCacheTopology();
+      }
+   }
 
-               newPendingCH = joinInfo.getConsistentHashFactory().updateMembers(pendingCH, newMembers);
-            }
+   @Override
+   public void removeLeavers(String cacheName, List<Address> leavers) throws Exception {
+      CacheStatus cacheStatus = cacheStatusMap.get(cacheName);
+      if (cacheStatus == null) {
+         log.tracef(""Ignoring members update for cache %s, as we haven't initialized it yet"", cacheName);
+         return;
+      }
 
-            newMembers.retainAll(currentCH.getMembers());
-            if (newMembers.isEmpty()) {
-               log.tracef(""Zero members remaining for cache %s"", cacheName);
-               return;
-            }
-            ConsistentHash newCurrentCH = joinInfo.getConsistentHashFactory().updateMembers(currentCH, newMembers);
+      synchronized (cacheStatus) {
+         // The list of ""current"" members will always be included in the set of ""pending"" members,
+         // because leaves are reflected at the same time in both collections
+         List<Address> newMembers = new ArrayList<Address>(clusterMembers);
+         newMembers.removeAll(leavers);
 
-            CacheTopology cacheTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
-            updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+         updateCacheMembers(cacheName, cacheStatus, newMembers);
+      }
+   }
 
-            triggerRebalance(cacheName, cacheStatus);
+   private void updateCacheMembers(String cacheName, CacheStatus cacheStatus, List<Address> newMembers)
+         throws Exception {
+      CacheJoinInfo joinInfo = cacheStatus.getJoinInfo();
+      int topologyId = cacheStatus.getCacheTopology().getTopologyId();
+      ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
+      ConsistentHash pendingCH = cacheStatus.getCacheTopology().getPendingCH();
+
+      ConsistentHash newPendingCH = null;
+      if (pendingCH != null) {
+         newMembers.retainAll(pendingCH.getMembers());
+         if (!newMembers.isEmpty()) {
+            newPendingCH = joinInfo.getConsistentHashFactory().updateMembers(pendingCH, newMembers);
+         } else {
+            log.tracef(""Zero new members remaining for cache %s"", cacheName);
          }
       }
 
-      if (!joiners.isEmpty()) {
-         synchronized (cacheStatus) {
-            addUniqueJoiners(cacheStatus.getJoiners(), joiners);
+      newMembers.retainAll(currentCH.getMembers());
+      ConsistentHash newCurrentCH;
+      if (!newMembers.isEmpty()) {
+         newCurrentCH = joinInfo.getConsistentHashFactory().updateMembers(currentCH, newMembers);
+      } else {
+         log.tracef(""Zero old members remaining for cache %s"", cacheName);
+         // use the new pending CH, it might be non-null if we have joiners
+         newCurrentCH = newPendingCH;
+      }
 
-            ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
-            if (currentCH == null) {
-               installInitialTopology(cacheName, cacheStatus);
-            } else {
-               triggerRebalance(cacheName, cacheStatus);
-            }
-         }
+      boolean hasMembers = newCurrentCH != null;
+      CacheTopology cacheTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
+
+      // Don't broadcast a cache topology when we don't have any members left
+      updateConsistentHash(cacheName, cacheStatus, cacheTopology, hasMembers);
+
+      // Don't trigger a rebalance without any members either
+      if (hasMembers) {
+         triggerRebalance(cacheName, cacheStatus);
       }
    }
 
@@ -247,7 +252,7 @@ private void installInitialTopology(String cacheName, CacheStatus cacheStatus) t
       CacheTopology cacheTopology = new CacheTopology(newTopologyId, balancedCH, null);
 
       log.tracef(""Installing initial topology for cache %s: %s"", cacheName, cacheTopology);
-      updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+      updateConsistentHash(cacheName, cacheStatus, cacheTopology, false);
    }
 
    private void addUniqueJoiners(List<Address> members, List<Address> joiners) {
@@ -269,33 +274,49 @@ public Object call() throws Exception {
    }
 
    private void doRebalance(String cacheName, CacheStatus cacheStatus) throws Exception {
+      CacheTopology cacheTopology = cacheStatus.getCacheTopology();
+      CacheTopology newCacheTopology;
+
       synchronized (cacheStatus) {
-         boolean isRebalanceInProgress = cacheStatus.getCacheTopology().getPendingCH() != null;
+         boolean isRebalanceInProgress = cacheTopology.getPendingCH() != null;
          if (isRebalanceInProgress) {
-            log.tracef(""Ignoring request to start rebalancing cache %s, there's already a rebalance in progress: %s"",
-                  cacheName, cacheStatus.getCacheTopology());
+            log.tracef(""Ignoring request to rebalance cache %s, there's already a rebalance in progress: %s"",
+                  cacheName, cacheTopology);
+            return;
+         }
+
+         List<Address> newMembers = new ArrayList<Address>(cacheTopology.getMembers());
+         if (newMembers.isEmpty()) {
+            log.tracef(""Ignoring request to rebalance cache %s, it doesn't have any member"", cacheName);
             return;
          }
 
-         List<Address> newMembers = new ArrayList<Address>(cacheStatus.getCacheTopology().getMembers());
          addUniqueJoiners(newMembers, cacheStatus.getJoiners());
          newMembers.retainAll(clusterMembers);
+
          log.tracef(""Rebalancing consistent hash for cache %s, members are %s"", cacheName, newMembers);
+         int newTopologyId = cacheTopology.getTopologyId() + 1;
+         ConsistentHash currentCH = cacheTopology.getCurrentCH();
+         if (currentCH == null) {
+            // There was one node in the cache before, and it left after the rebalance was triggered
+            // but before the rebalance actually started.
+            installInitialTopology(cacheName, cacheStatus);
+            return;
+         }
 
-         int newTopologyId = cacheStatus.getCacheTopology().getTopologyId() + 1;
-         ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
          ConsistentHashFactory chFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
          ConsistentHash updatedMembersCH = chFactory.updateMembers(currentCH, newMembers);
          ConsistentHash balancedCH = chFactory.rebalance(updatedMembersCH);
          if (balancedCH.equals(currentCH)) {
             log.tracef(""The balanced CH is the same as the current CH, not rebalancing"");
             return;
          }
-         CacheTopology cacheTopology = new CacheTopology(newTopologyId, currentCH, balancedCH);
-         log.tracef(""Updating cache %s topology for rebalance: %s"", cacheName, cacheTopology);
-         cacheStatus.setCacheTopology(cacheTopology);
+         newCacheTopology = new CacheTopology(newTopologyId, currentCH, balancedCH);
+         log.tracef(""Updating cache %s topology for rebalance: %s"", cacheName, newCacheTopology);
+         cacheStatus.setCacheTopology(newCacheTopology);
       }
-      clusterTopologyManager.rebalance(cacheName, cacheStatus.getCacheTopology());
+
+      clusterTopologyManager.rebalance(cacheName, newCacheTopology);
    }
 
    @Override
@@ -312,7 +333,7 @@ public void onRebalanceCompleted(String cacheName, int topologyId) throws Except
          ConsistentHash newCurrentCH = cacheStatus.getCacheTopology().getPendingCH();
 
          CacheTopology cacheTopology = new CacheTopology(newTopologyId, newCurrentCH, null);
-         updateConsistentHash(cacheName, cacheStatus, cacheTopology);
+         updateConsistentHash(cacheName, cacheStatus, cacheTopology, true);
 
          // Update the list of joiners
          // TODO Add some cleanup for nodes that left the cluster before getting any state",2012-08-31T21:05:51Z,597
"@@ -55,9 +55,15 @@ public interface RebalancePolicy {
    void updateMembersList(List<Address> membersList) throws Exception;
 
    /**
-    * Called when a member joins or leaves an individual cache.
+    * Called when one or more members join a cache.
+    * @return The previous cache topology.
     */
-   void updateMembersList(String cacheName, List<Address> joiners, List<Address> leavers) throws Exception;
+   CacheTopology addJoiners(String cacheName, List<Address> joiners) throws Exception;
+
+   /**
+    * Called when one or more members leave an individual cache (as opposed to leaving the cluster).
+    */
+   void removeLeavers(String cacheName, List<Address> leavers) throws Exception;
 
    /**
     * Called when every member has completed receiving data.",2012-08-31T21:05:51Z,598
"@@ -30,7 +30,6 @@
 import org.testng.annotations.Test;
 
 import java.util.List;
-import java.util.Set;
 
 /**
  * @author Mircea Markus
@@ -73,17 +72,17 @@ public void run() {
          @Override
          public boolean isSatisfied() throws Exception {
             List<Address> members = advancedCache(0).getRpcManager().getTransport().getMembers();
-            System.out.println(""members = "" + members);
+            log.trace(""members = "" + members);
             return members.size() == 1;
          }
       });
 
-      System.out.println(""MultipleNodesLeavingTest.testMultipleLeaves"");
+      log.trace(""MultipleNodesLeavingTest.testMultipleLeaves"");
 
       TestingUtil.blockUntilViewsReceived(60000, false, cache(0));
       TestingUtil.waitForRehashToComplete(cache(0));
       List<Address> caches = advancedCache(0).getDistributionManager().getConsistentHash().getMembers();
-      System.out.println(""caches = "" + caches);
+      log.tracef(""caches = %s"", caches);
       int size = caches.size();
       assert size == 1;
    }",2012-10-02T12:10:18Z,599
"@@ -71,13 +71,12 @@
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.marshall.jboss.ExternalizerTable;
 import org.infinispan.remoting.ReplicationQueue;
-import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.remoting.transport.jgroups.JGroupsTransport;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.topology.CacheTopology;
 import org.infinispan.topology.DefaultRebalancePolicy;
-import org.infinispan.topology.LocalTopologyManager;
 import org.infinispan.topology.RebalancePolicy;
 import org.infinispan.transaction.TransactionTable;
 import org.infinispan.util.concurrent.locks.LockManager;
@@ -167,14 +166,14 @@ public static void waitForRehashToComplete(Cache... caches) {
       // give it 1 second to start rehashing
       // TODO Should look at the last committed view instead and check if it contains all the caches
       LockSupport.parkNanos(TimeUnit.SECONDS.toNanos(1));
-      int gracetime = 90000; // 60 seconds
+      int gracetime = 90000; // 90 seconds
       long giveup = System.currentTimeMillis() + gracetime;
       for (Cache c : caches) {
-         LocalTopologyManager localTopologyManager = TestingUtil.extractGlobalComponent(c.getCacheManager(), LocalTopologyManager.class);
+         StateTransferManager stateTransferManager = TestingUtil.extractComponent(c, StateTransferManager.class);
          DefaultRebalancePolicy rebalancePolicy = (DefaultRebalancePolicy) TestingUtil.extractGlobalComponent(c.getCacheManager(), RebalancePolicy.class);
-         RpcManager rpcManager = TestingUtil.extractComponent(c, RpcManager.class);
+         Address cacheAddress = c.getAdvancedCache().getRpcManager().getAddress();
          while (true) {
-            CacheTopology cacheTopology = localTopologyManager.getCacheTopology(c.getName());
+            CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
             boolean chContainsAllMembers = cacheTopology.getCurrentCH().getMembers().size() == caches.length;
             boolean chIsBalanced = rebalancePolicy.isBalanced(cacheTopology.getCurrentCH());
             boolean stateTransferInProgress = cacheTopology.getPendingCH() != null;
@@ -190,7 +189,7 @@ public static void waitForRehashToComplete(Cache... caches) {
                   }
                   message = String.format(""Timed out waiting for rebalancing to complete on node %s, "" +
                         ""expected member list is %s, current member list is %s!"",
-                        rpcManager.getAddress(), Arrays.toString(addresses), cacheTopology.getCurrentCH().getMembers());
+                        cacheAddress, Arrays.toString(addresses), cacheTopology.getCurrentCH().getMembers());
                } else {
                   message = String.format(""Timed out waiting for rebalancing to complete on node %s, "" +
                         ""current topology is %s"", c.getCacheManager().getAddress(), cacheTopology);
@@ -201,7 +200,7 @@ public static void waitForRehashToComplete(Cache... caches) {
 
             LockSupport.parkNanos(TimeUnit.MILLISECONDS.toNanos(100));
          }
-         log.trace(""Node "" + rpcManager.getAddress() + "" finished state transfer."");
+         log.trace(""Node "" + cacheAddress + "" finished state transfer."");
       }
    }
 ",2012-10-02T12:10:18Z,50
"@@ -35,7 +35,6 @@
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.TransactionTable;
@@ -58,14 +57,9 @@ public abstract class AbstractTxLockingInterceptor extends AbstractLockingInterc
    public void setDependencies(TransactionTable txTable, RpcManager rpcManager) {
       this.txTable = txTable;
       this.rpcManager = rpcManager;
-   }
-
-   @Start
-   private void setClustered() {
       clustered = rpcManager != null;
    }
 
-
    @Override
    public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand command) throws Throwable {
       try {
@@ -169,10 +163,12 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
       TxInvocationContext txContext = (TxInvocationContext) ctx;
       int transactionViewId = -1;
+      boolean useStrictComparison = true;
       if (clustered) {
          transactionViewId = txContext.getCacheTransaction().getViewId();
          if (transactionViewId != TransactionTable.CACHE_STOPPED_VIEW_ID) {
-            checkForPendingLocks = transactionViewId > txTable.getMinViewId();
+            useStrictComparison = txTable.useStrictTopologyIdComparison();
+            checkForPendingLocks = isFromOlderTopology(txTable.getMinViewId(), transactionViewId, useStrictComparison);
          }
       }
 
@@ -183,15 +179,15 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
 
          // Check local transactions first
          for (CacheTransaction ct: txTable.getLocalTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
          }
 
          // ... then remote ones
          for (CacheTransaction ct: txTable.getRemoteTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
@@ -211,6 +207,19 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
    }
 
+   /**
+    * Checks if first topology id is smaller than the second. The comparison can be strict or non-strict,
+    * depending on the isStrictComparison flag.
+    *
+    * @param tx1TopologyId topology id of first transaction
+    * @param tx2TopologyId topology id of second transaction
+    * @param useStrictComparison a flag indicating if comparison must be strict
+    * @return if the first transaction was started in an older topology than the second transaction
+    */
+   private boolean isFromOlderTopology(int tx1TopologyId, int tx2TopologyId, boolean useStrictComparison) {
+      return useStrictComparison ? tx1TopologyId < tx2TopologyId : tx1TopologyId <= tx2TopologyId;
+   }
+
    private TimeoutException newTimeoutException(Object key, TxInvocationContext txContext) {
       return new TimeoutException(""Could not acquire lock on "" + key + "" on behalf of transaction "" +
                                        txContext.getGlobalTransaction() + "". Lock is being held by "" + lockManager.getOwner(key));",2012-09-21T12:26:43Z,131
"@@ -109,9 +109,7 @@ public interface CacheNotifier extends Listenable {
     */
    void notifyTransactionRegistered(GlobalTransaction globalTransaction, InvocationContext ctx);
 
-   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre);
-
-   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre);
-
+   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre);
 
+   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre);
 }
\ No newline at end of file",2012-09-21T12:26:43Z,132
"@@ -334,24 +334,25 @@ public void notifyTransactionRegistered(GlobalTransaction globalTransaction, Inv
    }
 
    @Override
-   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre) {
+   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre) {
       if (!dataRehashedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, DATA_REHASHED);
          e.setPre(pre);
          e.setMembersAtStart(oldView);
          e.setMembersAtEnd(newView);
-         e.setNewViewId(newViewId);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : dataRehashedListeners) listener.invoke(e);
       }
    }
 
    @Override
-   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre) {
+   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre) {
       if (!topologyChangedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, TOPOLOGY_CHANGED);
          e.setPre(pre);
          e.setConsistentHashAtStart(oldConsistentHash);
          e.setConsistentHashAtEnd(newConsistentHash);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : topologyChangedListeners) listener.invoke(e);
       }
    }",2012-09-21T12:26:43Z,133
"@@ -43,7 +43,7 @@ public interface DataRehashedEvent<K, V> extends Event<K, V> {
    Collection<Address> getMembersAtEnd();
 
    /**
-    * @return Retrieves the new view id after rehashing was triggered.
+    * @return Retrieves the new topology id after rehashing was triggered.
     */
-   long getNewViewId();
+   int getNewTopologyId();
 }",2012-09-21T12:26:43Z,134
"@@ -53,7 +53,7 @@ public class EventImpl<K, V> implements CacheEntryActivatedEvent, CacheEntryCrea
    private V value;
    private Collection<Address> membersAtStart, membersAtEnd;
    private ConsistentHash consistentHashAtStart, consistentHashAtEnd;
-   private long newViewId;
+   private int newTopologyId;
    private Map<Object, Object> entries;
 
    public EventImpl() {
@@ -150,8 +150,8 @@ public void setConsistentHashAtEnd(ConsistentHash consistentHashAtEnd) {
       this.consistentHashAtEnd = consistentHashAtEnd;
    }
 
-   public void setNewViewId(long newViewId) {
-      this.newViewId = newViewId;
+   public void setNewTopologyId(int newTopologyId) {
+      this.newTopologyId = newTopologyId;
    }
 
    @Override
@@ -189,7 +189,7 @@ public boolean equals(Object o) {
       if (!Util.safeEquals(consistentHashAtEnd, event.consistentHashAtEnd)) return false;
       if (!Util.safeEquals(membersAtStart, event.membersAtStart)) return false;
       if (!Util.safeEquals(membersAtEnd, event.membersAtEnd)) return false;
-      if (newViewId != event.newViewId) return false;
+      if (newTopologyId != event.newTopologyId) return false;
 
       return true;
    }
@@ -208,7 +208,7 @@ public int hashCode() {
       result = 31 * result + (membersAtEnd != null ? membersAtEnd.hashCode() : 0);
       result = 31 * result + (consistentHashAtStart != null ? consistentHashAtStart.hashCode() : 0);
       result = 31 * result + (consistentHashAtEnd != null ? consistentHashAtEnd.hashCode() : 0);
-      result = 31 * result + ((int) newViewId);
+      result = 31 * result + ((int) newTopologyId);
       return result;
    }
 
@@ -236,8 +236,8 @@ public Collection<Address> getMembersAtEnd() {
    }
 
    @Override
-   public long getNewViewId() {
-      return newViewId;
+   public int getNewTopologyId() {
+      return newTopologyId;
    }
 
    @Override",2012-09-21T12:26:43Z,135
"@@ -40,5 +40,7 @@ public interface TopologyChangedEvent<K, V> extends Event<K, V> {
     */
    ConsistentHash getConsistentHashAtEnd();
 
+   int getNewTopologyId();
+
    //todo [anistor] add topologyId, prevReadCH, prevWriteCH, newReadCH2, newWriteCH
 }",2012-09-21T12:26:43Z,136
"@@ -95,7 +95,7 @@ public class StateConsumerImpl implements StateConsumer {
    private AtomicInteger activeTopologyUpdates = new AtomicInteger(0);
 
    /**
-    * Indicates if currently executing topology update is a rabalance.
+    * Indicates if the currently executing topology update is a rebalance.
     */
    private AtomicBoolean rebalanceInProgress = new AtomicBoolean(false);
 
@@ -197,8 +197,10 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             removedSegments.removeAll(newSegments);
 
             // remove inbound transfers and any data for segments we no longer own
-            log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                  removedSegments, newSegments, previousSegments);
+            if (trace) {
+               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
+                     removedSegments, newSegments, previousSegments);
+            }
             discardSegments(removedSegments);
 
             if (fetchEnabled) {",2012-09-21T12:26:43Z,54
"@@ -80,7 +80,7 @@ public class StateProviderImpl implements StateProvider {
    private volatile ConsistentHash readCh;
 
    /**
-    * A map that keeps track of current outbound state transfers by source address. There could be multiple transfers
+    * A map that keeps track of current outbound state transfers by destination address. There could be multiple transfers
     * flowing to the same destination (but for different segments) so the values are lists.
     */
    private final Map<Address, List<OutboundTransferTask>> transfersByDestination = new HashMap<Address, List<OutboundTransferTask>>();
@@ -124,6 +124,7 @@ public boolean isStateTransferInProgress() {
    }
 
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // do all the work AFTER the consistent hash has changed
       if (tce.isPre())
@@ -236,12 +237,14 @@ private void collectTransactionsToTransfer(List<TransactionInfo> transactionsToT
                lockedKeys.add(key);
             }
          }
-         List<WriteCommand> txModifications = tx.getModifications();
-         WriteCommand[] modifications = null;
-         if (txModifications != null) {
-            modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+         if (!lockedKeys.isEmpty()) {
+            List<WriteCommand> txModifications = tx.getModifications();
+            WriteCommand[] modifications = null;
+            if (txModifications != null) {
+               modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+            }
+            transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), tx.getViewId(), modifications, lockedKeys));
          }
-         transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), modifications, lockedKeys));
       }
    }
 ",2012-09-21T12:26:43Z,55
"@@ -48,10 +48,9 @@
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 
+//todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
 /**
  * // TODO: Document this
  *
@@ -317,8 +316,8 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       } finally {
          stateTransferLock.commandsSharedUnlock();
 
-         log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
          if (newTargets != null && !newTargets.isEmpty()) {
+            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
             rpcManager.invokeRemotely(newTargets, command, true);
          }
       }",2012-09-21T12:26:43Z,115
"@@ -178,19 +178,20 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
       // TODO Improve notification to contain both CHs
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, true);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), true);
 
       stateConsumer.onTopologyUpdate(newCacheTopology, isRebalance);
       stateProvider.onTopologyUpdate(newCacheTopology, isRebalance);
 
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, false);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
       if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
          initialStateTransferComplete.countDown();
       }
    }
 
    @Start(priority = 1000)
+   @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
       if (trace) log.tracef(""Waiting for initial state transfer to finish"");
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);",2012-09-21T12:26:43Z,117
"@@ -50,8 +50,11 @@ public class TransactionInfo {
 
    private final Set<Object> lockedKeys;
 
-   public TransactionInfo(GlobalTransaction globalTransaction, WriteCommand[] modifications, Set<Object> lockedKeys) {
+   private final int topologyId;
+
+   public TransactionInfo(GlobalTransaction globalTransaction, int topologyId, WriteCommand[] modifications, Set<Object> lockedKeys) {
       this.globalTransaction = globalTransaction;
+      this.topologyId = topologyId;
       this.modifications = modifications;
       this.lockedKeys = lockedKeys;
    }
@@ -68,10 +71,15 @@ public Set<Object> getLockedKeys() {
       return lockedKeys;
    }
 
+   public int getTopologyId() {
+      return topologyId;
+   }
+
    @Override
    public String toString() {
       return ""TransactionInfo{"" +
             ""globalTransaction="" + globalTransaction +
+            "", topologyId="" + topologyId +
             "", modifications="" + Arrays.asList(modifications) +
             "", lockedKeys="" + lockedKeys +
             '}';
@@ -92,6 +100,7 @@ public Set<Class<? extends TransactionInfo>> getTypeClasses() {
       @Override
       public void writeObject(ObjectOutput output, TransactionInfo object) throws IOException {
          output.writeObject(object.globalTransaction);
+         output.writeInt(object.topologyId);
          output.writeObject(object.modifications);
          output.writeObject(object.lockedKeys);
       }
@@ -100,9 +109,10 @@ public void writeObject(ObjectOutput output, TransactionInfo object) throws IOEx
       @SuppressWarnings(""unchecked"")
       public TransactionInfo readObject(ObjectInput input) throws IOException, ClassNotFoundException {
          GlobalTransaction globalTransaction = (GlobalTransaction) input.readObject();
+         int topologyId = input.readInt();
          WriteCommand[] modifications = (WriteCommand[]) input.readObject();
          Set<Object> lockedKeys = (Set<Object>) input.readObject();
-         return new TransactionInfo(globalTransaction, modifications, lockedKeys);
+         return new TransactionInfo(globalTransaction, topologyId, modifications, lockedKeys);
       }
    }
 }",2012-09-21T12:26:43Z,137
"@@ -31,8 +31,6 @@
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
 import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.MembershipArithmetic;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
@@ -67,37 +65,41 @@ public class StaleTransactionCleanupService {
    private TransactionTable transactionTable;
    private InterceptorChain invoker;
    private String cacheName;
+   private boolean isDistributed;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
    private ExecutorService lockBreakingService; // a thread pool with max. 1 thread
 
-   /**
-    * Roll back remote transactions originating on nodes that have left the cluster.
-    */
-   @ViewChanged
-   public void onViewChange(ViewChangedEvent vce) {
-      final List<Address> leavers = MembershipArithmetic.getMembersLeft(vce.getOldMembers(),
-                                                                        vce.getNewMembers());
-      if (!leavers.isEmpty()) {
-         log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-         cleanTxForWhichTheOwnerLeft(leavers);
-      }
-   }
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * either because the main data owner left the cluster or because a node joined
     * the cluster and is the new data owner.
     * This method will only ever be called in distributed mode.
     */
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
-      // do all the work AFTER the consistent hash has changed
-      if (tce.isPre())
+      // Roll back remote transactions originating on nodes that have left the cluster.
+      if (tce.isPre()) {
+         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+         if (consistentHashAtStart != null) {
+            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+            if (!leavers.isEmpty()) {
+               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+               cleanTxForWhichTheOwnerLeft(leavers);
+            }
+         }
+         return;
+      }
+
+      if (!isDistributed) {
          return;
+      }
+
+      // do all the work AFTER the consistent hash has changed
 
       Address self = transactionTable.rpcManager.getAddress();
       ConsistentHash chOld = tce.getConsistentHashAtStart();
@@ -173,7 +175,7 @@ public void run() {
       }
    }
 
-   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain) {
+   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain, boolean isDistributed) {
       this.invoker = interceptorChain;
       ThreadFactory tf = new ThreadFactory() {
          @Override
@@ -185,8 +187,9 @@ public Thread newThread(Runnable r) {
          }
       };
       this.cacheName = cacheName;
+      this.isDistributed = isDistributed;
       lockBreakingService = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingDeque<Runnable>(), tf,
-                                                   new ThreadPoolExecutor.CallerRunsPolicy());
+                                                   new ThreadPoolExecutor.DiscardOldestPolicy());
    }
 
    public void stop() {",2012-09-21T12:26:43Z,126
"@@ -38,11 +38,10 @@
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.interceptors.InterceptorChain;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
-import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
+import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.synchronization.SyncLocalTransaction;
@@ -57,9 +56,7 @@
 
 import javax.transaction.Transaction;
 import javax.transaction.TransactionSynchronizationRegistry;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.locks.Lock;
@@ -76,7 +73,7 @@
  * @author Galder Zamarreño
  * @since 4.0
  */
-@Listener(sync = false)
+@Listener
 public class TransactionTable {
 
    public static final int CACHE_STOPPED_VIEW_ID = -1;
@@ -95,25 +92,23 @@ public class TransactionTable {
    protected CommandsFactory commandsFactory;
    private InterceptorChain invoker;
    private CacheNotifier notifier;
-   private EmbeddedCacheManager cm;
    private TransactionSynchronizationRegistry transactionSynchronizationRegistry;
    protected ClusteringDependentLogic clusteringLogic;
    protected boolean clustered = false;
    private Lock minViewRecalculationLock;
 
    /**
-    * minTxViewId is the minimum view ID across all ongoing local and remote transactions. It doesn't update on
-    * transaction creation, but only on removal. That's because it is not possible for a newly created transaction to
-    * have an bigger view ID than the current one.
+    * minTxViewId is the minimum view ID across all ongoing local and remote transactions.
     */
    private volatile int minTxViewId = CACHE_STOPPED_VIEW_ID;
    private volatile int currentViewId = CACHE_STOPPED_VIEW_ID;
+   private volatile boolean useStrictTopologyIdComparison = true;
    private String cacheName;
 
    @Inject
    public void initialize(RpcManager rpcManager, Configuration configuration,
                           InvocationContextContainer icc, InterceptorChain invoker, CacheNotifier notifier,
-                          TransactionFactory gtf, EmbeddedCacheManager cm, TransactionCoordinator txCoordinator,
+                          TransactionFactory gtf, TransactionCoordinator txCoordinator,
                           TransactionSynchronizationRegistry transactionSynchronizationRegistry,
                           CommandsFactory commandsFactory, ClusteringDependentLogic clusteringDependentLogic, Cache cache) {
       this.rpcManager = rpcManager;
@@ -122,7 +117,6 @@ public void initialize(RpcManager rpcManager, Configuration configuration,
       this.invoker = invoker;
       this.notifier = notifier;
       this.txFactory = gtf;
-      this.cm = cm;
       this.txCoordinator = txCoordinator;
       this.transactionSynchronizationRegistry = transactionSynchronizationRegistry;
       this.commandsFactory = commandsFactory;
@@ -139,24 +133,20 @@ private void start() {
          minViewRecalculationLock = new ReentrantLock();
          // Only initialize this if we are clustered.
          remoteTransactions = ConcurrentMapFactory.makeConcurrentMap(concurrencyLevel, 0.75f, concurrencyLevel);
-         cleanupService.start(cacheName, rpcManager, invoker);
-         cm.addListener(cleanupService);
-         cm.addListener(this);
+         cleanupService.start(cacheName, rpcManager, invoker, configuration.clustering().cacheMode().isDistributed());
          notifier.addListener(cleanupService);
-         minTxViewId = rpcManager.getTransport().getViewId();
-         currentViewId = minTxViewId;
-         log.debugf(""Min view id set to %s"", minTxViewId);
+         notifier.addListener(this);
          clustered = true;
       }
    }
 
    @Stop
+   @SuppressWarnings(""unused"")
    private void stop() {
       if (clustered) {
          notifier.removeListener(cleanupService);
-         cm.removeListener(cleanupService);
          cleanupService.stop();
-         cm.removeListener(this);
+         notifier.removeListener(this);
          currentViewId = CACHE_STOPPED_VIEW_ID; // indicate that the cache has stopped
       }
       shutDownGracefully();
@@ -223,6 +213,17 @@ public int getMinViewId() {
       return minTxViewId;
    }
 
+   /**
+    * Indicates if topology id comparisons should be strict if one wants to compare topology ids in oder to tell
+    * if a transaction was started in an older topology than a second transaction. This flag is true most of the time
+    * except when the current topology did not increase its id (it's not caused by a rebalance).
+    *
+    * @return true if strict topology id comparisons should be used, false otherwise
+    */
+   public boolean useStrictTopologyIdComparison() {
+      return useStrictTopologyIdComparison;
+   }
+
    protected void updateStateOnNodesLeaving(Collection<Address> leavers) {
       Set<GlobalTransaction> toKill = new HashSet<GlobalTransaction>();
       for (GlobalTransaction gt : remoteTransactions.keySet()) {
@@ -263,14 +264,24 @@ public void remoteTransactionRollback(GlobalTransaction gtx) {
    }
 
    /**
-    * Creates and register a {@link RemoteTransaction} with no modifications. Returns the created transaction.
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
     *
     * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
     *                               made.
     */
    public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications) {
-      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, currentViewId)
-            : txFactory.newRemoteTransaction(modifications, globalTx, currentViewId);
+      return createRemoteTransaction(globalTx, modifications, currentViewId);
+   }
+
+   /**
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
+    *
+    * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
+    *                               made.
+    */
+   public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications, int topologyId) {
+      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, topologyId)
+            : txFactory.newRemoteTransaction(modifications, globalTx, topologyId);
       registerRemoteTransaction(globalTx, remoteTransaction);
       return remoteTransaction;
    }
@@ -283,6 +294,10 @@ private void registerRemoteTransaction(GlobalTransaction gtx, RemoteTransaction
       }
 
       log.tracef(""Created and registered remote transaction %s"", rtx);
+      if (rtx.getViewId() < minTxViewId) {
+         log.tracef(""Changing minimum view ID from %d to %d"", minTxViewId, rtx.getViewId());
+         minTxViewId = rtx.getViewId();
+      }
    }
 
    /**
@@ -293,6 +308,9 @@ public LocalTransaction getOrCreateLocalTransaction(Transaction transaction, TxI
       LocalTransaction current = localTransactions.get(transaction);
       if (current == null) {
          Address localAddress = rpcManager != null ? rpcManager.getTransport().getAddress() : null;
+         if (rpcManager != null && currentViewId < 0) {
+            throw new IllegalStateException(""Cannot create transactions if topology id is not known yet!"");
+         }
          GlobalTransaction tx = txFactory.newGlobalTransaction(localAddress, false);
          current = txFactory.newLocalTransaction(transaction, tx, ctx.isImplicitTransaction(), currentViewId);
          log.tracef(""Created a new local transaction: %s"", current);
@@ -310,10 +328,6 @@ public boolean removeLocalTransaction(LocalTransaction localTransaction) {
       return localTransaction != null && (removeLocalTransactionInternal(localTransaction.getTransaction()) != null);
    }
 
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      return removeLocalTransactionInternal(tx);
-   }
-
    protected final LocalTransaction removeLocalTransactionInternal(Transaction tx) {
       LocalTransaction removed;
       removed = localTransactions.remove(tx);
@@ -357,8 +371,8 @@ public int getLocalTxCount() {
 
    /**
     * Looks up a LocalTransaction given a GlobalTransaction.
-    * @param txId
-    * @return
+    * @param txId the global transaction identifier
+    * @return the LocalTransaction or null if not found
     */
    public LocalTransaction getLocalTransaction(GlobalTransaction txId) {
       for (LocalTransaction localTx : localTransactions.values()) { //todo [anistor] optimize lookup!
@@ -402,17 +416,21 @@ protected final void recalculateMinViewIdIfNeeded(CacheTransaction removedTransa
       }
    }
 
-   @ViewChanged
-   public void recalculateMinViewIdOnTopologyChange(ViewChangedEvent vce) {
-      // don't do anything if this cache is not clustered - view changes are global
+   @TopologyChanged
+   @SuppressWarnings(""unused"")
+   public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
+      // don't do anything if this cache is not clustered
       if (clustered) {
-         log.debugf(""View changed, recalculating minViewId"");
-         currentViewId = vce.getViewId();
-         calculateMinViewId(-1);
+         if (tce.isPre()) {
+            useStrictTopologyIdComparison = tce.getNewTopologyId() != currentViewId;
+            currentViewId = tce.getNewTopologyId();
+         } else {
+            log.debugf(""Topology changed, recalculating minViewId"");
+            calculateMinViewId(-1);
+         }
       }
    }
 
-
    /**
     * This method calculates the minimum view ID known by the current node.  This method is only used in a clustered
     * cache, and only invoked when either a view change is detected, or a transaction whose view ID is not the same as
@@ -442,7 +460,7 @@ private void calculateMinViewId(int idOfRemovedTransaction) {
                int viewId = ct.getViewId();
                if (viewId < minViewIdFound) minViewIdFound = viewId;
             }
-            if (minViewIdFound > minTxViewId) {
+            if (minViewIdFound != minTxViewId) {
                log.tracef(""Changing minimum view ID from %s to %s"", minTxViewId, minViewIdFound);
                minTxViewId = minViewIdFound;
             } else {",2012-09-21T12:26:43Z,127
"@@ -80,13 +80,6 @@ private void removeXidTxMapping(LocalXaTransaction localTx) {
       xid2LocalTx.remove(xid);
    }
 
-   @Override
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      final LocalTransaction remove = removeLocalTransactionInternal(tx);
-      if (remove != null) removeXidTxMapping((LocalXaTransaction) remove);
-      return remove;
-   }
-
    public LocalXaTransaction getLocalTransaction(Xid xid) {
       return this.xid2LocalTx.get(xid);
    }",2012-09-21T12:26:43Z,138
"@@ -22,10 +22,8 @@
  */
 package org.infinispan.util.concurrent.locks;
 
-import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.jmx.annotations.MBean;",2012-09-21T12:26:43Z,139
"@@ -93,15 +93,16 @@ public boolean isSatisfied() throws Exception {
          public void run() {
             try {
                log.trace(""This thread runs a different tx"");
-               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).resume(suspend);
+               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).commit();
             } catch (Exception e) {
                e.printStackTrace();
             }
          }
       }, false);
 
+      // this 'ensures' transaction called 'suspend' has the chance to start the prepare phase and is waiting to acquire the locks on k held by first transaction before it gets resumed
       Thread.sleep(1000);
 
       log.trace(""Before completing the transaction!"");",2012-09-21T12:26:43Z,140
"@@ -21,7 +21,7 @@
 /**
  * @since 5.1
  */
-@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"", enabled = false) //todo [anistor] temporarily disabled for NBST
+@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"")
 @CleanupAfterMethod
 public class MainOwnerChangesLockTest extends MultipleCacheManagersTest {
 ",2012-09-21T12:26:43Z,141
"@@ -24,6 +24,7 @@
 package org.infinispan.lock.singlelock;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.CleanupAfterMethod;
@@ -33,8 +34,7 @@
 import org.infinispan.transaction.tm.DummyTransaction;
 import org.testng.annotations.Test;
 
-import javax.transaction.Status;
-
+import static org.testng.Assert.assertTrue;
 import static org.testng.Assert.assertEquals;
 
 
@@ -60,21 +60,22 @@ protected void createCacheManagers() throws Throwable {
       waitForClusterToForm();
    }
 
-   @Test(enabled = false, description = ""See ISPN-2113"")
    public void testMinViewId1() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
+
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);
 
       //add a new cache and check that min view is updated
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId2);
       assertEquals(tt1.getMinViewId(), viewId2);
@@ -88,8 +89,8 @@ public void testMinViewId2() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
 
       tm(1).begin();
       cache(1).put(getKeyForCache(0),""v"");
@@ -109,8 +110,8 @@ public boolean isSatisfied() throws Exception {
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);",2012-09-21T12:26:43Z,142
"@@ -36,7 +36,6 @@
 import javax.transaction.InvalidTransactionException;
 import javax.transaction.NotSupportedException;
 import javax.transaction.RollbackException;
-import javax.transaction.Status;
 import javax.transaction.SystemException;
 
 import static org.testng.Assert.assertEquals;
@@ -45,7 +44,7 @@
  * @author Mircea Markus
  * @since 5.1
  */
-@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"", enabled = false, description = ""See ISPN-2113"")
+@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"")
 @CleanupAfterMethod
 public class LockOwnerCrashPessimisticTest extends AbstractLockOwnerCrashTest {
 ",2012-09-21T12:26:43Z,143
"@@ -168,6 +168,9 @@ public InternalCacheEntry retrieveFromRemoteSource(Object key, InvocationContext
          }
       }
 
+      // TODO If everyone returned null, and the read CH has changed, retry the remote get.
+      // Otherwise our get command might be processed by the old owners after they have invalidated their data
+      // and we'd return a null even though the key exists on
       return null;
    }
 ",2012-09-28T09:43:46Z,60
"@@ -37,6 +37,7 @@
 import org.infinispan.factories.scopes.Scopes;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.statetransfer.StateTransferLock;
 import org.infinispan.transaction.WriteSkewHelper;
 import org.infinispan.transaction.xa.CacheTransaction;
 import org.infinispan.util.logging.Log;
@@ -148,6 +149,7 @@ public static final class DistributionLogic implements ClusteringDependentLogic
       private DataContainer dataContainer;
       private Configuration configuration;
       private RpcManager rpcManager;
+      private StateTransferLock stateTransferLock;
       private final WriteSkewHelper.KeySpecificLogic keySpecificLogic = new WriteSkewHelper.KeySpecificLogic() {
          @Override
          public boolean performCheckOnKey(Object key) {
@@ -156,11 +158,13 @@ public boolean performCheckOnKey(Object key) {
       };
 
       @Inject
-      public void init(DistributionManager dm, DataContainer dataContainer, Configuration configuration, RpcManager rpcManager) {
+      public void init(DistributionManager dm, DataContainer dataContainer, Configuration configuration,
+                       RpcManager rpcManager, StateTransferLock stateTransferLock) {
          this.dm = dm;
          this.dataContainer = dataContainer;
          this.configuration = configuration;
          this.rpcManager = rpcManager;
+         this.stateTransferLock = stateTransferLock;
       }
 
       @Override
@@ -183,19 +187,26 @@ public boolean localNodeIsPrimaryOwner(Object key) {
 
       @Override
       public void commitEntry(CacheEntry entry, EntryVersion newVersion, boolean skipOwnershipCheck) {
-         boolean doCommit = true;
-         // ignore locality for removals, even if skipOwnershipCheck is not true
-         if (!skipOwnershipCheck && !entry.isRemoved() && !localNodeIsOwner(entry.getKey())) {
-            if (configuration.clustering().l1().enabled()) {
-               dm.transformForL1(entry);
-            } else {
-               doCommit = false;
+         // Don't allow the CH to change (and state transfer to invalidate entries)
+         // between the ownership check and the commit
+         stateTransferLock.acquireSharedTopologyLock();
+         try {
+            boolean doCommit = true;
+            // ignore locality for removals, even if skipOwnershipCheck is not true
+            if (!skipOwnershipCheck && !entry.isRemoved() && !localNodeIsOwner(entry.getKey())) {
+               if (configuration.clustering().l1().enabled()) {
+                  dm.transformForL1(entry);
+               } else {
+                  doCommit = false;
+               }
             }
+            if (doCommit)
+               entry.commit(dataContainer, newVersion);
+            else
+               entry.rollback();
+         } finally {
+            stateTransferLock.releaseSharedTopologyLock();
          }
-         if (doCommit)
-            entry.commit(dataContainer, newVersion);
-         else
-            entry.rollback();
       }
 
       @Override",2012-09-28T09:43:46Z,172
"@@ -177,9 +177,12 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
          rebalanceInProgress.set(true);
       }
       ConsistentHash previousCh = this.cacheTopology != null ? this.cacheTopology.getWriteConsistentHash() : null;
+      // Ensures writes to the data container use the right consistent hash
+      // No need for a try/finally block, since it's just an assignment
+      stateTransferLock.acquireExclusiveTopologyLock();
       this.cacheTopology = cacheTopology;
-
-      stateTransferLock.setTopologyId(cacheTopology.getTopologyId());
+      stateTransferLock.releaseExclusiveTopologyLock();
+      stateTransferLock.topologyInstalled(cacheTopology.getTopologyId());
 
       try {
          Set<Integer> addedSegments;
@@ -224,14 +227,11 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
          }
 
          if (addedSegments != null && !addedSegments.isEmpty()) {
-            stateTransferLock.commandsExclusiveLock();
-            try {
-               addTransfers(addedSegments);  // add transfers for new or restarted segments
-            } finally {
-               stateTransferLock.commandsExclusiveUnlock();
-            }
+            addTransfers(addedSegments);  // add transfers for new or restarted segments
          }
       } finally {
+         stateTransferLock.transactionDataReceived(cacheTopology.getTopologyId());
+
          if (activeTopologyUpdates.decrementAndGet() == 0 && !isStateTransferInProgress()) {
             notifyEndOfTopologyUpdate(cacheTopology.getTopologyId());
          }",2012-09-28T09:43:46Z,54
"@@ -70,7 +70,7 @@ public interface StateProvider {
     * @param topologyId
     * @param segments
     */
-   void startOutboundTransfer(Address destination, int topologyId, Set<Integer> segments);
+   void startOutboundTransfer(Address destination, int topologyId, Set<Integer> segments) throws InterruptedException;
 
    /**
     * Cancel sending of cache entries that belong to the given set of segments. This is invoked in response to a",2012-09-28T09:43:46Z,55
"@@ -76,7 +76,7 @@ public class StateProviderImpl implements StateProvider {
    private long timeout;
    private int chunkSize;
 
-   private volatile int topolopyId;
+   private volatile int topologyId;
    private volatile ConsistentHash readCh;
 
    /**
@@ -134,7 +134,7 @@ public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
 
    public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
       this.readCh = cacheTopology.getReadConsistentHash();
-      this.topolopyId = cacheTopology.getTopologyId();
+      this.topologyId = cacheTopology.getTopologyId();
 
       // cancel outbound state transfers for destinations that are no longer members in new topology
       Set<Address> members = new HashSet<Address>(cacheTopology.getWriteConsistentHash().getMembers());
@@ -182,19 +182,23 @@ public void stop() {
       }
    }
 
-   public List<TransactionInfo> getTransactionsForSegments(Address destination, int topologyId, Set<Integer> segments) throws InterruptedException {
+   public List<TransactionInfo> getTransactionsForSegments(Address destination, int requestTopologyId, Set<Integer> segments) throws InterruptedException {
       if (trace) {
-         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, topologyId);
+         log.tracef(""Received request for transactions from node %s for segments %s with topology id %d"", destination, segments, requestTopologyId);
       }
 
       if (readCh == null) {
          throw new IllegalStateException(""No cache topology received yet"");  // no commands are processed until the join is complete, so this cannot normally happen
       }
 
-      //todo [anistor] here we should block until topologyId is installed so we are sure forwarding happens correctly
-      if (topologyId != this.topolopyId) {
-         log.warnf(""Transactions were requested by a node with topology (%d) that does not match local topology (%d)."", topologyId, this.topolopyId);
-         stateTransferLock.waitForTopology(topologyId);
+      if (requestTopologyId < topologyId) {
+         log.warnf(""Transactions were requested by node %s with topology %d, smaller than the local "" +
+               ""topology (%d)"", destination, requestTopologyId, topologyId);
+      } else if (requestTopologyId > topologyId) {
+         log.tracef(""Transactions were requested by node %s with topology %d, greater than the local "" +
+               ""topology (%d). Waiting for topology %d to be installed locally."", destination,
+               requestTopologyId, topologyId, requestTopologyId);
+         stateTransferLock.waitForTopology(requestTopologyId);
       }
       Set<Integer> ownedSegments = readCh.getSegmentsForOwner(rpcManager.getAddress());
       if (!ownedSegments.containsAll(segments)) {
@@ -205,17 +209,10 @@ public List<TransactionInfo> getTransactionsForSegments(Address destination, int
       List<TransactionInfo> transactions = new ArrayList<TransactionInfo>();
       //we migrate locks only if the cache is transactional and distributed
       if (configuration.transaction().transactionMode().isTransactional()) {
-         // all transactions should be briefly blocked now
-         stateTransferLock.transactionsExclusiveLock();
-         try {
-            collectTransactionsToTransfer(transactions, transactionTable.getRemoteTransactions(), segments);
-            collectTransactionsToTransfer(transactions, transactionTable.getLocalTransactions(), segments);
-            if (trace) {
-               log.tracef(""Found %d transaction(s) to transfer"", transactions.size());
-            }
-         } finally {
-            // all transactions should be unblocked now
-            stateTransferLock.transactionsExclusiveUnlock();
+         collectTransactionsToTransfer(transactions, transactionTable.getRemoteTransactions(), segments);
+         collectTransactionsToTransfer(transactions, transactionTable.getLocalTransactions(), segments);
+         if (trace) {
+            log.tracef(""Found %d transaction(s) to transfer"", transactions.size());
          }
       }
       return transactions;
@@ -249,15 +246,23 @@ private void collectTransactionsToTransfer(List<TransactionInfo> transactionsToT
    }
 
    @Override
-   public void startOutboundTransfer(Address destination, int topologyId, Set<Integer> segments) {
-      if (trace) {
-         log.tracef(""Starting outbound transfer of segments %s to node %s with topology id %d"", segments, destination, topologyId);
-      }
-      if (topologyId != this.topolopyId) {
-         log.warnf(""Segments were requested by a node with topology (%d) that does not match local topology (%d)."", topologyId, this.topolopyId);
+   public void startOutboundTransfer(Address destination, int requestTopologyId, Set<Integer> segments)
+         throws InterruptedException {
+      log.tracef(""Starting outbound transfer of segments %s to node %s with topology id %d"", segments,
+            destination, requestTopologyId);
+
+      if (requestTopologyId < topologyId) {
+         log.warnf(""Segments were requested by node %s with topology %d, smaller than the local "" +
+               ""topology (%d)"", destination, requestTopologyId, topologyId);
+      } else if (requestTopologyId > topologyId) {
+         log.tracef(""Segments were requested by node %s with topology %d, greater than the local "" +
+               ""topology (%d). Waiting for topology %d to be installed locally."", destination,
+               requestTopologyId, topologyId, requestTopologyId);
+         stateTransferLock.waitForTopology(requestTopologyId);
       }
+
       // the destination node must already have an InboundTransferTask waiting for these segments
-      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, topologyId,
+      OutboundTransferTask outboundTransfer = new OutboundTransferTask(destination, segments, chunkSize, requestTopologyId,
             readCh, this, dataContainer, cacheLoaderManager, rpcManager, configuration, commandsFactory, timeout);
       addTransfer(outboundTransfer);
       outboundTransfer.execute(executorService);",2012-09-28T09:43:46Z,55
"@@ -28,8 +28,6 @@
 import org.infinispan.commands.TopologyAffectedCommand;
 import org.infinispan.commands.VisitableCommand;
 import org.infinispan.commands.control.LockControlCommand;
-import org.infinispan.commands.read.GetKeyValueCommand;
-import org.infinispan.commands.remote.ClusteredGetCommand;
 import org.infinispan.commands.tx.*;
 import org.infinispan.commands.write.*;
 import org.infinispan.configuration.cache.Configuration;
@@ -198,132 +196,77 @@ public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) thr
     * @return
     * @throws Throwable
     */
-   private Object handleTxCommand(InvocationContext ctx, TransactionBoundaryCommand command) throws Throwable {
-      return handleTopologyAffectedCommand(ctx, command);
+   private Object handleTxCommand(TxInvocationContext ctx, TransactionBoundaryCommand command)
+         throws Throwable {
+      return handleTopologyAffectedCommand(ctx, command, ctx.getCacheTransaction() instanceof RemoteTransaction);
    }
 
    private Object handleWriteCommand(InvocationContext ctx, WriteCommand command) throws Throwable {
-      return handleTopologyAffectedCommand(ctx, command);
+      return handleTopologyAffectedCommand(ctx, command, ctx.isOriginLocal());
    }
 
    @Override
    protected Object handleDefault(InvocationContext ctx, VisitableCommand command) throws Throwable {
       if (command instanceof TopologyAffectedCommand) {
-         return handleTopologyAffectedCommand(ctx, (TopologyAffectedCommand) command);
+         return handleTopologyAffectedCommand(ctx, (TopologyAffectedCommand) command, ctx.isOriginLocal());
       } else {
          return invokeNextInterceptor(ctx, command);
       }
    }
 
-   private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffectedCommand command) throws Throwable {
-      final boolean isTxCommand = command instanceof TransactionBoundaryCommand;
+   private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffectedCommand command,
+                                                boolean originLocal) throws Throwable {
       boolean cacheModeLocal = false;
       if (command instanceof FlagAffectedCommand) {
          cacheModeLocal = ((FlagAffectedCommand)command).hasFlag(Flag.CACHE_MODE_LOCAL);
       }
-      if (cacheModeLocal) {
-         try {
-            if (isTxCommand) {
-               stateTransferLock.transactionsSharedLock();
-            }
-            return invokeNextInterceptor(ctx, command);
-         } finally {
-            if (isTxCommand) {
-               stateTransferLock.transactionsSharedUnlock();
-            }
-         }
+      if (originLocal || cacheModeLocal) {
+         return invokeNextInterceptor(ctx, command);
       }
 
-      stateTransferLock.commandsSharedLock();
-      final CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
-      final int topologyId = cacheTopology.getTopologyId();
-      final ConsistentHash readCh = cacheTopology.getReadConsistentHash();
-      final ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
-      Set<Address> newTargets = null;
-
-      // set the topology id if it was not set before (ie. this is not a remote or forwarded command)
+      // set the topology id if it was not set before (ie. this is local command)
+      // TODO Make tx commands extend FlagAffectedCommand so we can use CACHE_MODE_LOCAL in StaleTransactionCleanupService
       if (command.getTopologyId() == -1) {
-         command.setTopologyId(cacheTopology.getTopologyId());
+         command.setTopologyId(stateTransferManager.getCacheTopology().getTopologyId());
       }
-      try {
-         if (isTxCommand) {
-            stateTransferLock.transactionsSharedLock();
-         }
-         try {
-            // forward commands with older topology ids to their new targets
-            if (command.getTopologyId() < topologyId) {
-               // if it is a read request and comes from an older topology we need to check if we still hold the data
-               Object readKey = null;
-               if (command instanceof GetKeyValueCommand) {   //todo [anistor] would be nice to have a common ReadCommand interface for these
-                  readKey = ((GetKeyValueCommand) command).getKey();
-               } else if (command instanceof ClusteredGetCommand) {
-                  readKey = ((ClusteredGetCommand) command).getKey();
-               }
-               if (readKey != null) {
-                  // it's a read operation
-                  if (!readCh.isKeyLocalToNode(rpcManager.getAddress(), readKey)) {
-                     return null; //todo [anistor] throw an exception or return a special result that will cause the read command to be retried on the originator
-                  }
-               } else if (command instanceof PrepareCommand || command instanceof LockControlCommand || command instanceof WriteCommand) {  //todo a ClearCommand should be executed directly
-                  // a TX or a write command from an old topology should be forwarded unless it's a write and the context is transactional
-                  if (command instanceof WriteCommand && ctx instanceof TxInvocationContext) {
-                     // a transactional write is always local
-                     return invokeNextInterceptor(ctx, command);
-                  } else {
-                     Set<Object> affectedKeys = getAffectedKeys(ctx, command);
-                     newTargets = new HashSet<Address>();
-                     boolean localExecutionNeeded = false;
-                     for (Object key : affectedKeys) {
-                        if (writeCh.isKeyLocalToNode(rpcManager.getAddress(), key)) {
-                           localExecutionNeeded = true;
-                        } else {
-                           newTargets.addAll(writeCh.locateOwners(key));
-                        }
-                     }
-
-                     if (localExecutionNeeded) {
-                        return invokeNextInterceptor(ctx, command);
-                     }
-                  }
-               } else if (command instanceof CommitCommand || command instanceof RollbackCommand) {
-                  // for these commands we can determine affected keys only after they are executed
-                  try {
-                     // it does not harm to attempt to execute them if it might not be the proper destination
-                     return invokeNextInterceptor(ctx, command);
-                  } finally {
-                     newTargets = new HashSet<Address>();
-                     Set<Object> affectedKeys = ((TxInvocationContext) ctx).getAffectedKeys();
-                     for (Object key : affectedKeys) {
-                        if (!writeCh.isKeyLocalToNode(rpcManager.getAddress(), key)) {
-                           newTargets.addAll(writeCh.locateOwners(key));
-                        }
-                     }
-                  }
-               }
-            } else if (command.getTopologyId() > topologyId) {
-               // this means there will be a new topology installed soon
-               stateTransferLock.waitForTopology(command.getTopologyId());
-
-               // proceed normally
-            } else {
-               // proceed normally
-            }
 
-            // no special handling was needed, invoke normally (and do not forward)
-            return invokeNextInterceptor(ctx, command);
-         } finally {
-            if (isTxCommand) {
-               stateTransferLock.transactionsSharedUnlock();
+      // remote/forwarded command
+      int cmdTopologyId = command.getTopologyId();
+      stateTransferLock.waitForTransactionData(cmdTopologyId);
+
+      // TODO we may need to skip local invocation for read/write/tx commands if the command is too old and none of its keys are local
+      Object localResult = invokeNextInterceptor(ctx, command);
+
+      // forward commands with older topology ids to their new targets
+      // but we need to make sure we have the latest topology
+      CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
+      int localTopologyId = cacheTopology.getTopologyId();
+      // if it's a tx/lock/write command, forward it to the new owners
+      if (cmdTopologyId < localTopologyId) {
+         if (command instanceof TransactionBoundaryCommand || command instanceof LockControlCommand
+               || (command instanceof WriteCommand && !ctx.isInTxScope())) {
+            // We don't know the full topology history to send the command only to the new owners,
+            // but we do know two things:
+            // 1. The originator - which shouldn't receive the same command again
+            // 2. If the local topology = command topology + 1 and pendingCH = null, there are no new owners
+            ConsistentHash pendingCh = cacheTopology.getPendingCH();
+            if (pendingCh != null && cmdTopologyId < localTopologyId + 1) {
+               ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
+               Set<Object> affectedKeys = getAffectedKeys(ctx, command);
+               Set<Address> newTargets = writeCh.locateAllOwners(affectedKeys);
+               newTargets.remove(rpcManager.getAddress());
+               if (!newTargets.isEmpty()) {
+                  // Update the topology id to prevent cycles
+                  command.setTopologyId(localTopologyId);
+                  log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
+                  // TODO find a way to forward the command async if it was received async
+                  rpcManager.invokeRemotely(newTargets, command, true, false);
+               }
             }
          }
-      } finally {
-         stateTransferLock.commandsSharedUnlock();
-
-         if (newTargets != null && !newTargets.isEmpty()) {
-            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
-            rpcManager.invokeRemotely(newTargets, command, true);
-         }
       }
+
+      return localResult;
    }
 
    @SuppressWarnings(""unchecked"")",2012-09-28T09:43:46Z,115
"@@ -27,33 +27,44 @@
 import org.infinispan.factories.scopes.Scopes;
 
 /**
- * // TODO: Document this
+ * We use the state transfer lock for three different things:
+ * <ol>
+ *    <li>We don't want to execute a command until we have the transaction table for that topology id.
+ *    For this purpose it works like a latch, commands wait on the latch and state transfer opens the latch
+ *    when it has received all the transaction data for that topology id.</li>
+ *    <li>Do not write anything to the data container in a segment that we have already removed.
+ *    For this purpose, ownership checks and data container writes acquire a shared lock, and
+ *    the segment removal acquires an exclusive lock.</li>
+ *    <li>We want to handle state requests only after we have installed the same topology id, because
+ *    this guarantees that we also have installed the corresponding view id and we have all the joiners
+ *    in our JGroups view. Here it works like a latch as well, state requests wait on the latch and state
+ *    transfer opens the latch when it has received all the transaction data for that topology id.</li>
+ * </ol>
  *
  * @author anistor@redhat.com
+ * @author Dan Berindei
  * @since 5.2
  */
 @Scope(Scopes.NAMED_CACHE)
 public interface StateTransferLock {
 
-   void transactionsSharedLock();
+   // topology change lock
+   void acquireExclusiveTopologyLock();
 
-   void transactionsSharedUnlock();
+   void releaseExclusiveTopologyLock();
 
-   void transactionsExclusiveLock();
+   void acquireSharedTopologyLock();
 
-   void transactionsExclusiveUnlock();
+   void releaseSharedTopologyLock();
 
-   void commandsExclusiveLock();
+   // transaction data latch
+   void transactionDataReceived(int topologyId);
 
-   void commandsExclusiveUnlock();
+   void waitForTransactionData(int expectedTopologyId) throws InterruptedException;
 
-   void commandsSharedLock();
-
-   void commandsSharedUnlock();
-
-   int getTopologyId();
-
-   void setTopologyId(int topologyId);
+   // topology installation latch
+   // TODO move this to Cluster/LocalTopologyManagerImpl and don't start requesting state until every node has the jgroups view with the local node
+   void topologyInstalled(int topologyId);
 
    void waitForTopology(int expectedTopologyId) throws InterruptedException;
 }
\ No newline at end of file",2012-09-28T09:43:46Z,122
"@@ -30,69 +30,69 @@
 import org.infinispan.util.logging.LogFactory;
 
 /**
- * // TODO: Document this
+ * {@code StateTransferLock} implementation.
  *
  * @author anistor@redhat.com
+ * @author Dan Berindei
  * @since 5.2
  */
 public class StateTransferLockImpl implements StateTransferLock {
    private static final Log log = LogFactory.getLog(StateTransferLockImpl.class);
 
-   private final ReadWriteLock transactionTableLock = new ReentrantReadWriteLock();
-
-   private final ReadWriteLock commandLock = new ReentrantReadWriteLock();
+   private final ReadWriteLock ownershipLock = new ReentrantReadWriteLock();
 
    private volatile int topologyId;
-
    private final Object topologyLock = new Object();
 
-   @Override
-   public void transactionsSharedLock() {
-      transactionTableLock.readLock().lock();
-   }
-
-   @Override
-   public void transactionsSharedUnlock() {
-      transactionTableLock.readLock().unlock();
-   }
+   private volatile int transactionDataTopologyId;
+   private final Object transactionDataLock = new Object();
 
    @Override
-   public void transactionsExclusiveLock() {
-      transactionTableLock.writeLock().lock();
+   public void acquireExclusiveTopologyLock() {
+      ownershipLock.writeLock().lock();
    }
 
    @Override
-   public void transactionsExclusiveUnlock() {
-      transactionTableLock.writeLock().unlock();
+   public void releaseExclusiveTopologyLock() {
+      ownershipLock.writeLock().unlock();
    }
 
    @Override
-   public void commandsExclusiveLock() {
-      commandLock.writeLock().lock();
+   public void acquireSharedTopologyLock() {
+      ownershipLock.readLock().lock();
    }
 
    @Override
-   public void commandsExclusiveUnlock() {
-      commandLock.writeLock().unlock();
+   public void releaseSharedTopologyLock() {
+      ownershipLock.readLock().unlock();
    }
 
    @Override
-   public void commandsSharedLock() {
-      commandLock.readLock().lock();
+   public void transactionDataReceived(int topologyId) {
+      this.transactionDataTopologyId = topologyId;
+      synchronized (transactionDataLock) {
+         transactionDataLock.notifyAll();
+      }
    }
 
    @Override
-   public void commandsSharedUnlock() {
-      commandLock.readLock().unlock();
-   }
+   public void waitForTransactionData(int expectedTopologyId) throws InterruptedException {
+      if (transactionDataTopologyId >= expectedTopologyId)
+         return;
 
-   @Override
-   public int getTopologyId() {
-      return topologyId;
+      log.tracef(""Waiting for transaction data for topology %d, current topology is %d"", expectedTopologyId,
+            transactionDataTopologyId);
+      synchronized (transactionDataLock) {
+         // Do the comparison inside the synchronized lock
+         // otherwise the setter might be able to call notifyAll before we wait()
+         while (transactionDataTopologyId < expectedTopologyId) {
+            transactionDataLock.wait();
+         }
+      }
    }
 
    @Override
-   public void setTopologyId(int topologyId) {
+   public void topologyInstalled(int topologyId) {
       this.topologyId = topologyId;
       synchronized (topologyLock) {
          topologyLock.notifyAll();
@@ -104,7 +104,8 @@ public void waitForTopology(int expectedTopologyId) throws InterruptedException
       if (topologyId >= expectedTopologyId)
          return;
 
-      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId, topologyId);
+      log.tracef(""Waiting for topology %d to be installed, current topology is %d"", expectedTopologyId,
+            topologyId);
       synchronized (topologyLock) {
          // Do the comparison inside the synchronized lock
          // otherwise the setter might be able to call notifyAll before we wait()",2012-09-28T09:43:46Z,123
"@@ -82,8 +82,9 @@ public void testSequence1() throws ExecutionException, InterruptedException {
 
    }
 
-   // ****** This will probably always be an unsupported sequence of startup, in a single thread
-//   public void testSequence2() throws ExecutionException, InterruptedException {
+   @Test(timeOut = 60000)
+   public void testSequence2() throws ExecutionException, InterruptedException {
+      TestCacheManagerFactory.backgroundTestStarted(this);
       /*
 
       Sequence 2:
@@ -97,8 +98,8 @@ public void testSequence1() throws ExecutionException, InterruptedException {
 
        */
 
-//      doTest(false, false);
-//   }
+      doTest(false, false);
+   }
 
    @Test(timeOut = 60000)
    public void testSequence3() throws ExecutionException, InterruptedException {",2012-09-28T09:43:46Z,437
"@@ -48,13 +48,12 @@
 @CleanupAfterMethod
 public class StaleLocksWithCommitDuringStateTransferTest extends MultipleCacheManagersTest {
 
-   public static final int BLOCKING_CACHE_VIEW_ID = 1000;
    Cache<MagicKey, String> c1, c2;
 
    @Override
    protected void createCacheManagers() throws Throwable {
       Configuration cfg = TestCacheManagerFactory.getDefaultConfiguration(true, Configuration.CacheMode.DIST_SYNC);
-      cfg.setLockAcquisitionTimeout(100);
+      cfg.setSyncReplTimeout(100);
       cfg.setCacheStopTimeout(100);
       EmbeddedCacheManager cm1 = TestCacheManagerFactory.createClusteredCacheManager(cfg);
       EmbeddedCacheManager cm2 = TestCacheManagerFactory.createClusteredCacheManager(cfg);
@@ -107,15 +106,19 @@ public void run() {
                // Before calling commit we block transactions on one of the nodes to simulate a state transfer
                final StateTransferLock blockFirst = TestingUtil.extractComponent(failOnOriginator ? c1 : c2, StateTransferLock.class);
                final StateTransferLock blockSecond = TestingUtil.extractComponent(failOnOriginator ? c2 : c1, StateTransferLock.class);
-               blockFirst.transactionsExclusiveLock();
 
-               commitLatch.countDown();
+               try {
+                  blockFirst.acquireExclusiveTopologyLock();
+                  blockSecond.acquireExclusiveTopologyLock();
 
-               // should be much larger than the lock acquisition timeout
-               Thread.sleep(1000);
-               blockSecond.transactionsExclusiveLock();
-               blockFirst.transactionsExclusiveUnlock();
-               blockSecond.transactionsExclusiveUnlock();
+                  commitLatch.countDown();
+
+                  // should be much larger than the lock acquisition timeout
+                  Thread.sleep(1000);
+               } finally {
+                  blockSecond.releaseExclusiveTopologyLock();
+                  blockFirst.releaseExclusiveTopologyLock();
+               }
             } catch (Throwable t) {
                log.errorf(t, ""Error blocking/unblocking transactions"");
             }",2012-09-28T09:43:46Z,232
"@@ -181,9 +181,7 @@ public Iterator<InternalCacheEntry> answer(InvocationOnMock invocation) {
          // expected
       }
 
-      InOrder stateTransferLockVerifier = inOrder(stateTransferLock);
-      stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveLock();
-      stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveUnlock();
+      verifyNoMoreInteractions(stateTransferLock);
 
       stateProvider.startOutboundTransfer(new TestAddress(5), 1, Collections.singleton(0));
 
@@ -284,9 +282,7 @@ public Iterator<InternalCacheEntry> answer(InvocationOnMock invocation) {
          // expected
       }
 
-      InOrder stateTransferLockVerifier = inOrder(stateTransferLock);
-      stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveLock();
-      stateTransferLockVerifier.verify(stateTransferLock).transactionsExclusiveUnlock();
+      verifyNoMoreInteractions(stateTransferLock);
 
       stateProvider.startOutboundTransfer(new TestAddress(5), 1, Collections.singleton(0));
 ",2012-09-28T09:43:46Z,57
"@@ -88,6 +88,8 @@
 import org.infinispan.util.concurrent.locks.LockManager;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
+import org.infinispan.xsite.BackupSender;
+import org.infinispan.xsite.XSiteAdminCommand;
 
 import javax.transaction.xa.Xid;
 import java.util.Collection;
@@ -130,6 +132,7 @@ public class CommandsFactoryImpl implements CommandsFactory {
    private InternalEntryFactory entryFactory;
    private MapReduceManager mapReduceManager;
    private StateTransferManager stateTransferManager;
+   private BackupSender backupSender;
 
    private Map<Byte, ModuleCommandInitializer> moduleCommandInitializers;
 
@@ -139,7 +142,8 @@ public void setupDependencies(DataContainer container, CacheNotifier notifier, C
                                  InvocationContextContainer icc, TransactionTable txTable, Configuration configuration,
                                  @ComponentName(KnownComponentNames.MODULE_COMMAND_INITIALIZERS) Map<Byte, ModuleCommandInitializer> moduleCommandInitializers,
                                  RecoveryManager recoveryManager, StateProvider stateProvider, StateConsumer stateConsumer,
-                                 LockManager lockManager, InternalEntryFactory entryFactory, MapReduceManager mapReduceManager, StateTransferManager stm) {
+                                 LockManager lockManager, InternalEntryFactory entryFactory, MapReduceManager mapReduceManager,
+                                 StateTransferManager stm, BackupSender backupSender) {
       this.dataContainer = container;
       this.notifier = notifier;
       this.cache = cache;
@@ -156,6 +160,7 @@ public void setupDependencies(DataContainer container, CacheNotifier notifier, C
       this.entryFactory = entryFactory;
       this.mapReduceManager = mapReduceManager;
       this.stateTransferManager = stm;
+      this.backupSender = backupSender;
    }
 
    @Start(priority = 1)
@@ -432,6 +437,9 @@ public void initializeReplicableCommand(ReplicableCommand c, boolean isRemote) {
          case CreateCacheCommand.COMMAND_ID:
             CreateCacheCommand createCacheCommand = (CreateCacheCommand)c;
             createCacheCommand.init(cache.getCacheManager());
+         case XSiteAdminCommand.COMMAND_ID:
+            XSiteAdminCommand xSiteAdminCommand = (XSiteAdminCommand)c;
+            xSiteAdminCommand.init(backupSender);
          default:
             ModuleCommandInitializer mci = moduleCommandInitializers.get(c.getCommandId());
             if (mci != null) {",2012-10-19T19:37:36Z,111
"@@ -63,6 +63,7 @@
 import org.infinispan.statetransfer.StateRequestCommand;
 import org.infinispan.statetransfer.StateResponseCommand;
 import org.infinispan.topology.CacheTopologyControlCommand;
+import org.infinispan.xsite.XSiteAdminCommand;
 
 import java.util.Map;
 
@@ -231,6 +232,9 @@ public CacheRpcCommand fromStream(byte id, Object[] parameters, byte type, Strin
             case CreateCacheCommand.COMMAND_ID:
                command = new CreateCacheCommand(cacheName);   
                break;
+            case XSiteAdminCommand.COMMAND_ID:
+               command = new XSiteAdminCommand(cacheName);
+               break;
             default:
                throw new CacheException(""Unknown command id "" + id + ""!"");
          }",2012-10-19T19:37:36Z,632
"@@ -120,9 +120,6 @@ public <T> T construct(Class<T> componentType) {
          } else if (componentType.equals(TransactionFactory.class)) {
             return (T) new TransactionFactory();
          } else if (componentType.equals(BackupSender.class)) {
-            if (globalConfiguration.sites() == null || globalConfiguration.sites().localSite() == null) {
-               throw new ConfigurationException(""Local site must be defined in the global configuration when using cross site replication."");
-            }
             return (T) new BackupSenderImpl(globalConfiguration.sites().localSite());
          }
       }",2012-10-19T19:37:36Z,494
"@@ -31,7 +31,7 @@
 import org.infinispan.manager.DefaultCacheManager;
 import org.infinispan.upgrade.RollingUpgradeManager;
 import org.infinispan.transaction.xa.recovery.RecoveryAdminOperations;
-import org.infinispan.xsite.CrossSiteReplicationOperations;
+import org.infinispan.xsite.XSiteAdminOperations;
 
 /**
  * An internal factory for constructing Caches.  Used by the {@link DefaultCacheManager}, this is not intended as public
@@ -104,7 +104,7 @@ private void bootstrap(String cacheName, AdvancedCache<?, ?> cache, Configuratio
          componentRegistry.registerComponent(new RecoveryAdminOperations(), RecoveryAdminOperations.class.getName(), true);
       }
       if (!configuration.sites().inUseBackups().isEmpty()) {
-         componentRegistry.registerComponent(new CrossSiteReplicationOperations(), CrossSiteReplicationOperations.class.getName(), true);
+         componentRegistry.registerComponent(new XSiteAdminOperations(), XSiteAdminOperations.class.getName(), true);
       }
       // The RollingUpgradeManager should always be added so it is registered in JMX.
       componentRegistry.registerComponent(new RollingUpgradeManager(), RollingUpgradeManager.class.getName(), true);",2012-10-19T19:37:36Z,633
"@@ -51,6 +51,7 @@
 import org.infinispan.statetransfer.StateRequestCommand;
 import org.infinispan.statetransfer.StateResponseCommand;
 import org.infinispan.util.Util;
+import org.infinispan.xsite.XSiteAdminCommand;
 
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
@@ -88,7 +89,7 @@ public Set<Class<? extends CacheRpcCommand>> getTypeClasses() {
             TxCompletionNotificationCommand.class, GetInDoubtTransactionsCommand.class,
             GetInDoubtTxInfoCommand.class, CompleteTransactionCommand.class,
             VersionedPrepareCommand.class, CreateCacheCommand.class,
-            VersionedCommitCommand.class);
+            VersionedCommitCommand.class, XSiteAdminCommand.class);
       // Only interested in cache specific replicable commands
       coreCommands.addAll(gcr.getModuleProperties().moduleCacheRpcCommands());
       return coreCommands;",2012-10-19T19:37:36Z,634
"@@ -27,6 +27,7 @@
 import org.infinispan.remoting.transport.BackupResponse;
 
 import javax.transaction.Transaction;
+import java.util.Map;
 
 /**
  * Component responsible with sending backup data to remote sites. The send operation is executed async, it's up to the
@@ -57,9 +58,16 @@ public interface BackupSender {
 
    void processResponses(BackupResponse backupResponse, VisitableCommand command, Transaction transaction) throws Throwable;
 
+   OfflineStatus getOfflineStatus(String siteName);
+
+   /**
+    * Returns a Map having as entries the site names and as value Boolean.TRUE if the site is online and Boolean.FALSE
+    * if it is offline.
+    */
+   Map<String, Boolean> status();
+
    public enum BringSiteOnlineResponse {
       NO_SUCH_SITE,
-      OFFLINE_NOT_ENABLED,
       ALREADY_ONLINE,
       BROUGHT_ONLINE
    }
@@ -68,4 +76,12 @@ public enum BringSiteOnlineResponse {
     * Brings a site with the given name back online.
     */
    BringSiteOnlineResponse bringSiteOnline(String siteName);
+
+   public enum TakeSiteOfflineResponse {
+      NO_SUCH_SITE,
+      ALREADY_OFFLINE,
+      TAKEN_OFFLINE
+   }
+
+   TakeSiteOfflineResponse takeSiteOffline(String siteName);
 }",2012-10-19T19:37:36Z,635
"@@ -104,10 +104,8 @@ public void start() {
             CustomFailurePolicy instance = Util.getInstance(backupPolicy, globalConfig.classLoader());
             siteFailurePolicy.put(bc.site(), instance);
          }
-         if (bc.takeOffline().enabled()) {
-            OfflineStatus offline = new OfflineStatus(bc.takeOffline());
-            offlineStatus.put(bc.site(), offline);
-         }
+         OfflineStatus offline = new OfflineStatus(bc.takeOffline());
+         offlineStatus.put(bc.site(), offline);
       }
    }
 
@@ -140,11 +138,14 @@ private void updateOfflineSites(BackupResponse backupResponse) {
       Set<String> communicationErrors = backupResponse.getCommunicationErrors();
       for (Map.Entry<String, OfflineStatus> statusEntry : offlineStatus.entrySet()) {
          OfflineStatus status = statusEntry.getValue();
+         if (!status.isEnabled()) {
+            continue;
+         }
          if (communicationErrors.contains(statusEntry.getKey())) {
             status.updateOnCommunicationFailure(backupResponse.getSendTimeMillis());
             log.tracef(""OfflineStatus updated %s"", status);
          } else if(!status.isOffline()) {
-            status.updateOnCommunicationSuccess();
+             status.reset();
          }
       }
    }
@@ -177,13 +178,18 @@ public BringSiteOnlineResponse bringSiteOnline(String siteName) {
          return BringSiteOnlineResponse.NO_SUCH_SITE;
       } else {
          OfflineStatus offline = offlineStatus.get(siteName);
-         if (offline == null) {
-            log.tracef(""The site %s doesn't have enabled the 'takeOffline' functionality"", siteName);
-            return BringSiteOnlineResponse.OFFLINE_NOT_ENABLED;
-         } else {
-            boolean broughtOnline = offline.bringOnline();
-            return broughtOnline ? BringSiteOnlineResponse.BROUGHT_ONLINE : BringSiteOnlineResponse.ALREADY_ONLINE;
-         }
+         boolean broughtOnline = offline.bringOnline();
+         return broughtOnline ? BringSiteOnlineResponse.BROUGHT_ONLINE : BringSiteOnlineResponse.ALREADY_ONLINE;
+      }
+   }
+
+   @Override
+   public TakeSiteOfflineResponse takeSiteOffline(String siteName) {
+      if (!config.sites().hasInUseBackup(siteName)) {
+         return TakeSiteOfflineResponse.NO_SUCH_SITE;
+      } else {
+         OfflineStatus offline = offlineStatus.get(siteName);
+         return offline.forceOffline() ? TakeSiteOfflineResponse.TAKEN_OFFLINE : TakeSiteOfflineResponse.ALREADY_OFFLINE;
       }
    }
 
@@ -321,4 +327,13 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand command)
    public OfflineStatus getOfflineStatus(String site) {
       return offlineStatus.get(site);
    }
+
+   @Override
+   public Map<String, Boolean> status() {
+      Map<String, Boolean> result = new HashMap<String, Boolean>(offlineStatus.size());
+      for (Map.Entry<String, OfflineStatus> os : offlineStatus.entrySet()) {
+         result.put(os.getKey(), !os.getValue().isOffline());
+      }
+      return result;
+   }
 }",2012-10-19T19:37:36Z,636
"@@ -1,46 +0,0 @@
-/*
- * JBoss, Home of Professional Open Source
- * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
- * as indicated by the @author tags. All rights reserved.
- * See the copyright.txt in the distribution for a
- * full listing of individual contributors.
- *
- * This copyrighted material is made available to anyone wishing to use,
- * modify, copy, or redistribute it subject to the terms and conditions
- * of the GNU Lesser General Public License, v. 2.1.
- * This program is distributed in the hope that it will be useful, but WITHOUT A
- * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
- * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
- * You should have received a copy of the GNU Lesser General Public License,
- * v.2.1 along with this distribution; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
- * MA  02110-1301, USA.
- */
-
-package org.infinispan.xsite;
-
-import org.infinispan.factories.annotations.Inject;
-import org.infinispan.jmx.annotations.MBean;
-import org.infinispan.jmx.annotations.ManagedOperation;
-import org.rhq.helpers.pluginAnnotations.agent.Operation;
-
-/**
- * @author Mircea Markus
- * @since 5.2
- */
-@MBean(objectName = ""XSiteAdmin"", description = ""Exposes tooling for handling backing up data to remote sites."")
-public class CrossSiteReplicationOperations {
-
-   private volatile BackupSender backupSender;
-
-   @Inject
-   public void init(BackupSender backupSender) {
-      this.backupSender = backupSender;
-   }
-
-   @Operation(displayName = ""Brings the given site back online on this node."")
-   @ManagedOperation(description = ""Brings the given site back online on this node."")
-   public String bringSiteOnline(String siteName) {
-      return backupSender.bringSiteOnline(siteName).toString();
-   }
-}",2012-10-19T19:37:36Z,637
"@@ -43,10 +43,11 @@ public class OfflineStatus {
 
    private static Log log = LogFactory.getLog(OfflineStatus.class);
 
-   private final TakeOfflineConfiguration takeOffline;
+   private volatile TakeOfflineConfiguration takeOffline;
    private boolean recordingOfflineStatus = false;
    private long firstFailureTime;
    private int failureCount;
+   private volatile boolean forceOffline = false;
 
    public OfflineStatus(TakeOfflineConfiguration takeOfflineConfiguration) {
       this.takeOffline = takeOfflineConfiguration;
@@ -61,6 +62,9 @@ public synchronized void updateOnCommunicationFailure(long sendTimeMillis) {
    }
 
    public synchronized boolean isOffline() {
+      if (forceOffline)
+         return true;
+
       if (!recordingOfflineStatus)
          return false;
 
@@ -98,17 +102,41 @@ public synchronized long millisSinceFirstFailure() {
 
    public synchronized boolean bringOnline() {
       if (!isOffline()) return false;
-      updateOnCommunicationSuccess();
+      reset();
       return true;
    }
 
-   public synchronized void updateOnCommunicationSuccess() {
+   public synchronized int getFailureCount() {
+      return failureCount;
+   }
+
+   public synchronized boolean isEnabled() {
+      return takeOffline.enabled();
+   }
+
+   /**
+    * Configures the site to use the supplied configuration for determining when to take a site offline.
+    * Also triggers a state reset.
+    */
+   public void amend(TakeOfflineConfiguration takeOffline) {
+      this.takeOffline = takeOffline;
+      reset();
+   }
+
+   public void reset() {
       recordingOfflineStatus = false;
       failureCount = 0;
+      forceOffline = false;
    }
 
-   public synchronized int getFailureCount() {
-      return failureCount;
+   public TakeOfflineConfiguration getTakeOffline() {
+      return takeOffline;
+   }
+
+   public boolean forceOffline() {
+      if (isOffline()) return false;
+      forceOffline = true;
+      return true;
    }
 
    @Override
@@ -117,7 +145,16 @@ public String toString() {
             ""takeOffline="" + takeOffline +
             "", recordingOfflineStatus="" + recordingOfflineStatus +
             "", firstFailureTime="" + firstFailureTime +
+            "", forceOffline="" + forceOffline +
             "", failureCount="" + failureCount +
             '}';
    }
+
+   public void amend(Integer afterFailures, Long minTimeToWait) {
+      TakeOfflineConfiguration existing = getTakeOffline();
+      int newAfterFailures = afterFailures == null ? existing.afterFailures() : afterFailures;
+      long newMinTieToWait = minTimeToWait == null ? existing.minTimeToWait() : minTimeToWait;
+      TakeOfflineConfiguration newConfig = new TakeOfflineConfiguration(newAfterFailures, newMinTieToWait);
+      amend(newConfig);
+   }
 }",2012-10-19T19:37:36Z,638
"@@ -0,0 +1,136 @@
+/*
+ * JBoss, Home of Professional Open Source
+ *  Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ *  contributors as indicated by the @author tags. All rights reserved
+ *  See the copyright.txt in the distribution for a full listing of
+ *  individual contributors.
+ *
+ *  This is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU Lesser General Public License as
+ *  published by the Free Software Foundation; either version 2.1 of
+ *  the License, or (at your option) any later version.
+ *
+ *  This software is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ *  Lesser General Public License for more details.
+ *
+ *  You should have received a copy of the GNU Lesser General Public
+ *  License along with this software; if not, write to the Free
+ *  Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ *  02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.xsite;
+
+import org.infinispan.commands.remote.BaseRpcCommand;
+import org.infinispan.context.InvocationContext;
+
+/**
+ * Command used for handling XSiteReplication administrative operations.
+ *
+ * @author Mircea Markus
+ * @since 5.2
+ */
+public class XSiteAdminCommand extends BaseRpcCommand {
+
+   public static final int COMMAND_ID = 32;
+
+   public enum AdminOperation {
+      SITE_STATUS,
+      STATUS,
+      TAKE_OFFLINE,
+      BRING_ONLINE,
+      AMEND_TAKE_OFFLINE;
+   }
+
+   public enum Status {
+      OFFLINE, ONLINE
+   }
+
+   private String siteName;
+   private Integer afterFailures;
+   private Long minTimeToWait;
+   private AdminOperation adminOperation;
+
+   private BackupSender backupSender;
+
+   public XSiteAdminCommand(String cacheName) {
+      super(cacheName);// For command id uniqueness test
+   }
+
+   public XSiteAdminCommand(String cacheName, String siteName, AdminOperation op, Integer afterFailures, Long minTimeToWait) {
+      this(cacheName);
+      this.siteName = siteName;
+      this.adminOperation = op;
+      this.afterFailures = afterFailures;
+      this.minTimeToWait = minTimeToWait;
+   }
+
+   public void init(BackupSender backupSender) {
+      this.backupSender = backupSender;
+   }
+
+   @Override
+   public Object perform(InvocationContext ctx) throws Throwable {
+      switch (adminOperation) {
+         case SITE_STATUS: {
+            if (backupSender.getOfflineStatus(siteName).isOffline()) {
+               return Status.OFFLINE;
+            } else {
+               return Status.ONLINE;
+            }
+         }
+         case STATUS: {
+            return backupSender.status();
+         }
+         case TAKE_OFFLINE: {
+            return backupSender.takeSiteOffline(siteName);
+         }
+         case BRING_ONLINE: {
+            return backupSender.bringSiteOnline(siteName);
+         }
+         case AMEND_TAKE_OFFLINE: {
+            backupSender.getOfflineStatus(siteName).amend(afterFailures, minTimeToWait);
+            return null;
+         }
+         default: {
+            throw new IllegalStateException(""Unhandled admin operation "" + adminOperation);
+         }
+      }
+   }
+
+   @Override
+   public byte getCommandId() {
+      return COMMAND_ID;
+   }
+
+   @Override
+   public Object[] getParameters() {
+      return new Object[]{siteName, afterFailures, minTimeToWait, adminOperation};
+   }
+
+   @Override
+   public void setParameters(int commandId, Object[] parameters) {
+      this.siteName = (String) parameters[0];
+      this.afterFailures = (Integer)parameters[1];
+      this.minTimeToWait = (Long)parameters[2];
+      this.adminOperation = (AdminOperation)parameters[3];
+   }
+
+   @Override
+   public final boolean isReturnValueExpected() {
+      return true;
+   }
+
+   @Override
+   public String toString() {
+      return ""XSiteAdminCommand{"" +
+            ""siteName='"" + siteName + '\'' +
+            "", afterFailures="" + afterFailures +
+            "", minTimeToWait="" + minTimeToWait +
+            "", adminOperation="" + adminOperation +
+            "", backupSender="" + backupSender +
+            '}';
+   }
+}",2012-10-19T19:37:36Z,639
"@@ -0,0 +1,283 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.xsite;
+
+import org.infinispan.Cache;
+import org.infinispan.factories.annotations.Inject;
+import org.infinispan.jmx.annotations.MBean;
+import org.infinispan.jmx.annotations.ManagedOperation;
+import org.infinispan.remoting.responses.Response;
+import org.infinispan.remoting.responses.SuccessfulResponse;
+import org.infinispan.remoting.rpc.RpcManager;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.rhq.helpers.pluginAnnotations.agent.Operation;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * Managed bean exposing sys admin operations for Cross-Site replication functionality.
+ *
+ * @author Mircea Markus
+ * @since 5.2
+ */
+@MBean(objectName = ""XSiteAdmin"", description = ""Exposes tooling for handling backing up data to remote sites."")
+public class XSiteAdminOperations {
+
+   private static Log log = LogFactory.getLog(XSiteAdminOperations.class);
+
+   public static final String ONLINE = ""online"";
+   public static final String OFFLINE = ""offline"";
+   public static final String SUCCESS = ""ok"";
+
+   private RpcManager rpcManager;
+   private Cache cache;
+
+   private volatile BackupSender backupSender;
+
+   @Inject
+   public void init(RpcManager rpcManager, BackupSender backupSender, Cache cache) {
+      this.backupSender = backupSender;
+      this.rpcManager = rpcManager;
+      this.backupSender = backupSender;
+      this.cache = cache;
+   }
+
+   @Operation(displayName = ""Check whether the given backup site is offline or not."")
+   @ManagedOperation(description = ""Check whether the given backup site is offline or not."")
+   public String status(String site) {
+      //also consider local node
+      OfflineStatus offlineStatus = backupSender.getOfflineStatus(site);
+      if (offlineStatus == null)
+         return ""Incorrect site name: "" + offlineStatus;
+      log.tracef(""This node's status is %s"", offlineStatus);
+
+      XSiteAdminCommand command = new XSiteAdminCommand(cache.getName(), site, XSiteAdminCommand.AdminOperation.SITE_STATUS, null, null);
+      Map<Address, Response> responses = invokeRemotely(command);
+      List<Address> online = new ArrayList<Address>(responses.size());
+      List<Address> offline = new ArrayList<Address>(responses.size());
+      List<Address> failed = new ArrayList<Address>(responses.size());
+      for (Map.Entry<Address, Response> e : responses.entrySet()) {
+         if (!e.getValue().isSuccessful() || !e.getValue().isValid()) {
+            failed.add(e.getKey());
+            continue;
+         }
+         SuccessfulResponse response = (SuccessfulResponse) e.getValue();
+         log.tracef(""Got status %s from node %s"", response.getResponseValue(), e.getKey());
+         if (response.getResponseValue() == XSiteAdminCommand.Status.OFFLINE) {
+            offline.add(e.getKey());
+         } else if (response.getResponseValue() == XSiteAdminCommand.Status.ONLINE) {
+            online.add(e.getKey());
+         } else {
+            throw new IllegalStateException(""Unknown response: "" + response.getResponseValue());
+         }
+      }
+      if (!failed.isEmpty()) {
+         return rpcError(failed, ""Could not query nodes "");
+      }
+
+      if (offlineStatus.isOffline()) {
+         offline.add(rpcManager.getAddress());
+      } else {
+         online.add(rpcManager.getAddress());
+      }
+
+      if (offline.isEmpty()) {
+         return ONLINE;
+      }
+      if (online.isEmpty()) {
+         return OFFLINE;
+      }
+      return ""Site appears online on nodes:"" + online + "" and offline on nodes: "" + offline;
+   }
+
+   @Operation(displayName = ""Returns the the status(offline/online) of all the configured backup sites."")
+   @ManagedOperation(description = ""Returns the the status(offline/online) of all the configured backup sites."")
+   public String status() {
+      //also consider local node
+      Map<String, Boolean> localNodeStatus = backupSender.status();
+      XSiteAdminCommand command = new XSiteAdminCommand(cache.getName(), null, XSiteAdminCommand.AdminOperation.STATUS, null, null);
+      Map<Address, Response> responses = invokeRemotely(command);
+      List<Address> errors = checkForErrors(responses);
+      if (!errors.isEmpty()) {
+         return rpcError(errors, ""Failure invoking 'status()' on nodes: "");
+      }
+      //<site name, nodes where it failed>
+      Map<String, List<Address>> result = new HashMap<String, List<Address>>();
+      for (Map.Entry<String, Boolean> e : localNodeStatus.entrySet()) {
+         ArrayList<Address> failedSites = new ArrayList<Address>();
+         result.put(e.getKey(), failedSites);
+         if (!e.getValue()) {
+            failedSites.add(rpcManager.getAddress());
+         }
+      }
+      for (Map.Entry<Address, Response> response : responses.entrySet()) {
+         Map<String, Boolean> status = (Map<String, Boolean>) ((SuccessfulResponse)response.getValue()).getResponseValue();
+         for (Map.Entry<String, Boolean> entry : status.entrySet()) {
+            List<Address> addresses = result.get(entry.getKey());
+            if (addresses == null)
+               throw new IllegalStateException(""All sites must be defined on all the nodes of the cluster!"");
+            if (!entry.getValue()) {
+               addresses.add(rpcManager.getAddress());
+            }
+         }
+      }
+
+      int clusterSize = rpcManager.getTransport().getMembers().size();
+
+      StringBuilder resultStr = new StringBuilder();
+      //now generate the final response
+      boolean first = true;
+      for (Map.Entry<String, List<Address>> e : result.entrySet()) {
+         if (!first) {
+            resultStr.append(""\n"");
+         } else first = false;
+         resultStr.append(e.getKey()).append(""["");
+         List<Address> value = e.getValue();
+         if (value.isEmpty()) {
+            resultStr.append(""ONLINE"");
+         } else if (value.size() == clusterSize) {
+            resultStr.append(""OFFLINE"");
+         } else {
+            resultStr.append(""MIXED, offline on nodes: "").append(value);
+         }
+         resultStr.append(""]"");
+      }
+      return resultStr.toString();
+   }
+
+   @Operation(displayName = ""Takes this site offline in all nodes in the cluster."")
+   @ManagedOperation(description = ""Takes this site offline in all nodes in the cluster."")
+   public String takeSiteOffline(String site) {
+      OfflineStatus offlineStatus = backupSender.getOfflineStatus(site);
+      if (offlineStatus == null)
+         return incorrectSiteName(site);
+      backupSender.takeSiteOffline(site);
+      log.tracef(""Is site offline in node %s? %s"", rpcManager.getAddress(), offlineStatus.isOffline());
+
+      XSiteAdminCommand command = new XSiteAdminCommand(cache.getName(), site, XSiteAdminCommand.AdminOperation.TAKE_OFFLINE, null, null);
+      Map<Address, Response> responses = invokeRemotely(command);
+
+      List<Address> failed = checkForErrors(responses);
+
+      String prefix = ""Could not take the site offline on nodes:"";
+      return returnFailureOrSuccess(failed, prefix);
+   }
+
+   @Operation(displayName = ""Amends the values for 'afterFailures' for the 'TakeOffline' functionality on all the nodes in the cluster."")
+   @ManagedOperation(description = ""Amends the values for 'afterFailures' for the 'TakeOffline' functionality on all the nodes in the cluster."")
+   public String setTakeOfflineAfterFailures(String site, int afterFailures) {
+      return takeOffline(site, afterFailures, null);
+   }
+
+   @Operation(displayName = ""Amends the values for 'minTimeToWait' for the 'TakeOffline' functionality on all the nodes in the cluster."")
+   @ManagedOperation(description = ""Amends the values for 'minTimeToWait' for the 'TakeOffline' functionality on all the nodes in the cluster."")
+   public String setTakeOfflineMinTimeToWait(String site, long minTimeToWait) {
+      return takeOffline(site, null, minTimeToWait);
+   }
+
+   @Operation(displayName = ""Amends the values for 'TakeOffline' functionality on all the nodes in the cluster."")
+   @ManagedOperation(description = ""Amends the values for 'TakeOffline' functionality on all the nodes in the cluster."")
+   public String amendTakeOffline(String site, int afterFailures, long minTimeToWait) {
+      return takeOffline(site, afterFailures, minTimeToWait);
+   }
+
+   @Operation(displayName = ""Returns the value of the 'minTimeToWait' for the 'TakeOffline' functionality."")
+   @ManagedOperation(description = ""Returns the value of the 'minTimeToWait' for the 'TakeOffline' functionality."")
+   public String getTakeOfflineMinTimeToWait(String site) {
+      OfflineStatus offlineStatus = backupSender.getOfflineStatus(site);
+      if (offlineStatus == null) return incorrectSiteName(site);
+      return String.valueOf(offlineStatus.getTakeOffline().minTimeToWait());
+   }
+
+   @Operation(displayName = ""Returns the value of the 'afterFailures' for the 'TakeOffline' functionality."")
+   @ManagedOperation(description = ""Returns the value of the 'afterFailures' for the 'TakeOffline' functionality."")
+   public String getTakeOfflineAfterFailures(String site) {
+      OfflineStatus offlineStatus = backupSender.getOfflineStatus(site);
+      if (offlineStatus == null) return incorrectSiteName(site);
+      return String.valueOf(offlineStatus.getTakeOffline().afterFailures());
+   }
+
+   @Operation(displayName = ""Brings the given site back online on all the cluster."")
+   @ManagedOperation(description = ""Brings the given site back online on all the cluster."")
+   public String bringSiteOnline(String site) {
+      OfflineStatus offlineStatus = backupSender.getOfflineStatus(site);
+      if (offlineStatus == null)
+         return ""Incorrect site name: "" + offlineStatus;
+      backupSender.bringSiteOnline(site);
+
+      XSiteAdminCommand command = new XSiteAdminCommand(cache.getName(), site, XSiteAdminCommand.AdminOperation.BRING_ONLINE, null, null);
+      Map<Address, Response> responses = invokeRemotely(command);
+
+      List<Address> failed = checkForErrors(responses);
+
+      return returnFailureOrSuccess(failed, ""Could not take the site online on nodes:"");
+   }
+
+   private List<Address> checkForErrors(Map<Address, Response> responses) {
+      List<Address> failed = new ArrayList<Address>(responses.size());
+      for (Map.Entry<Address, Response> e : responses.entrySet()) {
+         if (!e.getValue().isSuccessful() || !e.getValue().isValid()) {
+            failed.add(e.getKey());
+         }
+      }
+      return failed;
+   }
+
+   private String takeOffline(String site, Integer afterFailures, Long minTimeToWait) {
+      OfflineStatus offlineStatus = backupSender.getOfflineStatus(site);
+      if (offlineStatus == null)
+         return incorrectSiteName(site);
+
+      XSiteAdminCommand command = new XSiteAdminCommand(cache.getName(), site, XSiteAdminCommand.AdminOperation.AMEND_TAKE_OFFLINE,
+                                                        afterFailures, minTimeToWait);
+      Map<Address, Response> responses = invokeRemotely(command);
+
+      //also amend locally
+      offlineStatus.amend(afterFailures,minTimeToWait);
+
+      List<Address> failed = checkForErrors(responses);
+
+      return returnFailureOrSuccess(failed, ""Could not amend for nodes:"");
+   }
+
+   private String returnFailureOrSuccess(List<Address> failed, String prefix) {
+      if (!failed.isEmpty()) {
+         return rpcError(failed, prefix);
+      }
+      return SUCCESS;
+   }
+
+   private String rpcError(List<Address> failed, String prefix) {
+      return prefix + failed.toString();
+   }
+
+   private String incorrectSiteName(String site) {
+      return ""Incorrect site name: "" + site;
+   }
+
+   private Map<Address, Response> invokeRemotely(XSiteAdminCommand command) {
+      return rpcManager.invokeRemotely(null, command, true, true);
+   }
+}",2012-10-19T19:37:36Z,640
"@@ -0,0 +1,109 @@
+/*
+ * JBoss, Home of Professional Open Source
+ *  Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ *  contributors as indicated by the @author tags. All rights reserved
+ *  See the copyright.txt in the distribution for a full listing of
+ *  individual contributors.
+ *
+ *  This is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU Lesser General Public License as
+ *  published by the Free Software Foundation; either version 2.1 of
+ *  the License, or (at your option) any later version.
+ *
+ *  This software is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ *  Lesser General Public License for more details.
+ *
+ *  You should have received a copy of the GNU Lesser General Public
+ *  License along with this software; if not, write to the Free
+ *  Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ *  02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.xsite;
+
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.cache.TakeOfflineConfiguration;
+import org.testng.annotations.Test;
+
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * @author Mircea Markus
+ * @since 5.2
+ */
+@Test(groups = ""xsite"", testName = ""xsite.admin.XSiteAdminOperationsTest"")
+public class XSiteAdminOperationsTest extends AbstractTwoSitesTest {
+
+   @Override
+   protected ConfigurationBuilder getNycActiveConfig() {
+      return getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+   }
+
+   @Override
+   protected ConfigurationBuilder getLonActiveConfig() {
+      return getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+   }
+
+   public void testSiteStatus() {
+      assertEquals(admin(""LON"", 0).status(""NYC""), XSiteAdminOperations.ONLINE);
+      assertEquals(admin(""LON"", 1).status(""NYC""), XSiteAdminOperations.ONLINE);
+
+      assertEquals(XSiteAdminOperations.SUCCESS, admin(""LON"", 1).takeSiteOffline(""NYC""));
+
+      assertEquals(admin(""LON"", 0).status(""NYC""), XSiteAdminOperations.OFFLINE);
+      assertEquals(admin(""LON"", 1).status(""NYC""), XSiteAdminOperations.OFFLINE);
+
+      assertEquals(XSiteAdminOperations.SUCCESS, admin(""LON"", 1).bringSiteOnline(""NYC""));
+      assertEquals(admin(""LON"", 0).status(""NYC""), XSiteAdminOperations.ONLINE);
+      assertEquals(admin(""LON"", 1).status(""NYC""), XSiteAdminOperations.ONLINE);
+   }
+
+   public void amendTakeOffline() {
+      assertEquals(admin(""LON"", 0).status(""NYC""), XSiteAdminOperations.ONLINE);
+      assertEquals(admin(""LON"", 1).status(""NYC""), XSiteAdminOperations.ONLINE);
+
+      BackupSenderImpl bs = backupSender(""LON"", 0);
+      OfflineStatus offlineStatus = bs.getOfflineStatus(""NYC"");
+      assertEquals(offlineStatus.getTakeOffline(), new TakeOfflineConfiguration(0, 0));
+
+      assertEquals(XSiteAdminOperations.SUCCESS, admin(""LON"", 1).amendTakeOffline(""NYC"", 7, 12));
+      assertEquals(offlineStatus.getTakeOffline(), new TakeOfflineConfiguration(7, 12));
+
+      assertEquals(XSiteAdminOperations.SUCCESS, admin(""LON"", 1).setTakeOfflineAfterFailures(""NYC"", 8));
+      assertEquals(offlineStatus.getTakeOffline(), new TakeOfflineConfiguration(8, 12));
+
+      assertEquals(XSiteAdminOperations.SUCCESS, admin(""LON"", 1).setTakeOfflineMinTimeToWait(""NYC"", 13));
+      assertEquals(offlineStatus.getTakeOffline(), new TakeOfflineConfiguration(8, 13));
+
+      assertEquals(admin(""LON"", 0).getTakeOfflineAfterFailures(""NYC""), ""8"");
+      assertEquals(admin(""LON"", 0).getTakeOfflineMinTimeToWait(""NYC""), ""13"");
+      assertEquals(admin(""LON"", 1).getTakeOfflineAfterFailures(""NYC""), ""8"");
+      assertEquals(admin(""LON"", 1).getTakeOfflineMinTimeToWait(""NYC""), ""13"");
+   }
+
+   public void testStatus() {
+      assertEquals(admin(""LON"", 0).status(), ""NYC[ONLINE]"");
+      assertEquals(admin(""LON"", 1).status(), ""NYC[ONLINE]"");
+
+      assertEquals(XSiteAdminOperations.SUCCESS, admin(""LON"", 1).takeSiteOffline(""NYC""));
+
+      assertEquals(admin(""LON"", 0).status(), ""NYC[OFFLINE]"");
+      assertEquals(admin(""LON"", 1).status(), ""NYC[OFFLINE]"");
+
+      assertEquals(XSiteAdminOperations.SUCCESS, admin(""LON"", 1).bringSiteOnline(""NYC""));
+      assertEquals(admin(""LON"", 0).status(), ""NYC[ONLINE]"");
+      assertEquals(admin(""LON"", 1).status(), ""NYC[ONLINE]"");
+
+   }
+
+   private BackupSenderImpl backupSender(String site, int cache) {
+      return (BackupSenderImpl) cache(site, cache).getAdvancedCache().getComponentRegistry().getComponent(BackupSender.class);
+   }
+
+   private XSiteAdminOperations admin(String site, int cache) {
+      return cache(site, cache).getAdvancedCache().getComponentRegistry().getComponent(XSiteAdminOperations.class);
+   }
+}",2012-10-19T19:37:36Z,641
"@@ -68,7 +68,7 @@ public boolean isSatisfied() throws Exception {
    public void testFailureBasedOnly() throws Throwable {
       final OfflineStatus offlineStatus = new OfflineStatus(new TakeOfflineConfiguration(10, 0));
       test(offlineStatus);
-      offlineStatus.updateOnCommunicationSuccess();
+      offlineStatus.reset();
       test(offlineStatus);
    }
 ",2012-10-19T19:37:36Z,642
"@@ -53,6 +53,7 @@
  *
  * @author <a href=""mailto:manik@jboss.org"">Manik Surtani (manik@jboss.org)</a>
  * @author Mircea.Markus@jboss.com
+ * @author Marko Luksa
  * @since 4.0
  */
 @DefaultFactoryFor(classes = InterceptorChain.class)
@@ -90,21 +91,18 @@ public InterceptorChain buildInterceptorChain() {
       boolean needsVersionAwareComponents = configuration.transaction().transactionMode().isTransactional() && configuration.locking().writeSkewCheck() &&
             configuration.transaction().lockingMode() == LockingMode.OPTIMISTIC && configuration.versioning().enabled();
 
+      InterceptorChain interceptorChain = new InterceptorChain(componentRegistry.getComponentMetadataRepo());
+      // add the interceptor chain to the registry first, since some interceptors may ask for it.
+      componentRegistry.registerComponent(interceptorChain, InterceptorChain.class);
+
       boolean invocationBatching = configuration.invocationBatching().enabled();
       // load the icInterceptor first
-
-      CommandInterceptor first;
       if (invocationBatching) {
-         first = createInterceptor(new BatchingInterceptor(), BatchingInterceptor.class);
+         interceptorChain.setFirstInChain(createInterceptor(new BatchingInterceptor(), BatchingInterceptor.class));
       } else {
-         first = createInterceptor(new InvocationContextInterceptor(), InvocationContextInterceptor.class);
+         interceptorChain.setFirstInChain(createInterceptor(new InvocationContextInterceptor(), InvocationContextInterceptor.class));
       }
 
-      InterceptorChain interceptorChain = new InterceptorChain(first, componentRegistry.getComponentMetadataRepo());
-
-      // add the interceptor chain to the registry first, since some interceptors may ask for it.
-      componentRegistry.registerComponent(interceptorChain, InterceptorChain.class);
-
       // add marshallable check interceptor for situations where we want to figure out before marshalling
       if (isUsingMarshalledValues(configuration) || configuration.clustering().async().asyncMarshalling()
             || configuration.clustering().async().useReplQueue() || hasAsyncStore())",2012-10-25T18:12:35Z,328
"@@ -66,8 +66,7 @@ public class InterceptorChain {
    /**
     * Constructs an interceptor chain having the supplied interceptor as first.
     */
-   public InterceptorChain(CommandInterceptor first, ComponentMetadataRepo componentMetadataRepo) {
-      this.firstInChain = first;
+   public InterceptorChain(ComponentMetadataRepo componentMetadataRepo) {
       this.componentMetadataRepo = componentMetadataRepo;
    }
 ",2012-10-25T18:12:35Z,643
"@@ -46,7 +46,8 @@ public class InterceptorChainTest {
    private static final Log log = LogFactory.getLog(InterceptorChainTest.class);
 
    public void testConcurrentAddRemove() throws Exception {
-      InterceptorChain ic = new InterceptorChain(new CallInterceptor(), new ComponentMetadataRepo());
+      InterceptorChain ic = new InterceptorChain(new ComponentMetadataRepo());
+      ic.setFirstInChain(new CallInterceptor());
       ic.addInterceptor(new ActivationInterceptor(), 1);
       CyclicBarrier barrier = new CyclicBarrier(4);
       List<Future<Void>> futures = new ArrayList<Future<Void>>(2);",2012-10-25T18:12:35Z,643
"@@ -32,6 +32,7 @@
 import org.infinispan.marshall.AdvancedExternalizer;
 import org.infinispan.marshall.Marshaller;
 import org.infinispan.remoting.transport.Transport;
+import org.jboss.marshalling.ClassResolver;
 
 import java.util.Properties;
 
@@ -108,6 +109,13 @@ public FluentGlobalConfiguration(GlobalConfiguration globalConfig) {
        * @param advancedExternalizers
        */
       <T> SerializationConfig addAdvancedExternalizer(AdvancedExternalizer<T>... advancedExternalizers);
+
+      /**
+       * Class resolver to use when unmarshallig objects.
+       *
+       * @param classResolver
+       */
+      SerializationConfig classResolver(ClassResolver classResolver);
    }
 
    /**",2012-03-19T13:24:00Z,11
"@@ -50,6 +50,7 @@
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
+import org.jboss.marshalling.ClassResolver;
 
 import javax.xml.bind.annotation.XmlAccessType;
 import javax.xml.bind.annotation.XmlAccessorType;
@@ -695,6 +696,10 @@ public List<AdvancedExternalizerConfig> getExternalizers() {
       return serialization.externalizerTypes.advancedExternalizers;
    }
 
+   public ClassResolver getClassResolver() {
+      return serialization.classResolver;
+   }
+
    public long getDistributedSyncTimeout() {
       return transport.distributedSyncTimeout;
    }
@@ -1361,6 +1366,9 @@ TransportType setGlobalConfiguration(GlobalConfiguration globalConfig) {
       @XmlElement(name = ""advancedExternalizers"")
       protected AdvancedExternalizersType externalizerTypes = new AdvancedExternalizersType();
 
+      @XmlTransient
+      private ClassResolver classResolver;
+
       public SerializationType() {
          super();
       }
@@ -1453,6 +1461,12 @@ public <T> SerializationConfig addAdvancedExternalizer(int id, AdvancedExternali
                new AdvancedExternalizerConfig().setId(id).setAdvancedExternalizer(advancedExternalizer));
          return this;
       }
+
+      @Override
+      public SerializationConfig classResolver(ClassResolver classResolver) {
+         this.classResolver = classResolver;
+         return this;
+      }
    }
 
    /**",2012-03-19T13:24:00Z,12
"@@ -73,6 +73,8 @@ public static org.infinispan.config.GlobalConfiguration adapt(GlobalConfiguratio
       for (Entry<Integer, AdvancedExternalizer<?>> entry : config.serialization().advancedExternalizers().entrySet()) {
          legacy.serialization().addAdvancedExternalizer(entry.getKey(), entry.getValue());
       }
+
+      legacy.serialization().classResolver(config.serialization().classResolver());
       
       legacy.asyncTransportExecutor()
          .factory(config.asyncTransportExecutor().factory().getClass())
@@ -134,6 +136,8 @@ public static org.infinispan.configuration.global.GlobalConfiguration adapt(org.
       for (AdvancedExternalizerConfig externalizerConfig : legacy.getExternalizers()) {
          builder.serialization().addAdvancedExternalizer(externalizerConfig.getId(), externalizerConfig.getAdvancedExternalizer());
       }
+
+      builder.serialization().classResolver(legacy.getClassResolver());
       
       builder.asyncTransportExecutor()
          .factory(Util.<ExecutorFactory>getInstance(legacy.getAsyncTransportExecutorFactoryClass(), legacy.getClassLoader()))",2012-03-19T13:24:00Z,13
"@@ -24,18 +24,22 @@
 
 import org.infinispan.marshall.AdvancedExternalizer;
 import org.infinispan.marshall.Marshaller;
+import org.jboss.marshalling.ClassResolver;
 
 public class SerializationConfiguration {
 
    private final Marshaller marshaller;
    private final short version;
    private final Map<Integer, AdvancedExternalizer<?>> advancedExternalizers;
+   private final ClassResolver classResolver;
    
    SerializationConfiguration(Marshaller marshaller, short version,
-         Map<Integer, AdvancedExternalizer<?>> advancedExternalizers) {
+         Map<Integer, AdvancedExternalizer<?>> advancedExternalizers,
+         ClassResolver classResolver) {
       this.marshaller = marshaller;
       this.version = version;
       this.advancedExternalizers = Collections.unmodifiableMap(new HashMap<Integer, AdvancedExternalizer<?>>(advancedExternalizers));
+      this.classResolver = classResolver;
    }
 
    public Marshaller marshaller() {
@@ -50,12 +54,17 @@ public Map<Integer, AdvancedExternalizer<?>> advancedExternalizers() {
       return advancedExternalizers;
    }
 
+   public ClassResolver classResolver() {
+      return classResolver;
+   }
+
    @Override
    public String toString() {
       return ""SerializationConfiguration{"" +
             ""advancedExternalizers="" + advancedExternalizers +
             "", marshaller="" + marshaller +
             "", version="" + version +
+            "", classResolver="" + classResolver +
             '}';
    }
 ",2012-03-19T13:24:00Z,14
"@@ -22,6 +22,8 @@
 import org.infinispan.marshall.AdvancedExternalizer;
 import org.infinispan.marshall.Marshaller;
 import org.infinispan.marshall.VersionAwareMarshaller;
+import org.jboss.marshalling.ClassResolver;
+
 import java.util.HashMap;
 import java.util.Map;
 
@@ -33,6 +35,7 @@ public class SerializationConfigurationBuilder extends AbstractGlobalConfigurati
    private Marshaller marshaller = new VersionAwareMarshaller();
    private short marshallVersion = Short.valueOf(Version.MAJOR_MINOR.replace(""."", """"));
    private Map<Integer, AdvancedExternalizer<?>> advancedExternalizers = new HashMap<Integer, AdvancedExternalizer<?>>();
+   private ClassResolver classResolver;
 
    SerializationConfigurationBuilder(GlobalConfigurationBuilder globalConfig) {
       super(globalConfig);
@@ -111,14 +114,25 @@ public <T> SerializationConfigurationBuilder addAdvancedExternalizer(AdvancedExt
       return this;
    }
 
+   /**
+    * Class resolver to use when unmarshallig objects.
+    *
+    * @param classResolver
+    */
+   public SerializationConfigurationBuilder classResolver(ClassResolver classResolver) {
+      this.classResolver = classResolver;
+      return this;
+   }
+
    @Override
    protected void validate() {
       // No-op, no validation required
    }
 
    @Override
    SerializationConfiguration create() {
-      return new SerializationConfiguration(marshaller, marshallVersion, advancedExternalizers);
+      return new SerializationConfiguration(
+            marshaller, marshallVersion, advancedExternalizers, classResolver);
    }
 
    @Override
@@ -136,6 +150,7 @@ public String toString() {
             ""advancedExternalizers="" + advancedExternalizers +
             "", marshaller="" + marshaller +
             "", marshallVersion="" + marshallVersion +
+            "", classResolver="" + classResolver +
             '}';
    }
 
@@ -151,6 +166,8 @@ public boolean equals(Object o) {
          return false;
       if (marshaller != null ? !marshaller.equals(that.marshaller) : that.marshaller != null)
          return false;
+      if (classResolver != null ? !classResolver.equals(that.classResolver) : that.classResolver != null)
+         return false;
 
       return true;
    }
@@ -160,6 +177,7 @@ public int hashCode() {
       int result = marshaller != null ? marshaller.hashCode() : 0;
       result = 31 * result + (int) marshallVersion;
       result = 31 * result + (advancedExternalizers != null ? advancedExternalizers.hashCode() : 0);
+      result = 31 * result + (classResolver != null ? classResolver.hashCode() : 0);
       return result;
    }
 ",2012-03-19T13:24:00Z,15
"@@ -1,6 +1,7 @@
 package org.infinispan.marshall;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Stop;
@@ -22,8 +23,10 @@ public CacheMarshaller(VersionAwareMarshaller marshaller) {
    }
 
    @Inject
-   public void inject(Configuration cfg, InvocationContextContainer icc, ExternalizerTable extTable) {
-      ((VersionAwareMarshaller) this.marshaller).inject(cfg, null, icc, extTable);
+   public void inject(Configuration cfg, InvocationContextContainer icc,
+            ExternalizerTable extTable, GlobalConfiguration globalCfg) {
+      ((VersionAwareMarshaller) this.marshaller).inject(
+            cfg, null, icc, extTable, globalCfg);
    }
 
    @Stop(priority = 11) // Stop after RPCManager to avoid send/receive and marshaller not being ready",2012-03-19T13:24:00Z,16
"@@ -1,5 +1,6 @@
 package org.infinispan.marshall;
 
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.factories.scopes.Scope;
@@ -22,8 +23,10 @@ public GlobalMarshaller(VersionAwareMarshaller marshaller) {
    }
 
    @Inject
-   public void inject(ClassLoader loader, ExternalizerTable extTable) {
-      ((VersionAwareMarshaller) this.marshaller).inject(null, loader, null, extTable);
+   public void inject(ClassLoader loader, ExternalizerTable extTable,
+            GlobalConfiguration globalCfg) {
+      ((VersionAwareMarshaller) this.marshaller).inject(
+            null, loader, null, extTable, globalCfg);
    }
 
    @Stop(priority = 11) // Stop after transport to avoid send/receive and marshaller not being ready",2012-03-19T13:24:00Z,17
"@@ -23,6 +23,7 @@
 package org.infinispan.marshall;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.io.ByteBuffer;
 import org.infinispan.io.ExposedByteArrayOutputStream;
@@ -61,7 +62,9 @@ public VersionAwareMarshaller() {
       defaultMarshaller = new JBossMarshaller();
    }
 
-   public void inject(Configuration cfg, ClassLoader loader, InvocationContextContainer icc, ExternalizerTable extTable) {
+   public void inject(Configuration cfg, ClassLoader loader,
+         InvocationContextContainer icc, ExternalizerTable extTable,
+         GlobalConfiguration globalCfg) {
       ClassLoader myClassLoader;
       if (cfg == null) {
          myClassLoader = loader;
@@ -71,7 +74,7 @@ public void inject(Configuration cfg, ClassLoader loader, InvocationContextConta
          this.cacheName = cfg.getName();
       }
 
-      this.defaultMarshaller.inject(extTable, myClassLoader, icc);
+      this.defaultMarshaller.inject(extTable, myClassLoader, icc, globalCfg);
    }
 
    public void stop() {",2012-03-19T13:24:00Z,18
"@@ -22,14 +22,11 @@
  */
 package org.infinispan.marshall.jboss;
 
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.marshall.StreamingMarshaller;
-import org.jboss.marshalling.Marshaller;
-import org.jboss.marshalling.MarshallingConfiguration;
-import org.jboss.marshalling.Unmarshaller;
-
-import java.io.IOException;
+import org.jboss.marshalling.ClassResolver;
 
 /**
  * A JBoss Marshalling based marshaller that is oriented at internal, embedded,
@@ -52,13 +49,20 @@ public final class JBossMarshaller extends AbstractJBossMarshaller implements St
 
    ExternalizerTable externalizerTable;
 
-   public void inject(ExternalizerTable externalizerTable, ClassLoader cl, InvocationContextContainer icc) {
+   public void inject(ExternalizerTable externalizerTable, ClassLoader cl,
+         InvocationContextContainer icc, GlobalConfiguration globalCfg) {
       log.debug(""Using JBoss Marshalling"");
       this.externalizerTable = externalizerTable;
       baseCfg.setObjectTable(externalizerTable);
-      // Override the class resolver with one that can detect injected
-      // classloaders via AdvancedCache.with(ClassLoader) calls.
-      baseCfg.setClassResolver(new EmbeddedContextClassResolver(cl, icc));
+
+      ClassResolver classResolver = globalCfg.getClassResolver();
+      if (classResolver == null) {
+         // Override the class resolver with one that can detect injected
+         // classloaders via AdvancedCache.with(ClassLoader) calls.
+         classResolver = new EmbeddedContextClassResolver(cl, icc);
+      }
+
+      baseCfg.setClassResolver(classResolver);
    }
 
    @Override",2012-03-19T13:24:00Z,19
"@@ -2,16 +2,16 @@
 
 import org.infinispan.Cache;
 import org.infinispan.CacheException;
-import org.infinispan.config.Configuration.CacheMode;
-import org.infinispan.config.GlobalConfiguration;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.test.CherryPickClassLoader;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
 import java.io.Serializable;
 
-import static org.infinispan.test.fwk.TestCacheManagerFactory.createCacheManager;
+import static org.infinispan.test.fwk.TestCacheManagerFactory.createClusteredCacheManager;
 import static org.testng.AssertJUnit.assertEquals;
 import static org.testng.AssertJUnit.fail;
 
@@ -30,22 +30,29 @@ public class WithClassLoaderTest extends MultipleCacheManagersTest {
 
    @Override
    protected void createCacheManagers() throws Throwable {
-      EmbeddedCacheManager cm0 = createCacheManager(GlobalConfiguration.getClusteredDefault());
-      cm0.getDefaultConfiguration().fluent()
-         .clustering().mode(CacheMode.REPL_SYNC)
-         .storeAsBinary().build();
+      ConfigurationBuilder builder = new ConfigurationBuilder();
+      builder.storeAsBinary().enable()
+            .clustering()
+            .cacheMode(org.infinispan.configuration.cache.CacheMode.REPL_SYNC);
+      EmbeddedCacheManager cm0 = createClusteredCacheManager(builder);
       cacheManagers.add(cm0);
 
       String[] notFound = new String[]{CAR};
       systemCl = Thread.currentThread().getContextClassLoader();
       CherryPickClassLoader cl = new CherryPickClassLoader(null, null, notFound, systemCl);
-      EmbeddedCacheManager cm1 = createCacheManager(GlobalConfiguration.getClusteredDefault(cl));
-      cm1.getDefaultConfiguration().fluent()
-         .clustering().mode(CacheMode.REPL_SYNC)
-         .storeAsBinary().build();
+
+      GlobalConfigurationBuilder gcBuilder = createSecondGlobalCfgBuilder(cl);
+      EmbeddedCacheManager cm1 = createClusteredCacheManager(gcBuilder, builder);
       cacheManagers.add(cm1);
    }
 
+   protected GlobalConfigurationBuilder createSecondGlobalCfgBuilder(ClassLoader cl) {
+      GlobalConfigurationBuilder gcBuilder =
+            GlobalConfigurationBuilder.defaultClusteredBuilder();
+      gcBuilder.classLoader(cl);
+      return gcBuilder;
+   }
+
    public void testReadingWithCorrectClassLoaderAfterReplication() {
       Cache<Integer, Car> cache0 = cache(0);
       Cache<Integer, Car> cache1 = cache(1);",2012-03-19T13:24:00Z,20
"@@ -0,0 +1,55 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.configuration;
+
+import org.infinispan.api.WithClassLoaderTest;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
+import org.infinispan.marshall.jboss.DefaultContextClassResolver;
+import org.testng.annotations.Test;
+
+/**
+ * A test that verifies that a class resolver can be configured successfully.
+ *
+ * @author Galder Zamarreño
+ * @since 5.1
+ */
+@Test(groups = ""functional"", testName = ""configuration.ClassResolverConfigTest"")
+public class ClassResolverConfigTest extends WithClassLoaderTest {
+
+   @Override
+   protected GlobalConfigurationBuilder createSecondGlobalCfgBuilder(ClassLoader cl) {
+      GlobalConfigurationBuilder gcBuilder = super.createSecondGlobalCfgBuilder(cl);
+      gcBuilder.serialization().classResolver(new DefaultContextClassResolver(cl));
+      return gcBuilder;
+   }
+
+   @Override
+   @Test(expectedExceptions = AssertionError.class,
+         expectedExceptionsMessageRegExp = ""Expected a ClassNotFoundException"")
+   public void testReadingWithCorrectClassLoaderAfterReplication() {
+      // With the default context class resolver, if configured correctly,
+      // the classloader that we set with the invocation context (i.e.
+      // coming from global configuration) is ignored (the super class test
+      // has one specific classloader that forces not finding a class), and
+      // so the class is found.
+      super.testReadingWithCorrectClassLoaderAfterReplication();
+   }
+
+}
\ No newline at end of file",2012-03-19T13:24:00Z,21
"@@ -29,6 +29,7 @@
 
 import org.infinispan.Version;
 
+import org.infinispan.factories.annotations.SurvivesRestarts;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
 
@@ -48,6 +49,7 @@
  *
  */
 @Scope(Scopes.GLOBAL)
+@SurvivesRestarts
 public class GlobalConfiguration {
 
    /**",2012-08-31T21:04:11Z,22
"@@ -495,9 +495,11 @@ private void populateLifeCycleMethods(Component c) {
     */
    public void resetVolatileComponents() {
       // destroy all components to clean up resources
+      getLog().tracef(""Resetting volatile components"");
       for (Component c : new HashSet<Component>(componentLookup.values())) {
          // the component is volatile!!
          if (!c.metadata.isSurvivesRestarts()) {
+            getLog().tracef(""Removing volatile component %s"", c.metadata.getName());
             componentLookup.remove(c.name);
          }
       }",2012-08-31T21:04:11Z,23
"@@ -106,8 +106,8 @@ public GlobalComponentRegistry(GlobalConfiguration configuration,
          globalConfiguration = configuration;
 
          registerComponent(this, GlobalComponentRegistry.class);
-         registerComponent(cacheManager, EmbeddedCacheManager.class);
          registerComponent(configuration, GlobalConfiguration.class);
+         registerComponent(cacheManager, EmbeddedCacheManager.class);
          registerComponent(new CacheManagerJmxRegistration(), CacheManagerJmxRegistration.class);
          registerComponent(new CacheManagerNotifierImpl(), CacheManagerNotifier.class);
 ",2012-08-31T21:04:11Z,24
"@@ -23,18 +23,13 @@
 package org.infinispan.container;
 
 import net.jcip.annotations.ThreadSafe;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalNullEntry;
 import org.infinispan.container.versioning.EntryVersion;
 import org.infinispan.eviction.EvictionManager;
 import org.infinispan.eviction.EvictionStrategy;
 import org.infinispan.eviction.EvictionThreadPolicy;
 import org.infinispan.eviction.PassivationManager;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
-import org.infinispan.loaders.CacheLoaderManager;
-import org.infinispan.loaders.decorators.AsyncStore;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.concurrent.BoundedConcurrentHashMap;
 import org.infinispan.util.concurrent.BoundedConcurrentHashMap.Eviction;
@@ -69,10 +64,6 @@ public class DefaultDataContainer implements DataContainer {
    final protected DefaultEvictionListener evictionListener;
    private EvictionManager evictionManager;
    private PassivationManager passivator;
-   private boolean isAsyncStore;
-   private CacheLoaderManager cacheLoaderManager;
-   private Configuration config;
-   private AsyncStore asyncStore;
 
    public DefaultDataContainer(int concurrencyLevel) {
       entries = ConcurrentMapFactory.makeConcurrentMap(128, concurrencyLevel);
@@ -108,19 +99,10 @@ protected DefaultDataContainer(int concurrencyLevel, int maxEntries, EvictionStr
 
    @Inject
    public void initialize(EvictionManager evictionManager, PassivationManager passivator,
-         InternalEntryFactory entryFactory, Configuration config, CacheLoaderManager cacheLoaderManager) {
+         InternalEntryFactory entryFactory) {
       this.evictionManager = evictionManager;
       this.passivator = passivator;
       this.entryFactory = entryFactory;
-      this.config = config;
-      this.cacheLoaderManager = cacheLoaderManager;
-   }
-
-   @Start(priority = 11) // Start after cache loader manager
-   public void start() {
-      this.isAsyncStore = config.loaders().usingAsyncStore();
-      if (isAsyncStore)
-         this.asyncStore = (AsyncStore) cacheLoaderManager.getCacheStore();
    }
 
    public static DataContainer boundedDataContainer(int concurrencyLevel, int maxEntries,
@@ -134,15 +116,7 @@ public static DataContainer unBoundedDataContainer(int concurrencyLevel) {
 
    @Override
    public InternalCacheEntry peek(Object key) {
-      InternalCacheEntry entry = entries.get(key);
-      // If the entry was passivated to an async store, it would have been
-      // marked as 'evicted', so check whether the key has been flushed to
-      // the cache store, and if it has, return null so that it can go through
-      // the activation process.
-      if (entry != null && entry.isEvicted() && isKeyFlushedToStore(key))
-         return null;
-
-      return entry;
+      return entries.get(key);
    }
 
    @Override
@@ -162,7 +136,7 @@ public InternalCacheEntry get(Object k) {
 
    @Override
    public void put(Object k, Object v, EntryVersion version, long lifespan, long maxIdle) {
-      InternalCacheEntry e = peek(k);
+      InternalCacheEntry e = entries.get(k);
       if (e != null) {
          e.setValue(v);
          InternalCacheEntry original = e;
@@ -191,12 +165,7 @@ public boolean containsKey(Object k) {
 
    @Override
    public InternalCacheEntry remove(Object k) {
-      InternalCacheEntry e;
-      if (isAsyncStore) {
-         e = entries.replace(k, new InternalNullEntry(asyncStore));
-      } else {
-         e = entries.remove(k);
-      }
+      InternalCacheEntry e = entries.remove(k);
       return e == null || (e.canExpire() && e.isExpired(System.currentTimeMillis())) ? null : e;
    }
 
@@ -230,24 +199,12 @@ public void purgeExpired() {
       long currentTimeMillis = System.currentTimeMillis();
       for (Iterator<InternalCacheEntry> purgeCandidates = entries.values().iterator(); purgeCandidates.hasNext();) {
          InternalCacheEntry e = purgeCandidates.next();
-         if (isAsyncStore && e instanceof InternalNullEntry) {
-            InternalNullEntry nullEntry = (InternalNullEntry) e;
-            if (nullEntry.isExpired(asyncStore.getAsyncProcessorId())) {
-               purgeCandidates.remove();
-               continue;
-            }
-         }
-
          if (e.isExpired(currentTimeMillis)) {
             purgeCandidates.remove();
          }
       }
    }
 
-   private boolean isKeyFlushedToStore(Object key) {
-      return !isAsyncStore || (isAsyncStore && !asyncStore.isLocked(key));
-   }
-
    @Override
    public Iterator<InternalCacheEntry> iterator() {
       return new EntryIterator(entries.values().iterator());
@@ -261,24 +218,10 @@ public void onEntryEviction(Map<Object, InternalCacheEntry> evicted) {
       }
 
       @Override
-      public boolean onEntryChosenForEviction(InternalCacheEntry entry) {
-         boolean allowEviction = isKeyFlushedToStore(entry.getKey());
-
-         if (allowEviction) {
-            passivator.passivate(entry);
-            if (isAsyncStore) {
-               // Storing in cache store is still in flight, so don't remove
-               // the entry from memory yet. Instead, mark the entry as 'evicted'
-               // and if someone requests it, check whether it's locked on the
-               // cache store. If it's not, assume that the entry was stored
-               // in the async store and the container can return null.
-               entry.setEvicted(true);
-               return false;
-            }
-         }
-
-         return allowEviction;
+      public void onEntryChosenForEviction(InternalCacheEntry entry) {
+         passivator.passivate(entry);
       }
+
    }
 
    private static class ImmutableEntryIterator extends EntryIterator {",2012-10-03T12:24:38Z,25
"@@ -34,7 +34,6 @@
 public abstract class AbstractInternalCacheEntry implements InternalCacheEntry {
 
    protected Object key;
-   private boolean evicted;
 
    protected AbstractInternalCacheEntry() {
    }
@@ -65,7 +64,7 @@ public final void setRemoved(boolean removed) {
 
    @Override
    public final void setEvicted(boolean evicted) {
-      this.evicted = evicted;
+      // no-op
    }
 
    @Override
@@ -95,7 +94,7 @@ public final boolean isRemoved() {
 
    @Override
    public final boolean isEvicted() {
-      return evicted;
+      return true;
    }
 
    @Override",2012-10-03T12:24:38Z,26
"@@ -1,229 +0,0 @@
-/*
- * Copyright 2012 Red Hat, Inc. and/or its affiliates.
- *
- * This is free software; you can redistribute it and/or modify it
- * under the terms of the GNU Lesser General Public License as
- * published by the Free Software Foundation; either version 2.1 of
- * the License, or (at your option) any later version.
- *
- * This software is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this library; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
- * 02110-1301 USA
- */
-
-package org.infinispan.container.entries;
-
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.versioning.EntryVersion;
-import org.infinispan.loaders.decorators.AsyncStore;
-
-/**
- * Internal null cache entry used to signal that an entry has been removed
- * but it's in the process of being removed from another component,
- * i.e. an async cache store.
- *
- * This entry helps deal with situations where an eventual removal
- * is under way.
- *
- * @author Galder Zamarreño
- * @since 5.2
- */
-public class InternalNullEntry implements InternalCacheEntry {
-
-   private final long asyncProcessorId;
-   private final AsyncStore asyncStore;
-
-   public InternalNullEntry(AsyncStore asyncStore) {
-      this.asyncStore = asyncStore;
-      this.asyncProcessorId = this.asyncStore.getAsyncProcessorId();
-   }
-
-   @Override
-   public boolean isNull() {
-      return false; // not null to avoid cache loader interceptor loading from store
-   }
-
-   @Override
-   public Object getValue() {
-      return this; // set this value to avoid cache loader interceptor
-   }
-
-   @Override
-   public boolean canExpire() {
-      return true;
-   }
-
-   @Override
-   public boolean isExpired(long now) {
-      return asyncStore.getAsyncProcessorId() > asyncProcessorId;
-   }
-
-   @Override
-   public boolean isExpired() {
-      return asyncStore.getAsyncProcessorId() > asyncProcessorId;
-   }
-
-   // Below are non-relevant method implementations
-
-   @Override
-   public boolean isChanged() {
-      return false;
-   }
-
-   @Override
-   public boolean isCreated() {
-      return false;
-   }
-
-   @Override
-   public boolean isRemoved() {
-      return false;
-   }
-
-   @Override
-   public boolean isEvicted() {
-      return false;
-   }
-
-   @Override
-   public boolean isValid() {
-      return false;
-   }
-
-   @Override
-   public Object getKey() {
-      return null;
-   }
-
-   @Override
-   public long getLifespan() {
-      return 0;
-   }
-
-   @Override
-   public long getMaxIdle() {
-      return 0;
-   }
-
-   @Override
-   public void setMaxIdle(long maxIdle) {
-      // Empty
-   }
-
-   @Override
-   public void setLifespan(long lifespan) {
-      // Empty
-   }
-
-   @Override
-   public Object setValue(Object value) {
-      return null;
-   }
-
-   @Override
-   public boolean equals(Object o) {
-      return false;
-   }
-
-   @Override
-   public int hashCode() {
-      return 0;
-   }
-
-   @Override
-   public void commit(DataContainer container, EntryVersion newVersion) {
-      // Empty
-   }
-
-   @Override
-   public void rollback() {
-      // Empty
-   }
-
-   @Override
-   public void setCreated(boolean created) {
-      // Empty
-   }
-
-   @Override
-   public void setRemoved(boolean removed) {
-      // Empty
-   }
-
-   @Override
-   public void setEvicted(boolean evicted) {
-      // Empty
-   }
-
-   @Override
-   public void setValid(boolean valid) {
-      // Empty
-   }
-
-   @Override
-   public boolean isLockPlaceholder() {
-      return false;
-   }
-
-   @Override
-   public boolean undelete(boolean doUndelete) {
-      return false;
-   }
-
-   @Override
-   public long getCreated() {
-      return 0;
-   }
-
-   @Override
-   public long getLastUsed() {
-      return 0;
-   }
-
-   @Override
-   public long getExpiryTime() {
-      return 0;
-   }
-
-   @Override
-   public void touch() {
-      // Empty
-   }
-
-   @Override
-   public void touch(long currentTimeMillis) {
-      // Empty
-   }
-
-   @Override
-   public void reincarnate() {
-      // Empty
-   }
-
-   @Override
-   public InternalCacheValue toInternalCacheValue() {
-      return null;
-   }
-
-   @Override
-   public InternalCacheEntry clone() {
-      return null;
-   }
-
-   @Override
-   public EntryVersion getVersion() {
-      return null;
-   }
-
-   @Override
-   public void setVersion(EntryVersion version) {
-      // Empty
-   }
-
-}",2012-10-03T12:24:38Z,27
"@@ -32,7 +32,6 @@
 import org.infinispan.container.EntryFactory;
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalNullEntry;
 import org.infinispan.container.entries.MVCCEntry;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
@@ -174,9 +173,6 @@ private boolean loadIfNeeded(InvocationContext ctx, Object key, boolean isRetrie
          } else {
             return false;
          }
-      } else if (e instanceof InternalNullEntry) {
-         ctx.putLookedUpEntry(key, null);
-         return false;
       } else {
          return true;
       }",2012-10-03T12:24:38Z,28
"@@ -50,7 +50,6 @@
 import org.infinispan.configuration.cache.StoreConfiguration;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.context.Flag;
-import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.ComponentRegistry;
 import org.infinispan.factories.annotations.ComponentName;
@@ -66,7 +65,6 @@
 import org.infinispan.loaders.decorators.SingletonStoreConfig;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.statetransfer.StateTransferManager;
-import org.infinispan.topology.CacheTopology;
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;",2012-10-03T12:24:38Z,29
"@@ -25,7 +25,7 @@
 import net.jcip.annotations.GuardedBy;
 import org.infinispan.Cache;
 import org.infinispan.CacheException;
-import org.infinispan.config.Configuration;
+import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.loaders.CacheLoaderConfig;
 import org.infinispan.loaders.CacheLoaderException;
@@ -37,43 +37,40 @@
 import org.infinispan.loaders.modifications.Store;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.transaction.xa.TransactionFactory;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.locks.containers.ReentrantPerEntryLockContainer;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
 import java.util.concurrent.LinkedBlockingQueue;
 import java.util.concurrent.ThreadFactory;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.atomic.AtomicLong;
-import java.util.concurrent.locks.Lock;
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
+import java.util.concurrent.locks.AbstractQueuedSynchronizer;
 
 /**
- * The AsyncStore is a delegating CacheStore that extends AbstractDelegatingStore, overriding methods to that should not
- * just delegate the operation to the underlying store.
+ * The AsyncStore is a delegating CacheStore that buffers changes and writes them asynchronously to
+ * the underlying CacheStore.
  * <p/>
- * Read operations are done synchronously, while write operations are done asynchronously.  There is no provision for
- * exception handling for problems encountered with the underlying store during a write operation, and the exception is
- * just logged.
+ * Read operations are done synchronously, taking into account the current state of buffered changes.
+ * <p/>
+ * There is no provision for exception handling for problems encountered with the underlying store
+ * during a write operation, and the exception is just logged.
  * <p/>
  * When configuring the loader, use the following element:
  * <p/>
  * <code> &lt;async enabled=""true"" /&gt; </code>
  * <p/>
- * to define whether cache loader operations are to be asynchronous.  If not specified, a cache loader operation is
+ * to define whether cache loader operations are to be asynchronous. If not specified, a cache loader operation is
  * assumed synchronous and this decorator is not applied.
  * <p/>
  * Write operations affecting same key are now coalesced so that only the final state is actually stored.
@@ -82,62 +79,43 @@
  * @author Manik Surtani
  * @author Galder Zamarreño
  * @author Sanne Grinovero
+ * @author Karsten Blees
  * @since 4.0
  */
 public class AsyncStore extends AbstractDelegatingStore {
    private static final Log log = LogFactory.getLog(AsyncStore.class);
    private static final boolean trace = log.isTraceEnabled();
    private static final AtomicInteger threadId = new AtomicInteger(0);
-   private final AtomicBoolean stopped = new AtomicBoolean(true);
-   
+
    private final AsyncStoreConfig asyncStoreConfig;
+   private final TransactionFactory txFactory;
    private Map<GlobalTransaction, List<? extends Modification>> transactions;
-   
-   /**
-    * This is used as marker to shutdown the AsyncStoreCoordinator
-    */
-   private static final Modification QUIT_SIGNAL = new Clear();
-   
-   /**
-    * clear() is performed in sync by the one thread of storeCoordinator, while blocking all
-    * other threads interacting with the decorated store.
-    */
-   private final ReadWriteLock clearAllLock = new ReentrantReadWriteLock();
-   private final Lock clearAllReadLock = clearAllLock.readLock();
-   private final Lock clearAllWriteLock = clearAllLock.writeLock();
-   private final Lock stateMapLock = new ReentrantLock();
-   
-   ExecutorService executor;
+
+   private ExecutorService executor;
+   private Thread coordinator;
    private int concurrencyLevel;
-   @GuardedBy(""stateMapLock"")
-   protected ConcurrentMap<Object, Modification> state;
-   private ReleaseAllLockContainer lockContainer;
-   private LinkedBlockingQueue<Modification> changesDeque;
-   public volatile boolean lastAsyncProcessorShutsDownExecutor = false;
    private long shutdownTimeout;
    private String cacheName;
 
-   /**
-    * Identifies each of the asynchronous processor runs. This incrementing
-    * counter can be used to decide whether a phantom null entry in the cache
-    * can be expired or not.
-    */
-   private final AtomicLong asyncProcessorId = new AtomicLong();
+   private BufferLock stateLock;
+   @GuardedBy(""stateLock"")
+   private volatile State state;
 
    public AsyncStore(CacheStore delegate, AsyncStoreConfig asyncStoreConfig) {
       super(delegate);
       this.asyncStoreConfig = asyncStoreConfig;
+      txFactory = new TransactionFactory();
+      txFactory.init(false, false, false, false);
    }
 
    @Override
    public void init(CacheLoaderConfig config, Cache<?, ?> cache, StreamingMarshaller m) throws CacheLoaderException {
       super.init(config, cache, m);
-      changesDeque = new LinkedBlockingQueue<Modification>(asyncStoreConfig.getModificationQueueSize());
-      Configuration cacheCfg = cache != null ? cache.getConfiguration() : null;
-      concurrencyLevel = cacheCfg != null ? cacheCfg.getConcurrencyLevel() : 16;
-      int cacheStopTimeout = cacheCfg != null ? cacheCfg.getCacheStopTimeout() : 30000;
+      Configuration cacheCfg = cache != null ? cache.getCacheConfiguration() : null;
+      concurrencyLevel = cacheCfg != null ? cacheCfg.locking().concurrencyLevel() : 16;
+      long cacheStopTimeout = cacheCfg != null ? cacheCfg.transaction().cacheStopTimeout() : 30000;
       Long configuredAsyncStopTimeout = asyncStoreConfig.getShutdownTimeout();
-      cacheName = cacheCfg != null ? cacheCfg.getName() : null;
+      cacheName = cache != null ? cache.getName() : null;
 
       // Async store shutdown timeout cannot be bigger than
       // the overall cache stop timeout, so limit it accordingly.
@@ -148,308 +126,476 @@ public void init(CacheLoaderConfig config, Cache<?, ?> cache, StreamingMarshalle
          shutdownTimeout = configuredAsyncStopTimeout;
       }
 
-      lockContainer = new ReleaseAllLockContainer(concurrencyLevel);
       transactions = ConcurrentMapFactory.makeConcurrentMap(64, concurrencyLevel);
    }
 
+   private State newState(boolean clear, State next) {
+      ConcurrentMap<Object, Modification> map = ConcurrentMapFactory.makeConcurrentMap(64, concurrencyLevel);
+      return new State(clear, map, next);
+   }
+
+   private void put(Modification mod, int count) {
+      stateLock.writeLock(count);
+      try {
+         state.put(mod);
+      } finally {
+         stateLock.writeUnlock();
+      }
+   }
+
+   @Override
+   public InternalCacheEntry load(Object key) throws CacheLoaderException {
+      Modification mod = state.get(key);
+      if (mod != null) {
+         switch (mod.getType()) {
+            case REMOVE:
+            case CLEAR:
+               return null;
+            case STORE:
+               InternalCacheEntry ice = ((Store) mod).getStoredEntry();
+               if (ice.isExpired())
+                  return null;
+               return ice;
+         }
+      }
+
+      return super.load(key);
+   }
+
+   @Override
+   public boolean containsKey(Object key) throws CacheLoaderException {
+      Modification mod = state.get(key);
+      if (mod != null)
+         return mod.getType() == Modification.Type.STORE;
+
+      return super.containsKey(key);
+   }
+
+   private void loadKeys(State s, Set<Object> exclude, Set<Object> result) throws CacheLoaderException {
+      // if not cleared, get keys from next State or the back-end store
+      if (!s.clear) {
+         State next = s.next;
+         if (next != null)
+            loadKeys(next, exclude, result);
+         else
+            result.addAll(super.loadAllKeys(exclude));
+      }
+
+      // merge keys of the current State
+      for (Modification mod : s.modifications.values()) {
+         switch (mod.getType()) {
+            case STORE:
+               Object key = ((Store) mod).getStoredEntry().getKey();
+               if (exclude == null || !exclude.contains(key))
+                  result.add(key);
+               break;
+            case REMOVE:
+               result.remove(((Remove) mod).getKey());
+               break;
+         }
+      }
+   }
+
+   @Override
+   public Set<Object> loadAllKeys(Set<Object> keysToExclude) throws CacheLoaderException {
+      Set<Object> result = new HashSet<Object>();
+      loadKeys(state, keysToExclude, result);
+      return result;
+   }
+
+   @Override
+   public Set<InternalCacheEntry> loadAll() throws CacheLoaderException {
+      return load(Integer.MAX_VALUE);
+   }
+
    @Override
-   public void store(InternalCacheEntry ed) {
-      enqueue(new Store(ed));
+   public Set<InternalCacheEntry> load(int numEntries) throws CacheLoaderException {
+      Set<InternalCacheEntry> result = new HashSet<InternalCacheEntry>();
+      for (Object key : loadAllKeys(null)) {
+         InternalCacheEntry entry = load(key);
+         if (entry != null) {
+            result.add(entry);
+            if (result.size() == numEntries)
+               return result;
+         }
+      }
+      return result;
+   }
+
+   @Override
+   public void store(InternalCacheEntry entry) {
+      put(new Store(entry), 1);
+   }
+
+   @Override
+   public void clear() {
+      stateLock.writeLock(1);
+      try {
+         state = newState(true, state.next);
+      } finally {
+         stateLock.reset(1);
+         stateLock.writeUnlock();
+      }
    }
 
    @Override
    public boolean remove(Object key) {
-      enqueue(new Remove(key));
+      put(new Remove(key), 1);
       return true;
    }
 
    @Override
-   public void clear() {
-      Clear clear = new Clear();
-      checkNotStopped(); //check we can change the changesDeque
-      changesDeque.clear();
-      enqueue(clear);
+   public void removeAll(Set<Object> keys) throws CacheLoaderException {
+      if (keys != null && !keys.isEmpty()) {
+         List<Modification> mods = new ArrayList<Modification>(keys.size());
+         for (Object key : keys)
+            mods.add(new Remove(key));
+         put(new ModificationsList(mods), mods.size());
+      }
    }
 
    @Override
-   public void prepare(List<? extends Modification> mods, GlobalTransaction tx, boolean isOnePhase) throws CacheLoaderException {
+   public void prepare(List<? extends Modification> mods, GlobalTransaction tx, boolean isOnePhase)
+         throws CacheLoaderException {
       if (isOnePhase) {
          enqueueModificationsList(mods);
       } else {
          transactions.put(tx, mods);
       }
    }
-   
+
    @Override
    public void rollback(GlobalTransaction tx) {
       transactions.remove(tx);
    }
 
    @Override
    public void commit(GlobalTransaction tx) throws CacheLoaderException {
-      List<? extends Modification> list = transactions.remove(tx);
-      enqueueModificationsList(list);
+      enqueueModificationsList(transactions.remove(tx));
    }
-   
-   protected void enqueueModificationsList(List<? extends Modification> mods) {
-      if (mods != null && !mods.isEmpty()) {
-         enqueue(new ModificationsList(mods));
+
+   private void enqueueModificationsList(List<? extends Modification> mods) {
+      // scan backwards to find the last CLEAR (anything before that can be discarded)
+      int i = mods.size() - 1;
+      for (; i >= 0; i--)
+         if (mods.get(i).getType() == Modification.Type.CLEAR)
+            break;
+      // treat CLEAR specially
+      if (i >= 0) {
+         clear();
+         mods = mods.subList(i + 1, mods.size());
       }
+      // put the rest
+      if (!mods.isEmpty())
+         put(new ModificationsList(mods), mods.size());
    }
 
    @Override
    public void start() throws CacheLoaderException {
-      state = newStateMap();
       log.debugf(""Async cache loader starting %s"", this);
-      stopped.set(false);
-      lastAsyncProcessorShutsDownExecutor = false;
+      state = newState(false, null);
+      stateLock = new BufferLock(asyncStoreConfig.getModificationQueueSize());
+
       super.start();
-      int poolSize = asyncStoreConfig.getThreadPoolSize();
-      executor = new ThreadPoolExecutor(poolSize, poolSize, 0L, TimeUnit.MILLISECONDS,
-               // note the use of poolSize+1 as maximum workingQueue together with DiscardPolicy:
-               // this way when a new AsyncProcessor is started unnecessarily we discard it
-               // before it takes locks to perform no work
-               // this way we save memory from the executor queue, CPU, and also avoid
-               // any possible RejectedExecutionException.
-               new LinkedBlockingQueue<Runnable>(poolSize + 1),
-               new ThreadFactory() {
-                  @Override
-                  public Thread newThread(Runnable r) {
-                     Thread t = new Thread(r, ""CoalescedAsyncStore-"" + threadId.getAndIncrement());
-                     t.setDaemon(true);
-                     return t;
-                  }
-               },
-               new ThreadPoolExecutor.DiscardPolicy()
-         );
-      startStoreCoordinator();
-   }
 
-   private void startStoreCoordinator() {
-      ExecutorService storeCoordinator = Executors.newFixedThreadPool(1);
-      storeCoordinator.execute( new AsyncStoreCoordinator() );
-      storeCoordinator.shutdown();
+      int poolSize = asyncStoreConfig.getThreadPoolSize();
+      executor = new ThreadPoolExecutor(0, poolSize, 120L, TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),
+            new ThreadFactory() {
+               @Override
+               public Thread newThread(Runnable r) {
+                  Thread t = new Thread(r, ""AsyncStoreProcessor-"" + cacheName + ""-"" + threadId.getAndIncrement());
+                  t.setDaemon(true);
+                  return t;
+               }
+            });
+      coordinator = new Thread(new AsyncStoreCoordinator(), ""AsyncStoreCoordinator-"" + cacheName);
+      coordinator.setDaemon(true);
+      coordinator.start();
    }
 
    @Override
    public void stop() throws CacheLoaderException {
-      stopped.set(true);
+      stateLock.writeLock(1);
+      state.stopped = true;
+      stateLock.writeUnlock();
       try {
-         changesDeque.put(QUIT_SIGNAL);
-         boolean finished = executor.awaitTermination(shutdownTimeout, TimeUnit.MILLISECONDS);
-         if (!finished) log.error(""Async store executor did not stop properly"");
+         coordinator.join(shutdownTimeout);
+         if (coordinator.isAlive())
+            log.error(""Async store executor did not stop properly"");
       } catch (InterruptedException e) {
          log.interruptedWaitingAsyncStorePush(e);
          Thread.currentThread().interrupt();
       }
       super.stop();
    }
 
-   public boolean isLocked(Object key) {
-      boolean locked = lockContainer.isLocked(key);
-      if (log.isTraceEnabled()) log.tracef(""Key %s is locked? %b"", key, locked);
-      return locked;
+   protected void applyModificationsSync(List<Modification> mods) throws CacheLoaderException {
+      getDelegate().prepare(mods, txFactory.newGlobalTransaction(null, false), true);
    }
 
-   public long getAsyncProcessorId() {
-      return asyncProcessorId.get();
-   }
+   private static class State {
+      private static final Clear CLEAR = new Clear();
+
+      /**
+       * True if the state has been cleared before making modifications.
+       */
+      private final boolean clear;
+
+      /**
+       * Modifications to apply to the back-end CacheStore.
+       */
+      private final ConcurrentMap<Object, Modification> modifications;
+
+      /**
+       * Next state in the chain, initialized in constructor, may be set to <code>null</code>
+       * asynchronously at any time.
+       */
+      private volatile State next;
+
+      /**
+       * True if the CacheStore has been stopped (i.e. this is the last state to process).
+       */
+      private volatile boolean stopped = false;
+
+      /**
+       * Number of worker threads that currently work with this instance.
+       */
+      private CountDownLatch workerThreads;
+
+      private State(boolean clear, ConcurrentMap<Object, Modification> modMap, State next) {
+         this.clear = clear;
+         this.modifications = modMap;
+         this.next = next;
+         if (next != null)
+            stopped = next.stopped;
+      }
 
-   protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
-      Set<Map.Entry<Object, Modification>> entries = mods.entrySet();
-      for (Map.Entry<Object, Modification> entry : entries) {
-         Modification mod = entry.getValue();
+      /**
+       * Gets the Modification for the specified key from this State object or chained (
+       * <code>next</code>) State objects.
+       *
+       * @param key
+       *           the key to look up
+       * @return the Modification for the specified key, or <code>CLEAR</code> if the state was
+       *         cleared, or <code>null</code> if the key is not in the state map
+       */
+      Modification get(Object key) {
+         for (State state = this; state != null; state = state.next) {
+            Modification mod = state.modifications.get(key);
+            if (mod != null)
+               return mod;
+            else if (state.clear)
+               return CLEAR;
+         }
+         return null;
+      }
+
+      /**
+       * Adds the Modification(s) to the state map.
+       *
+       * @param mod
+       *           the Modification to add, supports modification types STORE, REMOVE and LIST
+       */
+      void put(Modification mod) {
+         if (stopped)
+            throw new CacheException(""AsyncStore stopped; no longer accepting more entries."");
          switch (mod.getType()) {
             case STORE:
-               super.store(((Store) mod).getStoredEntry());
+               modifications.put(((Store) mod).getStoredEntry().getKey(), mod);
                break;
             case REMOVE:
-               super.remove(entry.getKey());
+               modifications.put(((Remove) mod).getKey(), mod);
+               break;
+            case LIST:
+               for (Modification m : ((ModificationsList) mod).getList())
+                  put(m);
                break;
             default:
-               throw new IllegalArgumentException(""Unexpected modification type "" + mod.getType());
+               throw new IllegalArgumentException(""Unknown modification type "" + mod.getType());
          }
       }
    }
-   
-   protected boolean applyClear() {
-      try {
-         super.clear();
-         return true;
-      } catch (CacheLoaderException e) {
-         log.errorClearinAsyncStore(e);
-         return false;
-      }
-   }
-   
-   protected void delegatePurgeExpired() {
-      try {
-         super.purgeExpired();
-      } catch (CacheLoaderException e) {
-         log.errorPurgingAsyncStore(e);
-      }
-   }
 
-   private void enqueue(Modification mod) {
-      try {
-         checkNotStopped();
-         if (trace) log.tracef(""Enqueuing modification %s"", mod);
-         changesDeque.put(mod);
-      } catch (Exception e) {
-         throw new CacheException(""Unable to enqueue asynchronous task"", e);
-      }
-   }
+   /**
+    * A custom reader-writer-lock combined with a bounded buffer size counter.
+    * <p/>
+    * Supports multiple concurrent writers and a single exclusive reader. This ensures that no more
+    * data is being written to the current state when the AsyncStoreCoordinator thread hands the
+    * data off to the back-end store.
+    * <p/>
+    * Additionally, {@link #writeLock(int)} blocks if the buffer is full, and {@link #readLock()}
+    * blocks if no data is available.
+    * <p/>
+    * This lock implementation is <em>not</em> reentrant!
+    */
+   private static class BufferLock {
+      /**
+       * AQS state is the number of 'items' in the buffer. AcquireShared blocks if the buffer is
+       * full (>= size).
+       */
+      private static class Counter extends AbstractQueuedSynchronizer {
+         private static final long serialVersionUID = 1688655561670368887L;
+         private final int size;
+
+         Counter(int size) {
+            this.size = size;
+         }
 
-   private void checkNotStopped() {
-      if (stopped.get()) {
-         throw new CacheException(""AsyncStore stopped; no longer accepting more entries."");
-      }
-   }
+         int add(int count) {
+            for (;;) {
+               int state = getState();
+               if (compareAndSetState(state, state + count))
+                  return state + count;
+            }
+         }
 
-   private void acquireLock(Lock lock) {
-      try {
-         if (!lock.tryLock(asyncStoreConfig.getFlushLockTimeout(), TimeUnit.MILLISECONDS))
-            throw new CacheException(""Unable to acquire lock on update map"");
-      } catch (InterruptedException ie) {
-         // restore interrupted status
-         Thread.currentThread().interrupt();
+         protected int tryAcquireShared(int count) {
+            for (;;) {
+               int state = getState();
+               if (state >= size)
+                  return -1;
+               if (compareAndSetState(state, state + count))
+                  return state + count >= size ? 0 : 1;
+            }
+         }
+
+         protected boolean tryReleaseShared(int state) {
+            setState(state);
+            return state < size;
+         }
       }
-   }
 
-   private ConcurrentMap<Object, Modification> newStateMap() {
-      return ConcurrentMapFactory.makeConcurrentMap(64, concurrencyLevel);
-   }
+      /**
+       * AQS state is 0 if no data is available, 1 otherwise. AcquireShared blocks if no data is
+       * available.
+       */
+      private static class Available extends AbstractQueuedSynchronizer {
+         private static final long serialVersionUID = 6464514100313353749L;
 
-   private void ensureMoreWorkIsHandled() {
-      executor.execute(new AsyncProcessor());
-   }
+         protected int tryAcquireShared(int unused) {
+            return getState() > 0 ? 1 : -1;
+         }
 
-   /**
-    * Processes modifications taking the latest updates from a state map.
-    */
-   class AsyncProcessor implements Runnable {
-      private final Set<Object> lockedKeys = new HashSet<Object>();
-      boolean runAgainAfterWaiting = false;
+         protected boolean tryReleaseShared(int state) {
+            setState(state > 0 ? 1 : 0);
+            return state > 0;
+         }
+      }
 
-      @Override
-      public void run() {
-         LogFactory.pushNDC(cacheName, trace);
-         try {
-            clearAllReadLock.lock();
-            try {
-               innerRun();
-            } catch (Throwable t) {
-               runAgainAfterWaiting = false;
-               log.unexpectedErrorInAsyncProcessor(t);
-            } finally {
-               clearAllReadLock.unlock();
+      /**
+       * Minimal non-reentrant read-write-lock. AQS state is number of concurrent shared locks, or 0
+       * if unlocked, or -1 if locked exclusively.
+       */
+      private static class Sync extends AbstractQueuedSynchronizer {
+         private static final long serialVersionUID = 2983687000985096017L;
+
+         protected boolean tryAcquire(int unused) {
+            if (!compareAndSetState(0, -1))
+               return false;
+            setExclusiveOwnerThread(Thread.currentThread());
+            return true;
+         }
+
+         protected boolean tryRelease(int unused) {
+            setExclusiveOwnerThread(null);
+            setState(0);
+            return true;
+         }
+
+         protected int tryAcquireShared(int unused) {
+            for (;;) {
+               int state = getState();
+               if (state < 0)
+                  return -1;
+               if (compareAndSetState(state, state + 1))
+                  return 1;
             }
-            if (runAgainAfterWaiting) {
-               try {
-                  Thread.sleep(10);
-               } catch (InterruptedException e) {
-                  // just speedup ignoring more sleep but still make sure to store all data
-               }
-               ensureMoreWorkIsHandled();
+         }
+
+         protected boolean tryReleaseShared(int unused) {
+            for (;;) {
+               int state = getState();
+               if (compareAndSetState(state, state - 1))
+                  return true;
             }
-         } finally {
-            LogFactory.popNDC(trace);
          }
       }
-      
-      private void innerRun() {
-         final ConcurrentMap<Object, Modification> swap;
-         if (trace) log.trace(""Checking for modifications"");
-         try {
-            acquireLock(stateMapLock);
-            try {
-               swap = state;
-               state = newStateMap();
-
-               // This needs to be done within the stateMapLock section, because if a key is in use,
-               // we need to put it back in the state
-               // map for later processing and we don't wanna do it in such way that we override a
-               // newer value that might
-               // have been taken already for processing by another instance of this same code.
-               // AsyncStoreCoordinator doesn't need to acquired the same lock as values put by it
-               // will never be overwritten (putIfAbsent below)
-               for (Object key : swap.keySet()) {
-                  if (trace) log.tracef(""Going to process mod key: %s"", key);
-                  boolean acquired;
-                  try {
-                     acquired = lockContainer.acquireLock(null, key, 0, TimeUnit.NANOSECONDS) != null;
-                  } catch (InterruptedException e) {
-                     log.interruptedAcquiringLock(0, e);
-                     Thread.currentThread().interrupt();
-                     return;
-                  }
-                  if (trace)
-                     log.tracef(""Lock for key %s was acquired=%s"", key, acquired);
-                  if (!acquired) {
-                     Modification prev = swap.remove(key);
-                     Modification didPut = state.putIfAbsent(key, prev); // don't overwrite more recently put work
-                     if (didPut == null) {
-                        // otherwise a new job is being spawned by the arbiter, so no need to create
-                        // a new worker
-                        runAgainAfterWaiting = true;
-                     }
-                  } else {
-                     lockedKeys.add(key);
-                  }
-               }
-            } finally {
-               stateMapLock.unlock();
-            }
 
-            if (swap.isEmpty()) {
-               if (lastAsyncProcessorShutsDownExecutor && !runAgainAfterWaiting) {
-                  executor.shutdown();
-               }
-            } else {
-               if (trace)
-                  log.tracef(""Apply %s modifications"", swap.size());
-               int maxRetries = 3;
-               int attemptNumber = 0;
-               boolean successful;
-               do {
-                  if (attemptNumber > 0 && log.isDebugEnabled())
-                     log.debugf(""Retrying due to previous failure. %s attempts left."", maxRetries - attemptNumber);
-                  successful = put(swap);
-                  attemptNumber++;
-               } while (!successful && attemptNumber <= maxRetries);
-
-               if (!successful)
-                  log.unableToProcessAsyncModifications(maxRetries);
+      private final Sync sync;
+      private final Counter counter;
+      private final Available available;
+
+      /**
+       * Create a new BufferLock with the specified buffer size.
+       *
+       * @param size
+       *           the buffer size
+       */
+      BufferLock(int size) {
+         sync = new Sync();
+         counter = size > 0 ? new Counter(size) : null;
+         available = new Available();
+      }
 
-            }
-         } finally {
-            lockContainer.releaseLocks(lockedKeys);
-            lockedKeys.clear();
-            asyncProcessorId.incrementAndGet();
-         }
+      /**
+       * Acquires the write lock and consumes the specified amount of buffer space. Blocks if the
+       * buffer is full or if the object is currently locked for reading.
+       *
+       * @param count
+       *           number of items the caller intends to write
+       */
+      void writeLock(int count) {
+         if (counter != null)
+            counter.acquireShared(count);
+         sync.acquireShared(1);
       }
 
-      boolean put(ConcurrentMap<Object, Modification> mods) {
-         try {
-            AsyncStore.this.applyModificationsSync(mods);
-            return true;
-         } catch (Exception e) {
-            if (log.isDebugEnabled()) log.debug(""Failed to process async modifications"", e);
-            return false;
-         }
+      /**
+       * Releases the write lock.
+       */
+      void writeUnlock() {
+         sync.releaseShared(1);
+         available.releaseShared(1);
       }
-   }
 
-   private static class ReleaseAllLockContainer extends ReentrantPerEntryLockContainer {
-      private ReleaseAllLockContainer(int concurrencyLevel) {
-         super(concurrencyLevel);
+      /**
+       * Acquires the read lock. Blocks if the buffer is empty or if the object is currently locked
+       * for writing.
+       */
+      void readLock() {
+         available.acquireShared(1);
+         sync.acquire(1);
       }
 
-      void releaseLocks(Set<Object> keys) {
-         for (Object key : keys) {
-            if (trace) log.tracef(""Release lock for key %s"", key);
-            releaseLock(null, key);
-         }
+      /**
+       * Releases the read lock.
+       */
+      void readUnlock() {
+         sync.release(1);
+      }
+
+      /**
+       * Resets the buffer counter to the specified number.
+       *
+       * @param count
+       *           number of available items in the buffer
+       */
+      void reset(int count) {
+         if (counter != null)
+            counter.releaseShared(count);
+         available.releaseShared(count);
+      }
+
+      /**
+       * Modifies the buffer counter by the specified value.
+       *
+       * @param count
+       *           number of items to add to the buffer counter
+       */
+      void add(int count) {
+         if (counter != null)
+            count = counter.add(count);
+         available.releaseShared(count);
       }
    }
 
@@ -459,106 +605,118 @@ private class AsyncStoreCoordinator implements Runnable {
       public void run() {
          LogFactory.pushNDC(cacheName, trace);
          try {
-            while (true) {
+            for (;;) {
+               State s, head, tail;
+               stateLock.readLock();
                try {
-                  Modification take = changesDeque.take();
-                  if (take == QUIT_SIGNAL) {
-                     lastAsyncProcessorShutsDownExecutor = true;
-                     ensureMoreWorkIsHandled();
-                     return;
+                  s = state;
+                  tail = s.next;
+                  assert tail == null || tail.next == null : ""State chain longer than 3 entries!"";
+                  state = head = newState(false, s);
+               } finally {
+                  stateLock.reset(0);
+                  stateLock.readUnlock();
+               }
+
+               try {
+                  if (s.clear) {
+                     // clear() must be called synchronously, wait until background threads are done
+                     if (tail != null)
+                        tail.workerThreads.await();
+                     getDelegate().clear();
                   }
-                  else {
-                     handleSafely(take);
+
+                  List<Modification> mods;
+                  if (tail != null) {
+                     // if there's work in progress, push-back keys that are still in use to the head state
+                     mods = new ArrayList<Modification>();
+                     for (Map.Entry<Object, Modification> e : s.modifications.entrySet()) {
+                        if (!tail.modifications.containsKey(e.getKey()))
+                           mods.add(e.getValue());
+                        else {
+                           if (!head.clear && head.modifications.putIfAbsent(e.getKey(), e.getValue()) == null)
+                              stateLock.add(1);
+                           s.modifications.remove(e.getKey());
+                        }
+                     }
+                  } else {
+                     mods = new ArrayList<Modification>(s.modifications.values());
+                  }
+
+                  // distribute modifications evenly across worker threads
+                  int threads = Math.min(mods.size(), asyncStoreConfig.getThreadPoolSize());
+                  s.workerThreads = new CountDownLatch(threads);
+                  if (threads > 0) {
+                     // schedule background threads
+                     int start = 0;
+                     int quotient = mods.size() / threads;
+                     int remainder = mods.size() % threads;
+                     for (int i = 0; i < threads; i++) {
+                        int end = start + quotient + (i < remainder ? 1 : 0);
+                        executor.execute(new AsyncStoreProcessor(mods.subList(start, end), s));
+                        start = end;
+                     }
+                     assert start == mods.size() : ""Thread distribution is broken!"";
+                  }
+
+                  // wait until background threads of previous round are done
+                  if (tail != null) {
+                     tail.workerThreads.await();
+                     s.next = null;
                   }
-               } catch (InterruptedException e) {
-                  log.asyncStoreCoordinatorInterrupted(e);
-                  return;
-               } catch (Throwable t) {
-                  log.unexpectedErrorInAsyncStoreCoordinator(t);
+
+                  // if this is the last state to process, wait for background threads, then quit
+                  if (s.stopped) {
+                     s.workerThreads.await();
+                     return;
+                  }
+               } catch (Exception e) {
+                  if (log.isDebugEnabled())
+                     log.debug(""Failed to process async modifications"", e);
                }
             }
          } finally {
             LogFactory.popNDC(trace);
          }
       }
+   }
 
-      private void handleSafely(Modification mod) {
-         try {
-            if (trace) log.tracef(""taking from modification queue: %s"", mod);
-            handle(mod, false);
-         } catch (Exception e) {
-            log.errorModifyingAsyncStore(e);
-         }
-      }
+   private class AsyncStoreProcessor implements Runnable {
+      private final List<Modification> modifications;
+      private final State myState;
 
-      private void handle(Modification mod, boolean nested) {
-         boolean asyncProcessorNeeded = false;
-         switch (mod.getType()) {
-            case STORE:
-               Store store = (Store) mod;
-               stateMapLock.lock();
-               state.put(store.getStoredEntry().getKey(), store);
-               stateMapLock.unlock();
-               asyncProcessorNeeded = true;
-               break;
-            case REMOVE:
-               Remove remove = (Remove) mod;
-               stateMapLock.lock();
-               state.put(remove.getKey(), remove);
-               stateMapLock.unlock();
-               asyncProcessorNeeded = true;
-               break;
-            case CLEAR:
-               performClear();
-               break;
-            case PURGE_EXPIRED:
-               delegatePurgeExpired();
-               break;
-            case LIST:
-               applyModificationsList((ModificationsList) mod);
-               asyncProcessorNeeded = true;
-               break;
-            default:
-               throw new IllegalArgumentException(""Unexpected modification type "" + mod.getType());
-         }
-         if (asyncProcessorNeeded && !nested) {
-            // we know when it's possible for some work to be done, starting short-lived
-            // AsyncProcessor(s) simplifies shutdown process.
-             ensureMoreWorkIsHandled();
-         }
+      AsyncStoreProcessor(List<Modification> modifications, State myState) {
+         this.modifications = modifications;
+         this.myState = myState;
       }
 
-      private void applyModificationsList(ModificationsList mod) {
-         for (Modification m : mod.getList()) {
-            handle(m, true);
-         }
+      @Override
+      public void run() {
+         // try 3 times to store the modifications
+         retryWork(3);
+
+         // decrement active worker threads and disconnect myState if this was the last one
+         myState.workerThreads.countDown();
+         if (myState.workerThreads.getCount() == 0)
+            for (State s = state; s != null; s = s.next)
+               if (s.next == myState)
+                  s.next = null;
       }
 
-      private void performClear() {
-         state.clear(); // cancel any other scheduled changes
-         clearAllWriteLock.lock(); // ensure no other tasks concurrently working
-         try {
-            // to acquire clearAllWriteLock we might have had to wait for N AsyncProcessor to have finished
-            // (as they have to release all clearAllReadLock),
-            // so as they might have put back some work to the state map, clear the state map again inside the writeLock:
-            state.clear();
-            if (trace) log.trace(""Performed clear operation"");
-            int maxRetries = 3;
-            int attemptNumber = 0;
-            boolean successful = false;
-            do {
-               if (attemptNumber > 0 && log.isDebugEnabled())
-                  log.debugf(""Retrying clear() due to previous failure. %s attempts left."", maxRetries - attemptNumber);
-               successful = applyClear();
-               attemptNumber++;
-            } while (!successful && attemptNumber <= maxRetries);
-            if (!successful) {
-               log.unableToClearAsyncStore();
+      private void retryWork(int maxRetries) {
+         for (int attempt = 0; attempt < maxRetries; attempt++) {
+            if (attempt > 0 && log.isDebugEnabled())
+               log.debugf(""Retrying due to previous failure. %s attempts left."", maxRetries - attempt);
+
+            try {
+               AsyncStore.this.applyModificationsSync(modifications);
+               return;
+            } catch (Exception e) {
+               if (log.isDebugEnabled())
+                  log.debug(""Failed to process async modifications"", e);
             }
-         } finally {
-            clearAllWriteLock.unlock();
          }
+         log.unableToProcessAsyncModifications(maxRetries);
       }
-
    }
-}
+}
\ No newline at end of file",2012-10-03T12:24:38Z,30
"@@ -26,9 +26,11 @@
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.NoSuchElementException;
+import java.util.Set;
 
 import static java.util.Collections.singletonMap;
 import static java.util.Collections.unmodifiableMap;
@@ -165,4 +167,20 @@ public static <K, V, E> Map<K, V> transformCollectionToMap(Collection<E> input,
          return unmodifiableMap(map);
       }
    }
+
+   /**
+    * Returns the elements that are present in s1 but which are not present
+    * in s2, without changing the contents of neither s1, nor s2.
+    *
+    * @param s1 first set
+    * @param s2 second set
+    * @param <E> type of objects in Set
+    * @return the elements in s1 that are not in s2
+    */
+   public static <E> Set<E> difference(Set<E> s1, Set<E> s2) {
+      Set<E> copy1 = new HashSet<E>(s1);
+      copy1.removeAll(new HashSet<E>(s2));
+      return copy1;
+   }
+
 }",2012-10-03T12:24:38Z,31
"@@ -295,18 +295,7 @@ public interface EvictionListener<K, V> {
 
       void onEntryEviction(Map<K, V> evicted);
 
-      /**
-       * Callback when an entry has been selected for eviction.
-       * Implementations can use this method to make a decision on whether the
-       * evicted entry should really be evicted, and they can use the return
-       * of this method to signal that.
-       *
-       * @param internalCacheEntry
-       * @return true if the eviction should go through, false if the
-       * eviction process should halt.
-       */
-      boolean onEntryChosenForEviction(V internalCacheEntry);
-
+      void onEntryChosenForEviction(V internalCacheEntry);
    }
 
    static final class NullEvictionListener<K, V> implements EvictionListener<K, V> {
@@ -315,9 +304,8 @@ public void onEntryEviction(Map<K, V> evicted) {
          // Do nothing.
       }
       @Override
-      public boolean onEntryChosenForEviction(V internalCacheEntry) {
+      public void onEntryChosenForEviction(V internalCacheEntry) {
          // Do nothing.
-         return false;
       }
    }
 
@@ -530,11 +518,9 @@ protected boolean removeEldestEntry(Map.Entry<HashEntry<K,V>,V> eldest){
          boolean aboveThreshold = isAboveThreshold();
          if(aboveThreshold){
             HashEntry<K, V> evictedEntry = eldest.getKey();
-            boolean evict = segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
-            if (evict) {
-               segment.remove(evictedEntry.key, evictedEntry.hash, null);
-               evicted.add(evictedEntry);
-            }
+            segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
+            segment.remove(evictedEntry.key, evictedEntry.hash, null);
+            evicted.add(evictedEntry);
          }
          return aboveThreshold;
       }
@@ -608,11 +594,9 @@ public void addAndRemoveEldest(HashEntry<K, V> entry) {
             LRUHashEntry<K, V> evictedEntry = head.nextEntry;
             //remove eldest entry from doubly-linked list
             head.nextEntry.remove();
-            boolean evict = segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
-            if (evict) {
-               segment.remove(evictedEntry.key, evictedEntry.hash, null);
-               evicted.add(evictedEntry);
-            }
+            segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
+            segment.remove(evictedEntry.key, evictedEntry.hash, null);
+            evicted.add(evictedEntry);
          }
       }
 
@@ -1231,9 +1215,10 @@ public Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> en) {
       private void removeFromSegment(Set<HashEntry<K, V>> evicted) {
          for (HashEntry<K, V> e : evicted) {
             ((LIRSHashEntry<K, V>)e).evict();
-            boolean evict = segment.evictionListener.onEntryChosenForEviction(e.value);
-            if (evict)
-               segment.remove(e.key, e.hash, null);
+//            boolean evict =
+            segment.evictionListener.onEntryChosenForEviction(e.value);
+//            if (evict)
+            segment.remove(e.key, e.hash, null);
          }
       }
 ",2012-10-03T12:24:38Z,32
"@@ -23,7 +23,6 @@
 package org.infinispan.config;
 
 import org.infinispan.AdvancedCache;
-import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.DefaultDataContainer;
 import org.infinispan.container.InternalEntryFactoryImpl;
@@ -79,8 +78,7 @@ public void testCustomDataContainerClass() throws IOException {
          AdvancedCache<Object, Object> cache = cm.getCache().getAdvancedCache();
 
          DataContainer ddc = DefaultDataContainer.unBoundedDataContainer(cache.getConfiguration().getConcurrencyLevel());
-         ((DefaultDataContainer) ddc).initialize(null, null,new InternalEntryFactoryImpl(),
-               new ConfigurationBuilder().build(), null);
+         ((DefaultDataContainer) ddc).initialize(null, null,new InternalEntryFactoryImpl());
          QueryableDataContainer.setDelegate(ddc);
 
          // Verify that the default is correctly established
@@ -113,8 +111,7 @@ public void testCustomDataContainer() {
          AdvancedCache<Object, Object> cache = cm.getCache().getAdvancedCache();
 
          DataContainer ddc = DefaultDataContainer.unBoundedDataContainer(cache.getConfiguration().getConcurrencyLevel());
-         ((DefaultDataContainer) ddc).initialize(
-               null, null,new InternalEntryFactoryImpl(), new ConfigurationBuilder().build(), null);
+         ((DefaultDataContainer) ddc).initialize(null, null,new InternalEntryFactoryImpl());
          QueryableDataContainer.setDelegate(ddc);
 
          // Verify that the config is correct",2012-10-03T12:24:38Z,33
"@@ -22,7 +22,6 @@
  */
 package org.infinispan.container;
 
-import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.container.entries.ImmortalCacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.MortalCacheEntry;
@@ -56,8 +55,7 @@ public void tearDown() {
 
    protected DataContainer createContainer() {
       DefaultDataContainer dc = new DefaultDataContainer(16);
-      dc.initialize(null, null, new InternalEntryFactoryImpl(),
-            new ConfigurationBuilder().build(), null);
+      dc.initialize(null, null, new InternalEntryFactoryImpl());
       return dc;
    }
 ",2012-10-03T12:24:38Z,34
"@@ -0,0 +1,297 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.loaders.decorators;
+
+import java.util.concurrent.locks.ReentrantLock;
+
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.cache.StoreConfigurationBuilder;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.eviction.EvictionStrategy;
+import org.infinispan.loaders.CacheLoaderConfig;
+import org.infinispan.loaders.CacheLoaderMetadata;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.test.CacheManagerCallable;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+
+import org.testng.annotations.Test;
+
+@Test(groups = ""unit"", testName = ""loaders.decorators.AsyncTest"")
+public class AsyncStoreEvictionTest {
+
+   // set to false to fix all the tests
+   private static final boolean USE_ASYNC_STORE = true;
+
+   private static ConfigurationBuilder config(boolean passivation, int threads) {
+      ConfigurationBuilder config = new ConfigurationBuilder();
+      config.expiration().wakeUpInterval(100);
+      config.eviction().maxEntries(1).strategy(EvictionStrategy.LRU);
+      StoreConfigurationBuilder store = config.loaders().passivation(passivation).addStore().cacheStore(new LockableCacheStore());
+      if (USE_ASYNC_STORE)
+         store.async().enable().threadPoolSize(threads);
+      return config;
+   }
+
+   private final static ThreadLocal<LockableCacheStore> STORE = new ThreadLocal<LockableCacheStore>();
+
+   public static class LockableCacheStoreConfig extends DummyInMemoryCacheStore.Cfg {
+      private static final long serialVersionUID = 1L;
+
+      public LockableCacheStoreConfig() {
+         setCacheLoaderClassName(LockableCacheStore.class.getName());
+      }
+   }
+
+   @CacheLoaderMetadata(configurationClass = LockableCacheStoreConfig.class)
+   public static class LockableCacheStore extends DummyInMemoryCacheStore {
+      private final ReentrantLock lock = new ReentrantLock();
+
+      public LockableCacheStore() {
+         super();
+         STORE.set(this);
+      }
+
+      @Override
+      public Class<? extends CacheLoaderConfig> getConfigurationClass() {
+         return LockableCacheStoreConfig.class;
+      }
+
+      @Override
+      public void store(InternalCacheEntry ed) {
+         lock.lock();
+         try {
+            super.store(ed);
+         } finally {
+            lock.unlock();
+         }
+      }
+
+      @Override
+      public boolean remove(Object key) {
+         lock.lock();
+         try {
+            return super.remove(key);
+         } finally {
+            lock.unlock();
+         }
+      }
+   }
+
+   private static abstract class CacheCallable extends CacheManagerCallable {
+      protected final Cache<String, String> cache;
+      protected final LockableCacheStore store;
+
+      CacheCallable(ConfigurationBuilder builder) {
+         super(TestCacheManagerFactory.createCacheManager(builder));
+         cache = cm.getCache();
+         store = STORE.get();
+      }
+   }
+
+   public void testEndToEndEvictionPassivation() throws Exception {
+      testEndToEndEviction(true);
+   }
+   public void testEndToEndEviction() throws Exception {
+      testEndToEndEviction(false);
+   }
+   private void testEndToEndEviction(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(passivation, 1)) {
+         @Override
+         public void call() {
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.put(""k1"", ""v1"");
+               cache.put(""k2"", ""v2""); // force eviction of ""k1""
+               TestingUtil.sleepThread(100); // wait until the only AsyncProcessor thread is blocked
+               cache.put(""k3"", ""v3"");
+               cache.put(""k4"", ""v4""); // force eviction of ""k3""
+
+               assert ""v3"".equals(cache.get(""k3"")) : ""cache must return k3 == v3 (was: "" + cache.get(""k3"") + "")"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testEndToEndUpdatePassivation() throws Exception {
+      testEndToEndUpdate(true);
+   }
+   public void testEndToEndUpdate() throws Exception {
+      testEndToEndUpdate(false);
+   }
+   private void testEndToEndUpdate(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(passivation, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v0"");
+            cache.put(""k2"", ""v2""); // force eviction of ""k1""
+
+            // wait for k1 == v1 to appear in store
+            while (store.load(""k1"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.put(""k3"", ""v3"");
+               cache.put(""k4"", ""v4""); // force eviction of ""k3""
+               TestingUtil.sleepThread(100); // wait until the only AsyncProcessor thread is blocked
+               cache.put(""k1"", ""v1"");
+               cache.put(""k5"", ""v5""); // force eviction of ""k1""
+
+               assert ""v1"".equals(cache.get(""k1"")) : ""cache must return k1 == v1 (was: "" + cache.get(""k1"") + "")"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testEndToEndRemovePassivation() throws Exception {
+      testEndToEndRemove(true);
+   }
+   public void testEndToEndRemove() throws Exception {
+      testEndToEndRemove(false);
+   }
+   private void testEndToEndRemove(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(passivation, 2)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2""); // force eviction of ""k1""
+
+            // wait for ""k1"" to appear in store
+            while (store.load(""k1"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.remove(""k1"");
+               TestingUtil.sleepThread(100); // wait until the first AsyncProcessor thread is blocked
+               cache.remove(""k1""); // make second AsyncProcessor thread burn asyncProcessorIds
+               TestingUtil.sleepThread(200); // wait for reaper to collect InternalNullEntry
+
+               assert null == cache.get(""k1"") : ""cache must return k1 == null (was: "" + cache.get(""k1"") + "")"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testNPE() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.remove(""k1"");
+            // this causes NPE in AsyncStore.isLocked(InternalNullEntry.getKey())
+            cache.put(""k2"", ""v2"");
+         }
+      });
+   }
+
+   public void testLIRS() throws Exception {
+      ConfigurationBuilder config = config(false, 1);
+      config.eviction().strategy(EvictionStrategy.LIRS).maxEntries(1);
+      TestingUtil.withCacheManager(new CacheCallable(config) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2"");
+            cache.put(""k1"", ""v3"");
+            cache.put(""k2"", ""v4"");
+            cache.put(""k3"", ""v3"");
+            cache.put(""k4"", ""v4"");
+         }
+      });
+   }
+
+   public void testSize() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2"");
+
+            assert cache.size() == 1 : ""cache size must be 1, was: "" + cache.size();
+         }
+      });
+   }
+
+   public void testSizeAfterExpiration() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2"");
+            TestingUtil.sleepThread(200);
+
+            assert !(cache.size() == 2) : ""expiry doesn't work even after expiration"";
+         }
+      });
+   }
+
+   public void testSizeAfterEvict() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.evict(""k1"");
+
+            assert cache.size() == 0 : ""cache size must be 0, was: "" + cache.size();
+         }
+      });
+   }
+
+   public void testSizeAfterRemove() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.remove(""k1"");
+
+            assert cache.size() == 0 : ""cache size must be 0, was: "" + cache.size();
+         }
+      });
+   }
+
+   public void testSizeAfterRemoveAndExpiration() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.remove(""k1"");
+            int size = cache.size();
+            TestingUtil.sleepThread(200);
+
+            assert !(size == 1 && cache.size() == 0) : ""remove only works after expiration"";
+         }
+      });
+   }
+}",2012-10-03T12:24:38Z,35
"@@ -35,6 +35,7 @@
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStoreConfigurationBuilder;
 import org.infinispan.loaders.modifications.Modification;
+import org.infinispan.loaders.modifications.Remove;
 import org.infinispan.loaders.modifications.Store;
 import org.infinispan.test.CacheManagerCallable;
 import org.infinispan.test.TestingUtil;
@@ -44,9 +45,9 @@
 import org.testng.annotations.Test;
 
 import java.util.Collection;
+import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
@@ -249,11 +250,11 @@ public MockAsyncStore(CountDownLatch modApplyLatch, CountDownLatch lockedWaitLat
       }
 
       @Override
-      protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
+      protected void applyModificationsSync(List<Modification> mods)
             throws CacheLoaderException {
          try {
             // Wait for signal to do the modification
-            if (mods.containsKey(1) && !isSkip(mods.get(1))) {
+            if (containsModificationForKey(1, mods) && !isSkip(findModificationForKey(1, mods))) {
                log.tracef(""Wait to apply modifications: %s"", mods);
                lockedWaitLatch.countDown();
                modApplyLatch.await(60, TimeUnit.SECONDS);
@@ -265,6 +266,30 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          }
       }
 
+      private boolean containsModificationForKey(Object key, List<Modification> mods) {
+         return findModificationForKey(key, mods) != null;
+      }
+
+      private Modification findModificationForKey(Object key, List<Modification> mods) {
+         for (Modification modification : mods) {
+            switch (modification.getType()) {
+               case STORE:
+                  Store store = (Store) modification;
+                  if (store.getStoredEntry().getKey().equals(key))
+                     return store;
+                  break;
+               case REMOVE:
+                  Remove remove = (Remove) modification;
+                  if (remove.getKey().equals(key))
+                     return remove;
+                  break;
+               default:
+                  return null;
+            }
+         }
+         return null;
+      }
+
       private boolean isSkip(Modification mod) {
          if (mod instanceof Store) {
             InternalCacheEntry storedEntry = ((Store) mod).getStoredEntry();",2012-10-03T12:24:38Z,36
"@@ -22,18 +22,23 @@
  */
 package org.infinispan.loaders.decorators;
 
+import org.infinispan.Cache;
 import org.infinispan.CacheException;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
 import org.infinispan.test.fwk.TestInternalCacheEntryFactory;
+import org.infinispan.loaders.CacheLoaderConfig;
 import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.CacheLoaderMetadata;
 import org.infinispan.loaders.CacheStore;
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
 import org.infinispan.loaders.modifications.Clear;
 import org.infinispan.loaders.modifications.Modification;
 import org.infinispan.loaders.modifications.Remove;
 import org.infinispan.loaders.modifications.Store;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.test.AbstractInfinispanTest;
+import org.infinispan.test.CacheManagerCallable;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.transaction.xa.TransactionFactory;
@@ -46,7 +51,6 @@
 import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;
@@ -55,6 +59,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.locks.ReentrantLock;
 
 import static org.infinispan.test.TestingUtil.k;
 import static org.infinispan.test.TestingUtil.v;
@@ -168,6 +173,8 @@ public void testThreadSafetyWritingDiffValuesForKey(Method m) throws Exception {
    }
 
    public void testTransactionalModificationsHappenInDiffThread(Method m) throws Exception {
+      final int waitTimeout = 10;
+      final TimeUnit waitUnit = TimeUnit.SECONDS;
       try {
          final TransactionFactory gtf = new TransactionFactory();
          gtf.init(false, false, true, false);
@@ -177,19 +184,30 @@ public void testTransactionalModificationsHappenInDiffThread(Method m) throws Ex
          DummyInMemoryCacheStore underlying = new DummyInMemoryCacheStore();
          store = new AsyncStore(underlying, asyncConfig) {
             @Override
-            protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
-               for (Map.Entry<Object, Modification> entry : mods.entrySet()) {
-                  localMods.put(entry.getKey(), entry.getValue());
-               }
+            protected void applyModificationsSync(List<Modification> mods) throws CacheLoaderException {
+               for (Modification mod : mods)
+                  localMods.put(getKey(mod), mod);
+
                super.applyModificationsSync(mods);
                try {
-                  barrier.await(5, TimeUnit.SECONDS);
+                  barrier.await(waitTimeout, waitUnit);
                } catch (TimeoutException e) {
                   assert false : ""Timed out applying for modifications"";
                } catch (Exception e) {
                   throw new CacheLoaderException(""Barrier failed"", e);
                }
             }
+
+            private Object getKey(Modification modification) {
+               switch (modification.getType()) {
+                  case STORE:
+                     return ((Store) modification).getStoredEntry().getKey();
+                  case REMOVE:
+                     return ((Remove) modification).getKey();
+                  default:
+                     return null;
+               }
+            }
          };
          dummyCfg = new DummyInMemoryCacheStore.Cfg();
          dummyCfg.setStoreName(m.getName());
@@ -208,7 +226,8 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert !store.containsKey(k2);
 
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit); // Wait for store
+         barrier.await(waitTimeout, waitUnit); // Wait for remove
          assert store.load(k2).getValue().equals(v2);
          assert !store.containsKey(k1);
          assert 2 == localMods.size();
@@ -221,6 +240,8 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
    }
 
    public void testTransactionalModificationsAreCoalesced(Method m) throws Exception {
+      final int waitTimeout = 10;
+      final TimeUnit waitUnit = TimeUnit.SECONDS;
       try {
          final TransactionFactory gtf = new TransactionFactory();
          gtf.init(false, false, true, false);
@@ -251,10 +272,12 @@ public void clear() {
          };
          store = new AsyncStore(underlying, asyncConfig) {
             @Override
-            protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
+            protected void applyModificationsSync(List<Modification> mods)
+                  throws CacheLoaderException {
                super.applyModificationsSync(mods);
                try {
-                  barrier.await(5, TimeUnit.SECONDS);
+                  log.tracef(""Wait to apply modifications: %s"", mods);
+                  barrier.await(waitTimeout, waitUnit);
                } catch (TimeoutException e) {
                   assert false : ""Timed out applying for modifications"";
                } catch (Exception e) {
@@ -280,7 +303,9 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS); //modifications applied all at once
+         log.tracef(""Wait for modifications to be queued: %s"", mods);
+         barrier.await(waitTimeout, waitUnit); // Wait for single store to be applied
+         barrier.await(waitTimeout, waitUnit); // Wait for single remove to be applied
          assert 1 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 1 == removeCount.get();
          assert 0 == clearCount.get();
@@ -301,7 +326,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit);
          assert 0 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 1 == removeCount.get();
          assert 1 == clearCount.get();
@@ -322,7 +347,9 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit); // Wait for store to be applied
+         barrier.await(waitTimeout, waitUnit); // Wait for first removal to be applied
+         barrier.await(waitTimeout, waitUnit); // Wait for second removal to be applied
          assert 1 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 2 == removeCount.get();
          assert 0 == clearCount.get();
@@ -340,7 +367,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit);
          assert 0 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 1 == removeCount.get();
          assert 1 == clearCount.get();
@@ -358,7 +385,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit);
          assert 1 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 0 == removeCount.get();
          assert 1 == clearCount.get();
@@ -375,94 +402,38 @@ private void doTestPut(int number, String key, String value) throws Exception {
          store.store(cacheEntry);
       }
 
-      store.stop();
-      store.start();
-
-      InternalCacheEntry[] entries = new InternalCacheEntry[number];
-      for (int i = 0; i < number; i++) {
-         entries[i] = store.load(key + i);
-      }
-
       for (int i = 0; i < number; i++) {
-         InternalCacheEntry entry = entries[i];
-         if (entry != null) {
-            assert entry.getValue().equals(value + i);
-         } else {
-            while (entry == null) {
-               entry = store.load(key + i);
-               if (entry != null) {
-                  assert entry.getValue().equals(value + i);
-               } else {
-                  TestingUtil.sleepThreadInt(20, ""still waiting for key to appear: "" + key + i);
-               }
-            }
-         }
+         InternalCacheEntry ice = store.load(key + i);
+         assert ice != null && (value + i).equals(ice.getValue());
       }
    }
 
    private void doTestSameKeyPut(int number, String key, String value) throws Exception {
       for (int i = 0; i < number; i++) {
          store.store(TestInternalCacheEntryFactory.create(key, value + i));
       }
-
-      store.stop();
-      store.start();
-      InternalCacheEntry entry;
-      boolean success = false;
-      for (int i = 0; i < 120; i++) {
-         TestingUtil.sleepThreadInt(20, null);
-         entry = store.load(key);
-         success = entry.getValue().equals(value + (number - 1));
-         if (success) break;
-      }
-      assert success;
+      InternalCacheEntry ice = store.load(key);
+      assert ice != null && (value + (number - 1)).equals(ice.getValue());
    }
 
    private void doTestRemove(int number, String key) throws Exception {
       for (int i = 0; i < number; i++) store.remove(key + i);
 
-      store.stop();//makes sure the store is flushed
-      store.start();
-
-      InternalCacheEntry[] entries = new InternalCacheEntry[number];
-      for (int i = 0; i < number; i++) {
-         entries[i] = store.load(key + i);
-      }
-
       for (int i = 0; i < number; i++) {
-         InternalCacheEntry entry = entries[i];
-         while (entry != null) {
-            TestingUtil.sleepThreadInt(20, ""still waiting for key to be removed: "" + key + i);
-            entry = store.load(key + i);
-         }
+         assert store.load(key + i) == null;
       }
    }
 
    private void doTestSameKeyRemove(String key) throws Exception {
       store.remove(key);
-      InternalCacheEntry entry;
-      do {
-         TestingUtil.sleepThreadInt(20, ""still waiting for key to be removed: "" + key);
-         entry = store.load(key);
-      } while (entry != null);
+      assert store.load(key) == null;
    }
 
    private void doTestClear(int number, String key) throws Exception {
       store.clear();
-      store.stop();
-      store.start();
-
-      InternalCacheEntry[] entries = new InternalCacheEntry[number];
-      for (int i = 0; i < number; i++) {
-         entries[i] = store.load(key + i);
-      }
 
       for (int i = 0; i < number; i++) {
-         InternalCacheEntry entry = entries[i];
-         while (entry != null) {
-            TestingUtil.sleepThreadInt(20, ""still waiting for key to be removed: "" + key + i);
-            entry = store.load(key + i);
-         }
+         assert store.load(key + i) == null;
       }
    }
 
@@ -483,23 +454,207 @@ static class MockAsyncStore extends AsyncStore {
       }
 
       @Override
-      protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
-         if (mods.get(key) != null && block) {
+      protected void applyModificationsSync(List<Modification> mods) throws CacheLoaderException {
+         boolean keyFound = findModificationForKey(key, mods) != null;
+         if (keyFound && block) {
             log.trace(""Wait for v1 latch"");
             try {
                v2Latch.countDown();
                block = false;
                v1Latch.await(2, TimeUnit.SECONDS);
             } catch (InterruptedException e) {
+               Thread.currentThread().interrupt();
             }
             super.applyModificationsSync(mods);
-         } else if (mods.get(key) != null && !block) {
+         } else if (keyFound && !block) {
             log.trace(""Do v2 modification and unleash v1 latch"");
             super.applyModificationsSync(mods);
             v1Latch.countDown();
             endLatch.countDown();
          }
       }
 
+      private Modification findModificationForKey(Object key, List<Modification> mods) {
+         for (Modification modification : mods) {
+            switch (modification.getType()) {
+               case STORE:
+                  Store store = (Store) modification;
+                  if (store.getStoredEntry().getKey().equals(key))
+                     return store;
+                  break;
+               case REMOVE:
+                  Remove remove = (Remove) modification;
+                  if (remove.getKey().equals(key))
+                     return remove;
+                  break;
+               default:
+                  return null;
+            }
+         }
+         return null;
+      }
+
+   }
+
+   private final static ThreadLocal<LockableCacheStore> STORE = new ThreadLocal<LockableCacheStore>();
+
+   public static class LockableCacheStoreConfig extends DummyInMemoryCacheStore.Cfg {
+      private static final long serialVersionUID = 1L;
+
+      public LockableCacheStoreConfig() {
+         setCacheLoaderClassName(LockableCacheStore.class.getName());
+      }
+   }
+
+   @CacheLoaderMetadata(configurationClass = LockableCacheStoreConfig.class)
+   public static class LockableCacheStore extends DummyInMemoryCacheStore {
+      private final ReentrantLock lock = new ReentrantLock();
+
+      public LockableCacheStore() {
+         super();
+         STORE.set(this);
+      }
+
+      @Override
+      public Class<? extends CacheLoaderConfig> getConfigurationClass() {
+         return LockableCacheStoreConfig.class;
+      }
+
+      @Override
+      public void store(InternalCacheEntry ed) {
+         lock.lock();
+         try {
+            super.store(ed);
+         } finally {
+            lock.unlock();
+         }
+      }
+
+      @Override
+      public boolean remove(Object key) {
+         lock.lock();
+         try {
+            return super.remove(key);
+         } finally {
+            lock.unlock();
+         }
+      }
+   }
+
+   public void testModificationQueueSize(final Method m) throws Exception {
+      LockableCacheStore underlying = new LockableCacheStore();
+      asyncConfig.modificationQueueSize(10);
+      store = new AsyncStore(underlying, asyncConfig);
+      store.init(new LockableCacheStoreConfig(), null, null);
+      store.start();
+      try {
+         final CountDownLatch done = new CountDownLatch(1);
+
+         underlying.lock.lock();
+         try {
+            Thread t = new Thread() {
+               @Override
+               public void run() {
+                  try {
+                     for (int i = 0; i < 100; i++)
+                        store.store(TestInternalCacheEntryFactory.create(k(m, i), v(m, i)));
+                  } catch (Exception e) {
+                     log.error(""Error storing entry"", e);
+                  }
+                  done.countDown();
+               }
+            };
+            t.start();
+
+            assert !done.await(1, TimeUnit.SECONDS) : ""Background thread should have blocked after adding 10 entries"";
+         } finally {
+            underlying.lock.unlock();
+         }
+      } finally {
+         store.stop();
+      }
+   }
+
+   private static abstract class OneEntryCacheManagerCallable extends CacheManagerCallable {
+      protected final Cache<String, String> cache;
+      protected final LockableCacheStore store;
+
+      private static ConfigurationBuilder config(boolean passivation) {
+         ConfigurationBuilder config = new ConfigurationBuilder();
+         config.eviction().maxEntries(1).loaders().passivation(passivation).addStore()
+               .cacheStore(new LockableCacheStore()).async().enable();
+         return config;
+      }
+
+      OneEntryCacheManagerCallable(boolean passivation) {
+         super(TestCacheManagerFactory.createCacheManager(config(passivation)));
+         cache = cm.getCache();
+         store = STORE.get();
+      }
+   }
+
+   public void testEndToEndPutPutPassivation() throws Exception {
+      doTestEndToEndPutPut(true);
+   }
+
+   public void testEndToEndPutPut() throws Exception {
+      doTestEndToEndPutPut(false);
+   }
+
+   private void doTestEndToEndPutPut(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new OneEntryCacheManagerCallable(passivation) {
+         @Override
+         public void call() {
+            cache.put(""X"", ""1"");
+            cache.put(""Y"", ""1""); // force eviction of ""X""
+
+            // wait for X == 1 to appear in store
+            while (store.load(""X"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.put(""X"", ""2"");
+               cache.put(""Y"", ""2""); // force eviction of ""X""
+
+               assert ""2"".equals(cache.get(""X"")) : ""cache must return X == 2"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testEndToEndPutRemovePassivation() throws Exception {
+      doTestEndToEndPutRemove(true);
+   }
+
+   public void testEndToEndPutRemove() throws Exception {
+      doTestEndToEndPutRemove(false);
+   }
+
+   private void doTestEndToEndPutRemove(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new OneEntryCacheManagerCallable(passivation) {
+         @Override
+         public void call() {
+            cache.put(""X"", ""1"");
+            cache.put(""Y"", ""1""); // force eviction of ""X""
+
+            // wait for ""X"" to appear in store
+            while (store.load(""X"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.remove(""X"");
+
+               assert null == cache.get(""X"") : ""cache must return X == null"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
    }
 }",2012-10-03T12:24:38Z,37
"@@ -28,6 +28,7 @@
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.marshall.TestObjectStreamMarshaller;
 import org.infinispan.test.TestingUtil;
+import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
@@ -38,18 +39,20 @@
 import java.util.*;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.atomic.AtomicInteger;
 
 @CacheLoaderMetadata(configurationClass = DummyInMemoryCacheStore.Cfg.class)
 public class DummyInMemoryCacheStore extends AbstractCacheStore {
    private static final Log log = LogFactory.getLog(DummyInMemoryCacheStore.class);
    private static final boolean trace = log.isTraceEnabled();
+   private static final boolean debug = log.isDebugEnabled();
    static final ConcurrentMap<String, Map<Object, InternalCacheEntry>> stores = new ConcurrentHashMap<String, Map<Object, InternalCacheEntry>>();
-   static final ConcurrentMap<String, ConcurrentMap<String, Integer>> storeStats =
-         new ConcurrentHashMap<String, ConcurrentMap<String, Integer>>();
+   static final ConcurrentMap<String, ConcurrentMap<String, AtomicInteger>> storeStats =
+         new ConcurrentHashMap<String, ConcurrentMap<String, AtomicInteger>>();
    String storeName;
    Map<Object, InternalCacheEntry> store;
    // When a store is 'shared', multiple nodes could be trying to update it concurrently.
-   ConcurrentMap<String, Integer> stats;
+   ConcurrentMap<String, AtomicInteger> stats;
    Cfg config;
 
    public DummyInMemoryCacheStore(String storeName) {
@@ -60,26 +63,14 @@ public DummyInMemoryCacheStore() {
    }
 
    private void record(String method) {
-      boolean replaced;
-      long end = System.currentTimeMillis() + 5000;
-      do {
-         int i = stats.get(method);
-         replaced = stats.replace(method, i, i + 1);
-         if (!replaced) {
-            try {
-               Thread.sleep(200);
-            } catch (InterruptedException e) {
-               Thread.currentThread().interrupt();
-            }
-         }
-      } while (!replaced && end < System.currentTimeMillis());
+      stats.get(method).incrementAndGet();
    }
 
    @Override
    public void store(InternalCacheEntry ed) {
       record(""store"");
       if (ed != null) {
-         if (trace) log.tracef(""Store %s in dummy map store@%s"", ed, Util.hexIdHashCode(store));
+         if (debug) log.debugf(""Store %s in dummy map store@%s"", ed, Util.hexIdHashCode(store));
          config.failIfNeeded(ed.getKey());
          store.put(ed.getKey(), ed);
       }
@@ -123,11 +114,11 @@ public void clear() {
    public boolean remove(Object key) {
       record(""remove"");
       if (store.remove(key) != null) {
-         if (trace) log.tracef(""Removed %s from dummy store"", key);
+         if (debug) log.debugf(""Removed %s from dummy store"", key);
          return true;
       }
 
-      if (trace) log.tracef(""Key %s not present in store, so don't remove"", key);
+      if (debug) log.debugf(""Key %s not present in store, so don't remove"", key);
       return false;
    }
 
@@ -238,7 +229,7 @@ public void start() throws CacheLoaderException {
             log.debugf(""Creating new in-memory cache store %s"", storeName);
          }
 
-         ConcurrentMap<String, Integer> existingStats = storeStats.putIfAbsent(storeName, stats);
+         ConcurrentMap<String, AtomicInteger> existingStats = storeStats.putIfAbsent(storeName, stats);
          if (existing != null) {
             stats = existingStats;
          }
@@ -248,10 +239,10 @@ public void start() throws CacheLoaderException {
       record(""start"");
    }
 
-   private ConcurrentMap<String, Integer> newStatsMap() {
-      ConcurrentMap<String, Integer> m = new ConcurrentHashMap<String, Integer>();
+   private ConcurrentMap<String, AtomicInteger> newStatsMap() {
+      ConcurrentMap<String, AtomicInteger> m = new ConcurrentHashMap<String, AtomicInteger>();
       for (Method method: CacheStore.class.getMethods()) {
-         m.put(method.getName(), 0);
+         m.put(method.getName(), new AtomicInteger(0));
       }
       return m;
    }
@@ -274,11 +265,13 @@ public boolean isEmpty() {
    }
 
    public Map<String, Integer> stats() {
-      return Collections.unmodifiableMap(stats);
+      Map<String, Integer> copy = new HashMap<String, Integer>(stats.size());
+      for (String k: stats.keySet()) copy.put(k, stats.get(k).get());
+      return copy;
    }
 
    public void clearStats() {
-      for (String k: stats.keySet()) stats.put(k, 0);
+      for (String k: stats.keySet()) stats.get(k).set(0);
    }
 
    public void blockUntilCacheStoreContains(Object key, Object expectedValue, long timeout) {
@@ -293,6 +286,57 @@ public void blockUntilCacheStoreContains(Object key, Object expectedValue, long
             timeout, key, expectedValue));
    }
 
+   public void blockUntilCacheStoreContains(Set<Map.Entry<Object, InternalCacheEntry>> expectedState, long timeout) {
+      long killTime = System.currentTimeMillis() + timeout;
+      // Set<? extends Map.Entry<?, InternalCacheEntry>> expectedEntries = expectedState.entrySet();
+      Set<Map.Entry<Object, InternalCacheEntry>> notStored = null;
+      Set<Map.Entry<Object, InternalCacheEntry>> notRemoved = null;
+      while (System.currentTimeMillis() < killTime) {
+         Set<Map.Entry<Object, InternalCacheEntry>> storeEntries = store.entrySet();
+         // Find out which entries might not have been removed from the store
+         notRemoved = InfinispanCollections.difference(storeEntries, expectedState);
+         // Find out which entries might not have been stored
+         notStored = InfinispanCollections.difference(expectedState, storeEntries);
+         if (!notStored.isEmpty() || !notRemoved.isEmpty()) {
+            TestingUtil.sleepThread(5000);
+         } else if (notStored.isEmpty() && notRemoved.isEmpty()) {
+            break;
+         }
+      }
+
+      if ((notStored != null && !notStored.isEmpty()) || (notRemoved != null && !notRemoved.isEmpty())) {
+         if (log.isTraceEnabled()) {
+            log.tracef(""Entries still not stored: %s"", notStored);
+            log.tracef(""Entries still not removed: %s"", notRemoved);
+         }
+         throw new RuntimeException(String.format(
+               ""Timed out waiting (%d ms) for cache store to be flushed. entries-not-stored=[%s], entries-not-removed=[%s]"",
+               timeout, notStored, notRemoved));
+      }
+
+
+//      if (missingEntries != null && !missingEntries.isEmpty())
+//         throw new RuntimeException(String.format(
+//            ""Timed out waiting (%d ms) for cache store to contain entry %s"",
+//            timeout, missingEntries));
+//
+//      long killTime = System.currentTimeMillis() + timeout;
+//      Map.Entry<?, ?> missingEntry = null;
+//      while (System.currentTimeMillis() < killTime) {
+//         for (Map.Entry<?, ?> stateEntry : expectedState.entrySet()) {
+//            InternalCacheEntry entry = store.get(stateEntry.getKey());
+//            if (entry == null || !entry.getValue().equals(stateEntry.getValue())) {
+//               missingEntry = entry;
+//               TestingUtil.sleepThread(50);
+//            }
+//         }
+//      }
+//      if (missingEntry != null)
+//         throw new RuntimeException(String.format(
+//            ""Timed out waiting (%d ms) for cache store to contain entry %s"",
+//            timeout, missingEntry));
+   }
+
    public static class Cfg extends AbstractCacheStoreConfig {
 
       private static final long serialVersionUID = 4258914047690999424L;",2012-10-03T12:24:38Z,38
"@@ -0,0 +1,466 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.stress;
+
+import org.infinispan.container.InternalEntryFactory;
+import org.infinispan.container.InternalEntryFactoryImpl;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.container.versioning.EntryVersion;
+import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.decorators.AbstractDelegatingStore;
+import org.infinispan.loaders.decorators.AsyncStore;
+import org.infinispan.loaders.decorators.AsyncStoreConfig;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.marshall.TestObjectStreamMarshaller;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.util.concurrent.locks.containers.LockContainer;
+import org.infinispan.util.concurrent.locks.containers.ReentrantPerEntryLockContainer;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.testng.annotations.DataProvider;
+import org.testng.annotations.Test;
+
+import java.util.ArrayList;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.TreeMap;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.locks.Lock;
+
+import static java.lang.Math.sqrt;
+
+/**
+ * Async store stress test.
+ *
+ * // TODO: Add a test to verify clear() too!
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(testName = ""stress.AsyncStoreStressTest"", groups = ""stress"",
+      enabled = true, description = ""Disabled by default, designed to be run manually."")
+public class AsyncStoreStressTest {
+
+   static final Log log = LogFactory.getLog(AsyncStoreStressTest.class);
+   static final boolean trace = log.isTraceEnabled();
+
+   static final int CAPACITY = Integer.getInteger(""size"", 100000);
+   static final int LOOP_FACTOR = 10;
+   static final long RUNNING_TIME = Integer.getInteger(""time"", 1) * 60 * 1000;
+   static final Random RANDOM = new Random(12345);
+
+   private volatile CountDownLatch latch;
+   private List<String> keys = new ArrayList<String>();
+   private InternalEntryFactory entryFactory = new InternalEntryFactoryImpl();
+   private Map<Object, InternalCacheEntry> expectedState = new ConcurrentHashMap<Object, InternalCacheEntry>();
+
+   // Lock container that mimics per-key locking produced by the cache.
+   // This per-key lock holder provides guarantees that the final expected
+   // state has not been affected by ordering issues such as this:
+   //
+   // (Thread-200:) Enqueuing modification Store{storedEntry=
+   // ImmortalCacheEntry{key=key165168, value=ImmortalCacheValue {value=60483}}}
+   // (Thread-194:) Enqueuing modification Store{storedEntry=
+   // ImmortalCacheEntry{key=key165168, value=ImmortalCacheValue {value=61456}}}
+   // (Thread-194:) Expected state updated with key=key165168, value=61456
+   // (Thread-200:) Expected state updated with key=key165168, value=60483
+   private LockContainer locks = new ReentrantPerEntryLockContainer(32);
+
+   private Map<String, AbstractDelegatingStore> createAsyncStores() throws CacheLoaderException {
+      Map<String, AbstractDelegatingStore> stores = new TreeMap<String, AbstractDelegatingStore>();
+      stores.put(""ASYNC"", createAsyncStore());
+      return stores;
+   }
+
+   private AsyncStore createAsyncStore() throws CacheLoaderException {
+      DummyInMemoryCacheStore backendStore = createBackendStore(""async2"");
+      AsyncStoreConfig asyncCfg = new AsyncStoreConfig();
+      asyncCfg.modificationQueueSize(0);
+      AsyncStore store = new AsyncStore(backendStore, asyncCfg);
+      store.init(backendStore.getCacheStoreConfig(), null, new TestObjectStreamMarshaller());
+      store.start();
+      return store;
+   }
+
+   private DummyInMemoryCacheStore createBackendStore(String storeName) throws CacheLoaderException {
+      DummyInMemoryCacheStore store = new DummyInMemoryCacheStore();
+      store.init(new DummyInMemoryCacheStore.Cfg(storeName), null, new TestObjectStreamMarshaller());
+      store.start();
+      return store;
+   }
+
+   @DataProvider(name = ""readWriteRemove"")
+   public Object[][] independentReadWriteRemoveParams() {
+      return new Object[][]{
+            new Object[]{CAPACITY, 3 * CAPACITY, 90, 9, 1},
+            new Object[]{CAPACITY, 3 * CAPACITY, 9, 1, 0},
+      };
+   }
+
+   @Test(dataProvider = ""readWriteRemove"", enabled = true)
+   public void testReadWriteRemove(int capacity, int numKeys,
+         int readerThreads, int writerThreads, int removerThreads) throws Exception {
+      System.out.printf(""Testing independent read/write/remove performance "" +
+            ""with capacity %d, keys %d, readers %d, writers %d, removers %d\n"",
+            capacity, numKeys, readerThreads, writerThreads, removerThreads);
+
+      generateKeyList(numKeys);
+
+      Map<String, AbstractDelegatingStore> stores = createAsyncStores();
+
+      for (Map.Entry<String, AbstractDelegatingStore> e : stores.entrySet()) {
+         mapTestReadWriteRemove(e.getKey(), e.getValue(), numKeys,
+               readerThreads, writerThreads, removerThreads);
+         e.setValue(null);
+      }
+   }
+
+   private void mapTestReadWriteRemove(String name, AbstractDelegatingStore store,
+         int numKeys, int readerThreads, int writerThreads, int removerThreads) throws Exception {
+      DummyInMemoryCacheStore delegate = (DummyInMemoryCacheStore) store.getDelegate();
+      try {
+         // warm up for 1 second
+         System.out.printf(""[store=%s] Warming up\n"", name);
+         runMapTestReadWriteRemove(name, store, readerThreads, writerThreads, removerThreads, 1000);
+
+         // real test
+         System.out.printf(""[store=%s] Testing...\n"", name);
+         TotalStats perf = runMapTestReadWriteRemove(name, store, readerThreads, writerThreads, removerThreads, RUNNING_TIME);
+
+         // Wait until the cache store contains the expected state
+         System.out.printf(""[store=%s] Verify contents\n"", name);
+         TestingUtil.sleepThread(10000); // Wait a bit before starting to verify contents
+         delegate.blockUntilCacheStoreContains(expectedState.entrySet(), 60000);
+
+         System.out.printf(""Container %-12s  "", name);
+         System.out.printf(""Ops/s %10.2f  "", perf.getTotalOpsPerSec());
+         System.out.printf(""Gets/s %10.2f  "", perf.getOpsPerSec(""GET""));
+         System.out.printf(""Puts/s %10.2f  "", perf.getOpsPerSec(""PUT""));
+         System.out.printf(""Removes/s %10.2f  "", perf.getOpsPerSec(""REMOVE""));
+         System.out.printf(""HitRatio %10.2f  "", perf.getTotalHitRatio() * 100);
+         System.out.printf(""Size %10d  "", store.loadAllKeys(null).size());
+         double stdDev = computeStdDev(store, numKeys);
+         System.out.printf(""StdDev %10.2f\n"", stdDev);
+      } finally {
+         // Clean up state, expected state and keys
+         expectedState.clear();
+         delegate.clear();
+      }
+   }
+
+   private TotalStats runMapTestReadWriteRemove(String name, final AbstractDelegatingStore store, int numReaders, int numWriters,
+         int numRemovers, final long runningTimeout) throws Exception {
+      latch = new CountDownLatch(1);
+      final TotalStats perf = new TotalStats();
+      List<Thread> threads = new LinkedList<Thread>();
+
+      for (int i = 0; i < numReaders; i++) {
+         Thread reader = new WorkerThread(""worker-"" + name + ""-get-"" + i, runningTimeout, perf, readOperation(store));
+         threads.add(reader);
+      }
+
+      for (int i = 0; i < numWriters; i++) {
+         Thread writer = new WorkerThread(""worker-"" + name + ""-put-"" + i, runningTimeout, perf, writeOperation(store));
+         threads.add(writer);
+      }
+
+      for (int i = 0; i < numRemovers; i++) {
+         Thread remover = new WorkerThread(""worker-"" + name + ""-remove-"" + i, runningTimeout, perf, removeOperation(store));
+         threads.add(remover);
+      }
+
+      for (Thread t : threads)
+         t.start();
+      latch.countDown();
+
+      for (Thread t : threads)
+         t.join();
+
+      return perf;
+   }
+
+   private void generateKeyList(int numKeys) {
+      // without this we keep getting OutOfMemoryErrors
+      keys = null;
+      keys = new ArrayList<String>(numKeys * LOOP_FACTOR);
+      for (int i = 0; i < numKeys * LOOP_FACTOR; i++) {
+         keys.add(""key"" + nextIntGaussian(numKeys));
+      }
+   }
+
+   private int nextIntGaussian(int numKeys) {
+      double gaussian = RANDOM.nextGaussian();
+      if (gaussian < -3 || gaussian > 3)
+         return nextIntGaussian(numKeys);
+
+      return (int) Math.abs((gaussian + 3) * numKeys / 6);
+   }
+
+   private void waitForStart() {
+      try {
+         latch.await();
+      } catch (InterruptedException e) {
+         throw new RuntimeException(e);
+      }
+   }
+
+   private Operation<String, Integer> readOperation(AbstractDelegatingStore store) {
+      return new Operation<String, Integer>(store, ""GET"") {
+         @Override
+         public boolean call(String key, long run) {
+            try {
+               InternalCacheEntry ice = store.load(key);
+               if (trace)
+                  log.tracef(""Loaded key=%s, value=%s"", key, ice != null ? ice.getValue() : ""null"");
+               return ice != null;
+            } catch (CacheLoaderException e) {
+               e.printStackTrace();
+               return false;
+            }
+         }
+      };
+   }
+
+   private Operation<String, Integer> writeOperation(AbstractDelegatingStore store) {
+      return new Operation<String, Integer>(store, ""PUT"") {
+         @Override
+         public boolean call(final String key, long run) {
+            final int value = (int) run;
+            final InternalCacheEntry entry =
+                  entryFactory.create(key, value, (EntryVersion) null);
+            // Store acquiring locks and catching exceptions
+            boolean result = withStore(key, new Callable<Boolean>() {
+               @Override
+               public Boolean call() throws Exception {
+                  store.store(entry);
+                  expectedState.put(key, entry);
+                  if (trace)
+                     log.tracef(""Expected state updated with key=%s, value=%s"", key, value);
+                  return true;
+               }
+            });
+            return result;
+         }
+      };
+   }
+
+   private Operation<String, Integer> removeOperation(AbstractDelegatingStore store) {
+      return new Operation<String, Integer>(store, ""REMOVE"") {
+         @Override
+         public boolean call(final String key, long run) {
+            // Remove acquiring locks and catching exceptions
+            boolean result = withStore(key, new Callable<Boolean>() {
+               @Override
+               public Boolean call() throws Exception {
+                  boolean removed = store.remove(key);
+                  if (removed) {
+                     expectedState.remove(key);
+                     if (trace)
+                        log.tracef(""Expected state removed key=%s"", key);
+                  }
+                  return true;
+               }
+            });
+            return result;
+         }
+      };
+   }
+   
+   private boolean withStore(String key, Callable<Boolean> call) {
+      Lock lock = null;
+      boolean result = false;
+      try {
+         lock = locks.acquireLock(Thread.currentThread(), key, 30, TimeUnit.SECONDS);
+         if (lock != null) {
+            result = call.call().booleanValue();
+         }
+      } catch (CacheLoaderException e) {
+         e.printStackTrace();
+         result = false;
+      } catch (InterruptedException e) {
+         e.printStackTrace();
+         result = false;
+      } finally {
+         if (lock == null) return false;
+         else {
+            lock.unlock();
+            return result;
+         }
+      }
+   }
+
+   private double computeStdDev(AbstractDelegatingStore store, int numKeys) throws CacheLoaderException {
+      // The keys closest to the mean are suposed to be accessed more often
+      // So we score each map by the standard deviation of the keys in the map
+      // at the end of the test
+      double variance = 0;
+      Set<Object> keys = store.loadAllKeys(null);
+      for (Object key : keys) {
+         double value = Integer.parseInt(((String )key).substring(3));
+         variance += (value - numKeys / 2) * (value - numKeys / 2);
+      }
+      return sqrt(variance / keys.size());
+   }
+
+   private class WorkerThread extends Thread {
+      private final long runningTimeout;
+      private final TotalStats perf;
+      private Operation<String, Integer> op;
+
+      public WorkerThread(String name, long runningTimeout, TotalStats perf, Operation<String, Integer> op) {
+         super(name);
+         this.runningTimeout = runningTimeout;
+         this.perf = perf;
+         this.op = op;
+      }
+
+      public void run() {
+         waitForStart();
+         long startMilis = System.currentTimeMillis();
+         long endMillis = startMilis + runningTimeout;
+         int keyIndex = RANDOM.nextInt(keys.size());
+         long runs = 0;
+         long missCount = 0;
+         while ((runs & 0x3FFF) != 0 || System.currentTimeMillis() < endMillis) {
+            boolean hit = op.call(keys.get(keyIndex), runs);
+            if (!hit) missCount++;
+            keyIndex++;
+            runs++;
+            if (keyIndex >= keys.size()) {
+               keyIndex = 0;
+            }
+         }
+         perf.addStats(op.getName(), runs, System.currentTimeMillis() - startMilis, missCount);
+      }
+   }
+
+   private static abstract class Operation<K, V> {
+      protected final AbstractDelegatingStore store;
+      protected final String name;
+
+      public Operation(AbstractDelegatingStore store, String name) {
+         this.store = store;
+         this.name = name;
+      }
+
+      /**
+       * @return Return true for a hit, false for a miss.
+       */
+      public abstract boolean call(K key, long run);
+
+      public String getName() {
+         return name;
+      }
+   }
+
+   private static class TotalStats {
+      private ConcurrentHashMap<String, OpStats> statsMap = new ConcurrentHashMap<String, OpStats>();
+
+      public void addStats(String opName, long opCount, long runningTime, long missCount) {
+         OpStats s = new OpStats(opName, opCount, runningTime, missCount);
+         OpStats old = statsMap.putIfAbsent(opName, s);
+         boolean replaced = old == null;
+         while (!replaced) {
+            old = statsMap.get(opName);
+            s = new OpStats(old, opCount, runningTime, missCount);
+            replaced = statsMap.replace(opName, old, s);
+         }
+      }
+
+      public double getOpsPerSec(String opName) {
+         OpStats s = statsMap.get(opName);
+         if (s == null) return 0;
+         return s.opCount * 1000. / s.runningTime * s.threadCount;
+      }
+
+      public double getTotalOpsPerSec() {
+         long totalOpCount = 0;
+         long totalRunningTime = 0;
+         long totalThreadCount = 0;
+         for (Map.Entry<String, OpStats> e : statsMap.entrySet()) {
+            OpStats s = e.getValue();
+            totalOpCount += s.opCount;
+            totalRunningTime += s.runningTime;
+            totalThreadCount += s.threadCount;
+         }
+         return totalOpCount * 1000. / totalRunningTime * totalThreadCount;
+      }
+
+      public double getHitRatio(String opName) {
+         OpStats s = statsMap.get(opName);
+         if (s == null) return 0;
+         return 1 - 1. * s.missCount / s.opCount;
+      }
+
+      public double getTotalHitRatio() {
+         long totalOpCount = 0;
+         long totalMissCount = 0;
+         for (Map.Entry<String, OpStats> e : statsMap.entrySet()) {
+            OpStats s = e.getValue();
+            totalOpCount += s.opCount;
+            totalMissCount += s.missCount;
+         }
+         return 1 - 1. * totalMissCount / totalOpCount;
+      }
+   }
+
+   private static class OpStats {
+      public final String opName;
+      public final int threadCount;
+      public final long opCount;
+      public final long runningTime;
+      public final long missCount;
+
+      private OpStats(String opName, long opCount, long runningTime, long missCount) {
+         this.opName = opName;
+         this.threadCount = 1;
+         this.opCount = opCount;
+         this.runningTime = runningTime;
+         this.missCount = missCount;
+      }
+
+      private OpStats(OpStats base, long opCount, long runningTime, long missCount) {
+         this.opName = base.opName;
+         this.threadCount = base.threadCount + 1;
+         this.opCount = base.opCount + opCount;
+         this.runningTime = base.runningTime + runningTime;
+         this.missCount = base.missCount + missCount;
+      }
+   }
+
+   @Test(enabled = false) // Disable explicitly to avoid TestNG thinking this is a test!!
+   public static void main(String[] args) throws Exception {
+      AsyncStoreStressTest test = new AsyncStoreStressTest();
+      test.testReadWriteRemove(100000, 300000, 90, 9, 1);
+      test.testReadWriteRemove(10000, 30000, 9, 1, 0);
+      System.exit(0);
+   }
+
+}",2012-10-03T12:24:38Z,39
"@@ -443,18 +443,20 @@ public void addStats(String opName, long opCount, long runningTime, long missCou
       public double getOpsPerSec(String opName) {
          OpStats s = statsMap.get(opName);
          if (s == null) return 0;
-         return s.opCount * 1000. / s.runningTime;
+         return s.opCount * 1000. / s.runningTime * s.threadCount;
       }
 
       public double getTotalOpsPerSec() {
          long totalOpCount = 0;
          long totalRunningTime = 0;
+         long totalThreadCount = 0;
          for (Map.Entry<String, OpStats> e : statsMap.entrySet()) {
             OpStats s = e.getValue();
             totalOpCount += s.opCount;
-            totalRunningTime = s.runningTime;
+            totalRunningTime += s.runningTime;
+            totalThreadCount += s.threadCount;
          }
-         return totalOpCount * 1000. / totalRunningTime;
+         return totalOpCount * 1000. / totalRunningTime * totalThreadCount;
       }
 
       public double getHitRatio(String opName) {",2012-10-03T12:24:38Z,40
"@@ -0,0 +1,123 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.util;
+
+import org.testng.annotations.Test;
+
+import java.util.HashSet;
+import java.util.Set;
+
+import static org.testng.AssertJUnit.assertEquals;
+import static org.testng.AssertJUnit.assertTrue;
+
+/**
+ * // TODO: Document this
+ *
+ * @author Galder Zamarreño
+ * @since // TODO
+ */
+@Test(testName = ""util.InfinispanCollectionsTest"")
+public class InfinispanCollectionsTest {
+
+   public void testDifferenceNotStored() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+      expected.add(""d"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(1, notStored.size());
+      assertTrue(notStored.contains(""d""));
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(0, notRemoved.size());
+   }
+
+   public void testDifferenceNotRemoved() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+      store.add(""d"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(0, notStored.size());
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(1, notRemoved.size());
+      assertTrue(notRemoved.contains(""d""));
+   }
+
+   public void testDifferenceNotStoreAndNotRemoved() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+      store.add(""d"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+      expected.add(""e"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(1, notStored.size());
+      assertTrue(notStored.contains(""e""));
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(1, notRemoved.size());
+      assertTrue(notRemoved.contains(""d""));
+   }
+
+   public void testNoDifference() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(0, notStored.size());
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(0, notRemoved.size());
+   }
+
+}",2012-10-03T12:24:38Z,31
"@@ -122,10 +122,15 @@ public S purgeSynchronously(boolean b) {
    public void validate() {
       async.validate();
       singletonStore.validate();
+      ConfigurationBuilder builder = getBuilder();
       if (!loaders().shared() && !fetchPersistentState && !purgeOnStartup
-            && getBuilder().clustering().cacheMode().isClustered())
+            && builder.clustering().cacheMode().isClustered())
          log.staleEntriesWithoutFetchPersistentStateOrPurgeOnStartup();
-   }
 
+      if (loaders().shared() && !loaders().preload()
+            && builder.indexing().enabled()
+            && builder.indexing().indexLocalOnly())
+         log.localIndexingWithSharedCacheLoaderRequiresPreload();
+   }
 
 }",2012-08-30T15:45:20Z,41
"@@ -62,6 +62,10 @@ public IndexingConfigurationBuilder enabled(boolean enabled) {
       return this;
    }
 
+   boolean enabled() {
+      return enabled;
+   }
+
    /**
     * If true, only index changes made locally, ignoring remote changes. This is useful if indexes
     * are shared across a cluster to prevent redundant indexing of updates.
@@ -71,6 +75,10 @@ public IndexingConfigurationBuilder indexLocalOnly(boolean b) {
       return this;
    }
 
+   boolean indexLocalOnly() {
+      return indexLocalOnly;
+   }
+
    /**
     * <p>
     * Defines a single property. Can be used multiple times to define all needed properties, but the",2012-08-30T15:45:20Z,42
"@@ -49,4 +49,4 @@ public interface LoaderConfigurationBuilder<T extends LoaderConfiguration, S ext
     */
    S withProperties(Properties p);
 
-}
\ No newline at end of file
+}",2012-08-30T15:45:20Z,43
"@@ -72,6 +72,10 @@ public LoadersConfigurationBuilder preload(boolean b) {
       return this;
    }
 
+   boolean preload() {
+      return preload;
+   }
+
    /**
     * This setting should be set to true when multiple cache instances share the same cache store
     * (e.g., multiple nodes in a cluster using a JDBC-based CacheStore pointing to the same, shared
@@ -173,7 +177,7 @@ public LegacyStoreConfigurationBuilder addStore() {
    /**
     * Adds a cache store which uses the specified builder instance to build its configuration
     *
-    * @param klass an instance of {@link StoreConfigurationBuilder}
+    * @param builder an instance of {@link StoreConfigurationBuilder}
     */
    public LoaderConfigurationBuilder<?, ?> addStore(StoreConfigurationBuilder<?, ?> builder) {
       this.cacheLoaders.add(builder);",2012-08-30T15:45:20Z,44
"@@ -31,7 +31,10 @@
 import static org.infinispan.context.Flag.IGNORE_RETURN_VALUES;
 import static org.infinispan.factories.KnownComponentNames.CACHE_MARSHALLER;
 
+import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collections;
+import java.util.List;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
@@ -47,6 +50,7 @@
 import org.infinispan.configuration.cache.LoadersConfiguration;
 import org.infinispan.configuration.cache.StoreConfiguration;
 import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.annotations.ComponentName;
@@ -189,18 +193,24 @@ public void preload() {
                throw new CacheException(""Unable to preload!"", e);
             }
 
-            for (InternalCacheEntry e : state) {
-               if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
-                  cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, SKIP_CACHE_STORE, IGNORE_RETURN_VALUES, SKIP_INDEXING)
-                       .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
-               } else {
-                  cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES, SKIP_INDEXING)
-                       .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
-               }
+            List<Flag> flags = new ArrayList(Arrays.asList(
+                  CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES));
+
+            if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
+               flags.add(SKIP_CACHE_STORE);
+               if (!localIndexingEnabled())
+                  flags.add(SKIP_INDEXING);
+            } else {
+               flags.add(SKIP_INDEXING);
             }
 
+            AdvancedCache<Object, Object> flaggedCache = cache.getAdvancedCache()
+                  .withFlags(flags.toArray(new Flag[]{}));
+
+            for (InternalCacheEntry e : state)
+               flaggedCache.put(e.getKey(), e.getValue(),
+                     e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
+
             if (debugTiming) {
                final long stop = System.nanoTime();
                log.debugf(""Preloaded %s keys in %s"", state.size(), Util.prettyPrintTime(stop - start, TimeUnit.NANOSECONDS));
@@ -209,6 +219,10 @@ public void preload() {
       }
    }
 
+   private boolean localIndexingEnabled() {
+      return configuration.indexing().enabled() && configuration.indexing().indexLocalOnly();
+   }
+
    private Set<InternalCacheEntry> loadState() throws CacheLoaderException {
       int ne = -1;
       if (configuration.eviction().strategy().isEnabled()) ne = configuration.eviction().maxEntries();",2012-08-30T15:45:20Z,29
"@@ -863,6 +863,11 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    void componentFailedToStop(@Cause Throwable e);
 
    @LogMessage(level = WARN)
-   @Message(value = ""Use of the 'loader' element to configure a store is deprecated, please use the 'store' element instead"")
+   @Message(value = ""Use of the 'loader' element to configure a store is deprecated, please use the 'store' element instead"", id = 190)
    void deprecatedLoaderAsStoreConfiguration();
+
+   @LogMessage(level = DEBUG)
+   @Message(value = ""When indexing locally a cache with shared cache loader, preload must be enabled"", id = 191)
+   void localIndexingWithSharedCacheLoaderRequiresPreload();
+
 }",2012-08-30T15:45:20Z,45
"@@ -29,7 +29,6 @@
 import org.infinispan.test.TestingUtil;
 import org.testng.annotations.Test;
 
-import java.util.LinkedList;
 import java.util.List;
 
 @Test (testName = ""loaders.SharedCacheStoreTest"", groups = ""functional"")
@@ -50,13 +49,6 @@ protected void createCacheManagers() throws Throwable {
       // don't create the caches here, we want them to join the cluster one by one
    }
 
-   private List<CacheStore> cachestores() {
-      List<CacheStore> l = new LinkedList<CacheStore>();
-      for (Cache<?, ?> c: caches())
-         l.add(TestingUtil.extractComponent(c, CacheLoaderManager.class).getCacheStore());
-      return l;
-   }
-
    public void testUnnecessaryWrites() throws CacheLoaderException {
       cache(0).put(""key"", ""value"");
 
@@ -66,7 +58,8 @@ public void testUnnecessaryWrites() throws CacheLoaderException {
       for (Cache<Object, Object> c: caches())
          assert ""value"".equals(c.get(""key""));
 
-      for (CacheStore cs: cachestores()) {
+      List<CacheStore> cachestores = TestingUtil.cachestores(caches());
+      for (CacheStore cs: cachestores) {
          assert cs.containsKey(""key"");
          DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
          assert dimcs.stats().get(""clear"") == 0: ""Cache store should not be cleared, purgeOnStartup is false"";
@@ -78,7 +71,7 @@ public void testUnnecessaryWrites() throws CacheLoaderException {
       for (Cache<Object, Object> c: caches())
          assert c.get(""key"") == null;
 
-      for (CacheStore cs: cachestores()) {
+      for (CacheStore cs: cachestores) {
          assert !cs.containsKey(""key"");
          DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
          assert dimcs.stats().get(""remove"") == 1: ""Entry should have been removed from the cache store just once, but was removed "" + dimcs.stats().get(""store"") + "" times"";",2012-08-30T15:45:20Z,46
"@@ -0,0 +1,73 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.TestingUtil;
+
+import java.util.concurrent.Callable;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+
+/**
+ * Represents a joining node, designed for state transfer related tests.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public class JoiningNode {
+
+   private final EmbeddedCacheManager cm;
+   private final CountDownLatch latch;
+   private final MergeOrViewChangeListener listener;
+
+   public JoiningNode(EmbeddedCacheManager cm) {
+      this.cm = cm;
+      latch = new CountDownLatch(1);
+      listener = new MergeOrViewChangeListener(latch);
+      cm.addListener(listener);
+   }
+
+   public Cache getCache() {
+      return cm.getCache();
+   }
+
+   public Cache getCache(String cacheName) {
+      return cm.getCache(cacheName);
+   }
+
+   public void waitForJoin(long timeout, Cache... caches) throws InterruptedException {
+      // Wait for either a merge or view change to happen
+      latch.await(timeout, TimeUnit.MILLISECONDS);
+      // Wait for the state transfer to end
+      TestingUtil.waitForRehashToComplete(caches);
+   }
+
+   private boolean isStateTransferred() {
+      return !listener.merged;
+   }
+
+   void verifyStateTransfer(Callable<Void> verify) throws Exception {
+      if (isStateTransferred())
+         verify.call();
+   }
+
+}",2012-08-30T15:45:20Z,47
"@@ -0,0 +1,72 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.statetransfer;
+
+import org.infinispan.notifications.Listener;
+import org.infinispan.notifications.cachemanagerlistener.annotation.Merged;
+import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
+import org.infinispan.notifications.cachemanagerlistener.event.MergeEvent;
+import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+import java.util.concurrent.CountDownLatch;
+
+/**
+ * Listener implementation that detects whether a merge or
+ * a view change occurred.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Listener
+public class MergeOrViewChangeListener {
+
+   private static final Log log = LogFactory.getLog(MergeOrViewChangeListener.class);
+
+   // The latch provides the visibility guarantees
+   public boolean merged;
+
+   // The latch provides the visibility guarantees
+   public boolean viewChanged;
+
+   private final CountDownLatch latch;
+
+   public MergeOrViewChangeListener(CountDownLatch latch) {
+      this.latch = latch;
+   }
+
+   @Merged
+   @SuppressWarnings(""unused"")
+   public void mergedView(MergeEvent me) {
+      log.infof(""View merged received %s"", me);
+      merged = true;
+      latch.countDown();
+   }
+
+   @ViewChanged
+   @SuppressWarnings(""unused"")
+   public void viewChanged(ViewChangedEvent e) {
+      log.infof(""View change received %s"", e);
+      viewChanged = true;
+      latch.countDown();
+   }
+
+}",2012-08-30T15:45:20Z,48
"@@ -25,11 +25,6 @@
 import org.infinispan.Cache;
 import org.infinispan.config.Configuration;
 import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.notifications.Listener;
-import org.infinispan.notifications.cachemanagerlistener.annotation.Merged;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.MergeEvent;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
@@ -46,8 +41,7 @@
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.lang.reflect.Method;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.TimeUnit;
+import java.util.concurrent.Callable;
 
 @Test(groups = ""functional"", testName = ""statetransfer.StateTransferFunctionalTest"", enabled = true)
 public class StateTransferFunctionalTest extends MultipleCacheManagersTest {
@@ -183,10 +177,10 @@ public void testInitialStateTransfer(Method m) throws Exception {
       cache1 = cm1.getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node = new JoiningNode();
+      JoiningNode node = new JoiningNode(createCacheManager());
       cache2 = node.getCache(cacheName);
       node.waitForJoin(60000, cache1, cache2);
-      node.verifyStateTransfer(cache2);
+      node.verifyStateTransfer(new CacheVerifier(cache2));
 
       logTestEnd(m);
    }
@@ -199,10 +193,10 @@ public void testInitialStateTransferCacheNotPresent(Method m) throws Exception {
       cache1 = cacheManager1.getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node = new JoiningNode();
+      JoiningNode node = new JoiningNode(createCacheManager());
       cache2 = node.getCache(cacheName);
       node.waitForJoin(60000, cache1, cache2);
-      node.verifyStateTransfer(cache2);
+      node.verifyStateTransfer(new CacheVerifier(cache2));
 
       cacheManager1.defineConfiguration(""otherCache"", config.clone());
       cacheManager1.getCache(""otherCache"");
@@ -216,16 +210,16 @@ public void testConcurrentStateTransfer(Method m) throws Exception {
       cache1 = createCacheManager().getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
 
       cache1.put(""delay"", new StateTransferFunctionalTest.DelayTransfer());
 
       node2.waitForJoin(60000, cache1, cache2);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
-      final JoiningNode node3 = new JoiningNode();
-      final JoiningNode node4 = new JoiningNode();
+      final JoiningNode node3 = new JoiningNode(createCacheManager());
+      final JoiningNode node4 = new JoiningNode(createCacheManager());
 
       Thread t1 = new Thread(new Runnable() {
          public void run() {
@@ -252,8 +246,8 @@ public void run() {
       node3.waitForJoin(120000, cache1, cache2, cache3, cache4);
       node4.waitForJoin(120000, cache1, cache2, cache3, cache4);
 
-      node3.verifyStateTransfer(cache3);
-      node4.verifyStateTransfer(cache4);
+      node3.verifyStateTransfer(new CacheVerifier(cache3));
+      node4.verifyStateTransfer(new CacheVerifier(cache4));
 
       logTestEnd(m);
    }
@@ -300,10 +294,10 @@ public void testInitialStateTransferAfterRestart(Method m) throws Exception {
       cache1 = createCacheManager().getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
       node2.waitForJoin(60000, cache1, cache2);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       cache2.stop();
       cache2.start();
@@ -324,7 +318,7 @@ private void logTestLifecycle(Method m, String lifecycle) {
       log.infof(""%s %s - %s"", m.getName(), lifecycle, testCount);
    }
 
-   private void thirdWritingCacheTest(boolean tx) throws InterruptedException {
+   private void thirdWritingCacheTest(boolean tx) throws Exception {
       Cache<Object, Object> cache1, cache2, cache3;
       cache1 = createCacheManager().getCache(cacheName);
       cache3 = createCacheManager().getCache(cacheName);
@@ -340,15 +334,15 @@ private void thirdWritingCacheTest(boolean tx) throws InterruptedException {
       WritingThread writerThread = new WritingThread(cache3, tx);
       writerThread.start();
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
 
       node2.waitForJoin(60000, cache1, cache2, cache3);
 
       writerThread.stopThread();
       writerThread.join();
 
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       int count = writerThread.result();
 
@@ -374,7 +368,7 @@ protected void writeInitialData(final Cache<Object, Object> c) {
       c.put(A_C_AGE, FORTY);
    }
 
-   private void writingThreadTest(boolean tx) throws InterruptedException {
+   private void writingThreadTest(boolean tx) throws Exception {
       Cache<Object, Object> cache1, cache2;
       cache1 = createCacheManager().getCache(cacheName);
 
@@ -388,81 +382,34 @@ private void writingThreadTest(boolean tx) throws InterruptedException {
       writerThread.start();
       verifyInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
       node2.waitForJoin(60000, cache1, cache2);
 
       writerThread.stopThread();
       writerThread.join();
 
       verifyInitialData(cache1);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       int count = writerThread.result();
 
       for (int c = 0; c < count; c++)
          assert new Integer(c).equals(cache2.get(""test"" + c)) : ""Entry under key [test"" + c + ""] was ["" + cache2.get(""test"" + c) + ""] but expected ["" + c + ""]"";
    }
 
-   @Listener
-   public static class MergeOrViewChangeListener {
-      // The latch provides the visibility guarantees
-      public boolean merged;
-      // The latch provides the visibility guarantees
-      public boolean viewChanged;
-      private final CountDownLatch latch;
+   public class CacheVerifier implements Callable<Void> {
 
-      public MergeOrViewChangeListener(CountDownLatch latch) {
-         this.latch = latch;
-      }
-
-      @Merged
-      public void mergedView(MergeEvent me) {
-         log.infof(""View merged received %s"", me);
-         merged = true;
-         latch.countDown();
-      }
-
-      @ViewChanged
-      public void viewChanged(ViewChangedEvent e) {
-         log.infof(""View change received %s"", e);
-         viewChanged = true;
-         latch.countDown();
-      }
-
-   }
-
-   private class JoiningNode {
-
-      private final EmbeddedCacheManager cm;
-      private final CountDownLatch latch;
-      private final MergeOrViewChangeListener listener;
-
-      private JoiningNode() {
-         cm = createCacheManager();
-         latch = new CountDownLatch(1);
-         listener = new MergeOrViewChangeListener(latch);
-         cm.addListener(listener);
-      }
-
-      Cache getCache(String cacheName) {
-         return cm.getCache(cacheName);
-      }
-
-      void waitForJoin(long timeout, Cache... caches) throws InterruptedException {
-         // Wait for either a merge or view change to happen
-         latch.await(timeout, TimeUnit.MILLISECONDS);
-         // Wait for the state transfer to end
-         TestingUtil.waitForRehashToComplete(caches);
-      }
+      private final Cache<Object, Object> cache;
 
-      private boolean isStateTransferred() {
-         return !listener.merged;
+      public CacheVerifier(Cache<Object, Object> cache) {
+         this.cache = cache;
       }
 
-      void verifyStateTransfer(Cache cache) {
-         if (isStateTransferred())
-            StateTransferFunctionalTest.this.verifyInitialData(cache);
+      @Override
+      public Void call() throws Exception {
+         verifyInitialData(cache);
+         return null;
       }
 
    }",2012-08-30T15:45:20Z,49
"@@ -33,6 +33,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.LinkedList;
 import java.util.List;
 import java.util.Random;
 import java.util.Set;
@@ -62,6 +63,7 @@
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.loaders.CacheLoader;
 import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.loaders.CacheStore;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.AbstractDelegatingMarshaller;
@@ -754,6 +756,13 @@ public static void clearCacheLoader(Cache cache) {
       }
    }
 
+   public static <K, V> List<CacheStore> cachestores(List<Cache<K, V>> caches) {
+      List<CacheStore> l = new LinkedList<CacheStore>();
+      for (Cache<?, ?> c: caches)
+         l.add(TestingUtil.extractComponent(c, CacheLoaderManager.class).getCacheStore());
+      return l;
+   }
+
    private static void removeInMemoryData(Cache cache) {
       EmbeddedCacheManager mgr = cache.getCacheManager();
       Address a = mgr.getAddress();",2012-08-30T15:45:20Z,50
"@@ -0,0 +1,69 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.cacheloaders;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.query.statetransfer.BaseReIndexingTest;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.Test;
+
+/**
+ * Tests behaviour of indexing and querying when a cache is clustered and
+ * and it's configured with a shared cache store. If preload is enabled,
+ * it should be possible to index the preloaded contents.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.cacheloaders.SharedCacheLoaderQueryIndexTest"")
+public class SharedCacheLoaderQueryIndexTest extends BaseReIndexingTest {
+
+   protected void configureCache(ConfigurationBuilder builder) {
+      // To force a shared cache store, make sure storeName property
+      // for dummy store is the same for all nodes
+      builder.clustering().stateTransfer().fetchInMemoryState(false)
+         .loaders().shared(true).preload(true).addStore()
+            .cacheStore(new DummyInMemoryCacheStore()).addProperty(""storeName"",
+            SharedCacheLoaderQueryIndexTest.class.getName());
+   }
+
+   public void testPreloadIndexingAfterAddingNewNode() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      for (CacheStore cs: TestingUtil.cachestores(this.<String, Person>caches())) {
+         assert cs.containsKey(persons[0].getName()) :
+               ""Cache misconfigured, maybe cache store not pointing to same place, maybe passivation on...etc"";
+         DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
+         assert dimcs.stats().get(""clear"") == 0:
+               ""Cache store should not be cleared, purgeOnStartup is false"";
+         assert dimcs.stats().get(""store"") == 4:
+               ""Cache store should have been written to just once, but was written to "" + dimcs.stats().get(""store"") + "" times"";
+      }
+
+      // Before adding a node, verify that the query resolves properly
+      executeSimpleQuery(this.<String, Person>caches().get(0));
+
+      addNodeCheckingContentsAndQuery();
+   }
+
+}",2012-08-30T15:45:20Z,7
"@@ -0,0 +1,138 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.apache.lucene.queryParser.ParseException;
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.query.CacheQuery;
+import org.infinispan.query.test.Person;
+import org.infinispan.statetransfer.JoiningNode;
+import org.infinispan.test.CacheManagerCallable;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.fwk.TransportFlags;
+
+import java.util.List;
+
+import static org.infinispan.query.helper.TestQueryHelperFactory.createCacheQuery;
+import static org.infinispan.test.TestingUtil.withCacheManager;
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Base class for state transfer and query related tests
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public abstract class BaseReIndexingTest extends MultipleCacheManagersTest {
+
+   protected Person[] persons;
+   protected ConfigurationBuilder builder;
+
+   abstract protected void configureCache(ConfigurationBuilder builder);
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      builder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, false);
+
+      // Explicitly disable fetching in-memory state in order
+      // to fetch it from the persistence layer
+      builder.indexing().enable().indexLocalOnly(true)
+            .addProperty(""hibernate.search.default.directory_provider"", ""ram"")
+            .addProperty(""hibernate.search.lucene_version"", ""LUCENE_CURRENT"");
+
+      configureCache(builder);
+
+      createClusteredCaches(2, builder);
+   }
+
+   private EmbeddedCacheManager createCacheManager() {
+      return addClusterEnabledCacheManager(
+            builder, new TransportFlags().withMerge(true));
+   }
+
+   protected void executeSimpleQuery(Cache<String, Person> cache) throws ParseException {
+      CacheQuery cacheQuery = createCacheQuery(cache, ""blurb"", ""playing"");
+      List<Object> found = cacheQuery.list();
+      int elems = found.size();
+      assertEquals(1, elems);
+      Object val = found.get(0);
+      Person expectedPerson = persons[0];
+      assertEquals(expectedPerson, val);
+   }
+
+   protected void loadCacheEntries(Cache<String, Person> cache) {
+      Person person1 = new Person();
+      person1.setName(""NavinSurtani"");
+      person1.setBlurb(""Likes playing WoW"");
+      person1.setAge(45);
+
+      Person person2 = new Person();
+      person2.setName(""BigGoat"");
+      person2.setBlurb(""Eats grass"");
+      person2.setAge(30);
+
+      Person person3 = new Person();
+      person3.setName(""MiniGoat"");
+      person3.setBlurb(""Eats cheese"");
+      person3.setAge(35);
+
+      Person person4 = new Person();
+      person4.setName(""MightyGoat"");
+      person4.setBlurb(""Also eats grass"");
+      person4.setAge(66);
+
+      persons = new Person[]{person1, person2, person3, person4};
+
+      // Put the 3 created objects in the cache
+      cache.put(person1.getName(), person1);
+      cache.put(person2.getName(), person2);
+      cache.put(person3.getName(), person3);
+      cache.put(person4.getName(), person4);
+   }
+
+   protected void addNodeCheckingContentsAndQuery() {
+      withCacheManager(new CacheManagerCallable(createCacheManager()) {
+         @Override
+         public void call() {
+            try {
+               // New node joining
+               JoiningNode newNode = new JoiningNode(cm);
+               Cache<String, Person> newCache = newNode.getCache();
+               newNode.waitForJoin(120000, caches().get(0), caches().get(1), newCache);
+
+               // Verify state transfer
+               int size = newCache.size();
+               assertEquals(4, size);
+               for (int i = 0; i < size; i++)
+                  assertEquals(persons[i], newCache.get(persons[i].getName()));
+
+               // Repeat query on new node
+               executeSimpleQuery(newCache);
+            } catch (Exception e) {
+               throw new RuntimeException(e);
+            }
+         }
+      });
+   }
+
+}",2012-08-30T15:45:20Z,51
"@@ -0,0 +1,94 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.Test;
+
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Test that verifies that querying works even after multiple nodes have
+ * started with unshared, passivated, cache stores, and a new node comes in
+ * to fetch the persistent state from the other nodes.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.PersistentStateTransferQueryIndexTest"")
+public class PersistentStateTransferQueryIndexTest extends BaseReIndexingTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      builder.clustering().stateTransfer().fetchInMemoryState(false)
+            .loaders().passivation(true).shared(false).addStore()
+            .cacheStore(new DummyInMemoryCacheStore())
+                  .fetchPersistentState(true);
+   }
+
+   public void testFetchingPersistentStateUpdatesIndex() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      // Before adding a node, verify that the query resolves properly
+      Cache<String, Person> cache1 = this.<String, Person>caches().get(0);
+      executeSimpleQuery(cache1);
+
+      // Since passivation is enabled, cache stores should still be empty
+      checkCacheStoresEmpty();
+
+      // Evict manually entries from both nodes
+      for (Cache<Object, Object> cache : caches()) {
+         for (Person p2 : persons) {
+            cache.evict(p2.getName());
+         }
+      }
+
+      // After eviction, cache stores should be loaded with instances
+      checkCacheStoresContainPersons();
+
+      // Finally add a node and verify that state transfer happens and query works
+      addNodeCheckingContentsAndQuery();
+   }
+
+   private void checkCacheStoresContainPersons() throws CacheLoaderException {
+      for (Cache<Object, Object> cache : caches()) {
+         CacheStore store = TestingUtil.extractComponent(cache, CacheLoaderManager.class).getCacheStore();
+         for (int i = 0; i < persons.length; i++)
+            assertEquals(persons[i], store.load(persons[i].getName()).getValue());
+      }
+   }
+
+   private void checkCacheStoresEmpty() throws CacheLoaderException {
+      for (Cache<Object, Object> cache : caches()) {
+         CacheStore store = TestingUtil.extractComponent(cache, CacheLoaderManager.class).getCacheStore();
+         for (Person person : persons) {
+            assert !store.containsKey(person.getName());
+         }
+      }
+   }
+
+}",2012-08-30T15:45:20Z,52
"@@ -0,0 +1,50 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.query.test.Person;
+import org.testng.annotations.Test;
+
+/**
+ * Test that verifies that querying works even after a new node is added and
+ * state transfer has provided it with the data belonging to that node.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.StateTransferQueryIndexTest"")
+public class StateTransferQueryIndexTest extends BaseReIndexingTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      builder.clustering().stateTransfer().fetchInMemoryState(true);
+   }
+
+   public void testQueryAfterAddingNewNode() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      // Before adding a node, verify that the query resolves properly
+      executeSimpleQuery(this.<String, Person>caches().get(0));
+
+      addNodeCheckingContentsAndQuery();
+   }
+
+}",2012-08-30T15:45:20Z,53
"@@ -29,7 +29,6 @@
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
 import org.infinispan.remoting.transport.Address;
-import org.infinispan.topology.CacheTopology;
 
 import java.util.Collection;
 import java.util.List;
@@ -41,6 +40,7 @@
  * @author Manik Surtani
  * @author Mircea.Markus@jboss.com
  * @author Vladimir Blagojevic
+ * @author anistor@redhat.com
  * @since 4.0
  */
 @Scope(Scopes.NAMED_CACHE)
@@ -124,13 +124,6 @@ public interface DistributionManager {
 
    ConsistentHash getWriteConsistentHash();
 
-   /**
-    * Sets the consistent hash implementation in use.
-    *
-    * @param cacheTopology
-    */
-   void setCacheTopology(CacheTopology cacheTopology);
-
    /**
     * Tests whether a given key is affected by a rehash that may be in progress.  If no rehash is in progress, this method
     * returns false.  Helps determine whether additional steps are necessary in handling an operation with a given key.",2012-08-31T21:04:51Z,60
"@@ -37,15 +37,13 @@
 import org.infinispan.jmx.annotations.MBean;
 import org.infinispan.jmx.annotations.ManagedOperation;
 import org.infinispan.newstatetransfer.StateTransferManager;
-import org.infinispan.notifications.cachelistener.CacheNotifier;
 import org.infinispan.remoting.responses.ClusteredGetResponseValidityFilter;
 import org.infinispan.remoting.responses.Response;
 import org.infinispan.remoting.responses.SuccessfulResponse;
 import org.infinispan.remoting.rpc.ResponseFilter;
 import org.infinispan.remoting.rpc.ResponseMode;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
-import org.infinispan.topology.CacheTopology;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.logging.Log;
@@ -68,6 +66,7 @@
  * @author Mircea.Markus@jboss.com
  * @author Bela Ban
  * @author Dan Berindei <dan@infinispan.org>
+ * @author anistor@redhat.com
  * @since 4.0
  */
 @MBean(objectName = ""DistributionManager"", description = ""Component that handles distribution of content across a cluster"")
@@ -79,10 +78,8 @@ public class DistributionManagerImpl implements DistributionManager {
    private Configuration configuration;
    private RpcManager rpcManager;
    private CommandsFactory cf;
-   private CacheNotifier cacheNotifier;
    private StateTransferManager stateTransferManager;
 
-   private volatile CacheTopology cacheTopology;
    private GlobalConfiguration globalCfg;
 
    /**
@@ -92,12 +89,11 @@ public DistributionManagerImpl() {
    }
 
    @Inject
-   public void init(Configuration configuration, RpcManager rpcManager, CommandsFactory cf, CacheNotifier cacheNotifier,
+   public void init(Configuration configuration, RpcManager rpcManager, CommandsFactory cf,
                     StateTransferManager stateTransferManager, GlobalConfiguration globalCfg) {
       this.configuration = configuration;
       this.rpcManager = rpcManager;
       this.cf = cf;
-      this.cacheNotifier = cacheNotifier;
       this.stateTransferManager = stateTransferManager;
       this.globalCfg = globalCfg;
    }
@@ -108,10 +104,6 @@ private void start() throws Exception {
       if (trace) log.tracef(""starting distribution manager on %s"", getAddress());
    }
 
-   private int getReplCount() {
-      return configuration.clustering().hash().numOwners();
-   }
-
    private Address getAddress() {
       return rpcManager.getAddress();
    }
@@ -125,7 +117,7 @@ public boolean isLocal(Object key) {
    @Override
    public DataLocality getLocality(Object key) {
       boolean transferInProgress = stateTransferManager.isStateTransferInProgressForKey(key);
-      boolean local = cacheTopology.getWriteConsistentHash().isKeyLocalToNode(getAddress(), key);
+      boolean local = stateTransferManager.getCacheTopology().getWriteConsistentHash().isKeyLocalToNode(getAddress(), key);
 
       if (transferInProgress) {
          if (local) {
@@ -193,25 +185,13 @@ public ConsistentHash getConsistentHash() {
    }
 
    public ConsistentHash getReadConsistentHash() {
-      return cacheTopology.getReadConsistentHash();
+      return stateTransferManager.getCacheTopology().getReadConsistentHash();
    }
 
    public ConsistentHash getWriteConsistentHash() {
-      return cacheTopology.getWriteConsistentHash();
-   }
-
-   @Override
-   public void setCacheTopology(CacheTopology newCacheTopology) {
-      if (trace) log.tracef(""Installing new cache topology %s"", newCacheTopology);
-      // TODO Replace the topology change notification with another notification that accepts two consistent hashes and a topology id
-      ConsistentHash oldCH = cacheTopology != null ? cacheTopology.getWriteConsistentHash() : null;
-      ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, true);
-      cacheTopology = newCacheTopology;
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, false);
+      return stateTransferManager.getCacheTopology().getWriteConsistentHash();
    }
 
-
    // TODO Move these methods to the StateTransferManager interface so we can eliminate the dependency
    @Override
    @ManagedOperation(description = ""Determines whether a given key is affected by an ongoing rehash, if any."")
@@ -258,9 +238,4 @@ public List<String> locateKey(@Parameter(name = ""key"", description = ""Key to loc
       for (Address a : locate(key)) l.add(a.toString());
       return l;
    }
-
-   @Override
-   public String toString() {
-      return ""DistributionManagerImpl["" + cacheTopology + ""]"";
-   }
 }",2012-08-31T21:04:51Z,60
"@@ -36,12 +36,12 @@
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
-import org.infinispan.distribution.DistributionManager;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.interceptors.base.CommandInterceptor;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
+import org.infinispan.topology.CacheTopology;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
@@ -63,7 +63,7 @@ public class StateTransferInterceptor extends CommandInterceptor {   //todo [ani
 
    private StateTransferLock stateTransferLock;
 
-   private DistributionManager distributionManager;
+   private StateTransferManager stateTransferManager;
 
    private RpcManager rpcManager;
 
@@ -75,10 +75,10 @@ protected Log getLog() {
    }
 
    @Inject
-   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager, DistributionManager distributionManager) {
+   public void init(StateTransferLock stateTransferLock, Configuration configuration, RpcManager rpcManager, StateTransferManager stateTransferManager) {
       this.stateTransferLock = stateTransferLock;
       this.rpcManager = rpcManager;
-      this.distributionManager = distributionManager;
+      this.stateTransferManager = stateTransferManager;
       // no need to retry for asynchronous caches
       this.rpcTimeout = configuration.clustering().cacheMode().isSynchronous()
             ? configuration.clustering().sync().replTimeout() : 0;
@@ -180,9 +180,10 @@ protected Object handleDefault(InvocationContext ctx, VisitableCommand command)
    private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffectedCommand command) throws Throwable {
       Set<Address> newTargets = null;
       stateTransferLock.commandsSharedLock();
-      final int topologyId = stateTransferLock.getTopologyId();
-      final ConsistentHash rCh = distributionManager.getReadConsistentHash();
-      final ConsistentHash wCh = distributionManager.getWriteConsistentHash();
+      CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
+      final int topologyId = cacheTopology.getTopologyId();
+      final ConsistentHash rCh = cacheTopology.getReadConsistentHash();
+      final ConsistentHash wCh = cacheTopology.getWriteConsistentHash();
       try {
          final boolean isTxCommand = command instanceof TransactionBoundaryCommand;
          if (isTxCommand) {
@@ -258,6 +259,7 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       }
    }
 
+   @SuppressWarnings(""unchecked"")
    private Set<Object> getAffectedKeys(InvocationContext ctx, VisitableCommand command) {
       Set<Object> affectedKeys = null;
       try {",2012-08-31T21:04:51Z,66
"@@ -27,6 +27,7 @@
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
 import org.infinispan.jmx.annotations.ManagedAttribute;
+import org.infinispan.topology.CacheTopology;
 import org.rhq.helpers.pluginAnnotations.agent.DataType;
 import org.rhq.helpers.pluginAnnotations.agent.Metric;
 
@@ -70,7 +71,7 @@ public interface StateTransferManager {
     */
    boolean isStateTransferInProgressForKey(Object key);
 
-   int getTopologyId();
+   CacheTopology getCacheTopology();
 
    void notifyEndOfStateTransfer(int topologyId);
 }",2012-08-31T21:04:51Z,69
"@@ -28,7 +28,6 @@
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.DataContainer;
 import org.infinispan.context.InvocationContextContainer;
-import org.infinispan.distribution.DistributionManager;
 import org.infinispan.distribution.ch.ConsistentHash;
 import org.infinispan.distribution.group.GroupManager;
 import org.infinispan.distribution.group.GroupingConsistentHash;
@@ -64,17 +63,16 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private StateTransferLock stateTransferLock;
 
    private Configuration configuration;
-   private DistributionManager distributionManager;
+   private CacheNotifier cacheNotifier;
    private LocalTopologyManager localTopologyManager;
    private RpcManager rpcManager;
    private GroupManager groupManager;
    private String cacheName;
 
-   private int topologyId = -1;
-
    private StateProvider stateProvider;
    private StateConsumer stateConsumer;
-   private boolean rebalanceInProgress;
+   private volatile boolean rebalanceInProgress;
+   private volatile CacheTopology cacheTopology;
 
    public StateTransferManagerImpl() {
    }
@@ -85,7 +83,6 @@ public void init(@ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService asyncT
                     Configuration configuration,
                     RpcManager rpcManager,
                     CommandsFactory commandsFactory,
-                    DistributionManager distributionManager,
                     CacheLoaderManager cacheLoaderManager,
                     DataContainer dataContainer,
                     InterceptorChain interceptorChain,
@@ -96,7 +93,7 @@ public void init(@ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService asyncT
                     Cache cache,
                     GroupManager groupManager) {
       this.configuration = configuration;
-      this.distributionManager = distributionManager;
+      this.cacheNotifier = cacheNotifier;
       this.localTopologyManager = localTopologyManager;
       this.rpcManager = rpcManager;
       this.stateTransferLock = stateTransferLock;
@@ -152,7 +149,9 @@ public void rebalance(CacheTopology cacheTopology) {
             doTopologyUpdate(cacheTopology, true);
          }
 
-         private void doTopologyUpdate(CacheTopology cacheTopology, boolean rebalance) {
+         private void doTopologyUpdate(CacheTopology newCacheTopology, boolean rebalance) {
+            if (trace) log.tracef(""Installing new cache topology %s"", newCacheTopology);
+
             // handle grouping
             if (groupManager != null) {
                ConsistentHash currentCH = cacheTopology.getCurrentCH();
@@ -164,12 +163,16 @@ private void doTopologyUpdate(CacheTopology cacheTopology, boolean rebalance) {
                cacheTopology = new CacheTopology(cacheTopology.getTopologyId(), currentCH, pendingCH);
             }
 
-            topologyId = cacheTopology.getTopologyId();
+            ConsistentHash oldCH = cacheTopology != null ? cacheTopology.getWriteConsistentHash() : null;
+            ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
+
             rebalanceInProgress = rebalance;
-            if (distributionManager != null) { // need to check we are really in distributed mode
-               distributionManager.setCacheTopology(cacheTopology);
-            }
-            onTopologyUpdate(topologyId, cacheTopology.getReadConsistentHash(), cacheTopology.getWriteConsistentHash());
+
+            cacheNotifier.notifyTopologyChanged(oldCH, newCH, true);
+            cacheTopology = newCacheTopology;
+            cacheNotifier.notifyTopologyChanged(oldCH, newCH, false);
+
+            onTopologyUpdate(cacheTopology.getTopologyId(), newCacheTopology.getReadConsistentHash(), newCacheTopology.getWriteConsistentHash());
          }
       };
 
@@ -201,7 +204,7 @@ public void onTopologyUpdate(int topologyId, ConsistentHash rCh, ConsistentHash
 
    @Override
    public boolean isJoinComplete() {
-      return topologyId != -1;
+      return cacheTopology != null;
    }
 
    @Override
@@ -215,8 +218,8 @@ public boolean isStateTransferInProgressForKey(Object key) {
    }
 
    @Override
-   public int getTopologyId() {
-      return topologyId;
+   public CacheTopology getCacheTopology() {
+      return cacheTopology;
    }
 
    public void notifyEndOfStateTransfer(int topologyId) {",2012-08-31T21:04:51Z,70
"@@ -171,7 +171,7 @@ public final Map<Address, Response> invokeRemotely(Collection<Address> recipient
                }
             }
             if (rpcCommand instanceof TopologyAffectedCommand) {
-               ((TopologyAffectedCommand)rpcCommand).setTopologyId(stateTransferManager.getTopologyId());
+               ((TopologyAffectedCommand)rpcCommand).setTopologyId(stateTransferManager.getCacheTopology().getTopologyId());
             }
             Map<Address, Response> result = t.invokeRemotely(recipients, rpcCommand, mode, timeout, usePriorityQueue, responseFilter);
             if (statisticsEnabled) replicationCount.incrementAndGet();",2012-08-31T21:04:51Z,105
"@@ -35,7 +35,6 @@
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.impl.TxInvocationContext;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.TransactionTable;
@@ -58,14 +57,9 @@ public abstract class AbstractTxLockingInterceptor extends AbstractLockingInterc
    public void setDependencies(TransactionTable txTable, RpcManager rpcManager) {
       this.txTable = txTable;
       this.rpcManager = rpcManager;
-   }
-
-   @Start
-   private void setClustered() {
       clustered = rpcManager != null;
    }
 
-
    @Override
    public Object visitRollbackCommand(TxInvocationContext ctx, RollbackCommand command) throws Throwable {
       try {
@@ -169,10 +163,12 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
       TxInvocationContext txContext = (TxInvocationContext) ctx;
       int transactionViewId = -1;
+      boolean useStrictComparison = true;
       if (clustered) {
          transactionViewId = txContext.getCacheTransaction().getViewId();
          if (transactionViewId != TransactionTable.CACHE_STOPPED_VIEW_ID) {
-            checkForPendingLocks = transactionViewId > txTable.getMinViewId();
+            useStrictComparison = txTable.useStrictTopologyIdComparison();
+            checkForPendingLocks = isFromOlderTopology(txTable.getMinViewId(), transactionViewId, useStrictComparison);
          }
       }
 
@@ -183,15 +179,15 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
 
          // Check local transactions first
          for (CacheTransaction ct: txTable.getLocalTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
          }
 
          // ... then remote ones
          for (CacheTransaction ct: txTable.getRemoteTransactions()) {
-            if (ct.getViewId() < transactionViewId) {
+            if (isFromOlderTopology(ct.getViewId(), transactionViewId, useStrictComparison)) {
                long remaining = expectedEndTime - nowMillis();
                if (remaining < 0 || !ct.waitForLockRelease(key, remaining)) throw newTimeoutException(key, txContext);
             }
@@ -211,6 +207,19 @@ protected final void lockKeyAndCheckOwnership(InvocationContext ctx, Object key,
       }
    }
 
+   /**
+    * Checks if first topology id is smaller than the second. The comparison can be strict or non-strict,
+    * depending on the isStrictComparison flag.
+    *
+    * @param tx1TopologyId topology id of first transaction
+    * @param tx2TopologyId topology id of second transaction
+    * @param useStrictComparison a flag indicating if comparison must be strict
+    * @return if the first transaction was started in an older topology than the second transaction
+    */
+   private boolean isFromOlderTopology(int tx1TopologyId, int tx2TopologyId, boolean useStrictComparison) {
+      return useStrictComparison ? tx1TopologyId < tx2TopologyId : tx1TopologyId <= tx2TopologyId;
+   }
+
    private TimeoutException newTimeoutException(Object key, TxInvocationContext txContext) {
       return new TimeoutException(""Could not acquire lock on "" + key + "" on behalf of transaction "" +
                                        txContext.getGlobalTransaction() + "". Lock is being held by "" + lockManager.getOwner(key));",2012-09-21T12:26:43Z,131
"@@ -109,9 +109,7 @@ public interface CacheNotifier extends Listenable {
     */
    void notifyTransactionRegistered(GlobalTransaction globalTransaction, InvocationContext ctx);
 
-   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre);
-
-   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre);
-
+   void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre);
 
+   void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre);
 }
\ No newline at end of file",2012-09-21T12:26:43Z,132
"@@ -334,24 +334,25 @@ public void notifyTransactionRegistered(GlobalTransaction globalTransaction, Inv
    }
 
    @Override
-   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, long newViewId, boolean pre) {
+   public void notifyDataRehashed(Collection<Address> oldView, Collection<Address> newView, int newTopologyId, boolean pre) {
       if (!dataRehashedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, DATA_REHASHED);
          e.setPre(pre);
          e.setMembersAtStart(oldView);
          e.setMembersAtEnd(newView);
-         e.setNewViewId(newViewId);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : dataRehashedListeners) listener.invoke(e);
       }
    }
 
    @Override
-   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, boolean pre) {
+   public void notifyTopologyChanged(ConsistentHash oldConsistentHash, ConsistentHash newConsistentHash, int newTopologyId, boolean pre) {
       if (!topologyChangedListeners.isEmpty()) {
          EventImpl<Object, Object> e = EventImpl.createEvent(cache, TOPOLOGY_CHANGED);
          e.setPre(pre);
          e.setConsistentHashAtStart(oldConsistentHash);
          e.setConsistentHashAtEnd(newConsistentHash);
+         e.setNewTopologyId(newTopologyId);
          for (ListenerInvocation listener : topologyChangedListeners) listener.invoke(e);
       }
    }",2012-09-21T12:26:43Z,133
"@@ -43,7 +43,7 @@ public interface DataRehashedEvent<K, V> extends Event<K, V> {
    Collection<Address> getMembersAtEnd();
 
    /**
-    * @return Retrieves the new view id after rehashing was triggered.
+    * @return Retrieves the new topology id after rehashing was triggered.
     */
-   long getNewViewId();
+   int getNewTopologyId();
 }",2012-09-21T12:26:43Z,134
"@@ -53,7 +53,7 @@ public class EventImpl<K, V> implements CacheEntryActivatedEvent, CacheEntryCrea
    private V value;
    private Collection<Address> membersAtStart, membersAtEnd;
    private ConsistentHash consistentHashAtStart, consistentHashAtEnd;
-   private long newViewId;
+   private int newTopologyId;
    private Map<Object, Object> entries;
 
    public EventImpl() {
@@ -150,8 +150,8 @@ public void setConsistentHashAtEnd(ConsistentHash consistentHashAtEnd) {
       this.consistentHashAtEnd = consistentHashAtEnd;
    }
 
-   public void setNewViewId(long newViewId) {
-      this.newViewId = newViewId;
+   public void setNewTopologyId(int newTopologyId) {
+      this.newTopologyId = newTopologyId;
    }
 
    @Override
@@ -189,7 +189,7 @@ public boolean equals(Object o) {
       if (!Util.safeEquals(consistentHashAtEnd, event.consistentHashAtEnd)) return false;
       if (!Util.safeEquals(membersAtStart, event.membersAtStart)) return false;
       if (!Util.safeEquals(membersAtEnd, event.membersAtEnd)) return false;
-      if (newViewId != event.newViewId) return false;
+      if (newTopologyId != event.newTopologyId) return false;
 
       return true;
    }
@@ -208,7 +208,7 @@ public int hashCode() {
       result = 31 * result + (membersAtEnd != null ? membersAtEnd.hashCode() : 0);
       result = 31 * result + (consistentHashAtStart != null ? consistentHashAtStart.hashCode() : 0);
       result = 31 * result + (consistentHashAtEnd != null ? consistentHashAtEnd.hashCode() : 0);
-      result = 31 * result + ((int) newViewId);
+      result = 31 * result + ((int) newTopologyId);
       return result;
    }
 
@@ -236,8 +236,8 @@ public Collection<Address> getMembersAtEnd() {
    }
 
    @Override
-   public long getNewViewId() {
-      return newViewId;
+   public int getNewTopologyId() {
+      return newTopologyId;
    }
 
    @Override",2012-09-21T12:26:43Z,135
"@@ -40,5 +40,7 @@ public interface TopologyChangedEvent<K, V> extends Event<K, V> {
     */
    ConsistentHash getConsistentHashAtEnd();
 
+   int getNewTopologyId();
+
    //todo [anistor] add topologyId, prevReadCH, prevWriteCH, newReadCH2, newWriteCH
 }",2012-09-21T12:26:43Z,136
"@@ -95,7 +95,7 @@ public class StateConsumerImpl implements StateConsumer {
    private AtomicInteger activeTopologyUpdates = new AtomicInteger(0);
 
    /**
-    * Indicates if currently executing topology update is a rabalance.
+    * Indicates if the currently executing topology update is a rebalance.
     */
    private AtomicBoolean rebalanceInProgress = new AtomicBoolean(false);
 
@@ -197,8 +197,10 @@ public void onTopologyUpdate(CacheTopology cacheTopology, boolean isRebalance) {
             removedSegments.removeAll(newSegments);
 
             // remove inbound transfers and any data for segments we no longer own
-            log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
-                  removedSegments, newSegments, previousSegments);
+            if (trace) {
+               log.tracef(""Discarding removed segments: %s; new segments: %s; old segments: %s"",
+                     removedSegments, newSegments, previousSegments);
+            }
             discardSegments(removedSegments);
 
             if (fetchEnabled) {",2012-09-21T12:26:43Z,54
"@@ -80,7 +80,7 @@ public class StateProviderImpl implements StateProvider {
    private volatile ConsistentHash readCh;
 
    /**
-    * A map that keeps track of current outbound state transfers by source address. There could be multiple transfers
+    * A map that keeps track of current outbound state transfers by destination address. There could be multiple transfers
     * flowing to the same destination (but for different segments) so the values are lists.
     */
    private final Map<Address, List<OutboundTransferTask>> transfersByDestination = new HashMap<Address, List<OutboundTransferTask>>();
@@ -124,6 +124,7 @@ public boolean isStateTransferInProgress() {
    }
 
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
       // do all the work AFTER the consistent hash has changed
       if (tce.isPre())
@@ -236,12 +237,14 @@ private void collectTransactionsToTransfer(List<TransactionInfo> transactionsToT
                lockedKeys.add(key);
             }
          }
-         List<WriteCommand> txModifications = tx.getModifications();
-         WriteCommand[] modifications = null;
-         if (txModifications != null) {
-            modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+         if (!lockedKeys.isEmpty()) {
+            List<WriteCommand> txModifications = tx.getModifications();
+            WriteCommand[] modifications = null;
+            if (txModifications != null) {
+               modifications = txModifications.toArray(new WriteCommand[txModifications.size()]);
+            }
+            transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), tx.getViewId(), modifications, lockedKeys));
          }
-         transactionsToTransfer.add(new TransactionInfo(tx.getGlobalTransaction(), modifications, lockedKeys));
       }
    }
 ",2012-09-21T12:26:43Z,55
"@@ -48,10 +48,9 @@
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
-import java.util.Collections;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 
+//todo [anistor] command forwarding breaks the rule that we have only one originator for a command. this opens now the possibility to have two threads processing incoming remote commands for the same TX
 /**
  * // TODO: Document this
  *
@@ -317,8 +316,8 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       } finally {
          stateTransferLock.commandsSharedUnlock();
 
-         log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
          if (newTargets != null && !newTargets.isEmpty()) {
+            log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
             rpcManager.invokeRemotely(newTargets, command, true);
          }
       }",2012-09-21T12:26:43Z,115
"@@ -178,19 +178,20 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
       // TODO Improve notification to contain both CHs
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, true);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), true);
 
       stateConsumer.onTopologyUpdate(newCacheTopology, isRebalance);
       stateProvider.onTopologyUpdate(newCacheTopology, isRebalance);
 
-      cacheNotifier.notifyTopologyChanged(oldCH, newCH, false);
+      cacheNotifier.notifyTopologyChanged(oldCH, newCH, newCacheTopology.getTopologyId(), false);
 
       if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
          initialStateTransferComplete.countDown();
       }
    }
 
    @Start(priority = 1000)
+   @SuppressWarnings(""unused"")
    public void waitForInitialStateTransferToComplete() throws InterruptedException {
       if (trace) log.tracef(""Waiting for initial state transfer to finish"");
       boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);",2012-09-21T12:26:43Z,117
"@@ -50,8 +50,11 @@ public class TransactionInfo {
 
    private final Set<Object> lockedKeys;
 
-   public TransactionInfo(GlobalTransaction globalTransaction, WriteCommand[] modifications, Set<Object> lockedKeys) {
+   private final int topologyId;
+
+   public TransactionInfo(GlobalTransaction globalTransaction, int topologyId, WriteCommand[] modifications, Set<Object> lockedKeys) {
       this.globalTransaction = globalTransaction;
+      this.topologyId = topologyId;
       this.modifications = modifications;
       this.lockedKeys = lockedKeys;
    }
@@ -68,10 +71,15 @@ public Set<Object> getLockedKeys() {
       return lockedKeys;
    }
 
+   public int getTopologyId() {
+      return topologyId;
+   }
+
    @Override
    public String toString() {
       return ""TransactionInfo{"" +
             ""globalTransaction="" + globalTransaction +
+            "", topologyId="" + topologyId +
             "", modifications="" + Arrays.asList(modifications) +
             "", lockedKeys="" + lockedKeys +
             '}';
@@ -92,6 +100,7 @@ public Set<Class<? extends TransactionInfo>> getTypeClasses() {
       @Override
       public void writeObject(ObjectOutput output, TransactionInfo object) throws IOException {
          output.writeObject(object.globalTransaction);
+         output.writeInt(object.topologyId);
          output.writeObject(object.modifications);
          output.writeObject(object.lockedKeys);
       }
@@ -100,9 +109,10 @@ public void writeObject(ObjectOutput output, TransactionInfo object) throws IOEx
       @SuppressWarnings(""unchecked"")
       public TransactionInfo readObject(ObjectInput input) throws IOException, ClassNotFoundException {
          GlobalTransaction globalTransaction = (GlobalTransaction) input.readObject();
+         int topologyId = input.readInt();
          WriteCommand[] modifications = (WriteCommand[]) input.readObject();
          Set<Object> lockedKeys = (Set<Object>) input.readObject();
-         return new TransactionInfo(globalTransaction, modifications, lockedKeys);
+         return new TransactionInfo(globalTransaction, topologyId, modifications, lockedKeys);
       }
    }
 }",2012-09-21T12:26:43Z,137
"@@ -31,8 +31,6 @@
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
 import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.MembershipArithmetic;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
@@ -67,37 +65,41 @@ public class StaleTransactionCleanupService {
    private TransactionTable transactionTable;
    private InterceptorChain invoker;
    private String cacheName;
+   private boolean isDistributed;
 
    public StaleTransactionCleanupService(TransactionTable transactionTable) {
       this.transactionTable = transactionTable;
    }
 
    private ExecutorService lockBreakingService; // a thread pool with max. 1 thread
 
-   /**
-    * Roll back remote transactions originating on nodes that have left the cluster.
-    */
-   @ViewChanged
-   public void onViewChange(ViewChangedEvent vce) {
-      final List<Address> leavers = MembershipArithmetic.getMembersLeft(vce.getOldMembers(),
-                                                                        vce.getNewMembers());
-      if (!leavers.isEmpty()) {
-         log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
-         cleanTxForWhichTheOwnerLeft(leavers);
-      }
-   }
-
    /**
     * Roll back remote transactions that have acquired lock that are no longer valid,
     * either because the main data owner left the cluster or because a node joined
     * the cluster and is the new data owner.
     * This method will only ever be called in distributed mode.
     */
    @TopologyChanged
+   @SuppressWarnings(""unused"")
    public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
-      // do all the work AFTER the consistent hash has changed
-      if (tce.isPre())
+      // Roll back remote transactions originating on nodes that have left the cluster.
+      if (tce.isPre()) {
+         ConsistentHash consistentHashAtStart = tce.getConsistentHashAtStart();
+         if (consistentHashAtStart != null) {
+            List<Address> leavers = MembershipArithmetic.getMembersLeft(consistentHashAtStart.getMembers(), tce.getConsistentHashAtEnd().getMembers());
+            if (!leavers.isEmpty()) {
+               log.tracef(""Saw %d leavers - kicking off a lock breaking task"", leavers.size());
+               cleanTxForWhichTheOwnerLeft(leavers);
+            }
+         }
+         return;
+      }
+
+      if (!isDistributed) {
          return;
+      }
+
+      // do all the work AFTER the consistent hash has changed
 
       Address self = transactionTable.rpcManager.getAddress();
       ConsistentHash chOld = tce.getConsistentHashAtStart();
@@ -173,7 +175,7 @@ public void run() {
       }
    }
 
-   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain) {
+   public void start(final String cacheName, final RpcManager rpcManager, InterceptorChain interceptorChain, boolean isDistributed) {
       this.invoker = interceptorChain;
       ThreadFactory tf = new ThreadFactory() {
          @Override
@@ -185,8 +187,9 @@ public Thread newThread(Runnable r) {
          }
       };
       this.cacheName = cacheName;
+      this.isDistributed = isDistributed;
       lockBreakingService = new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingDeque<Runnable>(), tf,
-                                                   new ThreadPoolExecutor.CallerRunsPolicy());
+                                                   new ThreadPoolExecutor.DiscardOldestPolicy());
    }
 
    public void stop() {",2012-09-21T12:26:43Z,126
"@@ -38,11 +38,10 @@
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.interceptors.InterceptorChain;
 import org.infinispan.interceptors.locking.ClusteringDependentLogic;
-import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.notifications.Listener;
 import org.infinispan.notifications.cachelistener.CacheNotifier;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.notifications.cachelistener.annotation.TopologyChanged;
+import org.infinispan.notifications.cachelistener.event.TopologyChangedEvent;
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.transaction.synchronization.SyncLocalTransaction;
@@ -57,9 +56,7 @@
 
 import javax.transaction.Transaction;
 import javax.transaction.TransactionSynchronizationRegistry;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.locks.Lock;
@@ -76,7 +73,7 @@
  * @author Galder Zamarreño
  * @since 4.0
  */
-@Listener(sync = false)
+@Listener
 public class TransactionTable {
 
    public static final int CACHE_STOPPED_VIEW_ID = -1;
@@ -95,25 +92,23 @@ public class TransactionTable {
    protected CommandsFactory commandsFactory;
    private InterceptorChain invoker;
    private CacheNotifier notifier;
-   private EmbeddedCacheManager cm;
    private TransactionSynchronizationRegistry transactionSynchronizationRegistry;
    protected ClusteringDependentLogic clusteringLogic;
    protected boolean clustered = false;
    private Lock minViewRecalculationLock;
 
    /**
-    * minTxViewId is the minimum view ID across all ongoing local and remote transactions. It doesn't update on
-    * transaction creation, but only on removal. That's because it is not possible for a newly created transaction to
-    * have an bigger view ID than the current one.
+    * minTxViewId is the minimum view ID across all ongoing local and remote transactions.
     */
    private volatile int minTxViewId = CACHE_STOPPED_VIEW_ID;
    private volatile int currentViewId = CACHE_STOPPED_VIEW_ID;
+   private volatile boolean useStrictTopologyIdComparison = true;
    private String cacheName;
 
    @Inject
    public void initialize(RpcManager rpcManager, Configuration configuration,
                           InvocationContextContainer icc, InterceptorChain invoker, CacheNotifier notifier,
-                          TransactionFactory gtf, EmbeddedCacheManager cm, TransactionCoordinator txCoordinator,
+                          TransactionFactory gtf, TransactionCoordinator txCoordinator,
                           TransactionSynchronizationRegistry transactionSynchronizationRegistry,
                           CommandsFactory commandsFactory, ClusteringDependentLogic clusteringDependentLogic, Cache cache) {
       this.rpcManager = rpcManager;
@@ -122,7 +117,6 @@ public void initialize(RpcManager rpcManager, Configuration configuration,
       this.invoker = invoker;
       this.notifier = notifier;
       this.txFactory = gtf;
-      this.cm = cm;
       this.txCoordinator = txCoordinator;
       this.transactionSynchronizationRegistry = transactionSynchronizationRegistry;
       this.commandsFactory = commandsFactory;
@@ -139,24 +133,20 @@ private void start() {
          minViewRecalculationLock = new ReentrantLock();
          // Only initialize this if we are clustered.
          remoteTransactions = ConcurrentMapFactory.makeConcurrentMap(concurrencyLevel, 0.75f, concurrencyLevel);
-         cleanupService.start(cacheName, rpcManager, invoker);
-         cm.addListener(cleanupService);
-         cm.addListener(this);
+         cleanupService.start(cacheName, rpcManager, invoker, configuration.clustering().cacheMode().isDistributed());
          notifier.addListener(cleanupService);
-         minTxViewId = rpcManager.getTransport().getViewId();
-         currentViewId = minTxViewId;
-         log.debugf(""Min view id set to %s"", minTxViewId);
+         notifier.addListener(this);
          clustered = true;
       }
    }
 
    @Stop
+   @SuppressWarnings(""unused"")
    private void stop() {
       if (clustered) {
          notifier.removeListener(cleanupService);
-         cm.removeListener(cleanupService);
          cleanupService.stop();
-         cm.removeListener(this);
+         notifier.removeListener(this);
          currentViewId = CACHE_STOPPED_VIEW_ID; // indicate that the cache has stopped
       }
       shutDownGracefully();
@@ -223,6 +213,17 @@ public int getMinViewId() {
       return minTxViewId;
    }
 
+   /**
+    * Indicates if topology id comparisons should be strict if one wants to compare topology ids in oder to tell
+    * if a transaction was started in an older topology than a second transaction. This flag is true most of the time
+    * except when the current topology did not increase its id (it's not caused by a rebalance).
+    *
+    * @return true if strict topology id comparisons should be used, false otherwise
+    */
+   public boolean useStrictTopologyIdComparison() {
+      return useStrictTopologyIdComparison;
+   }
+
    protected void updateStateOnNodesLeaving(Collection<Address> leavers) {
       Set<GlobalTransaction> toKill = new HashSet<GlobalTransaction>();
       for (GlobalTransaction gt : remoteTransactions.keySet()) {
@@ -263,14 +264,24 @@ public void remoteTransactionRollback(GlobalTransaction gtx) {
    }
 
    /**
-    * Creates and register a {@link RemoteTransaction} with no modifications. Returns the created transaction.
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
     *
     * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
     *                               made.
     */
    public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications) {
-      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, currentViewId)
-            : txFactory.newRemoteTransaction(modifications, globalTx, currentViewId);
+      return createRemoteTransaction(globalTx, modifications, currentViewId);
+   }
+
+   /**
+    * Creates and register a {@link RemoteTransaction}. Returns the created transaction.
+    *
+    * @throws IllegalStateException if an attempt to create a {@link RemoteTransaction} for an already registered id is
+    *                               made.
+    */
+   public RemoteTransaction createRemoteTransaction(GlobalTransaction globalTx, WriteCommand[] modifications, int topologyId) {
+      RemoteTransaction remoteTransaction = modifications == null ? txFactory.newRemoteTransaction(globalTx, topologyId)
+            : txFactory.newRemoteTransaction(modifications, globalTx, topologyId);
       registerRemoteTransaction(globalTx, remoteTransaction);
       return remoteTransaction;
    }
@@ -283,6 +294,10 @@ private void registerRemoteTransaction(GlobalTransaction gtx, RemoteTransaction
       }
 
       log.tracef(""Created and registered remote transaction %s"", rtx);
+      if (rtx.getViewId() < minTxViewId) {
+         log.tracef(""Changing minimum view ID from %d to %d"", minTxViewId, rtx.getViewId());
+         minTxViewId = rtx.getViewId();
+      }
    }
 
    /**
@@ -293,6 +308,9 @@ public LocalTransaction getOrCreateLocalTransaction(Transaction transaction, TxI
       LocalTransaction current = localTransactions.get(transaction);
       if (current == null) {
          Address localAddress = rpcManager != null ? rpcManager.getTransport().getAddress() : null;
+         if (rpcManager != null && currentViewId < 0) {
+            throw new IllegalStateException(""Cannot create transactions if topology id is not known yet!"");
+         }
          GlobalTransaction tx = txFactory.newGlobalTransaction(localAddress, false);
          current = txFactory.newLocalTransaction(transaction, tx, ctx.isImplicitTransaction(), currentViewId);
          log.tracef(""Created a new local transaction: %s"", current);
@@ -310,10 +328,6 @@ public boolean removeLocalTransaction(LocalTransaction localTransaction) {
       return localTransaction != null && (removeLocalTransactionInternal(localTransaction.getTransaction()) != null);
    }
 
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      return removeLocalTransactionInternal(tx);
-   }
-
    protected final LocalTransaction removeLocalTransactionInternal(Transaction tx) {
       LocalTransaction removed;
       removed = localTransactions.remove(tx);
@@ -357,8 +371,8 @@ public int getLocalTxCount() {
 
    /**
     * Looks up a LocalTransaction given a GlobalTransaction.
-    * @param txId
-    * @return
+    * @param txId the global transaction identifier
+    * @return the LocalTransaction or null if not found
     */
    public LocalTransaction getLocalTransaction(GlobalTransaction txId) {
       for (LocalTransaction localTx : localTransactions.values()) { //todo [anistor] optimize lookup!
@@ -402,17 +416,21 @@ protected final void recalculateMinViewIdIfNeeded(CacheTransaction removedTransa
       }
    }
 
-   @ViewChanged
-   public void recalculateMinViewIdOnTopologyChange(ViewChangedEvent vce) {
-      // don't do anything if this cache is not clustered - view changes are global
+   @TopologyChanged
+   @SuppressWarnings(""unused"")
+   public void onTopologyChange(TopologyChangedEvent<?, ?> tce) {
+      // don't do anything if this cache is not clustered
       if (clustered) {
-         log.debugf(""View changed, recalculating minViewId"");
-         currentViewId = vce.getViewId();
-         calculateMinViewId(-1);
+         if (tce.isPre()) {
+            useStrictTopologyIdComparison = tce.getNewTopologyId() != currentViewId;
+            currentViewId = tce.getNewTopologyId();
+         } else {
+            log.debugf(""Topology changed, recalculating minViewId"");
+            calculateMinViewId(-1);
+         }
       }
    }
 
-
    /**
     * This method calculates the minimum view ID known by the current node.  This method is only used in a clustered
     * cache, and only invoked when either a view change is detected, or a transaction whose view ID is not the same as
@@ -442,7 +460,7 @@ private void calculateMinViewId(int idOfRemovedTransaction) {
                int viewId = ct.getViewId();
                if (viewId < minViewIdFound) minViewIdFound = viewId;
             }
-            if (minViewIdFound > minTxViewId) {
+            if (minViewIdFound != minTxViewId) {
                log.tracef(""Changing minimum view ID from %s to %s"", minTxViewId, minViewIdFound);
                minTxViewId = minViewIdFound;
             } else {",2012-09-21T12:26:43Z,127
"@@ -80,13 +80,6 @@ private void removeXidTxMapping(LocalXaTransaction localTx) {
       xid2LocalTx.remove(xid);
    }
 
-   @Override
-   public LocalTransaction removeLocalTransaction(Transaction tx) {
-      final LocalTransaction remove = removeLocalTransactionInternal(tx);
-      if (remove != null) removeXidTxMapping((LocalXaTransaction) remove);
-      return remove;
-   }
-
    public LocalXaTransaction getLocalTransaction(Xid xid) {
       return this.xid2LocalTx.get(xid);
    }",2012-09-21T12:26:43Z,138
"@@ -22,10 +22,8 @@
  */
 package org.infinispan.util.concurrent.locks;
 
-import org.infinispan.commands.FlagAffectedCommand;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.CacheEntry;
-import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.jmx.annotations.MBean;",2012-09-21T12:26:43Z,139
"@@ -93,15 +93,16 @@ public boolean isSatisfied() throws Exception {
          public void run() {
             try {
                log.trace(""This thread runs a different tx"");
-               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).resume(suspend);
+               cache(secondTxNode).put(k, ""v2"");
                tm(secondTxNode).commit();
             } catch (Exception e) {
                e.printStackTrace();
             }
          }
       }, false);
 
+      // this 'ensures' transaction called 'suspend' has the chance to start the prepare phase and is waiting to acquire the locks on k held by first transaction before it gets resumed
       Thread.sleep(1000);
 
       log.trace(""Before completing the transaction!"");",2012-09-21T12:26:43Z,140
"@@ -21,7 +21,7 @@
 /**
  * @since 5.1
  */
-@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"", enabled = false) //todo [anistor] temporarily disabled for NBST
+@Test(groups = ""functional"", testName = ""lock.singlelock.MainOwnerChangesLockTest"")
 @CleanupAfterMethod
 public class MainOwnerChangesLockTest extends MultipleCacheManagersTest {
 ",2012-09-21T12:26:43Z,141
"@@ -24,6 +24,7 @@
 package org.infinispan.lock.singlelock;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.statetransfer.StateTransferManager;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.test.fwk.CleanupAfterMethod;
@@ -33,8 +34,7 @@
 import org.infinispan.transaction.tm.DummyTransaction;
 import org.testng.annotations.Test;
 
-import javax.transaction.Status;
-
+import static org.testng.Assert.assertTrue;
 import static org.testng.Assert.assertEquals;
 
 
@@ -60,21 +60,22 @@ protected void createCacheManagers() throws Throwable {
       waitForClusterToForm();
    }
 
-   @Test(enabled = false, description = ""See ISPN-2113"")
    public void testMinViewId1() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
+
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);
 
       //add a new cache and check that min view is updated
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId2);
       assertEquals(tt1.getMinViewId(), viewId2);
@@ -88,8 +89,8 @@ public void testMinViewId2() throws Exception {
       final TransactionTable tt0 = TestingUtil.getTransactionTable(cache(0));
       final TransactionTable tt1 = TestingUtil.getTransactionTable(cache(1));
 
-
-      final int viewId = advancedCache(0).getRpcManager().getTransport().getViewId();
+      StateTransferManager stateTransferManager0 = TestingUtil.extractComponent(cache(0), StateTransferManager.class);
+      final int viewId = stateTransferManager0.getCacheTopology().getTopologyId();
 
       tm(1).begin();
       cache(1).put(getKeyForCache(0),""v"");
@@ -109,8 +110,8 @@ public boolean isSatisfied() throws Exception {
       addClusterEnabledCacheManager(c);
       waitForClusterToForm();
 
-      final int viewId2 = advancedCache(0).getRpcManager().getTransport().getViewId();
-      assertEquals(viewId + 1, viewId2);
+      final int viewId2 = stateTransferManager0.getCacheTopology().getTopologyId();
+      assertTrue(viewId2 > viewId);
 
       assertEquals(tt0.getMinViewId(), viewId);
       assertEquals(tt1.getMinViewId(), viewId);",2012-09-21T12:26:43Z,142
"@@ -36,7 +36,6 @@
 import javax.transaction.InvalidTransactionException;
 import javax.transaction.NotSupportedException;
 import javax.transaction.RollbackException;
-import javax.transaction.Status;
 import javax.transaction.SystemException;
 
 import static org.testng.Assert.assertEquals;
@@ -45,7 +44,7 @@
  * @author Mircea Markus
  * @since 5.1
  */
-@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"", enabled = false, description = ""See ISPN-2113"")
+@Test (groups = ""functional"", testName = ""lock.singlelock.pessimistic.LockOwnerCrashPessimisticTest"")
 @CleanupAfterMethod
 public class LockOwnerCrashPessimisticTest extends AbstractLockOwnerCrashTest {
 ",2012-09-21T12:26:43Z,143
"@@ -40,6 +40,7 @@
 import org.infinispan.remoting.rpc.RpcManager;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.topology.CacheTopology;
+import org.infinispan.transaction.LocalTransaction;
 import org.infinispan.transaction.LockingMode;
 import org.infinispan.transaction.RemoteTransaction;
 import org.infinispan.transaction.WriteSkewHelper;
@@ -123,6 +124,7 @@ public Object visitCommitCommand(TxInvocationContext ctx, CommitCommand command)
             }
             commandFactory.initializeReplicableCommand(prepareCommand, true);
             prepareCommand.setOrigin(ctx.getOrigin());
+            log.tracef(""Replaying the transactions received as a result of state transfer %s"", prepareCommand);
             prepareCommand.perform(null);
          }
       }
@@ -191,14 +193,9 @@ public Object visitEvictCommand(InvocationContext ctx, EvictCommand command) thr
    /**
     * Special processing required for transaction commands.
     *
-    * @param ctx
-    * @param command
-    * @return
-    * @throws Throwable
     */
-   private Object handleTxCommand(TxInvocationContext ctx, TransactionBoundaryCommand command)
-         throws Throwable {
-      return handleTopologyAffectedCommand(ctx, command, ctx.getCacheTransaction() instanceof RemoteTransaction);
+   private Object handleTxCommand(TxInvocationContext ctx, TransactionBoundaryCommand command) throws Throwable {
+      return handleTopologyAffectedCommand(ctx, command, ctx.isOriginLocal());
    }
 
    private Object handleWriteCommand(InvocationContext ctx, WriteCommand command) throws Throwable {
@@ -220,10 +217,13 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       if (command instanceof FlagAffectedCommand) {
          cacheModeLocal = ((FlagAffectedCommand)command).hasFlag(Flag.CACHE_MODE_LOCAL);
       }
+      log.tracef(""handleTopologyAffectedCommand for command %s, originLocal=%s, cacheModeLocal=%s"", command, originLocal
+            , cacheModeLocal);
       if (originLocal || cacheModeLocal) {
          return invokeNextInterceptor(ctx, command);
       }
 
+
       // set the topology id if it was not set before (ie. this is local command)
       // TODO Make tx commands extend FlagAffectedCommand so we can use CACHE_MODE_LOCAL in StaleTransactionCleanupService
       if (command.getTopologyId() == -1) {
@@ -242,26 +242,20 @@ private Object handleTopologyAffectedCommand(InvocationContext ctx, TopologyAffe
       CacheTopology cacheTopology = stateTransferManager.getCacheTopology();
       int localTopologyId = cacheTopology.getTopologyId();
       // if it's a tx/lock/write command, forward it to the new owners
+      log.tracef(""CommandTopologyId=%s, localTopologyId=%s"", cmdTopologyId, localTopologyId);
+
       if (cmdTopologyId < localTopologyId) {
-         if (command instanceof TransactionBoundaryCommand || command instanceof LockControlCommand
-               || (command instanceof WriteCommand && !ctx.isInTxScope())) {
-            // We don't know the full topology history to send the command only to the new owners,
-            // but we do know two things:
-            // 1. The originator - which shouldn't receive the same command again
-            // 2. If the local topology = command topology + 1 and pendingCH = null, there are no new owners
-            ConsistentHash pendingCh = cacheTopology.getPendingCH();
-            if (pendingCh != null && cmdTopologyId < localTopologyId + 1) {
-               ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
-               Set<Object> affectedKeys = getAffectedKeys(ctx, command);
-               Set<Address> newTargets = writeCh.locateAllOwners(affectedKeys);
-               newTargets.remove(rpcManager.getAddress());
-               if (!newTargets.isEmpty()) {
-                  // Update the topology id to prevent cycles
-                  command.setTopologyId(localTopologyId);
-                  log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
-                  // TODO find a way to forward the command async if it was received async
-                  rpcManager.invokeRemotely(newTargets, command, true, false);
-               }
+         if (command instanceof TransactionBoundaryCommand  || (command instanceof WriteCommand && !ctx.isInTxScope())) {
+            ConsistentHash writeCh = cacheTopology.getWriteConsistentHash();
+            Set<Object> affectedKeys = getAffectedKeys(ctx, command);
+            Set<Address> newTargets = writeCh.locateAllOwners(affectedKeys);
+            newTargets.remove(rpcManager.getAddress());
+            if (!newTargets.isEmpty()) {
+               // Update the topology id to prevent cycles
+               command.setTopologyId(localTopologyId);
+               log.tracef(""Forwarding command %s to new targets %s"", command, newTargets);
+               // TODO find a way to forward the command async if it was received async
+               rpcManager.invokeRemotely(newTargets, command, true, false);
             }
          }
       }",2012-10-12T16:37:21Z,115
"@@ -0,0 +1,426 @@
+/*
+ * JBoss, Home of Professional Open Source
+ *  Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ *  contributors as indicated by the @author tags. All rights reserved
+ *  See the copyright.txt in the distribution for a full listing of
+ *  individual contributors.
+ *
+ *  This is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU Lesser General Public License as
+ *  published by the Free Software Foundation; either version 2.1 of
+ *  the License, or (at your option) any later version.
+ *
+ *  This software is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ *  Lesser General Public License for more details.
+ *
+ *  You should have received a copy of the GNU Lesser General Public
+ *  License along with this software; if not, write to the Free
+ *  Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ *  02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.tx;
+
+
+import org.infinispan.atomic.Delta;
+import org.infinispan.commands.CommandsFactory;
+import org.infinispan.commands.CreateCacheCommand;
+import org.infinispan.commands.ReplicableCommand;
+import org.infinispan.commands.control.LockControlCommand;
+import org.infinispan.commands.read.DistributedExecuteCommand;
+import org.infinispan.commands.read.EntrySetCommand;
+import org.infinispan.commands.read.GetKeyValueCommand;
+import org.infinispan.commands.read.KeySetCommand;
+import org.infinispan.commands.read.MapCombineCommand;
+import org.infinispan.commands.read.ReduceCommand;
+import org.infinispan.commands.read.SizeCommand;
+import org.infinispan.commands.read.ValuesCommand;
+import org.infinispan.commands.remote.ClusteredGetCommand;
+import org.infinispan.commands.remote.MultipleRpcCommand;
+import org.infinispan.commands.remote.SingleRpcCommand;
+import org.infinispan.commands.remote.recovery.CompleteTransactionCommand;
+import org.infinispan.commands.remote.recovery.GetInDoubtTransactionsCommand;
+import org.infinispan.commands.remote.recovery.GetInDoubtTxInfoCommand;
+import org.infinispan.commands.remote.recovery.TxCompletionNotificationCommand;
+import org.infinispan.commands.tx.CommitCommand;
+import org.infinispan.commands.tx.PrepareCommand;
+import org.infinispan.commands.tx.RollbackCommand;
+import org.infinispan.commands.tx.VersionedCommitCommand;
+import org.infinispan.commands.tx.VersionedPrepareCommand;
+import org.infinispan.commands.write.*;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.container.versioning.EntryVersion;
+import org.infinispan.context.Flag;
+import org.infinispan.distexec.mapreduce.Mapper;
+import org.infinispan.distexec.mapreduce.Reducer;
+import org.infinispan.factories.ComponentRegistry;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.statetransfer.StateChunk;
+import org.infinispan.statetransfer.StateRequestCommand;
+import org.infinispan.statetransfer.StateResponseCommand;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.transaction.TransactionTable;
+import org.infinispan.transaction.lookup.DummyTransactionManagerLookup;
+import org.infinispan.transaction.tm.DummyTransaction;
+import org.infinispan.transaction.tm.DummyTransactionManager;
+import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.util.concurrent.ReclosableLatch;
+import org.testng.annotations.Test;
+
+import javax.transaction.HeuristicMixedException;
+import javax.transaction.xa.Xid;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.concurrent.Callable;
+import java.util.concurrent.atomic.AtomicInteger;
+
+import static org.junit.Assert.*;
+
+/**
+ * @author Mircea Markus
+ * @since 5.2
+ */
+@Test (groups = ""functional"", testName = ""tx.LockCleanupStateTransferTest"")
+public class LockCleanupStateTransferTest extends MultipleCacheManagersTest {
+   private static final int KEY_SET_SIZE = 10;
+   private ConfigurationBuilder dcc;
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      dcc = getDefaultClusteredCacheConfig(CacheMode.DIST_SYNC, true);
+      dcc.transaction().transactionManagerLookup(new DummyTransactionManagerLookup());
+      dcc.clustering().hash().numOwners(1);
+      createCluster(dcc, 2);
+      waitForClusterToForm();
+   }
+
+   public void testLockReleasedCorrectly() throws Throwable {
+
+
+      ComponentRegistry componentRegistry = advancedCache(1).getComponentRegistry();
+      final ControlledCommandFactory ccf = new ControlledCommandFactory(componentRegistry.getCommandsFactory());
+      TestingUtil.replaceField(ccf, ""commandsFactory"", componentRegistry, ComponentRegistry.class);
+
+      //hack: re-add the component registry to the GlobalComponentRegistry's ""namedComponents"" (CHM) in order to correctly publish it for
+      // when it will be read by the InboundInvocationHandlder. IIH reads the value from the GlobalComponentRegistry.namedComponents before using it
+      advancedCache(1).getComponentRegistry().getGlobalComponentRegistry().registerNamedComponentRegistry(componentRegistry, EmbeddedCacheManager.DEFAULT_CACHE_NAME);
+      ccf.gate.close();
+
+      final Set<Object> keys = new HashSet<Object>(KEY_SET_SIZE);
+
+      //fork it into another test as this is going to block in commit
+      fork(new Callable<Object>() {
+         @Override
+         public Object call() throws Exception {
+            tm(0).begin();
+            for (int i = 0; i < KEY_SET_SIZE; i++) {
+               Object k = getKeyForCache(1);
+               keys.add(k);
+               cache(0).put(k, k);
+            }
+            tm(0).commit();
+            return null;
+         }
+      });
+
+      //now wait for all the commits to block
+      eventually(new Condition() {
+         @Override
+         public boolean isSatisfied() throws Exception {
+            return ccf.receivedCommits.get() == 1;
+         }
+      });
+
+      //now add a one new member
+      addClusterEnabledCacheManager(dcc);
+      waitForClusterToForm();
+
+      final Set<Object> migratedKeys = new HashSet<Object>(KEY_SET_SIZE);
+      for (Object key : keys) {
+         if (keyMapsToNode(key, 2)) {
+            migratedKeys.add(key);
+         }
+      }
+
+      log.tracef(""Number of migrated keys is %s"", migratedKeys.size());
+      System.out.println(""Number of migrated tx is "" + migratedKeys.size());
+      if (migratedKeys.size() == 0) return;
+
+      eventually(new Condition() {
+         @Override
+         public boolean isSatisfied() throws Exception {
+            int remoteTxCount = TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount();
+            int localTxCount = TestingUtil.getTransactionTable(cache(2)).getLocalTxCount();
+            log.trace(""remoteTxCount = "" + remoteTxCount);
+            log.trace(""localTxCount = "" + localTxCount);
+            return remoteTxCount == 1;
+         }
+      });
+
+      log.trace(""Releasing the gate"");
+      ccf.gate.open();
+
+      eventually(new Condition() {
+         @Override
+         public boolean isSatisfied() throws Exception {
+            return TestingUtil.getTransactionTable(cache(2)).getRemoteTxCount() == 0;
+         }
+      });
+
+
+      for (int i = 0; i < 3; i++) {
+         TransactionTable tt = TestingUtil.getTransactionTable(cache(i));
+         assertEquals(""For cache "" + i, 0, tt.getLocalTxCount());
+         assertEquals(""For cache "" + i, 0, tt.getRemoteTxCount());
+      }
+
+
+      for (Object key : keys) {
+         assertNotLocked(key);
+         assertEquals(key, cache(0).get(key));
+      }
+   }
+
+   private boolean keyMapsToNode(Object key, int nodeIndex) {
+      Address owner = owner(key);
+      return owner.equals(address(nodeIndex));
+   }
+
+   private Address owner(Object key) {
+      return advancedCache(0).getDistributionManager().getConsistentHash().locateOwners(key).get(0);
+   }
+
+   public class ControlledCommandFactory implements CommandsFactory {
+      final CommandsFactory actual;
+      final ReclosableLatch gate = new ReclosableLatch(true);
+      final AtomicInteger receivedCommits = new AtomicInteger(0);
+
+      public ControlledCommandFactory(CommandsFactory actual) {
+         this.actual = actual;
+      }
+
+      @Override
+      public PutKeyValueCommand buildPutKeyValueCommand(Object key, Object value, long lifespanMillis, long maxIdleTimeMillis, Set<Flag> flags) {
+         return actual.buildPutKeyValueCommand(key, value, lifespanMillis, maxIdleTimeMillis, flags);
+      }
+
+      @Override
+      public VersionedPutKeyValueCommand buildVersionedPutKeyValueCommand(Object key, Object value, long lifespanMillis, long maxIdleTimeMillis, EntryVersion version, Set<Flag> flags) {
+         return actual.buildVersionedPutKeyValueCommand(key, value, lifespanMillis, maxIdleTimeMillis, version, flags);
+      }
+
+      @Override
+      public RemoveCommand buildRemoveCommand(Object key, Object value, Set<Flag> flags) {
+         return actual.buildRemoveCommand(key, value, flags);
+      }
+
+      @Override
+      public InvalidateCommand buildInvalidateCommand(Set<Flag> flags, Object... keys) {
+         return actual.buildInvalidateCommand(flags, keys);
+      }
+
+      @Override
+      public InvalidateCommand buildInvalidateFromL1Command(boolean forRehash, Set<Flag> flags, Object... keys) {
+         return actual.buildInvalidateFromL1Command(forRehash, flags, keys);
+      }
+
+      @Override
+      public InvalidateCommand buildInvalidateFromL1Command(boolean forRehash, Set<Flag> flags, Collection<Object> keys) {
+         return actual.buildInvalidateFromL1Command(forRehash, flags, keys);
+      }
+
+      @Override
+      public InvalidateCommand buildInvalidateFromL1Command(Address origin, boolean forRehash, Set<Flag> flags, Collection<Object> keys) {
+         return actual.buildInvalidateFromL1Command(origin, forRehash, flags, keys);
+      }
+
+      @Override
+      public ReplaceCommand buildReplaceCommand(Object key, Object oldValue, Object newValue, long lifespanMillis, long maxIdleTimeMillis, Set<Flag> flags) {
+         return actual.buildReplaceCommand(key, oldValue, newValue, lifespanMillis, maxIdleTimeMillis, flags);
+      }
+
+      @Override
+      public SizeCommand buildSizeCommand() {
+         return actual.buildSizeCommand();
+      }
+
+      @Override
+      public GetKeyValueCommand buildGetKeyValueCommand(Object key, Set<Flag> flags) {
+         return actual.buildGetKeyValueCommand(key, flags);
+      }
+
+      @Override
+      public KeySetCommand buildKeySetCommand() {
+         return actual.buildKeySetCommand();
+      }
+
+      @Override
+      public ValuesCommand buildValuesCommand() {
+         return actual.buildValuesCommand();
+      }
+
+      @Override
+      public EntrySetCommand buildEntrySetCommand() {
+         return actual.buildEntrySetCommand();
+      }
+
+      @Override
+      public PutMapCommand buildPutMapCommand(Map<?, ?> map, long lifespanMillis, long maxIdleTimeMillis, Set<Flag> flags) {
+         return actual.buildPutMapCommand(map, lifespanMillis, maxIdleTimeMillis, flags);
+      }
+
+      @Override
+      public ClearCommand buildClearCommand(Set<Flag> flags) {
+         return actual.buildClearCommand(flags);
+      }
+
+      @Override
+      public EvictCommand buildEvictCommand(Object key, Set<Flag> flags) {
+         return actual.buildEvictCommand(key, flags);
+      }
+
+      @Override
+      public PrepareCommand buildPrepareCommand(GlobalTransaction gtx, List<WriteCommand> modifications, boolean onePhaseCommit) {
+         return actual.buildPrepareCommand(gtx, modifications, onePhaseCommit);
+      }
+
+      @Override
+      public VersionedPrepareCommand buildVersionedPrepareCommand(GlobalTransaction gtx, List<WriteCommand> modifications, boolean onePhase) {
+         return actual.buildVersionedPrepareCommand(gtx, modifications, onePhase);
+      }
+
+      @Override
+      public CommitCommand buildCommitCommand(GlobalTransaction gtx) {
+         return actual.buildCommitCommand(gtx);
+      }
+
+      @Override
+      public VersionedCommitCommand buildVersionedCommitCommand(GlobalTransaction gtx) {
+         return actual.buildVersionedCommitCommand(gtx);
+      }
+
+      @Override
+      public RollbackCommand buildRollbackCommand(GlobalTransaction gtx) {
+         return actual.buildRollbackCommand(gtx);
+      }
+
+      @Override
+      public void initializeReplicableCommand(ReplicableCommand command, boolean isRemote) {
+         if (isRemote && command instanceof CommitCommand) {
+            receivedCommits.incrementAndGet();
+            try {
+               gate.await();
+               log.tracef(""gate is opened, processing the commit:  %s"", command);
+            } catch (InterruptedException e) {
+               throw new RuntimeException(e);
+            }
+         }
+         actual.initializeReplicableCommand(command, isRemote);
+      }
+
+      @Override
+      public MultipleRpcCommand buildReplicateCommand(List<ReplicableCommand> toReplicate) {
+         return actual.buildReplicateCommand(toReplicate);
+      }
+
+      @Override
+      public SingleRpcCommand buildSingleRpcCommand(ReplicableCommand call) {
+         return actual.buildSingleRpcCommand(call);
+      }
+
+      @Override
+      public ClusteredGetCommand buildClusteredGetCommand(Object key, Set<Flag> flags, boolean acquireRemoteLock, GlobalTransaction gtx) {
+         return actual.buildClusteredGetCommand(key, flags, acquireRemoteLock, gtx);
+      }
+
+      @Override
+      public LockControlCommand buildLockControlCommand(Collection<Object> keys, Set<Flag> flags, GlobalTransaction gtx) {
+         return actual.buildLockControlCommand(keys, flags, gtx);
+      }
+
+      @Override
+      public LockControlCommand buildLockControlCommand(Object key, Set<Flag> flags, GlobalTransaction gtx) {
+         return actual.buildLockControlCommand(key, flags, gtx);
+      }
+
+      @Override
+      public LockControlCommand buildLockControlCommand(Collection<Object> keys, Set<Flag> flags) {
+         return actual.buildLockControlCommand(keys, flags);
+      }
+
+      @Override
+      public StateRequestCommand buildStateRequestCommand(StateRequestCommand.Type subtype, Address sender, int viewId, Set<Integer> segments) {
+         return actual.buildStateRequestCommand(subtype, sender, viewId, segments);
+      }
+
+      @Override
+      public StateResponseCommand buildStateResponseCommand(Address sender, int viewId, Collection<StateChunk> stateChunks) {
+         return actual.buildStateResponseCommand(sender, viewId, stateChunks);
+      }
+
+      @Override
+      public String getCacheName() {
+         return actual.getCacheName();
+      }
+
+      @Override
+      public GetInDoubtTransactionsCommand buildGetInDoubtTransactionsCommand() {
+         return actual.buildGetInDoubtTransactionsCommand();
+      }
+
+      @Override
+      public TxCompletionNotificationCommand buildTxCompletionNotificationCommand(Xid xid, GlobalTransaction globalTransaction) {
+         return actual.buildTxCompletionNotificationCommand(xid, globalTransaction);
+      }
+
+      @Override
+      public <T> DistributedExecuteCommand<T> buildDistributedExecuteCommand(Callable<T> callable, Address sender, Collection keys) {
+         return actual.buildDistributedExecuteCommand(callable, sender, keys);
+      }
+
+      @Override
+      public <KIn, VIn, KOut, VOut> MapCombineCommand<KIn, VIn, KOut, VOut> buildMapCombineCommand(String taskId, Mapper<KIn, VIn, KOut, VOut> m, Reducer<KOut, VOut> r, Collection<KIn> keys) {
+         return actual.buildMapCombineCommand(taskId, m, r, keys);
+      }
+
+      @Override
+      public <KOut, VOut> ReduceCommand<KOut, VOut> buildReduceCommand(String taskId, String destinationCache, Reducer<KOut, VOut> r, Collection<KOut> keys) {
+         return actual.buildReduceCommand(taskId, destinationCache, r, keys);
+      }
+
+      @Override
+      public GetInDoubtTxInfoCommand buildGetInDoubtTxInfoCommand() {
+         return actual.buildGetInDoubtTxInfoCommand();
+      }
+
+      @Override
+      public CompleteTransactionCommand buildCompleteTransactionCommand(Xid xid, boolean commit) {
+         return actual.buildCompleteTransactionCommand(xid, commit);
+      }
+
+      @Override
+      public TxCompletionNotificationCommand buildTxCompletionNotificationCommand(long internalId) {
+         return actual.buildTxCompletionNotificationCommand(internalId);
+      }
+
+      @Override
+      public ApplyDeltaCommand buildApplyDeltaCommand(Object deltaAwareValueKey, Delta delta, Collection keys) {
+         return actual.buildApplyDeltaCommand(deltaAwareValueKey, delta, keys);
+      }
+
+      @Override
+      public CreateCacheCommand buildCreateCacheCommand(String cacheName, String cacheConfigurationName) {
+         return actual.buildCreateCacheCommand(cacheName, cacheConfigurationName);
+      }
+   }
+}",2012-10-12T16:37:21Z,118
"@@ -0,0 +1,197 @@
+package org.infinispan.util.concurrent.jdk7backported;
+
+/*
+ * Written by Doug Lea with assistance from members of JCP JSR-166
+ * Expert Group and released to the public domain, as explained at
+ * http://creativecommons.org/publicdomain/zero/1.0/
+ */
+
+import java.util.Random;
+
+/**
+ * A random number generator isolated to the current thread.  Like the
+ * global {@link java.util.Random} generator used by the {@link
+ * java.lang.Math} class, a {@code ThreadLocalRandom} is initialized
+ * with an internally generated seed that may not otherwise be
+ * modified. When applicable, use of {@code ThreadLocalRandom} rather
+ * than shared {@code Random} objects in concurrent programs will
+ * typically encounter much less overhead and contention.  Use of
+ * {@code ThreadLocalRandom} is particularly appropriate when multiple
+ * tasks (for example, each a {@link ForkJoinTask}) use random numbers
+ * in parallel in thread pools.
+ *
+ * <p>Usages of this class should typically be of the form:
+ * {@code ThreadLocalRandom.current().nextX(...)} (where
+ * {@code X} is {@code Int}, {@code Long}, etc).
+ * When all usages are of this form, it is never possible to
+ * accidently share a {@code ThreadLocalRandom} across multiple threads.
+ *
+ * <p>This class also provides additional commonly used bounded random
+ * generation methods.
+ *
+ * @since 1.7
+ * @author Doug Lea
+ */
+public class ThreadLocalRandom extends Random {
+   // same constants as Random, but must be redeclared because private
+   private static final long multiplier = 0x5DEECE66DL;
+   private static final long addend = 0xBL;
+   private static final long mask = (1L << 48) - 1;
+
+   /**
+    * The random seed. We can't use super.seed.
+    */
+   private long rnd;
+
+   /**
+    * Initialization flag to permit calls to setSeed to succeed only
+    * while executing the Random constructor.  We can't allow others
+    * since it would cause setting seed in one part of a program to
+    * unintentionally impact other usages by the thread.
+    */
+   boolean initialized;
+
+   // Padding to help avoid memory contention among seed updates in
+   // different TLRs in the common case that they are located near
+   // each other.
+   private long pad0, pad1, pad2, pad3, pad4, pad5, pad6, pad7;
+
+   /**
+    * The actual ThreadLocal
+    */
+   private static final ThreadLocal<ThreadLocalRandom> localRandom =
+         new ThreadLocal<ThreadLocalRandom>() {
+            protected ThreadLocalRandom initialValue() {
+               return new ThreadLocalRandom();
+            }
+         };
+
+
+   /**
+    * Constructor called only by localRandom.initialValue.
+    */
+   ThreadLocalRandom() {
+      super();
+      initialized = true;
+   }
+
+   /**
+    * Returns the current thread's {@code ThreadLocalRandom}.
+    *
+    * @return the current thread's {@code ThreadLocalRandom}
+    */
+   public static ThreadLocalRandom current() {
+      return localRandom.get();
+   }
+
+   /**
+    * Throws {@code UnsupportedOperationException}.  Setting seeds in
+    * this generator is not supported.
+    *
+    * @throws UnsupportedOperationException always
+    */
+   public void setSeed(long seed) {
+      if (initialized)
+         throw new UnsupportedOperationException();
+      rnd = (seed ^ multiplier) & mask;
+   }
+
+   protected int next(int bits) {
+      rnd = (rnd * multiplier + addend) & mask;
+      return (int) (rnd >>> (48-bits));
+   }
+
+   /**
+    * Returns a pseudorandom, uniformly distributed value between the
+    * given least value (inclusive) and bound (exclusive).
+    *
+    * @param least the least value returned
+    * @param bound the upper bound (exclusive)
+    * @throws IllegalArgumentException if least greater than or equal
+    * to bound
+    * @return the next value
+    */
+   public int nextInt(int least, int bound) {
+      if (least >= bound)
+         throw new IllegalArgumentException();
+      return nextInt(bound - least) + least;
+   }
+
+   /**
+    * Returns a pseudorandom, uniformly distributed value
+    * between 0 (inclusive) and the specified value (exclusive).
+    *
+    * @param n the bound on the random number to be returned.  Must be
+    *        positive.
+    * @return the next value
+    * @throws IllegalArgumentException if n is not positive
+    */
+   public long nextLong(long n) {
+      if (n <= 0)
+         throw new IllegalArgumentException(""n must be positive"");
+      // Divide n by two until small enough for nextInt. On each
+      // iteration (at most 31 of them but usually much less),
+      // randomly choose both whether to include high bit in result
+      // (offset) and whether to continue with the lower vs upper
+      // half (which makes a difference only if odd).
+      long offset = 0;
+      while (n >= Integer.MAX_VALUE) {
+         int bits = next(2);
+         long half = n >>> 1;
+         long nextn = ((bits & 2) == 0) ? half : n - half;
+         if ((bits & 1) == 0)
+            offset += n - nextn;
+         n = nextn;
+      }
+      return offset + nextInt((int) n);
+   }
+
+   /**
+    * Returns a pseudorandom, uniformly distributed value between the
+    * given least value (inclusive) and bound (exclusive).
+    *
+    * @param least the least value returned
+    * @param bound the upper bound (exclusive)
+    * @return the next value
+    * @throws IllegalArgumentException if least greater than or equal
+    * to bound
+    */
+   public long nextLong(long least, long bound) {
+      if (least >= bound)
+         throw new IllegalArgumentException();
+      return nextLong(bound - least) + least;
+   }
+
+   /**
+    * Returns a pseudorandom, uniformly distributed {@code double} value
+    * between 0 (inclusive) and the specified value (exclusive).
+    *
+    * @param n the bound on the random number to be returned.  Must be
+    *        positive.
+    * @return the next value
+    * @throws IllegalArgumentException if n is not positive
+    */
+   public double nextDouble(double n) {
+      if (n <= 0)
+         throw new IllegalArgumentException(""n must be positive"");
+      return nextDouble() * n;
+   }
+
+   /**
+    * Returns a pseudorandom, uniformly distributed value between the
+    * given least value (inclusive) and bound (exclusive).
+    *
+    * @param least the least value returned
+    * @param bound the upper bound (exclusive)
+    * @return the next value
+    * @throws IllegalArgumentException if least greater than or equal
+    * to bound
+    */
+   public double nextDouble(double least, double bound) {
+      if (least >= bound)
+         throw new IllegalArgumentException();
+      return nextDouble() * (bound - least) + least;
+   }
+
+   private static final long serialVersionUID = -5851777807851030925L;
+}",2012-06-13T11:41:59Z,644
"@@ -1,22 +1,3 @@
-/*
- * Copyright 2012 Red Hat, Inc. and/or its affiliates.
- *
- * This is free software; you can redistribute it and/or modify it
- * under the terms of the GNU Lesser General Public License as
- * published by the Free Software Foundation; either version 2.1 of
- * the License, or (at your option) any later version.
- *
- * This software is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this library; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
- * 02110-1301 USA
- */
-
 package org.infinispan.util.concurrent.jdk8backported;
 
 /*
@@ -25,6 +6,8 @@
  * http://creativecommons.org/publicdomain/zero/1.0/
  */
 
+// Snapshot Tue Jun  5 14:56:09 2012  Doug Lea  (dl at altair)
+
 import java.util.Arrays;
 import java.util.Map;
 import java.util.Set;
@@ -36,6 +19,8 @@
 import java.util.ConcurrentModificationException;
 import java.util.NoSuchElementException;
 import java.util.concurrent.ConcurrentMap;
+import org.infinispan.util.concurrent.jdk7backported.ThreadLocalRandom;
+import java.util.concurrent.locks.AbstractQueuedSynchronizer;
 import java.io.Serializable;
 
 /**
@@ -162,18 +147,20 @@ public static interface RemappingFunction<K, V> {
    * supplying null-checks and casts as needed. This also allows
    * many of the public methods to be factored into a smaller number
    * of internal methods (although sadly not so for the five
-   * sprawling variants of put-related operations).
+   * variants of put-related operations). The validation-based
+   * approach explained below leads to a lot of code sprawl because
+   * retry-control precludes factoring into smaller methods.
    *
    * The table is lazily initialized to a power-of-two size upon the
-   * first insertion.  Each bin in the table contains a list of
-   * Nodes (most often, the list has only zero or one Node).  Table
-   * accesses require volatile/atomic reads, writes, and CASes.
-   * Because there is no other way to arrange this without adding
-   * further indirections, we use intrinsics (sun.misc.Unsafe)
-   * operations.  The lists of nodes within bins are always
-   * accurately traversable under volatile reads, so long as lookups
-   * check hash code and non-nullness of value before checking key
-   * equality.
+   * first insertion.  Each bin in the table normally contains a
+   * list of Nodes (most often, the list has only zero or one Node).
+   * Table accesses require volatile/atomic reads, writes, and
+   * CASes.  Because there is no other way to arrange this without
+   * adding further indirections, we use intrinsics
+   * (sun.misc.Unsafe) operations.  The lists of nodes within bins
+   * are always accurately traversable under volatile reads, so long
+   * as lookups check hash code and non-nullness of value before
+   * checking key equality.
    *
    * We use the top two bits of Node hash fields for control
    * purposes -- they are available anyway because of addressing
@@ -185,23 +172,23 @@ public static interface RemappingFunction<K, V> {
    *  10 - Node is a forwarding node
    *
    * The lower 30 bits of each Node's hash field contain a
-   * transformation (for better randomization -- method ""spread"") of
-   * the key's hash code, except for forwarding nodes, for which the
-   * lower bits are zero (and so always have hash field == MOVED).
+   * transformation of the key's hash code, except for forwarding
+   * nodes, for which the lower bits are zero (and so always have
+   * hash field == MOVED).
    *
    * Insertion (via put or its variants) of the first node in an
    * empty bin is performed by just CASing it to the bin.  This is
-   * by far the most common case for put operations.  Other update
-   * operations (insert, delete, and replace) require locks.  We do
-   * not want to waste the space required to associate a distinct
-   * lock object with each bin, so instead use the first node of a
-   * bin list itself as a lock. Blocking support for these locks
-   * relies on the builtin ""synchronized"" monitors.  However, we
-   * also need a tryLock construction, so we overlay these by using
-   * bits of the Node hash field for lock control (see above), and
-   * so normally use builtin monitors only for blocking and
-   * signalling using wait/notifyAll constructions. See
-   * Node.tryAwaitLock.
+   * by far the most common case for put operations under most
+   * key/hash distributions.  Other update operations (insert,
+   * delete, and replace) require locks.  We do not want to waste
+   * the space required to associate a distinct lock object with
+   * each bin, so instead use the first node of a bin list itself as
+   * a lock. Blocking support for these locks relies on the builtin
+   * ""synchronized"" monitors.  However, we also need a tryLock
+   * construction, so we overlay these by using bits of the Node
+   * hash field for lock control (see above), and so normally use
+   * builtin monitors only for blocking and signalling using
+   * wait/notifyAll constructions. See Node.tryAwaitLock.
    *
    * Using the first node of a list as a lock does not by itself
    * suffice though: When a node is locked, any update must first
@@ -216,30 +203,53 @@ public static interface RemappingFunction<K, V> {
    * The main disadvantage of per-bin locks is that other update
    * operations on other nodes in a bin list protected by the same
    * lock can stall, for example when user equals() or mapping
-   * functions take a long time.  However, statistically, this is
-   * not a common enough problem to outweigh the time/space overhead
-   * of alternatives: Under random hash codes, the frequency of
-   * nodes in bins follows a Poisson distribution
+   * functions take a long time.  However, statistically, under
+   * random hash codes, this is not a common problem.  Ideally, the
+   * frequency of nodes in bins follows a Poisson distribution
    * (http://en.wikipedia.org/wiki/Poisson_distribution) with a
    * parameter of about 0.5 on average, given the resizing threshold
    * of 0.75, although with a large variance because of resizing
    * granularity. Ignoring variance, the expected occurrences of
    * list size k are (exp(-0.5) * pow(0.5, k) / factorial(k)). The
-   * first few values are:
+   * first values are:
    *
-   * 0:    0.607
-   * 1:    0.303
-   * 2:    0.076
-   * 3:    0.012
-   * more: 0.002
+   * 0:    0.60653066
+   * 1:    0.30326533
+   * 2:    0.07581633
+   * 3:    0.01263606
+   * 4:    0.00157952
+   * 5:    0.00015795
+   * 6:    0.00001316
+   * 7:    0.00000094
+   * 8:    0.00000006
+   * more: less than 1 in ten million
    *
    * Lock contention probability for two threads accessing distinct
-   * elements is roughly 1 / (8 * #elements).  Function ""spread""
-   * performs hashCode randomization that improves the likelihood
-   * that these assumptions hold unless users define exactly the
-   * same value for too many hashCodes.
+   * elements is roughly 1 / (8 * #elements) under random hashes.
+   *
+   * Actual hash code distributions encountered in practice
+   * sometimes deviate significantly from uniform randomness.  This
+   * includes the case when N > (1<<30), so some keys MUST collide.
+   * Similarly for dumb or hostile usages in which multiple keys are
+   * designed to have identical hash codes. Also, although we guard
+   * against the worst effects of this (see method spread), sets of
+   * hashes may differ only in bits that do not impact their bin
+   * index for a given power-of-two mask.  So we use a secondary
+   * strategy that applies when the number of nodes in a bin exceeds
+   * a threshold, and at least one of the keys implements
+   * Comparable.  These TreeBins use a balanced tree to hold nodes
+   * (a specialized form of red-black trees), bounding search time
+   * to O(log N).  Each search step in a TreeBin is around twice as
+   * slow as in a regular list, but given that N cannot exceed
+   * (1<<64) (before running out of addresses) this bounds search
+   * steps, lock hold times, etc, to reasonable constants (roughly
+   * 100 nodes inspected per operation worst case) so long as keys
+   * are Comparable (which is very common -- String, Long, etc).
+   * TreeBin nodes (TreeNodes) also maintain the same ""next""
+   * traversal pointers as regular nodes, so can be traversed in
+   * iterators in the same way.
    *
-   * The table is resized when occupancy exceeds an occupancy
+   * The table is resized when occupancy exceeds a percentage
    * threshold (nominally, 0.75, but see below).  Only a single
    * thread performs the resize (using field ""sizeCtl"", to arrange
    * exclusion), but the table otherwise remains usable for reads
@@ -260,22 +270,22 @@ public static interface RemappingFunction<K, V> {
    *
    * Each bin transfer requires its bin lock. However, unlike other
    * cases, a transfer can skip a bin if it fails to acquire its
-   * lock, and revisit it later. Method rebuild maintains a buffer
-   * of TRANSFER_BUFFER_SIZE bins that have been skipped because of
-   * failure to acquire a lock, and blocks only if none are
-   * available (i.e., only very rarely).  The transfer operation
-   * must also ensure that all accessible bins in both the old and
-   * new table are usable by any traversal.  When there are no lock
-   * acquisition failures, this is arranged simply by proceeding
-   * from the last bin (table.length - 1) up towards the first.
-   * Upon seeing a forwarding node, traversals (see class
-   * InternalIterator) arrange to move to the new table without
-   * revisiting nodes.  However, when any node is skipped during a
-   * transfer, all earlier table bins may have become visible, so
-   * are initialized with a reverse-forwarding node back to the old
-   * table until the new ones are established. (This sometimes
-   * requires transiently locking a forwarding node, which is
-   * possible under the above encoding.) These more expensive
+   * lock, and revisit it later (unless it is a TreeBin). Method
+   * rebuild maintains a buffer of TRANSFER_BUFFER_SIZE bins that
+   * have been skipped because of failure to acquire a lock, and
+   * blocks only if none are available (i.e., only very rarely).
+   * The transfer operation must also ensure that all accessible
+   * bins in both the old and new table are usable by any traversal.
+   * When there are no lock acquisition failures, this is arranged
+   * simply by proceeding from the last bin (table.length - 1) up
+   * towards the first.  Upon seeing a forwarding node, traversals
+   * (see class InternalIterator) arrange to move to the new table
+   * without revisiting nodes.  However, when any node is skipped
+   * during a transfer, all earlier table bins may have become
+   * visible, so are initialized with a reverse-forwarding node back
+   * to the old table until the new ones are established. (This
+   * sometimes requires transiently locking a forwarding node, which
+   * is possible under the above encoding.) These more expensive
    * mechanics trigger only when necessary.
    *
    * The traversal scheme also applies to partial traversals of
@@ -362,6 +372,13 @@ public static interface RemappingFunction<K, V> {
     */
    private static final int TRANSFER_BUFFER_SIZE = 32;
 
+   /**
+    * The bin count threshold for using a tree rather than list for a
+    * bin.  The value reflects the approximate break-even point for
+    * using tree-based operations.
+    */
+   private static final int TREE_THRESHOLD = 8;
+
    /*
    * Encodings for special uses of Node hash fields. See above for
    * explanation.
@@ -401,6 +418,32 @@ public static interface RemappingFunction<K, V> {
    /** For serialization compatibility. Null unless serialized; see below */
    private Segment<K,V>[] segments;
 
+   /* ---------------- Table element access -------------- */
+
+   /*
+   * Volatile access methods are used for table elements as well as
+   * elements of in-progress next table while resizing.  Uses are
+   * null checked by callers, and implicitly bounds-checked, relying
+   * on the invariants that tab arrays have non-zero size, and all
+   * indices are masked with (tab.length - 1) which is never
+   * negative and always less than length. Note that, to be correct
+   * wrt arbitrary concurrency errors by users, bounds checks must
+   * operate on local variables, which accounts for some odd-looking
+   * inline assignments below.
+   */
+
+   static final Node tabAt(Node[] tab, int i) { // used by InternalIterator
+      return (Node)UNSAFE.getObjectVolatile(tab, ((long)i<<ASHIFT)+ABASE);
+   }
+
+   private static final boolean casTabAt(Node[] tab, int i, Node c, Node v) {
+      return UNSAFE.compareAndSwapObject(tab, ((long)i<<ASHIFT)+ABASE, c, v);
+   }
+
+   private static final void setTabAt(Node[] tab, int i, Node v) {
+      UNSAFE.putObjectVolatile(tab, ((long)i<<ASHIFT)+ABASE, v);
+   }
+
    /* ---------------- Nodes -------------- */
 
    /**
@@ -413,7 +456,7 @@ public static interface RemappingFunction<K, V> {
     * access, a key may be read before a val, but can only be used
     * after checking val to be non-null.
     */
-   static final class Node {
+   static class Node {
       volatile int hash;
       final Object key;
       volatile Object val;
@@ -450,11 +493,13 @@ final boolean casHash(int cmp, int val) {
        */
       final void tryAwaitLock(Node[] tab, int i) {
          if (tab != null && i >= 0 && i < tab.length) { // bounds check
+            int r = ThreadLocalRandom.current().nextInt(); // randomize spins
             int spins = MAX_SPINS, h;
             while (tabAt(tab, i) == this && ((h = hash) & LOCKED) != 0) {
                if (spins >= 0) {
-                  if (--spins == MAX_SPINS >>> 1)
-                     Thread.yield();  // heuristically yield mid-way
+                  r ^= r << 1; r ^= r >>> 3; r ^= r << 10; // xorshift
+                  if (r >= 0 && --spins == 0)
+                     Thread.yield();  // yield before block
                }
                else if (casHash(h, h | WAITING)) {
                   synchronized (this) {
@@ -491,64 +536,532 @@ else if (casHash(h, h | WAITING)) {
       }
    }
 
-   /* ---------------- Table element access -------------- */
+   /* ---------------- TreeBins -------------- */
 
-   /*
-   * Volatile access methods are used for table elements as well as
-   * elements of in-progress next table while resizing.  Uses are
-   * null checked by callers, and implicitly bounds-checked, relying
-   * on the invariants that tab arrays have non-zero size, and all
-   * indices are masked with (tab.length - 1) which is never
-   * negative and always less than length. Note that, to be correct
-   * wrt arbitrary concurrency errors by users, bounds checks must
-   * operate on local variables, which accounts for some odd-looking
-   * inline assignments below.
-   */
+   /**
+    * Nodes for use in TreeBins
+    */
+   static final class TreeNode extends Node {
+      TreeNode parent;  // red-black tree links
+      TreeNode left;
+      TreeNode right;
+      TreeNode prev;    // needed to unlink next upon deletion
+      boolean red;
 
-   static final Node tabAt(Node[] tab, int i) { // used by InternalIterator
-      return (Node)UNSAFE.getObjectVolatile(tab, ((long)i<<ASHIFT)+ABASE);
+      TreeNode(int hash, Object key, Object val, Node next, TreeNode parent) {
+         super(hash, key, val, next);
+         this.parent = parent;
+      }
    }
 
-   private static final boolean casTabAt(Node[] tab, int i, Node c, Node v) {
-      return UNSAFE.compareAndSwapObject(tab, ((long)i<<ASHIFT)+ABASE, c, v);
-   }
+   /**
+    * A specialized form of red-black tree for use in bins
+    * whose size exceeds a threshold.
+    *
+    * TreeBins use a special form of comparison for search and
+    * related operations (which is the main reason we cannot use
+    * existing collections such as TreeMaps). TreeBins contain
+    * Comparable elements, but may contain others, as well as
+    * elements that are Comparable but not necessarily Comparable<T>
+    * for the same T, so we cannot invoke compareTo among them. To
+    * handle this, the tree is ordered primarily by hash value, then
+    * by getClass().getName() order, and then by Comparator order
+    * among elements of the same class.  On lookup at a node, if
+    * non-Comparable, both left and right children may need to be
+    * searched in the case of tied hash values. (This corresponds to
+    * the full list search that would be necessary if all elements
+    * were non-Comparable and had tied hashes.)
+    *
+    * TreeBins also maintain a separate locking discipline than
+    * regular bins. Because they are forwarded via special MOVED
+    * nodes at bin heads (which can never change once established),
+    * we cannot use use those nodes as locks. Instead, TreeBin
+    * extends AbstractQueuedSynchronizer to support a simple form of
+    * read-write lock. For update operations and table validation,
+    * the exclusive form of lock behaves in the same way as bin-head
+    * locks. However, lookups use shared read-lock mechanics to allow
+    * multiple readers in the absence of writers.  Additionally,
+    * these lookups do not ever block: While the lock is not
+    * available, they proceed along the slow traversal path (via
+    * next-pointers) until the lock becomes available or the list is
+    * exhausted, whichever comes first. (These cases are not fast,
+    * but maximize aggregate expected throughput.)  The AQS mechanics
+    * for doing this are straightforward.  The lock state is held as
+    * AQS getState().  Read counts are negative; the write count (1)
+    * is positive.  There are no signalling preferences among readers
+    * and writers. Since we don't need to export full Lock API, we
+    * just override the minimal AQS methods and use them directly.
+    */
+   static final class TreeBin extends AbstractQueuedSynchronizer {
+      private static final long serialVersionUID = 2249069246763182397L;
+      TreeNode root;  // root of tree
+      TreeNode first; // head of next-pointer list
+
+      /* AQS overrides */
+      public final boolean isHeldExclusively() { return getState() > 0; }
+      public final boolean tryAcquire(int ignore) {
+         if (compareAndSetState(0, 1)) {
+            setExclusiveOwnerThread(Thread.currentThread());
+            return true;
+         }
+         return false;
+      }
+      public final boolean tryRelease(int ignore) {
+         setExclusiveOwnerThread(null);
+         setState(0);
+         return true;
+      }
+      public final int tryAcquireShared(int ignore) {
+         for (int c;;) {
+            if ((c = getState()) > 0)
+               return -1;
+            if (compareAndSetState(c, c -1))
+               return 1;
+         }
+      }
+      public final boolean tryReleaseShared(int ignore) {
+         int c;
+         do {} while (!compareAndSetState(c = getState(), c + 1));
+         return c == -1;
+      }
 
-   private static final void setTabAt(Node[] tab, int i, Node v) {
-      UNSAFE.putObjectVolatile(tab, ((long)i<<ASHIFT)+ABASE, v);
+      /**
+       * Return the TreeNode (or null if not found) for the given key
+       * starting at given root.
+       */
+      @SuppressWarnings(""unchecked"") // suppress Comparable cast warning
+      final TreeNode getTreeNode(int h, Object k, TreeNode p) {
+         Class<?> c = k.getClass();
+         while (p != null) {
+            int dir, ph;  Object pk; Class<?> pc; TreeNode r;
+            if (h < (ph = p.hash))
+               dir = -1;
+            else if (h > ph)
+               dir = 1;
+            else if ((pk = p.key) == k || k.equals(pk))
+               return p;
+            else if (c != (pc = pk.getClass()))
+               dir = c.getName().compareTo(pc.getName());
+            else if (k instanceof Comparable)
+               dir = ((Comparable)k).compareTo((Comparable)pk);
+            else
+               dir = 0;
+            TreeNode pr = p.right;
+            if (dir > 0)
+               p = pr;
+            else if (dir == 0 && pr != null && h >= pr.hash &&
+                  (r = getTreeNode(h, k, pr)) != null)
+               return r;
+            else
+               p = p.left;
+         }
+         return null;
+      }
+
+      /**
+       * Wrapper for getTreeNode used by CHM.get. Tries to obtain
+       * read-lock to call getTreeNode, but during failure to get
+       * lock, searches along next links.
+       */
+      final Object getValue(int h, Object k) {
+         Node r = null;
+         int c = getState(); // Must read lock state first
+         for (Node e = first; e != null; e = e.next) {
+            if (c <= 0 && compareAndSetState(c, c - 1)) {
+               try {
+                  r = getTreeNode(h, k, root);
+               } finally {
+                  releaseShared(0);
+               }
+               break;
+            }
+            else if ((e.hash & HASH_BITS) == h && k.equals(e.key)) {
+               r = e;
+               break;
+            }
+            else
+               c = getState();
+         }
+         return r == null ? null : r.val;
+      }
+
+      /**
+       * Find or add a node
+       * @return null if added
+       */
+      @SuppressWarnings(""unchecked"") // suppress Comparable cast warning
+      final TreeNode putTreeNode(int h, Object k, Object v) {
+         Class<?> c = k.getClass();
+         TreeNode p = root;
+         int dir = 0;
+         if (p != null) {
+            for (;;) {
+               int ph;  Object pk; Class<?> pc; TreeNode r;
+               if (h < (ph = p.hash))
+                  dir = -1;
+               else if (h > ph)
+                  dir = 1;
+               else if ((pk = p.key) == k || k.equals(pk))
+                  return p;
+               else if (c != (pc = (pk = p.key).getClass()))
+                  dir = c.getName().compareTo(pc.getName());
+               else if (k instanceof Comparable)
+                  dir = ((Comparable)k).compareTo((Comparable)pk);
+               else
+                  dir = 0;
+               TreeNode pr = p.right, pl;
+               if (dir > 0) {
+                  if (pr == null)
+                     break;
+                  p = pr;
+               }
+               else if (dir == 0 && pr != null && h >= pr.hash &&
+                     (r = getTreeNode(h, k, pr)) != null)
+                  return r;
+               else if ((pl = p.left) == null)
+                  break;
+               else
+                  p = pl;
+            }
+         }
+         TreeNode f = first;
+         TreeNode r = first = new TreeNode(h, k, v, f, p);
+         if (p == null)
+            root = r;
+         else {
+            if (dir <= 0)
+               p.left = r;
+            else
+               p.right = r;
+            if (f != null)
+               f.prev = r;
+            fixAfterInsertion(r);
+         }
+         return null;
+      }
+
+      /**
+       * Removes the given node, that must be present before this
+       * call.  This is messier than typical red-black deletion code
+       * because we cannot swap the contents of an interior node
+       * with a leaf successor that is pinned by ""next"" pointers
+       * that are accessible independently of lock. So instead we
+       * swap the tree linkages.
+       */
+      final void deleteTreeNode(TreeNode p) {
+         TreeNode next = (TreeNode)p.next; // unlink traversal pointers
+         TreeNode pred = p.prev;
+         if (pred == null)
+            first = next;
+         else
+            pred.next = next;
+         if (next != null)
+            next.prev = pred;
+         TreeNode replacement;
+         TreeNode pl = p.left;
+         TreeNode pr = p.right;
+         if (pl != null && pr != null) {
+            TreeNode s = pr;
+            while (s.left != null) // find successor
+               s = s.left;
+            boolean c = s.red; s.red = p.red; p.red = c; // swap colors
+            TreeNode sr = s.right;
+            TreeNode pp = p.parent;
+            if (s == pr) { // p was s's direct parent
+               p.parent = s;
+               s.right = p;
+            }
+            else {
+               TreeNode sp = s.parent;
+               if ((p.parent = sp) != null) {
+                  if (s == sp.left)
+                     sp.left = p;
+                  else
+                     sp.right = p;
+               }
+               if ((s.right = pr) != null)
+                  pr.parent = s;
+            }
+            p.left = null;
+            if ((p.right = sr) != null)
+               sr.parent = p;
+            if ((s.left = pl) != null)
+               pl.parent = s;
+            if ((s.parent = pp) == null)
+               root = s;
+            else if (p == pp.left)
+               pp.left = s;
+            else
+               pp.right = s;
+            replacement = sr;
+         }
+         else
+            replacement = (pl != null) ? pl : pr;
+         TreeNode pp = p.parent;
+         if (replacement == null) {
+            if (pp == null) {
+               root = null;
+               return;
+            }
+            replacement = p;
+         }
+         else {
+            replacement.parent = pp;
+            if (pp == null)
+               root = replacement;
+            else if (p == pp.left)
+               pp.left = replacement;
+            else
+               pp.right = replacement;
+            p.left = p.right = p.parent = null;
+         }
+         if (!p.red)
+            fixAfterDeletion(replacement);
+         if (p == replacement && (pp = p.parent) != null) {
+            if (p == pp.left) // detach pointers
+               pp.left = null;
+            else if (p == pp.right)
+               pp.right = null;
+            p.parent = null;
+         }
+      }
+
+      // CLR code updated from pre-jdk-collections version at
+      // http://gee.cs.oswego.edu/dl/classes/collections/RBCell.java
+
+      /** From CLR */
+      private void rotateLeft(TreeNode p) {
+         if (p != null) {
+            TreeNode r = p.right, pp, rl;
+            if ((rl = p.right = r.left) != null)
+               rl.parent = p;
+            if ((pp = r.parent = p.parent) == null)
+               root = r;
+            else if (pp.left == p)
+               pp.left = r;
+            else
+               pp.right = r;
+            r.left = p;
+            p.parent = r;
+         }
+      }
+
+      /** From CLR */
+      private void rotateRight(TreeNode p) {
+         if (p != null) {
+            TreeNode l = p.left, pp, lr;
+            if ((lr = p.left = l.right) != null)
+               lr.parent = p;
+            if ((pp = l.parent = p.parent) == null)
+               root = l;
+            else if (pp.right == p)
+               pp.right = l;
+            else
+               pp.left = l;
+            l.right = p;
+            p.parent = l;
+         }
+      }
+
+      /** From CLR */
+      private void fixAfterInsertion(TreeNode x) {
+         x.red = true;
+         TreeNode xp, xpp;
+         while (x != null && (xp = x.parent) != null && xp.red &&
+               (xpp = xp.parent) != null) {
+            TreeNode xppl = xpp.left;
+            if (xp == xppl) {
+               TreeNode y = xpp.right;
+               if (y != null && y.red) {
+                  y.red = false;
+                  xp.red = false;
+                  xpp.red = true;
+                  x = xpp;
+               }
+               else {
+                  if (x == xp.right) {
+                     x = xp;
+                     rotateLeft(x);
+                     xpp = (xp = x.parent) == null ? null : xp.parent;
+                  }
+                  if (xp != null) {
+                     xp.red = false;
+                     if (xpp != null) {
+                        xpp.red = true;
+                        rotateRight(xpp);
+                     }
+                  }
+               }
+            }
+            else {
+               TreeNode y = xppl;
+               if (y != null && y.red) {
+                  y.red = false;
+                  xp.red = false;
+                  xpp.red = true;
+                  x = xpp;
+               }
+               else {
+                  if (x == xp.left) {
+                     x = xp;
+                     rotateRight(x);
+                     xpp = (xp = x.parent) == null ? null : xp.parent;
+                  }
+                  if (xp != null) {
+                     xp.red = false;
+                     if (xpp != null) {
+                        xpp.red = true;
+                        rotateLeft(xpp);
+                     }
+                  }
+               }
+            }
+         }
+         TreeNode r = root;
+         if (r != null && r.red)
+            r.red = false;
+      }
+
+      /** From CLR */
+      private void fixAfterDeletion(TreeNode x) {
+         while (x != null) {
+            TreeNode xp, xpl;
+            if (x.red || (xp = x.parent) == null) {
+               x.red = false;
+               break;
+            }
+            if (x == (xpl = xp.left)) {
+               TreeNode sib = xp.right;
+               if (sib != null && sib.red) {
+                  sib.red = false;
+                  xp.red = true;
+                  rotateLeft(xp);
+                  sib = (xp = x.parent) == null ? null : xp.right;
+               }
+               if (sib == null)
+                  x = xp;
+               else {
+                  TreeNode sl = sib.left, sr = sib.right;
+                  if ((sr == null || !sr.red) &&
+                        (sl == null || !sl.red)) {
+                     sib.red = true;
+                     x = xp;
+                  }
+                  else {
+                     if (sr == null || !sr.red) {
+                        if (sl != null)
+                           sl.red = false;
+                        sib.red = true;
+                        rotateRight(sib);
+                        sib = (xp = x.parent) == null ? null : xp.right;
+                     }
+                     if (sib != null) {
+                        sib.red = (xp == null)? false : xp.red;
+                        if ((sr = sib.right) != null)
+                           sr.red = false;
+                     }
+                     if (xp != null) {
+                        xp.red = false;
+                        rotateLeft(xp);
+                     }
+                     x = root;
+                  }
+               }
+            }
+            else { // symmetric
+               TreeNode sib = xpl;
+               if (sib != null && sib.red) {
+                  sib.red = false;
+                  xp.red = true;
+                  rotateRight(xp);
+                  sib = (xp = x.parent) == null ? null : xp.left;
+               }
+               if (sib == null)
+                  x = xp;
+               else {
+                  TreeNode sl = sib.left, sr = sib.right;
+                  if ((sl == null || !sl.red) &&
+                        (sr == null || !sr.red)) {
+                     sib.red = true;
+                     x = xp;
+                  }
+                  else {
+                     if (sl == null || !sl.red) {
+                        if (sr != null)
+                           sr.red = false;
+                        sib.red = true;
+                        rotateLeft(sib);
+                        sib = (xp = x.parent) == null ? null : xp.left;
+                     }
+                     if (sib != null) {
+                        sib.red = (xp == null)? false : xp.red;
+                        if ((sl = sib.left) != null)
+                           sl.red = false;
+                     }
+                     if (xp != null) {
+                        xp.red = false;
+                        rotateRight(xp);
+                     }
+                     x = root;
+                  }
+               }
+            }
+         }
+      }
    }
 
-   /* ---------------- Internal access and update methods -------------- */
+   /* ---------------- Collision reduction methods -------------- */
 
    /**
-    * Applies a supplemental hash function to a given hashCode, which
-    * defends against poor quality hash functions.  The result must
-    * be have the top 2 bits clear. For reasonable performance, this
-    * function must have good avalanche properties; i.e., that each
-    * bit of the argument affects each bit of the result. (Although
-    * we don't care about the unused top 2 bits.)
+    * Spreads higher bits to lower, and also forces top 2 bits to 0.
+    * Because the table uses power-of-two masking, sets of hashes
+    * that vary only in bits above the current mask will always
+    * collide. (Among known examples are sets of Float keys holding
+    * consecutive whole numbers in small tables.)  To counter this,
+    * we apply a transform that spreads the impact of higher bits
+    * downward. There is a tradeoff between speed, utility, and
+    * quality of bit-spreading. Because many common sets of hashes
+    * are already reaonably distributed across bits (so don't benefit
+    * from spreading), and because we use trees to handle large sets
+    * of collisions in bins, we don't need excessively high quality.
     */
    private static final int spread(int h) {
-      // Apply base step of MurmurHash; see http://code.google.com/p/smhasher/
-      // Despite two multiplies, this is often faster than others
-      // with comparable bit-spread properties.
-      h ^= h >>> 16;
-      h *= 0x85ebca6b;
-      h ^= h >>> 13;
-      h *= 0xc2b2ae35;
-      return ((h >>> 16) ^ h) & HASH_BITS; // mask out top bits
+      h ^= (h >>> 18) ^ (h >>> 12);
+      return (h ^ (h >>> 10)) & HASH_BITS;
+   }
+
+   /**
+    * Replaces a list bin with a tree bin. Call only when locked.
+    * Fails to replace if the given key is non-comparable or table
+    * is, or needs, resizing.
+    */
+   private final void replaceWithTreeBin(Node[] tab, int index, Object key) {
+      if ((key instanceof Comparable) &&
+            (tab.length >= MAXIMUM_CAPACITY || counter.sum() < (long)sizeCtl)) {
+         TreeBin t = new TreeBin();
+         for (Node e = tabAt(tab, index); e != null; e = e.next)
+            t.putTreeNode(e.hash & HASH_BITS, e.key, e.val);
+         setTabAt(tab, index, new Node(MOVED, t, null, null));
+      }
    }
 
+   /* ---------------- Internal access and update methods -------------- */
+
    /** Implementation for get and containsKey */
    private final Object internalGet(Object k) {
       int h = spread(k.hashCode());
       retry: for (Node[] tab = table; tab != null;) {
-         Node e; Object ek, ev; int eh;    // locals to read fields once
+         Node e, p; Object ek, ev; int eh;      // locals to read fields once
          for (e = tabAt(tab, (tab.length - 1) & h); e != null; e = e.next) {
             if ((eh = e.hash) == MOVED) {
-               tab = (Node[])e.key;      // restart with new table
-               continue retry;
+               if ((ek = e.key) instanceof TreeBin)  // search TreeBin
+                  return ((TreeBin)ek).getValue(h, k);
+               else {                        // restart with new table
+                  tab = (Node[])ek;
+                  continue retry;
+               }
             }
-            if ((eh & HASH_BITS) == h && (ev = e.val) != null &&
+            else if ((eh & HASH_BITS) == h && (ev = e.val) != null &&
                   ((ek = e.key) == k || k.equals(ek)))
                return ev;
          }
@@ -566,12 +1079,43 @@ private final Object internalReplace(Object k, Object v, Object cv) {
       int h = spread(k.hashCode());
       Object oldVal = null;
       for (Node[] tab = table;;) {
-         Node f; int i, fh;
+         Node f; int i, fh; Object fk;
          if (tab == null ||
                (f = tabAt(tab, i = (tab.length - 1) & h)) == null)
             break;
-         else if ((fh = f.hash) == MOVED)
-            tab = (Node[])f.key;
+         else if ((fh = f.hash) == MOVED) {
+            if ((fk = f.key) instanceof TreeBin) {
+               TreeBin t = (TreeBin)fk;
+               boolean validated = false;
+               boolean deleted = false;
+               t.acquire(0);
+               try {
+                  if (tabAt(tab, i) == f) {
+                     validated = true;
+                     TreeNode p = t.getTreeNode(h, k, t.root);
+                     if (p != null) {
+                        Object pv = p.val;
+                        if (cv == null || cv == pv || cv.equals(pv)) {
+                           oldVal = pv;
+                           if ((p.val = v) == null) {
+                              deleted = true;
+                              t.deleteTreeNode(p);
+                           }
+                        }
+                     }
+                  }
+               } finally {
+                  t.release(0);
+               }
+               if (validated) {
+                  if (deleted)
+                     counter.add(-1L);
+                  break;
+               }
+            }
+            else
+               tab = (Node[])fk;
+         }
          else if ((fh & HASH_BITS) != h && f.next == null) // precheck
             break;                          // rules out possible existence
          else if ((fh & LOCKED) != 0) {
@@ -630,7 +1174,8 @@ else if (f.casHash(fh, fh | LOCKED)) {
    *  1. If table uninitialized, create
    *  2. If bin empty, try to CAS new node
    *  3. If bin stale, use new table
-   *  4. Lock and validate; if valid, scan and add or update
+   *  4. if bin converted to TreeBin, validate and relay to TreeBin methods
+   *  5. Lock and validate; if valid, scan and add or update
    *
    * The others interweave other checks and/or alternative actions:
    *  * Plain put checks for and performs resize after insertion.
@@ -651,28 +1196,51 @@ else if (f.casHash(fh, fh | LOCKED)) {
    /** Implementation for put */
    private final Object internalPut(Object k, Object v) {
       int h = spread(k.hashCode());
-      boolean checkSize = false;
+      int count = 0;
       for (Node[] tab = table;;) {
-         int i; Node f; int fh;
+         int i; Node f; int fh; Object fk;
          if (tab == null)
             tab = initTable();
          else if ((f = tabAt(tab, i = (tab.length - 1) & h)) == null) {
             if (casTabAt(tab, i, null, new Node(h, k, v, null)))
                break;                   // no lock when adding to empty bin
          }
-         else if ((fh = f.hash) == MOVED)
-            tab = (Node[])f.key;
+         else if ((fh = f.hash) == MOVED) {
+            if ((fk = f.key) instanceof TreeBin) {
+               TreeBin t = (TreeBin)fk;
+               Object oldVal = null;
+               t.acquire(0);
+               try {
+                  if (tabAt(tab, i) == f) {
+                     count = 2;
+                     TreeNode p = t.putTreeNode(h, k, v);
+                     if (p != null) {
+                        oldVal = p.val;
+                        p.val = v;
+                     }
+                  }
+               } finally {
+                  t.release(0);
+               }
+               if (count != 0) {
+                  if (oldVal != null)
+                     return oldVal;
+                  break;
+               }
+            }
+            else
+               tab = (Node[])fk;
+         }
          else if ((fh & LOCKED) != 0) {
             checkForResize();
             f.tryAwaitLock(tab, i);
          }
          else if (f.casHash(fh, fh | LOCKED)) {
             Object oldVal = null;
-            boolean validated = false;
             try {                        // needed in case equals() throws
                if (tabAt(tab, i) == f) {
-                  validated = true;    // retry if 1st already deleted
-                  for (Node e = f;;) {
+                  count = 1;
+                  for (Node e = f;; ++count) {
                      Object ek, ev;
                      if ((e.hash & HASH_BITS) == h &&
                            (ev = e.val) != null &&
@@ -684,8 +1252,8 @@ else if (f.casHash(fh, fh | LOCKED)) {
                      Node last = e;
                      if ((e = e.next) == null) {
                         last.next = new Node(h, k, v, null);
-                        if (last != f || tab.length <= 64)
-                           checkSize = true;
+                        if (count >= TREE_THRESHOLD)
+                           replaceWithTreeBin(tab, i, k);
                         break;
                      }
                   }
@@ -696,22 +1264,25 @@ else if (f.casHash(fh, fh | LOCKED)) {
                   synchronized (f) { f.notifyAll(); };
                }
             }
-            if (validated) {
+            if (count != 0) {
                if (oldVal != null)
                   return oldVal;
+               if (tab.length <= 64)
+                  count = 2;
                break;
             }
          }
       }
       counter.add(1L);
-      if (checkSize)
+      if (count > 1)
          checkForResize();
       return null;
    }
 
    /** Implementation for putIfAbsent */
    private final Object internalPutIfAbsent(Object k, Object v) {
       int h = spread(k.hashCode());
+      int count = 0;
       for (Node[] tab = table;;) {
          int i; Node f; int fh; Object fk, fv;
          if (tab == null)
@@ -720,8 +1291,30 @@ else if ((f = tabAt(tab, i = (tab.length - 1) & h)) == null) {
             if (casTabAt(tab, i, null, new Node(h, k, v, null)))
                break;
          }
-         else if ((fh = f.hash) == MOVED)
-            tab = (Node[])f.key;
+         else if ((fh = f.hash) == MOVED) {
+            if ((fk = f.key) instanceof TreeBin) {
+               TreeBin t = (TreeBin)fk;
+               Object oldVal = null;
+               t.acquire(0);
+               try {
+                  if (tabAt(tab, i) == f) {
+                     count = 2;
+                     TreeNode p = t.putTreeNode(h, k, v);
+                     if (p != null)
+                        oldVal = p.val;
+                  }
+               } finally {
+                  t.release(0);
+               }
+               if (count != 0) {
+                  if (oldVal != null)
+                     return oldVal;
+                  break;
+               }
+            }
+            else
+               tab = (Node[])fk;
+         }
          else if ((fh & HASH_BITS) == h && (fv = f.val) != null &&
                ((fk = f.key) == k || k.equals(fk)))
             return fv;
@@ -745,11 +1338,10 @@ else if ((fh & HASH_BITS) == h && (fv = f.val) != null &&
             }
             else if (tabAt(tab, i) == f && f.casHash(fh, fh | LOCKED)) {
                Object oldVal = null;
-               boolean validated = false;
                try {
                   if (tabAt(tab, i) == f) {
-                     validated = true;
-                     for (Node e = f;;) {
+                     count = 1;
+                     for (Node e = f;; ++count) {
                         Object ek, ev;
                         if ((e.hash & HASH_BITS) == h &&
                               (ev = e.val) != null &&
@@ -760,6 +1352,8 @@ else if (tabAt(tab, i) == f && f.casHash(fh, fh | LOCKED)) {
                         Node last = e;
                         if ((e = e.next) == null) {
                            last.next = new Node(h, k, v, null);
+                           if (count >= TREE_THRESHOLD)
+                              replaceWithTreeBin(tab, i, k);
                            break;
                         }
                      }
@@ -770,32 +1364,36 @@ else if (tabAt(tab, i) == f && f.casHash(fh, fh | LOCKED)) {
                      synchronized (f) { f.notifyAll(); };
                   }
                }
-               if (validated) {
+               if (count != 0) {
                   if (oldVal != null)
                      return oldVal;
+                  if (tab.length <= 64)
+                     count = 2;
                   break;
                }
             }
          }
       }
       counter.add(1L);
+      if (count > 1)
+         checkForResize();
       return null;
    }
 
    /** Implementation for computeIfAbsent */
    private final Object internalComputeIfAbsent(K k,
-                                                MappingFunction<? super K, ?> mf) {
+         MappingFunction<? super K, ?> mf) {
       int h = spread(k.hashCode());
       Object val = null;
+      int count = 0;
       for (Node[] tab = table;;) {
          Node f; int i, fh; Object fk, fv;
          if (tab == null)
             tab = initTable();
          else if ((f = tabAt(tab, i = (tab.length - 1) & h)) == null) {
             Node node = new Node(fh = h | LOCKED, k, null, null);
-            boolean validated = false;
             if (casTabAt(tab, i, null, node)) {
-               validated = true;
+               count = 1;
                try {
                   if ((val = mf.map(k)) != null)
                      node.val = val;
@@ -808,11 +1406,38 @@ else if ((f = tabAt(tab, i = (tab.length - 1) & h)) == null) {
                   }
                }
             }
-            if (validated)
+            if (count != 0)
                break;
          }
-         else if ((fh = f.hash) == MOVED)
-            tab = (Node[])f.key;
+         else if ((fh = f.hash) == MOVED) {
+            if ((fk = f.key) instanceof TreeBin) {
+               TreeBin t = (TreeBin)fk;
+               boolean added = false;
+               t.acquire(0);
+               try {
+                  if (tabAt(tab, i) == f) {
+                     count = 1;
+                     TreeNode p = t.getTreeNode(h, k, t.root);
+                     if (p != null)
+                        val = p.val;
+                     else if ((val = mf.map(k)) != null) {
+                        added = true;
+                        count = 2;
+                        t.putTreeNode(h, k, val);
+                     }
+                  }
+               } finally {
+                  t.release(0);
+               }
+               if (count != 0) {
+                  if (!added)
+                     return val;
+                  break;
+               }
+            }
+            else
+               tab = (Node[])fk;
+         }
          else if ((fh & HASH_BITS) == h && (fv = f.val) != null &&
                ((fk = f.key) == k || k.equals(fk)))
             return fv;
@@ -835,11 +1460,11 @@ else if ((fh & HASH_BITS) == h && (fv = f.val) != null &&
                f.tryAwaitLock(tab, i);
             }
             else if (tabAt(tab, i) == f && f.casHash(fh, fh | LOCKED)) {
-               boolean validated = false;
+               boolean added = false;
                try {
                   if (tabAt(tab, i) == f) {
-                     validated = true;
-                     for (Node e = f;;) {
+                     count = 1;
+                     for (Node e = f;; ++count) {
                         Object ek, ev;
                         if ((e.hash & HASH_BITS) == h &&
                               (ev = e.val) != null &&
@@ -849,8 +1474,12 @@ else if (tabAt(tab, i) == f && f.casHash(fh, fh | LOCKED)) {
                         }
                         Node last = e;
                         if ((e = e.next) == null) {
-                           if ((val = mf.map(k)) != null)
+                           if ((val = mf.map(k)) != null) {
+                              added = true;
                               last.next = new Node(h, k, val, null);
+                              if (count >= TREE_THRESHOLD)
+                                 replaceWithTreeBin(tab, i, k);
+                           }
                            break;
                         }
                      }
@@ -861,35 +1490,41 @@ else if (tabAt(tab, i) == f && f.casHash(fh, fh | LOCKED)) {
                      synchronized (f) { f.notifyAll(); };
                   }
                }
-               if (validated)
+               if (count != 0) {
+                  if (!added)
+                     return val;
+                  if (tab.length <= 64)
+                     count = 2;
                   break;
+               }
             }
          }
       }
       if (val == null)
          throw new NullPointerException();
       counter.add(1L);
+      if (count > 1)
+         checkForResize();
       return val;
    }
 
    /** Implementation for compute */
    @SuppressWarnings(""unchecked"")
    private final Object internalCompute(K k,
-                                        RemappingFunction<? super K, V> mf) {
+         RemappingFunction<? super K, V> mf) {
       int h = spread(k.hashCode());
       Object val = null;
       boolean added = false;
-      boolean checkSize = false;
+      int count = 0;
       for (Node[] tab = table;;) {
-         Node f; int i, fh;
+         Node f; int i, fh; Object fk;
          if (tab == null)
             tab = initTable();
          else if ((f = tabAt(tab, i = (tab.length - 1) & h)) == null) {
             Node node = new Node(fh = h | LOCKED, k, null, null);
-            boolean validated = false;
             if (casTabAt(tab, i, null, node)) {
-               validated = true;
                try {
+                  count = 1;
                   if ((val = mf.remap(k, null)) != null) {
                      node.val = val;
                      added = true;
@@ -903,21 +1538,46 @@ else if ((f = tabAt(tab, i = (tab.length - 1) & h)) == null) {
                   }
                }
             }
-            if (validated)
+            if (count != 0)
                break;
          }
-         else if ((fh = f.hash) == MOVED)
-            tab = (Node[])f.key;
+         else if ((fh = f.hash) == MOVED) {
+            if ((fk = f.key) instanceof TreeBin) {
+               TreeBin t = (TreeBin)fk;
+               t.acquire(0);
+               try {
+                  if (tabAt(tab, i) == f) {
+                     count = 1;
+                     TreeNode p = t.getTreeNode(h, k, t.root);
+                     Object pv = (p == null)? null : p.val;
+                     if ((val = mf.remap(k, (V)pv)) != null) {
+                        if (p != null)
+                           p.val = val;
+                        else {
+                           count = 2;
+                           added = true;
+                           t.putTreeNode(h, k, val);
+                        }
+                     }
+                  }
+               } finally {
+                  t.release(0);
+               }
+               if (count != 0)
+                  break;
+            }
+            else
+               tab = (Node[])fk;
+         }
          else if ((fh & LOCKED) != 0) {
             checkForResize();
             f.tryAwaitLock(tab, i);
          }
          else if (f.casHash(fh, fh | LOCKED)) {
-            boolean validated = false;
             try {
                if (tabAt(tab, i) == f) {
-                  validated = true;
-                  for (Node e = f;;) {
+                  count = 1;
+                  for (Node e = f;; ++count) {
                      Object ek, ev;
                      if ((e.hash & HASH_BITS) == h &&
                            (ev = e.val) != null &&
@@ -932,8 +1592,8 @@ else if (f.casHash(fh, fh | LOCKED)) {
                         if ((val = mf.remap(k, null)) != null) {
                            last.next = new Node(h, k, val, null);
                            added = true;
-                           if (last != f || tab.length <= 64)
-                              checkSize = true;
+                           if (count >= TREE_THRESHOLD)
+                              replaceWithTreeBin(tab, i, k);
                         }
                         break;
                      }
@@ -945,15 +1605,18 @@ else if (f.casHash(fh, fh | LOCKED)) {
                   synchronized (f) { f.notifyAll(); };
                }
             }
-            if (validated)
+            if (count != 0) {
+               if (tab.length <= 64)
+                  count = 2;
                break;
+            }
          }
       }
       if (val == null)
          throw new NullPointerException();
       if (added) {
          counter.add(1L);
-         if (checkSize)
+         if (count > 1)
             checkForResize();
       }
       return val;
@@ -974,7 +1637,7 @@ private final void internalPutAll(Map<?, ?> m) {
             }
             int h = spread(k.hashCode());
             for (Node[] tab = table;;) {
-               int i; Node f; int fh;
+               int i; Node f; int fh; Object fk;
                if (tab == null)
                   tab = initTable();
                else if ((f = tabAt(tab, i = (tab.length - 1) & h)) == null){
@@ -983,21 +1646,43 @@ else if ((f = tabAt(tab, i = (tab.length - 1) & h)) == null){
                      break;
                   }
                }
-               else if ((fh = f.hash) == MOVED)
-                  tab = (Node[])f.key;
+               else if ((fh = f.hash) == MOVED) {
+                  if ((fk = f.key) instanceof TreeBin) {
+                     TreeBin t = (TreeBin)fk;
+                     boolean validated = false;
+                     t.acquire(0);
+                     try {
+                        if (tabAt(tab, i) == f) {
+                           validated = true;
+                           TreeNode p = t.getTreeNode(h, k, t.root);
+                           if (p != null)
+                              p.val = v;
+                           else {
+                              t.putTreeNode(h, k, v);
+                              ++delta;
+                           }
+                        }
+                     } finally {
+                        t.release(0);
+                     }
+                     if (validated)
+                        break;
+                  }
+                  else
+                     tab = (Node[])fk;
+               }
                else if ((fh & LOCKED) != 0) {
                   counter.add(delta);
                   delta = 0L;
                   checkForResize();
                   f.tryAwaitLock(tab, i);
                }
                else if (f.casHash(fh, fh | LOCKED)) {
-                  boolean validated = false;
-                  boolean tooLong = false;
+                  int count = 0;
                   try {
                      if (tabAt(tab, i) == f) {
-                        validated = true;
-                        for (Node e = f;;) {
+                        count = 1;
+                        for (Node e = f;; ++count) {
                            Object ek, ev;
                            if ((e.hash & HASH_BITS) == h &&
                                  (ev = e.val) != null &&
@@ -1009,9 +1694,10 @@ else if (f.casHash(fh, fh | LOCKED)) {
                            if ((e = e.next) == null) {
                               ++delta;
                               last.next = new Node(h, k, v, null);
+                              if (count >= TREE_THRESHOLD)
+                                 replaceWithTreeBin(tab, i, k);
                               break;
                            }
-                           tooLong = true;
                         }
                      }
                   } finally {
@@ -1020,8 +1706,8 @@ else if (f.casHash(fh, fh | LOCKED)) {
                         synchronized (f) { f.notifyAll(); };
                      }
                   }
-                  if (validated) {
-                     if (tooLong) {
+                  if (count != 0) {
+                     if (count > 1) {
                         counter.add(delta);
                         delta = 0L;
                         checkForResize();
@@ -1177,35 +1863,31 @@ private static final Node[] rebuild(Node[] tab) {
                }
             }
          }
-         else if (((fh = f.hash) & LOCKED) == 0 && f.casHash(fh, fh|LOCKED)) {
+         else if ((fh = f.hash) == MOVED) {
+            Object fk = f.key;
+            if (fk instanceof TreeBin) {
+               TreeBin t = (TreeBin)fk;
+               boolean validated = false;
+               t.acquire(0);
+               try {
+                  if (tabAt(tab, i) == f) {
+                     validated = true;
+                     splitTreeBin(nextTab, i, t);
+                     setTabAt(tab, i, fwd);
+                  }
+               } finally {
+                  t.release(0);
+               }
+               if (!validated)
+                  continue;
+            }
+         }
+         else if ((fh & LOCKED) == 0 && f.casHash(fh, fh|LOCKED)) {
             boolean validated = false;
             try {              // split to lo and hi lists; copying as needed
                if (tabAt(tab, i) == f) {
                   validated = true;
-                  Node e = f, lastRun = f;
-                  Node lo = null, hi = null;
-                  int runBit = e.hash & n;
-                  for (Node p = e.next; p != null; p = p.next) {
-                     int b = p.hash & n;
-                     if (b != runBit) {
-                        runBit = b;
-                        lastRun = p;
-                     }
-                  }
-                  if (runBit == 0)
-                     lo = lastRun;
-                  else
-                     hi = lastRun;
-                  for (Node p = e; p != lastRun; p = p.next) {
-                     int ph = p.hash & HASH_BITS;
-                     Object pk = p.key, pv = p.val;
-                     if ((ph & n) == 0)
-                        lo = new Node(ph, pk, pv, lo);
-                     else
-                        hi = new Node(ph, pk, pv, hi);
-                  }
-                  setTabAt(nextTab, i, lo);
-                  setTabAt(nextTab, i + n, hi);
+                  splitBin(nextTab, i, f);
                   setTabAt(tab, i, fwd);
                }
             } finally {
@@ -1250,6 +1932,76 @@ else if (buffer != null && nbuffered > 0) {
       }
    }
 
+   /**
+    * Split a normal bin with list headed by e into lo and hi parts;
+    * install in given table
+    */
+   private static void splitBin(Node[] nextTab, int i, Node e) {
+      int bit = nextTab.length >>> 1; // bit to split on
+      int runBit = e.hash & bit;
+      Node lastRun = e, lo = null, hi = null;
+      for (Node p = e.next; p != null; p = p.next) {
+         int b = p.hash & bit;
+         if (b != runBit) {
+            runBit = b;
+            lastRun = p;
+         }
+      }
+      if (runBit == 0)
+         lo = lastRun;
+      else
+         hi = lastRun;
+      for (Node p = e; p != lastRun; p = p.next) {
+         int ph = p.hash & HASH_BITS;
+         Object pk = p.key, pv = p.val;
+         if ((ph & bit) == 0)
+            lo = new Node(ph, pk, pv, lo);
+         else
+            hi = new Node(ph, pk, pv, hi);
+      }
+      setTabAt(nextTab, i, lo);
+      setTabAt(nextTab, i + bit, hi);
+   }
+
+   /**
+    * Split a tree bin into lo and hi parts; install in given table
+    */
+   private static void splitTreeBin(Node[] nextTab, int i, TreeBin t) {
+      int bit = nextTab.length >>> 1;
+      TreeBin lt = new TreeBin();
+      TreeBin ht = new TreeBin();
+      int lc = 0, hc = 0;
+      for (Node e = t.first; e != null; e = e.next) {
+         int h = e.hash & HASH_BITS;
+         Object k = e.key, v = e.val;
+         if ((h & bit) == 0) {
+            ++lc;
+            lt.putTreeNode(h, k, v);
+         }
+         else {
+            ++hc;
+            ht.putTreeNode(h, k, v);
+         }
+      }
+      Node ln, hn; // throw away trees if too small
+      if (lc <= (TREE_THRESHOLD >>> 1)) {
+         ln = null;
+         for (Node p = lt.first; p != null; p = p.next)
+            ln = new Node(p.hash, p.key, p.val, ln);
+      }
+      else
+         ln = new Node(MOVED, lt, null, null);
+      setTabAt(nextTab, i, ln);
+      if (hc <= (TREE_THRESHOLD >>> 1)) {
+         hn = null;
+         for (Node p = ht.first; p != null; p = p.next)
+            hn = new Node(p.hash, p.key, p.val, hn);
+      }
+      else
+         hn = new Node(MOVED, ht, null, null);
+      setTabAt(nextTab, i + bit, hn);
+   }
+
    /**
     * Implementation for clear. Steps through each bin, removing all
     * nodes.
@@ -1259,45 +2011,58 @@ private final void internalClear() {
       int i = 0;
       Node[] tab = table;
       while (tab != null && i < tab.length) {
-         int fh;
+         int fh; Object fk;
          Node f = tabAt(tab, i);
          if (f == null)
             ++i;
-         else if ((fh = f.hash) == MOVED)
-            tab = (Node[])f.key;
+         else if ((fh = f.hash) == MOVED) {
+            if ((fk = f.key) instanceof TreeBin) {
+               TreeBin t = (TreeBin)fk;
+               t.acquire(0);
+               try {
+                  if (tabAt(tab, i) == f) {
+                     for (Node p = t.first; p != null; p = p.next) {
+                        p.val = null;
+                        --delta;
+                     }
+                     t.first = null;
+                     t.root = null;
+                     ++i;
+                  }
+               } finally {
+                  t.release(0);
+               }
+            }
+            else
+               tab = (Node[])fk;
+         }
          else if ((fh & LOCKED) != 0) {
             counter.add(delta); // opportunistically update count
             delta = 0L;
             f.tryAwaitLock(tab, i);
          }
          else if (f.casHash(fh, fh | LOCKED)) {
-            boolean validated = false;
             try {
                if (tabAt(tab, i) == f) {
-                  validated = true;
                   for (Node e = f; e != null; e = e.next) {
-                     if (e.val != null) { // currently always true
-                        e.val = null;
-                        --delta;
-                     }
+                     e.val = null;
+                     --delta;
                   }
                   setTabAt(tab, i, null);
+                  ++i;
                }
             } finally {
                if (!f.casHash(fh | LOCKED, fh)) {
                   f.hash = fh;
                   synchronized (f) { f.notifyAll(); };
                }
             }
-            if (validated)
-               ++i;
          }
       }
       if (delta != 0)
          counter.add(delta);
    }
 
-
    /* ----------------Table Traversal -------------- */
 
    /**
@@ -1376,14 +2141,19 @@ final void advance() {
             if (e != null)                  // advance past used/skipped node
                e = e.next;
             while (e == null) {             // get to next non-null bin
-               Node[] t; int b, i, n;      // checks must use locals
+               Node[] t; int b, i, n; Object ek; // checks must use locals
                if ((b = baseIndex) >= baseLimit || (i = index) < 0 ||
                      (t = tab) == null || i >= (n = t.length))
                   break outer;
-               else if ((e = tabAt(t, i)) != null && e.hash == MOVED)
-                  tab = (Node[])e.key;    // restarts due to null val
-               else                        // visit upper slots if present
-                  index = (i += baseSize) < n ? i : (baseIndex = b + 1);
+               else if ((e = tabAt(t, i)) != null && e.hash == MOVED) {
+                  if ((ek = e.key) instanceof TreeBin)
+                     e = ((TreeBin)ek).first;
+                  else {
+                     tab = (Node[])ek;
+                     continue;           // restarts due to null val
+                  }
+               }                           // visit upper slots if present
+               index = (i += baseSize) < n ? i : (baseIndex = b + 1);
             }
             nextKey = e.key;
          } while ((nextVal = e.val) == null);// skip deleted or special nodes
@@ -1469,7 +2239,7 @@ public ConcurrentHashMapV8(int initialCapacity, float loadFactor) {
     * nonpositive
     */
    public ConcurrentHashMapV8(int initialCapacity,
-                              float loadFactor, int concurrencyLevel) {
+         float loadFactor, int concurrencyLevel) {
       if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
          throw new IllegalArgumentException();
       if (initialCapacity < concurrencyLevel)   // Use at least as many bins
@@ -1484,15 +2254,13 @@ public ConcurrentHashMapV8(int initialCapacity,
    /**
     * {@inheritDoc}
     */
-   @Override
    public boolean isEmpty() {
       return counter.sum() <= 0L; // ignore transient negative values
    }
 
    /**
     * {@inheritDoc}
     */
-   @Override
    public int size() {
       long n = counter.sum();
       return ((n < 0L) ? 0 :
@@ -1516,7 +2284,6 @@ final long longSize() { // accurate version of size needed for views
     *
     * @throws NullPointerException if the specified key is null
     */
-   @Override
    @SuppressWarnings(""unchecked"")
    public V get(Object key) {
       if (key == null)
@@ -1533,7 +2300,6 @@ public V get(Object key) {
     *         {@code equals} method; {@code false} otherwise
     * @throws NullPointerException if the specified key is null
     */
-   @Override
    public boolean containsKey(Object key) {
       if (key == null)
          throw new NullPointerException();
@@ -1550,7 +2316,6 @@ public boolean containsKey(Object key) {
     *         specified value
     * @throws NullPointerException if the specified value is null
     */
-   @Override
    public boolean containsValue(Object value) {
       if (value == null)
          throw new NullPointerException();
@@ -1596,7 +2361,6 @@ public boolean contains(Object value) {
     *         {@code null} if there was no mapping for {@code key}
     * @throws NullPointerException if the specified key or value is null
     */
-   @Override
    @SuppressWarnings(""unchecked"")
    public V put(K key, V value) {
       if (key == null || value == null)
@@ -1611,7 +2375,6 @@ public V put(K key, V value) {
     *         or {@code null} if there was no mapping for the key
     * @throws NullPointerException if the specified key or value is null
     */
-   @Override
    @SuppressWarnings(""unchecked"")
    public V putIfAbsent(K key, V value) {
       if (key == null || value == null)
@@ -1626,7 +2389,6 @@ public V putIfAbsent(K key, V value) {
     *
     * @param m mappings to be stored in this map
     */
-   @Override
    public void putAll(Map<? extends K, ? extends V> m) {
       internalPutAll(m);
    }
@@ -1731,7 +2493,6 @@ public V compute(K key, RemappingFunction<? super K, V> remappingFunction) {
     *         {@code null} if there was no mapping for {@code key}
     * @throws NullPointerException if the specified key is null
     */
-   @Override
    @SuppressWarnings(""unchecked"")
    public V remove(Object key) {
       if (key == null)
@@ -1744,7 +2505,6 @@ public V remove(Object key) {
     *
     * @throws NullPointerException if the specified key is null
     */
-   @Override
    public boolean remove(Object key, Object value) {
       if (key == null)
          throw new NullPointerException();
@@ -1758,7 +2518,6 @@ public boolean remove(Object key, Object value) {
     *
     * @throws NullPointerException if any of the arguments are null
     */
-   @Override
    public boolean replace(K key, V oldValue, V newValue) {
       if (key == null || oldValue == null || newValue == null)
          throw new NullPointerException();
@@ -1772,7 +2531,6 @@ public boolean replace(K key, V oldValue, V newValue) {
     *         or {@code null} if there was no mapping for the key
     * @throws NullPointerException if the specified key or value is null
     */
-   @Override
    @SuppressWarnings(""unchecked"")
    public V replace(K key, V value) {
       if (key == null || value == null)
@@ -1783,7 +2541,6 @@ public V replace(K key, V value) {
    /**
     * Removes all of the mappings from this map.
     */
-   @Override
    public void clear() {
       internalClear();
    }
@@ -1804,7 +2561,6 @@ public void clear() {
     * construction of the iterator, and may (but is not guaranteed to)
     * reflect any modifications subsequent to construction.
     */
-   @Override
    public Set<K> keySet() {
       KeySet<K,V> ks = keySet;
       return (ks != null) ? ks : (keySet = new KeySet<K,V>(this));
@@ -1826,7 +2582,6 @@ public Set<K> keySet() {
     * construction of the iterator, and may (but is not guaranteed to)
     * reflect any modifications subsequent to construction.
     */
-   @Override
    public Collection<V> values() {
       Values<K,V> vs = values;
       return (vs != null) ? vs : (values = new Values<K,V>(this));
@@ -1848,7 +2603,6 @@ public Collection<V> values() {
     * construction of the iterator, and may (but is not guaranteed to)
     * reflect any modifications subsequent to construction.
     */
-   @Override
    public Set<Map.Entry<K,V>> entrySet() {
       EntrySet<K,V> es = entrySet;
       return (es != null) ? es : (entrySet = new EntrySet<K,V>(this));
@@ -1984,7 +2738,6 @@ static final class KeyIterator<K,V> extends ViewIterator<K,V>
          implements Iterator<K>, Enumeration<K> {
       KeyIterator(ConcurrentHashMapV8<K, V> map) { super(map); }
 
-      @Override
       @SuppressWarnings(""unchecked"")
       public final K next() {
          if (next == null)
@@ -1994,15 +2747,13 @@ public final K next() {
          return (K)k;
       }
 
-      @Override
       public final K nextElement() { return next(); }
    }
 
    static final class ValueIterator<K,V> extends ViewIterator<K,V>
          implements Iterator<V>, Enumeration<V> {
       ValueIterator(ConcurrentHashMapV8<K, V> map) { super(map); }
 
-      @Override
       @SuppressWarnings(""unchecked"")
       public final V next() {
          if (next == null)
@@ -2012,15 +2763,13 @@ public final V next() {
          return (V)v;
       }
 
-      @Override
       public final V nextElement() { return next(); }
    }
 
    static final class EntryIterator<K,V> extends ViewIterator<K,V>
          implements Iterator<Map.Entry<K,V>> {
       EntryIterator(ConcurrentHashMapV8<K, V> map) { super(map); }
 
-      @Override
       @SuppressWarnings(""unchecked"")
       public final Map.Entry<K,V> next() {
          if (next == null)
@@ -2036,7 +2785,6 @@ static final class SnapshotEntryIterator<K,V> extends ViewIterator<K,V>
          implements Iterator<Map.Entry<K,V>> {
       SnapshotEntryIterator(ConcurrentHashMapV8<K, V> map) { super(map); }
 
-      @Override
       @SuppressWarnings(""unchecked"")
       public final Map.Entry<K,V> next() {
          if (next == null)
@@ -2055,9 +2803,7 @@ static abstract class MapEntry<K,V> implements Map.Entry<K, V> {
       final K key; // non-null
       V val;       // non-null
       MapEntry(K key, V val)        { this.key = key; this.val = val; }
-      @Override
       public final K getKey()       { return key; }
-      @Override
       public final V getValue()     { return val; }
       public final int hashCode()   { return key.hashCode() ^ val.hashCode(); }
       public final String toString(){ return key + ""="" + val; }
@@ -2071,7 +2817,6 @@ public final boolean equals(Object o) {
                        (v == val || v.equals(val)));
       }
 
-      @Override
       public abstract V setValue(V value);
    }
 
@@ -2096,7 +2841,6 @@ static final class WriteThroughEntry<K,V> extends MapEntry<K,V>
        * removed in which case the put will re-establish). We do not
        * and cannot guarantee more.
        */
-      @Override
       public final V setValue(V value) {
          if (value == null) throw new NullPointerException();
          V v = val;
@@ -2112,7 +2856,6 @@ public final V setValue(V value) {
    static final class SnapshotEntry<K,V> extends MapEntry<K,V>
          implements Map.Entry<K, V> {
       SnapshotEntry(K key, V val) { super(key, val); }
-      @Override
       public final V setValue(V value) { // only locally update
          if (value == null) throw new NullPointerException();
          V v = val;
@@ -2255,24 +2998,18 @@ public final boolean retainAll(Collection<?> c) {
 
    static final class KeySet<K,V> extends MapView<K,V> implements Set<K> {
       KeySet(ConcurrentHashMapV8<K, V> map)   { super(map); }
-      @Override
       public final boolean contains(Object o) { return map.containsKey(o); }
-      @Override
       public final boolean remove(Object o)   { return map.remove(o) != null; }
 
-      @Override
       public final Iterator<K> iterator() {
          return new KeyIterator<K,V>(map);
       }
-      @Override
       final Iterator<?> iter() {
          return new KeyIterator<K,V>(map);
       }
-      @Override
       public final boolean add(K e) {
          throw new UnsupportedOperationException();
       }
-      @Override
       public final boolean addAll(Collection<? extends K> c) {
          throw new UnsupportedOperationException();
       }
@@ -2287,10 +3024,8 @@ public boolean equals(Object o) {
    static final class Values<K,V> extends MapView<K,V>
          implements Collection<V> {
       Values(ConcurrentHashMapV8<K, V> map)   { super(map); }
-      @Override
       public final boolean contains(Object o) { return map.containsValue(o); }
 
-      @Override
       public final boolean remove(Object o) {
          if (o != null) {
             Iterator<V> it = new ValueIterator<K,V>(map);
@@ -2303,19 +3038,15 @@ public final boolean remove(Object o) {
          }
          return false;
       }
-      @Override
       public final Iterator<V> iterator() {
          return new ValueIterator<K,V>(map);
       }
-      @Override
       final Iterator<?> iter() {
          return new ValueIterator<K,V>(map);
       }
-      @Override
       public final boolean add(V e) {
          throw new UnsupportedOperationException();
       }
-      @Override
       public final boolean addAll(Collection<? extends V> c) {
          throw new UnsupportedOperationException();
       }
@@ -2325,7 +3056,6 @@ static final class EntrySet<K,V> extends MapView<K,V>
          implements Set<Map.Entry<K,V>> {
       EntrySet(ConcurrentHashMapV8<K, V> map) { super(map); }
 
-      @Override
       public final boolean contains(Object o) {
          Object k, v, r; Map.Entry<?,?> e;
          return ((o instanceof Map.Entry) &&
@@ -2335,7 +3065,6 @@ public final boolean contains(Object o) {
                        (v == r || v.equals(r)));
       }
 
-      @Override
       public final boolean remove(Object o) {
          Object k, v; Map.Entry<?,?> e;
          return ((o instanceof Map.Entry) &&
@@ -2344,19 +3073,15 @@ public final boolean remove(Object o) {
                        map.remove(k, v));
       }
 
-      @Override
       public final Iterator<Map.Entry<K,V>> iterator() {
          return new EntryIterator<K,V>(map);
       }
-      @Override
       final Iterator<?> iter() {
          return new SnapshotEntryIterator<K,V>(map);
       }
-      @Override
       public final boolean add(Entry<K,V> e) {
          throw new UnsupportedOperationException();
       }
-      @Override
       public final boolean addAll(Collection<? extends Entry<K,V>> c) {
          throw new UnsupportedOperationException();
       }
@@ -2429,7 +3154,8 @@ private void readObject(java.io.ObjectInputStream s)
          K k = (K) s.readObject();
          V v = (V) s.readObject();
          if (k != null && v != null) {
-            p = new Node(spread(k.hashCode()), k, v, p);
+            int h = spread(k.hashCode());
+            p = new Node(h, k, v, p);
             ++size;
          }
          else
@@ -2445,6 +3171,7 @@ private void readObject(java.io.ObjectInputStream s)
             n = tableSizeFor(sz + (sz >>> 1) + 1);
          }
          int sc = sizeCtl;
+         boolean collide = false;
          if (n > sc &&
                UNSAFE.compareAndSwapInt(this, sizeCtlOffset, sc, -1)) {
             try {
@@ -2455,8 +3182,10 @@ private void readObject(java.io.ObjectInputStream s)
                   while (p != null) {
                      int j = p.hash & mask;
                      Node next = p.next;
-                     p.next = tabAt(tab, j);
+                     Node q = p.next = tabAt(tab, j);
                      setTabAt(tab, j, p);
+                     if (!collide && q != null && q.hash == p.hash)
+                        collide = true;
                      p = next;
                   }
                   table = tab;
@@ -2466,13 +3195,27 @@ private void readObject(java.io.ObjectInputStream s)
             } finally {
                sizeCtl = sc;
             }
+            if (collide) { // rescan and convert to TreeBins
+               Node[] tab = table;
+               for (int i = 0; i < tab.length; ++i) {
+                  int c = 0;
+                  for (Node e = tabAt(tab, i); e != null; e = e.next) {
+                     if (++c > TREE_THRESHOLD &&
+                           (e.key instanceof Comparable)) {
+                        replaceWithTreeBin(tab, i, e.key);
+                        break;
+                     }
+                  }
+               }
+            }
          }
          if (!init) { // Can only happen if unsafely published.
             while (p != null) {
                internalPut(p.key, p.val);
                p = p.next;
             }
          }
+
       }
    }
 
@@ -2518,7 +3261,6 @@ private static sun.misc.Unsafe getUnsafe() {
             return java.security.AccessController.doPrivileged
                   (new java.security
                         .PrivilegedExceptionAction<sun.misc.Unsafe>() {
-                     @Override
                      public sun.misc.Unsafe run() throws Exception {
                         java.lang.reflect.Field f = sun.misc
                               .Unsafe.class.getDeclaredField(""theUnsafe"");
@@ -2527,7 +3269,7 @@ public sun.misc.Unsafe run() throws Exception {
                      }});
          } catch (java.security.PrivilegedActionException e) {
             throw new RuntimeException(""Could not initialize intrinsics"",
-                                       e.getCause());
+                  e.getCause());
          }
       }
    }",2012-06-13T11:41:59Z,645
"@@ -224,4 +224,4 @@ private void readObject(ObjectInputStream s)
       base = s.readLong();
    }
 
-}
\ No newline at end of file
+}",2012-06-13T11:41:59Z,646
"@@ -47,7 +47,7 @@
  * @author Mircea.Markus@jboss.com
  * @since 4.1
  */
-public class BaseKeyAffinityServiceTest extends BaseDistFunctionalTest {
+public abstract class BaseKeyAffinityServiceTest extends BaseDistFunctionalTest {
 
    protected ThreadFactory threadFactory = new ThreadFactory() {
       public Thread newThread(Runnable r) {",2012-06-13T11:41:59Z,647
"@@ -125,11 +125,19 @@ public Object getOwner(Object key) {
 
          if (l instanceof OwnableReentrantLock) {
             return ((OwnableReentrantLock) l).getOwner();
-         } else {
-            // cannot determine owner, JDK Reentrant locks only provide best-effort guesses.
-            return ANOTHER_THREAD;
+         } else if (l instanceof VisibleOwnerReentrantLock) {
+            Thread owner = ((VisibleOwnerReentrantLock) l).getOwner();
+            // Don't assume the key is unlocked if getOwner() returned null.
+            // JDK ReentrantLocks can return null e.g. if another thread is in the process of acquiring the lock
+            if (owner != null)
+               return owner;
          }
-      } else return null;
+
+         return ANOTHER_THREAD;
+      } else {
+         // not locked
+         return null;
+      }
    }
 
    @Override",2012-09-27T11:30:18Z,139
"@@ -0,0 +1,35 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.util.concurrent.locks;
+
+import java.util.concurrent.locks.ReentrantLock;
+
+/**
+* Extends {@link ReentrantLock} only to make the {@link #getOwner()} method public.
+*
+* @author Dan Berindei
+* @since 5.2
+*/
+public class VisibleOwnerReentrantLock extends ReentrantLock {
+   @Override
+   public Thread getOwner() {
+      return super.getOwner();
+   }
+}",2012-09-27T11:30:18Z,648
"@@ -25,6 +25,8 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.locks.ReentrantLock;
 
+import org.infinispan.util.concurrent.locks.VisibleOwnerReentrantLock;
+
 /**
  * A per-entry lock container for ReentrantLocks
  *
@@ -39,7 +41,7 @@ public ReentrantPerEntryLockContainer(int concurrencyLevel) {
 
    @Override
    protected ReentrantLock newLock() {
-      return new ReentrantLock();
+      return new VisibleOwnerReentrantLock();
    }
 
    @Override
@@ -67,4 +69,5 @@ protected void unlock(ReentrantLock l, Object unused) {
    protected boolean tryLock(ReentrantLock lock, long timeout, TimeUnit unit, Object unused) throws InterruptedException {
       return lock.tryLock(timeout, unit);
    }
+
 }",2012-09-27T11:30:18Z,649
"@@ -32,6 +32,7 @@
 import org.infinispan.marshall.AdvancedExternalizer;
 import org.infinispan.marshall.Marshaller;
 import org.infinispan.remoting.transport.Transport;
+import org.jboss.marshalling.ClassResolver;
 
 import java.util.Properties;
 
@@ -108,6 +109,13 @@ public FluentGlobalConfiguration(GlobalConfiguration globalConfig) {
        * @param advancedExternalizers
        */
       <T> SerializationConfig addAdvancedExternalizer(AdvancedExternalizer<T>... advancedExternalizers);
+
+      /**
+       * Class resolver to use when unmarshallig objects.
+       *
+       * @param classResolver
+       */
+      SerializationConfig classResolver(ClassResolver classResolver);
    }
 
    /**",2012-03-19T13:24:00Z,11
"@@ -50,6 +50,7 @@
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
+import org.jboss.marshalling.ClassResolver;
 
 import javax.xml.bind.annotation.XmlAccessType;
 import javax.xml.bind.annotation.XmlAccessorType;
@@ -695,6 +696,10 @@ public List<AdvancedExternalizerConfig> getExternalizers() {
       return serialization.externalizerTypes.advancedExternalizers;
    }
 
+   public ClassResolver getClassResolver() {
+      return serialization.classResolver;
+   }
+
    public long getDistributedSyncTimeout() {
       return transport.distributedSyncTimeout;
    }
@@ -1361,6 +1366,9 @@ TransportType setGlobalConfiguration(GlobalConfiguration globalConfig) {
       @XmlElement(name = ""advancedExternalizers"")
       protected AdvancedExternalizersType externalizerTypes = new AdvancedExternalizersType();
 
+      @XmlTransient
+      private ClassResolver classResolver;
+
       public SerializationType() {
          super();
       }
@@ -1453,6 +1461,12 @@ public <T> SerializationConfig addAdvancedExternalizer(int id, AdvancedExternali
                new AdvancedExternalizerConfig().setId(id).setAdvancedExternalizer(advancedExternalizer));
          return this;
       }
+
+      @Override
+      public SerializationConfig classResolver(ClassResolver classResolver) {
+         this.classResolver = classResolver;
+         return this;
+      }
    }
 
    /**",2012-03-19T13:24:00Z,12
"@@ -73,6 +73,8 @@ public static org.infinispan.config.GlobalConfiguration adapt(GlobalConfiguratio
       for (Entry<Integer, AdvancedExternalizer<?>> entry : config.serialization().advancedExternalizers().entrySet()) {
          legacy.serialization().addAdvancedExternalizer(entry.getKey(), entry.getValue());
       }
+
+      legacy.serialization().classResolver(config.serialization().classResolver());
       
       legacy.asyncTransportExecutor()
          .factory(config.asyncTransportExecutor().factory().getClass())
@@ -134,6 +136,8 @@ public static org.infinispan.configuration.global.GlobalConfiguration adapt(org.
       for (AdvancedExternalizerConfig externalizerConfig : legacy.getExternalizers()) {
          builder.serialization().addAdvancedExternalizer(externalizerConfig.getId(), externalizerConfig.getAdvancedExternalizer());
       }
+
+      builder.serialization().classResolver(legacy.getClassResolver());
       
       builder.asyncTransportExecutor()
          .factory(Util.<ExecutorFactory>getInstance(legacy.getAsyncTransportExecutorFactoryClass(), legacy.getClassLoader()))",2012-03-19T13:24:00Z,13
"@@ -24,18 +24,22 @@
 
 import org.infinispan.marshall.AdvancedExternalizer;
 import org.infinispan.marshall.Marshaller;
+import org.jboss.marshalling.ClassResolver;
 
 public class SerializationConfiguration {
 
    private final Marshaller marshaller;
    private final short version;
    private final Map<Integer, AdvancedExternalizer<?>> advancedExternalizers;
+   private final ClassResolver classResolver;
    
    SerializationConfiguration(Marshaller marshaller, short version,
-         Map<Integer, AdvancedExternalizer<?>> advancedExternalizers) {
+         Map<Integer, AdvancedExternalizer<?>> advancedExternalizers,
+         ClassResolver classResolver) {
       this.marshaller = marshaller;
       this.version = version;
       this.advancedExternalizers = Collections.unmodifiableMap(new HashMap<Integer, AdvancedExternalizer<?>>(advancedExternalizers));
+      this.classResolver = classResolver;
    }
 
    public Marshaller marshaller() {
@@ -50,12 +54,17 @@ public Map<Integer, AdvancedExternalizer<?>> advancedExternalizers() {
       return advancedExternalizers;
    }
 
+   public ClassResolver classResolver() {
+      return classResolver;
+   }
+
    @Override
    public String toString() {
       return ""SerializationConfiguration{"" +
             ""advancedExternalizers="" + advancedExternalizers +
             "", marshaller="" + marshaller +
             "", version="" + version +
+            "", classResolver="" + classResolver +
             '}';
    }
 ",2012-03-19T13:24:00Z,14
"@@ -22,6 +22,8 @@
 import org.infinispan.marshall.AdvancedExternalizer;
 import org.infinispan.marshall.Marshaller;
 import org.infinispan.marshall.VersionAwareMarshaller;
+import org.jboss.marshalling.ClassResolver;
+
 import java.util.HashMap;
 import java.util.Map;
 
@@ -33,6 +35,7 @@ public class SerializationConfigurationBuilder extends AbstractGlobalConfigurati
    private Marshaller marshaller = new VersionAwareMarshaller();
    private short marshallVersion = Short.valueOf(Version.MAJOR_MINOR.replace(""."", """"));
    private Map<Integer, AdvancedExternalizer<?>> advancedExternalizers = new HashMap<Integer, AdvancedExternalizer<?>>();
+   private ClassResolver classResolver;
 
    SerializationConfigurationBuilder(GlobalConfigurationBuilder globalConfig) {
       super(globalConfig);
@@ -111,14 +114,25 @@ public <T> SerializationConfigurationBuilder addAdvancedExternalizer(AdvancedExt
       return this;
    }
 
+   /**
+    * Class resolver to use when unmarshallig objects.
+    *
+    * @param classResolver
+    */
+   public SerializationConfigurationBuilder classResolver(ClassResolver classResolver) {
+      this.classResolver = classResolver;
+      return this;
+   }
+
    @Override
    protected void validate() {
       // No-op, no validation required
    }
 
    @Override
    SerializationConfiguration create() {
-      return new SerializationConfiguration(marshaller, marshallVersion, advancedExternalizers);
+      return new SerializationConfiguration(
+            marshaller, marshallVersion, advancedExternalizers, classResolver);
    }
 
    @Override
@@ -136,6 +150,7 @@ public String toString() {
             ""advancedExternalizers="" + advancedExternalizers +
             "", marshaller="" + marshaller +
             "", marshallVersion="" + marshallVersion +
+            "", classResolver="" + classResolver +
             '}';
    }
 
@@ -151,6 +166,8 @@ public boolean equals(Object o) {
          return false;
       if (marshaller != null ? !marshaller.equals(that.marshaller) : that.marshaller != null)
          return false;
+      if (classResolver != null ? !classResolver.equals(that.classResolver) : that.classResolver != null)
+         return false;
 
       return true;
    }
@@ -160,6 +177,7 @@ public int hashCode() {
       int result = marshaller != null ? marshaller.hashCode() : 0;
       result = 31 * result + (int) marshallVersion;
       result = 31 * result + (advancedExternalizers != null ? advancedExternalizers.hashCode() : 0);
+      result = 31 * result + (classResolver != null ? classResolver.hashCode() : 0);
       return result;
    }
 ",2012-03-19T13:24:00Z,15
"@@ -1,6 +1,7 @@
 package org.infinispan.marshall;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Stop;
@@ -22,8 +23,10 @@ public CacheMarshaller(VersionAwareMarshaller marshaller) {
    }
 
    @Inject
-   public void inject(Configuration cfg, InvocationContextContainer icc, ExternalizerTable extTable) {
-      ((VersionAwareMarshaller) this.marshaller).inject(cfg, null, icc, extTable);
+   public void inject(Configuration cfg, InvocationContextContainer icc,
+            ExternalizerTable extTable, GlobalConfiguration globalCfg) {
+      ((VersionAwareMarshaller) this.marshaller).inject(
+            cfg, null, icc, extTable, globalCfg);
    }
 
    @Stop(priority = 11) // Stop after RPCManager to avoid send/receive and marshaller not being ready",2012-03-19T13:24:00Z,16
"@@ -1,5 +1,6 @@
 package org.infinispan.marshall;
 
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.factories.annotations.Inject;
 import org.infinispan.factories.annotations.Stop;
 import org.infinispan.factories.scopes.Scope;
@@ -22,8 +23,10 @@ public GlobalMarshaller(VersionAwareMarshaller marshaller) {
    }
 
    @Inject
-   public void inject(ClassLoader loader, ExternalizerTable extTable) {
-      ((VersionAwareMarshaller) this.marshaller).inject(null, loader, null, extTable);
+   public void inject(ClassLoader loader, ExternalizerTable extTable,
+            GlobalConfiguration globalCfg) {
+      ((VersionAwareMarshaller) this.marshaller).inject(
+            null, loader, null, extTable, globalCfg);
    }
 
    @Stop(priority = 11) // Stop after transport to avoid send/receive and marshaller not being ready",2012-03-19T13:24:00Z,17
"@@ -23,6 +23,7 @@
 package org.infinispan.marshall;
 
 import org.infinispan.config.Configuration;
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.io.ByteBuffer;
 import org.infinispan.io.ExposedByteArrayOutputStream;
@@ -61,7 +62,9 @@ public VersionAwareMarshaller() {
       defaultMarshaller = new JBossMarshaller();
    }
 
-   public void inject(Configuration cfg, ClassLoader loader, InvocationContextContainer icc, ExternalizerTable extTable) {
+   public void inject(Configuration cfg, ClassLoader loader,
+         InvocationContextContainer icc, ExternalizerTable extTable,
+         GlobalConfiguration globalCfg) {
       ClassLoader myClassLoader;
       if (cfg == null) {
          myClassLoader = loader;
@@ -71,7 +74,7 @@ public void inject(Configuration cfg, ClassLoader loader, InvocationContextConta
          this.cacheName = cfg.getName();
       }
 
-      this.defaultMarshaller.inject(extTable, myClassLoader, icc);
+      this.defaultMarshaller.inject(extTable, myClassLoader, icc, globalCfg);
    }
 
    public void stop() {",2012-03-19T13:24:00Z,18
"@@ -22,14 +22,11 @@
  */
 package org.infinispan.marshall.jboss;
 
+import org.infinispan.config.GlobalConfiguration;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.marshall.StreamingMarshaller;
-import org.jboss.marshalling.Marshaller;
-import org.jboss.marshalling.MarshallingConfiguration;
-import org.jboss.marshalling.Unmarshaller;
-
-import java.io.IOException;
+import org.jboss.marshalling.ClassResolver;
 
 /**
  * A JBoss Marshalling based marshaller that is oriented at internal, embedded,
@@ -52,13 +49,20 @@ public final class JBossMarshaller extends AbstractJBossMarshaller implements St
 
    ExternalizerTable externalizerTable;
 
-   public void inject(ExternalizerTable externalizerTable, ClassLoader cl, InvocationContextContainer icc) {
+   public void inject(ExternalizerTable externalizerTable, ClassLoader cl,
+         InvocationContextContainer icc, GlobalConfiguration globalCfg) {
       log.debug(""Using JBoss Marshalling"");
       this.externalizerTable = externalizerTable;
       baseCfg.setObjectTable(externalizerTable);
-      // Override the class resolver with one that can detect injected
-      // classloaders via AdvancedCache.with(ClassLoader) calls.
-      baseCfg.setClassResolver(new EmbeddedContextClassResolver(cl, icc));
+
+      ClassResolver classResolver = globalCfg.getClassResolver();
+      if (classResolver == null) {
+         // Override the class resolver with one that can detect injected
+         // classloaders via AdvancedCache.with(ClassLoader) calls.
+         classResolver = new EmbeddedContextClassResolver(cl, icc);
+      }
+
+      baseCfg.setClassResolver(classResolver);
    }
 
    @Override",2012-03-19T13:24:00Z,19
"@@ -2,16 +2,16 @@
 
 import org.infinispan.Cache;
 import org.infinispan.CacheException;
-import org.infinispan.config.Configuration.CacheMode;
-import org.infinispan.config.GlobalConfiguration;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.test.CherryPickClassLoader;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.testng.annotations.Test;
 
 import java.io.Serializable;
 
-import static org.infinispan.test.fwk.TestCacheManagerFactory.createCacheManager;
+import static org.infinispan.test.fwk.TestCacheManagerFactory.createClusteredCacheManager;
 import static org.testng.AssertJUnit.assertEquals;
 import static org.testng.AssertJUnit.fail;
 
@@ -30,22 +30,29 @@ public class WithClassLoaderTest extends MultipleCacheManagersTest {
 
    @Override
    protected void createCacheManagers() throws Throwable {
-      EmbeddedCacheManager cm0 = createCacheManager(GlobalConfiguration.getClusteredDefault());
-      cm0.getDefaultConfiguration().fluent()
-         .clustering().mode(CacheMode.REPL_SYNC)
-         .storeAsBinary().build();
+      ConfigurationBuilder builder = new ConfigurationBuilder();
+      builder.storeAsBinary().enable()
+            .clustering()
+            .cacheMode(org.infinispan.configuration.cache.CacheMode.REPL_SYNC);
+      EmbeddedCacheManager cm0 = createClusteredCacheManager(builder);
       cacheManagers.add(cm0);
 
       String[] notFound = new String[]{CAR};
       systemCl = Thread.currentThread().getContextClassLoader();
       CherryPickClassLoader cl = new CherryPickClassLoader(null, null, notFound, systemCl);
-      EmbeddedCacheManager cm1 = createCacheManager(GlobalConfiguration.getClusteredDefault(cl));
-      cm1.getDefaultConfiguration().fluent()
-         .clustering().mode(CacheMode.REPL_SYNC)
-         .storeAsBinary().build();
+
+      GlobalConfigurationBuilder gcBuilder = createSecondGlobalCfgBuilder(cl);
+      EmbeddedCacheManager cm1 = createClusteredCacheManager(gcBuilder, builder);
       cacheManagers.add(cm1);
    }
 
+   protected GlobalConfigurationBuilder createSecondGlobalCfgBuilder(ClassLoader cl) {
+      GlobalConfigurationBuilder gcBuilder =
+            GlobalConfigurationBuilder.defaultClusteredBuilder();
+      gcBuilder.classLoader(cl);
+      return gcBuilder;
+   }
+
    public void testReadingWithCorrectClassLoaderAfterReplication() {
       Cache<Integer, Car> cache0 = cache(0);
       Cache<Integer, Car> cache1 = cache(1);",2012-03-19T13:24:00Z,20
"@@ -0,0 +1,55 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.configuration;
+
+import org.infinispan.api.WithClassLoaderTest;
+import org.infinispan.configuration.global.GlobalConfigurationBuilder;
+import org.infinispan.marshall.jboss.DefaultContextClassResolver;
+import org.testng.annotations.Test;
+
+/**
+ * A test that verifies that a class resolver can be configured successfully.
+ *
+ * @author Galder Zamarreño
+ * @since 5.1
+ */
+@Test(groups = ""functional"", testName = ""configuration.ClassResolverConfigTest"")
+public class ClassResolverConfigTest extends WithClassLoaderTest {
+
+   @Override
+   protected GlobalConfigurationBuilder createSecondGlobalCfgBuilder(ClassLoader cl) {
+      GlobalConfigurationBuilder gcBuilder = super.createSecondGlobalCfgBuilder(cl);
+      gcBuilder.serialization().classResolver(new DefaultContextClassResolver(cl));
+      return gcBuilder;
+   }
+
+   @Override
+   @Test(expectedExceptions = AssertionError.class,
+         expectedExceptionsMessageRegExp = ""Expected a ClassNotFoundException"")
+   public void testReadingWithCorrectClassLoaderAfterReplication() {
+      // With the default context class resolver, if configured correctly,
+      // the classloader that we set with the invocation context (i.e.
+      // coming from global configuration) is ignored (the super class test
+      // has one specific classloader that forces not finding a class), and
+      // so the class is found.
+      super.testReadingWithCorrectClassLoaderAfterReplication();
+   }
+
+}
\ No newline at end of file",2012-03-19T13:24:00Z,21
"@@ -29,6 +29,7 @@
 
 import org.infinispan.Version;
 
+import org.infinispan.factories.annotations.SurvivesRestarts;
 import org.infinispan.factories.scopes.Scope;
 import org.infinispan.factories.scopes.Scopes;
 
@@ -48,6 +49,7 @@
  *
  */
 @Scope(Scopes.GLOBAL)
+@SurvivesRestarts
 public class GlobalConfiguration {
 
    /**",2012-08-31T21:04:11Z,22
"@@ -495,9 +495,11 @@ private void populateLifeCycleMethods(Component c) {
     */
    public void resetVolatileComponents() {
       // destroy all components to clean up resources
+      getLog().tracef(""Resetting volatile components"");
       for (Component c : new HashSet<Component>(componentLookup.values())) {
          // the component is volatile!!
          if (!c.metadata.isSurvivesRestarts()) {
+            getLog().tracef(""Removing volatile component %s"", c.metadata.getName());
             componentLookup.remove(c.name);
          }
       }",2012-08-31T21:04:11Z,23
"@@ -106,8 +106,8 @@ public GlobalComponentRegistry(GlobalConfiguration configuration,
          globalConfiguration = configuration;
 
          registerComponent(this, GlobalComponentRegistry.class);
-         registerComponent(cacheManager, EmbeddedCacheManager.class);
          registerComponent(configuration, GlobalConfiguration.class);
+         registerComponent(cacheManager, EmbeddedCacheManager.class);
          registerComponent(new CacheManagerJmxRegistration(), CacheManagerJmxRegistration.class);
          registerComponent(new CacheManagerNotifierImpl(), CacheManagerNotifier.class);
 ",2012-08-31T21:04:11Z,24
"@@ -23,18 +23,13 @@
 package org.infinispan.container;
 
 import net.jcip.annotations.ThreadSafe;
-import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalNullEntry;
 import org.infinispan.container.versioning.EntryVersion;
 import org.infinispan.eviction.EvictionManager;
 import org.infinispan.eviction.EvictionStrategy;
 import org.infinispan.eviction.EvictionThreadPolicy;
 import org.infinispan.eviction.PassivationManager;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
-import org.infinispan.loaders.CacheLoaderManager;
-import org.infinispan.loaders.decorators.AsyncStore;
 import org.infinispan.util.Immutables;
 import org.infinispan.util.concurrent.BoundedConcurrentHashMap;
 import org.infinispan.util.concurrent.BoundedConcurrentHashMap.Eviction;
@@ -69,10 +64,6 @@ public class DefaultDataContainer implements DataContainer {
    final protected DefaultEvictionListener evictionListener;
    private EvictionManager evictionManager;
    private PassivationManager passivator;
-   private boolean isAsyncStore;
-   private CacheLoaderManager cacheLoaderManager;
-   private Configuration config;
-   private AsyncStore asyncStore;
 
    public DefaultDataContainer(int concurrencyLevel) {
       entries = ConcurrentMapFactory.makeConcurrentMap(128, concurrencyLevel);
@@ -108,19 +99,10 @@ protected DefaultDataContainer(int concurrencyLevel, int maxEntries, EvictionStr
 
    @Inject
    public void initialize(EvictionManager evictionManager, PassivationManager passivator,
-         InternalEntryFactory entryFactory, Configuration config, CacheLoaderManager cacheLoaderManager) {
+         InternalEntryFactory entryFactory) {
       this.evictionManager = evictionManager;
       this.passivator = passivator;
       this.entryFactory = entryFactory;
-      this.config = config;
-      this.cacheLoaderManager = cacheLoaderManager;
-   }
-
-   @Start(priority = 11) // Start after cache loader manager
-   public void start() {
-      this.isAsyncStore = config.loaders().usingAsyncStore();
-      if (isAsyncStore)
-         this.asyncStore = (AsyncStore) cacheLoaderManager.getCacheStore();
    }
 
    public static DataContainer boundedDataContainer(int concurrencyLevel, int maxEntries,
@@ -134,15 +116,7 @@ public static DataContainer unBoundedDataContainer(int concurrencyLevel) {
 
    @Override
    public InternalCacheEntry peek(Object key) {
-      InternalCacheEntry entry = entries.get(key);
-      // If the entry was passivated to an async store, it would have been
-      // marked as 'evicted', so check whether the key has been flushed to
-      // the cache store, and if it has, return null so that it can go through
-      // the activation process.
-      if (entry != null && entry.isEvicted() && isKeyFlushedToStore(key))
-         return null;
-
-      return entry;
+      return entries.get(key);
    }
 
    @Override
@@ -162,7 +136,7 @@ public InternalCacheEntry get(Object k) {
 
    @Override
    public void put(Object k, Object v, EntryVersion version, long lifespan, long maxIdle) {
-      InternalCacheEntry e = peek(k);
+      InternalCacheEntry e = entries.get(k);
       if (e != null) {
          e.setValue(v);
          InternalCacheEntry original = e;
@@ -191,12 +165,7 @@ public boolean containsKey(Object k) {
 
    @Override
    public InternalCacheEntry remove(Object k) {
-      InternalCacheEntry e;
-      if (isAsyncStore) {
-         e = entries.replace(k, new InternalNullEntry(asyncStore));
-      } else {
-         e = entries.remove(k);
-      }
+      InternalCacheEntry e = entries.remove(k);
       return e == null || (e.canExpire() && e.isExpired(System.currentTimeMillis())) ? null : e;
    }
 
@@ -230,24 +199,12 @@ public void purgeExpired() {
       long currentTimeMillis = System.currentTimeMillis();
       for (Iterator<InternalCacheEntry> purgeCandidates = entries.values().iterator(); purgeCandidates.hasNext();) {
          InternalCacheEntry e = purgeCandidates.next();
-         if (isAsyncStore && e instanceof InternalNullEntry) {
-            InternalNullEntry nullEntry = (InternalNullEntry) e;
-            if (nullEntry.isExpired(asyncStore.getAsyncProcessorId())) {
-               purgeCandidates.remove();
-               continue;
-            }
-         }
-
          if (e.isExpired(currentTimeMillis)) {
             purgeCandidates.remove();
          }
       }
    }
 
-   private boolean isKeyFlushedToStore(Object key) {
-      return !isAsyncStore || (isAsyncStore && !asyncStore.isLocked(key));
-   }
-
    @Override
    public Iterator<InternalCacheEntry> iterator() {
       return new EntryIterator(entries.values().iterator());
@@ -261,24 +218,10 @@ public void onEntryEviction(Map<Object, InternalCacheEntry> evicted) {
       }
 
       @Override
-      public boolean onEntryChosenForEviction(InternalCacheEntry entry) {
-         boolean allowEviction = isKeyFlushedToStore(entry.getKey());
-
-         if (allowEviction) {
-            passivator.passivate(entry);
-            if (isAsyncStore) {
-               // Storing in cache store is still in flight, so don't remove
-               // the entry from memory yet. Instead, mark the entry as 'evicted'
-               // and if someone requests it, check whether it's locked on the
-               // cache store. If it's not, assume that the entry was stored
-               // in the async store and the container can return null.
-               entry.setEvicted(true);
-               return false;
-            }
-         }
-
-         return allowEviction;
+      public void onEntryChosenForEviction(InternalCacheEntry entry) {
+         passivator.passivate(entry);
       }
+
    }
 
    private static class ImmutableEntryIterator extends EntryIterator {",2012-10-03T12:24:38Z,25
"@@ -34,7 +34,6 @@
 public abstract class AbstractInternalCacheEntry implements InternalCacheEntry {
 
    protected Object key;
-   private boolean evicted;
 
    protected AbstractInternalCacheEntry() {
    }
@@ -65,7 +64,7 @@ public final void setRemoved(boolean removed) {
 
    @Override
    public final void setEvicted(boolean evicted) {
-      this.evicted = evicted;
+      // no-op
    }
 
    @Override
@@ -95,7 +94,7 @@ public final boolean isRemoved() {
 
    @Override
    public final boolean isEvicted() {
-      return evicted;
+      return true;
    }
 
    @Override",2012-10-03T12:24:38Z,26
"@@ -1,229 +0,0 @@
-/*
- * Copyright 2012 Red Hat, Inc. and/or its affiliates.
- *
- * This is free software; you can redistribute it and/or modify it
- * under the terms of the GNU Lesser General Public License as
- * published by the Free Software Foundation; either version 2.1 of
- * the License, or (at your option) any later version.
- *
- * This software is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with this library; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
- * 02110-1301 USA
- */
-
-package org.infinispan.container.entries;
-
-import org.infinispan.container.DataContainer;
-import org.infinispan.container.versioning.EntryVersion;
-import org.infinispan.loaders.decorators.AsyncStore;
-
-/**
- * Internal null cache entry used to signal that an entry has been removed
- * but it's in the process of being removed from another component,
- * i.e. an async cache store.
- *
- * This entry helps deal with situations where an eventual removal
- * is under way.
- *
- * @author Galder Zamarreño
- * @since 5.2
- */
-public class InternalNullEntry implements InternalCacheEntry {
-
-   private final long asyncProcessorId;
-   private final AsyncStore asyncStore;
-
-   public InternalNullEntry(AsyncStore asyncStore) {
-      this.asyncStore = asyncStore;
-      this.asyncProcessorId = this.asyncStore.getAsyncProcessorId();
-   }
-
-   @Override
-   public boolean isNull() {
-      return false; // not null to avoid cache loader interceptor loading from store
-   }
-
-   @Override
-   public Object getValue() {
-      return this; // set this value to avoid cache loader interceptor
-   }
-
-   @Override
-   public boolean canExpire() {
-      return true;
-   }
-
-   @Override
-   public boolean isExpired(long now) {
-      return asyncStore.getAsyncProcessorId() > asyncProcessorId;
-   }
-
-   @Override
-   public boolean isExpired() {
-      return asyncStore.getAsyncProcessorId() > asyncProcessorId;
-   }
-
-   // Below are non-relevant method implementations
-
-   @Override
-   public boolean isChanged() {
-      return false;
-   }
-
-   @Override
-   public boolean isCreated() {
-      return false;
-   }
-
-   @Override
-   public boolean isRemoved() {
-      return false;
-   }
-
-   @Override
-   public boolean isEvicted() {
-      return false;
-   }
-
-   @Override
-   public boolean isValid() {
-      return false;
-   }
-
-   @Override
-   public Object getKey() {
-      return null;
-   }
-
-   @Override
-   public long getLifespan() {
-      return 0;
-   }
-
-   @Override
-   public long getMaxIdle() {
-      return 0;
-   }
-
-   @Override
-   public void setMaxIdle(long maxIdle) {
-      // Empty
-   }
-
-   @Override
-   public void setLifespan(long lifespan) {
-      // Empty
-   }
-
-   @Override
-   public Object setValue(Object value) {
-      return null;
-   }
-
-   @Override
-   public boolean equals(Object o) {
-      return false;
-   }
-
-   @Override
-   public int hashCode() {
-      return 0;
-   }
-
-   @Override
-   public void commit(DataContainer container, EntryVersion newVersion) {
-      // Empty
-   }
-
-   @Override
-   public void rollback() {
-      // Empty
-   }
-
-   @Override
-   public void setCreated(boolean created) {
-      // Empty
-   }
-
-   @Override
-   public void setRemoved(boolean removed) {
-      // Empty
-   }
-
-   @Override
-   public void setEvicted(boolean evicted) {
-      // Empty
-   }
-
-   @Override
-   public void setValid(boolean valid) {
-      // Empty
-   }
-
-   @Override
-   public boolean isLockPlaceholder() {
-      return false;
-   }
-
-   @Override
-   public boolean undelete(boolean doUndelete) {
-      return false;
-   }
-
-   @Override
-   public long getCreated() {
-      return 0;
-   }
-
-   @Override
-   public long getLastUsed() {
-      return 0;
-   }
-
-   @Override
-   public long getExpiryTime() {
-      return 0;
-   }
-
-   @Override
-   public void touch() {
-      // Empty
-   }
-
-   @Override
-   public void touch(long currentTimeMillis) {
-      // Empty
-   }
-
-   @Override
-   public void reincarnate() {
-      // Empty
-   }
-
-   @Override
-   public InternalCacheValue toInternalCacheValue() {
-      return null;
-   }
-
-   @Override
-   public InternalCacheEntry clone() {
-      return null;
-   }
-
-   @Override
-   public EntryVersion getVersion() {
-      return null;
-   }
-
-   @Override
-   public void setVersion(EntryVersion version) {
-      // Empty
-   }
-
-}",2012-10-03T12:24:38Z,27
"@@ -32,7 +32,6 @@
 import org.infinispan.container.EntryFactory;
 import org.infinispan.container.entries.CacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
-import org.infinispan.container.entries.InternalNullEntry;
 import org.infinispan.container.entries.MVCCEntry;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
@@ -174,9 +173,6 @@ private boolean loadIfNeeded(InvocationContext ctx, Object key, boolean isRetrie
          } else {
             return false;
          }
-      } else if (e instanceof InternalNullEntry) {
-         ctx.putLookedUpEntry(key, null);
-         return false;
       } else {
          return true;
       }",2012-10-03T12:24:38Z,28
"@@ -50,7 +50,6 @@
 import org.infinispan.configuration.cache.StoreConfiguration;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.context.Flag;
-import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.ComponentRegistry;
 import org.infinispan.factories.annotations.ComponentName;
@@ -66,7 +65,6 @@
 import org.infinispan.loaders.decorators.SingletonStoreConfig;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.statetransfer.StateTransferManager;
-import org.infinispan.topology.CacheTopology;
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;",2012-10-03T12:24:38Z,29
"@@ -25,7 +25,7 @@
 import net.jcip.annotations.GuardedBy;
 import org.infinispan.Cache;
 import org.infinispan.CacheException;
-import org.infinispan.config.Configuration;
+import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.loaders.CacheLoaderConfig;
 import org.infinispan.loaders.CacheLoaderException;
@@ -37,43 +37,40 @@
 import org.infinispan.loaders.modifications.Store;
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.transaction.xa.GlobalTransaction;
+import org.infinispan.transaction.xa.TransactionFactory;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
-import org.infinispan.util.concurrent.locks.containers.ReentrantPerEntryLockContainer;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
 
+import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
 import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
 import java.util.concurrent.LinkedBlockingQueue;
 import java.util.concurrent.ThreadFactory;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.atomic.AtomicLong;
-import java.util.concurrent.locks.Lock;
-import java.util.concurrent.locks.ReadWriteLock;
-import java.util.concurrent.locks.ReentrantLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
+import java.util.concurrent.locks.AbstractQueuedSynchronizer;
 
 /**
- * The AsyncStore is a delegating CacheStore that extends AbstractDelegatingStore, overriding methods to that should not
- * just delegate the operation to the underlying store.
+ * The AsyncStore is a delegating CacheStore that buffers changes and writes them asynchronously to
+ * the underlying CacheStore.
  * <p/>
- * Read operations are done synchronously, while write operations are done asynchronously.  There is no provision for
- * exception handling for problems encountered with the underlying store during a write operation, and the exception is
- * just logged.
+ * Read operations are done synchronously, taking into account the current state of buffered changes.
+ * <p/>
+ * There is no provision for exception handling for problems encountered with the underlying store
+ * during a write operation, and the exception is just logged.
  * <p/>
  * When configuring the loader, use the following element:
  * <p/>
  * <code> &lt;async enabled=""true"" /&gt; </code>
  * <p/>
- * to define whether cache loader operations are to be asynchronous.  If not specified, a cache loader operation is
+ * to define whether cache loader operations are to be asynchronous. If not specified, a cache loader operation is
  * assumed synchronous and this decorator is not applied.
  * <p/>
  * Write operations affecting same key are now coalesced so that only the final state is actually stored.
@@ -82,62 +79,43 @@
  * @author Manik Surtani
  * @author Galder Zamarreño
  * @author Sanne Grinovero
+ * @author Karsten Blees
  * @since 4.0
  */
 public class AsyncStore extends AbstractDelegatingStore {
    private static final Log log = LogFactory.getLog(AsyncStore.class);
    private static final boolean trace = log.isTraceEnabled();
    private static final AtomicInteger threadId = new AtomicInteger(0);
-   private final AtomicBoolean stopped = new AtomicBoolean(true);
-   
+
    private final AsyncStoreConfig asyncStoreConfig;
+   private final TransactionFactory txFactory;
    private Map<GlobalTransaction, List<? extends Modification>> transactions;
-   
-   /**
-    * This is used as marker to shutdown the AsyncStoreCoordinator
-    */
-   private static final Modification QUIT_SIGNAL = new Clear();
-   
-   /**
-    * clear() is performed in sync by the one thread of storeCoordinator, while blocking all
-    * other threads interacting with the decorated store.
-    */
-   private final ReadWriteLock clearAllLock = new ReentrantReadWriteLock();
-   private final Lock clearAllReadLock = clearAllLock.readLock();
-   private final Lock clearAllWriteLock = clearAllLock.writeLock();
-   private final Lock stateMapLock = new ReentrantLock();
-   
-   ExecutorService executor;
+
+   private ExecutorService executor;
+   private Thread coordinator;
    private int concurrencyLevel;
-   @GuardedBy(""stateMapLock"")
-   protected ConcurrentMap<Object, Modification> state;
-   private ReleaseAllLockContainer lockContainer;
-   private LinkedBlockingQueue<Modification> changesDeque;
-   public volatile boolean lastAsyncProcessorShutsDownExecutor = false;
    private long shutdownTimeout;
    private String cacheName;
 
-   /**
-    * Identifies each of the asynchronous processor runs. This incrementing
-    * counter can be used to decide whether a phantom null entry in the cache
-    * can be expired or not.
-    */
-   private final AtomicLong asyncProcessorId = new AtomicLong();
+   private BufferLock stateLock;
+   @GuardedBy(""stateLock"")
+   private volatile State state;
 
    public AsyncStore(CacheStore delegate, AsyncStoreConfig asyncStoreConfig) {
       super(delegate);
       this.asyncStoreConfig = asyncStoreConfig;
+      txFactory = new TransactionFactory();
+      txFactory.init(false, false, false, false);
    }
 
    @Override
    public void init(CacheLoaderConfig config, Cache<?, ?> cache, StreamingMarshaller m) throws CacheLoaderException {
       super.init(config, cache, m);
-      changesDeque = new LinkedBlockingQueue<Modification>(asyncStoreConfig.getModificationQueueSize());
-      Configuration cacheCfg = cache != null ? cache.getConfiguration() : null;
-      concurrencyLevel = cacheCfg != null ? cacheCfg.getConcurrencyLevel() : 16;
-      int cacheStopTimeout = cacheCfg != null ? cacheCfg.getCacheStopTimeout() : 30000;
+      Configuration cacheCfg = cache != null ? cache.getCacheConfiguration() : null;
+      concurrencyLevel = cacheCfg != null ? cacheCfg.locking().concurrencyLevel() : 16;
+      long cacheStopTimeout = cacheCfg != null ? cacheCfg.transaction().cacheStopTimeout() : 30000;
       Long configuredAsyncStopTimeout = asyncStoreConfig.getShutdownTimeout();
-      cacheName = cacheCfg != null ? cacheCfg.getName() : null;
+      cacheName = cache != null ? cache.getName() : null;
 
       // Async store shutdown timeout cannot be bigger than
       // the overall cache stop timeout, so limit it accordingly.
@@ -148,308 +126,476 @@ public void init(CacheLoaderConfig config, Cache<?, ?> cache, StreamingMarshalle
          shutdownTimeout = configuredAsyncStopTimeout;
       }
 
-      lockContainer = new ReleaseAllLockContainer(concurrencyLevel);
       transactions = ConcurrentMapFactory.makeConcurrentMap(64, concurrencyLevel);
    }
 
+   private State newState(boolean clear, State next) {
+      ConcurrentMap<Object, Modification> map = ConcurrentMapFactory.makeConcurrentMap(64, concurrencyLevel);
+      return new State(clear, map, next);
+   }
+
+   private void put(Modification mod, int count) {
+      stateLock.writeLock(count);
+      try {
+         state.put(mod);
+      } finally {
+         stateLock.writeUnlock();
+      }
+   }
+
+   @Override
+   public InternalCacheEntry load(Object key) throws CacheLoaderException {
+      Modification mod = state.get(key);
+      if (mod != null) {
+         switch (mod.getType()) {
+            case REMOVE:
+            case CLEAR:
+               return null;
+            case STORE:
+               InternalCacheEntry ice = ((Store) mod).getStoredEntry();
+               if (ice.isExpired())
+                  return null;
+               return ice;
+         }
+      }
+
+      return super.load(key);
+   }
+
+   @Override
+   public boolean containsKey(Object key) throws CacheLoaderException {
+      Modification mod = state.get(key);
+      if (mod != null)
+         return mod.getType() == Modification.Type.STORE;
+
+      return super.containsKey(key);
+   }
+
+   private void loadKeys(State s, Set<Object> exclude, Set<Object> result) throws CacheLoaderException {
+      // if not cleared, get keys from next State or the back-end store
+      if (!s.clear) {
+         State next = s.next;
+         if (next != null)
+            loadKeys(next, exclude, result);
+         else
+            result.addAll(super.loadAllKeys(exclude));
+      }
+
+      // merge keys of the current State
+      for (Modification mod : s.modifications.values()) {
+         switch (mod.getType()) {
+            case STORE:
+               Object key = ((Store) mod).getStoredEntry().getKey();
+               if (exclude == null || !exclude.contains(key))
+                  result.add(key);
+               break;
+            case REMOVE:
+               result.remove(((Remove) mod).getKey());
+               break;
+         }
+      }
+   }
+
+   @Override
+   public Set<Object> loadAllKeys(Set<Object> keysToExclude) throws CacheLoaderException {
+      Set<Object> result = new HashSet<Object>();
+      loadKeys(state, keysToExclude, result);
+      return result;
+   }
+
+   @Override
+   public Set<InternalCacheEntry> loadAll() throws CacheLoaderException {
+      return load(Integer.MAX_VALUE);
+   }
+
    @Override
-   public void store(InternalCacheEntry ed) {
-      enqueue(new Store(ed));
+   public Set<InternalCacheEntry> load(int numEntries) throws CacheLoaderException {
+      Set<InternalCacheEntry> result = new HashSet<InternalCacheEntry>();
+      for (Object key : loadAllKeys(null)) {
+         InternalCacheEntry entry = load(key);
+         if (entry != null) {
+            result.add(entry);
+            if (result.size() == numEntries)
+               return result;
+         }
+      }
+      return result;
+   }
+
+   @Override
+   public void store(InternalCacheEntry entry) {
+      put(new Store(entry), 1);
+   }
+
+   @Override
+   public void clear() {
+      stateLock.writeLock(1);
+      try {
+         state = newState(true, state.next);
+      } finally {
+         stateLock.reset(1);
+         stateLock.writeUnlock();
+      }
    }
 
    @Override
    public boolean remove(Object key) {
-      enqueue(new Remove(key));
+      put(new Remove(key), 1);
       return true;
    }
 
    @Override
-   public void clear() {
-      Clear clear = new Clear();
-      checkNotStopped(); //check we can change the changesDeque
-      changesDeque.clear();
-      enqueue(clear);
+   public void removeAll(Set<Object> keys) throws CacheLoaderException {
+      if (keys != null && !keys.isEmpty()) {
+         List<Modification> mods = new ArrayList<Modification>(keys.size());
+         for (Object key : keys)
+            mods.add(new Remove(key));
+         put(new ModificationsList(mods), mods.size());
+      }
    }
 
    @Override
-   public void prepare(List<? extends Modification> mods, GlobalTransaction tx, boolean isOnePhase) throws CacheLoaderException {
+   public void prepare(List<? extends Modification> mods, GlobalTransaction tx, boolean isOnePhase)
+         throws CacheLoaderException {
       if (isOnePhase) {
          enqueueModificationsList(mods);
       } else {
          transactions.put(tx, mods);
       }
    }
-   
+
    @Override
    public void rollback(GlobalTransaction tx) {
       transactions.remove(tx);
    }
 
    @Override
    public void commit(GlobalTransaction tx) throws CacheLoaderException {
-      List<? extends Modification> list = transactions.remove(tx);
-      enqueueModificationsList(list);
+      enqueueModificationsList(transactions.remove(tx));
    }
-   
-   protected void enqueueModificationsList(List<? extends Modification> mods) {
-      if (mods != null && !mods.isEmpty()) {
-         enqueue(new ModificationsList(mods));
+
+   private void enqueueModificationsList(List<? extends Modification> mods) {
+      // scan backwards to find the last CLEAR (anything before that can be discarded)
+      int i = mods.size() - 1;
+      for (; i >= 0; i--)
+         if (mods.get(i).getType() == Modification.Type.CLEAR)
+            break;
+      // treat CLEAR specially
+      if (i >= 0) {
+         clear();
+         mods = mods.subList(i + 1, mods.size());
       }
+      // put the rest
+      if (!mods.isEmpty())
+         put(new ModificationsList(mods), mods.size());
    }
 
    @Override
    public void start() throws CacheLoaderException {
-      state = newStateMap();
       log.debugf(""Async cache loader starting %s"", this);
-      stopped.set(false);
-      lastAsyncProcessorShutsDownExecutor = false;
+      state = newState(false, null);
+      stateLock = new BufferLock(asyncStoreConfig.getModificationQueueSize());
+
       super.start();
-      int poolSize = asyncStoreConfig.getThreadPoolSize();
-      executor = new ThreadPoolExecutor(poolSize, poolSize, 0L, TimeUnit.MILLISECONDS,
-               // note the use of poolSize+1 as maximum workingQueue together with DiscardPolicy:
-               // this way when a new AsyncProcessor is started unnecessarily we discard it
-               // before it takes locks to perform no work
-               // this way we save memory from the executor queue, CPU, and also avoid
-               // any possible RejectedExecutionException.
-               new LinkedBlockingQueue<Runnable>(poolSize + 1),
-               new ThreadFactory() {
-                  @Override
-                  public Thread newThread(Runnable r) {
-                     Thread t = new Thread(r, ""CoalescedAsyncStore-"" + threadId.getAndIncrement());
-                     t.setDaemon(true);
-                     return t;
-                  }
-               },
-               new ThreadPoolExecutor.DiscardPolicy()
-         );
-      startStoreCoordinator();
-   }
 
-   private void startStoreCoordinator() {
-      ExecutorService storeCoordinator = Executors.newFixedThreadPool(1);
-      storeCoordinator.execute( new AsyncStoreCoordinator() );
-      storeCoordinator.shutdown();
+      int poolSize = asyncStoreConfig.getThreadPoolSize();
+      executor = new ThreadPoolExecutor(0, poolSize, 120L, TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),
+            new ThreadFactory() {
+               @Override
+               public Thread newThread(Runnable r) {
+                  Thread t = new Thread(r, ""AsyncStoreProcessor-"" + cacheName + ""-"" + threadId.getAndIncrement());
+                  t.setDaemon(true);
+                  return t;
+               }
+            });
+      coordinator = new Thread(new AsyncStoreCoordinator(), ""AsyncStoreCoordinator-"" + cacheName);
+      coordinator.setDaemon(true);
+      coordinator.start();
    }
 
    @Override
    public void stop() throws CacheLoaderException {
-      stopped.set(true);
+      stateLock.writeLock(1);
+      state.stopped = true;
+      stateLock.writeUnlock();
       try {
-         changesDeque.put(QUIT_SIGNAL);
-         boolean finished = executor.awaitTermination(shutdownTimeout, TimeUnit.MILLISECONDS);
-         if (!finished) log.error(""Async store executor did not stop properly"");
+         coordinator.join(shutdownTimeout);
+         if (coordinator.isAlive())
+            log.error(""Async store executor did not stop properly"");
       } catch (InterruptedException e) {
          log.interruptedWaitingAsyncStorePush(e);
          Thread.currentThread().interrupt();
       }
       super.stop();
    }
 
-   public boolean isLocked(Object key) {
-      boolean locked = lockContainer.isLocked(key);
-      if (log.isTraceEnabled()) log.tracef(""Key %s is locked? %b"", key, locked);
-      return locked;
+   protected void applyModificationsSync(List<Modification> mods) throws CacheLoaderException {
+      getDelegate().prepare(mods, txFactory.newGlobalTransaction(null, false), true);
    }
 
-   public long getAsyncProcessorId() {
-      return asyncProcessorId.get();
-   }
+   private static class State {
+      private static final Clear CLEAR = new Clear();
+
+      /**
+       * True if the state has been cleared before making modifications.
+       */
+      private final boolean clear;
+
+      /**
+       * Modifications to apply to the back-end CacheStore.
+       */
+      private final ConcurrentMap<Object, Modification> modifications;
+
+      /**
+       * Next state in the chain, initialized in constructor, may be set to <code>null</code>
+       * asynchronously at any time.
+       */
+      private volatile State next;
+
+      /**
+       * True if the CacheStore has been stopped (i.e. this is the last state to process).
+       */
+      private volatile boolean stopped = false;
+
+      /**
+       * Number of worker threads that currently work with this instance.
+       */
+      private CountDownLatch workerThreads;
+
+      private State(boolean clear, ConcurrentMap<Object, Modification> modMap, State next) {
+         this.clear = clear;
+         this.modifications = modMap;
+         this.next = next;
+         if (next != null)
+            stopped = next.stopped;
+      }
 
-   protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
-      Set<Map.Entry<Object, Modification>> entries = mods.entrySet();
-      for (Map.Entry<Object, Modification> entry : entries) {
-         Modification mod = entry.getValue();
+      /**
+       * Gets the Modification for the specified key from this State object or chained (
+       * <code>next</code>) State objects.
+       *
+       * @param key
+       *           the key to look up
+       * @return the Modification for the specified key, or <code>CLEAR</code> if the state was
+       *         cleared, or <code>null</code> if the key is not in the state map
+       */
+      Modification get(Object key) {
+         for (State state = this; state != null; state = state.next) {
+            Modification mod = state.modifications.get(key);
+            if (mod != null)
+               return mod;
+            else if (state.clear)
+               return CLEAR;
+         }
+         return null;
+      }
+
+      /**
+       * Adds the Modification(s) to the state map.
+       *
+       * @param mod
+       *           the Modification to add, supports modification types STORE, REMOVE and LIST
+       */
+      void put(Modification mod) {
+         if (stopped)
+            throw new CacheException(""AsyncStore stopped; no longer accepting more entries."");
          switch (mod.getType()) {
             case STORE:
-               super.store(((Store) mod).getStoredEntry());
+               modifications.put(((Store) mod).getStoredEntry().getKey(), mod);
                break;
             case REMOVE:
-               super.remove(entry.getKey());
+               modifications.put(((Remove) mod).getKey(), mod);
+               break;
+            case LIST:
+               for (Modification m : ((ModificationsList) mod).getList())
+                  put(m);
                break;
             default:
-               throw new IllegalArgumentException(""Unexpected modification type "" + mod.getType());
+               throw new IllegalArgumentException(""Unknown modification type "" + mod.getType());
          }
       }
    }
-   
-   protected boolean applyClear() {
-      try {
-         super.clear();
-         return true;
-      } catch (CacheLoaderException e) {
-         log.errorClearinAsyncStore(e);
-         return false;
-      }
-   }
-   
-   protected void delegatePurgeExpired() {
-      try {
-         super.purgeExpired();
-      } catch (CacheLoaderException e) {
-         log.errorPurgingAsyncStore(e);
-      }
-   }
 
-   private void enqueue(Modification mod) {
-      try {
-         checkNotStopped();
-         if (trace) log.tracef(""Enqueuing modification %s"", mod);
-         changesDeque.put(mod);
-      } catch (Exception e) {
-         throw new CacheException(""Unable to enqueue asynchronous task"", e);
-      }
-   }
+   /**
+    * A custom reader-writer-lock combined with a bounded buffer size counter.
+    * <p/>
+    * Supports multiple concurrent writers and a single exclusive reader. This ensures that no more
+    * data is being written to the current state when the AsyncStoreCoordinator thread hands the
+    * data off to the back-end store.
+    * <p/>
+    * Additionally, {@link #writeLock(int)} blocks if the buffer is full, and {@link #readLock()}
+    * blocks if no data is available.
+    * <p/>
+    * This lock implementation is <em>not</em> reentrant!
+    */
+   private static class BufferLock {
+      /**
+       * AQS state is the number of 'items' in the buffer. AcquireShared blocks if the buffer is
+       * full (>= size).
+       */
+      private static class Counter extends AbstractQueuedSynchronizer {
+         private static final long serialVersionUID = 1688655561670368887L;
+         private final int size;
+
+         Counter(int size) {
+            this.size = size;
+         }
 
-   private void checkNotStopped() {
-      if (stopped.get()) {
-         throw new CacheException(""AsyncStore stopped; no longer accepting more entries."");
-      }
-   }
+         int add(int count) {
+            for (;;) {
+               int state = getState();
+               if (compareAndSetState(state, state + count))
+                  return state + count;
+            }
+         }
 
-   private void acquireLock(Lock lock) {
-      try {
-         if (!lock.tryLock(asyncStoreConfig.getFlushLockTimeout(), TimeUnit.MILLISECONDS))
-            throw new CacheException(""Unable to acquire lock on update map"");
-      } catch (InterruptedException ie) {
-         // restore interrupted status
-         Thread.currentThread().interrupt();
+         protected int tryAcquireShared(int count) {
+            for (;;) {
+               int state = getState();
+               if (state >= size)
+                  return -1;
+               if (compareAndSetState(state, state + count))
+                  return state + count >= size ? 0 : 1;
+            }
+         }
+
+         protected boolean tryReleaseShared(int state) {
+            setState(state);
+            return state < size;
+         }
       }
-   }
 
-   private ConcurrentMap<Object, Modification> newStateMap() {
-      return ConcurrentMapFactory.makeConcurrentMap(64, concurrencyLevel);
-   }
+      /**
+       * AQS state is 0 if no data is available, 1 otherwise. AcquireShared blocks if no data is
+       * available.
+       */
+      private static class Available extends AbstractQueuedSynchronizer {
+         private static final long serialVersionUID = 6464514100313353749L;
 
-   private void ensureMoreWorkIsHandled() {
-      executor.execute(new AsyncProcessor());
-   }
+         protected int tryAcquireShared(int unused) {
+            return getState() > 0 ? 1 : -1;
+         }
 
-   /**
-    * Processes modifications taking the latest updates from a state map.
-    */
-   class AsyncProcessor implements Runnable {
-      private final Set<Object> lockedKeys = new HashSet<Object>();
-      boolean runAgainAfterWaiting = false;
+         protected boolean tryReleaseShared(int state) {
+            setState(state > 0 ? 1 : 0);
+            return state > 0;
+         }
+      }
 
-      @Override
-      public void run() {
-         LogFactory.pushNDC(cacheName, trace);
-         try {
-            clearAllReadLock.lock();
-            try {
-               innerRun();
-            } catch (Throwable t) {
-               runAgainAfterWaiting = false;
-               log.unexpectedErrorInAsyncProcessor(t);
-            } finally {
-               clearAllReadLock.unlock();
+      /**
+       * Minimal non-reentrant read-write-lock. AQS state is number of concurrent shared locks, or 0
+       * if unlocked, or -1 if locked exclusively.
+       */
+      private static class Sync extends AbstractQueuedSynchronizer {
+         private static final long serialVersionUID = 2983687000985096017L;
+
+         protected boolean tryAcquire(int unused) {
+            if (!compareAndSetState(0, -1))
+               return false;
+            setExclusiveOwnerThread(Thread.currentThread());
+            return true;
+         }
+
+         protected boolean tryRelease(int unused) {
+            setExclusiveOwnerThread(null);
+            setState(0);
+            return true;
+         }
+
+         protected int tryAcquireShared(int unused) {
+            for (;;) {
+               int state = getState();
+               if (state < 0)
+                  return -1;
+               if (compareAndSetState(state, state + 1))
+                  return 1;
             }
-            if (runAgainAfterWaiting) {
-               try {
-                  Thread.sleep(10);
-               } catch (InterruptedException e) {
-                  // just speedup ignoring more sleep but still make sure to store all data
-               }
-               ensureMoreWorkIsHandled();
+         }
+
+         protected boolean tryReleaseShared(int unused) {
+            for (;;) {
+               int state = getState();
+               if (compareAndSetState(state, state - 1))
+                  return true;
             }
-         } finally {
-            LogFactory.popNDC(trace);
          }
       }
-      
-      private void innerRun() {
-         final ConcurrentMap<Object, Modification> swap;
-         if (trace) log.trace(""Checking for modifications"");
-         try {
-            acquireLock(stateMapLock);
-            try {
-               swap = state;
-               state = newStateMap();
-
-               // This needs to be done within the stateMapLock section, because if a key is in use,
-               // we need to put it back in the state
-               // map for later processing and we don't wanna do it in such way that we override a
-               // newer value that might
-               // have been taken already for processing by another instance of this same code.
-               // AsyncStoreCoordinator doesn't need to acquired the same lock as values put by it
-               // will never be overwritten (putIfAbsent below)
-               for (Object key : swap.keySet()) {
-                  if (trace) log.tracef(""Going to process mod key: %s"", key);
-                  boolean acquired;
-                  try {
-                     acquired = lockContainer.acquireLock(null, key, 0, TimeUnit.NANOSECONDS) != null;
-                  } catch (InterruptedException e) {
-                     log.interruptedAcquiringLock(0, e);
-                     Thread.currentThread().interrupt();
-                     return;
-                  }
-                  if (trace)
-                     log.tracef(""Lock for key %s was acquired=%s"", key, acquired);
-                  if (!acquired) {
-                     Modification prev = swap.remove(key);
-                     Modification didPut = state.putIfAbsent(key, prev); // don't overwrite more recently put work
-                     if (didPut == null) {
-                        // otherwise a new job is being spawned by the arbiter, so no need to create
-                        // a new worker
-                        runAgainAfterWaiting = true;
-                     }
-                  } else {
-                     lockedKeys.add(key);
-                  }
-               }
-            } finally {
-               stateMapLock.unlock();
-            }
 
-            if (swap.isEmpty()) {
-               if (lastAsyncProcessorShutsDownExecutor && !runAgainAfterWaiting) {
-                  executor.shutdown();
-               }
-            } else {
-               if (trace)
-                  log.tracef(""Apply %s modifications"", swap.size());
-               int maxRetries = 3;
-               int attemptNumber = 0;
-               boolean successful;
-               do {
-                  if (attemptNumber > 0 && log.isDebugEnabled())
-                     log.debugf(""Retrying due to previous failure. %s attempts left."", maxRetries - attemptNumber);
-                  successful = put(swap);
-                  attemptNumber++;
-               } while (!successful && attemptNumber <= maxRetries);
-
-               if (!successful)
-                  log.unableToProcessAsyncModifications(maxRetries);
+      private final Sync sync;
+      private final Counter counter;
+      private final Available available;
+
+      /**
+       * Create a new BufferLock with the specified buffer size.
+       *
+       * @param size
+       *           the buffer size
+       */
+      BufferLock(int size) {
+         sync = new Sync();
+         counter = size > 0 ? new Counter(size) : null;
+         available = new Available();
+      }
 
-            }
-         } finally {
-            lockContainer.releaseLocks(lockedKeys);
-            lockedKeys.clear();
-            asyncProcessorId.incrementAndGet();
-         }
+      /**
+       * Acquires the write lock and consumes the specified amount of buffer space. Blocks if the
+       * buffer is full or if the object is currently locked for reading.
+       *
+       * @param count
+       *           number of items the caller intends to write
+       */
+      void writeLock(int count) {
+         if (counter != null)
+            counter.acquireShared(count);
+         sync.acquireShared(1);
       }
 
-      boolean put(ConcurrentMap<Object, Modification> mods) {
-         try {
-            AsyncStore.this.applyModificationsSync(mods);
-            return true;
-         } catch (Exception e) {
-            if (log.isDebugEnabled()) log.debug(""Failed to process async modifications"", e);
-            return false;
-         }
+      /**
+       * Releases the write lock.
+       */
+      void writeUnlock() {
+         sync.releaseShared(1);
+         available.releaseShared(1);
       }
-   }
 
-   private static class ReleaseAllLockContainer extends ReentrantPerEntryLockContainer {
-      private ReleaseAllLockContainer(int concurrencyLevel) {
-         super(concurrencyLevel);
+      /**
+       * Acquires the read lock. Blocks if the buffer is empty or if the object is currently locked
+       * for writing.
+       */
+      void readLock() {
+         available.acquireShared(1);
+         sync.acquire(1);
       }
 
-      void releaseLocks(Set<Object> keys) {
-         for (Object key : keys) {
-            if (trace) log.tracef(""Release lock for key %s"", key);
-            releaseLock(null, key);
-         }
+      /**
+       * Releases the read lock.
+       */
+      void readUnlock() {
+         sync.release(1);
+      }
+
+      /**
+       * Resets the buffer counter to the specified number.
+       *
+       * @param count
+       *           number of available items in the buffer
+       */
+      void reset(int count) {
+         if (counter != null)
+            counter.releaseShared(count);
+         available.releaseShared(count);
+      }
+
+      /**
+       * Modifies the buffer counter by the specified value.
+       *
+       * @param count
+       *           number of items to add to the buffer counter
+       */
+      void add(int count) {
+         if (counter != null)
+            count = counter.add(count);
+         available.releaseShared(count);
       }
    }
 
@@ -459,106 +605,118 @@ private class AsyncStoreCoordinator implements Runnable {
       public void run() {
          LogFactory.pushNDC(cacheName, trace);
          try {
-            while (true) {
+            for (;;) {
+               State s, head, tail;
+               stateLock.readLock();
                try {
-                  Modification take = changesDeque.take();
-                  if (take == QUIT_SIGNAL) {
-                     lastAsyncProcessorShutsDownExecutor = true;
-                     ensureMoreWorkIsHandled();
-                     return;
+                  s = state;
+                  tail = s.next;
+                  assert tail == null || tail.next == null : ""State chain longer than 3 entries!"";
+                  state = head = newState(false, s);
+               } finally {
+                  stateLock.reset(0);
+                  stateLock.readUnlock();
+               }
+
+               try {
+                  if (s.clear) {
+                     // clear() must be called synchronously, wait until background threads are done
+                     if (tail != null)
+                        tail.workerThreads.await();
+                     getDelegate().clear();
                   }
-                  else {
-                     handleSafely(take);
+
+                  List<Modification> mods;
+                  if (tail != null) {
+                     // if there's work in progress, push-back keys that are still in use to the head state
+                     mods = new ArrayList<Modification>();
+                     for (Map.Entry<Object, Modification> e : s.modifications.entrySet()) {
+                        if (!tail.modifications.containsKey(e.getKey()))
+                           mods.add(e.getValue());
+                        else {
+                           if (!head.clear && head.modifications.putIfAbsent(e.getKey(), e.getValue()) == null)
+                              stateLock.add(1);
+                           s.modifications.remove(e.getKey());
+                        }
+                     }
+                  } else {
+                     mods = new ArrayList<Modification>(s.modifications.values());
+                  }
+
+                  // distribute modifications evenly across worker threads
+                  int threads = Math.min(mods.size(), asyncStoreConfig.getThreadPoolSize());
+                  s.workerThreads = new CountDownLatch(threads);
+                  if (threads > 0) {
+                     // schedule background threads
+                     int start = 0;
+                     int quotient = mods.size() / threads;
+                     int remainder = mods.size() % threads;
+                     for (int i = 0; i < threads; i++) {
+                        int end = start + quotient + (i < remainder ? 1 : 0);
+                        executor.execute(new AsyncStoreProcessor(mods.subList(start, end), s));
+                        start = end;
+                     }
+                     assert start == mods.size() : ""Thread distribution is broken!"";
+                  }
+
+                  // wait until background threads of previous round are done
+                  if (tail != null) {
+                     tail.workerThreads.await();
+                     s.next = null;
                   }
-               } catch (InterruptedException e) {
-                  log.asyncStoreCoordinatorInterrupted(e);
-                  return;
-               } catch (Throwable t) {
-                  log.unexpectedErrorInAsyncStoreCoordinator(t);
+
+                  // if this is the last state to process, wait for background threads, then quit
+                  if (s.stopped) {
+                     s.workerThreads.await();
+                     return;
+                  }
+               } catch (Exception e) {
+                  if (log.isDebugEnabled())
+                     log.debug(""Failed to process async modifications"", e);
                }
             }
          } finally {
             LogFactory.popNDC(trace);
          }
       }
+   }
 
-      private void handleSafely(Modification mod) {
-         try {
-            if (trace) log.tracef(""taking from modification queue: %s"", mod);
-            handle(mod, false);
-         } catch (Exception e) {
-            log.errorModifyingAsyncStore(e);
-         }
-      }
+   private class AsyncStoreProcessor implements Runnable {
+      private final List<Modification> modifications;
+      private final State myState;
 
-      private void handle(Modification mod, boolean nested) {
-         boolean asyncProcessorNeeded = false;
-         switch (mod.getType()) {
-            case STORE:
-               Store store = (Store) mod;
-               stateMapLock.lock();
-               state.put(store.getStoredEntry().getKey(), store);
-               stateMapLock.unlock();
-               asyncProcessorNeeded = true;
-               break;
-            case REMOVE:
-               Remove remove = (Remove) mod;
-               stateMapLock.lock();
-               state.put(remove.getKey(), remove);
-               stateMapLock.unlock();
-               asyncProcessorNeeded = true;
-               break;
-            case CLEAR:
-               performClear();
-               break;
-            case PURGE_EXPIRED:
-               delegatePurgeExpired();
-               break;
-            case LIST:
-               applyModificationsList((ModificationsList) mod);
-               asyncProcessorNeeded = true;
-               break;
-            default:
-               throw new IllegalArgumentException(""Unexpected modification type "" + mod.getType());
-         }
-         if (asyncProcessorNeeded && !nested) {
-            // we know when it's possible for some work to be done, starting short-lived
-            // AsyncProcessor(s) simplifies shutdown process.
-             ensureMoreWorkIsHandled();
-         }
+      AsyncStoreProcessor(List<Modification> modifications, State myState) {
+         this.modifications = modifications;
+         this.myState = myState;
       }
 
-      private void applyModificationsList(ModificationsList mod) {
-         for (Modification m : mod.getList()) {
-            handle(m, true);
-         }
+      @Override
+      public void run() {
+         // try 3 times to store the modifications
+         retryWork(3);
+
+         // decrement active worker threads and disconnect myState if this was the last one
+         myState.workerThreads.countDown();
+         if (myState.workerThreads.getCount() == 0)
+            for (State s = state; s != null; s = s.next)
+               if (s.next == myState)
+                  s.next = null;
       }
 
-      private void performClear() {
-         state.clear(); // cancel any other scheduled changes
-         clearAllWriteLock.lock(); // ensure no other tasks concurrently working
-         try {
-            // to acquire clearAllWriteLock we might have had to wait for N AsyncProcessor to have finished
-            // (as they have to release all clearAllReadLock),
-            // so as they might have put back some work to the state map, clear the state map again inside the writeLock:
-            state.clear();
-            if (trace) log.trace(""Performed clear operation"");
-            int maxRetries = 3;
-            int attemptNumber = 0;
-            boolean successful = false;
-            do {
-               if (attemptNumber > 0 && log.isDebugEnabled())
-                  log.debugf(""Retrying clear() due to previous failure. %s attempts left."", maxRetries - attemptNumber);
-               successful = applyClear();
-               attemptNumber++;
-            } while (!successful && attemptNumber <= maxRetries);
-            if (!successful) {
-               log.unableToClearAsyncStore();
+      private void retryWork(int maxRetries) {
+         for (int attempt = 0; attempt < maxRetries; attempt++) {
+            if (attempt > 0 && log.isDebugEnabled())
+               log.debugf(""Retrying due to previous failure. %s attempts left."", maxRetries - attempt);
+
+            try {
+               AsyncStore.this.applyModificationsSync(modifications);
+               return;
+            } catch (Exception e) {
+               if (log.isDebugEnabled())
+                  log.debug(""Failed to process async modifications"", e);
             }
-         } finally {
-            clearAllWriteLock.unlock();
          }
+         log.unableToProcessAsyncModifications(maxRetries);
       }
-
    }
-}
+}
\ No newline at end of file",2012-10-03T12:24:38Z,30
"@@ -26,9 +26,11 @@
 import java.util.Collection;
 import java.util.Collections;
 import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.NoSuchElementException;
+import java.util.Set;
 
 import static java.util.Collections.singletonMap;
 import static java.util.Collections.unmodifiableMap;
@@ -165,4 +167,20 @@ public static <K, V, E> Map<K, V> transformCollectionToMap(Collection<E> input,
          return unmodifiableMap(map);
       }
    }
+
+   /**
+    * Returns the elements that are present in s1 but which are not present
+    * in s2, without changing the contents of neither s1, nor s2.
+    *
+    * @param s1 first set
+    * @param s2 second set
+    * @param <E> type of objects in Set
+    * @return the elements in s1 that are not in s2
+    */
+   public static <E> Set<E> difference(Set<E> s1, Set<E> s2) {
+      Set<E> copy1 = new HashSet<E>(s1);
+      copy1.removeAll(new HashSet<E>(s2));
+      return copy1;
+   }
+
 }",2012-10-03T12:24:38Z,31
"@@ -295,18 +295,7 @@ public interface EvictionListener<K, V> {
 
       void onEntryEviction(Map<K, V> evicted);
 
-      /**
-       * Callback when an entry has been selected for eviction.
-       * Implementations can use this method to make a decision on whether the
-       * evicted entry should really be evicted, and they can use the return
-       * of this method to signal that.
-       *
-       * @param internalCacheEntry
-       * @return true if the eviction should go through, false if the
-       * eviction process should halt.
-       */
-      boolean onEntryChosenForEviction(V internalCacheEntry);
-
+      void onEntryChosenForEviction(V internalCacheEntry);
    }
 
    static final class NullEvictionListener<K, V> implements EvictionListener<K, V> {
@@ -315,9 +304,8 @@ public void onEntryEviction(Map<K, V> evicted) {
          // Do nothing.
       }
       @Override
-      public boolean onEntryChosenForEviction(V internalCacheEntry) {
+      public void onEntryChosenForEviction(V internalCacheEntry) {
          // Do nothing.
-         return false;
       }
    }
 
@@ -530,11 +518,9 @@ protected boolean removeEldestEntry(Map.Entry<HashEntry<K,V>,V> eldest){
          boolean aboveThreshold = isAboveThreshold();
          if(aboveThreshold){
             HashEntry<K, V> evictedEntry = eldest.getKey();
-            boolean evict = segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
-            if (evict) {
-               segment.remove(evictedEntry.key, evictedEntry.hash, null);
-               evicted.add(evictedEntry);
-            }
+            segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
+            segment.remove(evictedEntry.key, evictedEntry.hash, null);
+            evicted.add(evictedEntry);
          }
          return aboveThreshold;
       }
@@ -608,11 +594,9 @@ public void addAndRemoveEldest(HashEntry<K, V> entry) {
             LRUHashEntry<K, V> evictedEntry = head.nextEntry;
             //remove eldest entry from doubly-linked list
             head.nextEntry.remove();
-            boolean evict = segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
-            if (evict) {
-               segment.remove(evictedEntry.key, evictedEntry.hash, null);
-               evicted.add(evictedEntry);
-            }
+            segment.evictionListener.onEntryChosenForEviction(evictedEntry.value);
+            segment.remove(evictedEntry.key, evictedEntry.hash, null);
+            evicted.add(evictedEntry);
          }
       }
 
@@ -1231,9 +1215,10 @@ public Set<HashEntry<K, V>> onEntryMiss(HashEntry<K, V> en) {
       private void removeFromSegment(Set<HashEntry<K, V>> evicted) {
          for (HashEntry<K, V> e : evicted) {
             ((LIRSHashEntry<K, V>)e).evict();
-            boolean evict = segment.evictionListener.onEntryChosenForEviction(e.value);
-            if (evict)
-               segment.remove(e.key, e.hash, null);
+//            boolean evict =
+            segment.evictionListener.onEntryChosenForEviction(e.value);
+//            if (evict)
+            segment.remove(e.key, e.hash, null);
          }
       }
 ",2012-10-03T12:24:38Z,32
"@@ -23,7 +23,6 @@
 package org.infinispan.config;
 
 import org.infinispan.AdvancedCache;
-import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.container.DataContainer;
 import org.infinispan.container.DefaultDataContainer;
 import org.infinispan.container.InternalEntryFactoryImpl;
@@ -79,8 +78,7 @@ public void testCustomDataContainerClass() throws IOException {
          AdvancedCache<Object, Object> cache = cm.getCache().getAdvancedCache();
 
          DataContainer ddc = DefaultDataContainer.unBoundedDataContainer(cache.getConfiguration().getConcurrencyLevel());
-         ((DefaultDataContainer) ddc).initialize(null, null,new InternalEntryFactoryImpl(),
-               new ConfigurationBuilder().build(), null);
+         ((DefaultDataContainer) ddc).initialize(null, null,new InternalEntryFactoryImpl());
          QueryableDataContainer.setDelegate(ddc);
 
          // Verify that the default is correctly established
@@ -113,8 +111,7 @@ public void testCustomDataContainer() {
          AdvancedCache<Object, Object> cache = cm.getCache().getAdvancedCache();
 
          DataContainer ddc = DefaultDataContainer.unBoundedDataContainer(cache.getConfiguration().getConcurrencyLevel());
-         ((DefaultDataContainer) ddc).initialize(
-               null, null,new InternalEntryFactoryImpl(), new ConfigurationBuilder().build(), null);
+         ((DefaultDataContainer) ddc).initialize(null, null,new InternalEntryFactoryImpl());
          QueryableDataContainer.setDelegate(ddc);
 
          // Verify that the config is correct",2012-10-03T12:24:38Z,33
"@@ -22,7 +22,6 @@
  */
 package org.infinispan.container;
 
-import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.container.entries.ImmortalCacheEntry;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.container.entries.MortalCacheEntry;
@@ -56,8 +55,7 @@ public void tearDown() {
 
    protected DataContainer createContainer() {
       DefaultDataContainer dc = new DefaultDataContainer(16);
-      dc.initialize(null, null, new InternalEntryFactoryImpl(),
-            new ConfigurationBuilder().build(), null);
+      dc.initialize(null, null, new InternalEntryFactoryImpl());
       return dc;
    }
 ",2012-10-03T12:24:38Z,34
"@@ -0,0 +1,297 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+package org.infinispan.loaders.decorators;
+
+import java.util.concurrent.locks.ReentrantLock;
+
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.configuration.cache.StoreConfigurationBuilder;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.eviction.EvictionStrategy;
+import org.infinispan.loaders.CacheLoaderConfig;
+import org.infinispan.loaders.CacheLoaderMetadata;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.test.CacheManagerCallable;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.test.fwk.TestCacheManagerFactory;
+
+import org.testng.annotations.Test;
+
+@Test(groups = ""unit"", testName = ""loaders.decorators.AsyncTest"")
+public class AsyncStoreEvictionTest {
+
+   // set to false to fix all the tests
+   private static final boolean USE_ASYNC_STORE = true;
+
+   private static ConfigurationBuilder config(boolean passivation, int threads) {
+      ConfigurationBuilder config = new ConfigurationBuilder();
+      config.expiration().wakeUpInterval(100);
+      config.eviction().maxEntries(1).strategy(EvictionStrategy.LRU);
+      StoreConfigurationBuilder store = config.loaders().passivation(passivation).addStore().cacheStore(new LockableCacheStore());
+      if (USE_ASYNC_STORE)
+         store.async().enable().threadPoolSize(threads);
+      return config;
+   }
+
+   private final static ThreadLocal<LockableCacheStore> STORE = new ThreadLocal<LockableCacheStore>();
+
+   public static class LockableCacheStoreConfig extends DummyInMemoryCacheStore.Cfg {
+      private static final long serialVersionUID = 1L;
+
+      public LockableCacheStoreConfig() {
+         setCacheLoaderClassName(LockableCacheStore.class.getName());
+      }
+   }
+
+   @CacheLoaderMetadata(configurationClass = LockableCacheStoreConfig.class)
+   public static class LockableCacheStore extends DummyInMemoryCacheStore {
+      private final ReentrantLock lock = new ReentrantLock();
+
+      public LockableCacheStore() {
+         super();
+         STORE.set(this);
+      }
+
+      @Override
+      public Class<? extends CacheLoaderConfig> getConfigurationClass() {
+         return LockableCacheStoreConfig.class;
+      }
+
+      @Override
+      public void store(InternalCacheEntry ed) {
+         lock.lock();
+         try {
+            super.store(ed);
+         } finally {
+            lock.unlock();
+         }
+      }
+
+      @Override
+      public boolean remove(Object key) {
+         lock.lock();
+         try {
+            return super.remove(key);
+         } finally {
+            lock.unlock();
+         }
+      }
+   }
+
+   private static abstract class CacheCallable extends CacheManagerCallable {
+      protected final Cache<String, String> cache;
+      protected final LockableCacheStore store;
+
+      CacheCallable(ConfigurationBuilder builder) {
+         super(TestCacheManagerFactory.createCacheManager(builder));
+         cache = cm.getCache();
+         store = STORE.get();
+      }
+   }
+
+   public void testEndToEndEvictionPassivation() throws Exception {
+      testEndToEndEviction(true);
+   }
+   public void testEndToEndEviction() throws Exception {
+      testEndToEndEviction(false);
+   }
+   private void testEndToEndEviction(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(passivation, 1)) {
+         @Override
+         public void call() {
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.put(""k1"", ""v1"");
+               cache.put(""k2"", ""v2""); // force eviction of ""k1""
+               TestingUtil.sleepThread(100); // wait until the only AsyncProcessor thread is blocked
+               cache.put(""k3"", ""v3"");
+               cache.put(""k4"", ""v4""); // force eviction of ""k3""
+
+               assert ""v3"".equals(cache.get(""k3"")) : ""cache must return k3 == v3 (was: "" + cache.get(""k3"") + "")"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testEndToEndUpdatePassivation() throws Exception {
+      testEndToEndUpdate(true);
+   }
+   public void testEndToEndUpdate() throws Exception {
+      testEndToEndUpdate(false);
+   }
+   private void testEndToEndUpdate(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(passivation, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v0"");
+            cache.put(""k2"", ""v2""); // force eviction of ""k1""
+
+            // wait for k1 == v1 to appear in store
+            while (store.load(""k1"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.put(""k3"", ""v3"");
+               cache.put(""k4"", ""v4""); // force eviction of ""k3""
+               TestingUtil.sleepThread(100); // wait until the only AsyncProcessor thread is blocked
+               cache.put(""k1"", ""v1"");
+               cache.put(""k5"", ""v5""); // force eviction of ""k1""
+
+               assert ""v1"".equals(cache.get(""k1"")) : ""cache must return k1 == v1 (was: "" + cache.get(""k1"") + "")"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testEndToEndRemovePassivation() throws Exception {
+      testEndToEndRemove(true);
+   }
+   public void testEndToEndRemove() throws Exception {
+      testEndToEndRemove(false);
+   }
+   private void testEndToEndRemove(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(passivation, 2)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2""); // force eviction of ""k1""
+
+            // wait for ""k1"" to appear in store
+            while (store.load(""k1"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.remove(""k1"");
+               TestingUtil.sleepThread(100); // wait until the first AsyncProcessor thread is blocked
+               cache.remove(""k1""); // make second AsyncProcessor thread burn asyncProcessorIds
+               TestingUtil.sleepThread(200); // wait for reaper to collect InternalNullEntry
+
+               assert null == cache.get(""k1"") : ""cache must return k1 == null (was: "" + cache.get(""k1"") + "")"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testNPE() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.remove(""k1"");
+            // this causes NPE in AsyncStore.isLocked(InternalNullEntry.getKey())
+            cache.put(""k2"", ""v2"");
+         }
+      });
+   }
+
+   public void testLIRS() throws Exception {
+      ConfigurationBuilder config = config(false, 1);
+      config.eviction().strategy(EvictionStrategy.LIRS).maxEntries(1);
+      TestingUtil.withCacheManager(new CacheCallable(config) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2"");
+            cache.put(""k1"", ""v3"");
+            cache.put(""k2"", ""v4"");
+            cache.put(""k3"", ""v3"");
+            cache.put(""k4"", ""v4"");
+         }
+      });
+   }
+
+   public void testSize() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2"");
+
+            assert cache.size() == 1 : ""cache size must be 1, was: "" + cache.size();
+         }
+      });
+   }
+
+   public void testSizeAfterExpiration() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.put(""k2"", ""v2"");
+            TestingUtil.sleepThread(200);
+
+            assert !(cache.size() == 2) : ""expiry doesn't work even after expiration"";
+         }
+      });
+   }
+
+   public void testSizeAfterEvict() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.evict(""k1"");
+
+            assert cache.size() == 0 : ""cache size must be 0, was: "" + cache.size();
+         }
+      });
+   }
+
+   public void testSizeAfterRemove() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.remove(""k1"");
+
+            assert cache.size() == 0 : ""cache size must be 0, was: "" + cache.size();
+         }
+      });
+   }
+
+   public void testSizeAfterRemoveAndExpiration() throws Exception {
+      TestingUtil.withCacheManager(new CacheCallable(config(false, 1)) {
+         @Override
+         public void call() {
+            cache.put(""k1"", ""v1"");
+            cache.remove(""k1"");
+            int size = cache.size();
+            TestingUtil.sleepThread(200);
+
+            assert !(size == 1 && cache.size() == 0) : ""remove only works after expiration"";
+         }
+      });
+   }
+}",2012-10-03T12:24:38Z,35
"@@ -35,6 +35,7 @@
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStoreConfigurationBuilder;
 import org.infinispan.loaders.modifications.Modification;
+import org.infinispan.loaders.modifications.Remove;
 import org.infinispan.loaders.modifications.Store;
 import org.infinispan.test.CacheManagerCallable;
 import org.infinispan.test.TestingUtil;
@@ -44,9 +45,9 @@
 import org.testng.annotations.Test;
 
 import java.util.Collection;
+import java.util.List;
 import java.util.Map;
 import java.util.Set;
-import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;
 import java.util.concurrent.TimeUnit;
 
@@ -249,11 +250,11 @@ public MockAsyncStore(CountDownLatch modApplyLatch, CountDownLatch lockedWaitLat
       }
 
       @Override
-      protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
+      protected void applyModificationsSync(List<Modification> mods)
             throws CacheLoaderException {
          try {
             // Wait for signal to do the modification
-            if (mods.containsKey(1) && !isSkip(mods.get(1))) {
+            if (containsModificationForKey(1, mods) && !isSkip(findModificationForKey(1, mods))) {
                log.tracef(""Wait to apply modifications: %s"", mods);
                lockedWaitLatch.countDown();
                modApplyLatch.await(60, TimeUnit.SECONDS);
@@ -265,6 +266,30 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          }
       }
 
+      private boolean containsModificationForKey(Object key, List<Modification> mods) {
+         return findModificationForKey(key, mods) != null;
+      }
+
+      private Modification findModificationForKey(Object key, List<Modification> mods) {
+         for (Modification modification : mods) {
+            switch (modification.getType()) {
+               case STORE:
+                  Store store = (Store) modification;
+                  if (store.getStoredEntry().getKey().equals(key))
+                     return store;
+                  break;
+               case REMOVE:
+                  Remove remove = (Remove) modification;
+                  if (remove.getKey().equals(key))
+                     return remove;
+                  break;
+               default:
+                  return null;
+            }
+         }
+         return null;
+      }
+
       private boolean isSkip(Modification mod) {
          if (mod instanceof Store) {
             InternalCacheEntry storedEntry = ((Store) mod).getStoredEntry();",2012-10-03T12:24:38Z,36
"@@ -22,18 +22,23 @@
  */
 package org.infinispan.loaders.decorators;
 
+import org.infinispan.Cache;
 import org.infinispan.CacheException;
 import org.infinispan.container.entries.InternalCacheEntry;
 import org.infinispan.test.fwk.TestCacheManagerFactory;
 import org.infinispan.test.fwk.TestInternalCacheEntryFactory;
+import org.infinispan.loaders.CacheLoaderConfig;
 import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.CacheLoaderMetadata;
 import org.infinispan.loaders.CacheStore;
 import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
 import org.infinispan.loaders.modifications.Clear;
 import org.infinispan.loaders.modifications.Modification;
 import org.infinispan.loaders.modifications.Remove;
 import org.infinispan.loaders.modifications.Store;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
 import org.infinispan.test.AbstractInfinispanTest;
+import org.infinispan.test.CacheManagerCallable;
 import org.infinispan.test.TestingUtil;
 import org.infinispan.transaction.xa.GlobalTransaction;
 import org.infinispan.transaction.xa.TransactionFactory;
@@ -46,7 +51,6 @@
 import java.lang.reflect.Method;
 import java.util.ArrayList;
 import java.util.List;
-import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.CountDownLatch;
@@ -55,6 +59,7 @@
 import java.util.concurrent.TimeUnit;
 import java.util.concurrent.TimeoutException;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.locks.ReentrantLock;
 
 import static org.infinispan.test.TestingUtil.k;
 import static org.infinispan.test.TestingUtil.v;
@@ -168,6 +173,8 @@ public void testThreadSafetyWritingDiffValuesForKey(Method m) throws Exception {
    }
 
    public void testTransactionalModificationsHappenInDiffThread(Method m) throws Exception {
+      final int waitTimeout = 10;
+      final TimeUnit waitUnit = TimeUnit.SECONDS;
       try {
          final TransactionFactory gtf = new TransactionFactory();
          gtf.init(false, false, true, false);
@@ -177,19 +184,30 @@ public void testTransactionalModificationsHappenInDiffThread(Method m) throws Ex
          DummyInMemoryCacheStore underlying = new DummyInMemoryCacheStore();
          store = new AsyncStore(underlying, asyncConfig) {
             @Override
-            protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
-               for (Map.Entry<Object, Modification> entry : mods.entrySet()) {
-                  localMods.put(entry.getKey(), entry.getValue());
-               }
+            protected void applyModificationsSync(List<Modification> mods) throws CacheLoaderException {
+               for (Modification mod : mods)
+                  localMods.put(getKey(mod), mod);
+
                super.applyModificationsSync(mods);
                try {
-                  barrier.await(5, TimeUnit.SECONDS);
+                  barrier.await(waitTimeout, waitUnit);
                } catch (TimeoutException e) {
                   assert false : ""Timed out applying for modifications"";
                } catch (Exception e) {
                   throw new CacheLoaderException(""Barrier failed"", e);
                }
             }
+
+            private Object getKey(Modification modification) {
+               switch (modification.getType()) {
+                  case STORE:
+                     return ((Store) modification).getStoredEntry().getKey();
+                  case REMOVE:
+                     return ((Remove) modification).getKey();
+                  default:
+                     return null;
+               }
+            }
          };
          dummyCfg = new DummyInMemoryCacheStore.Cfg();
          dummyCfg.setStoreName(m.getName());
@@ -208,7 +226,8 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert !store.containsKey(k2);
 
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit); // Wait for store
+         barrier.await(waitTimeout, waitUnit); // Wait for remove
          assert store.load(k2).getValue().equals(v2);
          assert !store.containsKey(k1);
          assert 2 == localMods.size();
@@ -221,6 +240,8 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
    }
 
    public void testTransactionalModificationsAreCoalesced(Method m) throws Exception {
+      final int waitTimeout = 10;
+      final TimeUnit waitUnit = TimeUnit.SECONDS;
       try {
          final TransactionFactory gtf = new TransactionFactory();
          gtf.init(false, false, true, false);
@@ -251,10 +272,12 @@ public void clear() {
          };
          store = new AsyncStore(underlying, asyncConfig) {
             @Override
-            protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
+            protected void applyModificationsSync(List<Modification> mods)
+                  throws CacheLoaderException {
                super.applyModificationsSync(mods);
                try {
-                  barrier.await(5, TimeUnit.SECONDS);
+                  log.tracef(""Wait to apply modifications: %s"", mods);
+                  barrier.await(waitTimeout, waitUnit);
                } catch (TimeoutException e) {
                   assert false : ""Timed out applying for modifications"";
                } catch (Exception e) {
@@ -280,7 +303,9 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS); //modifications applied all at once
+         log.tracef(""Wait for modifications to be queued: %s"", mods);
+         barrier.await(waitTimeout, waitUnit); // Wait for single store to be applied
+         barrier.await(waitTimeout, waitUnit); // Wait for single remove to be applied
          assert 1 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 1 == removeCount.get();
          assert 0 == clearCount.get();
@@ -301,7 +326,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit);
          assert 0 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 1 == removeCount.get();
          assert 1 == clearCount.get();
@@ -322,7 +347,9 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit); // Wait for store to be applied
+         barrier.await(waitTimeout, waitUnit); // Wait for first removal to be applied
+         barrier.await(waitTimeout, waitUnit); // Wait for second removal to be applied
          assert 1 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 2 == removeCount.get();
          assert 0 == clearCount.get();
@@ -340,7 +367,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit);
          assert 0 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 1 == removeCount.get();
          assert 1 == clearCount.get();
@@ -358,7 +385,7 @@ protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods)
          assert 0 == removeCount.get();
          assert 0 == clearCount.get();
          store.commit(tx);
-         barrier.await(5, TimeUnit.SECONDS);
+         barrier.await(waitTimeout, waitUnit);
          assert 1 == storeCount.get() : ""Store count was "" + storeCount.get();
          assert 0 == removeCount.get();
          assert 1 == clearCount.get();
@@ -375,94 +402,38 @@ private void doTestPut(int number, String key, String value) throws Exception {
          store.store(cacheEntry);
       }
 
-      store.stop();
-      store.start();
-
-      InternalCacheEntry[] entries = new InternalCacheEntry[number];
-      for (int i = 0; i < number; i++) {
-         entries[i] = store.load(key + i);
-      }
-
       for (int i = 0; i < number; i++) {
-         InternalCacheEntry entry = entries[i];
-         if (entry != null) {
-            assert entry.getValue().equals(value + i);
-         } else {
-            while (entry == null) {
-               entry = store.load(key + i);
-               if (entry != null) {
-                  assert entry.getValue().equals(value + i);
-               } else {
-                  TestingUtil.sleepThreadInt(20, ""still waiting for key to appear: "" + key + i);
-               }
-            }
-         }
+         InternalCacheEntry ice = store.load(key + i);
+         assert ice != null && (value + i).equals(ice.getValue());
       }
    }
 
    private void doTestSameKeyPut(int number, String key, String value) throws Exception {
       for (int i = 0; i < number; i++) {
          store.store(TestInternalCacheEntryFactory.create(key, value + i));
       }
-
-      store.stop();
-      store.start();
-      InternalCacheEntry entry;
-      boolean success = false;
-      for (int i = 0; i < 120; i++) {
-         TestingUtil.sleepThreadInt(20, null);
-         entry = store.load(key);
-         success = entry.getValue().equals(value + (number - 1));
-         if (success) break;
-      }
-      assert success;
+      InternalCacheEntry ice = store.load(key);
+      assert ice != null && (value + (number - 1)).equals(ice.getValue());
    }
 
    private void doTestRemove(int number, String key) throws Exception {
       for (int i = 0; i < number; i++) store.remove(key + i);
 
-      store.stop();//makes sure the store is flushed
-      store.start();
-
-      InternalCacheEntry[] entries = new InternalCacheEntry[number];
-      for (int i = 0; i < number; i++) {
-         entries[i] = store.load(key + i);
-      }
-
       for (int i = 0; i < number; i++) {
-         InternalCacheEntry entry = entries[i];
-         while (entry != null) {
-            TestingUtil.sleepThreadInt(20, ""still waiting for key to be removed: "" + key + i);
-            entry = store.load(key + i);
-         }
+         assert store.load(key + i) == null;
       }
    }
 
    private void doTestSameKeyRemove(String key) throws Exception {
       store.remove(key);
-      InternalCacheEntry entry;
-      do {
-         TestingUtil.sleepThreadInt(20, ""still waiting for key to be removed: "" + key);
-         entry = store.load(key);
-      } while (entry != null);
+      assert store.load(key) == null;
    }
 
    private void doTestClear(int number, String key) throws Exception {
       store.clear();
-      store.stop();
-      store.start();
-
-      InternalCacheEntry[] entries = new InternalCacheEntry[number];
-      for (int i = 0; i < number; i++) {
-         entries[i] = store.load(key + i);
-      }
 
       for (int i = 0; i < number; i++) {
-         InternalCacheEntry entry = entries[i];
-         while (entry != null) {
-            TestingUtil.sleepThreadInt(20, ""still waiting for key to be removed: "" + key + i);
-            entry = store.load(key + i);
-         }
+         assert store.load(key + i) == null;
       }
    }
 
@@ -483,23 +454,207 @@ static class MockAsyncStore extends AsyncStore {
       }
 
       @Override
-      protected void applyModificationsSync(ConcurrentMap<Object, Modification> mods) throws CacheLoaderException {
-         if (mods.get(key) != null && block) {
+      protected void applyModificationsSync(List<Modification> mods) throws CacheLoaderException {
+         boolean keyFound = findModificationForKey(key, mods) != null;
+         if (keyFound && block) {
             log.trace(""Wait for v1 latch"");
             try {
                v2Latch.countDown();
                block = false;
                v1Latch.await(2, TimeUnit.SECONDS);
             } catch (InterruptedException e) {
+               Thread.currentThread().interrupt();
             }
             super.applyModificationsSync(mods);
-         } else if (mods.get(key) != null && !block) {
+         } else if (keyFound && !block) {
             log.trace(""Do v2 modification and unleash v1 latch"");
             super.applyModificationsSync(mods);
             v1Latch.countDown();
             endLatch.countDown();
          }
       }
 
+      private Modification findModificationForKey(Object key, List<Modification> mods) {
+         for (Modification modification : mods) {
+            switch (modification.getType()) {
+               case STORE:
+                  Store store = (Store) modification;
+                  if (store.getStoredEntry().getKey().equals(key))
+                     return store;
+                  break;
+               case REMOVE:
+                  Remove remove = (Remove) modification;
+                  if (remove.getKey().equals(key))
+                     return remove;
+                  break;
+               default:
+                  return null;
+            }
+         }
+         return null;
+      }
+
+   }
+
+   private final static ThreadLocal<LockableCacheStore> STORE = new ThreadLocal<LockableCacheStore>();
+
+   public static class LockableCacheStoreConfig extends DummyInMemoryCacheStore.Cfg {
+      private static final long serialVersionUID = 1L;
+
+      public LockableCacheStoreConfig() {
+         setCacheLoaderClassName(LockableCacheStore.class.getName());
+      }
+   }
+
+   @CacheLoaderMetadata(configurationClass = LockableCacheStoreConfig.class)
+   public static class LockableCacheStore extends DummyInMemoryCacheStore {
+      private final ReentrantLock lock = new ReentrantLock();
+
+      public LockableCacheStore() {
+         super();
+         STORE.set(this);
+      }
+
+      @Override
+      public Class<? extends CacheLoaderConfig> getConfigurationClass() {
+         return LockableCacheStoreConfig.class;
+      }
+
+      @Override
+      public void store(InternalCacheEntry ed) {
+         lock.lock();
+         try {
+            super.store(ed);
+         } finally {
+            lock.unlock();
+         }
+      }
+
+      @Override
+      public boolean remove(Object key) {
+         lock.lock();
+         try {
+            return super.remove(key);
+         } finally {
+            lock.unlock();
+         }
+      }
+   }
+
+   public void testModificationQueueSize(final Method m) throws Exception {
+      LockableCacheStore underlying = new LockableCacheStore();
+      asyncConfig.modificationQueueSize(10);
+      store = new AsyncStore(underlying, asyncConfig);
+      store.init(new LockableCacheStoreConfig(), null, null);
+      store.start();
+      try {
+         final CountDownLatch done = new CountDownLatch(1);
+
+         underlying.lock.lock();
+         try {
+            Thread t = new Thread() {
+               @Override
+               public void run() {
+                  try {
+                     for (int i = 0; i < 100; i++)
+                        store.store(TestInternalCacheEntryFactory.create(k(m, i), v(m, i)));
+                  } catch (Exception e) {
+                     log.error(""Error storing entry"", e);
+                  }
+                  done.countDown();
+               }
+            };
+            t.start();
+
+            assert !done.await(1, TimeUnit.SECONDS) : ""Background thread should have blocked after adding 10 entries"";
+         } finally {
+            underlying.lock.unlock();
+         }
+      } finally {
+         store.stop();
+      }
+   }
+
+   private static abstract class OneEntryCacheManagerCallable extends CacheManagerCallable {
+      protected final Cache<String, String> cache;
+      protected final LockableCacheStore store;
+
+      private static ConfigurationBuilder config(boolean passivation) {
+         ConfigurationBuilder config = new ConfigurationBuilder();
+         config.eviction().maxEntries(1).loaders().passivation(passivation).addStore()
+               .cacheStore(new LockableCacheStore()).async().enable();
+         return config;
+      }
+
+      OneEntryCacheManagerCallable(boolean passivation) {
+         super(TestCacheManagerFactory.createCacheManager(config(passivation)));
+         cache = cm.getCache();
+         store = STORE.get();
+      }
+   }
+
+   public void testEndToEndPutPutPassivation() throws Exception {
+      doTestEndToEndPutPut(true);
+   }
+
+   public void testEndToEndPutPut() throws Exception {
+      doTestEndToEndPutPut(false);
+   }
+
+   private void doTestEndToEndPutPut(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new OneEntryCacheManagerCallable(passivation) {
+         @Override
+         public void call() {
+            cache.put(""X"", ""1"");
+            cache.put(""Y"", ""1""); // force eviction of ""X""
+
+            // wait for X == 1 to appear in store
+            while (store.load(""X"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.put(""X"", ""2"");
+               cache.put(""Y"", ""2""); // force eviction of ""X""
+
+               assert ""2"".equals(cache.get(""X"")) : ""cache must return X == 2"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
+   }
+
+   public void testEndToEndPutRemovePassivation() throws Exception {
+      doTestEndToEndPutRemove(true);
+   }
+
+   public void testEndToEndPutRemove() throws Exception {
+      doTestEndToEndPutRemove(false);
+   }
+
+   private void doTestEndToEndPutRemove(boolean passivation) throws Exception {
+      TestingUtil.withCacheManager(new OneEntryCacheManagerCallable(passivation) {
+         @Override
+         public void call() {
+            cache.put(""X"", ""1"");
+            cache.put(""Y"", ""1""); // force eviction of ""X""
+
+            // wait for ""X"" to appear in store
+            while (store.load(""X"") == null)
+               TestingUtil.sleepThread(10);
+
+            // simulate slow back end store
+            store.lock.lock();
+            try {
+               cache.remove(""X"");
+
+               assert null == cache.get(""X"") : ""cache must return X == null"";
+            } finally {
+               store.lock.unlock();
+            }
+         }
+      });
    }
 }",2012-10-03T12:24:38Z,37
"@@ -28,6 +28,7 @@
 import org.infinispan.marshall.StreamingMarshaller;
 import org.infinispan.marshall.TestObjectStreamMarshaller;
 import org.infinispan.test.TestingUtil;
+import org.infinispan.util.InfinispanCollections;
 import org.infinispan.util.Util;
 import org.infinispan.util.logging.Log;
 import org.infinispan.util.logging.LogFactory;
@@ -38,18 +39,20 @@
 import java.util.*;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.atomic.AtomicInteger;
 
 @CacheLoaderMetadata(configurationClass = DummyInMemoryCacheStore.Cfg.class)
 public class DummyInMemoryCacheStore extends AbstractCacheStore {
    private static final Log log = LogFactory.getLog(DummyInMemoryCacheStore.class);
    private static final boolean trace = log.isTraceEnabled();
+   private static final boolean debug = log.isDebugEnabled();
    static final ConcurrentMap<String, Map<Object, InternalCacheEntry>> stores = new ConcurrentHashMap<String, Map<Object, InternalCacheEntry>>();
-   static final ConcurrentMap<String, ConcurrentMap<String, Integer>> storeStats =
-         new ConcurrentHashMap<String, ConcurrentMap<String, Integer>>();
+   static final ConcurrentMap<String, ConcurrentMap<String, AtomicInteger>> storeStats =
+         new ConcurrentHashMap<String, ConcurrentMap<String, AtomicInteger>>();
    String storeName;
    Map<Object, InternalCacheEntry> store;
    // When a store is 'shared', multiple nodes could be trying to update it concurrently.
-   ConcurrentMap<String, Integer> stats;
+   ConcurrentMap<String, AtomicInteger> stats;
    Cfg config;
 
    public DummyInMemoryCacheStore(String storeName) {
@@ -60,26 +63,14 @@ public DummyInMemoryCacheStore() {
    }
 
    private void record(String method) {
-      boolean replaced;
-      long end = System.currentTimeMillis() + 5000;
-      do {
-         int i = stats.get(method);
-         replaced = stats.replace(method, i, i + 1);
-         if (!replaced) {
-            try {
-               Thread.sleep(200);
-            } catch (InterruptedException e) {
-               Thread.currentThread().interrupt();
-            }
-         }
-      } while (!replaced && end < System.currentTimeMillis());
+      stats.get(method).incrementAndGet();
    }
 
    @Override
    public void store(InternalCacheEntry ed) {
       record(""store"");
       if (ed != null) {
-         if (trace) log.tracef(""Store %s in dummy map store@%s"", ed, Util.hexIdHashCode(store));
+         if (debug) log.debugf(""Store %s in dummy map store@%s"", ed, Util.hexIdHashCode(store));
          config.failIfNeeded(ed.getKey());
          store.put(ed.getKey(), ed);
       }
@@ -123,11 +114,11 @@ public void clear() {
    public boolean remove(Object key) {
       record(""remove"");
       if (store.remove(key) != null) {
-         if (trace) log.tracef(""Removed %s from dummy store"", key);
+         if (debug) log.debugf(""Removed %s from dummy store"", key);
          return true;
       }
 
-      if (trace) log.tracef(""Key %s not present in store, so don't remove"", key);
+      if (debug) log.debugf(""Key %s not present in store, so don't remove"", key);
       return false;
    }
 
@@ -238,7 +229,7 @@ public void start() throws CacheLoaderException {
             log.debugf(""Creating new in-memory cache store %s"", storeName);
          }
 
-         ConcurrentMap<String, Integer> existingStats = storeStats.putIfAbsent(storeName, stats);
+         ConcurrentMap<String, AtomicInteger> existingStats = storeStats.putIfAbsent(storeName, stats);
          if (existing != null) {
             stats = existingStats;
          }
@@ -248,10 +239,10 @@ public void start() throws CacheLoaderException {
       record(""start"");
    }
 
-   private ConcurrentMap<String, Integer> newStatsMap() {
-      ConcurrentMap<String, Integer> m = new ConcurrentHashMap<String, Integer>();
+   private ConcurrentMap<String, AtomicInteger> newStatsMap() {
+      ConcurrentMap<String, AtomicInteger> m = new ConcurrentHashMap<String, AtomicInteger>();
       for (Method method: CacheStore.class.getMethods()) {
-         m.put(method.getName(), 0);
+         m.put(method.getName(), new AtomicInteger(0));
       }
       return m;
    }
@@ -274,11 +265,13 @@ public boolean isEmpty() {
    }
 
    public Map<String, Integer> stats() {
-      return Collections.unmodifiableMap(stats);
+      Map<String, Integer> copy = new HashMap<String, Integer>(stats.size());
+      for (String k: stats.keySet()) copy.put(k, stats.get(k).get());
+      return copy;
    }
 
    public void clearStats() {
-      for (String k: stats.keySet()) stats.put(k, 0);
+      for (String k: stats.keySet()) stats.get(k).set(0);
    }
 
    public void blockUntilCacheStoreContains(Object key, Object expectedValue, long timeout) {
@@ -293,6 +286,57 @@ public void blockUntilCacheStoreContains(Object key, Object expectedValue, long
             timeout, key, expectedValue));
    }
 
+   public void blockUntilCacheStoreContains(Set<Map.Entry<Object, InternalCacheEntry>> expectedState, long timeout) {
+      long killTime = System.currentTimeMillis() + timeout;
+      // Set<? extends Map.Entry<?, InternalCacheEntry>> expectedEntries = expectedState.entrySet();
+      Set<Map.Entry<Object, InternalCacheEntry>> notStored = null;
+      Set<Map.Entry<Object, InternalCacheEntry>> notRemoved = null;
+      while (System.currentTimeMillis() < killTime) {
+         Set<Map.Entry<Object, InternalCacheEntry>> storeEntries = store.entrySet();
+         // Find out which entries might not have been removed from the store
+         notRemoved = InfinispanCollections.difference(storeEntries, expectedState);
+         // Find out which entries might not have been stored
+         notStored = InfinispanCollections.difference(expectedState, storeEntries);
+         if (!notStored.isEmpty() || !notRemoved.isEmpty()) {
+            TestingUtil.sleepThread(5000);
+         } else if (notStored.isEmpty() && notRemoved.isEmpty()) {
+            break;
+         }
+      }
+
+      if ((notStored != null && !notStored.isEmpty()) || (notRemoved != null && !notRemoved.isEmpty())) {
+         if (log.isTraceEnabled()) {
+            log.tracef(""Entries still not stored: %s"", notStored);
+            log.tracef(""Entries still not removed: %s"", notRemoved);
+         }
+         throw new RuntimeException(String.format(
+               ""Timed out waiting (%d ms) for cache store to be flushed. entries-not-stored=[%s], entries-not-removed=[%s]"",
+               timeout, notStored, notRemoved));
+      }
+
+
+//      if (missingEntries != null && !missingEntries.isEmpty())
+//         throw new RuntimeException(String.format(
+//            ""Timed out waiting (%d ms) for cache store to contain entry %s"",
+//            timeout, missingEntries));
+//
+//      long killTime = System.currentTimeMillis() + timeout;
+//      Map.Entry<?, ?> missingEntry = null;
+//      while (System.currentTimeMillis() < killTime) {
+//         for (Map.Entry<?, ?> stateEntry : expectedState.entrySet()) {
+//            InternalCacheEntry entry = store.get(stateEntry.getKey());
+//            if (entry == null || !entry.getValue().equals(stateEntry.getValue())) {
+//               missingEntry = entry;
+//               TestingUtil.sleepThread(50);
+//            }
+//         }
+//      }
+//      if (missingEntry != null)
+//         throw new RuntimeException(String.format(
+//            ""Timed out waiting (%d ms) for cache store to contain entry %s"",
+//            timeout, missingEntry));
+   }
+
    public static class Cfg extends AbstractCacheStoreConfig {
 
       private static final long serialVersionUID = 4258914047690999424L;",2012-10-03T12:24:38Z,38
"@@ -0,0 +1,466 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.stress;
+
+import org.infinispan.container.InternalEntryFactory;
+import org.infinispan.container.InternalEntryFactoryImpl;
+import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.container.versioning.EntryVersion;
+import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.decorators.AbstractDelegatingStore;
+import org.infinispan.loaders.decorators.AsyncStore;
+import org.infinispan.loaders.decorators.AsyncStoreConfig;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.marshall.TestObjectStreamMarshaller;
+import org.infinispan.test.TestingUtil;
+import org.infinispan.util.concurrent.locks.containers.LockContainer;
+import org.infinispan.util.concurrent.locks.containers.ReentrantPerEntryLockContainer;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+import org.testng.annotations.DataProvider;
+import org.testng.annotations.Test;
+
+import java.util.ArrayList;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Random;
+import java.util.Set;
+import java.util.TreeMap;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.locks.Lock;
+
+import static java.lang.Math.sqrt;
+
+/**
+ * Async store stress test.
+ *
+ * // TODO: Add a test to verify clear() too!
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(testName = ""stress.AsyncStoreStressTest"", groups = ""stress"",
+      enabled = true, description = ""Disabled by default, designed to be run manually."")
+public class AsyncStoreStressTest {
+
+   static final Log log = LogFactory.getLog(AsyncStoreStressTest.class);
+   static final boolean trace = log.isTraceEnabled();
+
+   static final int CAPACITY = Integer.getInteger(""size"", 100000);
+   static final int LOOP_FACTOR = 10;
+   static final long RUNNING_TIME = Integer.getInteger(""time"", 1) * 60 * 1000;
+   static final Random RANDOM = new Random(12345);
+
+   private volatile CountDownLatch latch;
+   private List<String> keys = new ArrayList<String>();
+   private InternalEntryFactory entryFactory = new InternalEntryFactoryImpl();
+   private Map<Object, InternalCacheEntry> expectedState = new ConcurrentHashMap<Object, InternalCacheEntry>();
+
+   // Lock container that mimics per-key locking produced by the cache.
+   // This per-key lock holder provides guarantees that the final expected
+   // state has not been affected by ordering issues such as this:
+   //
+   // (Thread-200:) Enqueuing modification Store{storedEntry=
+   // ImmortalCacheEntry{key=key165168, value=ImmortalCacheValue {value=60483}}}
+   // (Thread-194:) Enqueuing modification Store{storedEntry=
+   // ImmortalCacheEntry{key=key165168, value=ImmortalCacheValue {value=61456}}}
+   // (Thread-194:) Expected state updated with key=key165168, value=61456
+   // (Thread-200:) Expected state updated with key=key165168, value=60483
+   private LockContainer locks = new ReentrantPerEntryLockContainer(32);
+
+   private Map<String, AbstractDelegatingStore> createAsyncStores() throws CacheLoaderException {
+      Map<String, AbstractDelegatingStore> stores = new TreeMap<String, AbstractDelegatingStore>();
+      stores.put(""ASYNC"", createAsyncStore());
+      return stores;
+   }
+
+   private AsyncStore createAsyncStore() throws CacheLoaderException {
+      DummyInMemoryCacheStore backendStore = createBackendStore(""async2"");
+      AsyncStoreConfig asyncCfg = new AsyncStoreConfig();
+      asyncCfg.modificationQueueSize(0);
+      AsyncStore store = new AsyncStore(backendStore, asyncCfg);
+      store.init(backendStore.getCacheStoreConfig(), null, new TestObjectStreamMarshaller());
+      store.start();
+      return store;
+   }
+
+   private DummyInMemoryCacheStore createBackendStore(String storeName) throws CacheLoaderException {
+      DummyInMemoryCacheStore store = new DummyInMemoryCacheStore();
+      store.init(new DummyInMemoryCacheStore.Cfg(storeName), null, new TestObjectStreamMarshaller());
+      store.start();
+      return store;
+   }
+
+   @DataProvider(name = ""readWriteRemove"")
+   public Object[][] independentReadWriteRemoveParams() {
+      return new Object[][]{
+            new Object[]{CAPACITY, 3 * CAPACITY, 90, 9, 1},
+            new Object[]{CAPACITY, 3 * CAPACITY, 9, 1, 0},
+      };
+   }
+
+   @Test(dataProvider = ""readWriteRemove"", enabled = true)
+   public void testReadWriteRemove(int capacity, int numKeys,
+         int readerThreads, int writerThreads, int removerThreads) throws Exception {
+      System.out.printf(""Testing independent read/write/remove performance "" +
+            ""with capacity %d, keys %d, readers %d, writers %d, removers %d\n"",
+            capacity, numKeys, readerThreads, writerThreads, removerThreads);
+
+      generateKeyList(numKeys);
+
+      Map<String, AbstractDelegatingStore> stores = createAsyncStores();
+
+      for (Map.Entry<String, AbstractDelegatingStore> e : stores.entrySet()) {
+         mapTestReadWriteRemove(e.getKey(), e.getValue(), numKeys,
+               readerThreads, writerThreads, removerThreads);
+         e.setValue(null);
+      }
+   }
+
+   private void mapTestReadWriteRemove(String name, AbstractDelegatingStore store,
+         int numKeys, int readerThreads, int writerThreads, int removerThreads) throws Exception {
+      DummyInMemoryCacheStore delegate = (DummyInMemoryCacheStore) store.getDelegate();
+      try {
+         // warm up for 1 second
+         System.out.printf(""[store=%s] Warming up\n"", name);
+         runMapTestReadWriteRemove(name, store, readerThreads, writerThreads, removerThreads, 1000);
+
+         // real test
+         System.out.printf(""[store=%s] Testing...\n"", name);
+         TotalStats perf = runMapTestReadWriteRemove(name, store, readerThreads, writerThreads, removerThreads, RUNNING_TIME);
+
+         // Wait until the cache store contains the expected state
+         System.out.printf(""[store=%s] Verify contents\n"", name);
+         TestingUtil.sleepThread(10000); // Wait a bit before starting to verify contents
+         delegate.blockUntilCacheStoreContains(expectedState.entrySet(), 60000);
+
+         System.out.printf(""Container %-12s  "", name);
+         System.out.printf(""Ops/s %10.2f  "", perf.getTotalOpsPerSec());
+         System.out.printf(""Gets/s %10.2f  "", perf.getOpsPerSec(""GET""));
+         System.out.printf(""Puts/s %10.2f  "", perf.getOpsPerSec(""PUT""));
+         System.out.printf(""Removes/s %10.2f  "", perf.getOpsPerSec(""REMOVE""));
+         System.out.printf(""HitRatio %10.2f  "", perf.getTotalHitRatio() * 100);
+         System.out.printf(""Size %10d  "", store.loadAllKeys(null).size());
+         double stdDev = computeStdDev(store, numKeys);
+         System.out.printf(""StdDev %10.2f\n"", stdDev);
+      } finally {
+         // Clean up state, expected state and keys
+         expectedState.clear();
+         delegate.clear();
+      }
+   }
+
+   private TotalStats runMapTestReadWriteRemove(String name, final AbstractDelegatingStore store, int numReaders, int numWriters,
+         int numRemovers, final long runningTimeout) throws Exception {
+      latch = new CountDownLatch(1);
+      final TotalStats perf = new TotalStats();
+      List<Thread> threads = new LinkedList<Thread>();
+
+      for (int i = 0; i < numReaders; i++) {
+         Thread reader = new WorkerThread(""worker-"" + name + ""-get-"" + i, runningTimeout, perf, readOperation(store));
+         threads.add(reader);
+      }
+
+      for (int i = 0; i < numWriters; i++) {
+         Thread writer = new WorkerThread(""worker-"" + name + ""-put-"" + i, runningTimeout, perf, writeOperation(store));
+         threads.add(writer);
+      }
+
+      for (int i = 0; i < numRemovers; i++) {
+         Thread remover = new WorkerThread(""worker-"" + name + ""-remove-"" + i, runningTimeout, perf, removeOperation(store));
+         threads.add(remover);
+      }
+
+      for (Thread t : threads)
+         t.start();
+      latch.countDown();
+
+      for (Thread t : threads)
+         t.join();
+
+      return perf;
+   }
+
+   private void generateKeyList(int numKeys) {
+      // without this we keep getting OutOfMemoryErrors
+      keys = null;
+      keys = new ArrayList<String>(numKeys * LOOP_FACTOR);
+      for (int i = 0; i < numKeys * LOOP_FACTOR; i++) {
+         keys.add(""key"" + nextIntGaussian(numKeys));
+      }
+   }
+
+   private int nextIntGaussian(int numKeys) {
+      double gaussian = RANDOM.nextGaussian();
+      if (gaussian < -3 || gaussian > 3)
+         return nextIntGaussian(numKeys);
+
+      return (int) Math.abs((gaussian + 3) * numKeys / 6);
+   }
+
+   private void waitForStart() {
+      try {
+         latch.await();
+      } catch (InterruptedException e) {
+         throw new RuntimeException(e);
+      }
+   }
+
+   private Operation<String, Integer> readOperation(AbstractDelegatingStore store) {
+      return new Operation<String, Integer>(store, ""GET"") {
+         @Override
+         public boolean call(String key, long run) {
+            try {
+               InternalCacheEntry ice = store.load(key);
+               if (trace)
+                  log.tracef(""Loaded key=%s, value=%s"", key, ice != null ? ice.getValue() : ""null"");
+               return ice != null;
+            } catch (CacheLoaderException e) {
+               e.printStackTrace();
+               return false;
+            }
+         }
+      };
+   }
+
+   private Operation<String, Integer> writeOperation(AbstractDelegatingStore store) {
+      return new Operation<String, Integer>(store, ""PUT"") {
+         @Override
+         public boolean call(final String key, long run) {
+            final int value = (int) run;
+            final InternalCacheEntry entry =
+                  entryFactory.create(key, value, (EntryVersion) null);
+            // Store acquiring locks and catching exceptions
+            boolean result = withStore(key, new Callable<Boolean>() {
+               @Override
+               public Boolean call() throws Exception {
+                  store.store(entry);
+                  expectedState.put(key, entry);
+                  if (trace)
+                     log.tracef(""Expected state updated with key=%s, value=%s"", key, value);
+                  return true;
+               }
+            });
+            return result;
+         }
+      };
+   }
+
+   private Operation<String, Integer> removeOperation(AbstractDelegatingStore store) {
+      return new Operation<String, Integer>(store, ""REMOVE"") {
+         @Override
+         public boolean call(final String key, long run) {
+            // Remove acquiring locks and catching exceptions
+            boolean result = withStore(key, new Callable<Boolean>() {
+               @Override
+               public Boolean call() throws Exception {
+                  boolean removed = store.remove(key);
+                  if (removed) {
+                     expectedState.remove(key);
+                     if (trace)
+                        log.tracef(""Expected state removed key=%s"", key);
+                  }
+                  return true;
+               }
+            });
+            return result;
+         }
+      };
+   }
+   
+   private boolean withStore(String key, Callable<Boolean> call) {
+      Lock lock = null;
+      boolean result = false;
+      try {
+         lock = locks.acquireLock(Thread.currentThread(), key, 30, TimeUnit.SECONDS);
+         if (lock != null) {
+            result = call.call().booleanValue();
+         }
+      } catch (CacheLoaderException e) {
+         e.printStackTrace();
+         result = false;
+      } catch (InterruptedException e) {
+         e.printStackTrace();
+         result = false;
+      } finally {
+         if (lock == null) return false;
+         else {
+            lock.unlock();
+            return result;
+         }
+      }
+   }
+
+   private double computeStdDev(AbstractDelegatingStore store, int numKeys) throws CacheLoaderException {
+      // The keys closest to the mean are suposed to be accessed more often
+      // So we score each map by the standard deviation of the keys in the map
+      // at the end of the test
+      double variance = 0;
+      Set<Object> keys = store.loadAllKeys(null);
+      for (Object key : keys) {
+         double value = Integer.parseInt(((String )key).substring(3));
+         variance += (value - numKeys / 2) * (value - numKeys / 2);
+      }
+      return sqrt(variance / keys.size());
+   }
+
+   private class WorkerThread extends Thread {
+      private final long runningTimeout;
+      private final TotalStats perf;
+      private Operation<String, Integer> op;
+
+      public WorkerThread(String name, long runningTimeout, TotalStats perf, Operation<String, Integer> op) {
+         super(name);
+         this.runningTimeout = runningTimeout;
+         this.perf = perf;
+         this.op = op;
+      }
+
+      public void run() {
+         waitForStart();
+         long startMilis = System.currentTimeMillis();
+         long endMillis = startMilis + runningTimeout;
+         int keyIndex = RANDOM.nextInt(keys.size());
+         long runs = 0;
+         long missCount = 0;
+         while ((runs & 0x3FFF) != 0 || System.currentTimeMillis() < endMillis) {
+            boolean hit = op.call(keys.get(keyIndex), runs);
+            if (!hit) missCount++;
+            keyIndex++;
+            runs++;
+            if (keyIndex >= keys.size()) {
+               keyIndex = 0;
+            }
+         }
+         perf.addStats(op.getName(), runs, System.currentTimeMillis() - startMilis, missCount);
+      }
+   }
+
+   private static abstract class Operation<K, V> {
+      protected final AbstractDelegatingStore store;
+      protected final String name;
+
+      public Operation(AbstractDelegatingStore store, String name) {
+         this.store = store;
+         this.name = name;
+      }
+
+      /**
+       * @return Return true for a hit, false for a miss.
+       */
+      public abstract boolean call(K key, long run);
+
+      public String getName() {
+         return name;
+      }
+   }
+
+   private static class TotalStats {
+      private ConcurrentHashMap<String, OpStats> statsMap = new ConcurrentHashMap<String, OpStats>();
+
+      public void addStats(String opName, long opCount, long runningTime, long missCount) {
+         OpStats s = new OpStats(opName, opCount, runningTime, missCount);
+         OpStats old = statsMap.putIfAbsent(opName, s);
+         boolean replaced = old == null;
+         while (!replaced) {
+            old = statsMap.get(opName);
+            s = new OpStats(old, opCount, runningTime, missCount);
+            replaced = statsMap.replace(opName, old, s);
+         }
+      }
+
+      public double getOpsPerSec(String opName) {
+         OpStats s = statsMap.get(opName);
+         if (s == null) return 0;
+         return s.opCount * 1000. / s.runningTime * s.threadCount;
+      }
+
+      public double getTotalOpsPerSec() {
+         long totalOpCount = 0;
+         long totalRunningTime = 0;
+         long totalThreadCount = 0;
+         for (Map.Entry<String, OpStats> e : statsMap.entrySet()) {
+            OpStats s = e.getValue();
+            totalOpCount += s.opCount;
+            totalRunningTime += s.runningTime;
+            totalThreadCount += s.threadCount;
+         }
+         return totalOpCount * 1000. / totalRunningTime * totalThreadCount;
+      }
+
+      public double getHitRatio(String opName) {
+         OpStats s = statsMap.get(opName);
+         if (s == null) return 0;
+         return 1 - 1. * s.missCount / s.opCount;
+      }
+
+      public double getTotalHitRatio() {
+         long totalOpCount = 0;
+         long totalMissCount = 0;
+         for (Map.Entry<String, OpStats> e : statsMap.entrySet()) {
+            OpStats s = e.getValue();
+            totalOpCount += s.opCount;
+            totalMissCount += s.missCount;
+         }
+         return 1 - 1. * totalMissCount / totalOpCount;
+      }
+   }
+
+   private static class OpStats {
+      public final String opName;
+      public final int threadCount;
+      public final long opCount;
+      public final long runningTime;
+      public final long missCount;
+
+      private OpStats(String opName, long opCount, long runningTime, long missCount) {
+         this.opName = opName;
+         this.threadCount = 1;
+         this.opCount = opCount;
+         this.runningTime = runningTime;
+         this.missCount = missCount;
+      }
+
+      private OpStats(OpStats base, long opCount, long runningTime, long missCount) {
+         this.opName = base.opName;
+         this.threadCount = base.threadCount + 1;
+         this.opCount = base.opCount + opCount;
+         this.runningTime = base.runningTime + runningTime;
+         this.missCount = base.missCount + missCount;
+      }
+   }
+
+   @Test(enabled = false) // Disable explicitly to avoid TestNG thinking this is a test!!
+   public static void main(String[] args) throws Exception {
+      AsyncStoreStressTest test = new AsyncStoreStressTest();
+      test.testReadWriteRemove(100000, 300000, 90, 9, 1);
+      test.testReadWriteRemove(10000, 30000, 9, 1, 0);
+      System.exit(0);
+   }
+
+}",2012-10-03T12:24:38Z,39
"@@ -443,18 +443,20 @@ public void addStats(String opName, long opCount, long runningTime, long missCou
       public double getOpsPerSec(String opName) {
          OpStats s = statsMap.get(opName);
          if (s == null) return 0;
-         return s.opCount * 1000. / s.runningTime;
+         return s.opCount * 1000. / s.runningTime * s.threadCount;
       }
 
       public double getTotalOpsPerSec() {
          long totalOpCount = 0;
          long totalRunningTime = 0;
+         long totalThreadCount = 0;
          for (Map.Entry<String, OpStats> e : statsMap.entrySet()) {
             OpStats s = e.getValue();
             totalOpCount += s.opCount;
-            totalRunningTime = s.runningTime;
+            totalRunningTime += s.runningTime;
+            totalThreadCount += s.threadCount;
          }
-         return totalOpCount * 1000. / totalRunningTime;
+         return totalOpCount * 1000. / totalRunningTime * totalThreadCount;
       }
 
       public double getHitRatio(String opName) {",2012-10-03T12:24:38Z,40
"@@ -0,0 +1,123 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other
+ * contributors as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a full listing of
+ * individual contributors.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this software; if not, write to the Free
+ * Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
+ * 02110-1301 USA, or see the FSF site: http://www.fsf.org.
+ */
+
+package org.infinispan.util;
+
+import org.testng.annotations.Test;
+
+import java.util.HashSet;
+import java.util.Set;
+
+import static org.testng.AssertJUnit.assertEquals;
+import static org.testng.AssertJUnit.assertTrue;
+
+/**
+ * // TODO: Document this
+ *
+ * @author Galder Zamarreño
+ * @since // TODO
+ */
+@Test(testName = ""util.InfinispanCollectionsTest"")
+public class InfinispanCollectionsTest {
+
+   public void testDifferenceNotStored() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+      expected.add(""d"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(1, notStored.size());
+      assertTrue(notStored.contains(""d""));
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(0, notRemoved.size());
+   }
+
+   public void testDifferenceNotRemoved() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+      store.add(""d"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(0, notStored.size());
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(1, notRemoved.size());
+      assertTrue(notRemoved.contains(""d""));
+   }
+
+   public void testDifferenceNotStoreAndNotRemoved() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+      store.add(""d"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+      expected.add(""e"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(1, notStored.size());
+      assertTrue(notStored.contains(""e""));
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(1, notRemoved.size());
+      assertTrue(notRemoved.contains(""d""));
+   }
+
+   public void testNoDifference() {
+      Set<String> store = new HashSet<String>();
+      store.add(""a"");
+      store.add(""b"");
+      store.add(""c"");
+
+      Set<String> expected = new HashSet<String>();
+      expected.add(""a"");
+      expected.add(""b"");
+      expected.add(""c"");
+
+      Set<String> notStored = InfinispanCollections.difference(expected, store);
+      assertEquals(0, notStored.size());
+
+      Set<String> notRemoved = InfinispanCollections.difference(store, expected);
+      assertEquals(0, notRemoved.size());
+   }
+
+}",2012-10-03T12:24:38Z,31
"@@ -122,10 +122,15 @@ public S purgeSynchronously(boolean b) {
    public void validate() {
       async.validate();
       singletonStore.validate();
+      ConfigurationBuilder builder = getBuilder();
       if (!loaders().shared() && !fetchPersistentState && !purgeOnStartup
-            && getBuilder().clustering().cacheMode().isClustered())
+            && builder.clustering().cacheMode().isClustered())
          log.staleEntriesWithoutFetchPersistentStateOrPurgeOnStartup();
-   }
 
+      if (loaders().shared() && !loaders().preload()
+            && builder.indexing().enabled()
+            && builder.indexing().indexLocalOnly())
+         log.localIndexingWithSharedCacheLoaderRequiresPreload();
+   }
 
 }",2012-08-30T15:45:20Z,41
"@@ -62,6 +62,10 @@ public IndexingConfigurationBuilder enabled(boolean enabled) {
       return this;
    }
 
+   boolean enabled() {
+      return enabled;
+   }
+
    /**
     * If true, only index changes made locally, ignoring remote changes. This is useful if indexes
     * are shared across a cluster to prevent redundant indexing of updates.
@@ -71,6 +75,10 @@ public IndexingConfigurationBuilder indexLocalOnly(boolean b) {
       return this;
    }
 
+   boolean indexLocalOnly() {
+      return indexLocalOnly;
+   }
+
    /**
     * <p>
     * Defines a single property. Can be used multiple times to define all needed properties, but the",2012-08-30T15:45:20Z,42
"@@ -49,4 +49,4 @@ public interface LoaderConfigurationBuilder<T extends LoaderConfiguration, S ext
     */
    S withProperties(Properties p);
 
-}
\ No newline at end of file
+}",2012-08-30T15:45:20Z,43
"@@ -72,6 +72,10 @@ public LoadersConfigurationBuilder preload(boolean b) {
       return this;
    }
 
+   boolean preload() {
+      return preload;
+   }
+
    /**
     * This setting should be set to true when multiple cache instances share the same cache store
     * (e.g., multiple nodes in a cluster using a JDBC-based CacheStore pointing to the same, shared
@@ -173,7 +177,7 @@ public LegacyStoreConfigurationBuilder addStore() {
    /**
     * Adds a cache store which uses the specified builder instance to build its configuration
     *
-    * @param klass an instance of {@link StoreConfigurationBuilder}
+    * @param builder an instance of {@link StoreConfigurationBuilder}
     */
    public LoaderConfigurationBuilder<?, ?> addStore(StoreConfigurationBuilder<?, ?> builder) {
       this.cacheLoaders.add(builder);",2012-08-30T15:45:20Z,44
"@@ -31,7 +31,10 @@
 import static org.infinispan.context.Flag.IGNORE_RETURN_VALUES;
 import static org.infinispan.factories.KnownComponentNames.CACHE_MARSHALLER;
 
+import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collections;
+import java.util.List;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
@@ -47,6 +50,7 @@
 import org.infinispan.configuration.cache.LoadersConfiguration;
 import org.infinispan.configuration.cache.StoreConfiguration;
 import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.annotations.ComponentName;
@@ -189,18 +193,24 @@ public void preload() {
                throw new CacheException(""Unable to preload!"", e);
             }
 
-            for (InternalCacheEntry e : state) {
-               if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
-                  cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, SKIP_CACHE_STORE, IGNORE_RETURN_VALUES, SKIP_INDEXING)
-                       .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
-               } else {
-                  cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES, SKIP_INDEXING)
-                       .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
-               }
+            List<Flag> flags = new ArrayList(Arrays.asList(
+                  CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES));
+
+            if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
+               flags.add(SKIP_CACHE_STORE);
+               if (!localIndexingEnabled())
+                  flags.add(SKIP_INDEXING);
+            } else {
+               flags.add(SKIP_INDEXING);
             }
 
+            AdvancedCache<Object, Object> flaggedCache = cache.getAdvancedCache()
+                  .withFlags(flags.toArray(new Flag[]{}));
+
+            for (InternalCacheEntry e : state)
+               flaggedCache.put(e.getKey(), e.getValue(),
+                     e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
+
             if (debugTiming) {
                final long stop = System.nanoTime();
                log.debugf(""Preloaded %s keys in %s"", state.size(), Util.prettyPrintTime(stop - start, TimeUnit.NANOSECONDS));
@@ -209,6 +219,10 @@ public void preload() {
       }
    }
 
+   private boolean localIndexingEnabled() {
+      return configuration.indexing().enabled() && configuration.indexing().indexLocalOnly();
+   }
+
    private Set<InternalCacheEntry> loadState() throws CacheLoaderException {
       int ne = -1;
       if (configuration.eviction().strategy().isEnabled()) ne = configuration.eviction().maxEntries();",2012-08-30T15:45:20Z,29
"@@ -863,6 +863,11 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    void componentFailedToStop(@Cause Throwable e);
 
    @LogMessage(level = WARN)
-   @Message(value = ""Use of the 'loader' element to configure a store is deprecated, please use the 'store' element instead"")
+   @Message(value = ""Use of the 'loader' element to configure a store is deprecated, please use the 'store' element instead"", id = 190)
    void deprecatedLoaderAsStoreConfiguration();
+
+   @LogMessage(level = DEBUG)
+   @Message(value = ""When indexing locally a cache with shared cache loader, preload must be enabled"", id = 191)
+   void localIndexingWithSharedCacheLoaderRequiresPreload();
+
 }",2012-08-30T15:45:20Z,45
"@@ -29,7 +29,6 @@
 import org.infinispan.test.TestingUtil;
 import org.testng.annotations.Test;
 
-import java.util.LinkedList;
 import java.util.List;
 
 @Test (testName = ""loaders.SharedCacheStoreTest"", groups = ""functional"")
@@ -50,13 +49,6 @@ protected void createCacheManagers() throws Throwable {
       // don't create the caches here, we want them to join the cluster one by one
    }
 
-   private List<CacheStore> cachestores() {
-      List<CacheStore> l = new LinkedList<CacheStore>();
-      for (Cache<?, ?> c: caches())
-         l.add(TestingUtil.extractComponent(c, CacheLoaderManager.class).getCacheStore());
-      return l;
-   }
-
    public void testUnnecessaryWrites() throws CacheLoaderException {
       cache(0).put(""key"", ""value"");
 
@@ -66,7 +58,8 @@ public void testUnnecessaryWrites() throws CacheLoaderException {
       for (Cache<Object, Object> c: caches())
          assert ""value"".equals(c.get(""key""));
 
-      for (CacheStore cs: cachestores()) {
+      List<CacheStore> cachestores = TestingUtil.cachestores(caches());
+      for (CacheStore cs: cachestores) {
          assert cs.containsKey(""key"");
          DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
          assert dimcs.stats().get(""clear"") == 0: ""Cache store should not be cleared, purgeOnStartup is false"";
@@ -78,7 +71,7 @@ public void testUnnecessaryWrites() throws CacheLoaderException {
       for (Cache<Object, Object> c: caches())
          assert c.get(""key"") == null;
 
-      for (CacheStore cs: cachestores()) {
+      for (CacheStore cs: cachestores) {
          assert !cs.containsKey(""key"");
          DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
          assert dimcs.stats().get(""remove"") == 1: ""Entry should have been removed from the cache store just once, but was removed "" + dimcs.stats().get(""store"") + "" times"";",2012-08-30T15:45:20Z,46
"@@ -0,0 +1,73 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.TestingUtil;
+
+import java.util.concurrent.Callable;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+
+/**
+ * Represents a joining node, designed for state transfer related tests.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public class JoiningNode {
+
+   private final EmbeddedCacheManager cm;
+   private final CountDownLatch latch;
+   private final MergeOrViewChangeListener listener;
+
+   public JoiningNode(EmbeddedCacheManager cm) {
+      this.cm = cm;
+      latch = new CountDownLatch(1);
+      listener = new MergeOrViewChangeListener(latch);
+      cm.addListener(listener);
+   }
+
+   public Cache getCache() {
+      return cm.getCache();
+   }
+
+   public Cache getCache(String cacheName) {
+      return cm.getCache(cacheName);
+   }
+
+   public void waitForJoin(long timeout, Cache... caches) throws InterruptedException {
+      // Wait for either a merge or view change to happen
+      latch.await(timeout, TimeUnit.MILLISECONDS);
+      // Wait for the state transfer to end
+      TestingUtil.waitForRehashToComplete(caches);
+   }
+
+   private boolean isStateTransferred() {
+      return !listener.merged;
+   }
+
+   void verifyStateTransfer(Callable<Void> verify) throws Exception {
+      if (isStateTransferred())
+         verify.call();
+   }
+
+}",2012-08-30T15:45:20Z,47
"@@ -0,0 +1,72 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.statetransfer;
+
+import org.infinispan.notifications.Listener;
+import org.infinispan.notifications.cachemanagerlistener.annotation.Merged;
+import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
+import org.infinispan.notifications.cachemanagerlistener.event.MergeEvent;
+import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+import java.util.concurrent.CountDownLatch;
+
+/**
+ * Listener implementation that detects whether a merge or
+ * a view change occurred.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Listener
+public class MergeOrViewChangeListener {
+
+   private static final Log log = LogFactory.getLog(MergeOrViewChangeListener.class);
+
+   // The latch provides the visibility guarantees
+   public boolean merged;
+
+   // The latch provides the visibility guarantees
+   public boolean viewChanged;
+
+   private final CountDownLatch latch;
+
+   public MergeOrViewChangeListener(CountDownLatch latch) {
+      this.latch = latch;
+   }
+
+   @Merged
+   @SuppressWarnings(""unused"")
+   public void mergedView(MergeEvent me) {
+      log.infof(""View merged received %s"", me);
+      merged = true;
+      latch.countDown();
+   }
+
+   @ViewChanged
+   @SuppressWarnings(""unused"")
+   public void viewChanged(ViewChangedEvent e) {
+      log.infof(""View change received %s"", e);
+      viewChanged = true;
+      latch.countDown();
+   }
+
+}",2012-08-30T15:45:20Z,48
"@@ -25,11 +25,6 @@
 import org.infinispan.Cache;
 import org.infinispan.config.Configuration;
 import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.notifications.Listener;
-import org.infinispan.notifications.cachemanagerlistener.annotation.Merged;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.MergeEvent;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
@@ -46,8 +41,7 @@
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.lang.reflect.Method;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.TimeUnit;
+import java.util.concurrent.Callable;
 
 @Test(groups = ""functional"", testName = ""statetransfer.StateTransferFunctionalTest"", enabled = true)
 public class StateTransferFunctionalTest extends MultipleCacheManagersTest {
@@ -183,10 +177,10 @@ public void testInitialStateTransfer(Method m) throws Exception {
       cache1 = cm1.getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node = new JoiningNode();
+      JoiningNode node = new JoiningNode(createCacheManager());
       cache2 = node.getCache(cacheName);
       node.waitForJoin(60000, cache1, cache2);
-      node.verifyStateTransfer(cache2);
+      node.verifyStateTransfer(new CacheVerifier(cache2));
 
       logTestEnd(m);
    }
@@ -199,10 +193,10 @@ public void testInitialStateTransferCacheNotPresent(Method m) throws Exception {
       cache1 = cacheManager1.getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node = new JoiningNode();
+      JoiningNode node = new JoiningNode(createCacheManager());
       cache2 = node.getCache(cacheName);
       node.waitForJoin(60000, cache1, cache2);
-      node.verifyStateTransfer(cache2);
+      node.verifyStateTransfer(new CacheVerifier(cache2));
 
       cacheManager1.defineConfiguration(""otherCache"", config.clone());
       cacheManager1.getCache(""otherCache"");
@@ -216,16 +210,16 @@ public void testConcurrentStateTransfer(Method m) throws Exception {
       cache1 = createCacheManager().getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
 
       cache1.put(""delay"", new StateTransferFunctionalTest.DelayTransfer());
 
       node2.waitForJoin(60000, cache1, cache2);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
-      final JoiningNode node3 = new JoiningNode();
-      final JoiningNode node4 = new JoiningNode();
+      final JoiningNode node3 = new JoiningNode(createCacheManager());
+      final JoiningNode node4 = new JoiningNode(createCacheManager());
 
       Thread t1 = new Thread(new Runnable() {
          public void run() {
@@ -252,8 +246,8 @@ public void run() {
       node3.waitForJoin(120000, cache1, cache2, cache3, cache4);
       node4.waitForJoin(120000, cache1, cache2, cache3, cache4);
 
-      node3.verifyStateTransfer(cache3);
-      node4.verifyStateTransfer(cache4);
+      node3.verifyStateTransfer(new CacheVerifier(cache3));
+      node4.verifyStateTransfer(new CacheVerifier(cache4));
 
       logTestEnd(m);
    }
@@ -300,10 +294,10 @@ public void testInitialStateTransferAfterRestart(Method m) throws Exception {
       cache1 = createCacheManager().getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
       node2.waitForJoin(60000, cache1, cache2);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       cache2.stop();
       cache2.start();
@@ -324,7 +318,7 @@ private void logTestLifecycle(Method m, String lifecycle) {
       log.infof(""%s %s - %s"", m.getName(), lifecycle, testCount);
    }
 
-   private void thirdWritingCacheTest(boolean tx) throws InterruptedException {
+   private void thirdWritingCacheTest(boolean tx) throws Exception {
       Cache<Object, Object> cache1, cache2, cache3;
       cache1 = createCacheManager().getCache(cacheName);
       cache3 = createCacheManager().getCache(cacheName);
@@ -340,15 +334,15 @@ private void thirdWritingCacheTest(boolean tx) throws InterruptedException {
       WritingThread writerThread = new WritingThread(cache3, tx);
       writerThread.start();
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
 
       node2.waitForJoin(60000, cache1, cache2, cache3);
 
       writerThread.stopThread();
       writerThread.join();
 
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       int count = writerThread.result();
 
@@ -374,7 +368,7 @@ protected void writeInitialData(final Cache<Object, Object> c) {
       c.put(A_C_AGE, FORTY);
    }
 
-   private void writingThreadTest(boolean tx) throws InterruptedException {
+   private void writingThreadTest(boolean tx) throws Exception {
       Cache<Object, Object> cache1, cache2;
       cache1 = createCacheManager().getCache(cacheName);
 
@@ -388,81 +382,34 @@ private void writingThreadTest(boolean tx) throws InterruptedException {
       writerThread.start();
       verifyInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
       node2.waitForJoin(60000, cache1, cache2);
 
       writerThread.stopThread();
       writerThread.join();
 
       verifyInitialData(cache1);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       int count = writerThread.result();
 
       for (int c = 0; c < count; c++)
          assert new Integer(c).equals(cache2.get(""test"" + c)) : ""Entry under key [test"" + c + ""] was ["" + cache2.get(""test"" + c) + ""] but expected ["" + c + ""]"";
    }
 
-   @Listener
-   public static class MergeOrViewChangeListener {
-      // The latch provides the visibility guarantees
-      public boolean merged;
-      // The latch provides the visibility guarantees
-      public boolean viewChanged;
-      private final CountDownLatch latch;
+   public class CacheVerifier implements Callable<Void> {
 
-      public MergeOrViewChangeListener(CountDownLatch latch) {
-         this.latch = latch;
-      }
-
-      @Merged
-      public void mergedView(MergeEvent me) {
-         log.infof(""View merged received %s"", me);
-         merged = true;
-         latch.countDown();
-      }
-
-      @ViewChanged
-      public void viewChanged(ViewChangedEvent e) {
-         log.infof(""View change received %s"", e);
-         viewChanged = true;
-         latch.countDown();
-      }
-
-   }
-
-   private class JoiningNode {
-
-      private final EmbeddedCacheManager cm;
-      private final CountDownLatch latch;
-      private final MergeOrViewChangeListener listener;
-
-      private JoiningNode() {
-         cm = createCacheManager();
-         latch = new CountDownLatch(1);
-         listener = new MergeOrViewChangeListener(latch);
-         cm.addListener(listener);
-      }
-
-      Cache getCache(String cacheName) {
-         return cm.getCache(cacheName);
-      }
-
-      void waitForJoin(long timeout, Cache... caches) throws InterruptedException {
-         // Wait for either a merge or view change to happen
-         latch.await(timeout, TimeUnit.MILLISECONDS);
-         // Wait for the state transfer to end
-         TestingUtil.waitForRehashToComplete(caches);
-      }
+      private final Cache<Object, Object> cache;
 
-      private boolean isStateTransferred() {
-         return !listener.merged;
+      public CacheVerifier(Cache<Object, Object> cache) {
+         this.cache = cache;
       }
 
-      void verifyStateTransfer(Cache cache) {
-         if (isStateTransferred())
-            StateTransferFunctionalTest.this.verifyInitialData(cache);
+      @Override
+      public Void call() throws Exception {
+         verifyInitialData(cache);
+         return null;
       }
 
    }",2012-08-30T15:45:20Z,49
"@@ -33,6 +33,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.LinkedList;
 import java.util.List;
 import java.util.Random;
 import java.util.Set;
@@ -62,6 +63,7 @@
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.loaders.CacheLoader;
 import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.loaders.CacheStore;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.AbstractDelegatingMarshaller;
@@ -754,6 +756,13 @@ public static void clearCacheLoader(Cache cache) {
       }
    }
 
+   public static <K, V> List<CacheStore> cachestores(List<Cache<K, V>> caches) {
+      List<CacheStore> l = new LinkedList<CacheStore>();
+      for (Cache<?, ?> c: caches)
+         l.add(TestingUtil.extractComponent(c, CacheLoaderManager.class).getCacheStore());
+      return l;
+   }
+
    private static void removeInMemoryData(Cache cache) {
       EmbeddedCacheManager mgr = cache.getCacheManager();
       Address a = mgr.getAddress();",2012-08-30T15:45:20Z,50
"@@ -0,0 +1,69 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.cacheloaders;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.query.statetransfer.BaseReIndexingTest;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.Test;
+
+/**
+ * Tests behaviour of indexing and querying when a cache is clustered and
+ * and it's configured with a shared cache store. If preload is enabled,
+ * it should be possible to index the preloaded contents.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.cacheloaders.SharedCacheLoaderQueryIndexTest"")
+public class SharedCacheLoaderQueryIndexTest extends BaseReIndexingTest {
+
+   protected void configureCache(ConfigurationBuilder builder) {
+      // To force a shared cache store, make sure storeName property
+      // for dummy store is the same for all nodes
+      builder.clustering().stateTransfer().fetchInMemoryState(false)
+         .loaders().shared(true).preload(true).addStore()
+            .cacheStore(new DummyInMemoryCacheStore()).addProperty(""storeName"",
+            SharedCacheLoaderQueryIndexTest.class.getName());
+   }
+
+   public void testPreloadIndexingAfterAddingNewNode() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      for (CacheStore cs: TestingUtil.cachestores(this.<String, Person>caches())) {
+         assert cs.containsKey(persons[0].getName()) :
+               ""Cache misconfigured, maybe cache store not pointing to same place, maybe passivation on...etc"";
+         DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
+         assert dimcs.stats().get(""clear"") == 0:
+               ""Cache store should not be cleared, purgeOnStartup is false"";
+         assert dimcs.stats().get(""store"") == 4:
+               ""Cache store should have been written to just once, but was written to "" + dimcs.stats().get(""store"") + "" times"";
+      }
+
+      // Before adding a node, verify that the query resolves properly
+      executeSimpleQuery(this.<String, Person>caches().get(0));
+
+      addNodeCheckingContentsAndQuery();
+   }
+
+}",2012-08-30T15:45:20Z,7
"@@ -0,0 +1,138 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.apache.lucene.queryParser.ParseException;
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.query.CacheQuery;
+import org.infinispan.query.test.Person;
+import org.infinispan.statetransfer.JoiningNode;
+import org.infinispan.test.CacheManagerCallable;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.fwk.TransportFlags;
+
+import java.util.List;
+
+import static org.infinispan.query.helper.TestQueryHelperFactory.createCacheQuery;
+import static org.infinispan.test.TestingUtil.withCacheManager;
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Base class for state transfer and query related tests
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public abstract class BaseReIndexingTest extends MultipleCacheManagersTest {
+
+   protected Person[] persons;
+   protected ConfigurationBuilder builder;
+
+   abstract protected void configureCache(ConfigurationBuilder builder);
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      builder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, false);
+
+      // Explicitly disable fetching in-memory state in order
+      // to fetch it from the persistence layer
+      builder.indexing().enable().indexLocalOnly(true)
+            .addProperty(""hibernate.search.default.directory_provider"", ""ram"")
+            .addProperty(""hibernate.search.lucene_version"", ""LUCENE_CURRENT"");
+
+      configureCache(builder);
+
+      createClusteredCaches(2, builder);
+   }
+
+   private EmbeddedCacheManager createCacheManager() {
+      return addClusterEnabledCacheManager(
+            builder, new TransportFlags().withMerge(true));
+   }
+
+   protected void executeSimpleQuery(Cache<String, Person> cache) throws ParseException {
+      CacheQuery cacheQuery = createCacheQuery(cache, ""blurb"", ""playing"");
+      List<Object> found = cacheQuery.list();
+      int elems = found.size();
+      assertEquals(1, elems);
+      Object val = found.get(0);
+      Person expectedPerson = persons[0];
+      assertEquals(expectedPerson, val);
+   }
+
+   protected void loadCacheEntries(Cache<String, Person> cache) {
+      Person person1 = new Person();
+      person1.setName(""NavinSurtani"");
+      person1.setBlurb(""Likes playing WoW"");
+      person1.setAge(45);
+
+      Person person2 = new Person();
+      person2.setName(""BigGoat"");
+      person2.setBlurb(""Eats grass"");
+      person2.setAge(30);
+
+      Person person3 = new Person();
+      person3.setName(""MiniGoat"");
+      person3.setBlurb(""Eats cheese"");
+      person3.setAge(35);
+
+      Person person4 = new Person();
+      person4.setName(""MightyGoat"");
+      person4.setBlurb(""Also eats grass"");
+      person4.setAge(66);
+
+      persons = new Person[]{person1, person2, person3, person4};
+
+      // Put the 3 created objects in the cache
+      cache.put(person1.getName(), person1);
+      cache.put(person2.getName(), person2);
+      cache.put(person3.getName(), person3);
+      cache.put(person4.getName(), person4);
+   }
+
+   protected void addNodeCheckingContentsAndQuery() {
+      withCacheManager(new CacheManagerCallable(createCacheManager()) {
+         @Override
+         public void call() {
+            try {
+               // New node joining
+               JoiningNode newNode = new JoiningNode(cm);
+               Cache<String, Person> newCache = newNode.getCache();
+               newNode.waitForJoin(120000, caches().get(0), caches().get(1), newCache);
+
+               // Verify state transfer
+               int size = newCache.size();
+               assertEquals(4, size);
+               for (int i = 0; i < size; i++)
+                  assertEquals(persons[i], newCache.get(persons[i].getName()));
+
+               // Repeat query on new node
+               executeSimpleQuery(newCache);
+            } catch (Exception e) {
+               throw new RuntimeException(e);
+            }
+         }
+      });
+   }
+
+}",2012-08-30T15:45:20Z,51
"@@ -0,0 +1,94 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.Test;
+
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Test that verifies that querying works even after multiple nodes have
+ * started with unshared, passivated, cache stores, and a new node comes in
+ * to fetch the persistent state from the other nodes.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.PersistentStateTransferQueryIndexTest"")
+public class PersistentStateTransferQueryIndexTest extends BaseReIndexingTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      builder.clustering().stateTransfer().fetchInMemoryState(false)
+            .loaders().passivation(true).shared(false).addStore()
+            .cacheStore(new DummyInMemoryCacheStore())
+                  .fetchPersistentState(true);
+   }
+
+   public void testFetchingPersistentStateUpdatesIndex() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      // Before adding a node, verify that the query resolves properly
+      Cache<String, Person> cache1 = this.<String, Person>caches().get(0);
+      executeSimpleQuery(cache1);
+
+      // Since passivation is enabled, cache stores should still be empty
+      checkCacheStoresEmpty();
+
+      // Evict manually entries from both nodes
+      for (Cache<Object, Object> cache : caches()) {
+         for (Person p2 : persons) {
+            cache.evict(p2.getName());
+         }
+      }
+
+      // After eviction, cache stores should be loaded with instances
+      checkCacheStoresContainPersons();
+
+      // Finally add a node and verify that state transfer happens and query works
+      addNodeCheckingContentsAndQuery();
+   }
+
+   private void checkCacheStoresContainPersons() throws CacheLoaderException {
+      for (Cache<Object, Object> cache : caches()) {
+         CacheStore store = TestingUtil.extractComponent(cache, CacheLoaderManager.class).getCacheStore();
+         for (int i = 0; i < persons.length; i++)
+            assertEquals(persons[i], store.load(persons[i].getName()).getValue());
+      }
+   }
+
+   private void checkCacheStoresEmpty() throws CacheLoaderException {
+      for (Cache<Object, Object> cache : caches()) {
+         CacheStore store = TestingUtil.extractComponent(cache, CacheLoaderManager.class).getCacheStore();
+         for (Person person : persons) {
+            assert !store.containsKey(person.getName());
+         }
+      }
+   }
+
+}",2012-08-30T15:45:20Z,52
"@@ -0,0 +1,50 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.query.test.Person;
+import org.testng.annotations.Test;
+
+/**
+ * Test that verifies that querying works even after a new node is added and
+ * state transfer has provided it with the data belonging to that node.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.StateTransferQueryIndexTest"")
+public class StateTransferQueryIndexTest extends BaseReIndexingTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      builder.clustering().stateTransfer().fetchInMemoryState(true);
+   }
+
+   public void testQueryAfterAddingNewNode() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      // Before adding a node, verify that the query resolves properly
+      executeSimpleQuery(this.<String, Person>caches().get(0));
+
+      addNodeCheckingContentsAndQuery();
+   }
+
+}",2012-08-30T15:45:20Z,53
"@@ -0,0 +1,243 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.topology;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.util.Immutables;
+
+/**
+* Keeps track of a cache's status: members, current/pending consistent hashes, and rebalance status
+*
+* @author Dan Berindei
+* @since 5.2
+*/
+class ClusterCacheStatus {
+   private final String cacheName;
+   private final CacheJoinInfo joinInfo;
+   // Cache members, some of which may not have received state yet
+   private volatile List<Address> members;
+   // Cache members that have not yet received state
+   private volatile List<Address> joiners;
+   // Cache topology. Its consistent hashes contain only members that did receive/are receiving state
+   private volatile CacheTopology cacheTopology;
+
+   private volatile RebalanceConfirmationCollector rebalanceStatus;
+
+   public ClusterCacheStatus(String cacheName, CacheJoinInfo joinInfo) {
+      this.cacheName = cacheName;
+      this.joinInfo = joinInfo;
+
+      this.cacheTopology = new CacheTopology(-1, null, null);
+      this.members = Collections.emptyList();
+      this.joiners = Collections.emptyList();
+   }
+
+   public CacheJoinInfo getJoinInfo() {
+      return joinInfo;
+   }
+
+   public List<Address> getMembers() {
+      return members;
+   }
+
+   public boolean hasMembers() {
+      return !members.isEmpty();
+   }
+
+   public List<Address> getJoiners() {
+      return joiners;
+   }
+
+   public boolean hasJoiners() {
+      return !joiners.isEmpty();
+   }
+
+   public void setMembers(List<Address> newMembers) {
+      synchronized (this) {
+         members = Immutables.immutableListCopy(newMembers);
+
+         ConsistentHash currentCH = cacheTopology.getCurrentCH();
+         if (currentCH != null) {
+            joiners = immutableRemoveAll(members, currentCH.getMembers());
+         } else {
+            joiners = members;
+         }
+      }
+   }
+
+   /**
+    * @return {@code true} if the joiner was not already a member, {@code false} otherwise
+    */
+   public boolean addMember(Address joiner) {
+      synchronized (this) {
+         if (members.contains(joiner))
+            return false;
+
+         members = immutableAdd(members, joiner);
+         joiners = immutableAdd(joiners, joiner);
+         return true;
+      }
+   }
+
+   /**
+    * @return {@code true} if the leaver was a member, {@code false} otherwise
+    */
+   public boolean removeMember(Address leaver) {
+      synchronized (this) {
+         if (!members.contains(leaver))
+            return false;
+
+         members = immutableRemove(members, leaver);
+         joiners = immutableRemove(joiners, leaver);
+         return true;
+      }
+   }
+
+   /**
+    * @return {@code true} if the members list has changed, {@code false} otherwise
+    */
+   public boolean updateClusterMembers(List<Address> newClusterMembers) {
+      synchronized (this) {
+         if (newClusterMembers.containsAll(members))
+            return false;
+
+         members = immutableRetainAll(members, newClusterMembers);
+         joiners = immutableRetainAll(joiners, newClusterMembers);
+         return true;
+      }
+   }
+
+   public CacheTopology getCacheTopology() {
+      return cacheTopology;
+   }
+
+   public void updateCacheTopology(CacheTopology newTopology) {
+      synchronized (this) {
+         this.cacheTopology = newTopology;
+
+         // update the joiners list
+         if (newTopology.getCurrentCH() != null) {
+            joiners = immutableRemoveAll(joiners, newTopology.getCurrentCH().getMembers());
+         }
+      }
+   }
+
+   public boolean needConsistentHashUpdate() {
+      // The list of current members is always included in the list of pending members,
+      // so we only need to check one list.
+      // Also returns false if both CHs are null
+      return !members.containsAll(cacheTopology.getMembers());
+   }
+
+   public List<Address> pruneInvalidMembers(List<Address> possibleMembers) {
+      return immutableRetainAll(possibleMembers, members);
+   }
+
+   public boolean isRebalanceInProgress() {
+      return rebalanceStatus != null;
+   }
+
+   /**
+    * @return {@code true} if a rebalance was started, {@code false} if a rebalance was already in progress
+    */
+   public boolean startRebalance(CacheTopology newTopology) {
+      synchronized (this) {
+         if (rebalanceStatus != null)
+            return false;
+
+         rebalanceStatus = new RebalanceConfirmationCollector(cacheName, newTopology.getTopologyId(),
+               newTopology.getMembers());
+         this.cacheTopology = newTopology;
+         return true;
+      }
+   }
+
+   /**
+    * @return {@code true} if this was the last confirmation needed, {@code false} if more confirmations
+    *    are needed or if the rebalance was already confirmed in another way (e.g. members list update)
+    */
+   public boolean confirmRebalanceOnNode(Address member, int receivedTopologyId) {
+      synchronized (this) {
+         if (rebalanceStatus == null)
+            return false;
+
+         return rebalanceStatus.confirmRebalance(member, receivedTopologyId);
+      }
+   }
+
+   /**
+    * Should be called after the members list was updated in any other way ({@link #removeMember(Address)},
+    * {@link #updateClusterMembers} etc.)
+    *
+    * @return {@code true} if the rebalance was confirmed with this update, {@code false} if more confirmations
+    *    are needed or if the rebalance was already confirmed in another way (e.g. the last member confirmed)
+    */
+   public boolean updateRebalanceMembersList() {
+      synchronized (this) {
+         if (rebalanceStatus == null)
+            return false;
+
+         return rebalanceStatus.updateMembers(members);
+      }
+   }
+
+   public void endRebalance(CacheTopology newTopology) {
+      synchronized (this) {
+         if (rebalanceStatus == null) {
+            throw new IllegalStateException(""Can't end rebalance, there is no rebalance in progress"");
+         }
+
+         updateCacheTopology(newTopology);
+         rebalanceStatus = null;
+      }
+   }
+
+   // Helpers for working with immutable lists
+   private <T> List<T> immutableAdd(List<T> list, T element) {
+      List<T> result = new ArrayList<T>(list);
+      result.add(element);
+      return Collections.unmodifiableList(result);
+   }
+
+   private <T> List<T> immutableRemove(List<T> list, T element) {
+      List<T> result = new ArrayList<T>(list);
+      result.remove(element);
+      return Collections.unmodifiableList(result);
+   }
+
+   private <T> List<T> immutableRemoveAll(List<T> list, List<T> otherList) {
+      List<T> result = new ArrayList<T>(list);
+      result.removeAll(otherList);
+      return Collections.unmodifiableList(result);
+   }
+
+   private <T> List<T> immutableRetainAll(List<T> list, List<T> otherList) {
+      List<T> result = new ArrayList<T>(list);
+      result.retainAll(otherList);
+      return Collections.unmodifiableList(result);
+   }
+
+
+}",2012-09-28T14:00:48Z,650
"@@ -33,16 +33,10 @@
  */
 @Scope(Scopes.GLOBAL)
 public interface ClusterTopologyManager {
-   /**
-    * Used by {@link RebalancePolicy} to update the consistent hash on all the members,
-    * without triggering a state transfer.
-    */
-   void updateConsistentHash(String cacheName, CacheTopology cacheTopology) throws Exception;
-
    /**
     * Used by {@link RebalancePolicy} to start a state transfer.
     */
-   void rebalance(String cacheName, CacheTopology cacheTopology) throws Exception;
+   void triggerRebalance(String cacheName) throws Exception;
 
 
    /**",2012-09-28T14:00:48Z,651
"@@ -21,13 +21,9 @@
 
 
 import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
 import java.util.HashMap;
-import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
-import java.util.Set;
 import java.util.concurrent.Callable;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.ExecutorService;
@@ -37,6 +33,8 @@
 import org.infinispan.CacheException;
 import org.infinispan.commands.ReplicableCommand;
 import org.infinispan.configuration.global.GlobalConfiguration;
+import org.infinispan.distribution.ch.ConsistentHash;
+import org.infinispan.distribution.ch.ConsistentHashFactory;
 import org.infinispan.factories.GlobalComponentRegistry;
 import org.infinispan.factories.annotations.ComponentName;
 import org.infinispan.factories.annotations.Inject;
@@ -81,7 +79,7 @@ public class ClusterTopologyManagerImpl implements ClusterTopologyManager {
 
 
    //private ConcurrentMap<String, CacheJoinInfo> clusterCaches = ConcurrentMapFactory.makeConcurrentMap();
-   private final ConcurrentMap<String, RebalanceInfo> rebalanceStatusMap = ConcurrentMapFactory.makeConcurrentMap();
+   private final ConcurrentMap<String, ClusterCacheStatus> cacheStatusMap = ConcurrentMapFactory.makeConcurrentMap();
    private ClusterTopologyManagerImpl.ClusterViewListener listener;
 
    @Inject
@@ -124,46 +122,16 @@ public void stop() {
    }
 
    @Override
-   public void updateConsistentHash(String cacheName, CacheTopology cacheTopology) throws Exception {
-      log.debugf(""Updating cluster-wide consistent hash for cache %s, topology = %s"",
-            cacheName, cacheTopology);
-      ReplicableCommand command = new CacheTopologyControlCommand(cacheName,
-            CacheTopologyControlCommand.Type.CH_UPDATE, transport.getAddress(), cacheTopology,
-            transport.getViewId());
-      executeOnClusterSync(command, getGlobalTimeout());
-
-      RebalanceInfo rebalanceInfo = rebalanceStatusMap.get(cacheName);
-      if (rebalanceInfo != null) {
-         List<Address> members = cacheTopology.getMembers();
-         if (rebalanceInfo.updateMembers(members)) {
-            // all the nodes that haven't confirmed yet have left the cache/cluster
-            onClusterRebalanceCompleted(cacheName, cacheTopology.getTopologyId(), rebalanceInfo);
+   public void triggerRebalance(final String cacheName) throws Exception {
+      asyncTransportExecutor.submit(new Callable<Object>() {
+         @Override
+         public Object call() throws Exception {
+            startRebalance(cacheName);
+            return null;
          }
-      }
-   }
-
-   private void onClusterRebalanceCompleted(String cacheName, int topologyId, RebalanceInfo rebalanceInfo) throws Exception {
-      log.debugf(""Removing rebalance information for topology id %d"", topologyId);
-      rebalanceStatusMap.remove(cacheName);
-      rebalancePolicy.onRebalanceCompleted(cacheName, topologyId);
+      });
    }
 
-   @Override
-   public void rebalance(String cacheName, CacheTopology cacheTopology) throws Exception {
-      log.debugf(""Starting cluster-wide rebalance for cache %s, topology = %s"", cacheName, cacheTopology);
-      int topologyId = cacheTopology.getTopologyId();
-      Collection<Address> members = cacheTopology.getPendingCH().getMembers();
-      RebalanceInfo existingRebalance = rebalanceStatusMap.putIfAbsent(cacheName,
-            new RebalanceInfo(cacheName, topologyId, members));
-      if (existingRebalance != null) {
-         throw new IllegalStateException(""Aborting the current rebalance, there is another operation "" +
-               ""in progress: "" + existingRebalance);
-      }
-      ReplicableCommand command = new CacheTopologyControlCommand(cacheName,
-            CacheTopologyControlCommand.Type.REBALANCE_START, transport.getAddress(), cacheTopology,
-            viewId);
-      executeOnClusterAsync(command);
-   }
 
    @Override
    public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo joinInfo, int viewId) throws Exception {
@@ -173,8 +141,32 @@ public CacheTopology handleJoin(String cacheName, Address joiner, CacheJoinInfo
                joiner, cacheName);
          return null;
       }
-      rebalancePolicy.initCache(cacheName, joinInfo);
-      return rebalancePolicy.addJoiners(cacheName, Collections.singletonList(joiner));
+
+      ClusterCacheStatus cacheStatus = initCacheStatusIfAbsent(cacheName, joinInfo);
+      boolean hadEmptyConsistentHashes;
+      synchronized (cacheStatus) {
+         hadEmptyConsistentHashes = cacheStatus.getCacheTopology().getMembers().isEmpty();
+         cacheStatus.addMember(joiner);
+         if (hadEmptyConsistentHashes) {
+            // This node was the first to join. We need to install the initial CH
+            int newTopologyId = cacheStatus.getCacheTopology().getTopologyId() + 1;
+            List<Address> initialMembers = cacheStatus.getMembers();
+            ConsistentHash initialCH = joinInfo.getConsistentHashFactory().create(
+                  joinInfo.getHashFunction(), joinInfo.getNumOwners(), joinInfo.getNumSegments(), initialMembers);
+            CacheTopology initialTopology = new CacheTopology(newTopologyId, initialCH, null);
+            cacheStatus.updateCacheTopology(initialTopology);
+            // Don't need to broadcast the initial CH, just return the cache topology to the joiner
+         } else {
+            // Do nothing. The rebalance policy will trigger a rebalance later.
+         }
+      }
+      if (hadEmptyConsistentHashes) {
+         rebalancePolicy.initCache(cacheName, cacheStatus);
+      } else {
+         rebalancePolicy.updateCacheStatus(cacheName, cacheStatus);
+      }
+
+      return cacheStatus.getCacheTopology();
    }
 
    @Override
@@ -184,7 +176,18 @@ public void handleLeave(String cacheName, Address leaver, int viewId) throws Exc
                leaver, cacheName);
          return;
       }
-      rebalancePolicy.removeLeavers(cacheName, Collections.singletonList(leaver));
+
+      ClusterCacheStatus cacheStatus = cacheStatusMap.get(cacheName);
+      if (cacheStatus == null) {
+         // This can happen if we've just become coordinator
+         log.tracef(""Ignoring leave request from %s for cache %s because it doesn't have a cache status entry"");
+         return;
+      }
+      boolean actualLeaver = cacheStatus.removeMember(leaver);
+      if (!actualLeaver)
+         return;
+
+      onCacheMembershipChange(cacheName, cacheStatus);
    }
 
    @Override
@@ -196,14 +199,275 @@ public void handleRebalanceCompleted(String cacheName, Address node, int topolog
       }
       log.debugf(""Finished local rebalance for cache %s on node %s, topology id = %d"", cacheName, node,
             topologyId);
-      RebalanceInfo rebalanceInfo = rebalanceStatusMap.get(cacheName);
-      if (rebalanceInfo == null) {
+      ClusterCacheStatus cacheStatus = cacheStatusMap.get(cacheName);
+      if (cacheStatus == null || !cacheStatus.isRebalanceInProgress()) {
          throw new CacheException(String.format(""Received invalid rebalance confirmation from %s "" +
                ""for cache %s, we don't have a rebalance in progress"", node, cacheName));
       }
 
-      if (rebalanceInfo.confirmRebalance(node, topologyId)) {
-         onClusterRebalanceCompleted(cacheName, topologyId, rebalanceInfo);
+      boolean rebalanceCompleted = cacheStatus.confirmRebalanceOnNode(node, topologyId);
+      if (rebalanceCompleted) {
+         endRebalance(cacheName, cacheStatus);
+         broadcastConsistentHashUpdate(cacheName, cacheStatus);
+         rebalancePolicy.updateCacheStatus(cacheName, cacheStatus);
+      }
+   }
+
+   protected void handleNewView(List<Address> newMembers, boolean mergeView, int newViewId) {
+      // check to ensure this is not an older view
+      if (newViewId <= viewId) {
+         log.tracef(""Ignoring old cluster view notification: %s"", newViewId);
+         return;
+      }
+
+      log.tracef(""Received new cluster view: %s"", newViewId);
+      boolean becameCoordinator = !isCoordinator && transport.isCoordinator();
+      isCoordinator = transport.isCoordinator();
+
+      if (mergeView || becameCoordinator) {
+         try {
+            Map<String, List<CacheTopology>> clusterCacheMap = recoverClusterStatus();
+
+            for (Map.Entry<String, List<CacheTopology>> e : clusterCacheMap.entrySet()) {
+               String cacheName = e.getKey();
+               List<CacheTopology> topologyList = e.getValue();
+               updateCacheStatusAfterMerge(cacheName, topologyList);
+            }
+         } catch (InterruptedException e) {
+            log.tracef(""Cluster state recovery interrupted because the coordinator is shutting down"");
+            // the CTMI has already stopped, no need to update the view id or notify waiters
+            return;
+         } catch (Exception e) {
+            // TODO Retry?
+            log.failedToRecoverClusterState(e);
+         }
+      } else if (isCoordinator) {
+         try {
+            updateClusterMembers(newMembers);
+         } catch (Exception e) {
+            log.errorUpdatingMembersList(e);
+         }
+      }
+
+      synchronized (viewUpdateLock) {
+         // update the view id last, so join requests from other nodes wait until we recovered existing members' info
+         viewId = newViewId;
+         viewUpdateLock.notifyAll();
+      }
+   }
+
+   private ClusterCacheStatus initCacheStatusIfAbsent(String cacheName, CacheJoinInfo joinInfo) {
+      ClusterCacheStatus cacheStatus = cacheStatusMap.get(cacheName);
+      if (cacheStatus == null) {
+         ClusterCacheStatus newCacheStatus = new ClusterCacheStatus(cacheName, joinInfo);
+         cacheStatus = cacheStatusMap.putIfAbsent(cacheName, newCacheStatus);
+         if (cacheStatus == null) {
+            cacheStatus = newCacheStatus;
+         }
+      }
+      return cacheStatus;
+   }
+
+   public void updateCacheStatusAfterMerge(String cacheName, List<CacheTopology> partitionTopologies) throws Exception {
+      log.tracef(""Initializing rebalance policy for cache %s, pre-existing partitions are %s"", cacheName, partitionTopologies);
+      ClusterCacheStatus cacheStatus = cacheStatusMap.get(cacheName);
+      if (partitionTopologies.isEmpty())
+         return;
+
+      int unionTopologyId = 0;
+      ConsistentHash currentCHUnion = null;
+      ConsistentHash pendingCHUnion = null;
+      ConsistentHashFactory chFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
+      for (CacheTopology topology : partitionTopologies) {
+         if (topology.getTopologyId() > unionTopologyId) {
+            unionTopologyId = topology.getTopologyId();
+         }
+         if (currentCHUnion == null) {
+            currentCHUnion = topology.getCurrentCH();
+         } else {
+            currentCHUnion = chFactory.union(currentCHUnion, topology.getCurrentCH());
+         }
+
+         if (pendingCHUnion == null) {
+            pendingCHUnion = topology.getPendingCH();
+         } else {
+            if (topology.getPendingCH() != null)
+               pendingCHUnion = chFactory.union(pendingCHUnion, topology.getPendingCH());
+         }
+      }
+
+      synchronized (cacheStatus) {
+         CacheTopology cacheTopology = new CacheTopology(unionTopologyId, currentCHUnion, pendingCHUnion);
+         // TODO Deal with members had joined in a partition, but which did not start receiving data yet
+         // (i.e. they weren't in the current or in the pending CH)
+         cacheStatus.setMembers(cacheTopology.getMembers());
+         cacheStatus.updateCacheTopology(cacheTopology);
+      }
+
+      broadcastConsistentHashUpdate(cacheName, cacheStatus);
+   }
+
+   private void broadcastConsistentHashUpdate(String cacheName, ClusterCacheStatus cacheStatus) throws Exception {
+      CacheTopology cacheTopology = cacheStatus.getCacheTopology();
+      log.debugf(""Updating cluster-wide consistent hash for cache %s, topology = %s"",
+            cacheName, cacheTopology);
+      ReplicableCommand command = new CacheTopologyControlCommand(cacheName,
+            CacheTopologyControlCommand.Type.CH_UPDATE, transport.getAddress(), cacheTopology,
+            transport.getViewId());
+      executeOnClusterSync(command, getGlobalTimeout());
+   }
+
+   private void startRebalance(String cacheName) throws Exception {
+      ClusterCacheStatus cacheStatus = cacheStatusMap.get(cacheName);
+      CacheTopology cacheTopology = cacheStatus.getCacheTopology();
+      CacheTopology newTopology;
+
+      synchronized (cacheStatus) {
+         boolean isRebalanceInProgress = cacheTopology.getPendingCH() != null;
+         if (isRebalanceInProgress) {
+            log.tracef(""Ignoring request to rebalance cache %s, there's already a rebalance in progress: %s"",
+                  cacheName, cacheTopology);
+            return;
+         }
+
+         List<Address> newMembers = new ArrayList<Address>(cacheStatus.getMembers());
+         if (newMembers.isEmpty()) {
+            log.tracef(""Ignoring request to rebalance cache %s, it doesn't have any member"", cacheName);
+            return;
+         }
+
+         log.tracef(""Rebalancing consistent hash for cache %s, members are %s"", cacheName, newMembers);
+         int newTopologyId = cacheTopology.getTopologyId() + 1;
+         ConsistentHash currentCH = cacheTopology.getCurrentCH();
+         if (currentCH == null) {
+            // There was one node in the cache before, and it left after the rebalance was triggered
+            // but before the rebalance actually started.
+            return;
+         }
+
+         ConsistentHashFactory chFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
+         ConsistentHash updatedMembersCH = chFactory.updateMembers(currentCH, newMembers);
+         ConsistentHash balancedCH = chFactory.rebalance(updatedMembersCH);
+         if (balancedCH.equals(currentCH)) {
+            log.tracef(""The balanced CH is the same as the current CH, not rebalancing"");
+            return;
+         }
+         newTopology = new CacheTopology(newTopologyId, currentCH, balancedCH);
+         log.tracef(""Updating cache %s topology for rebalance: %s"", cacheName, newTopology);
+         cacheStatus.startRebalance(newTopology);
+      }
+
+      rebalancePolicy.updateCacheStatus(cacheName, cacheStatus);
+      broadcastRebalanceStart(cacheName, cacheStatus);
+   }
+
+   private void broadcastRebalanceStart(String cacheName, ClusterCacheStatus cacheStatus) throws Exception {
+      CacheTopology cacheTopology = cacheStatus.getCacheTopology();
+      log.debugf(""Updating cluster-wide consistent hash for cache %s, topology = %s"",
+            cacheName, cacheTopology);
+      ReplicableCommand command = new CacheTopologyControlCommand(cacheName,
+            CacheTopologyControlCommand.Type.REBALANCE_START, transport.getAddress(), cacheTopology,
+            transport.getViewId());
+      executeOnClusterSync(command, getGlobalTimeout());
+   }
+
+   private void endRebalance(String cacheName, ClusterCacheStatus cacheStatus) {
+      CacheTopology currentTopology = cacheStatus.getCacheTopology();
+      int currentTopologyId = currentTopology.getTopologyId();
+      log.debugf(""Finished cluster-wide rebalance for cache %s, topology id = %d"",
+            cacheName, currentTopologyId);
+      int newTopologyId = currentTopologyId + 1;
+      ConsistentHash newCurrentCH = currentTopology.getPendingCH();
+      CacheTopology newTopology = new CacheTopology(newTopologyId, newCurrentCH, null);
+      cacheStatus.endRebalance(newTopology);
+   }
+
+   private HashMap<String, List<CacheTopology>> recoverClusterStatus() throws Exception {
+      log.debugf(""Recovering running caches in the cluster"");
+      ReplicableCommand command = new CacheTopologyControlCommand(null,
+            CacheTopologyControlCommand.Type.GET_STATUS, transport.getAddress(), viewId);
+      Map<Address, Object> statusResponses = executeOnClusterSync(command, getGlobalTimeout());
+
+      HashMap<String, List<CacheTopology>> clusterCacheMap = new HashMap<String, List<CacheTopology>>();
+      for (Object o : statusResponses.values()) {
+         Map<String, Object[]> nodeStatus = (Map<String, Object[]>) o;
+         for (Map.Entry<String, Object[]> e : nodeStatus.entrySet()) {
+            String cacheName = e.getKey();
+            CacheJoinInfo joinInfo = (CacheJoinInfo) e.getValue()[0];
+            CacheTopology cacheTopology = (CacheTopology) e.getValue()[1];
+
+            List<CacheTopology> topologyList = clusterCacheMap.get(cacheName);
+            if (topologyList == null) {
+               // this is the first CacheJoinInfo we got for this cache, initialize its ClusterCacheStatus
+               initCacheStatusIfAbsent(cacheName, joinInfo);
+
+               topologyList = new ArrayList<CacheTopology>();
+               clusterCacheMap.put(cacheName, topologyList);
+            }
+            topologyList.add(cacheTopology);
+         }
+      }
+      return clusterCacheMap;
+   }
+
+   public void updateClusterMembers(List<Address> newClusterMembers) throws Exception {
+      log.tracef(""Updating cluster members for all the caches. New list is %s"", newClusterMembers);
+
+      for (Map.Entry<String, ClusterCacheStatus> e : cacheStatusMap.entrySet()) {
+         String cacheName = e.getKey();
+         ClusterCacheStatus cacheStatus = e.getValue();
+         boolean cacheMembersModified = cacheStatus.updateClusterMembers(newClusterMembers);
+         if (!cacheMembersModified)
+            return;
+
+         onCacheMembershipChange(cacheName, cacheStatus);
+      }
+   }
+
+   private boolean onCacheMembershipChange(String cacheName, ClusterCacheStatus cacheStatus) throws Exception {
+      boolean topologyChanged = updateTopologyAfterMembershipChange(cacheStatus);
+      if (!topologyChanged)
+         return true;
+
+      boolean rebalanceCompleted = cacheStatus.updateRebalanceMembersList();
+      if (rebalanceCompleted) {
+         endRebalance(cacheName, cacheStatus);
+      }
+
+      // We need a consistent hash update even when rebalancing did end
+      broadcastConsistentHashUpdate(cacheName, cacheStatus);
+
+      rebalancePolicy.updateCacheStatus(cacheName, cacheStatus);
+      return false;
+   }
+
+   private boolean updateTopologyAfterMembershipChange(ClusterCacheStatus cacheStatus) {
+      synchronized (cacheStatus) {
+         ConsistentHashFactory consistentHashFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
+         int topologyId = cacheStatus.getCacheTopology().getTopologyId();
+         ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
+         ConsistentHash pendingCH = cacheStatus.getCacheTopology().getPendingCH();
+         if (!cacheStatus.needConsistentHashUpdate()) {
+            // The cache already had an empty CH, there's nothing left to do
+            return false;
+         }
+
+         List<Address> newCurrentMembers = cacheStatus.pruneInvalidMembers(currentCH.getMembers());
+         if (newCurrentMembers.isEmpty()) {
+            CacheTopology newTopology = new CacheTopology(topologyId + 1, null, null);
+            cacheStatus.updateCacheTopology(newTopology);
+            // Technically the topology changed, but there's nobody to broadcast that update to
+            return false;
+         }
+         ConsistentHash newCurrentCH = consistentHashFactory.updateMembers(currentCH, newCurrentMembers);
+         ConsistentHash newPendingCH = null;
+         if (pendingCH != null) {
+            List<Address> newPendingMembers = cacheStatus.pruneInvalidMembers(pendingCH.getMembers());
+            newPendingCH = consistentHashFactory.updateMembers(pendingCH, newPendingMembers);
+         }
+         CacheTopology newTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
+         cacheStatus.updateCacheTopology(newTopology);
+         return true;
       }
    }
 
@@ -284,6 +548,10 @@ public Object call() throws Exception {
       });
    }
 
+   private int getGlobalTimeout() {
+      // TODO Rename setting to something like globalRpcTimeout
+      return (int) globalConfiguration.transport().distributedSyncTimeout();
+   }
 
    // need to recover existing caches asynchronously (in case we just became the coordinator)
    @Listener(sync = false)
@@ -295,135 +563,4 @@ public void handleViewChange(final ViewChangedEvent e) {
       }
    }
 
-   private void handleNewView(List<Address> newMembers, boolean mergeView, int newViewId) {
-      // check to ensure this is not an older view
-      if (newViewId <= viewId) {
-         log.tracef(""Ignoring old cluster view notification: %s"", newViewId);
-         return;
-      }
-
-      log.tracef(""Received new cluster view: %s"", newViewId);
-      boolean becameCoordinator = !isCoordinator && transport.isCoordinator();
-      isCoordinator = transport.isCoordinator();
-
-      if (mergeView || becameCoordinator) {
-         try {
-            Map<String, List<CacheTopology>> clusterCacheMap = recoverClusterStatus();
-
-            for (Map.Entry<String, List<CacheTopology>> e : clusterCacheMap.entrySet()) {
-               String cacheName = e.getKey();
-               List<CacheTopology> topologyList = e.getValue();
-               rebalancePolicy.initCache(cacheName, topologyList);
-            }
-         } catch (InterruptedException e) {
-            log.tracef(""Cluster state recovery interrupted because the coordinator is shutting down"");
-            // the CTMI has already stopped, no need to update the view id or notify waiters
-            return;
-         } catch (Exception e) {
-            // TODO Retry?
-            log.failedToRecoverClusterState(e);
-         }
-      } else if (isCoordinator) {
-         try {
-            rebalancePolicy.updateMembersList(newMembers);
-         } catch (Exception e) {
-            log.errorUpdatingMembersList(e);
-         }
-      }
-
-      synchronized (viewUpdateLock) {
-         // update the view id last, so join requests from other nodes wait until we recovered existing members' info
-         viewId = newViewId;
-         viewUpdateLock.notifyAll();
-      }
-   }
-
-   private HashMap<String, List<CacheTopology>> recoverClusterStatus() throws Exception {
-      log.debugf(""Recovering running caches in the cluster"");
-      ReplicableCommand command = new CacheTopologyControlCommand(null,
-         CacheTopologyControlCommand.Type.GET_STATUS, transport.getAddress(), transport.getViewId());
-      Map<Address, Object> statusResponses = executeOnClusterSync(command, getGlobalTimeout());
-
-      HashMap<String, List<CacheTopology>> clusterCacheMap = new HashMap<String, List<CacheTopology>>();
-      for (Object o : statusResponses.values()) {
-         Map<String, Object[]> nodeStatus = (Map<String, Object[]>) o;
-         for (Map.Entry<String, Object[]> e : nodeStatus.entrySet()) {
-            String cacheName = e.getKey();
-            CacheJoinInfo joinInfo = (CacheJoinInfo) e.getValue()[0];
-            CacheTopology cacheTopology = (CacheTopology) e.getValue()[1];
-
-            List<CacheTopology> topologyList = clusterCacheMap.get(cacheName);
-            if (topologyList == null) {
-               // this is the first CacheJoinInfo we got for this cache
-               rebalancePolicy.initCache(cacheName, joinInfo);
-
-               topologyList = new ArrayList<CacheTopology>();
-               clusterCacheMap.put(cacheName, topologyList);
-            }
-            topologyList.add(cacheTopology);
-         }
-      }
-      return clusterCacheMap;
-   }
-
-   private int getGlobalTimeout() {
-      // TODO Rename setting to something like globalRpcTimeout
-      return (int) globalConfiguration.transport().distributedSyncTimeout();
-   }
-
-
-   private static class RebalanceInfo {
-      private final String cacheName;
-      private final int topologyId;
-      private final Set<Address> confirmationsNeeded;
-
-      public RebalanceInfo(String cacheName, int topologyId, Collection<Address> members) {
-         this.cacheName = cacheName;
-         this.topologyId = topologyId;
-         this.confirmationsNeeded = new HashSet<Address>(members);
-         log.tracef(""Initialized rebalance confirmation collector %d, initial list is %s"", topologyId, confirmationsNeeded);
-      }
-
-      /**
-       * @return {@code true} if everyone has confirmed
-       */
-      public boolean confirmRebalance(Address node, int receivedTopologyId) {
-         synchronized (this) {
-            if (topologyId != receivedTopologyId) {
-               throw new CacheException(String.format(""Received invalid rebalance confirmation from %s "" +
-                     ""for cache %s, expecting topology id %d but got %d"", node, cacheName, topologyId, receivedTopologyId));
-            }
-
-            boolean removed = confirmationsNeeded.remove(node);
-            if (!removed) {
-               log.tracef(""Rebalance confirmation collector %d ignored confirmation for %s, which is not a member"",
-                     topologyId, node);
-               return false;
-            }
-
-            log.tracef(""Rebalance confirmation collector %d received confirmation for %s, remaining list is %s"",
-                  topologyId, node, confirmationsNeeded);
-            return confirmationsNeeded.isEmpty();
-         }
-      }
-
-      /**
-       * @return {@code true} if everyone has confirmed
-       */
-      public boolean updateMembers(Collection<Address> newMembers) {
-         synchronized (this) {
-            // only return true the first time
-            boolean modified = confirmationsNeeded.retainAll(newMembers);
-            return modified && confirmationsNeeded.isEmpty();
-         }
-      }
-
-      @Override
-      public String toString() {
-         return ""RebalanceInfo{"" +
-               ""topologyId="" + topologyId +
-               "", confirmationsNeeded="" + confirmationsNeeded +
-               '}';
-      }
-   }
 }
\ No newline at end of file",2012-09-28T14:00:48Z,124
"@@ -19,19 +19,13 @@
 
 package org.infinispan.topology;
 
-import java.util.ArrayList;
 import java.util.List;
-import java.util.Map;
-import java.util.concurrent.Callable;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.ExecutorService;
 
-import org.infinispan.configuration.global.GlobalConfiguration;
 import org.infinispan.distribution.ch.ConsistentHash;
-import org.infinispan.distribution.ch.ConsistentHashFactory;
 import org.infinispan.factories.annotations.ComponentName;
 import org.infinispan.factories.annotations.Inject;
-import org.infinispan.factories.annotations.Start;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.remoting.transport.Transport;
 import org.infinispan.util.concurrent.ConcurrentMapFactory;
@@ -49,313 +43,42 @@
 public class DefaultRebalancePolicy implements RebalancePolicy {
    private static Log log = LogFactory.getLog(DefaultRebalancePolicy.class);
 
-   private Transport transport;
    private ClusterTopologyManager clusterTopologyManager;
-   private ExecutorService asyncTransportExecutor;
-   private GlobalConfiguration globalConfiguration;
-
-   private volatile List<Address> clusterMembers;
-   private final ConcurrentMap<String, CacheStatus> cacheStatusMap = ConcurrentMapFactory.makeConcurrentMap();
 
    @Inject
-   public void inject(Transport transport, ClusterTopologyManager clusterTopologyManager,
-                      @ComponentName(ASYNC_TRANSPORT_EXECUTOR) ExecutorService asyncTransportExecutor,
-                      GlobalConfiguration globalConfiguration) {
-      this.transport = transport;
+   public void inject(ClusterTopologyManager clusterTopologyManager) {
       this.clusterTopologyManager = clusterTopologyManager;
-      this.asyncTransportExecutor = asyncTransportExecutor;
-      this.globalConfiguration = globalConfiguration;
-   }
-
-   // must start before ClusterTopologyManager
-   @Start(priority = 99)
-   public void start() {
-      this.clusterMembers = transport.getMembers();
    }
 
    @Override
-   public void initCache(String cacheName, CacheJoinInfo joinInfo) throws Exception {
+   public void initCache(String cacheName, ClusterCacheStatus cacheStatus) throws Exception {
       log.tracef(""Initializing rebalance policy for cache %s"", cacheName);
-      cacheStatusMap.putIfAbsent(cacheName, new CacheStatus(joinInfo));
    }
 
    @Override
-   public void initCache(String cacheName, List<CacheTopology> partitionTopologies) throws Exception {
-      log.tracef(""Initializing rebalance policy for cache %s, pre-existing partitions are %s"", cacheName, partitionTopologies);
-      CacheStatus cacheStatus = cacheStatusMap.get(cacheName);
-      if (partitionTopologies.isEmpty())
+   public void updateCacheStatus(String cacheName, ClusterCacheStatus cacheStatus) throws Exception {
+      log.tracef(""Cache %s status changed: joiners=%s, topology=%s"", cacheName, cacheStatus.getJoiners(),
+            cacheStatus.getCacheTopology());
+      if (!cacheStatus.hasMembers()) {
+         log.tracef(""Not triggering rebalance for zero-members cache %s"", cacheName);
          return;
-
-      int unionTopologyId = 0;
-      ConsistentHash currentCHUnion = null;
-      ConsistentHash pendingCHUnion = null;
-      ConsistentHashFactory chFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
-      for (CacheTopology topology : partitionTopologies) {
-         if (topology.getTopologyId() > unionTopologyId) {
-            unionTopologyId = topology.getTopologyId();
-         }
-         if (currentCHUnion == null) {
-            currentCHUnion = topology.getCurrentCH();
-         } else {
-            currentCHUnion = chFactory.union(currentCHUnion, topology.getCurrentCH());
-         }
-
-         if (pendingCHUnion == null) {
-            pendingCHUnion = topology.getPendingCH();
-         } else {
-            if (topology.getPendingCH() != null)
-            pendingCHUnion = chFactory.union(pendingCHUnion, topology.getPendingCH());
-         }
-      }
-
-      synchronized (cacheStatus) {
-         CacheTopology cacheTopology = new CacheTopology(unionTopologyId, currentCHUnion, pendingCHUnion);
-         updateConsistentHash(cacheName, cacheStatus, cacheTopology, true);
-         // TODO Trigger a new rebalance
-      }
-   }
-
-   /**
-    * Should only be called while holding the cacheStatus lock
-    */
-   private void updateConsistentHash(String cacheName, CacheStatus cacheStatus, CacheTopology cacheTopology,
-                                     boolean broadcast) throws Exception {
-      log.tracef(""Updating cache %s topology: %s"", cacheName, cacheTopology);
-      cacheStatus.setCacheTopology(cacheTopology);
-      ConsistentHash currentCH = cacheTopology.getCurrentCH();
-      if (currentCH != null) {
-         cacheStatus.getJoiners().removeAll(currentCH.getMembers());
-         log.tracef(""Updated joiners list for cache %s: %s"", cacheName, cacheStatus.getJoiners());
-      }
-      if (broadcast) {
-         clusterTopologyManager.updateConsistentHash(cacheName, cacheStatus.getCacheTopology());
-      }
-   }
-
-   @Override
-   public void updateMembersList(List<Address> newClusterMembers) throws Exception {
-      this.clusterMembers = newClusterMembers;
-      log.tracef(""Updating cluster members for all the caches. New list is %s"", newClusterMembers);
-
-      for (Map.Entry<String, CacheStatus> e : cacheStatusMap.entrySet()) {
-         String cacheName = e.getKey();
-         CacheStatus cacheStatus = e.getValue();
-         synchronized (cacheStatus) {
-            //cacheStatus.joiners.retainAll(newClusterMembers);
-            ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
-            // the consistent hash may not be initialized yet
-            if (currentCH == null)
-               continue;
-            ConsistentHash pendingCH = cacheStatus.getCacheTopology().getPendingCH();
-            boolean currentMembersValid = newClusterMembers.containsAll(currentCH.getMembers());
-            boolean pendingMembersValid = pendingCH == null || newClusterMembers.containsAll(pendingCH.getMembers());
-            if (!currentMembersValid || !pendingMembersValid) {
-               List<Address> newCurrentMembers = new ArrayList<Address>(currentCH.getMembers());
-               newCurrentMembers.retainAll(newClusterMembers);
-               updateCacheMembers(cacheName, cacheStatus, newCurrentMembers);
-            }
-
-            if (!isBalanced(cacheStatus.getCacheTopology().getCurrentCH()) || !cacheStatus.getJoiners().isEmpty()) {
-               // Rebalance after a leave.
-               // Also, in rare cases we get the join request from a new node before JGroups has installed the new view
-               // If that happens, we re-trigger the rebalance after the view containing it has been installed.
-               triggerRebalance(cacheName, cacheStatus);
-            }
-         }
       }
-   }
 
-   @Override
-   public CacheTopology addJoiners(String cacheName, List<Address> joiners) throws Exception {
-      CacheStatus cacheStatus = cacheStatusMap.get(cacheName);
-      if (cacheStatus == null) {
-         log.tracef(""Ignoring members update for cache %s, as we haven't initialized it yet"", cacheName);
-         return null;
-      }
-
-      synchronized (cacheStatus) {
-         addUniqueJoiners(cacheStatus.getJoiners(), joiners);
-
-         ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
-         if (currentCH == null) {
-            installInitialTopology(cacheName, cacheStatus);
-         } else {
-            triggerRebalance(cacheName, cacheStatus);
-         }
-         return cacheStatus.getCacheTopology();
-      }
-   }
-
-   @Override
-   public void removeLeavers(String cacheName, List<Address> leavers) throws Exception {
-      CacheStatus cacheStatus = cacheStatusMap.get(cacheName);
-      if (cacheStatus == null) {
-         log.tracef(""Ignoring members update for cache %s, as we haven't initialized it yet"", cacheName);
+      if (!cacheStatus.hasJoiners() && isBalanced(cacheStatus.getCacheTopology().getCurrentCH())) {
+         log.tracef(""Not triggering rebalance for cache %s, no joiners and the current consistent hash is already balanced"",
+               cacheName);
          return;
       }
 
-      synchronized (cacheStatus) {
-         // The list of ""current"" members will always be included in the set of ""pending"" members,
-         // because leaves are reflected at the same time in both collections
-         List<Address> newMembers = new ArrayList<Address>(clusterMembers);
-         newMembers.removeAll(leavers);
-
-         updateCacheMembers(cacheName, cacheStatus, newMembers);
-      }
-   }
-
-   private void updateCacheMembers(String cacheName, CacheStatus cacheStatus, List<Address> newMembers)
-         throws Exception {
-      CacheJoinInfo joinInfo = cacheStatus.getJoinInfo();
-      int topologyId = cacheStatus.getCacheTopology().getTopologyId();
-      ConsistentHash currentCH = cacheStatus.getCacheTopology().getCurrentCH();
-      ConsistentHash pendingCH = cacheStatus.getCacheTopology().getPendingCH();
-
-      ConsistentHash newPendingCH = null;
-      if (pendingCH != null) {
-         newMembers.retainAll(pendingCH.getMembers());
-         if (!newMembers.isEmpty()) {
-            newPendingCH = joinInfo.getConsistentHashFactory().updateMembers(pendingCH, newMembers);
-         } else {
-            log.tracef(""Zero new members remaining for cache %s"", cacheName);
-         }
-      }
-
-      newMembers.retainAll(currentCH.getMembers());
-      ConsistentHash newCurrentCH;
-      if (!newMembers.isEmpty()) {
-         newCurrentCH = joinInfo.getConsistentHashFactory().updateMembers(currentCH, newMembers);
-      } else {
-         log.tracef(""Zero old members remaining for cache %s"", cacheName);
-         // use the new pending CH, it might be non-null if we have joiners
-         newCurrentCH = newPendingCH;
-      }
-
-      boolean hasMembers = newCurrentCH != null;
-      CacheTopology cacheTopology = new CacheTopology(topologyId, newCurrentCH, newPendingCH);
-
-      // Don't broadcast a cache topology when we don't have any members left
-      updateConsistentHash(cacheName, cacheStatus, cacheTopology, hasMembers);
-
-      // Don't trigger a rebalance without any members either
-      if (hasMembers) {
-         triggerRebalance(cacheName, cacheStatus);
-      }
-   }
-
-   private void installInitialTopology(String cacheName, CacheStatus cacheStatus) throws Exception {
-      CacheJoinInfo joinInfo = cacheStatus.getJoinInfo();
-      int topologyId = cacheStatus.getCacheTopology().getTopologyId();
-      ConsistentHash balancedCH = joinInfo.getConsistentHashFactory().create(joinInfo.getHashFunction(),
-            joinInfo.getNumOwners(), joinInfo.getNumSegments(), cacheStatus.getJoiners());
-      int newTopologyId = topologyId + 1;
-      CacheTopology cacheTopology = new CacheTopology(newTopologyId, balancedCH, null);
-
-      log.tracef(""Installing initial topology for cache %s: %s"", cacheName, cacheTopology);
-      updateConsistentHash(cacheName, cacheStatus, cacheTopology, false);
-   }
-
-   private void addUniqueJoiners(List<Address> members, List<Address> joiners) {
-      for (Address joiner : joiners) {
-         if (!members.contains(joiner)) {
-            members.add(joiner);
-         }
-      }
-   }
-
-   private void triggerRebalance(final String cacheName, final CacheStatus cacheStatus) throws Exception {
-      asyncTransportExecutor.submit(new Callable<Object>() {
-         @Override
-         public Object call() throws Exception {
-            doRebalance(cacheName, cacheStatus);
-            return null;
-         }
-      });
-   }
-
-   private void doRebalance(String cacheName, CacheStatus cacheStatus) throws Exception {
-      CacheTopology cacheTopology = cacheStatus.getCacheTopology();
-      CacheTopology newCacheTopology;
-
-      synchronized (cacheStatus) {
-         boolean isRebalanceInProgress = cacheTopology.getPendingCH() != null;
-         if (isRebalanceInProgress) {
-            log.tracef(""Ignoring request to rebalance cache %s, there's already a rebalance in progress: %s"",
-                  cacheName, cacheTopology);
-            return;
-         }
-
-         List<Address> newMembers = new ArrayList<Address>(cacheTopology.getMembers());
-         if (newMembers.isEmpty()) {
-            log.tracef(""Ignoring request to rebalance cache %s, it doesn't have any member"", cacheName);
-            return;
-         }
-
-         addUniqueJoiners(newMembers, cacheStatus.getJoiners());
-         newMembers.retainAll(clusterMembers);
-
-         log.tracef(""Rebalancing consistent hash for cache %s, members are %s"", cacheName, newMembers);
-         int newTopologyId = cacheTopology.getTopologyId() + 1;
-         ConsistentHash currentCH = cacheTopology.getCurrentCH();
-         if (currentCH == null) {
-            // There was one node in the cache before, and it left after the rebalance was triggered
-            // but before the rebalance actually started.
-            installInitialTopology(cacheName, cacheStatus);
-            return;
-         }
-
-         ConsistentHashFactory chFactory = cacheStatus.getJoinInfo().getConsistentHashFactory();
-         ConsistentHash updatedMembersCH = chFactory.updateMembers(currentCH, newMembers);
-         ConsistentHash balancedCH = chFactory.rebalance(updatedMembersCH);
-         if (balancedCH.equals(currentCH)) {
-            log.tracef(""The balanced CH is the same as the current CH, not rebalancing"");
-            return;
-         }
-         newCacheTopology = new CacheTopology(newTopologyId, currentCH, balancedCH);
-         log.tracef(""Updating cache %s topology for rebalance: %s"", cacheName, newCacheTopology);
-         cacheStatus.setCacheTopology(newCacheTopology);
-      }
-
-      clusterTopologyManager.rebalance(cacheName, newCacheTopology);
-   }
-
-   @Override
-   public void onRebalanceCompleted(String cacheName, int topologyId) throws Exception {
-      log.debugf(""Finished cluster-wide rebalance for cache %s, topology id = %d"",
-            cacheName, topologyId);
-      CacheStatus cacheStatus = cacheStatusMap.get(cacheName);
-      synchronized (cacheStatus) {
-         if (topologyId != cacheStatus.getCacheTopology().getTopologyId()) {
-            throw new IllegalStateException(String.format(""Invalid cluster-wide rebalance confirmation: received topology id %d, expected %d"",
-                  topologyId, cacheStatus.getCacheTopology().getTopologyId()));
-         }
-         int newTopologyId = topologyId + 1;
-         ConsistentHash newCurrentCH = cacheStatus.getCacheTopology().getPendingCH();
-
-         CacheTopology cacheTopology = new CacheTopology(newTopologyId, newCurrentCH, null);
-         updateConsistentHash(cacheName, cacheStatus, cacheTopology, true);
-
-         // Update the list of joiners
-         // TODO Add some cleanup for nodes that left the cluster before getting any state
-         cacheStatus.getJoiners().removeAll(newCurrentCH.getMembers());
-         log.tracef(""After rebalance, joiners without state are %s"", cacheStatus.getJoiners());
-
-         // If we have postponed some joiners, start a new rebalance for them now
-         // If the CH is still not balanced (perhaps because of a leaver), restart the rebalance process
-         if (cacheStatus.getJoiners().isEmpty() && isBalanced(newCurrentCH)) {
-            log.tracef(""Consistent hash is now balanced for cache %s"", cacheName);
-         } else {
-            triggerRebalance(cacheName, cacheStatus);
-         }
+      if (cacheStatus.isRebalanceInProgress()) {
+         log.tracef(""Not triggering rebalance for cache %s, a rebalance is already in progress"");
+         return;
       }
-   }
 
-   @Override
-   public CacheTopology getTopology(String cacheName) {
-      return cacheStatusMap.get(cacheName).cacheTopology;
+      log.tracef(""Triggering rebalance for cache %s"", cacheName);
+      clusterTopologyManager.triggerRebalance(cacheName);
    }
 
-   // TODO Need a proper API for this
    public boolean isBalanced(ConsistentHash ch) {
       int numSegments = ch.getNumSegments();
       for (int i = 0; i < numSegments; i++) {
@@ -367,42 +90,4 @@ public boolean isBalanced(ConsistentHash ch) {
       return true;
    }
 
-   private static class CacheStatus {
-      private final CacheJoinInfo joinInfo;
-      private final List<Address> joiners;
-
-      private CacheTopology cacheTopology;
-
-      public CacheStatus(CacheJoinInfo joinInfo) {
-         this.joinInfo = joinInfo;
-
-         this.cacheTopology = new CacheTopology(-1, null, null);
-         this.joiners = new ArrayList<Address>();
-      }
-
-      public CacheJoinInfo getJoinInfo() {
-         return joinInfo;
-      }
-
-      public List<Address> getJoiners() {
-         return joiners;
-      }
-
-      public CacheTopology getCacheTopology() {
-         return cacheTopology;
-      }
-
-      public void setCacheTopology(CacheTopology cacheTopology) {
-         this.cacheTopology = cacheTopology;
-      }
-
-      @Override
-      public String toString() {
-         return ""CacheStatus{"" +
-               ""joinInfo="" + joinInfo +
-               "", cacheTopology="" + cacheTopology +
-               "", joiners="" + joiners +
-               '}';
-      }
-   }
 }",2012-09-28T14:00:48Z,597
"@@ -0,0 +1,92 @@
+/*
+ * JBoss, Home of Professional Open Source
+ * Copyright 2012 Red Hat Inc. and/or its affiliates and other contributors
+ * as indicated by the @author tags. All rights reserved.
+ * See the copyright.txt in the distribution for a
+ * full listing of individual contributors.
+ *
+ * This copyrighted material is made available to anyone wishing to use,
+ * modify, copy, or redistribute it subject to the terms and conditions
+ * of the GNU Lesser General Public License, v. 2.1.
+ * This program is distributed in the hope that it will be useful, but WITHOUT A
+ * WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
+ * PARTICULAR PURPOSE.  See the GNU Lesser General Public License for more details.
+ * You should have received a copy of the GNU Lesser General Public License,
+ * v.2.1 along with this distribution; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
+ * MA  02110-1301, USA.
+ */
+
+package org.infinispan.topology;
+
+import java.util.Collection;
+import java.util.HashSet;
+import java.util.Set;
+
+import org.infinispan.CacheException;
+import org.infinispan.remoting.transport.Address;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+/**
+* Created with
+*
+* @author Dan Berindei
+* @since 5.2
+*/
+class RebalanceConfirmationCollector {
+   private final static Log log = LogFactory.getLog(RebalanceConfirmationCollector.class);
+   
+   private final String cacheName;
+   private final int topologyId;
+   private final Set<Address> confirmationsNeeded;
+
+   public RebalanceConfirmationCollector(String cacheName, int topologyId, Collection<Address> members) {
+      this.cacheName = cacheName;
+      this.topologyId = topologyId;
+      this.confirmationsNeeded = new HashSet<Address>(members);
+      log.tracef(""Initialized rebalance confirmation collector %d, initial list is %s"", topologyId, confirmationsNeeded);
+   }
+
+   /**
+    * @return {@code true} if everyone has confirmed
+    */
+   public boolean confirmRebalance(Address node, int receivedTopologyId) {
+      synchronized (this) {
+         if (topologyId != receivedTopologyId) {
+            throw new CacheException(String.format(""Received invalid rebalance confirmation from %s "" +
+                  ""for cache %s, expecting topology id %d but got %d"", node, cacheName, topologyId, receivedTopologyId));
+         }
+
+         boolean removed = confirmationsNeeded.remove(node);
+         if (!removed) {
+            log.tracef(""Rebalance confirmation collector %d ignored confirmation for %s, which is not a member"",
+                  topologyId, node);
+            return false;
+         }
+
+         log.tracef(""Rebalance confirmation collector %d received confirmation for %s, remaining list is %s"",
+               topologyId, node, confirmationsNeeded);
+         return confirmationsNeeded.isEmpty();
+      }
+   }
+
+   /**
+    * @return {@code true} if everyone has confirmed
+    */
+   public boolean updateMembers(Collection<Address> newMembers) {
+      synchronized (this) {
+         // only return true the first time
+         boolean modified = confirmationsNeeded.retainAll(newMembers);
+         return modified && confirmationsNeeded.isEmpty();
+      }
+   }
+
+   @Override
+   public String toString() {
+      return ""RebalanceInfo{"" +
+            ""topologyId="" + topologyId +
+            "", confirmationsNeeded="" + confirmationsNeeded +
+            '}';
+   }
+}",2012-09-28T14:00:48Z,652
"@@ -31,6 +31,11 @@
  *
  * It is used both in distributed and replicated mode.
  *
+ * Implementations can trigger a rebalance using {@link ClusterTopologyManager#triggerRebalance(String)}.
+ * They don't control the resulting consistent hash directly, but they can use the {@link ClusterCacheStatus}
+ * to access the cache's custom {@link org.infinispan.distribution.ch.ConsistentHashFactory} implementation
+ * and influence the generated consistent hash indirectly.
+ *
  * @author Dan Berindei
  * @since 5.2
  */
@@ -40,38 +45,10 @@ public interface RebalancePolicy {
     * Initialize the policy for a cache, without a list of members.
     * It won't have any effect if the cache is already initialized.
     */
-   void initCache(String cacheName, CacheJoinInfo joinInfo) throws Exception;
-
-   /**
-    * Initialize the policy for an existing cache, after this node became the coordinator.
-    * It will overwrite the current status of the cache, but it will not reset any pending join or leave
-    * operations.
-    */
-   void initCache(String cacheName, List<CacheTopology> partitionTopologies) throws Exception;
-
-   /**
-    * Called when the membership of the cluster changes. It updates the members list of each cache atomically.
-    */
-   void updateMembersList(List<Address> membersList) throws Exception;
-
-   /**
-    * Called when one or more members join a cache.
-    * @return The previous cache topology.
-    */
-   CacheTopology addJoiners(String cacheName, List<Address> joiners) throws Exception;
-
-   /**
-    * Called when one or more members leave an individual cache (as opposed to leaving the cluster).
-    */
-   void removeLeavers(String cacheName, List<Address> leavers) throws Exception;
-
-   /**
-    * Called when every member has completed receiving data.
-    */
-   void onRebalanceCompleted(String cacheName, int topologyId) throws Exception;
+   void initCache(String cacheName, ClusterCacheStatus cacheStatus) throws Exception;
 
    /**
-    * @return The current topology (current CH + pending CH) of a cache.
+    * Called when the status of a cache changes. It could be a node joining or leaving, or a merge, or a
     */
-   CacheTopology getTopology(String cacheName);
+   void updateCacheStatus(String cacheName, ClusterCacheStatus cacheStatus) throws Exception;
 }",2012-09-28T14:00:48Z,598
"@@ -122,10 +122,15 @@ public S purgeSynchronously(boolean b) {
    public void validate() {
       async.validate();
       singletonStore.validate();
+      ConfigurationBuilder builder = getBuilder();
       if (!loaders().shared() && !fetchPersistentState && !purgeOnStartup
-            && getBuilder().clustering().cacheMode().isClustered())
+            && builder.clustering().cacheMode().isClustered())
          log.staleEntriesWithoutFetchPersistentStateOrPurgeOnStartup();
-   }
 
+      if (loaders().shared() && !loaders().preload()
+            && builder.indexing().enabled()
+            && builder.indexing().indexLocalOnly())
+         log.localIndexingWithSharedCacheLoaderRequiresPreload();
+   }
 
 }",2012-08-30T15:45:20Z,41
"@@ -62,6 +62,10 @@ public IndexingConfigurationBuilder enabled(boolean enabled) {
       return this;
    }
 
+   boolean enabled() {
+      return enabled;
+   }
+
    /**
     * If true, only index changes made locally, ignoring remote changes. This is useful if indexes
     * are shared across a cluster to prevent redundant indexing of updates.
@@ -71,6 +75,10 @@ public IndexingConfigurationBuilder indexLocalOnly(boolean b) {
       return this;
    }
 
+   boolean indexLocalOnly() {
+      return indexLocalOnly;
+   }
+
    /**
     * <p>
     * Defines a single property. Can be used multiple times to define all needed properties, but the",2012-08-30T15:45:20Z,42
"@@ -49,4 +49,4 @@ public interface LoaderConfigurationBuilder<T extends LoaderConfiguration, S ext
     */
    S withProperties(Properties p);
 
-}
\ No newline at end of file
+}",2012-08-30T15:45:20Z,43
"@@ -72,6 +72,10 @@ public LoadersConfigurationBuilder preload(boolean b) {
       return this;
    }
 
+   boolean preload() {
+      return preload;
+   }
+
    /**
     * This setting should be set to true when multiple cache instances share the same cache store
     * (e.g., multiple nodes in a cluster using a JDBC-based CacheStore pointing to the same, shared
@@ -173,7 +177,7 @@ public LegacyStoreConfigurationBuilder addStore() {
    /**
     * Adds a cache store which uses the specified builder instance to build its configuration
     *
-    * @param klass an instance of {@link StoreConfigurationBuilder}
+    * @param builder an instance of {@link StoreConfigurationBuilder}
     */
    public LoaderConfigurationBuilder<?, ?> addStore(StoreConfigurationBuilder<?, ?> builder) {
       this.cacheLoaders.add(builder);",2012-08-30T15:45:20Z,44
"@@ -31,7 +31,10 @@
 import static org.infinispan.context.Flag.IGNORE_RETURN_VALUES;
 import static org.infinispan.factories.KnownComponentNames.CACHE_MARSHALLER;
 
+import java.util.ArrayList;
+import java.util.Arrays;
 import java.util.Collections;
+import java.util.List;
 import java.util.Set;
 import java.util.concurrent.TimeUnit;
 
@@ -47,6 +50,7 @@
 import org.infinispan.configuration.cache.LoadersConfiguration;
 import org.infinispan.configuration.cache.StoreConfiguration;
 import org.infinispan.container.entries.InternalCacheEntry;
+import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.context.InvocationContextContainer;
 import org.infinispan.factories.annotations.ComponentName;
@@ -189,18 +193,24 @@ public void preload() {
                throw new CacheException(""Unable to preload!"", e);
             }
 
-            for (InternalCacheEntry e : state) {
-               if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
-                  cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, SKIP_CACHE_STORE, IGNORE_RETURN_VALUES, SKIP_INDEXING)
-                       .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
-               } else {
-                  cache.getAdvancedCache()
-                       .withFlags(CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES, SKIP_INDEXING)
-                       .put(e.getKey(), e.getValue(), e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
-               }
+            List<Flag> flags = new ArrayList(Arrays.asList(
+                  CACHE_MODE_LOCAL, SKIP_OWNERSHIP_CHECK, IGNORE_RETURN_VALUES));
+
+            if (clmConfig.shared() || !(loader instanceof ChainingCacheStore)) {
+               flags.add(SKIP_CACHE_STORE);
+               if (!localIndexingEnabled())
+                  flags.add(SKIP_INDEXING);
+            } else {
+               flags.add(SKIP_INDEXING);
             }
 
+            AdvancedCache<Object, Object> flaggedCache = cache.getAdvancedCache()
+                  .withFlags(flags.toArray(new Flag[]{}));
+
+            for (InternalCacheEntry e : state)
+               flaggedCache.put(e.getKey(), e.getValue(),
+                     e.getLifespan(), MILLISECONDS, e.getMaxIdle(), MILLISECONDS);
+
             if (debugTiming) {
                final long stop = System.nanoTime();
                log.debugf(""Preloaded %s keys in %s"", state.size(), Util.prettyPrintTime(stop - start, TimeUnit.NANOSECONDS));
@@ -209,6 +219,10 @@ public void preload() {
       }
    }
 
+   private boolean localIndexingEnabled() {
+      return configuration.indexing().enabled() && configuration.indexing().indexLocalOnly();
+   }
+
    private Set<InternalCacheEntry> loadState() throws CacheLoaderException {
       int ne = -1;
       if (configuration.eviction().strategy().isEnabled()) ne = configuration.eviction().maxEntries();",2012-08-30T15:45:20Z,29
"@@ -863,6 +863,11 @@ void asyncStoreShutdownTimeoutTooHigh(long configuredAsyncStopTimeout,
    void componentFailedToStop(@Cause Throwable e);
 
    @LogMessage(level = WARN)
-   @Message(value = ""Use of the 'loader' element to configure a store is deprecated, please use the 'store' element instead"")
+   @Message(value = ""Use of the 'loader' element to configure a store is deprecated, please use the 'store' element instead"", id = 190)
    void deprecatedLoaderAsStoreConfiguration();
+
+   @LogMessage(level = DEBUG)
+   @Message(value = ""When indexing locally a cache with shared cache loader, preload must be enabled"", id = 191)
+   void localIndexingWithSharedCacheLoaderRequiresPreload();
+
 }",2012-08-30T15:45:20Z,45
"@@ -29,7 +29,6 @@
 import org.infinispan.test.TestingUtil;
 import org.testng.annotations.Test;
 
-import java.util.LinkedList;
 import java.util.List;
 
 @Test (testName = ""loaders.SharedCacheStoreTest"", groups = ""functional"")
@@ -50,13 +49,6 @@ protected void createCacheManagers() throws Throwable {
       // don't create the caches here, we want them to join the cluster one by one
    }
 
-   private List<CacheStore> cachestores() {
-      List<CacheStore> l = new LinkedList<CacheStore>();
-      for (Cache<?, ?> c: caches())
-         l.add(TestingUtil.extractComponent(c, CacheLoaderManager.class).getCacheStore());
-      return l;
-   }
-
    public void testUnnecessaryWrites() throws CacheLoaderException {
       cache(0).put(""key"", ""value"");
 
@@ -66,7 +58,8 @@ public void testUnnecessaryWrites() throws CacheLoaderException {
       for (Cache<Object, Object> c: caches())
          assert ""value"".equals(c.get(""key""));
 
-      for (CacheStore cs: cachestores()) {
+      List<CacheStore> cachestores = TestingUtil.cachestores(caches());
+      for (CacheStore cs: cachestores) {
          assert cs.containsKey(""key"");
          DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
          assert dimcs.stats().get(""clear"") == 0: ""Cache store should not be cleared, purgeOnStartup is false"";
@@ -78,7 +71,7 @@ public void testUnnecessaryWrites() throws CacheLoaderException {
       for (Cache<Object, Object> c: caches())
          assert c.get(""key"") == null;
 
-      for (CacheStore cs: cachestores()) {
+      for (CacheStore cs: cachestores) {
          assert !cs.containsKey(""key"");
          DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
          assert dimcs.stats().get(""remove"") == 1: ""Entry should have been removed from the cache store just once, but was removed "" + dimcs.stats().get(""store"") + "" times"";",2012-08-30T15:45:20Z,46
"@@ -0,0 +1,73 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.test.TestingUtil;
+
+import java.util.concurrent.Callable;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+
+/**
+ * Represents a joining node, designed for state transfer related tests.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public class JoiningNode {
+
+   private final EmbeddedCacheManager cm;
+   private final CountDownLatch latch;
+   private final MergeOrViewChangeListener listener;
+
+   public JoiningNode(EmbeddedCacheManager cm) {
+      this.cm = cm;
+      latch = new CountDownLatch(1);
+      listener = new MergeOrViewChangeListener(latch);
+      cm.addListener(listener);
+   }
+
+   public Cache getCache() {
+      return cm.getCache();
+   }
+
+   public Cache getCache(String cacheName) {
+      return cm.getCache(cacheName);
+   }
+
+   public void waitForJoin(long timeout, Cache... caches) throws InterruptedException {
+      // Wait for either a merge or view change to happen
+      latch.await(timeout, TimeUnit.MILLISECONDS);
+      // Wait for the state transfer to end
+      TestingUtil.waitForRehashToComplete(caches);
+   }
+
+   private boolean isStateTransferred() {
+      return !listener.merged;
+   }
+
+   void verifyStateTransfer(Callable<Void> verify) throws Exception {
+      if (isStateTransferred())
+         verify.call();
+   }
+
+}",2012-08-30T15:45:20Z,47
"@@ -0,0 +1,72 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.statetransfer;
+
+import org.infinispan.notifications.Listener;
+import org.infinispan.notifications.cachemanagerlistener.annotation.Merged;
+import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
+import org.infinispan.notifications.cachemanagerlistener.event.MergeEvent;
+import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
+import org.infinispan.util.logging.Log;
+import org.infinispan.util.logging.LogFactory;
+
+import java.util.concurrent.CountDownLatch;
+
+/**
+ * Listener implementation that detects whether a merge or
+ * a view change occurred.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Listener
+public class MergeOrViewChangeListener {
+
+   private static final Log log = LogFactory.getLog(MergeOrViewChangeListener.class);
+
+   // The latch provides the visibility guarantees
+   public boolean merged;
+
+   // The latch provides the visibility guarantees
+   public boolean viewChanged;
+
+   private final CountDownLatch latch;
+
+   public MergeOrViewChangeListener(CountDownLatch latch) {
+      this.latch = latch;
+   }
+
+   @Merged
+   @SuppressWarnings(""unused"")
+   public void mergedView(MergeEvent me) {
+      log.infof(""View merged received %s"", me);
+      merged = true;
+      latch.countDown();
+   }
+
+   @ViewChanged
+   @SuppressWarnings(""unused"")
+   public void viewChanged(ViewChangedEvent e) {
+      log.infof(""View change received %s"", e);
+      viewChanged = true;
+      latch.countDown();
+   }
+
+}",2012-08-30T15:45:20Z,48
"@@ -25,11 +25,6 @@
 import org.infinispan.Cache;
 import org.infinispan.config.Configuration;
 import org.infinispan.manager.EmbeddedCacheManager;
-import org.infinispan.notifications.Listener;
-import org.infinispan.notifications.cachemanagerlistener.annotation.Merged;
-import org.infinispan.notifications.cachemanagerlistener.annotation.ViewChanged;
-import org.infinispan.notifications.cachemanagerlistener.event.MergeEvent;
-import org.infinispan.notifications.cachemanagerlistener.event.ViewChangedEvent;
 import org.infinispan.remoting.transport.Address;
 import org.infinispan.test.MultipleCacheManagersTest;
 import org.infinispan.test.TestingUtil;
@@ -46,8 +41,7 @@
 import java.io.ObjectOutputStream;
 import java.io.Serializable;
 import java.lang.reflect.Method;
-import java.util.concurrent.CountDownLatch;
-import java.util.concurrent.TimeUnit;
+import java.util.concurrent.Callable;
 
 @Test(groups = ""functional"", testName = ""statetransfer.StateTransferFunctionalTest"", enabled = true)
 public class StateTransferFunctionalTest extends MultipleCacheManagersTest {
@@ -183,10 +177,10 @@ public void testInitialStateTransfer(Method m) throws Exception {
       cache1 = cm1.getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node = new JoiningNode();
+      JoiningNode node = new JoiningNode(createCacheManager());
       cache2 = node.getCache(cacheName);
       node.waitForJoin(60000, cache1, cache2);
-      node.verifyStateTransfer(cache2);
+      node.verifyStateTransfer(new CacheVerifier(cache2));
 
       logTestEnd(m);
    }
@@ -199,10 +193,10 @@ public void testInitialStateTransferCacheNotPresent(Method m) throws Exception {
       cache1 = cacheManager1.getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node = new JoiningNode();
+      JoiningNode node = new JoiningNode(createCacheManager());
       cache2 = node.getCache(cacheName);
       node.waitForJoin(60000, cache1, cache2);
-      node.verifyStateTransfer(cache2);
+      node.verifyStateTransfer(new CacheVerifier(cache2));
 
       cacheManager1.defineConfiguration(""otherCache"", config.clone());
       cacheManager1.getCache(""otherCache"");
@@ -216,16 +210,16 @@ public void testConcurrentStateTransfer(Method m) throws Exception {
       cache1 = createCacheManager().getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
 
       cache1.put(""delay"", new StateTransferFunctionalTest.DelayTransfer());
 
       node2.waitForJoin(60000, cache1, cache2);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
-      final JoiningNode node3 = new JoiningNode();
-      final JoiningNode node4 = new JoiningNode();
+      final JoiningNode node3 = new JoiningNode(createCacheManager());
+      final JoiningNode node4 = new JoiningNode(createCacheManager());
 
       Thread t1 = new Thread(new Runnable() {
          public void run() {
@@ -252,8 +246,8 @@ public void run() {
       node3.waitForJoin(120000, cache1, cache2, cache3, cache4);
       node4.waitForJoin(120000, cache1, cache2, cache3, cache4);
 
-      node3.verifyStateTransfer(cache3);
-      node4.verifyStateTransfer(cache4);
+      node3.verifyStateTransfer(new CacheVerifier(cache3));
+      node4.verifyStateTransfer(new CacheVerifier(cache4));
 
       logTestEnd(m);
    }
@@ -300,10 +294,10 @@ public void testInitialStateTransferAfterRestart(Method m) throws Exception {
       cache1 = createCacheManager().getCache(cacheName);
       writeInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
       node2.waitForJoin(60000, cache1, cache2);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       cache2.stop();
       cache2.start();
@@ -324,7 +318,7 @@ private void logTestLifecycle(Method m, String lifecycle) {
       log.infof(""%s %s - %s"", m.getName(), lifecycle, testCount);
    }
 
-   private void thirdWritingCacheTest(boolean tx) throws InterruptedException {
+   private void thirdWritingCacheTest(boolean tx) throws Exception {
       Cache<Object, Object> cache1, cache2, cache3;
       cache1 = createCacheManager().getCache(cacheName);
       cache3 = createCacheManager().getCache(cacheName);
@@ -340,15 +334,15 @@ private void thirdWritingCacheTest(boolean tx) throws InterruptedException {
       WritingThread writerThread = new WritingThread(cache3, tx);
       writerThread.start();
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
 
       node2.waitForJoin(60000, cache1, cache2, cache3);
 
       writerThread.stopThread();
       writerThread.join();
 
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       int count = writerThread.result();
 
@@ -374,7 +368,7 @@ protected void writeInitialData(final Cache<Object, Object> c) {
       c.put(A_C_AGE, FORTY);
    }
 
-   private void writingThreadTest(boolean tx) throws InterruptedException {
+   private void writingThreadTest(boolean tx) throws Exception {
       Cache<Object, Object> cache1, cache2;
       cache1 = createCacheManager().getCache(cacheName);
 
@@ -388,81 +382,34 @@ private void writingThreadTest(boolean tx) throws InterruptedException {
       writerThread.start();
       verifyInitialData(cache1);
 
-      JoiningNode node2 = new JoiningNode();
+      JoiningNode node2 = new JoiningNode(createCacheManager());
       cache2 = node2.getCache(cacheName);
       node2.waitForJoin(60000, cache1, cache2);
 
       writerThread.stopThread();
       writerThread.join();
 
       verifyInitialData(cache1);
-      node2.verifyStateTransfer(cache2);
+      node2.verifyStateTransfer(new CacheVerifier(cache2));
 
       int count = writerThread.result();
 
       for (int c = 0; c < count; c++)
          assert new Integer(c).equals(cache2.get(""test"" + c)) : ""Entry under key [test"" + c + ""] was ["" + cache2.get(""test"" + c) + ""] but expected ["" + c + ""]"";
    }
 
-   @Listener
-   public static class MergeOrViewChangeListener {
-      // The latch provides the visibility guarantees
-      public boolean merged;
-      // The latch provides the visibility guarantees
-      public boolean viewChanged;
-      private final CountDownLatch latch;
+   public class CacheVerifier implements Callable<Void> {
 
-      public MergeOrViewChangeListener(CountDownLatch latch) {
-         this.latch = latch;
-      }
-
-      @Merged
-      public void mergedView(MergeEvent me) {
-         log.infof(""View merged received %s"", me);
-         merged = true;
-         latch.countDown();
-      }
-
-      @ViewChanged
-      public void viewChanged(ViewChangedEvent e) {
-         log.infof(""View change received %s"", e);
-         viewChanged = true;
-         latch.countDown();
-      }
-
-   }
-
-   private class JoiningNode {
-
-      private final EmbeddedCacheManager cm;
-      private final CountDownLatch latch;
-      private final MergeOrViewChangeListener listener;
-
-      private JoiningNode() {
-         cm = createCacheManager();
-         latch = new CountDownLatch(1);
-         listener = new MergeOrViewChangeListener(latch);
-         cm.addListener(listener);
-      }
-
-      Cache getCache(String cacheName) {
-         return cm.getCache(cacheName);
-      }
-
-      void waitForJoin(long timeout, Cache... caches) throws InterruptedException {
-         // Wait for either a merge or view change to happen
-         latch.await(timeout, TimeUnit.MILLISECONDS);
-         // Wait for the state transfer to end
-         TestingUtil.waitForRehashToComplete(caches);
-      }
+      private final Cache<Object, Object> cache;
 
-      private boolean isStateTransferred() {
-         return !listener.merged;
+      public CacheVerifier(Cache<Object, Object> cache) {
+         this.cache = cache;
       }
 
-      void verifyStateTransfer(Cache cache) {
-         if (isStateTransferred())
-            StateTransferFunctionalTest.this.verifyInitialData(cache);
+      @Override
+      public Void call() throws Exception {
+         verifyInitialData(cache);
+         return null;
       }
 
    }",2012-08-30T15:45:20Z,49
"@@ -33,6 +33,7 @@
 import java.util.Collection;
 import java.util.HashSet;
 import java.util.Iterator;
+import java.util.LinkedList;
 import java.util.List;
 import java.util.Random;
 import java.util.Set;
@@ -62,6 +63,7 @@
 import org.infinispan.lifecycle.ComponentStatus;
 import org.infinispan.loaders.CacheLoader;
 import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.loaders.CacheStore;
 import org.infinispan.manager.CacheContainer;
 import org.infinispan.manager.EmbeddedCacheManager;
 import org.infinispan.marshall.AbstractDelegatingMarshaller;
@@ -754,6 +756,13 @@ public static void clearCacheLoader(Cache cache) {
       }
    }
 
+   public static <K, V> List<CacheStore> cachestores(List<Cache<K, V>> caches) {
+      List<CacheStore> l = new LinkedList<CacheStore>();
+      for (Cache<?, ?> c: caches)
+         l.add(TestingUtil.extractComponent(c, CacheLoaderManager.class).getCacheStore());
+      return l;
+   }
+
    private static void removeInMemoryData(Cache cache) {
       EmbeddedCacheManager mgr = cache.getCacheManager();
       Address a = mgr.getAddress();",2012-08-30T15:45:20Z,50
"@@ -0,0 +1,69 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.cacheloaders;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.query.statetransfer.BaseReIndexingTest;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.Test;
+
+/**
+ * Tests behaviour of indexing and querying when a cache is clustered and
+ * and it's configured with a shared cache store. If preload is enabled,
+ * it should be possible to index the preloaded contents.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.cacheloaders.SharedCacheLoaderQueryIndexTest"")
+public class SharedCacheLoaderQueryIndexTest extends BaseReIndexingTest {
+
+   protected void configureCache(ConfigurationBuilder builder) {
+      // To force a shared cache store, make sure storeName property
+      // for dummy store is the same for all nodes
+      builder.clustering().stateTransfer().fetchInMemoryState(false)
+         .loaders().shared(true).preload(true).addStore()
+            .cacheStore(new DummyInMemoryCacheStore()).addProperty(""storeName"",
+            SharedCacheLoaderQueryIndexTest.class.getName());
+   }
+
+   public void testPreloadIndexingAfterAddingNewNode() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      for (CacheStore cs: TestingUtil.cachestores(this.<String, Person>caches())) {
+         assert cs.containsKey(persons[0].getName()) :
+               ""Cache misconfigured, maybe cache store not pointing to same place, maybe passivation on...etc"";
+         DummyInMemoryCacheStore dimcs = (DummyInMemoryCacheStore) cs;
+         assert dimcs.stats().get(""clear"") == 0:
+               ""Cache store should not be cleared, purgeOnStartup is false"";
+         assert dimcs.stats().get(""store"") == 4:
+               ""Cache store should have been written to just once, but was written to "" + dimcs.stats().get(""store"") + "" times"";
+      }
+
+      // Before adding a node, verify that the query resolves properly
+      executeSimpleQuery(this.<String, Person>caches().get(0));
+
+      addNodeCheckingContentsAndQuery();
+   }
+
+}",2012-08-30T15:45:20Z,7
"@@ -0,0 +1,138 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.apache.lucene.queryParser.ParseException;
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.CacheMode;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.manager.EmbeddedCacheManager;
+import org.infinispan.query.CacheQuery;
+import org.infinispan.query.test.Person;
+import org.infinispan.statetransfer.JoiningNode;
+import org.infinispan.test.CacheManagerCallable;
+import org.infinispan.test.MultipleCacheManagersTest;
+import org.infinispan.test.fwk.TransportFlags;
+
+import java.util.List;
+
+import static org.infinispan.query.helper.TestQueryHelperFactory.createCacheQuery;
+import static org.infinispan.test.TestingUtil.withCacheManager;
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Base class for state transfer and query related tests
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+public abstract class BaseReIndexingTest extends MultipleCacheManagersTest {
+
+   protected Person[] persons;
+   protected ConfigurationBuilder builder;
+
+   abstract protected void configureCache(ConfigurationBuilder builder);
+
+   @Override
+   protected void createCacheManagers() throws Throwable {
+      builder = getDefaultClusteredCacheConfig(CacheMode.REPL_SYNC, false);
+
+      // Explicitly disable fetching in-memory state in order
+      // to fetch it from the persistence layer
+      builder.indexing().enable().indexLocalOnly(true)
+            .addProperty(""hibernate.search.default.directory_provider"", ""ram"")
+            .addProperty(""hibernate.search.lucene_version"", ""LUCENE_CURRENT"");
+
+      configureCache(builder);
+
+      createClusteredCaches(2, builder);
+   }
+
+   private EmbeddedCacheManager createCacheManager() {
+      return addClusterEnabledCacheManager(
+            builder, new TransportFlags().withMerge(true));
+   }
+
+   protected void executeSimpleQuery(Cache<String, Person> cache) throws ParseException {
+      CacheQuery cacheQuery = createCacheQuery(cache, ""blurb"", ""playing"");
+      List<Object> found = cacheQuery.list();
+      int elems = found.size();
+      assertEquals(1, elems);
+      Object val = found.get(0);
+      Person expectedPerson = persons[0];
+      assertEquals(expectedPerson, val);
+   }
+
+   protected void loadCacheEntries(Cache<String, Person> cache) {
+      Person person1 = new Person();
+      person1.setName(""NavinSurtani"");
+      person1.setBlurb(""Likes playing WoW"");
+      person1.setAge(45);
+
+      Person person2 = new Person();
+      person2.setName(""BigGoat"");
+      person2.setBlurb(""Eats grass"");
+      person2.setAge(30);
+
+      Person person3 = new Person();
+      person3.setName(""MiniGoat"");
+      person3.setBlurb(""Eats cheese"");
+      person3.setAge(35);
+
+      Person person4 = new Person();
+      person4.setName(""MightyGoat"");
+      person4.setBlurb(""Also eats grass"");
+      person4.setAge(66);
+
+      persons = new Person[]{person1, person2, person3, person4};
+
+      // Put the 3 created objects in the cache
+      cache.put(person1.getName(), person1);
+      cache.put(person2.getName(), person2);
+      cache.put(person3.getName(), person3);
+      cache.put(person4.getName(), person4);
+   }
+
+   protected void addNodeCheckingContentsAndQuery() {
+      withCacheManager(new CacheManagerCallable(createCacheManager()) {
+         @Override
+         public void call() {
+            try {
+               // New node joining
+               JoiningNode newNode = new JoiningNode(cm);
+               Cache<String, Person> newCache = newNode.getCache();
+               newNode.waitForJoin(120000, caches().get(0), caches().get(1), newCache);
+
+               // Verify state transfer
+               int size = newCache.size();
+               assertEquals(4, size);
+               for (int i = 0; i < size; i++)
+                  assertEquals(persons[i], newCache.get(persons[i].getName()));
+
+               // Repeat query on new node
+               executeSimpleQuery(newCache);
+            } catch (Exception e) {
+               throw new RuntimeException(e);
+            }
+         }
+      });
+   }
+
+}",2012-08-30T15:45:20Z,51
"@@ -0,0 +1,94 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.Cache;
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.loaders.CacheLoaderException;
+import org.infinispan.loaders.CacheLoaderManager;
+import org.infinispan.loaders.CacheStore;
+import org.infinispan.loaders.dummy.DummyInMemoryCacheStore;
+import org.infinispan.query.test.Person;
+import org.infinispan.test.TestingUtil;
+import org.testng.annotations.Test;
+
+import static org.testng.AssertJUnit.assertEquals;
+
+/**
+ * Test that verifies that querying works even after multiple nodes have
+ * started with unshared, passivated, cache stores, and a new node comes in
+ * to fetch the persistent state from the other nodes.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.PersistentStateTransferQueryIndexTest"")
+public class PersistentStateTransferQueryIndexTest extends BaseReIndexingTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      builder.clustering().stateTransfer().fetchInMemoryState(false)
+            .loaders().passivation(true).shared(false).addStore()
+            .cacheStore(new DummyInMemoryCacheStore())
+                  .fetchPersistentState(true);
+   }
+
+   public void testFetchingPersistentStateUpdatesIndex() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      // Before adding a node, verify that the query resolves properly
+      Cache<String, Person> cache1 = this.<String, Person>caches().get(0);
+      executeSimpleQuery(cache1);
+
+      // Since passivation is enabled, cache stores should still be empty
+      checkCacheStoresEmpty();
+
+      // Evict manually entries from both nodes
+      for (Cache<Object, Object> cache : caches()) {
+         for (Person p2 : persons) {
+            cache.evict(p2.getName());
+         }
+      }
+
+      // After eviction, cache stores should be loaded with instances
+      checkCacheStoresContainPersons();
+
+      // Finally add a node and verify that state transfer happens and query works
+      addNodeCheckingContentsAndQuery();
+   }
+
+   private void checkCacheStoresContainPersons() throws CacheLoaderException {
+      for (Cache<Object, Object> cache : caches()) {
+         CacheStore store = TestingUtil.extractComponent(cache, CacheLoaderManager.class).getCacheStore();
+         for (int i = 0; i < persons.length; i++)
+            assertEquals(persons[i], store.load(persons[i].getName()).getValue());
+      }
+   }
+
+   private void checkCacheStoresEmpty() throws CacheLoaderException {
+      for (Cache<Object, Object> cache : caches()) {
+         CacheStore store = TestingUtil.extractComponent(cache, CacheLoaderManager.class).getCacheStore();
+         for (Person person : persons) {
+            assert !store.containsKey(person.getName());
+         }
+      }
+   }
+
+}",2012-08-30T15:45:20Z,52
"@@ -0,0 +1,50 @@
+/*
+ * Copyright 2012 Red Hat, Inc. and/or its affiliates.
+ *
+ * This is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU Lesser General Public License as
+ * published by the Free Software Foundation; either version 2.1 of
+ * the License, or (at your option) any later version.
+ *
+ * This software is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
+ * 02110-1301 USA
+ */
+
+package org.infinispan.query.statetransfer;
+
+import org.infinispan.configuration.cache.ConfigurationBuilder;
+import org.infinispan.query.test.Person;
+import org.testng.annotations.Test;
+
+/**
+ * Test that verifies that querying works even after a new node is added and
+ * state transfer has provided it with the data belonging to that node.
+ *
+ * @author Galder Zamarreño
+ * @since 5.2
+ */
+@Test(groups = ""functional"", testName = ""query.statetransfer.StateTransferQueryIndexTest"")
+public class StateTransferQueryIndexTest extends BaseReIndexingTest {
+
+   @Override
+   protected void configureCache(ConfigurationBuilder builder) {
+      builder.clustering().stateTransfer().fetchInMemoryState(true);
+   }
+
+   public void testQueryAfterAddingNewNode() throws Exception {
+      loadCacheEntries(this.<String, Person>caches().get(0));
+
+      // Before adding a node, verify that the query resolves properly
+      executeSimpleQuery(this.<String, Person>caches().get(0));
+
+      addNodeCheckingContentsAndQuery();
+   }
+
+}",2012-08-30T15:45:20Z,53
"@@ -23,7 +23,11 @@
 
 package org.infinispan.statetransfer;
 
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
+
 import org.infinispan.Cache;
+import org.infinispan.CacheException;
 import org.infinispan.configuration.cache.CacheMode;
 import org.infinispan.configuration.cache.Configuration;
 import org.infinispan.configuration.global.GlobalConfiguration;
@@ -61,6 +65,8 @@ public class StateTransferManagerImpl implements StateTransferManager {
    private GroupManager groupManager;   // optional
    private LocalTopologyManager localTopologyManager;
 
+   private CountDownLatch initialStateTransferComplete = new CountDownLatch(1);
+
    public StateTransferManagerImpl() {
    }
 
@@ -170,12 +176,27 @@ private void doTopologyUpdate(CacheTopology newCacheTopology, boolean isRebalanc
       ConsistentHash oldCH = oldCacheTopology != null ? oldCacheTopology.getWriteConsistentHash() : null;
       ConsistentHash newCH = newCacheTopology.getWriteConsistentHash();
 
+      // TODO Improve notification to contain both CHs
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, true);
 
       stateConsumer.onTopologyUpdate(newCacheTopology, isRebalance);
       stateProvider.onTopologyUpdate(newCacheTopology, isRebalance);
 
       cacheNotifier.notifyTopologyChanged(oldCH, newCH, false);
+
+      if (newCacheTopology.getCurrentCH().getMembers().contains(rpcManager.getAddress())) {
+         initialStateTransferComplete.countDown();
+      }
+   }
+
+   @Start(priority = 1000)
+   public void waitForInitialStateTransferToComplete() throws InterruptedException {
+      if (trace) log.tracef(""Waiting for initial state transfer to finish"");
+      boolean success = initialStateTransferComplete.await(configuration.clustering().stateTransfer().timeout(), TimeUnit.MILLISECONDS);
+      if (!success) {
+         throw new CacheException(String.format(""Initial state transfer timed out for cache %s on %s"",
+               cacheName, rpcManager.getAddress()));
+      }
    }
 
    @Stop(priority = 20)",2012-08-31T21:05:45Z,117
"@@ -20,7 +20,7 @@
 
 import junit.framework.AssertionFailedError;
 
-import org.infinispan.commands.VisitableCommand;
+import org.infinispan.commands.AbstractFlagAffectedCommand;
 import org.infinispan.commands.write.ApplyDeltaCommand;
 import org.infinispan.commands.write.ClearCommand;
 import org.infinispan.commands.write.PutKeyValueCommand;
@@ -71,8 +71,8 @@ public Object visitApplyDeltaCommand(InvocationContext ctx, ApplyDeltaCommand co
       return handleDefaultCheckingAssertion(ctx, command);
    }
 
-   protected Object handleDefaultCheckingAssertion(InvocationContext ctx, VisitableCommand command) throws Throwable {
-      if (! ctx.hasFlag(Flag.SKIP_INDEXING)) {
+   protected Object handleDefaultCheckingAssertion(InvocationContext ctx, AbstractFlagAffectedCommand command) throws Throwable {
+      if (! command.hasFlag(Flag.SKIP_INDEXING)) {
          throw new AssertionFailedError(""A write operation was detected which is not using SKIP_INDEXING flag"");
       }
       return super.invokeNextInterceptor(ctx, command);",2012-09-18T12:40:22Z,600
"@@ -23,6 +23,7 @@
 package org.infinispan.query.backend;
 
 import org.hibernate.search.spi.SearchFactoryIntegrator;
+import org.infinispan.commands.AbstractFlagAffectedCommand;
 import org.infinispan.context.Flag;
 import org.infinispan.context.InvocationContext;
 import org.infinispan.factories.KnownComponentNames;
@@ -72,7 +73,7 @@ public void injectDependencies(TransactionManager transactionManager,
    }
 
    @Override
-   protected boolean shouldModifyIndexes(InvocationContext ctx) {
-      return ctx.isOriginLocal() && ! ctx.hasFlag(Flag.SKIP_INDEXING);
+   protected boolean shouldModifyIndexes(AbstractFlagAffectedCommand command, InvocationContext ctx) {
+      return ctx.isOriginLocal() && ! command.hasFlag(Flag.SKIP_INDEXING);
    }
 }",2012-09-18T12:40:22Z,566
"@@ -27,6 +27,7 @@
 import org.hibernate.search.backend.spi.WorkType;
 import org.hibernate.search.engine.spi.EntityIndexBinder;
 import org.hibernate.search.spi.SearchFactoryIntegrator;
+import org.infinispan.commands.AbstractFlagAffectedCommand;
 import org.infinispan.commands.write.ClearCommand;
 import org.infinispan.commands.write.PutKeyValueCommand;
 import org.infinispan.commands.write.PutMapCommand;
@@ -94,8 +95,8 @@ public void injectDependencies(
       this.asyncExecutor = e;
    }
 
-   protected boolean shouldModifyIndexes(InvocationContext ctx) {
-      return ! ctx.hasFlag(Flag.SKIP_INDEXING);
+   protected boolean shouldModifyIndexes(AbstractFlagAffectedCommand command, InvocationContext ctx) {
+      return !command.hasFlag(Flag.SKIP_INDEXING);
    }
 
    /**
@@ -113,7 +114,7 @@ public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand
       // do the actual put first.
       Object toReturn = invokeNextInterceptor(ctx, command);
 
-      if (shouldModifyIndexes(ctx)) {
+      if (shouldModifyIndexes(command, ctx)) {
          // First making a check to see if the key is already in the cache or not. If it isn't we can add the key no problem,
          // otherwise we need to be updating the indexes as opposed to simply adding to the indexes.
          getLog().debug(""Infinispan Query indexing is triggered"");
@@ -138,7 +139,7 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
       // remove the object out of the cache first.
       Object valueRemoved = invokeNextInterceptor(ctx, command);
 
-      if (command.isSuccessful() && !command.isNonExistent() && shouldModifyIndexes(ctx)) {
+      if (command.isSuccessful() && !command.isNonExistent() && shouldModifyIndexes(command, ctx)) {
          Object value = extractValue(valueRemoved);
          if (updateKnownTypesIfNeeded( value )) {
             removeFromIndexes(value, extractValue(command.getKey()));
@@ -150,7 +151,7 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
    @Override
    public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
       Object valueReplaced = invokeNextInterceptor(ctx, command);
-      if (valueReplaced != null && command.isSuccessful() && shouldModifyIndexes(ctx)) {
+      if (valueReplaced != null && command.isSuccessful() && shouldModifyIndexes(command, ctx)) {
 
          Object[] parameters = command.getParameters();
          Object p1 = extractValue(parameters[1]);
@@ -174,7 +175,7 @@ public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command)
    public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) throws Throwable {
       Object mapPut = invokeNextInterceptor(ctx, command);
 
-      if (shouldModifyIndexes(ctx)) {
+      if (shouldModifyIndexes(command, ctx)) {
          Map<Object, Object> dataMap = command.getMap();
 
          // Loop through all the keys and put those key, value pairings into lucene.
@@ -195,7 +196,7 @@ public Object visitClearCommand(InvocationContext ctx, ClearCommand command) thr
       // This method is called when somebody calls a cache.clear() and we will need to wipe everything in the indexes.
       Object returnValue = invokeNextInterceptor(ctx, command);
 
-      if (shouldModifyIndexes(ctx)) {
+      if (shouldModifyIndexes(command, ctx)) {
          if (getLog().isTraceEnabled()) getLog().trace(""shouldModifyIndexes() is true and we can clear the indexes"");
 
          for (Class c : this.knownClasses.keySet()) {",2012-09-18T12:40:22Z,363
"@@ -26,6 +26,7 @@
 import org.infinispan.CacheException;
 import org.infinispan.commands.AbstractVisitor;
 import org.infinispan.commands.control.LockControlCommand;
+import org.infinispan.commands.read.GetKeyValueCommand;
 import org.infinispan.commands.tx.PrepareCommand;
 import org.infinispan.commands.write.ApplyDeltaCommand;
 import org.infinispan.commands.write.ClearCommand;
@@ -65,8 +66,8 @@ public class OptimisticLockingInterceptor extends AbstractTxLockingInterceptor {
 
    private LockAcquisitionVisitor lockAcquisitionVisitor;
    private static final MurmurHash3 HASH = new MurmurHash3();
+   private boolean needToMarkReads;
    private final static Comparator<Object> keyComparator = new Comparator<Object>() {
-
       @Override
       public int compare(Object o1, Object o2) {
          int thisVal = HASH.hash(o1);
@@ -95,11 +96,20 @@ public void start() {
             configuration.isWriteSkewCheck() &&
             configuration.getIsolationLevel() == IsolationLevel.REPEATABLE_READ) {
          lockAcquisitionVisitor = new LocalWriteSkewCheckingLockAcquisitionVisitor();
+         needToMarkReads = true;
       } else {
          lockAcquisitionVisitor = new LockAcquisitionVisitor();
+         needToMarkReads = false;
       }
    }
 
+   private void markKeyAsRead(InvocationContext ctx, Object key) {
+      if (needToMarkReads && ctx.isInTxScope()) {
+         TxInvocationContext tctx = (TxInvocationContext) ctx;
+         tctx.getCacheTransaction().addReadKey(key);
+      }
+   }
+   
    @Override
    public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand command) throws Throwable {
       abortIfRemoteTransactionInvalid(ctx, command);
@@ -125,12 +135,19 @@ public Object visitPrepareCommand(TxInvocationContext ctx, PrepareCommand comman
    @Override
    public Object visitPutKeyValueCommand(InvocationContext ctx, PutKeyValueCommand command) throws Throwable {
       try {
+         if (command.isConditional()) markKeyAsRead(ctx, command.getKey());
          return invokeNextInterceptor(ctx, command);
       } catch (Throwable te) {
          throw cleanLocksAndRethrow(ctx, te);
       }
    }
    
+   @Override
+   public Object visitGetKeyValueCommand(InvocationContext ctx, GetKeyValueCommand command) throws Throwable {
+      markKeyAsRead(ctx, command.getKey());
+      return super.visitGetKeyValueCommand(ctx, command);
+   }
+   
    @Override
    public Object visitApplyDeltaCommand(InvocationContext ctx, ApplyDeltaCommand command) throws Throwable {
       try {
@@ -152,6 +169,7 @@ public Object visitPutMapCommand(InvocationContext ctx, PutMapCommand command) t
    @Override
    public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) throws Throwable {
       try {
+         if (command.isConditional()) markKeyAsRead(ctx, command.getKey());
          return invokeNextInterceptor(ctx, command);
       } catch (Throwable te) {
          throw cleanLocksAndRethrow(ctx, te);
@@ -161,6 +179,7 @@ public Object visitRemoveCommand(InvocationContext ctx, RemoveCommand command) t
    @Override
    public Object visitReplaceCommand(InvocationContext ctx, ReplaceCommand command) throws Throwable {
       try {
+         markKeyAsRead(ctx, command.getKey());
          return invokeNextInterceptor(ctx, command);
       } catch (Throwable te) {
          throw cleanLocksAndRethrow(ctx, te);
@@ -254,8 +273,8 @@ private class LocalWriteSkewCheckingLockAcquisitionVisitor extends LockAcquisiti
       @Override
       protected void performWriteSkewCheck(TxInvocationContext ctx, Object key) {
          CacheEntry ce = ctx.lookupEntry(key);
-         if (ce instanceof RepeatableReadEntry) {
-            ((RepeatableReadEntry) ce).performLocalWriteSkewCheck(dataContainer, true);
+         if (ce instanceof RepeatableReadEntry && ctx.getCacheTransaction().keyRead(key)) {
+               ((RepeatableReadEntry) ce).performLocalWriteSkewCheck(dataContainer, true);
          }
       }
    }",2012-03-28T06:27:41Z,444
"@@ -200,4 +200,14 @@ public EntryVersionsMap getUpdatedEntryVersions() {
    public void setUpdatedEntryVersions(EntryVersionsMap updatedEntryVersions) {
       this.updatedEntryVersions = updatedEntryVersions;
    }
+   
+   @Override
+   public void addReadKey(Object key) {
+      // No-op
+   }
+   
+   @Override
+   public boolean keyRead(Object key) {
+      return false;
+   }
 }",2012-03-28T06:27:41Z,541
"@@ -53,6 +53,7 @@ public abstract class LocalTransaction extends AbstractCacheTransaction {
    private static final boolean trace = log.isTraceEnabled();
 
    private Set<Address> remoteLockedNodes;
+   protected Set<Object> readKeys = null;
 
    /** mark as volatile as this might be set from the tx thread code on view change*/
    private volatile boolean isMarkedForRollback;
@@ -169,4 +170,15 @@ public String toString() {
    public void setModifications(List<WriteCommand> modifications) {
       this.modifications = modifications;
    }
+
+   @Override
+   public void addReadKey(Object key) {
+      if (readKeys == null) readKeys = new HashSet<Object>(2);
+      readKeys.add(key);
+   }
+
+   @Override
+   public boolean keyRead(Object key) {
+      return readKeys != null && readKeys.contains(key);
+   }
 }",2012-03-28T06:27:41Z,454
"@@ -84,4 +84,8 @@ public interface CacheTransaction {
    EntryVersionsMap getUpdatedEntryVersions();
 
    void setUpdatedEntryVersions(EntryVersionsMap updatedEntryVersions);
+
+   boolean keyRead(Object key);
+
+   void addReadKey(Object key);
 }",2012-03-28T06:27:41Z,544
